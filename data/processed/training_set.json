{
    "instances": [
        {
            "instance_id": "R108331xR108312",
            "comparison_id": "R108331",
            "paper_id": "R108312",
            "text": "Rapid knowledge work visualization for organizations purpose \u2013 the purpose of this contribution is to motivate a new, rapid approach to modeling knowledge work in organizational settings and to introduce a software tool that demonstrates the viability of the envisioned concept.design/methodology/approach \u2013 based on existing modeling structures, the knowflow toolset that aids knowledge analysts in rapidly conducting interviews and in conducting multi\u2010perspective analysis of organizational knowledge work is introduced.findings \u2013 this article demonstrates how rapid knowledge work visualization can be conducted largely without human modelers by developing an interview structure that allows for self\u2010service interviews. two application scenarios illustrate the pressing need for and the potentials of rapid knowledge work visualizations in organizational settings.research limitations/implications \u2013 the efforts necessary for traditional modeling approaches in the area of knowledge management are often prohibitive. this contribution argues that future research needs ...",
            "contribution_ids": [
                "R108314"
            ]
        },
        {
            "instance_id": "R108331xR108292",
            "comparison_id": "R108331",
            "paper_id": "R108292",
            "text": "Process Oriented Knowledge Management: A Service Based Approach this paper introduces a new viewpoint in knowledge management by introducing km-services as a basic concept for knowledge management. this text discusses the vision of service oriented knowledge management (km) as a realisation approach of process oriented knowledge management. in the following process oriented knowledge management as it was defined in the eu-project promote (ist-1999-11658) is presented and the km-service approach to realise process oriented knowledge management is explained. the last part is concerned with an implementation scenario that uses web-technology to realise a service framework for a km-system.",
            "contribution_ids": [
                "R108293"
            ]
        },
        {
            "instance_id": "R108331xR108321",
            "comparison_id": "R108331",
            "paper_id": "R108321",
            "text": "Modelling knowledge transfer: A knowledge dynamics perspective the increasing complexity in design activities leads designers to collaborate and share knowledge within distributed teams. this makes designers use systems such as knowledge management systems to reach their goal. in this article, our aim is to investigate on improving the use of knowledge management systems by defining a framework for modelling knowledge transfer in such context. the proposed framework is partly based on reuse of existing models found in the literature and on a participant observation methodology. then, we tested this framework through several case studies presented in this article. these investigations enable us to observe, define and model more finely the knowledge dynamics that occur between knowledge workers and knowledge management systems.",
            "contribution_ids": [
                "R108323"
            ]
        },
        {
            "instance_id": "R108331xR108307",
            "comparison_id": "R108331",
            "paper_id": "R108307",
            "text": "Knowledge modelling in weakly\u00e2\u0080\u0090structured business processes in this paper we present a new approach for integrating knowledge management and business process management. we focus on the modelling of weakly\u2010structured knowledge\u2010intensive business processes. we develop a framework for modelling this type of processes that explicitly considers knowledge\u2010related tasks and knowledge objects and present a workflow tool that is an implementation of our theoretical meta\u2010model. as an example, we sketch one case study, the process for granting full old age pension as it is performed in the greek social security institution. finally we briefly describe some related approaches and compare them to our work and draw the main conclusions and further research directions.",
            "contribution_ids": [
                "R108309"
            ]
        },
        {
            "instance_id": "R108331xR108301",
            "comparison_id": "R108331",
            "paper_id": "R108301",
            "text": "A notation for Knowledge-Intensive Processes \"business process modeling has become essential for managing organizational knowledge artifacts. however, this is not an easy task, especially when it comes to the so-called knowledge-intensive processes (kips). a kip comprises activities based on acquisition, sharing, storage, and (re)use of knowledge, as well as collaboration among participants, so that the amount of value added to the organization depends on process agents' knowledge. the previously developed knowledge intensive process ontology (kipo) structures all the concepts (and relationships among them) to make a kip explicit. nevertheless, kipo does not include a graphical notation, which is crucial for kip stakeholders to reach a common understanding about it. this paper proposes the knowledge intensive process notation (kipn), a notation for building knowledge-intensive processes graphical models.\"",
            "contribution_ids": [
                "R108303"
            ]
        },
        {
            "instance_id": "R108331xR108325",
            "comparison_id": "R108331",
            "paper_id": "R108325",
            "text": "Modeling Knowledge Work for the Design of Knowledge Infrastructures during the last years, a large number of information and communication technologies (ict) have been proposed to be supportive of knowledge management (km). several km instruments have been developed and implemented in many organizations that require support by ict. recently, many of these technologies are bundled in the form of comprehensive, enterprise-wide knowledge infrastructures. the implementation of both, instruments and infrastructures, requires adequate modeling techniques that consider the specifics of modeling context in knowledge work. the paper studies knowledge work, km instruments and knowledge infrastructures. modeling techniques are reviewed, especially for business process management and activity theory. the concept of knowledge stance is discussed in order to relate functions from process models to actions from activity theory, thus detailing the context relevant for knowledge work.",
            "contribution_ids": [
                "R108326"
            ]
        },
        {
            "instance_id": "R108332xR108316",
            "comparison_id": "R108332",
            "paper_id": "R108316",
            "text": "Analyzing Knowledge Transfer Effectiveness--An Agent-Oriented Modeling Approach \"facilitating the transfer of knowledge between knowledge workers represents one of the main challenges of knowledge management. knowledge transfer instruments, such as the experience factory concept, represent means for facilitating knowledge transfer in organizations. as past research has shown, effectiveness of knowledge transfer instruments strongly depends on their situational context, on the stakeholders involved in knowledge transfer, and on their acceptance, motivation and goals. in this paper, we introduce an agent-oriented modeling approach for analyzing the effectiveness of knowledge transfer instruments in the light of (potentially conflicting) stakeholders' goals. we apply this intentional approach to the experience factory concept and analyze under which conditions it can fail, and how adaptations to the experience factory can be explored in a structured way\"",
            "contribution_ids": [
                "R108318"
            ]
        },
        {
            "instance_id": "R108332xR108328",
            "comparison_id": "R108332",
            "paper_id": "R108328",
            "text": "Modeling Techniques for Knowledge Management:  knowledge management is an umbrella concept for different management tasks and activities. various modeling abstractions and techniques have been developed providing specialized support for different knowledge management tasks. this article gives an overview of modeling abstractions that are frequently discussed in the knowledge management literature as well as some promising techniques in a mature research state. six groups of modeling techniques are presented and additionally evaluated with respect to their suitability for different fields of applications within the knowledge management domain.",
            "contribution_ids": [
                "R108330"
            ]
        },
        {
            "instance_id": "R108332xR108321",
            "comparison_id": "R108332",
            "paper_id": "R108321",
            "text": "Modelling knowledge transfer: A knowledge dynamics perspective the increasing complexity in design activities leads designers to collaborate and share knowledge within distributed teams. this makes designers use systems such as knowledge management systems to reach their goal. in this article, our aim is to investigate on improving the use of knowledge management systems by defining a framework for modelling knowledge transfer in such context. the proposed framework is partly based on reuse of existing models found in the literature and on a participant observation methodology. then, we tested this framework through several case studies presented in this article. these investigations enable us to observe, define and model more finely the knowledge dynamics that occur between knowledge workers and knowledge management systems.",
            "contribution_ids": [
                "R108323"
            ]
        },
        {
            "instance_id": "R108332xR108301",
            "comparison_id": "R108332",
            "paper_id": "R108301",
            "text": "A notation for Knowledge-Intensive Processes \"business process modeling has become essential for managing organizational knowledge artifacts. however, this is not an easy task, especially when it comes to the so-called knowledge-intensive processes (kips). a kip comprises activities based on acquisition, sharing, storage, and (re)use of knowledge, as well as collaboration among participants, so that the amount of value added to the organization depends on process agents' knowledge. the previously developed knowledge intensive process ontology (kipo) structures all the concepts (and relationships among them) to make a kip explicit. nevertheless, kipo does not include a graphical notation, which is crucial for kip stakeholders to reach a common understanding about it. this paper proposes the knowledge intensive process notation (kipn), a notation for building knowledge-intensive processes graphical models.\"",
            "contribution_ids": [
                "R108303"
            ]
        },
        {
            "instance_id": "R108332xR108296",
            "comparison_id": "R108332",
            "paper_id": "R108296",
            "text": "B-KIDE: a framework and a tool for business process-oriented knowledge infrastructure development \"the need for an effective management of knowledge is gaining increasing recognition in today's economy. to acknowledge this fact, new promising and powerful technologies have emerged from industrial and academic research. with these innovations maturing, organizations are increasingly willing to adapt such new knowledge management technologies to improve their knowledge-intensive businesses. however, the successful application in given business contexts is a complex, multidimensional challenge and a current research topic. therefore, this contribution addresses this challenge and introduces a framework for the development of business process-supportive, technological knowledge infrastructures. while business processes represent the organizational setting for the application of knowledge management technologies, knowledge infrastructures represent a concept that can enable knowledge management in organizations. the b-kide framework introduced in this work provides support for the development of knowledge infrastructures that comprise innovative knowledge management functionality and are visibly supportive of an organization's business processes. the developed b-kide tool eases the application of the b-kide framework for knowledge infrastructure developers. three empirical studies that were conducted with industrial partners from heterogeneous industry sectors corroborate the relevance and viability of the introduced concepts. copyright \u00a9 2005 john wiley & sons, ltd.\"",
            "contribution_ids": [
                "R108298"
            ]
        },
        {
            "instance_id": "R108332xR108312",
            "comparison_id": "R108332",
            "paper_id": "R108312",
            "text": "Rapid knowledge work visualization for organizations purpose \u2013 the purpose of this contribution is to motivate a new, rapid approach to modeling knowledge work in organizational settings and to introduce a software tool that demonstrates the viability of the envisioned concept.design/methodology/approach \u2013 based on existing modeling structures, the knowflow toolset that aids knowledge analysts in rapidly conducting interviews and in conducting multi\u2010perspective analysis of organizational knowledge work is introduced.findings \u2013 this article demonstrates how rapid knowledge work visualization can be conducted largely without human modelers by developing an interview structure that allows for self\u2010service interviews. two application scenarios illustrate the pressing need for and the potentials of rapid knowledge work visualizations in organizational settings.research limitations/implications \u2013 the efforts necessary for traditional modeling approaches in the area of knowledge management are often prohibitive. this contribution argues that future research needs ...",
            "contribution_ids": [
                "R108314"
            ]
        },
        {
            "instance_id": "R108358xR108102",
            "comparison_id": "R108358",
            "paper_id": "R108102",
            "text": "First impressions from the PRISMA  hyperspectral mission prisma is a hyperspectral mission launched by the italian space agency on 21 march 2019. prisma is the spaceborne hyperspectral sensor which provides imageries of the earth\u2019s surface with (i) global coverage of 30 km \u00d7 30 km with a total acquisition capacity of 1800 km in a continuous strip, and (ii) spectral resolution of 12 nm for the contiguous bands (400\u2013 2500 nm wavelength). this study presents a review of the hyperspectral datasets from prisma for geological applications. a few geological regions from india are selected to check the capability of the prisma datasets. dimensionality reduction and spectral analysis were performed and narrowband indices were generated. few constraints with the previous hyperspectral sensors, i.e. large swath with a medium resolution camera on-board, are now covered in the prisma mission. this study is focused on the characteristics and compatibilities of the prisma hyperspectral sensor and will be beneficial to the scientific and users community.",
            "contribution_ids": [
                "R108105"
            ]
        },
        {
            "instance_id": "R108358xR108129",
            "comparison_id": "R108358",
            "paper_id": "R108129",
            "text": "Comparison of Airborne Hyperspectral Data and EO-1 Hyperion for Mineral Mapping \"airborne hyperspectral data have been available to researchers since the early 1980s and their use for geologic applications is well documented. the launch of the national aeronautics and space administration earth observing 1 hyperion sensor in november 2000 marked the establishment of a test bed for spaceborne hyperspectral capabilities. hyperion covers the 0.4-2.5-/spl mu/m range with 242 spectral bands at approximately 10-nm spectral resolution and 30-m spatial resolution. analytical imaging and geophysics llc and the commonwealth scientific and industrial research organisation have been involved in efforts to evaluate, validate, and demonstrate hyperions's utility for geologic mapping in a variety of sites in the united states and around the world. initial results over several sites with established ground truth and years of airborne hyperspectral data show that hyperion data from the shortwave infrared spectrometer can be used to produce useful geologic (mineralogic) information. minerals mapped include carbonates, chlorite, epidote, kaolinite, alunite, buddingtonite, muscovite, hydrothermal silica, and zeolite. hyperion data collected under optimum conditions (summer season, bright targets, well-exposed geology) indicate that hyperion data meet prelaunch specifications and allow subtle distinctions such as determining the difference between calcite and dolomite and mapping solid solution differences in micas caused by substitution in octahedral molecular sites. comparison of airborne hyperspectral data [from the airborne visible/infrared imaging spectrometer (aviris)] to the hyperion data establishes that hyperion provides similar basic mineralogic information, with the principal limitation being limited mapping of fine spectral detail under less-than-optimum acquisition conditions (winter season, dark targets) based on lower signal-to-noise ratios. case histories demonstrate the analysis methodologies and level of information available from the hyperion data. they also show the viability of hyperion as a means of extending hyperspectral mineral mapping to areas not accessible to aircraft sensors. the analysis results demonstrate that spaceborne hyperspectral sensors can produce useful mineralogic information, but also indicate that snr improvements are required for future spaceborne sensors to allow the same level of mapping that is currently possible from airborne sensors such as aviris.\"",
            "contribution_ids": [
                "R108130"
            ]
        },
        {
            "instance_id": "R108358xR108126",
            "comparison_id": "R108358",
            "paper_id": "R108126",
            "text": "The Performance of the Satellite-borne Hyperion Hyperspectral VNIR-SWIR Imaging System for Mineral Mapping at Mount Fitton, South Australia \"satellite-based hyperspectral imaging became a reality in november 2000 with the successful launch and operation of the hyperion system on board the eo-1 platform. hyperion is a pushbroom imager with 220 spectral bands in the 400-2500 nm wavelength range, a 30 meter pixel size and a 7.5 km swath. pre-launch characterization of hyperion measured low signal to noise (snr<40:1) for the geologically significant shortwave infrared (swir) wavelength region (2000-2500 nm). the impact of this low snr on hyperion's capacity to resolve spectral detail was evaluated for the mount fitton test site in south australia, which comprises a diverse range of minerals with narrow, diagnostic absorption bands in the swir. following radiative transfer correction of the hyperion radiance at sensor data to surface radiance (apparent reflectance), diagnostic spectral signatures were clearly apparent, including: green vegetation; talc; dolomite; chlorite; white mica and possibly tremolite. even though the derived surface composition maps generated from these image endmembers were noisy (both random and column), they were nonetheless spatially coherent and correlated well with the known geology. in addition, the hyperion data were used to measure and map spectral shifts of <10 nm in the swir related to white mica chemical variations.\"",
            "contribution_ids": [
                "R108127"
            ]
        },
        {
            "instance_id": "R108358xR108147",
            "comparison_id": "R108358",
            "paper_id": "R108147",
            "text": "Potential of airborne hyperspectral data for  geo-exploration over parts of different  geological/metallogenic provinces in India based on AVIRIS-NG observations satadru bhattacharya*, hrishikesh kumar, arindam guha, aditya k. dagar, sumit pathak, komal rani (pasricha), s. mondal, k. vinod kumar, william farrand, snehamoy chatterjee, s. ravi, a. k. sharma and a. s. rajawat space applications centre, indian space research organisation, ahmedabad 380 015, india national remote sensing centre, indian space research organisation, hyderabad 500 042, india department of geophysics, indian institute of technology (ism), dhanbad 826 004, india space science institute, boulder, colorado 80301, usa department of geological and mining engineering and sciences, michigan technological university, houghton, michigan 49931, usa geological survey of india training institute, bandlaguda, hyderabad 500 068, india",
            "contribution_ids": [
                "R108148"
            ]
        },
        {
            "instance_id": "R109612xR109394",
            "comparison_id": "R109612",
            "paper_id": "R109394",
            "text": "Heterotrophic bacteria as major nitrogen fixers in the euphotic zone of the Indian Ocean diazotrophy in the indian ocean is poorly understood compared to that in the atlantic and pacific oceans. we first examined the basin\u2010scale community structure of diazotrophs and their nitrogen fixation activity within the euphotic zone during the northeast monsoon period along about 69\u00b0e from 17\u00b0n to 20\u00b0s in the oligotrophic indian ocean, where a shallow nitracline (49\u201359\\u2009m) prevailed widely and the sea surface temperature (sst) was above 25\u00b0c. phosphate was detectable at the surface throughout the study area. the dissolved iron concentration and the ratio of iron to nitrate\\u2009+\\u2009nitrite at the surface were significantly higher in the arabian sea than in the equatorial and southern indian ocean. nitrogen fixation in the arabian sea (24.6\u201347.1 \u03bcmoln m\u22122 d\u22121) was also significantly greater than that in the equatorial and southern indian ocean (6.27\u201316.6 \u03bcmoln m\u22122 d\u22121), indicating that iron could control diazotrophy in the indian ocean. phylogenetic analysis of nifh showed that most diazotrophs belonged to the proteobacteria and that cyanobacterial diazotrophs were absent in the study area except in the arabian sea. furthermore, nitrogen fixation was not associated with light intensity throughout the study area. these results are consistent with nitrogen fixation in the indian ocean, being largely performed by heterotrophic bacteria and not by cyanobacteria. the low cyanobacterial diazotrophy was attributed to the shallow nitracline, which is rarely observed in the pacific and atlantic oligotrophic oceans. because the shallower nitracline favored enhanced upward nitrate flux, the competitive advantage of cyanobacterial diazotrophs over nondiazotrophic phytoplankton was not as significant as it is in other oligotrophic oceans.",
            "contribution_ids": [
                "R109395",
                "R109572",
                "R109590"
            ]
        },
        {
            "instance_id": "R109612xR108803",
            "comparison_id": "R109612",
            "paper_id": "R108803",
            "text": "Dinitrogen fixation rates in the Bay of Bengal during summer monsoon abstract \\n biological dinitrogen (n 2 ) fixation exerts an important control on oceanic primary production by providing bioavailable form of nitrogen (such as ammonium) to photosynthetic microorganisms. n 2 fixation is dominant in nutrient poor and warm surface waters. the bay of bengal is one such region where no measurements of phototrophic n 2 fixation rates exist. the surface water of the bay of bengal is generally nitrate-poor and warm due to prevailing stratification and thus, could favour n 2 fixation. we commenced the first n 2 fixation study in the photic zone of the bay of bengal using 15 n 2 gas tracer incubation experiment during summer monsoon 2018. we collected seawater samples from four depths (covering the mixed layer depth of up to 75 m) at eight stations. n 2 fixation rates varied from 4 to 75 \u03bc mol n m \u22122 d \u22121 . the contribution of n 2 fixation to primary production was negligible (&lt;1%). however, the upper bound of observed n 2 fixation rates is higher than the rates measured in other oceanic regimes, such as the eastern tropical south pacific, the tropical northwest atlantic, and the equatorial and southern indian ocean.",
            "contribution_ids": [
                "R108807",
                "R109398",
                "R109582",
                "R109597",
                "R138414"
            ]
        },
        {
            "instance_id": "R109612xR109569",
            "comparison_id": "R109612",
            "paper_id": "R109569",
            "text": "An extensive bloom of the N2-fixing cyanobacterium Trichodesmium erythraeum in the central Arabian Sea \"lve encountered an extensive surface bloom of the n, fixing cyanobactenum trichodesrniurn erythraeum in the central basin of the arabian sea during the spring ~nter-n~onsoon of 1995. the bloom, which occurred dunng a penod of calm winds and relatively high atmospher~c iron content, was metabollcally active. carbon fixation by the bloom represented about one-quarter of water column primary productivity while input by h:: flxation could account for a major fraction of the estimated 'new' n demand of pnmary production. isotopic measurements of the n in surface suspended material confirmed a direct contribution of n, fixation to the organic nltrogen pools of the upper water column. retrospective analysis of noaa-12 avhrr imagery indicated that blooms covered up to 2 x 106 km2, or 20% of the arabian sea surface, during the period from 22 to 27 may 1995. in addition to their biogeochemical impact, surface blooms of this extent may have secondary effects on sea surface albedo and light penetration as well as heat and gas exchange across the air-sea interface. a preliminary extrapolation based on our observed, non-bloom rates of n, fixation from our limited sampling in the spring intermonsoon, including a conservative estimate of the input by blooms, suggest n2 fixation may account for an input of about 1 tg n yr-i this is substantial, but relatively minor compared to current estimates of the removal of n through denitrification in the basin. however, n2 fixation may also occur in the central basin through the mild winter monsoon, be considerably greater during the fall intermonsoon than we observed during the spring intermonsoon, and may also occur at higher levels in the chronically oligotrophic southern basin. ongoing satellite observations will help to determine more accurately the distribution and density of trichodesmium in this and other tropical oceanic basins, as well as resolving the actual frequency and duration of bloom occurrence.\"",
            "contribution_ids": [
                "R109570",
                "R109586"
            ]
        },
        {
            "instance_id": "R109612xR109392",
            "comparison_id": "R109612",
            "paper_id": "R109392",
            "text": "First direct measurements of N2 fixation during a Trichodesmium bloom in the eastern Arabian Sea we report the first direct estimates of n2 fixation rates measured during the spring, 2009 using the 15n2 gas tracer technique in the eastern arabian sea, which is well known for significant loss of nitrogen due to intense denitrification. carbon uptake rates are also concurrently estimated using the 13c tracer technique. the n2 fixation rates vary from \u223c0.1 to 34 mmol n m\u22122d\u22121 after correcting for the isotopic under\u2010equilibrium with dissolved air in the samples. these higher n2 fixation rates are consistent with higher chlorophyll a and low \u03b415n of natural particulate organic nitrogen. our estimates of n2 fixation is a useful step toward reducing the uncertainty in the nitrogen budget.",
            "contribution_ids": [
                "R109393",
                "R109571",
                "R109588"
            ]
        },
        {
            "instance_id": "R109904xR109875",
            "comparison_id": "R109904",
            "paper_id": "R109875",
            "text": "A survey of Chinese interpreting studies: who influences who \u00e2\u0080\u00a6and why? this paper describes how scholars in chinese interpreting studies (cis) interact with each other and form discrete circles of influence. it also discusses what it means to be an influential scholar in the community and the relationship between an author\u2019s choice of research topic and his academic influence. the study examines an all-but-exhaustive collection of 59,303 citations from 1,289 ma theses, 32 doctoral dissertations and 2,909 research papers, combining traditional citation analysis with the newer social network analysis to paint a panorama of cis. it concludes that the community cannot be broadly divided into liberal arts and empirical science camps; rather, it comprises several distinct communities with various defining features. the analysis also reveals that the top western influencers have an array of academic backgrounds and research interests across many different disciplines, whereas their chinese counterparts are predominantly focused on interpreting studies. last but not least, there is found to be a positive correlation between choosing non-mainstream research topics and having a high level of academic influence in the community.",
            "contribution_ids": [
                "R109877"
            ]
        },
        {
            "instance_id": "R109904xR109854",
            "comparison_id": "R109904",
            "paper_id": "R109854",
            "text": "A systematic metadata harvesting workflow for analysing scientific networks one of the disciplines behind the science of science is the study of scientific networks. this work focuses on scientific networks as a social network having different nodes and connections. nodes can be represented by authors, articles or journals while connections by citation, co-citation or co-authorship. one of the challenges in creating scientific networks is the lack of publicly available comprehensive data set. it limits the variety of analyses on the same set of nodes of different scientific networks. to supplement such analyses we have worked on publicly available citation metadata from crossref and opencitatons. using this data a workflow is developed to create scientific networks. analysis of these networks gives insights into academic research and scholarship. different techniques of social network analysis have been applied in the literature to study these networks. it includes centrality analysis, community detection, and clustering coefficient. we have used metadata of scientometrics journal, as a case study, to present our workflow. we did a sample run of the proposed workflow to identify prominent authors using centrality analysis. this work is not a bibliometric study of any field rather it presents replicable python scripts to perform network analysis. with an increase in the popularity of open access and open metadata, we hypothesise that this workflow shall provide an avenue for understanding scientific scholarship in multiple dimensions.",
            "contribution_ids": [
                "R109858"
            ]
        },
        {
            "instance_id": "R111045xR111005",
            "comparison_id": "R111045",
            "paper_id": "R111005",
            "text": "White-light emission from discrete heterometallic lanthanide-directed self-assembled complexes in solution herein, we have developed a white-light-emitting system based on the formation of discrete lanthanide-based self-assembled complexes using a newly-designed ligand. we demonstrate that fine tuning of the lanthanide ions molar ratio in the self-assemblies combined with the intrinsic blue fluorescence of the ligand allows for the successful emission of pure white light with cie coordinates of (0.33, 0.34).",
            "contribution_ids": [
                "R111010"
            ]
        },
        {
            "instance_id": "R111045xR110972",
            "comparison_id": "R111045",
            "paper_id": "R110972",
            "text": "Mixed Methyl Aryloxy Rare-Earth-Metal Complexes Stabilized by a Superbulky Tris(pyrazolyl)borato Ligand various mixed methyl aryloxide complexes tptbu,melnme(oar) (ln = y, lu) were obtained in moderate to high yields according to distinct synthesis protocols dependent on the metal size and sterics of the phenolic proligand. the reaction of tptbu,melume2 and tptbu,meyme(alme4) via protonolysis with 1 or 2 equiv hoc6h2tbu2-2,6-me-4 in n-hexane gave the desired complexes tptbu,melnme(oar). corresponding treatment of tptbu,melume2 with the sterically less demanding hoc6h3me2-2,6, hoc6h3ipr2-2,6 and hoc6h3(cf3)2-3,5 led to the formation of the bis(aryloxy) lutetium complexes tptbu,melu(oar)2. application of a salt-metathesis protocol employing tptbu,melnme(alme4) and the potassium aryloxides koar made complexes tptbu,melnme(oar) accessible for the smaller aryloxy ligands as well. all complexes were analyzed by x-ray crystallography to compare the terminal ln\u2013me bond lengths and to evaluate the implication of the methyl/aryloxy coordination for the exact cone angles \u03b8\u00b0 of the [tptbu,me] ancillary ligand. treatmen...",
            "contribution_ids": [
                "R110977"
            ]
        },
        {
            "instance_id": "R111045xR111023",
            "comparison_id": "R111045",
            "paper_id": "R111023",
            "text": "Access to divalent lanthanide NHC complexes by redox-transmetallation from silver and CO2 insertion reactions divalent nhc\u2013lanthanide complexes were obtained by redox-transmetallation. treatment with co 2 led to insertion reactions without oxidation of the metal centre.",
            "contribution_ids": [
                "R111028"
            ]
        },
        {
            "instance_id": "R112387xR111969",
            "comparison_id": "R112387",
            "paper_id": "R111969",
            "text": "User Feedback from Tweets vs App Store Reviews: An Exploratory Study of Frequency, Timing and Content context: user feedback on apps is essential for gauging market needs and maintaining a competitive edge in the mobile apps development industry. app store reviews have been a primary resource for this feedback, however, recent studies have observed that twitter is another potentially valuable source for this information. objective: the objective of this study is to assess user feedback from twitter in terms of timing as well as content and compare with the app store reviews. method: this study employs various text analysis and natural language processing methods such as semantic analysis and latent dirichlet allocation (lda) to analyze tweets and app store reviews. additionally, supervised learning classifiers are used to classify them as semantically similar tweet and app store reviews. results: in spite of a difference in the magnitude between tweets and app store review counts, frequency analysis shows that bug report and feature request are discussed mostly on twitter first as the number of tweets during the reporting time reached the peak a few days earlier. likewise, timing analysis on a set of 426 tweets and 2,383 reviews (which are bug reports and feature requests) show that approximately 15% appear on twitter first. of these 15% tweets, 72% are related to functional or behavioural aspects of the mobile app. content analysis shows that user feedback in tweets mostly focuses on critical issues related to the feature failure and improper functionality. conclusion: the results of this investigation show that the twitter is not only a strong contender for useful information but also a faster source of information for mobile app improvement.",
            "contribution_ids": [
                "R111971"
            ]
        },
        {
            "instance_id": "R112387xR108341",
            "comparison_id": "R112387",
            "paper_id": "R108341",
            "text": "Release planning of mobile apps based on user reviews developers have to to constantly improve their apps by fixing critical bugs and implementing the most desired features in order to gain shares in the continuously increasing and competitive market of mobile apps. a precious source of information to plan such activities is represented by reviews left by users on the app store. however, in order to exploit such information developers need to manually analyze such reviews. this is something not doable if, as frequently happens, the app receives hundreds of reviews per day. in this paper we introduce clap (crowd listener for release planning), a thorough solution to (i) categorize user reviews based on the information they carry out (e.g., bug reporting), (ii) cluster together related reviews (e.g., all reviews reporting the same bug), and (iii) automatically prioritize the clusters of reviews to be implemented when planning the subsequent app release. we evaluated all the steps behind clap, showing its high accuracy in categorizing and clustering reviews and the meaningfulness of the recommended prioritizations. also, given the availability of clap as a working tool, we assessed its practical applicability in industrial environments.",
            "contribution_ids": [
                "R109123"
            ]
        },
        {
            "instance_id": "R112387xR112015",
            "comparison_id": "R112387",
            "paper_id": "R112015",
            "text": "A Little Bird Told Me: Mining Tweets for Requirements and Software Evolution \"twitter is one of the most popular social networks. previous research found that users employ twitter to communicate about software applications via short messages, commonly referred to as tweets, and that these tweets can be useful for requirements engineering and software evolution. however, due to their large number---in the range of thousands per day for popular applications---a manual analysis is unfeasible.in this work we present alertme, an approach to automatically classify, group and rank tweets about software applications. we apply machine learning techniques for automatically classifying tweets requesting improvements, topic modeling for grouping semantically related tweets and a weighted function for ranking tweets according to specific attributes, such as content category, sentiment and number of retweets. we ran our approach on 68,108 collected tweets from three software applications and compared its results against software practitioners' judgement. our results show that alertme is an effective approach for filtering, summarizing and ranking tweets about software applications. alertme enables the exploitation of twitter as a feedback channel for information relevant to software evolution, including end-user requirements.\"",
            "contribution_ids": [
                "R112017"
            ]
        },
        {
            "instance_id": "R112387xR78466",
            "comparison_id": "R112387",
            "paper_id": "R78466",
            "text": "How can I improve my app? Classifying user reviews for software maintenance and evolution app stores, such as google play or the apple store, allow users to provide feedback on apps by posting review comments and giving star ratings. these platforms constitute a useful electronic mean in which application developers and users can productively exchange information about apps. previous research showed that users feedback contains usage scenarios, bug reports and feature requests, that can help app developers to accomplish software maintenance and evolution tasks. however, in the case of the most popular apps, the large amount of received feedback, its unstructured nature and varying quality can make the identification of useful user feedback a very challenging task. in this paper we present a taxonomy to classify app reviews into categories relevant to software maintenance and evolution, as well as an approach that merges three techniques: (1) natural language processing, (2) text analysis and (3) sentiment analysis to automatically classify app reviews into the proposed categories. we show that the combined use of these techniques allows to achieve better results (a precision of 75% and a recall of 74%) than results obtained using each technique individually (precision of 70% and a recall of 67%).",
            "contribution_ids": [
                "R78468"
            ]
        },
        {
            "instance_id": "R112387xR76818",
            "comparison_id": "R112387",
            "paper_id": "R76818",
            "text": "App Review Analysis Via Active Learning: Reducing Supervision Effort without Compromising Classification Accuracy automated app review analysis is an important avenue for extracting a variety of requirements-related information. typically, a first step toward performing such analysis is preparing a training dataset, where developers (experts) identify a set of reviews and, manually, annotate them according to a given task. having sufficiently large training data is important for both achieving a high prediction accuracy and avoiding overfitting. given millions of reviews, preparing a training set is laborious. we propose to incorporate active learning, a machine learning paradigm, in order to reduce the human effort involved in app review analysis. our app review classification framework exploits three active learning strategies based on uncertainty sampling. we apply these strategies to an existing dataset of 4,400 app reviews for classifying app reviews as features, bugs, rating, and user experience. we find that active learning, compared to a training dataset chosen randomly, yields a significantly higher prediction accuracy under multiple scenarios.",
            "contribution_ids": [
                "R195137",
                "R76820",
                "R76825"
            ]
        },
        {
            "instance_id": "R112387xR112000",
            "comparison_id": "R112387",
            "paper_id": "R112000",
            "text": "Ensemble Methods for App Review Classification: An Approach for Software Evolution (N) app marketplaces are distribution platforms for mobile applications that serve as a communication channel between users and developers. these platforms allow users to write reviews about downloaded apps. recent studies found that such reviews include information that is useful for software evolution. however, the manual analysis of a large amount of user reviews is a tedious and time consuming task. in this work we propose a taxonomy for classifying app reviews into categories relevant for software evolution. additionally, we describe an experiment that investigates the performance of individual machine learning algorithms and its ensembles for automatically classifying the app reviews. we evaluated the performance of the machine learning techniques on 4550 reviews that were systematically labeled using content analysis methods. overall, the ensembles had a better performance than the individual classifiers, with an average precision of 0.74 and 0.59 recall.",
            "contribution_ids": [
                "R112002"
            ]
        },
        {
            "instance_id": "R112387xR111979",
            "comparison_id": "R112387",
            "paper_id": "R111979",
            "text": "\"What Parts of Your Apps are Loved by Users?\" (T) recently, begel et al. found that one of the most important questions software developers ask is \"what parts of software are used/loved by users.\" user reviews provide an effective channel to address this question. however, most existing review summarization tools treat reviews as bags-of-words (i.e., mixed review categories) and are limited to extract software aspects and user preferences. we present a novel review summarization framework, sur-miner. instead of a bags-of-words assumption, it classifies reviews into five categories and extracts aspects for sentences which include aspect evaluation using a pattern-based parser. then, sur-miner visualizes the summaries using two interactive diagrams. our evaluation on seventeen popular apps shows that sur-miner summarizes more accurate and clearer aspects than state-of-the-art techniques, with an f1-score of 0.81, significantly greater than that of reviewspotlight (0.56) and guzmans\\' method (0.55). feedback from developers shows that 88% developers agreed with the usefulness of the summaries from sur-miner.",
            "contribution_ids": [
                "R111981"
            ]
        },
        {
            "instance_id": "R112387xR76792",
            "comparison_id": "R112387",
            "paper_id": "R76792",
            "text": "Mining Twitter Feeds for Software User Requirements \"twitter enables large populations of end-users of software to publicly share their experiences and concerns about software systems in the form of micro-blogs. such data can be collected and classified to help software developers infer users' needs, detect bugs in their code, and plan for future releases of their systems. however, automatically capturing, classifying, and presenting useful tweets is not a trivial task. challenges stem from the scale of the data available, its unique format, diverse nature, and high percentage of irrelevant information and spam. motivated by these challenges, this paper reports on a three-fold study that is aimed at leveraging twitter as a main source of software user requirements. the main objective is to enable a responsive, interactive, and adaptive data-driven requirements engineering process. our analysis is conducted using 4,000 tweets collected from the twitter feeds of 10 software systems sampled from a broad range of application domains. the results reveal that around 50% of collected tweets contain useful technical information. the results also show that text classifiers such as support vector machines and naive bayes can be very effective in capturing and categorizing technically informative tweets. additionally, the paper describes and evaluates multiple summarization strategies for generating meaningful summaries of informative software-relevant tweets.\"",
            "contribution_ids": [
                "R195470",
                "R76794",
                "R76800",
                "R108764"
            ]
        },
        {
            "instance_id": "R112387xR78392",
            "comparison_id": "R112387",
            "paper_id": "R78392",
            "text": "Bug report, feature request, or simply praise? On automatically classifying app reviews app stores like google play and apple appstore have over 3 million apps covering nearly every kind of software and service. billions of users regularly download, use, and review these apps. recent studies have shown that reviews written by the users represent a rich source of information for the app vendors and the developers, as they include information about bugs, ideas for new features, or documentation of released features. this paper introduces several probabilistic techniques to classify app reviews into four types: bug reports, feature requests, user experiences, and ratings. for this we use review metadata such as the star rating and the tense, as well as, text classification, natural language processing, and sentiment analysis techniques. we conducted a series of experiments to compare the accuracy of the techniques and compared them with simple string matching. we found that metadata alone results in a poor classification accuracy. when combined with natural language processing, the classification precision got between 70-95% while the recall between 80-90%. multiple binary classifiers outperformed single multiclass classifiers. our results impact the design of review analytics tools which help app vendors, developers, and users to deal with the large amount of reviews, filter critical reviews, and assign them to the appropriate stakeholders.",
            "contribution_ids": [
                "R199165",
                "R78394"
            ]
        },
        {
            "instance_id": "R112387xR111988",
            "comparison_id": "R112387",
            "paper_id": "R111988",
            "text": "A Needle in a Haystack: What Do Twitter Users Say about Software? users of the twitter microblogging platform share a vast amount of information about various topics through short messages on a daily basis. some of these so called tweets include information that is relevant for software companies and could, for example, help requirements engineers to identify user needs. therefore, tweets have the potential to aid in the continuous evolution of software applications. despite the existence of such relevant tweets, little is known about their number and content. in this paper we report on the results of an exploratory study in which we analyzed the usage characteristics, content and automatic classification potential of tweets about software applications by using descriptive statistics, content analysis and machine learning techniques. although the manual search of relevant information within the vast stream of tweets can be compared to looking for a needle in a haystack, our analysis shows that tweets provide a valuable input for software companies. furthermore, our results demonstrate that machine learning techniques have the capacity to identify and harvest relevant information automatically.",
            "contribution_ids": [
                "R198817",
                "R111990"
            ]
        },
        {
            "instance_id": "R112387xR111923",
            "comparison_id": "R112387",
            "paper_id": "R111923",
            "text": "Same App, Different App Stores: A Comparative Study to attract more users, implementing the same mobile app for different platforms has become a common industry practice. app stores provide a unique channel for users to share feedback on the acquired apps through ratings and textual reviews. however, each mobile platform has its own online store for distributing apps to users. to understand the characteristics of and discrepancies in how users perceive the same app implemented for and distributed through different platforms, we present a large-scale comparative study of cross-platform apps. we mine the characteristics of 80,000 app-pairs (160k apps in total) from a corpus of 2.4 million apps collected from the apple and google play app stores. we quantitatively compare their app-store attributes, such as stars, versions, and prices. we measure the aggregated user-perceived ratings and find many discrepancies across the platforms. further, we employ machine learning to classify 1.7 million textual user reviews obtained from 2,000 of the mined app-pairs. we analyze discrepancies and root causes of user complaints to understand cross-platform development challenges that impact cross-platform user-perceived ratings. we also follow up with the developers to understand the reasons behind identified discrepancies.",
            "contribution_ids": [
                "R111925"
            ]
        },
        {
            "instance_id": "R114155xR113067",
            "comparison_id": "R114155",
            "paper_id": "R113067",
            "text": "Mining User Rationale from Software Reviews rationale refers to the reasoning and justification behind human decisions, opinions, and beliefs. in software engineering, rationale management focuses on capturing design and requirements decisions and on organizing and reusing project knowledge. this paper takes a different view on rationale written by users in online reviews. we studied 32,414 reviews for 52 software applications in the amazon store. through a grounded theory approach and peer content analysis, we investigated how users argue and justify their decisions, e.g. about upgrading, installing, or switching software applications. we also studied the occurrence frequency of rationale concepts such as issues encountered or alternatives considered in the reviews and found that assessment criteria like performance, compatibility, and usability represent the most pervasive concept. we then used the truth set of manually labeled review sentences to explore how accurately we can mine rationale concepts from the reviews. support vector classifier, naive bayes, and logistic regression, trained on the review metadata, syntax tree of the review text, and influential terms, achieved a precision around 80% for predicting sentences with alternatives and decisions, with top recall values of 98%. on the review level, precision was up to 13% higher with recall values reaching 99%. we discuss the findings and the rationale importance for supporting deliberation in user communities and synthesizing the reviews for developers.",
            "contribution_ids": [
                "R195534",
                "R113069"
            ]
        },
        {
            "instance_id": "R114155xR112472",
            "comparison_id": "R114155",
            "paper_id": "R112472",
            "text": "CRAFT: A Crowd-Annotated Feedback Technique the ever increasing accessibility of the web for the crowd offered by various electronic devices such as smartphones has facilitated the communication of the needs, ideas, and wishes of millions of stakeholders. to cater for the scale of this input and reduce the overhead of manual elicitation methods, data mining and text mining techniques have been utilised to automatically capture and categorise this stream of feedback, which is also used, amongst other things, by stakeholders to communicate their requirements to software developers. such techniques, however, fall short of identifying some of the peculiarities and idiosyncrasies of the natural language that people use colloquially. this paper proposes craft, a technique that utilises the power of the crowd to support richer, more powerful text mining by enabling the crowd to categorise and annotate feedback through a context menu. this, in turn, helps requirements engineers to better identify user requirements within such feedback. this paper presents the theoretical foundations as well as the initial evaluation of this crowd-based feedback annotation technique for requirements identification.",
            "contribution_ids": [
                "R112474"
            ]
        },
        {
            "instance_id": "R114155xR113054",
            "comparison_id": "R114155",
            "paper_id": "R113054",
            "text": "A gradual approach to crowd-based requirements engineering: The case of conference online social networks this paper proposes a gradual approach to crowd-based requirements engineering (re) for supporting the establishment of a more engaged crowd, hence, mitigating the low involvement risk in crowd-based re. our approach advocates involving micro-crowds (mcs), where in each micro-crowd, the population is relatively cohesive and familiar with each other. using this approach, the evolving product is developed iteratively. at each iteration, a new mc can join the already established crowd to enhance the requirements for the next version, while adding terminology to an evolving folksonomy. we are currently using this approach in an on-going research project to develop an online social network (osn) for academic researchers that will facilitate discussions and knowledge sharing around conferences.",
            "contribution_ids": [
                "R113056"
            ]
        },
        {
            "instance_id": "R114155xR112425",
            "comparison_id": "R114155",
            "paper_id": "R112425",
            "text": "Refinement and Resolution of Just-in-Time Requirements in Open Source Software: A Case Study just-in-time (jit) requirements are characterized as not following the traditional requirement engineering approach, instead focusing on elaboration when the implementation begins. in this experience report, we analyze both functional and nonfunctional jit requirements from three successful open source software (oss) projects, including firefox, lucene, and mylyn, to explore the common activities that shaped those requirements. we identify a novel refinement and resolution process that all studied requirements followed from requirement inception to their complete realization and subsequent release. this research provides new insights into how oss project teams create quality features from simple initial descriptions of jit requirements. our study also initiates three captivating questions regarding jit requirements and opens new avenues for further research in this emerging field.",
            "contribution_ids": [
                "R112427"
            ]
        },
        {
            "instance_id": "R114155xR113160",
            "comparison_id": "R114155",
            "paper_id": "R113160",
            "text": "Customer Rating Reactions Can Be Predicted Purely using App Features in this paper we provide empirical evidence that the rating that an app attracts can be accurately predicted from the features it offers. our results, based on an analysis of 11,537 apps from the samsung android and blackberry world app stores, indicate that the rating of 89% of these apps can be predicted with 100% accuracy. our prediction model is built by using feature and rating information from the existing apps offered in the app store and it yields highly accurate rating predictions, using only a few (11-12) existing apps for case-based prediction. these findings may have important implications for requirements engineering in app stores: they indicate that app developers may be able to obtain (very accurate) assessments of the customer reaction to their proposed feature sets (requirements), thereby providing new opportunities to support the requirements elicitation process for app developers.",
            "contribution_ids": [
                "R194980",
                "R113162"
            ]
        },
        {
            "instance_id": "R114155xR112416",
            "comparison_id": "R114155",
            "paper_id": "R112416",
            "text": "Using the crowds to satisfy unbounded requirements the internet is a social space that is shaped by humans through the development of websites, the release of web services, the collaborative creation of encyclopedias and forums, the exchange of information through social networks, the provision of work through crowdsourcing platforms, etc. this landscape offers novel possibilities for software systems to satisfy their requirements, e.g., by retrieving and aggregating the information from internet websites as well as by crowdsourcing the execution of certain functions. in this paper, we present a special type of functional requirements (called unbounded) that is not fully satisfiable and whose satisfaction is increased by gathering evidence from multiple sources. in addition to charac- terizing unbounded requirements, we explain how to maximize their satisfaction by asking and by combining opinions of mul- tiple sources: people, services, information, and algorithms. we provide evidence of the existence of these requirements through examples by studying a modern web application (spotify) and from a traditional system (microsoft word).",
            "contribution_ids": [
                "R112418"
            ]
        },
        {
            "instance_id": "R114155xR76126",
            "comparison_id": "R114155",
            "paper_id": "R76126",
            "text": "Crowd-centric Requirements Engineering requirements engineering is a preliminary and crucial phase for the correctness and quality of software systems. despite the agreement on the positive correlation between user involvement in requirements engineering and software success, current development methods employ a too narrow concept of that user and rely on a recruited set of users considered to be representative. such approaches might not cater for the diversity and dynamism of the actual users and the context of software usage. this is especially true in new paradigms such as cloud and mobile computing. to overcome these limitations, we propose crowd-centric requirements engineering (ccre) as a revised method for requirements engineering where users become primary contributors, resulting in higher-quality requirements and increased user satisfaction. ccre relies on crowd sourcing to support a broader user involvement, and on gamification to motivate that voluntary involvement.",
            "contribution_ids": [
                "R76128"
            ]
        },
        {
            "instance_id": "R114155xR113137",
            "comparison_id": "R114155",
            "paper_id": "R113137",
            "text": "Mining Context-Aware User Requirements from Crowd Contributed Mobile Data internetware is required to respond quickly to emergent user requirements or requirements changes by providing application upgrade or making context-aware recommendations. as user requirements in internet computing environment are often changing fast and new requirements emerge more and more in a creative way, traditional requirements engineering approaches based on requirements elicitation and analysis cannot ensure the quick response of internetware. in this paper, we propose an approach for mining context-aware user requirements from crowd contributed mobile data. the approach captures behavior records contributed by a crowd of mobile users and automatically mines context-aware user behavior patterns (i.e., when, where and under what conditions users require a specific service) from them using apriori-m algorithm. based on the mined user behaviors, emergent requirements or requirements changes can be inferred from the mined user behavior patterns and solutions that satisfy the requirements can be recommended to users. to evaluate the proposed approach, we conduct an experimental study and show the effectiveness of the requirements mining approach.",
            "contribution_ids": [
                "R113139"
            ]
        },
        {
            "instance_id": "R114155xR76792",
            "comparison_id": "R114155",
            "paper_id": "R76792",
            "text": "Mining Twitter Feeds for Software User Requirements \"twitter enables large populations of end-users of software to publicly share their experiences and concerns about software systems in the form of micro-blogs. such data can be collected and classified to help software developers infer users' needs, detect bugs in their code, and plan for future releases of their systems. however, automatically capturing, classifying, and presenting useful tweets is not a trivial task. challenges stem from the scale of the data available, its unique format, diverse nature, and high percentage of irrelevant information and spam. motivated by these challenges, this paper reports on a three-fold study that is aimed at leveraging twitter as a main source of software user requirements. the main objective is to enable a responsive, interactive, and adaptive data-driven requirements engineering process. our analysis is conducted using 4,000 tweets collected from the twitter feeds of 10 software systems sampled from a broad range of application domains. the results reveal that around 50% of collected tweets contain useful technical information. the results also show that text classifiers such as support vector machines and naive bayes can be very effective in capturing and categorizing technically informative tweets. additionally, the paper describes and evaluates multiple summarization strategies for generating meaningful summaries of informative software-relevant tweets.\"",
            "contribution_ids": [
                "R195470",
                "R76794",
                "R76800",
                "R108764"
            ]
        },
        {
            "instance_id": "R114155xR113122",
            "comparison_id": "R114155",
            "paper_id": "R113122",
            "text": "UCFrame: A Use Case Framework for Crowd-Centric Requirement Acquisition to build needed mobile applications in specific domains, requirements should be collected and analyzed in holistic approach. however, resource is limited for small vendor groups to perform holistic requirement acquisition and elicitation. the rise of crowdsourcing and crowdfunding gives small vendor groups new opportunities to build needed mobile applications for the crowd. by finding prior stakeholders and gathering requirements effectively from the crowd, mobile application projects can establish sound foundation in early phase of software process. therefore, integration of crowd-based requirement engineering into software process is important for small vendor groups. conventional requirement acquisition and elicitation methods are analyst-centric. very little discussion is in adapting requirement acquisition tools for crowdcentric context. in this study, several tool features of use case documentation are revised in crowd-centric context. these features constitute a use case-based framework, called ucframe, for crowd-centric requirement acquisition. an instantiation of ucframe is also presented to demonstrate the effectiveness of ucframe in collecting crowd requirements for building two mobile applications.",
            "contribution_ids": [
                "R113124"
            ]
        },
        {
            "instance_id": "R114155xR76118",
            "comparison_id": "R114155",
            "paper_id": "R76118",
            "text": "CrowdREquire: A Requirements Engineering Crowdsourcing Platform this paper describes crowdrequire, a platform that supports requirements engineering using the crowdsourcing concept. the power of the crowd is in the diversity of talents and expertise available within the crowd and crowdrequire specifies how requirements engineering can harness skills available in the crowd. in developing crowdrequire, this paper designs a crowdsourcing business model and market strategy for crowdsourcing requirements engineering irrespective of the professions and areas of expertise of the crowd involved. this is also a specific application of crowdsourcing which establishes the general applicability and efficacy of crowdsourcing. the results obtained could be used as a reference for other crowdsourcing systems as well.",
            "contribution_ids": [
                "R76120"
            ]
        },
        {
            "instance_id": "R114155xR108199",
            "comparison_id": "R114155",
            "paper_id": "R108199",
            "text": "A Little Bird Told Me: Mining Tweets for Requirements and Software Evolution \"twitter is one of the most popular social networks. previous research found that users employ twitter to communicate about software applications via short messages, commonly referred to as tweets, and that these tweets can be useful for requirements engineering and software evolution. however, due to their large number---in the range of thousands per day for popular applications---a manual analysis is unfeasible.in this work we present alertme, an approach to automatically classify, group and rank tweets about software applications. we apply machine learning techniques for automatically classifying tweets requesting improvements, topic modeling for grouping semantically related tweets and a weighted function for ranking tweets according to specific attributes, such as content category, sentiment and number of retweets. we ran our approach on 68,108 collected tweets from three software applications and compared its results against software practitioners' judgement. our results show that alertme is an effective approach for filtering, summarizing and ranking tweets about software applications. alertme enables the exploitation of twitter as a feedback channel for information relevant to software evolution, including end-user requirements.\"",
            "contribution_ids": [
                "R195486",
                "R108201"
            ]
        },
        {
            "instance_id": "R114155xR76353",
            "comparison_id": "R114155",
            "paper_id": "R76353",
            "text": "Providing a User Forum is not enough: First Experiences of a Software Company with CrowdRE \"crowd-based requirements engineering (crowdre) is promising to derive requirements by gathering and analyzing information from the crowd. setting up crowdre in practice seems challenging, although first solutions to support crowdre exist. in this paper, we report on a german software company's experience on crowd involvement by using feedback communication channels and a monitoring solution for user-event data. in our case study, we identified several problem areas that a software company is confronted with to setup an environment for gathering requirements from the crowd. we conclude that a crowdre process cannot be implemented ad-hoc and that future work is needed to create and analyze a continuous feedback and monitoring data stream.\"",
            "contribution_ids": [
                "R76355"
            ]
        },
        {
            "instance_id": "R114155xR113151",
            "comparison_id": "R114155",
            "paper_id": "R113151",
            "text": "Linguistic Analysis of Crowd Requirements: An Experimental Study \"users of today's online software services are often diversified and distributed, whose needs are hard to elicit using conventional re approaches. as a consequence, crowd-based, data intensive requirements engineering approaches are considered important. in this paper, we have conducted an experimental study on a dataset of 2,966 requirements statements to evaluate the performance of three text clustering algorithms. the purpose of the study is to aggregate similar requirement statements suggested by the crowd users, and also to identify domain objects and operations, as well as required features from the given requirements statements dataset. the experimental results are then cross-checked with original tags provided by data providers for validation.\"",
            "contribution_ids": [
                "R113153"
            ]
        },
        {
            "instance_id": "R114155xR113196",
            "comparison_id": "R114155",
            "paper_id": "R113196",
            "text": "A Needle in a Haystack: What Do Twitter Users Say about Software? users of the twitter microblogging platform share a vast amount of information about various topics through short messages on a daily basis. some of these so called tweets include information that is relevant for software companies and could, for example, help requirements engineers to identify user needs. therefore, tweets have the potential to aid in the continuous evolution of software applications. despite the existence of such relevant tweets, little is known about their number and content. in this paper we report on the results of an exploratory study in which we analyzed the usage characteristics, content and automatic classification potential of tweets about software applications by using descriptive statistics, content analysis and machine learning techniques. although the manual search of relevant information within the vast stream of tweets can be compared to looking for a needle in a haystack, our analysis shows that tweets provide a valuable input for software companies. furthermore, our results demonstrate that machine learning techniques have the capacity to identify and harvest relevant information automatically.",
            "contribution_ids": [
                "R113198"
            ]
        },
        {
            "instance_id": "R114155xR76818",
            "comparison_id": "R114155",
            "paper_id": "R76818",
            "text": "App Review Analysis Via Active Learning: Reducing Supervision Effort without Compromising Classification Accuracy automated app review analysis is an important avenue for extracting a variety of requirements-related information. typically, a first step toward performing such analysis is preparing a training dataset, where developers (experts) identify a set of reviews and, manually, annotate them according to a given task. having sufficiently large training data is important for both achieving a high prediction accuracy and avoiding overfitting. given millions of reviews, preparing a training set is laborious. we propose to incorporate active learning, a machine learning paradigm, in order to reduce the human effort involved in app review analysis. our app review classification framework exploits three active learning strategies based on uncertainty sampling. we apply these strategies to an existing dataset of 4,400 app reviews for classifying app reviews as features, bugs, rating, and user experience. we find that active learning, compared to a training dataset chosen randomly, yields a significantly higher prediction accuracy under multiple scenarios.",
            "contribution_ids": [
                "R195137",
                "R76820",
                "R76825"
            ]
        },
        {
            "instance_id": "R114155xR113085",
            "comparison_id": "R114155",
            "paper_id": "R113085",
            "text": "Discovering Requirements through Goal-Driven Process Mining \"software systems are designed to support their users in performing tasks that are parts of more general processes. unfortunately, software designers often make invalid assumptions about the users' processes and therefore about the requirements to support such processes. eliciting and validating such assumptions through manual means (e.g., through observations, interviews, and workshops) is expensive, time-consuming, and may fail to identify the users' real processes. using process mining may reduce these problems by automating the monitoring and discovery of the actual processes followed by a crowd of users. the crowd provides an opportunity to involve diverse groups of users to interact with a system and conduct their intended processes. this implicit feedback in the form of discovered processes can then be used to modify the existing system's functionalities and ensure whether or not a software product is used as initially designed. in addition, the analysis of user-system interactions may reveal lacking functionalities and quality issues. these ideas are illustrated on the greensoft personal energy management system.\"",
            "contribution_ids": [
                "R113087"
            ]
        },
        {
            "instance_id": "R12250xR12235",
            "comparison_id": "R12250",
            "paper_id": "R12235",
            "text": "Estimating the effective reproduction number of the 2019-nCoV in China abstract we estimate the effective reproduction number for 2019-ncov based on the daily reported cases from china cdc. the results indicate that 2019-ncov has a higher effective reproduction number than sars with a comparable fatality rate. article summary line this modeling study indicates that 2019-ncov has a higher effective reproduction number than sars with a comparable fatality rate.",
            "contribution_ids": [
                "R12236"
            ]
        },
        {
            "instance_id": "R12250xR12226",
            "comparison_id": "R12250",
            "paper_id": "R12226",
            "text": "Time-varying transmission dynamics of Novel Coronavirus Pneumonia in China abstract rationale several studies have estimated basic production number of novel coronavirus pneumonia (ncp). however, the time-varying transmission dynamics of ncp during the outbreak remain unclear. objectives we aimed to estimate the basic and time-varying transmission dynamics of ncp across china, and compared them with sars. methods data on ncp cases by february 7, 2020 were collected from epidemiological investigations or official websites. data on severe acute respiratory syndrome (sars) cases in guangdong province, beijing and hong kong during 2002-2003 were also obtained. we estimated the doubling time, basic reproduction number ( r 0 ) and time-varying reproduction number ( r t ) of ncp and sars. measurements and main results as of february 7, 2020, 34,598 ncp cases were identified in china, and daily confirmed cases decreased after february 4. the doubling time of ncp nationwide was 2.4 days which was shorter than that of sars in guangdong (14.3 days), hong kong (5.7 days) and beijing (12.4 days). the r 0 of ncp cases nationwide and in wuhan were 4.5 and 4.4 respectively, which were higher than r 0 of sars in guangdong ( r 0 =2.3), hongkong ( r 0 =2.3), and beijing ( r 0 =2.6). the r t for ncp continuously decreased especially after january 16 nationwide and in wuhan. the r 0 for secondary ncp cases in guangdong was 0.6, and the r t values were less than 1 during the epidemic. conclusions ncp may have a higher transmissibility than sars, and the efforts of containing the outbreak are effective. however, the efforts are needed to persist in for reducing time-varying reproduction number below one. at a glance commentary scientific knowledge on the subject since december 29, 2019, pneumonia infection with 2019-ncov, now named as novel coronavirus pneumonia (ncp), occurred in wuhan, hubei province, china. the disease has rapidly spread from wuhan to other areas. as a novel virus, the time-varying transmission dynamics of ncp remain unclear, and it is also important to compare it with sars. what this study adds to the field we compared the transmission dynamics of ncp with sars, and found that ncp has a higher transmissibility than sars. time-varying production number indicates that rigorous control measures taken by governments are effective across china, and persistent efforts are needed to be taken for reducing instantaneous reproduction number below one.",
            "contribution_ids": [
                "R12227",
                "R12229"
            ]
        },
        {
            "instance_id": "R12250xR12237",
            "comparison_id": "R12250",
            "paper_id": "R12237",
            "text": "Preliminary estimation of the basic reproduction number of novel coronavirus (2019-nCoV) in China, from 2019 to 2020: A data-driven analysis in the early phase of the outbreak abstract backgrounds an ongoing outbreak of a novel coronavirus (2019-ncov) pneumonia hit a major city of china, wuhan, december 2019 and subsequently reached other provinces/regions of china and countries. we present estimates of the basic reproduction number, r 0 , of 2019-ncov in the early phase of the outbreak. methods accounting for the impact of the variations in disease reporting rate, we modelled the epidemic curve of 2019-ncov cases time series, in mainland china from january 10 to january 24, 2020, through the exponential growth. with the estimated intrinsic growth rate ( \u03b3 ), we estimated r 0 by using the serial intervals (si) of two other well-known coronavirus diseases, mers and sars, as approximations for the true unknown si. findings the early outbreak data largely follows the exponential growth. we estimated that the mean r 0 ranges from 2.24 (95%ci: 1.96-2.55) to 3.58 (95%ci: 2.89-4.39) associated with 8-fold to 2-fold increase in the reporting rate. we demonstrated that changes in reporting rate substantially affect estimates of r 0 . conclusion the mean estimate of r 0 for the 2019-ncov ranges from 2.24 to 3.58, and significantly larger than 1. our findings indicate the potential of 2019-ncov to cause outbreaks.",
            "contribution_ids": [
                "R12238",
                "R12240"
            ]
        },
        {
            "instance_id": "R12250xR12233",
            "comparison_id": "R12250",
            "paper_id": "R12233",
            "text": "Early transmissibility assessment of a novel coronavirus in Wuhan between december 1, 2019 and january 26, 2020, nearly 3000 cases of respiratory illness caused by a novel coronavirus originating in wuhan, china have been reported. in this short analysis, we combine publicly available cumulative case data from the ongoing outbreak with phenomenological modeling methods to conduct an early transmissibility assessment. our model suggests that the basic reproduction number associated with the outbreak (at time of writing) may range from 2.0 to 3.1. though these estimates are preliminary and subject to change, they are consistent with previous findings regarding the transmissibility of the related sars-coronavirus and indicate the possibility of epidemic potential.",
            "contribution_ids": [
                "R12234"
            ]
        },
        {
            "instance_id": "R12250xR12245",
            "comparison_id": "R12250",
            "paper_id": "R12245",
            "text": "Estimation of the Transmission Risk of 2019-nCov and Its Implication for Public Health Interventions english abstract: background: since the emergence of the first pneumonia cases in wuhan, china, the novel coronavirus (2019-ncov) infection has been quickly spreading out to other provinces and neighbouring countries. estimation of the basic reproduction number by means of mathematical modelling can be helpful for determining the potential and severity of an outbreak, and providing critical information for identifying the type of disease interventions and intensity.\\r\\n\\r\\nmethods: a deterministic compartmental model was devised based on the clinical progression of the disease, epidemiological status of the individuals, and the intervention measures.\\r\\n\\r\\nfindings: the estimation results based on likelihood and model analysis reveal that the control reproduction number may be as high as 6.47 (95% ci 5.71-7.23). sensitivity analyses reveal that interventions, such as intensive contact tracing followed by quarantine and isolation, can effectively reduce the control reproduction number and transmission risk, with the effect of travel restriction of wuhan on 2019-ncov infection in beijing being almost equivalent to increasing quarantine by 100-thousand baseline value.\\r\\n\\r\\ninterpretation: it is essential to assess how the expensive, resource-intensive measures implemented by the chinese authorities can contribute to the prevention and control of the 2019-ncov infection, and how long should be maintained. under the most restrictive measures, the outbreak is expected to peak within two weeks (since january 23rd 2020) with significant low peak value. with travel restriction (no imported exposed individuals to beijing), the number of infected individuals in 7 days will decrease by 91.14% in beijing, compared with the scenario of no travel restriction.\\r\\n\\r\\nmandarin abstract: \u80cc\u666f\uff1a\u81ea\u4ece\u4e2d\u56fd\u6b66\u6c49\u51fa\u73b0\u7b2c\u4e00\u4f8b\u80ba\u708e\u75c5\u4f8b\u4ee5\u6765\uff0c\u65b0\u578b\u51a0\u72b6\u75c5\u6bd2\uff082019-ncov\uff09\u611f\u67d3\u5df2\u8fc5\u901f\u4f20\u64ad\u5230\u5176\u4ed6\u7701\u4efd\u548c\u5468\u8fb9\u56fd\u5bb6\u3002\u901a\u8fc7\u6570\u5b66\u6a21\u578b\u4f30\u8ba1\u57fa\u672c\u518d\u751f\u6570\uff0c\u6709\u52a9\u4e8e\u786e\u5b9a\u75ab\u60c5\u7206\u53d1\u7684\u53ef\u80fd\u6027\u548c\u4e25\u91cd\u6027\uff0c\u5e76\u4e3a\u786e\u5b9a\u75be\u75c5\u5e72\u9884\u7c7b\u578b\u548c\u5f3a\u5ea6\u63d0\u4f9b\u5173\u952e\u4fe1\u606f\u3002\\r\\n\\r\\n\u65b9\u6cd5\uff1a\u6839\u636e\u75be\u75c5\u7684\u4e34\u5e8a\u8fdb\u5c55\uff0c\u4e2a\u4f53\u7684\u6d41\u884c\u75c5\u5b66\u72b6\u51b5\u548c\u5e72\u9884\u63aa\u65bd\uff0c\u8bbe\u8ba1\u786e\u5b9a\u6027\u7684\u4ed3\u5ba4\u6a21\u578b\u3002\\r\\n\\r\\n\u7ed3\u679c\uff1a\u57fa\u4e8e\u4f3c\u7136\u51fd\u6570\u548c\u6a21\u578b\u5206\u6790\u7684\u4f30\u8ba1\u7ed3\u679c\u8868\u660e\uff0c\u63a7\u5236\u518d\u751f\u6570\u53ef\u80fd\u9ad8\u8fbe6.47\uff0895\uff05ci 5.71-7.23\uff09\u3002\u654f\u611f\u6027\u5206\u6790\u663e\u793a\uff0c\u5bc6\u96c6\u63a5\u89e6\u8ffd\u8e2a\u548c\u9694\u79bb\u7b49\u5e72\u9884\u63aa\u65bd\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u63a7\u5236\u518d\u751f\u6570\u548c\u4f20\u64ad\u98ce\u9669\uff0c\u6b66\u6c49\u5c01\u57ce\u63aa\u65bd\u5bf9\u5317\u4eac2019-ncov\u611f\u67d3\u7684\u5f71\u54cd\u51e0\u4e4e\u7b49\u540c\u4e8e\u589e\u52a0\u9694\u79bb\u63aa\u65bd10\u4e07\u7684\u57fa\u7ebf\u503c\u3002\\r\\n\\r\\n\u89e3\u91ca\uff1a\u5fc5\u987b\u8bc4\u4f30\u4e2d\u56fd\u5f53\u5c40\u5b9e\u65bd\u7684\u6602\u8d35\uff0c\u8d44\u6e90\u5bc6\u96c6\u578b\u63aa\u65bd\u5982\u4f55\u6709\u52a9\u4e8e\u9884\u9632\u548c\u63a7\u52362019-ncov\u611f\u67d3\uff0c\u4ee5\u53ca\u5e94\u7ef4\u6301\u591a\u957f\u65f6\u95f4\u3002\u5728\u6700\u4e25\u683c\u7684\u63aa\u65bd\u4e0b\uff0c\u9884\u8ba1\u75ab\u60c5\u5c06\u5728\u4e24\u5468\u5185\uff08\u81ea2020\u5e741\u670823\u65e5\u8d77\uff09\u8fbe\u5230\u5cf0\u503c\uff0c\u5cf0\u503c\u8f83\u4f4e\u3002\u4e0e\u6ca1\u6709\u51fa\u884c\u9650\u5236\u7684\u60c5\u51b5\u76f8\u6bd4\uff0c\u6709\u4e86\u51fa\u884c\u9650\u5236\uff08\u5373\u6ca1\u6709\u8f93\u5165\u7684\u6f5c\u4f0f\u7c7b\u4e2a\u4f53\u8fdb\u5165\u5317\u4eac\uff09\uff0c\u5317\u4eac\u76847\u5929\u611f\u67d3\u8005\u6570\u91cf\u5c06\u51cf\u5c1191.14\uff05\u3002",
            "contribution_ids": [
                "R12246"
            ]
        },
        {
            "instance_id": "R12250xR12223",
            "comparison_id": "R12250",
            "paper_id": "R12223",
            "text": "Modelling the epidemic trend of the 2019 novel coronavirus outbreak in China we present a timely evaluation of the chinese 2019-ncov epidemic in its initial phase, where 2019-ncov demonstrates comparable transmissibility but lower fatality rates than sars and mers. a quick diagnosis that leads to case isolation and integrated interventions will have a major impact on its future trend. nevertheless, as china is facing its spring festival travel rush and the epidemic has spread beyond its borders, further investigation on its potential spatiotemporal transmission pattern and novel intervention strategies are warranted.",
            "contribution_ids": [
                "R12224"
            ]
        },
        {
            "instance_id": "R12251xR12245",
            "comparison_id": "R12251",
            "paper_id": "R12245",
            "text": "Estimation of the Transmission Risk of 2019-nCov and Its Implication for Public Health Interventions english abstract: background: since the emergence of the first pneumonia cases in wuhan, china, the novel coronavirus (2019-ncov) infection has been quickly spreading out to other provinces and neighbouring countries. estimation of the basic reproduction number by means of mathematical modelling can be helpful for determining the potential and severity of an outbreak, and providing critical information for identifying the type of disease interventions and intensity.\\r\\n\\r\\nmethods: a deterministic compartmental model was devised based on the clinical progression of the disease, epidemiological status of the individuals, and the intervention measures.\\r\\n\\r\\nfindings: the estimation results based on likelihood and model analysis reveal that the control reproduction number may be as high as 6.47 (95% ci 5.71-7.23). sensitivity analyses reveal that interventions, such as intensive contact tracing followed by quarantine and isolation, can effectively reduce the control reproduction number and transmission risk, with the effect of travel restriction of wuhan on 2019-ncov infection in beijing being almost equivalent to increasing quarantine by 100-thousand baseline value.\\r\\n\\r\\ninterpretation: it is essential to assess how the expensive, resource-intensive measures implemented by the chinese authorities can contribute to the prevention and control of the 2019-ncov infection, and how long should be maintained. under the most restrictive measures, the outbreak is expected to peak within two weeks (since january 23rd 2020) with significant low peak value. with travel restriction (no imported exposed individuals to beijing), the number of infected individuals in 7 days will decrease by 91.14% in beijing, compared with the scenario of no travel restriction.\\r\\n\\r\\nmandarin abstract: \u80cc\u666f\uff1a\u81ea\u4ece\u4e2d\u56fd\u6b66\u6c49\u51fa\u73b0\u7b2c\u4e00\u4f8b\u80ba\u708e\u75c5\u4f8b\u4ee5\u6765\uff0c\u65b0\u578b\u51a0\u72b6\u75c5\u6bd2\uff082019-ncov\uff09\u611f\u67d3\u5df2\u8fc5\u901f\u4f20\u64ad\u5230\u5176\u4ed6\u7701\u4efd\u548c\u5468\u8fb9\u56fd\u5bb6\u3002\u901a\u8fc7\u6570\u5b66\u6a21\u578b\u4f30\u8ba1\u57fa\u672c\u518d\u751f\u6570\uff0c\u6709\u52a9\u4e8e\u786e\u5b9a\u75ab\u60c5\u7206\u53d1\u7684\u53ef\u80fd\u6027\u548c\u4e25\u91cd\u6027\uff0c\u5e76\u4e3a\u786e\u5b9a\u75be\u75c5\u5e72\u9884\u7c7b\u578b\u548c\u5f3a\u5ea6\u63d0\u4f9b\u5173\u952e\u4fe1\u606f\u3002\\r\\n\\r\\n\u65b9\u6cd5\uff1a\u6839\u636e\u75be\u75c5\u7684\u4e34\u5e8a\u8fdb\u5c55\uff0c\u4e2a\u4f53\u7684\u6d41\u884c\u75c5\u5b66\u72b6\u51b5\u548c\u5e72\u9884\u63aa\u65bd\uff0c\u8bbe\u8ba1\u786e\u5b9a\u6027\u7684\u4ed3\u5ba4\u6a21\u578b\u3002\\r\\n\\r\\n\u7ed3\u679c\uff1a\u57fa\u4e8e\u4f3c\u7136\u51fd\u6570\u548c\u6a21\u578b\u5206\u6790\u7684\u4f30\u8ba1\u7ed3\u679c\u8868\u660e\uff0c\u63a7\u5236\u518d\u751f\u6570\u53ef\u80fd\u9ad8\u8fbe6.47\uff0895\uff05ci 5.71-7.23\uff09\u3002\u654f\u611f\u6027\u5206\u6790\u663e\u793a\uff0c\u5bc6\u96c6\u63a5\u89e6\u8ffd\u8e2a\u548c\u9694\u79bb\u7b49\u5e72\u9884\u63aa\u65bd\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u63a7\u5236\u518d\u751f\u6570\u548c\u4f20\u64ad\u98ce\u9669\uff0c\u6b66\u6c49\u5c01\u57ce\u63aa\u65bd\u5bf9\u5317\u4eac2019-ncov\u611f\u67d3\u7684\u5f71\u54cd\u51e0\u4e4e\u7b49\u540c\u4e8e\u589e\u52a0\u9694\u79bb\u63aa\u65bd10\u4e07\u7684\u57fa\u7ebf\u503c\u3002\\r\\n\\r\\n\u89e3\u91ca\uff1a\u5fc5\u987b\u8bc4\u4f30\u4e2d\u56fd\u5f53\u5c40\u5b9e\u65bd\u7684\u6602\u8d35\uff0c\u8d44\u6e90\u5bc6\u96c6\u578b\u63aa\u65bd\u5982\u4f55\u6709\u52a9\u4e8e\u9884\u9632\u548c\u63a7\u52362019-ncov\u611f\u67d3\uff0c\u4ee5\u53ca\u5e94\u7ef4\u6301\u591a\u957f\u65f6\u95f4\u3002\u5728\u6700\u4e25\u683c\u7684\u63aa\u65bd\u4e0b\uff0c\u9884\u8ba1\u75ab\u60c5\u5c06\u5728\u4e24\u5468\u5185\uff08\u81ea2020\u5e741\u670823\u65e5\u8d77\uff09\u8fbe\u5230\u5cf0\u503c\uff0c\u5cf0\u503c\u8f83\u4f4e\u3002\u4e0e\u6ca1\u6709\u51fa\u884c\u9650\u5236\u7684\u60c5\u51b5\u76f8\u6bd4\uff0c\u6709\u4e86\u51fa\u884c\u9650\u5236\uff08\u5373\u6ca1\u6709\u8f93\u5165\u7684\u6f5c\u4f0f\u7c7b\u4e2a\u4f53\u8fdb\u5165\u5317\u4eac\uff09\uff0c\u5317\u4eac\u76847\u5929\u611f\u67d3\u8005\u6570\u91cf\u5c06\u51cf\u5c1191.14\uff05\u3002",
            "contribution_ids": [
                "R12246"
            ]
        },
        {
            "instance_id": "R12251xR12223",
            "comparison_id": "R12251",
            "paper_id": "R12223",
            "text": "Modelling the epidemic trend of the 2019 novel coronavirus outbreak in China we present a timely evaluation of the chinese 2019-ncov epidemic in its initial phase, where 2019-ncov demonstrates comparable transmissibility but lower fatality rates than sars and mers. a quick diagnosis that leads to case isolation and integrated interventions will have a major impact on its future trend. nevertheless, as china is facing its spring festival travel rush and the epidemic has spread beyond its borders, further investigation on its potential spatiotemporal transmission pattern and novel intervention strategies are warranted.",
            "contribution_ids": [
                "R12224"
            ]
        },
        {
            "instance_id": "R12251xR12235",
            "comparison_id": "R12251",
            "paper_id": "R12235",
            "text": "Estimating the effective reproduction number of the 2019-nCoV in China abstract we estimate the effective reproduction number for 2019-ncov based on the daily reported cases from china cdc. the results indicate that 2019-ncov has a higher effective reproduction number than sars with a comparable fatality rate. article summary line this modeling study indicates that 2019-ncov has a higher effective reproduction number than sars with a comparable fatality rate.",
            "contribution_ids": [
                "R12236"
            ]
        },
        {
            "instance_id": "R12251xR36114",
            "comparison_id": "R12251",
            "paper_id": "R36114",
            "text": "Estimation of the epidemic properties of the 2019 novel coronavirus: A mathematical modeling study abstract background the 2019 novel coronavirus (covid-19) emerged in wuhan, china in december 2019 and has been spreading rapidly in china. decisions about its pandemic threat and the appropriate level of public health response depend heavily on estimates of its basic reproduction number and assessments of interventions conducted in the early stages of the epidemic. methods we conducted a mathematical modeling study using five independent methods to assess the basic reproduction number (r0) of covid-19, using data on confirmed cases obtained from the china national health commission for the period 10 th january \u2013 8 th february. we analyzed the data for the period before the closure of wuhan city (10 th january \u2013 23 rd january) and the post-closure period (23 rd january \u2013 8 th february) and for the whole period, to assess both the epidemic risk of the virus and the effectiveness of the closure of wuhan city on spread of covid-19. findings before the closure of wuhan city the basic reproduction number of covid-19 was 4.38 (95% ci: 3.63 \u2013 5.13), dropping to 3.41 (95% ci: 3.16 \u2013 3.65) after the closure of wuhan city. over the entire epidemic period covid-19 had a basic reproduction number of 3.39 (95% ci: 3.09 \u2013 3.70), indicating it has a very high transmissibility. interpretation covid-19 is a highly transmissible virus with a very high risk of epidemic outbreak once it emerges in metropolitan areas. the closure of wuhan city was effective in reducing the severity of the epidemic, but even after closure of the city and the subsequent expansion of that closure to other parts of hubei the virus remained extremely infectious. emergency planners in other cities should consider this high infectiousness when considering responses to this virus. funding national natural science foundation of china, china medical board, national science and technology major project of china",
            "contribution_ids": [
                "R36115",
                "R36116",
                "R36117"
            ]
        },
        {
            "instance_id": "R12251xR12237",
            "comparison_id": "R12251",
            "paper_id": "R12237",
            "text": "Preliminary estimation of the basic reproduction number of novel coronavirus (2019-nCoV) in China, from 2019 to 2020: A data-driven analysis in the early phase of the outbreak abstract backgrounds an ongoing outbreak of a novel coronavirus (2019-ncov) pneumonia hit a major city of china, wuhan, december 2019 and subsequently reached other provinces/regions of china and countries. we present estimates of the basic reproduction number, r 0 , of 2019-ncov in the early phase of the outbreak. methods accounting for the impact of the variations in disease reporting rate, we modelled the epidemic curve of 2019-ncov cases time series, in mainland china from january 10 to january 24, 2020, through the exponential growth. with the estimated intrinsic growth rate ( \u03b3 ), we estimated r 0 by using the serial intervals (si) of two other well-known coronavirus diseases, mers and sars, as approximations for the true unknown si. findings the early outbreak data largely follows the exponential growth. we estimated that the mean r 0 ranges from 2.24 (95%ci: 1.96-2.55) to 3.58 (95%ci: 2.89-4.39) associated with 8-fold to 2-fold increase in the reporting rate. we demonstrated that changes in reporting rate substantially affect estimates of r 0 . conclusion the mean estimate of r 0 for the 2019-ncov ranges from 2.24 to 3.58, and significantly larger than 1. our findings indicate the potential of 2019-ncov to cause outbreaks.",
            "contribution_ids": [
                "R12238",
                "R12240"
            ]
        },
        {
            "instance_id": "R12251xR12243",
            "comparison_id": "R12251",
            "paper_id": "R12243",
            "text": "Pattern of early human-to-human transmission of Wuhan 2019-nCoV abstract on december 31, 2019, the world health organization was notified about a cluster of pneumonia of unknown aetiology in the city of wuhan, china. chinese authorities later identified a new coronavirus (2019-ncov) as the causative agent of the outbreak. as of january 23, 2020, 655 cases have been confirmed in china and several other countries. understanding the transmission characteristics and the potential for sustained human-to-human transmission of 2019-ncov is critically important for coordinating current screening and containment strategies, and determining whether the outbreak constitutes a public health emergency of international concern (pheic). we performed stochastic simulations of early outbreak trajectories that are consistent with the epidemiological findings to date. we found the basic reproduction number, r 0 , to be around 2.2 (90% high density interval 1.4\u20143.8), indicating the potential for sustained human-to-human transmission. transmission characteristics appear to be of a similar magnitude to severe acute respiratory syndrome-related coronavirus (sars-cov) and the 1918 pandemic influenza. these findings underline the importance of heightened screening, surveillance and control efforts, particularly at airports and other travel hubs, in order to prevent further international spread of 2019-ncov.",
            "contribution_ids": [
                "R12244"
            ]
        },
        {
            "instance_id": "R12251xR37006",
            "comparison_id": "R12251",
            "paper_id": "R37006",
            "text": "Estimating the Unreported Number of Novel Coronavirus (2019-nCoV) Cases in China in the First Half of January 2020: A Data-Driven Modelling Analysis of the Early Outbreak background: in december 2019, an outbreak of respiratory illness caused by a novel coronavirus (2019-ncov) emerged in wuhan, china and has swiftly spread to other parts of china and a number of foreign countries. the 2019-ncov cases might have been under-reported roughly from 1 to 15 january 2020, and thus we estimated the number of unreported cases and the basic reproduction number, r0, of 2019-ncov. methods: we modelled the epidemic curve of 2019-ncov cases, in mainland china from 1 december 2019 to 24 january 2020 through the exponential growth. the number of unreported cases was determined by the maximum likelihood estimation. we used the serial intervals (si) of infection caused by two other well-known coronaviruses (cov), severe acute respiratory syndrome (sars) and middle east respiratory syndrome (mers) covs, as approximations of the unknown si for 2019-ncov to estimate r0. results: we confirmed that the initial growth phase followed an exponential growth pattern. the under-reporting was likely to have resulted in 469 (95% ci: 403\u2013540) unreported cases from 1 to 15 january 2020. the reporting rate after 17 january 2020 was likely to have increased 21-fold (95% ci: 18\u201325) in comparison to the situation from 1 to 17 january 2020 on average. we estimated the r0 of 2019-ncov at 2.56 (95% ci: 2.49\u20132.63). conclusion: the under-reporting was likely to have occurred during the first half of january 2020 and should be considered in future investigation.",
            "contribution_ids": [
                "R37007"
            ]
        },
        {
            "instance_id": "R12251xR36151",
            "comparison_id": "R12251",
            "paper_id": "R36151",
            "text": "Effects of voluntary event cancellation and school closure as countermeasures against COVID-19 outbreak in Japan abstract background to control the covid-19 outbreak in japan, sports and entertainment events were canceled and schools were closed throughout japan from february 26 through march 19. that policy has been designated as voluntary event cancellation and school closure (vecsc). object this study assesses vecsc effectiveness based on predicted outcomes. method: a simple susceptible\u2013infected\u2013recovery model was applied to data of patients with symptoms in japan during january 14 through march 25. the respective reproduction numbers were estimated before vecsc (r), during vecsc (r e ), and after vecsc (r a ). results results suggest r before vecsc as 1.987 [1.908, 2.055], r e during vecsc as 1.122 [0.980, 1.260], and r a after vecsc as 3.086 [2.529, 3.739]. discussion and conclusion results demonstrated that vecsc can reduce covid-19 infectiousness considerably, but the value of r rose to exceed 2.5 after vecsc.",
            "contribution_ids": [
                "R36152"
            ]
        },
        {
            "instance_id": "R12251xR12226",
            "comparison_id": "R12251",
            "paper_id": "R12226",
            "text": "Time-varying transmission dynamics of Novel Coronavirus Pneumonia in China abstract rationale several studies have estimated basic production number of novel coronavirus pneumonia (ncp). however, the time-varying transmission dynamics of ncp during the outbreak remain unclear. objectives we aimed to estimate the basic and time-varying transmission dynamics of ncp across china, and compared them with sars. methods data on ncp cases by february 7, 2020 were collected from epidemiological investigations or official websites. data on severe acute respiratory syndrome (sars) cases in guangdong province, beijing and hong kong during 2002-2003 were also obtained. we estimated the doubling time, basic reproduction number ( r 0 ) and time-varying reproduction number ( r t ) of ncp and sars. measurements and main results as of february 7, 2020, 34,598 ncp cases were identified in china, and daily confirmed cases decreased after february 4. the doubling time of ncp nationwide was 2.4 days which was shorter than that of sars in guangdong (14.3 days), hong kong (5.7 days) and beijing (12.4 days). the r 0 of ncp cases nationwide and in wuhan were 4.5 and 4.4 respectively, which were higher than r 0 of sars in guangdong ( r 0 =2.3), hongkong ( r 0 =2.3), and beijing ( r 0 =2.6). the r t for ncp continuously decreased especially after january 16 nationwide and in wuhan. the r 0 for secondary ncp cases in guangdong was 0.6, and the r t values were less than 1 during the epidemic. conclusions ncp may have a higher transmissibility than sars, and the efforts of containing the outbreak are effective. however, the efforts are needed to persist in for reducing time-varying reproduction number below one. at a glance commentary scientific knowledge on the subject since december 29, 2019, pneumonia infection with 2019-ncov, now named as novel coronavirus pneumonia (ncp), occurred in wuhan, hubei province, china. the disease has rapidly spread from wuhan to other areas. as a novel virus, the time-varying transmission dynamics of ncp remain unclear, and it is also important to compare it with sars. what this study adds to the field we compared the transmission dynamics of ncp with sars, and found that ncp has a higher transmissibility than sars. time-varying production number indicates that rigorous control measures taken by governments are effective across china, and persistent efforts are needed to be taken for reducing instantaneous reproduction number below one.",
            "contribution_ids": [
                "R12227",
                "R12229"
            ]
        },
        {
            "instance_id": "R12251xR12247",
            "comparison_id": "R12251",
            "paper_id": "R12247",
            "text": "Early transmission dynamics in wuhan, china, of novel coronavirus-infected pneumonia abstract background the initial cases of novel coronavirus (2019-ncov)\u2013infected pneumonia (ncip) occurred in wuhan, hubei province, china, in december 2019 and january 2020. we analyzed data on the first 425 confirmed cases in wuhan to determine the epidemiologic characteristics of ncip. methods we collected information on demographic characteristics, exposure history, and illness timelines of laboratory-confirmed cases of ncip that had been reported by january 22, 2020. we described characteristics of the cases and estimated the key epidemiologic time-delay distributions. in the early period of exponential growth, we estimated the epidemic doubling time and the basic reproductive number. results among the first 425 patients with confirmed ncip, the median age was 59 years and 56% were male. the majority of cases (55%) with onset before january 1, 2020, were linked to the huanan seafood wholesale market, as compared with 8.6% of the subsequent cases. the mean incubation period was 5.2 days (95% confidence interval [ci], 4.1 to 7.0), with the 95th percentile of the distribution at 12.5 days. in its early stages, the epidemic doubled in size every 7.4 days. with a mean serial interval of 7.5 days (95% ci, 5.3 to 19), the basic reproductive number was estimated to be 2.2 (95% ci, 1.4 to 3.9). conclusions on the basis of this information, there is evidence that human-to-human transmission has occurred among close contacts since the middle of december 2019. considerable efforts to reduce transmission will be required to control outbreaks if similar dynamics apply elsewhere. measures to prevent or reduce transmission should be implemented in populations at risk. (funded by the ministry of science and technology of china and others.)",
            "contribution_ids": [
                "R12248",
                "R41228"
            ]
        },
        {
            "instance_id": "R12251xR12233",
            "comparison_id": "R12251",
            "paper_id": "R12233",
            "text": "Early transmissibility assessment of a novel coronavirus in Wuhan between december 1, 2019 and january 26, 2020, nearly 3000 cases of respiratory illness caused by a novel coronavirus originating in wuhan, china have been reported. in this short analysis, we combine publicly available cumulative case data from the ongoing outbreak with phenomenological modeling methods to conduct an early transmissibility assessment. our model suggests that the basic reproduction number associated with the outbreak (at time of writing) may range from 2.0 to 3.1. though these estimates are preliminary and subject to change, they are consistent with previous findings regarding the transmissibility of the related sars-coronavirus and indicate the possibility of epidemic potential.",
            "contribution_ids": [
                "R12234"
            ]
        },
        {
            "instance_id": "R137469xR137444",
            "comparison_id": "R137469",
            "paper_id": "R137444",
            "text": "Mechanisms of bacterial inactivation in the liquid phase induced by a remote RF cold atmospheric pressure plasma jet a radio-frequency atmospheric pressure argon plasma jet is used for the inactivation of bacteria (pseudomonas aeruginosa) in solutions. the source is characterized by measurements of power dissipation, gas temperature, absolute uv irradiance as well as mass spectrometry measurements of emitted ions. the plasma-induced liquid chemistry is studied by performing liquid ion chromatography and hydrogen peroxide concentration measurements on treated distilled water samples. additionally, a quantitative estimation of an extensive liquid chemistry induced by the plasma is made by solution kinetics calculations. the role of the different active components of the plasma is evaluated based on either measurements, as mentioned above, or estimations based on published data of measurements of those components. for the experimental conditions being considered in this work, it is shown that the bactericidal effect can be solely ascribed to plasma-induced liquid chemistry, leading to the production of stable and transient chemical species. it is shown that hno2, onoo\u2212 and h2o2 are present in the liquid phase in similar quantities to concentrations which are reported in the literature to cause bacterial inactivation. the importance of plasma-induced chemistry at the gas\u2013liquid interface is illustrated and discussed in detail.",
            "contribution_ids": [
                "R137446",
                "R137459"
            ]
        },
        {
            "instance_id": "R137469xR137401",
            "comparison_id": "R137469",
            "paper_id": "R137401",
            "text": "On the spatio-temporal dynamics of a self-pulsed nanosecond transient spark discharge: a spectroscopic and electrical analysis a self-pulsing discharge in flowing argon is investigated by means of electrical, optical and spectroscopic methods. the dependence of the discharge self-pulsing frequency on external parameters (applied negative dc voltage, gap dimensions) is determined, and optical and spectroscopic methods are used to investigate the discharge development with high spatial and temporal resolution. high-resolution spectroscopic measurements at several wavelengths reveal the complex dynamics of the transient spark discharge: a pre-phase at the needle tip and capillary edge, propagation of positive and negative streamers, creation of a transient glow discharge structure and a long-lasting afterglow. excited plasma species necessary for the treatment of an exposed sample continue to be present even 80 \u00b5s after the breakdown of the active plasma.",
            "contribution_ids": [
                "R137403"
            ]
        },
        {
            "instance_id": "R137469xR137413",
            "comparison_id": "R137469",
            "paper_id": "R137413",
            "text": "Inactivation of Gram-positive biofilms by low-temperature plasma jet at atmospheric pressure this work is devoted to the evaluation of the efficiency of a new low-temperature plasma jet driven in ambient air by a dc-corona discharge to inactivate adherent cells and biofilms of gram-positive bacteria. the selected microorganisms were lactic acid bacteria, a weissella confusa strain which has the particularity to excrete a polysaccharide polymer (dextran) when sucrose is present. both adherent cells and biofilms were treated with the low-temperature plasma jet for different exposure times. the antimicrobial efficiency of the plasma was tested against adherent cells and 48 h-old biofilms grown with or without sucrose. bacterial survival was estimated using both colony-forming unit counts and fluorescence-based assays for bacterial cell viability. the experiments show the ability of the low-temperature plasma jet at atmospheric pressure to inactivate the bacteria. an increased resistance of bacteria embedded within biofilms is clearly observed. the resistance is also significantly higher with biofilm in the presence of sucrose, which indicates that dextran could play a protective role.",
            "contribution_ids": [
                "R137415"
            ]
        },
        {
            "instance_id": "R137469xR137447",
            "comparison_id": "R137469",
            "paper_id": "R137447",
            "text": "Spectroscopic Investigation of a Microwave-Generated Atmospheric Pressure Plasma Torch \"the investigated new microwave plasma torch is based on an axially symmetric resonator. microwaves of a frequency of 2.45 ghz are resonantly fed into this cavity resulting in a sufficiently high electric field to ignite plasma without any additional igniters as well as to maintain stable plasma operation. optical emission spectroscopy was carried out to characterize a humid air plasma. oh\u2010bands were used to determine the gas rotational temperature trot while the electron temperature was estimated by a boltzmann plot of oxygen lines. maximum temperatures of trot of about 3600 k and electron temperatures of 5800 k could be measured. the electron density ne was estimated to ne \u2248 3 \u00b7 1020m\u20133 by using saha's equation. parametric studies in dependence of the gas flow and the supplied microwave power revealed that the maximum temperatures are independent of these parameters. however, the volume of the plasma increases with increasing microwave power and with a decrease of the gas flow. considerations using collision frequencies, energy transfer times and power coupling provide an explanation of the observed phenomena: the optimal microwave heating is reached for electron\u2010neutral collision frequencies \u03bden being near to the angular frequency of the wave \u03c9 (\u00a9 2012 wiley\u2010vch verlag gmbh & co. kgaa, weinheim)\"",
            "contribution_ids": [
                "R137449"
            ]
        },
        {
            "instance_id": "R137469xR137392",
            "comparison_id": "R137469",
            "paper_id": "R137392",
            "text": "Steam plasma jet treatment of phenol in aqueous solution at atmospheric pressure steam plasma jet (spj) was generated by phenol aqueous solution introduced into water plasma torch as plasma forming gas, which injected into phenol aqueous solution to conduct oxidation degradation of organic pollutants in aqueous solutions. the experimental results indicated that the phenol was not only decomposed in spj, but also degraded in phenol aqueous solution due to high concentration hydroxyl radicals. moreover, the energy efficiencies significantly increased from (1.6\u20131.8) \u00d7 10\u221210 to (4.8\u20138.0) \u00d7 10\u22128 mol \u00b7 j\u22121 with the initial concentration of phenol increased from 0.5 to 50.0 g \u00b7 l\u22121. the main intermediates of phenol decomposition were pyrocatechol, hydroquinone, maleic acid, butanedioic acid, and muconic acid in liquid. the major gaseous effluence products were h2, co, and co2.",
            "contribution_ids": [
                "R137394"
            ]
        },
        {
            "instance_id": "R137469xR137438",
            "comparison_id": "R137469",
            "paper_id": "R137438",
            "text": "Power coupling and electrical characterization of a radio-frequency micro atmospheric pressure plasma jet we propose an efficient rf power coupling scheme for a micro atmospheric pressure plasma jet operating in helium. the discharge gap is used as a resonant element in a series lc circuit. in resonance, the voltage across the discharge gap is amplified and the ignition of the plasma is enabled with the input rf power as low as 0.5 w. high power coupling efficiency and simplicity of the circuit allow accurate electrical characterization of the discharge. systematic measurements of the dissipated power as a function of the applied voltage are reported for the discharge operating in helium with molecular admixtures of n2 and o2.",
            "contribution_ids": [
                "R137440"
            ]
        },
        {
            "instance_id": "R137469xR137441",
            "comparison_id": "R137469",
            "paper_id": "R137441",
            "text": "Photons and particles emitted from cold atmospheric-pressure plasma inactivate bacteria and biomolecules independently and synergistically cold atmospheric-pressure plasmas are currently in use in medicine as surgical tools and are being evaluated for new applications, including wound treatment and cosmetic care. the disinfecting properties of plasmas are of particular interest, given the threat of antibiotic resistance to modern medicine. plasma effluents comprise (v)uv photons and various reactive particles, such as accelerated ions and radicals, that modify biomolecules; however, a full understanding of the molecular mechanisms that underlie plasma-based disinfection has been lacking. here, we investigate the antibacterial mechanisms of plasma, including the separate, additive and synergistic effects of plasma-generated (v)uv photons and particles at the cellular and molecular levels. using scanning electron microscopy, we show that plasma-emitted particles cause physical damage to the cell envelope, whereas uv radiation does not. the lethal effects of the plasma effluent exceed the zone of physical damage. we demonstrate that both plasma-generated particles and (v)uv photons modify dna nucleobases. the particles also induce breaks in the dna backbone. the plasma effluent, and particularly the plasma-generated particles, also rapidly inactivate proteins in the cellular milieu. thus, in addition to physical damage to the cellular envelope, modifications to dna and proteins contribute to the bactericidal properties of cold atmospheric-pressure plasma.",
            "contribution_ids": [
                "R137443"
            ]
        },
        {
            "instance_id": "R137469xR137395",
            "comparison_id": "R137469",
            "paper_id": "R137395",
            "text": "Direct current plasma jet at atmospheric pressure operating in nitrogen and air an atmospheric pressure direct current (dc) plasma jet is investigated in n2 and dry air in terms of plasma properties and generation of active species in the active zone and the afterglow. the influence of working gases and the discharge current on plasma parameters and afterglow properties are studied. the electrical diagnostics show that discharge can be sustained in two different operating modes, depending on the current range: a self-pulsing regime at low current and a glow regime at high current. the gas temperature and the n2 vibrational temperature in the active zone of the jet and in the afterglow are determined by means of emission spectroscopy, based on fitting spectra of n2 second positive system (c3\u03c0-b3\u03c0) and the boltzmann plot method, respectively. the spectra and temperature differences between the n2 and the air plasma jet are presented and analyzed. space-resolved ozone and nitric oxide density measurements are carried out in the afterglow of the jet. the density of ozone, which is formed...",
            "contribution_ids": [
                "R137397"
            ]
        },
        {
            "instance_id": "R137469xR137419",
            "comparison_id": "R137469",
            "paper_id": "R137419",
            "text": "The influence of the geometry and electrical characteristics on the formation of the atmospheric pressure plasma jet an extensive electrical study was performed on a coaxial geometry atmospheric pressure plasma jet source in helium, driven by 30 khz sine voltage. two modes of operation were observed, a highly reproducible low-power mode that features the emission of one plasma bullet per voltage period and an erratic high-power mode in which micro-discharges appear around the grounded electrode. the minimum of power transfer efficiency corresponds to the transition between the two modes. effective capacitance was identified as a varying property influenced by the discharge and the dissipated power. the charge carried by plasma bullets was found to be a small fraction of charge produced in the source irrespective of input power and configuration of the grounded electrode. the biggest part of the produced charge stays localized in the plasma source and below the grounded electrode, in the range 1.2\u20133.3 nc for ground length of 3\u20138 mm.",
            "contribution_ids": [
                "R137421"
            ]
        },
        {
            "instance_id": "R137469xR137386",
            "comparison_id": "R137469",
            "paper_id": "R137386",
            "text": "Cold DC-Operated Air Plasma Jet for the Inactivation of Infectious Microorganisms we evaluated a nonthermal plasma jet for a respective use to prevent infections from bacteria and yeasts. the plasma jet is generated from the flow of ambient air with 8 slm through a microhollow cathode discharge assembly that is operated with a direct current of 30 ma. with these parameters, the temperature in the jet reaches 43 \u00b0c at 10 mm from the discharge. agar plates that were inoculated with staphylococcus aureus, pseudomonas aeruginosa, acinetobacter baumannii, and candida kefyr were treated at this distance, moving the plates through the jet in a meander that covered a 2 cm by 2 cm area. different exposure times were realized by changing the speed of the movement and adjusting the distance between consecutive passes. s. aureus was most responsive to the exposure with a reduction in the number of colony forming units of 5.5 log steps in 40 s. all other microorganisms show a more gradual inactivation with exposure times. for all bacteria, a clearing of the treated area is achieved in about 2.5-3.5 min, corresponding to log-reduction factors of 5.5-6.5. complete inactivation of the yeast requires about 7 min. both s. aureus and c. kefyr show considerable inactivation also outside the immediate treatment area, while p. aeruginosa and a. baumannii do not. we conclude that differences in the morphologies of the membrane structures are responsible for the diverging results, together with a targeted response to different agents provided with the plasma jet. for the gram negative bacteria, we hold short-lived agents, acting across a short range, responsible, while for the other microorganisms, longer lived species seem more important. our measurements show that neither heat, ultraviolet radiation, nor the generation of ozone can be responsible for the observed results. the most prominent long lived reaction product found is nitric oxide, which, by itself or through induced chemical reactions, might affect cell viability.",
            "contribution_ids": [
                "R137388"
            ]
        },
        {
            "instance_id": "R137469xR137407",
            "comparison_id": "R137469",
            "paper_id": "R137407",
            "text": "Discharge Dynamics and Modes of an Atmospheric Pressure Non-Equilibrium Air Plasma Jet a plasma jet operated with atmospheric pressure air is presented. unlike the dynamics of plasma jets working with noble gases, the propagation of the jet that is operated with air is primarily determined by the gas flow. this jet can be generated by applying a continuous, i.e., dc high voltage. however, depending on the applied voltage and gas flow rate a true dc operation can be distinguished from a self-pulsing mode. the gas temperature of the plasma plume when operated in the pulsed mode is lower than for the dc mode. conversely, emission intensities of atomic oxygen, o, and nitrogen species, n 2 and n + 2 , are much higher for the pulsed mode than observed for dc operation.",
            "contribution_ids": [
                "R137409"
            ]
        },
        {
            "instance_id": "R137469xR137389",
            "comparison_id": "R137469",
            "paper_id": "R137389",
            "text": "Arrays of microplasmas for the controlled production of tunable high fluxes of reactive oxygen species at atmospheric pressure the atmospheric-pressure generation of singlet delta oxygen (o2(a 1\u03b4g)) by microplasmas was experimentally studied. the remarkable stability of microcathode sustained discharges (mcsds) allowed the operation of dc glow discharges, free from the glow-to-arc transition, in he/o2/no mixtures at atmospheric pressure. from optical diagnostics measurements we deduced the yield of o2(a 1\u03b4g). by operating arrays of several mcsds in series, o2(a 1\u03b4g) densities higher than 1.0 \u00d7 1017 cm\u22123 were efficiently produced and transported over distances longer than 50 cm, corresponding to o2(a 1\u03b4g) partial pressures and production yields greater than 5 mbar and 6%, respectively. at such high o2(a 1\u03b4g) densities, the fluorescence of the so-called o2(a 1\u03b4g) dimol was observed as a red glow at 634 nm up to 1 m downstream. parallel operation of arrays of mcsds was also implemented, generating o2(a 1\u03b4g) fluxes as high as 100 mmol h\u22121. in addition, ozone (o3) densities up to 1016 cm\u22123 were obtained. finally, the density ratio of o2(a 1\u03b4g) to o3 was finely and easily tuned in the range [10\u22123\u201310+5], through the values of the discharge current and no concentration. this opens up opportunities for a large spectrum of new applications, making this plasma source notably very useful for biomedicine.",
            "contribution_ids": [
                "R137391"
            ]
        },
        {
            "instance_id": "R137469xR137450",
            "comparison_id": "R137469",
            "paper_id": "R137450",
            "text": "Modeling of microwave-induced plasma in argon at atmospheric pressure a two-dimensional model of microwave-induced plasma (field frequency 2.45 ghz) in argon at atmospheric pressure is presented. the model describes in a self-consistent manner the gas flow and heat transfer, the in-coupling of the microwave energy into the plasma, and the reaction kinetics relevant to high-pressure argon plasma including the contribution of molecular ion species. the model provides the gas and electron temperature distributions, the electron, ion, and excited state number densities, and the power deposited into the plasma for given gas flow rate and temperature at the inlet, and input power of the incoming tem microwave. for flow rate and absorbed microwave power typical for analytical applications (200-400 ml/min and 20 w), the plasma is far from thermodynamic equilibrium. the gas temperature reaches values above 2000 k in the plasma region, while the electron temperature is about 1 ev. the electron density reaches a maximum value of about 4 \u00d7 10(21) m(-3). the balance of the charged particles is essentially controlled by the kinetics of the molecular ions. for temperatures above 1200 k, quasineutrality of the plasma is provided by the atomic ions, and below 1200 k the molecular ion density exceeds the atomic ion density and a contraction of the discharge is observed. comparison with experimental data is presented which demonstrates good quantitative and qualitative agreement.",
            "contribution_ids": [
                "R137452"
            ]
        },
        {
            "instance_id": "R137469xR137404",
            "comparison_id": "R137469",
            "paper_id": "R137404",
            "text": "Characteristics of an atmospheric-pressure argon plasma jet excited by a dc voltage a dc-excited plasma jet is developed to generate a diffuse plasma plume in flowing argon. the discharge characteristics of the plasma jet are investigated by optical and electrical methods. the results show that the plasma plume is a pulsed discharge even when a dc voltage is applied. the discharge frequency varies with a change in the applied voltage, the gas flow rate and the gas gap width. it is found that the discharges at different positions of the plasma plume are initiated and quenched almost at the same time with a jitter of about 10 ns by the spatially resolved measurement. optical emission spectroscopy is used to investigate the excited electron temperature of the plasma plume. the results show that the excited electron temperature decreases with increasing applied voltage, gas flow rate or gas gap width. these results are analyzed qualitatively.",
            "contribution_ids": [
                "R137406",
                "R137428"
            ]
        },
        {
            "instance_id": "R137469xR137383",
            "comparison_id": "R137469",
            "paper_id": "R137383",
            "text": "Study on Plasma Agent Effect of a Direct-Current Atmospheric Pressure Oxygen-Plasma Jet on Inactivation of E. coli Using Bacterial Mutants biosensors of single-gene knockout mutants and physical methods using mesh and quartz glass are employed to discriminate plasma agents and assess their lethal effects generated in a direct-current atmospheric-pressure oxygen plasma jet. radicals generated in plasma are determined by optical emission spectroscopy, along with the o3 density measurement by uv absorption spectroscopy. besides, thermal effect is investigated by an infrared camera. the biosensors include three kinds of escherichia coli (e. coli) k-12 substrains with their mutants, totalling 8 kinds of bacteria. results show that oxidative stress plays a main role in the inactivation process. rather than superoxide o2-, neutral reactive oxygen species such as o3 and o2(a1\u03b4g) are identified as dominant sources for oxidative stress. in addition, dna damage caused by oxidation is found to be an important destruction mechanism.",
            "contribution_ids": [
                "R137385"
            ]
        },
        {
            "instance_id": "R137469xR137377",
            "comparison_id": "R137469",
            "paper_id": "R137377",
            "text": "A dc non-thermal atmospheric-pressure plasma microjet a direct current (dc), non-thermal, atmospheric-pressure plasma microjet is generated with helium/oxygen gas mixture as working gas. the electrical property is characterized as a function of the oxygen concentration and show distinctive regions of operation. side-on images of the jet were taken to analyze the mode of operation as well as the jet length. a self-pulsed mode is observed before the transition of the discharge to normal glow mode. optical emission spectroscopy is employed from both end-on and side-on along the jet to analyze the reactive species generated in the plasma. line emissions from atomic oxygen (at 777.4 nm) and helium (at 706.5 nm) were studied with respect to the oxygen volume percentage in the working gas, flow rate and discharge current. optical emission intensities of cu and oh are found to depend heavily on the oxygen concentration in the working gas. ozone concentration measured in a semi-confined zone in front of the plasma jet is found to be from tens to \u223c120 ppm. the results presented here demonstrate potential pathways for the adjustment and tuning of various plasma parameters such as reactive species selectivity and quantities or even ultraviolet emission intensities manipulation in an atmospheric-pressure non-thermal plasma source. the possibilities of fine tuning these plasma species allows for enhanced applications in health and medical related areas.",
            "contribution_ids": [
                "R137379"
            ]
        },
        {
            "instance_id": "R138127xR138043",
            "comparison_id": "R138127",
            "paper_id": "R138043",
            "text": "Paclitaxel-loaded PLGA nanoparticles surface modified with transferrin and Pluronic\u00c2\u00aeP85, anin vitrocell line andin vivobiodistribution studies on rat model the development of multidrug resistance (due to drug efflux by p-glycoproteins) is a major drawback with the use of paclitaxel (ptx) in the treatment of cancer. the rationale behind this study is to prepare ptx nanoparticles (nps) for the reversal of multidrug resistance based on the fact that ptx loaded into nps is not recognized by p-glycoproteins and hence is not effluxed out of the cell. also, the intracellular penetration of the nps could be enhanced by anchoring transferrin (tf) on the ptx-plga-nps. ptx-loaded plga nps (ptx-plga-nps), pluronic\u00aep85-coated plga nps (p85-ptx-plga-nps), and tf-anchored plga nps (tf-ptx-plga-nps) were prepared and evaluted for cytotoxicity and intracellular uptake using c6 rat glioma cell line. a significant increase in cytotoxicity was observed in the order of tf-ptx-plga-nps > p85-ptx-plga-nps > ptx-plga-nps in comparison to drug solution. in vivo biodistribution on male sprague\u2013dawley rats bearing c6 glioma (subcutaneous) showed higher tumor ptx concentrations in animals administered with ptx-nps compared to drug solution.",
            "contribution_ids": [
                "R138045"
            ]
        },
        {
            "instance_id": "R138127xR138058",
            "comparison_id": "R138127",
            "paper_id": "R138058",
            "text": "Formulation, optimization, hemocompatibility and pharmacokinetic evaluation of PLGA nanoparticles containing paclitaxel abstract objective: paclitaxel (ptx)-loaded polymer (poly(lactic-co-glycolic acid), plga)-based nanoformulation was developed with the objective of formulating cremophor el-free nanoformulation intended for intravenous use. significance: the polymeric ptx nanoparticles free from the cremophor el will help in eliminating the shortcomings of the existing delivery system as cremophor el causes serious allergic reactions to the subjects after intravenous use. methods and results: paclitaxel-loaded nanoparticles were formulated by nanoprecipitation method. the diminutive nanoparticles (143.2\\u2009nm) with uniform size throughout (polydispersity index, 0.115) and high entrapment efficiency (95.34%) were obtained by employing the box\u2013behnken design for the optimization of the formulation with the aid of desirability approach-based numerical optimization technique. optimized levels for each factor viz. polymer concentration (x1), amount of organic solvent (x2), and surfactant concentration (x3) were 0.23%, 5\\u2009ml %, and 1.13%, respectively. the results of the hemocompatibility studies confirmed the safety of plga-based nanoparticles for intravenous administration. pharmacokinetic evaluations confirmed the longer retention of ptx in systemic circulation. conclusion: in a nutshell, the developed polymeric nanoparticle formulation of ptx precludes the inadequacy of existing ptx formulation and can be considered as superior alternative carrier system of the same.",
            "contribution_ids": [
                "R138064"
            ]
        },
        {
            "instance_id": "R139050xR138884",
            "comparison_id": "R139050",
            "paper_id": "R138884",
            "text": "Automatic Detection of ADHD and ASD from Expressive Behaviour in RGBD Data attention deficit hyperactivity disorder (adhd) and autism spectrum disorder (asd) are neurodevelopmental conditions which impact on a significant number of children and adults. currently, the diagnosis of such disorders is done by experts who employ standard questionnaires and look for certain behavioural markers through manual observation. such methods for their diagnosis are not only subjective, difficult to repeat, and costly but also extremely time consuming. in this work, we present a novel methodology to aid diagnostic predictions about the presence/absence of adhd and asd by automatic visual analysis of a persons behaviour. to do so, we conduct the questionnaires in a computer-mediated way while recording participants with modern rgbd (colour+depth) sensors. in contrast to previous automatic approaches which have focussed only on detecting certain behavioural markers, our approach provides a fully automatic end-to-end system to directly predict adhd and asd in adults. using state of the art facial expression analysis based on dynamic deep learning and 3d analysis of behaviour, we attain classification rates of 96% for controls vs condition (adhd/asd) groups and 94% for comorbid (adhd+asd) vs asd only group. we show that our system is a potentially useful time saving contribution to the clinical diagnosis of adhd and asd.",
            "contribution_ids": [
                "R138886"
            ]
        },
        {
            "instance_id": "R139050xR138964",
            "comparison_id": "R139050",
            "paper_id": "R138964",
            "text": "The Facial Stress Recognition Based on Multi-histogram Features and Convolutional Neural Network the health disorders due to stress and depression should not be considered trivial because it has a negative impact on health. prolonged stress not only triggers mental fatigue but also affects physical health. therefore, we must be able to identify stress early. in this paper, we proposed the new methods for stress recognition on three classes (neutral, low stress, high stress) from a facial frontal image. each image divided into three parts, i.e. pairs of eyes, nose, and mouth. facial features have extracted on each image pixel using dog, hog, and dwt. the strength of orthonormality features is considered by the rica. the gda distributes the nonlinear covariance. furthermore, the histogram features of the image parts are applied at a depth-based learning of convnet to model the facial stress expression. the proposed method is used feret databases for training and validation. the k-fold validation method is used as a validation with k=5. based on the experiments result, the proposed method accuracy showing outperforms compared with other works.",
            "contribution_ids": [
                "R138966"
            ]
        },
        {
            "instance_id": "R139050xR139024",
            "comparison_id": "R139050",
            "paper_id": "R139024",
            "text": "X-A-BiLSTM: a Deep Learning Approach for Depression Detection in Imbalanced Data an increasing number of people suffering from mental health conditions resort to online resources (specialized websites, social media, etc.) to share their feelings. early depression detection using social media data through deep learning models can help to change life trajectories and save lives. but the accuracy of these models was not satisfying due to the real-world imbalanced data distributions. to tackle this problem, we propose a deep learning model (x-a-bilstm) for depression detection in imbalanced social media data. the x-a-bilstm model consists of two essential components: the first one is xgboost, which is used to reduce data imbalance; and the second one is an attention-bilstm neural network, which enhances classification capacity. the reddit self-reported depression diagnosis (rsdd) dataset was chosen, which included approximately 9,000 users who claimed to have been diagnosed with depression (\u201ddiagnosed users and approximately 107,000 matched control users. results demonstrate that our approach significantly outperforms the previous state-of-the-art models on the rsdd dataset.",
            "contribution_ids": [
                "R139026"
            ]
        },
        {
            "instance_id": "R139050xR138825",
            "comparison_id": "R139050",
            "paper_id": "R138825",
            "text": "Comprehensive functional genomic resource and integrative model for the human brain \\n introduction \\n strong genetic associations have been found for a number of psychiatric disorders. however, understanding the underlying molecular mechanisms remains challenging. \\n \\n \\n rationale \\n to address this challenge, the psychencode consortium has developed a comprehensive online resource and integrative models for the functional genomics of the human brain. \\n \\n \\n results \\n the base of the pyramidal resource is the datasets generated by psychencode, including bulk transcriptome, chromatin, genotype, and hi-c datasets and single-cell transcriptomic data from ~32,000 cells for major brain regions. we have merged these with data from genotype-tissue expression (gtex), encode, roadmap epigenomics, and single-cell analyses. via uniform processing, we created a harmonized resource, allowing us to survey functional genomics data on the brain over a sample size of 1866 individuals. \\n from this uniformly processed dataset, we created derived data products. these include lists of brain-expressed genes, coexpression modules, and single-cell expression profiles for many brain cell types; ~79,000 brain-active enhancers with associated hi-c loops and topologically associating domains; and ~2.5 million expression quantitative-trait loci (qtls) comprising ~238,000 linkage-disequilibrium\u2013independent single-nucleotide polymorphisms and of other types of qtls associated with splice isoforms, cell fractions, and chromatin activity. by using these, we found that &gt;88% of the cross-population variation in brain gene expression can be accounted for by cell fraction changes. furthermore, a number of disorders and aging are associated with changes in cell-type proportions. the derived data also enable comparison between the brain and other tissues. in particular, by using spectral analyses, we found that the brain has distinct expression and epigenetic patterns, including a greater extent of noncoding transcription than other tissues. \\n the top level of the resource consists of integrative networks for regulation and machine-learning models for disease prediction. the networks include a full gene regulatory network (grn) for the brain, linking transcription factors, enhancers, and target genes from merging of the qtls, generalized element-activity correlations, and hi-c data. by using this network, we link disease genes to genome-wide association study (gwas) variants for psychiatric disorders. for schizophrenia, we linked 321 genes to the 142 reported gwas loci. we then embedded the regulatory network into a deep-learning model to predict psychiatric phenotypes from genotype and expression. our model gives a ~6-fold improvement in prediction over additive polygenic risk scores. moreover, it achieves a ~3-fold improvement over additive models, even when the gene expression data are imputed, highlighting the value of having just a small amount of transcriptome data for disease prediction. lastly, it highlights key genes and pathways associated with disorder prediction, including immunological, synaptic, and metabolic pathways, recapitulating de novo results from more targeted analyses. \\n \\n \\n conclusion \\n our resource and integrative analyses have uncovered genomic elements and networks in the brain, which in turn have provided insight into the molecular mechanisms underlying psychiatric disorders. our deep-learning model improves disease risk prediction over traditional approaches and can be extended with additional data types (e.g., microrna and neuroimaging). \\n \\n \\n a comprehensive functional genomic resource for the adult human brain. \\n the resource forms a three-layer pyramid. the bottom layer includes sequencing datasets for traits, such as schizophrenia. the middle layer represents derived datasets, including functional genomic elements and qtls. the top layer contains integrated models, which link genotypes to phenotypes. dspn, deep structured phenotype network; pc1 and pc2, principal components 1 and 2; ref, reference; alt, alternate; h3k27ac, histone h3 acetylation at lysine 27. \\n \\n \\n \\n",
            "contribution_ids": [
                "R138856"
            ]
        },
        {
            "instance_id": "R139050xR138690",
            "comparison_id": "R139050",
            "paper_id": "R138690",
            "text": "Deep learning based automatic diagnoses of attention deficit hyperactive disorder in this paper, we aim to develop a deep learning based automatic attention deficit hyperactive disorder (adhd) diagnosis algorithm using resting state functional magnetic resonance imaging (rs-fmri) scans. however, relative to millions of parameters in deep neural networks (dnn), the number of fmri samples is still limited to learn discriminative features from the raw data. in light of this, we first encode our prior knowledge on 3d features voxel-wisely, including regional homogeneity (reho), fractional amplitude of low frequency fluctuations (falff) and voxel-mirrored homotopic connectivity (vmhc), and take these 3d images as the input to the dnn. inspired by the way that radiologists examine brain images, we further investigate a novel 3d convolutional neural network (cnn) architecture to learn 3d local patterns which may boost the diagnosis accuracy. investigation on the hold-out testing data of the adhd-200 global competition demonstrates that the proposed 3d cnn approach yields superior performances when compared to the reported classifiers in the literature, even with less training samples.",
            "contribution_ids": [
                "R138692"
            ]
        },
        {
            "instance_id": "R139050xR138679",
            "comparison_id": "R139050",
            "paper_id": "R138679",
            "text": "Synthetic structural magnetic resonance image generator improves deep learning prediction of schizophrenia despite the rapidly growing interest, progress in the study of relations between physiological abnormalities and mental disorders is hampered by complexity of the human brain and high costs of data collection. the complexity can be captured by deep learning approaches, but they still may require significant amounts of data. in this paper, we seek to mitigate the latter challenge by developing a generator for synthetic realistic training data. our method greatly improves generalization in classification of schizophrenia patients and healthy controls from their structural magnetic resonance images. a feed forward neural network trained exclusively on continuously generated synthetic data produces the best area under the curve compared to classifiers trained on real data alone.",
            "contribution_ids": [
                "R138681"
            ]
        },
        {
            "instance_id": "R139050xR138756",
            "comparison_id": "R139050",
            "paper_id": "R138756",
            "text": "Learning Spatial\u00e2\u0080\u0093Spectral\u00e2\u0080\u0093Temporal EEG Features With Recurrent 3D Convolutional Neural Networks for Cross-Task Mental Workload Assessment mental workload assessment is essential for maintaining human health and preventing accidents. most research on this issue is limited to a single task. however, cross-task assessment is indispensable for extending a pre-trained model to new workload conditions. because brain dynamics are complex across different tasks, it is difficult to propose efficient human-designed features based on prior knowledge. therefore, this paper proposes a concatenated structure of deep recurrent and 3d convolutional neural networks (r3dcnns) to learn eeg features across different tasks without prior knowledge. first, this paper adds frequency and time dimensions to eeg topographic maps based on a morlet wavelet transformation. then, r3dcnn is proposed to simultaneously learn eeg features from the spatial, spectral, and temporal dimensions. the proposed model is validated based on the eeg signals collected from 20 subjects. this paper employs a binary classification of low and high mental workload across spatial n-back and arithmetic tasks. the results show that the r3dcnn achieves an average accuracy of 88.9%, which is a significant increase compared with that of the state-of-the-art methods. in addition, the visualization of the convolutional layers demonstrates that the deep neural network can extract detailed features. these results indicate that r3dcnn is capable of identifying the mental workload levels for cross-task conditions.",
            "contribution_ids": [
                "R138761"
            ]
        },
        {
            "instance_id": "R139050xR138934",
            "comparison_id": "R139050",
            "paper_id": "R138934",
            "text": "An Affect Prediction Approach Through Depression Severity Parameter Incorporation in Neural Networks humans use emotional expressions to communicate their internal affective states. these behavioral expressions are often multi-modal (e.g. facial expression, voice and gestures) and researchers have proposed several schemes to predict the latent affective states based on these expressions. the relationship between the latent affective states and their expression is hypothesized to be affected by several factors; depression disorder being one of them. despite a wide interest in affect prediction, and several studies linking the effect of depression on affective expressions, only a limited number of affect prediction models account for the depression severity. in this work, we present a novel scheme that incorporates depression severity as a parameter in deep neural networks (dnns). in order to predict affective dimensions for an individual at hand, our scheme alters the dnn activation function based on the subject\u2019s depression severity. we perform experiments on affect prediction in two different sessions of the audio-visual depressive language corpus, which involves patients with varying degree of depression. our results show improvements in arousal and valence prediction on both the sessions using the proposed dnn modeling. we also present analysis of the impact of such an alteration in dnns during training and testing.",
            "contribution_ids": [
                "R138936"
            ]
        },
        {
            "instance_id": "R139050xR139038",
            "comparison_id": "R139050",
            "paper_id": "R139038",
            "text": "Hierarchical neural model with attention mechanisms for the\n            classification of social media text related to mental health mental health problems represent a major public health challenge. automated analysis of text related to mental health is aimed to help medical decision-making, public health policies and to improve health care. such analysis may involve text classification. traditionally, automated classification has been performed mainly using machine learning methods involving costly feature engineering. recently, the performance of those methods has been dramatically improved by neural methods. however, mainly convolutional neural networks (cnns) have been explored. in this paper, we apply a hierarchical recurrent neural network (rnn) architecture with an attention mechanism on social media data related to mental health. we show that this architecture improves overall classification results as compared to previously reported results on the same data. benefitting from the attention mechanism, it can also efficiently select text elements crucial for classification decisions, which can also be used for in-depth analysis.",
            "contribution_ids": [
                "R139040"
            ]
        },
        {
            "instance_id": "R139050xR139014",
            "comparison_id": "R139050",
            "paper_id": "R139014",
            "text": "Detecting Stress Based on Social Interactions in Social Networks psychological stress is threatening people\u2019s health. it is non-trivial to detect stress timely for proactive care. with the popularity of social media, people are used to sharing their daily activities and interacting with friends on social media platforms, making it feasible to leverage online social network data for stress detection. in this paper, we find that users stress state is closely related to that of his/her friends in social media, and we employ a large-scale dataset from real-world social platforms to systematically study the correlation of users\u2019 stress states and social interactions. we first define a set of stress-related textual, visual, and social attributes from various aspects, and then propose a novel hybrid model - a factor graph model combined with convolutional neural network to leverage tweet content and social interaction information for stress detection. experimental results show that the proposed model can improve the detection performance by 6-9 percent in f1-score. by further analyzing the social interaction data, we also discover several intriguing phenomena, i.e., the number of social structures of sparse connections (i.e., with no delta connections) of stressed users is around 14 percent higher than that of non-stressed users, indicating that the social structure of stressed users\u2019 friends tend to be less connected and less complicated than that of non-stressed users.",
            "contribution_ids": [
                "R139016"
            ]
        },
        {
            "instance_id": "R139050xR138719",
            "comparison_id": "R139050",
            "paper_id": "R138719",
            "text": "Deep Neural Generative Model of Functional MRI Images for Psychiatric Disorder Diagnosis \"accurate diagnosis of psychiatric disorders plays a critical role in improving the quality of life for patients and potentially supports the development of new treatments. many studies have been conducted on machine learning techniques that seek brain imaging data for specific biomarkers of disorders. these studies have encountered the following dilemma: a direct classification overfits to a small number of high-dimensional samples but unsupervised feature-extraction has the risk of extracting a signal of no interest. in addition, such studies often provided only diagnoses for patients without presenting the reasons for these diagnoses. this study proposed a deep neural generative model of resting-state functional magnetic resonance imaging (fmri) data. the proposed model is conditioned by the assumption of the subject's state and estimates the posterior probability of the subject's state given the imaging data, using bayes\u2019 rule. this study applied the proposed model to diagnose schizophrenia and bipolar disorders. diagnostic accuracy was improved by a large margin over competitive approaches, namely classifications of functional connectivity, discriminative/generative models of regionwise signals, and those with unsupervised feature-extractors. the proposed model visualizes brain regions largely related to the disorders, thus motivating further biological investigation.\"",
            "contribution_ids": [
                "R138724"
            ]
        },
        {
            "instance_id": "R139050xR138931",
            "comparison_id": "R139050",
            "paper_id": "R138931",
            "text": "DCNN and DNN based multi-modal depression recognition \"in this paper, we propose an audio visual multimodal depression recognition framework composed of deep convolutional neural network (dcnn) and deep neural network (dnn) models. for each modality, corresponding feature descriptors are input into a dcnn to learn high-level global features with compact dynamic information, which are then fed into a dnn to predict the phq-8 score. for multi-modal depression recognition, the predicted phq-8 scores from each modality are integrated in a dnn for the final prediction. in addition, we propose the histogram of displacement range as a novel global visual descriptor to quantify the range and speed of the facial landmarks' displacements. experiments have been carried out on the distress analysis interview corpus-wizard of oz (daic-woz) dataset for the depression sub-challenge of the audio-visual emotion challenge (avec 2016), results show that the proposed multi-modal depression recognition framework obtains very promising results on both the development set and test set, which outperforms the state-of-the-art results.\"",
            "contribution_ids": [
                "R138933"
            ]
        },
        {
            "instance_id": "R139050xR138859",
            "comparison_id": "R139050",
            "paper_id": "R138859",
            "text": "Multi task sequence learning for depression scale prediction from video depression is a typical mood disorder, which affects people in mental and even physical problems. people who suffer depression always behave abnormal in visual behavior and the voice. in this paper, an audio visual based multimodal depression scale prediction system is proposed. firstly, features are extracted from video and audio are fused in feature level to represent the audio visual behavior. secondly, long short memory recurrent neural network (lstm-rnn) is utilized to encode the dynamic temporal information of the abnormal audio visual behavior. thirdly, emotion information is utilized by multi-task learning to boost the performance further. the proposed approach is evaluated on the audio-visual emotion challenge (avec2014) dataset. experiments results show the dimensional emotion recognition helps to depression scale prediction.",
            "contribution_ids": [
                "R138861"
            ]
        },
        {
            "instance_id": "R139050xR138879",
            "comparison_id": "R139050",
            "paper_id": "R138879",
            "text": "Exploring microscopic fluctuation of facial expression for mood disorder classification in clinical diagnosis of mood disorder, depression is one of the most common psychiatric disorders. there are two major types of mood disorders: major depressive disorder (mdd) and bipolar disorder (bpd). a large portion of bpd are misdiagnosed as mdd in the diagnostic of mood disorders. short-term detection which could be used in early detection and intervention is thus desirable. this study investigates microscopic facial expression changes for the subjects with mdd, bpd and control group (cg), when elicited by emotional video clips. this study uses eight basic orientations of motion vector (mv) to characterize the subtle changes in microscopic facial expression. then, wavelet decomposition is applied to extract entropy and energy of different frequency bands. next, an autoencoder neural network is adopted to extract the bottleneck features for dimensionality reduction. finally, the long short term memory (lstm) is employed for modeling the long-term variation among different mood disorders types. for evaluation of the proposed method, the elicited data from 36 subjects (12 for each of mdd, bpd and cg) were considered in the k-fold (k=12) cross validation experiments, and the performance for distinguishing among mdd, bpd and cg achieved 67.7% accuracy.",
            "contribution_ids": [
                "R138881"
            ]
        },
        {
            "instance_id": "R139050xR138796",
            "comparison_id": "R139050",
            "paper_id": "R138796",
            "text": "A Deep Learning Approach for Predicting Antidepressant Response in Major Depression Using Clinical and Genetic Biomarkers in the wake of recent advances in scientific research, personalized medicine using deep learning techniques represents a new paradigm. in this work, our goal was to establish deep learning models which distinguish responders from non-responders, and also to predict possible antidepressant treatment outcomes in major depressive disorder (mdd). to uncover relationships between the responsiveness of antidepressant treatment and biomarkers, we developed a deep learning prediction approach resulting from the analysis of genetic and clinical factors such as single nucleotide polymorphisms (snps), age, sex, baseline hamilton rating scale for depression score, depressive episodes, marital status, and suicide attempt status of mdd patients. the cohort consisted of 455 patients who were treated with selective serotonin reuptake inhibitors (treatment-response rate = 61.0%; remission rate = 33.0%). by using the snp dataset that was original to a genome-wide association study, we selected 10 snps (including abca13 rs4917029, bnip3 rs9419139, cacna1e rs704329, exoc4 rs6978272, grin2b rs7954376, lhfpl3 rs4352778, nell1 rs2139423, nuak1 rs2956406, prex1 rs4810894, and slit3 rs139863958) which were associated with antidepressant treatment response. furthermore, we pinpointed 10 snps (including arntl rs11022778, camk1d rs2724812, gabrb3 rs12904459, grm8 rs35864549, naaladl2 rs9878985, ncald rs483986, pla2g4a rs12046378, prok2 rs73103153, rbfox1 rs17134927, and znf536 rs77554113) in relation to remission. then, we employed multilayer feedforward neural networks (mfnns) containing 1\u20133 hidden layers and compared mfnn models with logistic regression models. our analysis results revealed that the mfnn model with 2 hidden layers (area under the receiver operating characteristic curve (auc) = 0.8228 \u00b1 0.0571; sensitivity = 0.7546 \u00b1 0.0619; specificity = 0.6922 \u00b1 0.0765) performed maximally among predictive models to infer the complex relationship between antidepressant treatment response and biomarkers. in addition, the mfnn model with 3 hidden layers (auc = 0.8060 \u00b1 0.0722; sensitivity = 0.7732 \u00b1 0.0583; specificity = 0.6623 \u00b1 0.0853) achieved best among predictive models to predict remission. our study indicates that the deep mfnn framework may provide a suitable method to establish a tool for distinguishing treatment responders from non-responders prior to antidepressant therapy.",
            "contribution_ids": [
                "R138798"
            ]
        },
        {
            "instance_id": "R139050xR138870",
            "comparison_id": "R139050",
            "paper_id": "R138870",
            "text": "DepAudioNet: An Efficient Deep Model for Audio based Depression Classification this paper presents a novel and effective audio based method on depression classification. it focuses on two important issues, \\\\emph{i.e.} data representation and sample imbalance, which are not well addressed in literature. for the former one, in contrast to traditional shallow hand-crafted features, we propose a deep model, namely depaudionet, to encode the depression related characteristics in the vocal channel, combining convolutional neural network (cnn) and long short-term memory (lstm) to deliver a more comprehensive audio representation. for the latter one, we introduce a random sampling strategy in the model training phase to balance the positive and negative samples, which largely alleviates the bias caused by uneven sample distribution. evaluations are carried out on the daic-woz dataset for the depression classification sub-challenge (dcc) at the 2016 audio-visual emotion challenge (avec), and the experimental results achieved clearly demonstrate the effectiveness of the proposed approach.",
            "contribution_ids": [
                "R138872"
            ]
        },
        {
            "instance_id": "R139050xR138944",
            "comparison_id": "R139050",
            "paper_id": "R138944",
            "text": "Affective Computational Model to Extract Natural Affective States of Students With Asperger Syndrome (AS) in Computer-Based Learning Environment this paper was inspired by looking at the central role of emotion in the learning process, its impact on students\u2019 performance; as well as the lack of affective computing models to detect and infer affective-cognitive states in real time for students with and without asperger syndrome (as). this model overcomes gaps in other models that were designed for people with autism, which needed the use of sensors or physiological instrumentations to collect data. the model uses a webcam to capture students\u2019 affective-cognitive states of confidence, uncertainty, engagement, anxiety, and boredom. these states have a dominant effect on the learning process. the model was trained and tested on a natural-spontaneous affective dataset for students with and without as, which was collected for this purpose. the dataset was collected in an uncontrolled environment and included variations in culture, ethnicity, gender, facial and hairstyle, head movement, talking, glasses, illumination changes, and background variation. the model structure used deep learning (dl) techniques like convolutional neural network and long short-term memory. the dl is the-state-of-art tool that used to reduce data dimensionality and capturing non-linear complex features from simpler representations. the affective model provides reliable results with accuracy 90.06%. this model is the first model to detected affective states for adult students with as without physiological or wearable instruments. for the first time, the occlusions in this model, like hand over face or head were considered an important indicator for affective states like boredom, anxiety, and uncertainty. these occlusions have been ignored in most other affective models. the essential information channels in this model are facial expressions, head movement, and eye gaze. the model can serve as an aided-technology for tutors to monitor and detect the behaviors of all students at the same time and help in predicting negative affective states during learning process.",
            "contribution_ids": [
                "R138947"
            ]
        },
        {
            "instance_id": "R139050xR138927",
            "comparison_id": "R139050",
            "paper_id": "R138927",
            "text": "DeepBreath: Deep learning of breathing patterns for automatic stress recognition using low-cost thermal imaging in unconstrained settings \"we propose deepbreath, a deep learning model which automatically recognises people's psychological stress level (mental overload) from their breathing patterns. using a low cost thermal camera, we track a person's breathing patterns as temperature changes around his/her nostril. the paper's technical contribution is threefold. first of all, instead of creating handcrafted features to capture aspects of the breathing patterns, we transform the uni-dimensional breathing signals into two dimensional respiration variability spectrogram (rvs) sequences. the spectrograms easily capture the complexity of the breathing dynamics. second, a spatial pattern analysis based on a deep convolutional neural network (cnn) is directly applied to the spectrogram sequences without the need of hand-crafting features. finally, a data augmentation technique, inspired from solutions for over-fitting problems in deep learning, is applied to allow the cnn to learn with a small-scale dataset from short-term measurements (e.g., up to a few hours). the model is trained and tested with data collected from people exposed to two types of cognitive tasks (stroop colour word test, mental computation test) with sessions of different difficulty levels. using normalised self-report as ground truth, the cnn reaches 84.59% accuracy in discriminating between two levels of stress and 56.52% in discriminating between three levels. in addition, the cnn outperformed powerful shallow learning methods based on a single layer neural network. finally, the dataset of labelled thermal images will be open to the community.\"",
            "contribution_ids": [
                "R138929"
            ]
        },
        {
            "instance_id": "R139050xR139028",
            "comparison_id": "R139050",
            "paper_id": "R139028",
            "text": "Natural Language Processing of Social Media as Screening for Suicide Risk suicide is among the 10 most common causes of death, as assessed by the world health organization. for every death by suicide, an estimated 138 people\u2019s lives are meaningfully affected, and almost any other statistic around suicide deaths is equally alarming. the pervasiveness of social media\u2014and the near-ubiquity of mobile devices used to access social media networks\u2014offers new types of data for understanding the behavior of those who (attempt to) take their own lives and suggests new possibilities for preventive intervention. we demonstrate the feasibility of using social media data to detect those at risk for suicide. specifically, we use natural language processing and machine learning (specifically deep learning) techniques to detect quantifiable signals around suicide attempts, and describe designs for an automated system for estimating suicide risk, usable by those without specialized mental health training (eg, a primary care doctor). we also discuss the ethical use of such technology and examine privacy implications. currently, this technology is only used for intervention for individuals who have \u201copted in\u201d for the analysis and intervention, but the technology enables scalable screening for suicide risk, potentially identifying many people who are at risk preventively and prior to any engagement with a health care system. this raises a significant cultural question about the trade-off between privacy and prevention\u2014we have potentially life-saving technology that is currently reaching only a fraction of the possible people at risk because of respect for their privacy. is the current trade-off between privacy and prevention the right one?",
            "contribution_ids": [
                "R139030"
            ]
        },
        {
            "instance_id": "R139050xR138687",
            "comparison_id": "R139050",
            "paper_id": "R138687",
            "text": "Diagnosis of attention deficit hyperactivity disorder using deep belief network based on greedy approach attention deficit hyperactivity disorder creates conditions for the child as s/he cannot sit calm and still, control his/her behavior and focus his/her attention on a particular issue. five out of every hundred children are affected by the disease. boys are three times more than girls at risk for this complication. the disorder often begins before age seven, and parents may not realize their children problem until they get older. children with hyperactivity and attention deficit are at high risk of conduct disorder, antisocial personality, and drug abuse. most children suffering from the disease will develop a feeling of depression, anxiety and lack of self-confidence. given the importance of diagnosis the disease, deep belief networks (dbns) were used as a deep learning model to predict the disease. in this system, in addition to fmri images features, sophisticated features such as age and iq as well as functional characteristics, etc. were used. the proposed method was evaluated by two standard data sets of adhd-200 global competitions, including neuroimage and nyu data sets, and compared with state-of-the-art algorithms. the results showed the superiority of the proposed method rather than other systems. the prediction accuracy has improved respectively as +12.04 and +27.81 over neuroimage and nyu datasets compared to the best proposed method in the adhd-200 global competition.",
            "contribution_ids": [
                "R138689"
            ]
        },
        {
            "instance_id": "R139050xR139019",
            "comparison_id": "R139050",
            "paper_id": "R139019",
            "text": "UArizona at the CLEF eRisk 2017 Pilot Task: Linear and Recurrent Models for Early Depression Detection \"the 2017 clef erisk pilot task focuses on automatically detecting depression as early as possible from a users' posts to reddit. in this paper we present the techniques employed for the university of arizona team's participation in this early risk detection shared task. we leveraged external information beyond the small training set, including a preexisting depression lexicon and concepts from the unified medical language system as features. for prediction, we used both sequential (recurrent neural network) and non-sequential (support vector machine) models. our models perform decently on the test data, and the recurrent neural models perform better than the non-sequential support vector machines while using the same feature sets.\"",
            "contribution_ids": [
                "R139021"
            ]
        },
        {
            "instance_id": "R139050xR138802",
            "comparison_id": "R139050",
            "paper_id": "R138802",
            "text": "Assessing the severity of positive valence symptoms in initial psychiatric evaluation records: Should we use convolutional neural networks? background and objective efficiently capturing the severity of positive valence symptoms could aid in risk stratification for adverse outcomes among patients with psychiatric disorders and identify optimal treatment strategies for patient subgroups. motivated by the success of convolutional neural networks (cnns) in classification tasks, we studied the application of various cnn architectures and their performance in predicting the severity of positive valence symptoms in patients with psychiatric disorders based on initial psychiatric evaluation records. methods psychiatric evaluation records contain unstructured text and semi-structured data such as question\u2013answer pairs. for a given record, we tokenise and normalise the semi-structured content. pre-processed tokenised words are represented as one-hot encoded word vectors. we then apply different configurations of convolutional and max pooling layers to automatically learn important features from various word representations. we conducted a series of experiments to explore the effect of different cnn architectures on the classification of psychiatric records. results our best cnn model achieved a mean absolute error (mae) of 0.539 and a normalized mae of 0.785 on the test dataset, which is comparable to the other well-known text classification algorithms studied in this work. our results also suggest that the normalisation step has a great impact on the performance of the developed models. conclusions we demonstrate that normalisation of the semi-structured contents can improve the mae among all cnn configurations. without advanced feature engineering, cnn-based approaches can provide a comparable solution for classifying positive valence symptom severity in initial psychiatric evaluation records. although word embedding is well known for its ability to capture relatively low-dimensional similarity between words, our experimental results show that pre-trained embeddings do not improve the classification performance. this phenomenon may be due to the inability of word embeddings to capture problem specific contextual semantic information implying the quality of the employing embedding is critical for obtaining an accurate cnn model.",
            "contribution_ids": [
                "R138806"
            ]
        },
        {
            "instance_id": "R139050xR139004",
            "comparison_id": "R139050",
            "paper_id": "R139004",
            "text": "Characterisation of mental health conditions in social media using Informed Deep Learning abstract \\n the number of people affected by mental illness is on the increase and with it the burden on health and social care use, as well as the loss of both productivity and quality-adjusted life-years. natural language processing of electronic health records is increasingly used to study mental health conditions and risk behaviours on a large scale. however, narrative notes written by clinicians do not capture first-hand the patients\u2019 own experiences, and only record cross-sectional, professional impressions at the point of care. social media platforms have become a source of \u2018in the moment\u2019 daily exchange, with topics including well-being and mental health. in this study, we analysed posts from the social media platform reddit and developed classifiers to recognise and classify posts related to mental illness according to 11 disorder themes. using a neural network and deep learning approach, we could automatically recognise mental illness-related posts in our balenced dataset with an accuracy of 91.08% and select the correct theme with a weighted average accuracy of 71.37%. we believe that these results are a first step in developing methods to characterise large amounts of user-generated content that could support content curation and targeted interventions.",
            "contribution_ids": [
                "R139006"
            ]
        },
        {
            "instance_id": "R139050xR139047",
            "comparison_id": "R139050",
            "paper_id": "R139047",
            "text": "Question Answering for Suicide Risk Assessment Using Reddit mental health america designed ten questionnaires that are used to determine the risk of mental disorders. they are also commonly used by mental health professionals (mhps) to assess suicidality. specifically, the columbia suicide severity rating scale (c-ssrs), a widely used suicide assessment questionnaire, helps mhps determine the severity of suicide risk and offer an appropriate treatment. a major challenge in suicide treatment is the social stigma wherein the patient feels reluctance in discussing his/her conditions with an mhp, which leads to inaccurate assessment and treatment of patients. on the other hand, the same patient is comfortable freely discussing his/her mental health condition on social media due to the anonymity of platforms such as reddit, and the ability to control what, when and how to share. the popular \u201csuicidewatch\u201d subreddit has been widely used among individuals who experience suicidal thoughts, and provides significant cues for suicidality. the timeliness in sharing thoughts, the flexibility in describing feelings, and the interoperability in using medical terminologies make reddit an important platform to be utilized as a complementary tool to the conventional healthcare system. as mhps develop an implicit weighting scheme over the questionnaire (i.e., c-ssrs) to assess suicide risk severity, creating a relative weighting scheme for answers to be automatically generated to the questions in the questionnaire poses as a key challenge. in this interdisciplinary study, we position our approach towards a solution for an automated suicide risk-elicitation framework through a novel question answering mechanism. our two-fold approach benefits from using: 1) semantic clustering, and 2) sequence-to-sequence (seq2seq) models. we also generate a gold standard dataset of suicide posts with their risk levels. this work forms a basis for the next step of building conversational agents that elicit suicide-related natural conversation based on questions.",
            "contribution_ids": [
                "R139049"
            ]
        },
        {
            "instance_id": "R139050xR138974",
            "comparison_id": "R139050",
            "paper_id": "R138974",
            "text": "Depression Severity Classification from Speech Emotion major depressive disorder (mdd) is a common psychiatric illness. automatically classifying depression severity using audio analysis can help clinical management decisions during deep brain stimulation (dbs) treatment of mdd patients. leveraging the link between short-term emotions and long-term depressed mood states, we build our predictive model on the top of emotion-based features. because acquiring emotion labels of mdd patients is a challenging task, we propose to use an auxiliary emotion dataset to train a deep neural network (dnn) model. the dnn is then applied to audio recordings of mdd patients to find their low dimensional representation to be used in the classification algorithm. our preliminary results indicate that the proposed approach, in comparison to the alternatives, effectively classifies depressed and improved phases of dbs treatment with an auc of 0.80.",
            "contribution_ids": [
                "R138976"
            ]
        },
        {
            "instance_id": "R139050xR138959",
            "comparison_id": "R139050",
            "paper_id": "R138959",
            "text": "Automated Depression Diagnosis Based on Deep Networks to Encode Facial Appearance and Dynamics as a severe psychiatric disorder disease, depression is a state of low mood and aversion to activity, which prevents a person from functioning normally in both work and daily lives. the study on automated mental health assessment has been given increasing attentions in recent years. in this paper, we study the problem of automatic diagnosis of depression. a new approach to predict the beck depression inventory ii (bdi-ii) values from video data is proposed based on the deep networks. the proposed framework is designed in a two stream manner, aiming at capturing both the facial appearance and dynamics. further, we employ joint tuning layers that can implicitly integrate the appearance and dynamic information. experiments are conducted on two depression databases, avec2013 and avec2014. the experimental results show that our proposed approach significantly improve the depression prediction performance, compared to other visual-based approaches.",
            "contribution_ids": [
                "R138962"
            ]
        },
        {
            "instance_id": "R139050xR138710",
            "comparison_id": "R139050",
            "paper_id": "R138710",
            "text": "A general prediction model for the detection of ADHD and Autism using structural and functional MRI this work presents a novel method for learning a model that can diagnose attention deficit hyperactivity disorder (adhd), as well as autism, using structural texture and functional connectivity features obtained from 3-dimensional structural magnetic resonance imaging (mri) and 4-dimensional resting-state functional magnetic resonance imaging (fmri) scans of subjects. we explore a series of three learners: (1) the lefms learner first extracts features from the structural mri images using the texture-based filters produced by a sparse autoencoder. these filters are then convolved with the original mri image using an unsupervised convolutional network. the resulting features are used as input to a linear support vector machine (svm) classifier. (2) the lefmf learner produces a diagnostic model by first computing spatial non-stationary independent components of the fmri scans, which it uses to decompose each subject\u2019s fmri scan into the time courses of these common spatial components. these features can then be used with a learner by themselves or in combination with other features to produce the model. regardless of which approach is used, the final set of features are input to a linear support vector machine (svm) classifier. (3) finally, the overall lefmsf learner uses the combined features obtained from the two feature extraction processes in (1) and (2) above as input to an svm classifier, achieving an accuracy of 0.673 on the adhd-200 holdout data and 0.643 on the abide holdout data. both of these results, obtained with the same lefmsf framework, are the best known, over all hold-out accuracies on these datasets when only using imaging data\u2014exceeding previously-published results by 0.012 for adhd and 0.042 for autism. our results show that combining multi-modal features can yield good classification accuracy for diagnosis of adhd and autism, which is an important step towards computer-aided diagnosis of these psychiatric diseases and perhaps others as well.",
            "contribution_ids": [
                "R138713"
            ]
        },
        {
            "instance_id": "R139050xR138814",
            "comparison_id": "R139050",
            "paper_id": "R138814",
            "text": "A deep learning based scoring system for prioritizing susceptibility variants for mental disorders many rare and common genetic variants, including snps and cnvs, are reported to be associated with mental disorders, yet more remain to be discovered. however, despite the large amount of high-throughput genomics data, there is a lack of integrative methods to systematically prioritize variants that confer susceptibility to mental disorders in personal genomes. here, we developed a computational tool: a deep learning based scoring system (ncdeepbrain) to analyze whole genome/exome sequencing data on personal genomes by integrating contributions from coding, non-coding, structural variants, known brain expression quantitative trait locus (eqtls), and enhancer/promoter peaks from psychencode. the input is whole-genome variants and the output is prioritized list of variants that may be of relevance to the phenotypes. for population studies, our method can help prioritize novel variants that are associated with disease susceptibility; for individual patients, our method can help identify variants with major effect sizes for mental disorders.",
            "contribution_ids": [
                "R138816"
            ]
        },
        {
            "instance_id": "R139190xR139071",
            "comparison_id": "R139190",
            "paper_id": "R139071",
            "text": "On the Vacuum Ultraviolet Radiation of a Miniaturized Non-thermal Atmospheric Pressure Plasma Jet the suitability of a miniaturized non-thermal appj operating with ar at ambient atmosphere for applications related to surface treatment is demonstrated. the vuv emission is measured and the dependence of selected line intensities over the radius of the plasma jet is presented. the ar discharge is characterized by an intense vuv radiation, attributed to n, h, and o atomic lines along with an ar2* excimer continuum, which is drastically reduced after adding up to 5% n2 to the ar working gas. two absorption dips are found in the vuv spectrum. the surface energy enhancement of substrates at temperatures as low as 35\\u2009\u00b0c along with chemical reactivity originating from abundant no and oh free radicals and uv/vuv radiation in the plasma give rise to numerous applications, e.g., in the medical and biological field.",
            "contribution_ids": [
                "R139167"
            ]
        },
        {
            "instance_id": "R139190xR139068",
            "comparison_id": "R139190",
            "paper_id": "R139068",
            "text": "An atmospheric pressure plasma source an atmospheric pressure plasma source operated by radio frequency power has been developed. this source produces a unique discharge that is volumetric and homogeneous at atmospheric pressure with a gas temperature below 300\\u200a\u00b0c. it also produces a large quantity of oxygen atoms, \u223c5\u00d71015\\u200acm\u22123, which has important value for materials applications. a theoretical model shows electron densities of 0.2\u20132\u00d71011\\u200acm\u22123 and characteristic electron energies of 2\u20134 ev for helium discharges at a power level of 3\u201330 w\\u200acm\u22123.",
            "contribution_ids": [
                "R139166"
            ]
        },
        {
            "instance_id": "R139190xR139074",
            "comparison_id": "R139190",
            "paper_id": "R139074",
            "text": "RF Capillary Jet - a Tool for Localized Surface Treatment the uv/vuv spectrum of a non\u2010thermal capillary plasma jet operating with ar at ambient atmosphere and the temperature load of a substrate exposed to the jet have been measured. the vuv radiation is assigned to n, h, and o atomic lines along with an ar*2 excimer continuum. the absolute radiance (115\u2010200 nm) of the source has been determined. maximum values of 880 \u03bcw/mm2sr are obtained. substrate temperatures range between 35 \u00b0c for low powers and high gas flow conditions and 95 \u00b0c for high powers and reduced gas flow. the plasma source (13.56, 27.12 or 40.78 mhz) can be operated in ar and in n2. the further addition of a low percentage of silicon containing reactive admixtures has been demonstrated for thin film deposition. several further applications related to surface modification have been successfully applied. (\u00a9 2007 wiley\u2010vch verlag gmbh & co. kgaa, weinheim)",
            "contribution_ids": [
                "R139076",
                "R139142",
                "R139168"
            ]
        },
        {
            "instance_id": "R139190xR139115",
            "comparison_id": "R139190",
            "paper_id": "R139115",
            "text": "Chemical kinetics in an atmospheric pressure helium plasma containing humidity investigating the formation and kinetics of o and oh in a he\u2013h 2 o plasma jet using absorption spectroscopy and 0d modelling.",
            "contribution_ids": [
                "R139182"
            ]
        },
        {
            "instance_id": "R139190xR139083",
            "comparison_id": "R139190",
            "paper_id": "R139083",
            "text": "Vacuum UV Radiation of a Plasma Jet Operated With Rare Gases at Atmospheric Pressure the vacuum ultraviolet (vuv) emissions from 115 to 200 nm from the effluent of an rf (1.2 mhz) capillary jet fed with pure argon and binary mixtures of argon and xenon or krypton (up to 20%) are analyzed. the feed gas mixture is emanating into air at normal pressure. the ar2 excimer second continuum, observed in the region of 120-135 nm, prevails in the pure ar discharge. it decreases when small amounts (as low as 0.5%) of xe or kr are added. in that case, the resonant emission of xe at 147 nm (or 124 nm for kr, respectively) becomes dominant. the xe2 second continuum at 172 nm appears for higher admixtures of xe (10%). furthermore, several n i emission lines, the o i resonance line, and h i line appear due to ambient air. two absorption bands (120.6 and 124.6 nm) are present in the spectra. their origin could be unequivocally associated to o2 and o3. the radiance is determined end-on at varying axial distance in absolute units for various mixtures of ar/xe and ar/kr and compared to pure ar. integration over the entire vuv wavelength region provides the integrated spectral distribution. maximum values of 2.2 mw middotmm-2middotsr-1 are attained in pure ar and at a distance of 4 mm from the outlet nozzle of the discharge. by adding diminutive admixtures of kr or xe, the intensity and spectral distribution is effectively changed.",
            "contribution_ids": [
                "R139171"
            ]
        },
        {
            "instance_id": "R139190xR139103",
            "comparison_id": "R139190",
            "paper_id": "R139103",
            "text": "Summarizing results on the performance of a selective set of atmospheric plasma jets for separation of photons and reactive particles a microscale atmospheric-pressure plasma jet is a remote plasma jet, where plasma-generated reactive particles and photons are involved in substrate treatment. here, we summarize our efforts to develop and characterize a particle- or photon-selective set of otherwise identical jets. in that way, the reactive species or photons can be used separately or in combination to study their isolated or combined effects to test whether the effects are additive or synergistic. the final version of the set of three jets\u2014particle-jet, photon-jet and combined jet\u2014is introduced. this final set realizes the highest reproducibility of the photon and particle fluxes, avoids turbulent gas flow, and the fluxes of the selected plasma-emitted components are almost identical in the case of all jets, while the other component is effectively blocked, which was verified by optical emission spectroscopy and mass spectrometry. schlieren-imaging and a fluid dynamics simulation show the stability of the gas flow. the performance of these selective jets is demonstrated with the example of the treatment of e. coli bacteria with the different components emitted by a he-only, a he/n2 and a he/o2 plasma. additionally, measurements of the vacuum uv photon spectra down to the wavelength of 50\\u2009nm can be made with the photon-jet and the relative comparison of spectral intensities among different gas mixtures is reported here. the results will show that the vacuum uv photons can lead to the inactivation of the e.coli bacteria.",
            "contribution_ids": [
                "R139178"
            ]
        },
        {
            "instance_id": "R139190xR139112",
            "comparison_id": "R139190",
            "paper_id": "R139112",
            "text": "Absolute ozone densities in a radio-frequency driven atmospheric pressure plasma using two-beam UV-LED absorption spectroscopy and numerical simulations the efficient generation of reactive oxygen species (ros) in cold atmospheric pressure plasma jets (appjs) is an increasingly important topic, e.g. for the treatment of temperature sensitive biological samples in the field of plasma medicine. a 13.56 mhz radio-frequency (rf) driven appj device operated with helium feed gas and small admixtures of oxygen (up to 1%), generating a homogeneous glow-mode plasma at low gas temperatures, was investigated. absolute densities of ozone, one of the most prominent ros, were measured across the 11 mm wide discharge channel by means of broadband absorption spectroscopy using the hartley band centred at \u03bb = 255 nm. a two-beam setup with a reference beam in mach\u2013zehnder configuration is employed for improved signal-to-noise ratio allowing high-sensitivity measurements in the investigated single-pass weak-absorbance regime. the results are correlated to gas temperature measurements, deduced from the rotational temperature of the n2 (c 3 \u03c0 u + \u2192 b 3 \u03c0 g + , \u03c5 = 0 \u2192 2) optical emission from introduced air impurities. the observed opposing trends of both quantities as a function of rf power input and oxygen admixture are analysed and explained in terms of a zero-dimensional plasma-chemical kinetics simulation. it is found that the gas temperature as well as the densities of o and o2(b 1 \u03c3 g + ) influence the absolute o3 densities when the rf power is varied.",
            "contribution_ids": [
                "R139181"
            ]
        },
        {
            "instance_id": "R139190xR139132",
            "comparison_id": "R139190",
            "paper_id": "R139132",
            "text": "Characterization of an RF-driven argon plasma at atmospheric pressure using broadband absorption and optical emission spectroscopy atmospheric pressure plasmas in argon are of particular interest due to the production of highly excited and reactive species enabling numerous plasma-aided applications. in this contribution, we report on absolute optical emission and absorption spectroscopy of a radio frequency (rf) driven capacitively coupled argon glow discharge operated in a parallel-plate configuration. this enabled the study of all key parameters including electron density and temperature, gas temperature, and absolute densities of atoms in highly electronically excited states. space and time-averaged electron density and temperature were determined from the measurement of the absolute intensity of the electron-atom bremsstrahlung in the visible range. considering the non-maxwellian electron energy distribution function, an electron temperature ( t e) of 2.1\\u2009ev and an electron density ( n e) of 1.1 \u00d7 10 19 m \u2212 3 were obtained. the time-averaged and spatially resolved absolute densities of atoms in the metastable ( 1 s 5 and 1 s 3) and resonant ( 1 s 4 and 1 s 2) states of argon in the pure ar and ar/he mixture were obtained by broadband absorption spectroscopy. the 1 s 5 metastable atoms had the largest density near the sheath region with a maximum value of 8 \u00d7 10 17 m \u2212 3, while all other 1s states had densities of at most 2 \u00d7 10 17 m \u2212 3. the dominant production and loss mechanisms of these atoms were discussed, in particular, the role of radiation trapping. we conclude with comparison of the plasma properties of the argon rf glow discharges with the more common he equivalent and highlight their differences.",
            "contribution_ids": [
                "R139188"
            ]
        },
        {
            "instance_id": "R139190xR139109",
            "comparison_id": "R139190",
            "paper_id": "R139109",
            "text": "Cold Atmospheric Pressure Plasma VUV Interactions With Surfaces: Effect of Local Gas Environment and Source Design this study uses photoresist materials in combination with several optical filters as a diagnostic to examine the relative importance of vuv-induced surface modifications for different cold atmospheric pressure plasma (capp) sources. the argon fed khz-driven ring-appj showed the largest ratio of vuv surface modification relative to the total modification introduced, whereas the mhz appj showed the largest overall surface modification. the mhz appj shows increased total thickness reduction and reduced vuv effect as oxygen is added to the feed gas, a condition that is often used for practical applications. we examine the influence of noble gas flow from the appj on the local environment. the local environment has a decisive impact on polymer modification from vuv emission as o2 readily absorbs vuv photons.",
            "contribution_ids": [
                "R139180"
            ]
        },
        {
            "instance_id": "R139190xR139100",
            "comparison_id": "R139190",
            "paper_id": "R139100",
            "text": "Impact of plasma jet vacuum ultraviolet radiation on reactive oxygen species generation in bio-relevant liquids plasma medicine utilizes the combined interaction of plasma produced reactive components. these are reactive atoms, molecules, ions, metastable species, and radiation. here, ultraviolet (uv, 100\u2013400\\u2009nm) and, in particular, vacuum ultraviolet (vuv, 10\u2013200\\u2009nm) radiation generated by an atmospheric pressure argon plasma jet were investigated regarding plasma emission, absorption in a humidified atmosphere and in solutions relevant for plasma medicine. the energy absorption was obtained for simple solutions like distilled water (dh2o) or ultrapure water and sodium chloride (nacl) solution as well as for more complex ones, for example, rosewell park memorial institute (rpmi 1640) cell culture media. as moderate stable reactive oxygen species, hydrogen peroxide (h2o2) was studied. highly reactive oxygen radicals, namely, superoxide anion (o2\u2022\u2212) and hydroxyl radicals (\u2022oh), were investigated by the use of electron paramagnetic resonance spectroscopy. all species amounts were detected for three different treatmen...",
            "contribution_ids": [
                "R139177"
            ]
        },
        {
            "instance_id": "R139190xR139130",
            "comparison_id": "R139190",
            "paper_id": "R139130",
            "text": "Atmospheric plasma VUV photon emission owing to its distinctive photon energy range, vacuum ultraviolet (vuv) emission plays a key role in diverse photo-induced natural and technological processes. atmospheric-pressure plasma produced vuv is central to resolve long-held issues in dynamics of natural (e.g., lightning) and laboratory (e.g., streamer) plasmas. challenging the seemingly unavoidable vacuum systems used to prevent vuv emission quenching by ambient gases, here we report the first observation of vacuum-free generation of stable sub-110 nm vuv emission from atmospheric-pressure plasmas jetted into open air and atmospheric air plasma. emission from atomic helium at 58.4 nm is observed from a nonequilibrium atmospheric pressure plasma jet (n-appj), jetted directly into ambient air. in a similar experiment, we also report vuv emission from excited nitrogen species in an atmospheric pressure discharge in ambient air. the photon emissions detected expand the window of photo-induced processes beyond \u223c10 ev commonly achievable by existing non-excimer vuv plasma sources, and enables direct photo-excitation and ionization of molecular species such as co2 and many others. the thus-enabled direct photoionization of o2, o, and n species further justifies the role of direct photoionization in the dynamics of natural and laboratory atmospheric-pressure plasmas and informs the development of the relevant plasma photoionization models, which currently largely sidestep the sub-110 nm domain. these findings can make contribution to the complement of photoionization model of lightning, streamer, and other plasmas, open new avenues to quantify the yet elusive role of photoionization in the plasma dynamics.",
            "contribution_ids": [
                "R139187"
            ]
        },
        {
            "instance_id": "R139190xR139094",
            "comparison_id": "R139190",
            "paper_id": "R139094",
            "text": "Characterization of transient discharges under atmospheric-pressure conditions applying nitrogen photoemission and current measurements the plasma parameters such as electron distribution function and electron density of three atmospheric-pressure transient discharges namely filamentary and homogeneous dielectric barrier discharges in air, and the spark discharge of an argon plasma coagulation (apc) system are determined. a combination of numerical simulation as well as diagnostic methods including current measurement and optical emission spectroscopy (oes) based on nitrogen emissions is used. the applied methods supplement each other and resolve problems, which arise when these methods are used individually. nitrogen is used as a sensor gas and is admixed in low amount to argon for characterizing the apc discharge. both direct and stepwise electron-impact excitation of nitrogen emissions are included in the plasma-chemical model applied for characterization of these transient discharges using oes where ambiguity arises in the determination of plasma parameters under specific discharge conditions. it is shown that the measured current solves this problem by providing additional information useful for the determination of discharge-specific plasma parameters.",
            "contribution_ids": [
                "R139175"
            ]
        },
        {
            "instance_id": "R139190xR139124",
            "comparison_id": "R139190",
            "paper_id": "R139124",
            "text": "Comparison of electron heating and energy loss mechanisms in an RF plasma jet operated in argon and helium the \u03bc-appj is a well-investigated atmospheric pressure rf plasma jet. up to now, it has mainly been operated using helium as feed gas due to stability restrictions. however, the cost-jet design including precise electrical probes now offers the stability and reproducibility to create equi-operational plasmas in helium as well as in argon. in this publication, we compare fundamental plasma parameters and physical processes inside the cost reference microplasma jet, a capacitively coupled rf atmospheric pressure plasma jet, under operation in argon and in helium. differences already observable by the naked eye are reflected in differences in the power-voltage characteristic for both gases. using an electrical model and a power balance, we calculated the electron density and temperature at 0.6 w to be 9 \u00d7 10 17 m \u2212 3 , 1.2 ev and 7.8 \u00d7 10 16 m \u2212 3 , 1.7 ev for argon and helium, respectively. in case of helium, a considerable part of the discharge power is dissipated in elastic electron-atom collisions, while for argon most of the input power is used for ionization. phase-resolved optical emission spectroscopy reveals differently pronounced heating mechanisms. whereas bulk heating is more prominent in argon compared to helium, the opposite trend is observed for sheath heating. this also explains the different behavior observed in the power-voltage characteristics.",
            "contribution_ids": [
                "R139185"
            ]
        },
        {
            "instance_id": "R139190xR139097",
            "comparison_id": "R139190",
            "paper_id": "R139097",
            "text": "Absolute atomic oxygen and nitrogen densities in radio-frequency driven atmospheric pressure cold plasmas: Synchrotron vacuum ultra-violet high-resolution Fourier-transform absorption measurements reactive atomic species play a key role in emerging cold atmospheric pressure plasma applications, in particular, in plasma medicine. absolute densities of atomic oxygen and atomic nitrogen were measured in a radio-frequency driven non-equilibrium plasma operated at atmospheric pressure using vacuum ultra-violet (vuv) absorption spectroscopy. the experiment was conducted on the desirs synchrotron beamline using a unique vuv fourier-transform spectrometer. measurements were carried out in plasmas operated in helium with air-like n2/o2 (4:1) admixtures. a maximum in the o-atom concentration of (9.1\\u2009\u00b1\\u20090.7)\u00d71020\\u2009m\u22123 was found at admixtures of 0.35\\u2009vol.\\u2009%, while the n-atom concentration exhibits a maximum of (5.7\\u2009\u00b1\\u20090.4)\u00d71019\\u2009m\u22123 at 0.1\\u2009vol.\\u2009%.",
            "contribution_ids": [
                "R139176"
            ]
        },
        {
            "instance_id": "R139190xR139065",
            "comparison_id": "R139190",
            "paper_id": "R139065",
            "text": "Etching materials with an atmospheric-pressure plasma jet a plasma jet has been developed for etching materials at atmospheric pressure and between 100 and c. gas mixtures containing helium, oxygen and carbon tetrafluoride were passed between an outer, grounded electrode and a centre electrode, which was driven by 13.56 mhz radio frequency power at 50 to 500 w. at a flow rate of , a stable, arc-free discharge was produced. this discharge extended out through a nozzle at the end of the electrodes, forming a plasma jet. materials placed 0.5 cm downstream from the nozzle were etched at the following maximum rates: for kapton ( and he only), for silicon dioxide, for tantalum and for tungsten. optical emission spectroscopy was used to identify the electronically excited species inside the plasma and outside in the jet effluent.",
            "contribution_ids": [
                "R139165"
            ]
        },
        {
            "instance_id": "R139526xR139484",
            "comparison_id": "R139526",
            "paper_id": "R139484",
            "text": "Production scheduling in a knitted fabric dyeing and finishing process abstract developing detailed production schedules for dyeing and finishing operations is a very difficult task that has received relatively little attention in the literature. in this paper, a scheduling procedure is presented for a knitted fabric dyeing and finishing plant that is essentially a flexible job shop with sequence-dependent setups. an existing job shop scheduling algorithm is modified to take into account the complexities of the case plant. the resulting approach based on family scheduling is tested on problems generated with case plant characteristics.",
            "contribution_ids": [
                "R139486"
            ]
        },
        {
            "instance_id": "R139526xR139463",
            "comparison_id": "R139526",
            "paper_id": "R139463",
            "text": "Energy management and optimization: case study of a textile plant in Istanbul, Turkey \\n purpose \\n this paper aims to present the results of energy management and optimization studies in one turkish textile factory. in a case study of a print and dye factory in istanbul, the authors identified energy-sensitive processes and proposed energy management applications. \\n \\n \\n design/methodology/approach \\n appropriate energy management methods have been implemented in the factory, and the results were examined in terms of energy efficiency and cost reduction. \\n \\n \\n findings \\n by applying the methods for fuel distribution optimization, the authors demonstrated that energy costs could be decreased by approximately. \\n \\n \\n originality/value \\n energy management is a vital issue for industries particularly in developing countries such as turkey. turkey is an energy poor country and imports more than half of its energy to satisfy its increasing domestic demands. an important share of these demands stems from the presence of a strong textile industry that operates throughout the country. \\n",
            "contribution_ids": [
                "R139465"
            ]
        },
        {
            "instance_id": "R139526xR139487",
            "comparison_id": "R139526",
            "paper_id": "R139487",
            "text": "Scheduling with multi-attribute set-up times on unrelated parallel machines this paper studies a problem in the knitting process of the textile industry. in such a production system, each job has a number of attributes and each attribute has one or more levels. because there is at least one different attribute level between two adjacent jobs, it is necessary to make a set-up adjustment whenever there is a switch to a different job. the problem can be formulated as a scheduling problem with multi-attribute set-up times on unrelated parallel machines. the objective of the problem is to assign jobs to different machines to minimise the makespan. a constructive heuristic is developed to obtain a qualified solution. to improve the solution further, a meta-heuristic that uses a genetic algorithm with a new crossover operator and three local searches are proposed. the computational experiments show that the proposed constructive heuristic outperforms two existed heuristics and the current scheduling method used by the case textile plant.",
            "contribution_ids": [
                "R139489"
            ]
        },
        {
            "instance_id": "R139551xR139538",
            "comparison_id": "R139551",
            "paper_id": "R139538",
            "text": "High resolution DNA barcode library for European butterflies reveals continental patterns of mitochondrial genetic diversity abstract the study of global biodiversity will greatly benefit from access to comprehensive dna barcode libraries at continental scale, but such datasets are still very rare. here, we assemble the first high-resolution reference library for european butterflies that provides 97% taxon coverage (459 species) and 22,306 coi sequences. we estimate that we captured 62% of the total haplotype diversity and show that most species possess a few very common haplotypes and many rare ones. specimens in the dataset have an average 95.3% probability of being correctly identified. mitochondrial diversity displayed elevated haplotype richness in southern european refugia, establishing the generality of this key biogeographic pattern for an entire taxonomic group. fifteen percent of the species are involved in barcode sharing, but two thirds of these cases may reflect the need for further taxonomic research. this dataset provides a unique resource for conservation and for studying evolutionary processes, cryptic species, phylogeography, and ecology.",
            "contribution_ids": [
                "R139543",
                "R156950"
            ]
        },
        {
            "instance_id": "R139551xR108983",
            "comparison_id": "R139551",
            "paper_id": "R108983",
            "text": "Barcoding the butterflies of southern South America: Species delimitation efficacy, cryptic diversity and geographic patterns of divergence because the tropical regions of america harbor the highest concentration of butterfly species, its fauna has attracted considerable attention. much less is known about the butterflies of southern south america, particularly argentina, where over 1,200 species occur. to advance understanding of this fauna, we assembled a dna barcode reference library for 417 butterfly species of argentina, focusing on the atlantic forest, a biodiversity hotspot. we tested the efficacy of this library for specimen identification, used it to assess the frequency of cryptic species, and examined geographic patterns of genetic variation, making this study the first large-scale genetic assessment of the butterflies of southern south america. the average sequence divergence to the nearest neighbor (i.e. minimum interspecific distance) was 6.91%, ten times larger than the mean distance to the furthest conspecific (0.69%), with a clear barcode gap present in all but four of the species represented by two or more specimens. as a consequence, the dna barcode library was extremely effective in the discrimination of these species, allowing a correct identification in more than 95% of the cases. singletons (i.e. species represented by a single sequence) were also distinguishable in the gene trees since they all had unique dna barcodes, divergent from those of the closest non-conspecific. the clustering algorithms implemented recognized from 416 to 444 barcode clusters, suggesting that the actual diversity of butterflies in argentina is 3%\u20139% higher than currently recognized. furthermore, our survey added three new records of butterflies for the country (eurema agave, mithras hannelore, melanis hillapana). in summary, this study not only supported the utility of dna barcoding for the identification of the butterfly species of argentina, but also highlighted several cases of both deep intraspecific and shallow interspecific divergence that should be studied in more detail.",
            "contribution_ids": [
                "R157025",
                "R108986"
            ]
        },
        {
            "instance_id": "R139551xR108960",
            "comparison_id": "R139551",
            "paper_id": "R108960",
            "text": "Use of species delimitation approaches to tackle the cryptic diversity of an assemblage of high Andean butterflies (Lepidoptera: Papilionoidea) cryptic biological diversity has generated ambiguity in taxonomic and evolutionary studies. single-locus methods and other approaches for species delimitation are useful for addressing this challenge, enabling the practical processing of large numbers of samples for identification and inventory purposes. this study analyzed an assemblage of high andean butterflies using dna barcoding and compared the identifications based on the current morphological taxonomy with three methods of species delimitation (automatic barcode gap discovery, generalized mixed yule coalescent model, and poisson tree processes). sixteen potential cryptic species were recognized using these three methods, representing a net richness increase of 11.3% in the assemblage. a well-studied taxon of the genus vanessa, which has a wide geographical distribution, appeared with the potential cryptic species that had a higher genetic differentiation at the local level than at the continental level. the analyses were useful for identifying the potential cryptic species in pedaliodes and forsterinaria complexes, which also show differentiation along altitudinal and latitudinal gradients. this genetic assessment of an entire assemblage of high andean butterflies (papilionoidea) provides baseline information for future research in a region characterized by high rates of endemism and population isolation.",
            "contribution_ids": [
                "R157029",
                "R108962"
            ]
        },
        {
            "instance_id": "R139551xR139497",
            "comparison_id": "R139551",
            "paper_id": "R139497",
            "text": "Congruence between morphology-based species and Barcode Index Numbers (BINs) in Neotropical Eumaeini (Lycaenidae) \\n background \\n with about 1,000 species in the neotropics, the eumaeini (theclinae) are one of the most diverse butterfly tribes. correct morphology-based identifications are challenging in many genera due to relatively little interspecific differences in wing patterns. geographic infraspecific variation is sometimes more substantial than variation between species. in this paper we present a large dna barcode dataset of south american lycaenidae. we analyze how well dna barcode bins match morphologically delimited species. \\n \\n \\n methods \\n we compare morphology-based species identifications with the clustering of molecular operational taxonomic units (motus) delimitated by the resl algorithm in bold, which assigns barcode index numbers (bins). we examine intra- and interspecific divergences for genera represented by at least four morphospecies. we discuss the existence of local barcode gaps in a genus by genus analysis. we also note differences in the percentage of species with barcode gaps in groups of lowland and high mountain genera. \\n \\n \\n results \\n we identified 2,213 specimens and obtained 1,839 sequences of 512 species in 90 genera. overall, the mean intraspecific divergence value of co1 sequences was 1.20%, while the mean interspecific divergence between nearest congeneric neighbors was 4.89%, demonstrating the presence of a barcode gap. however, the gap seemed to disappear from the entire set when comparing the maximum intraspecific distance (8.40%) with the minimum interspecific distance (0.40%). clear barcode gaps are present in many genera but absent in others. from the set of specimens that yielded coi fragment lengths of at least 650 bp, 75% of the a priori morphology-based identifications were unambiguously assigned to a single barcode index number (bin). however, after a taxonomic a posteriori review, the percentage of matched identifications rose to 85%. bin splitting was observed for 17% of the species and bin sharing for 9%. we found that genera that contain primarily lowland species show higher percentages of local barcode gaps and congruence between bins and morphology than genera that contain exclusively high montane species. the divergence values to the nearest neighbors were significantly lower in high andean species while the intra-specific divergence values were significantly lower in the lowland species. these results raise questions regarding the causes of observed low inter and high intraspecific genetic variation. we discuss incomplete lineage sorting and hybridization as most likely causes of this phenomenon, as the montane species concerned are relatively young and hybridization is probable. the release of our data set represents an essential baseline for a reference library for biological assessment studies of butterflies in mega diverse countries using modern high-throughput technologies an highlights the necessity of taxonomic revisions for various genera combining both molecular and morphological data. \\n",
            "contribution_ids": [
                "R139502",
                "R156958"
            ]
        },
        {
            "instance_id": "R139551xR136193",
            "comparison_id": "R139551",
            "paper_id": "R136193",
            "text": "Complete DNA barcode reference library for a country's butterfly fauna reveals high performance for temperate Europe dna barcoding aims to accelerate species identification and discovery, but performance tests have shown marked differences in identification success. as a consequence, there remains a great need for comprehensive studies which objectively test the method in groups with a solid taxonomic framework. this study focuses on the 180 species of butterflies in romania, accounting for about one third of the european butterfly fauna. this country includes five eco-regions, the highest of any in the european union, and is a good representative for temperate areas. morphology and dna barcodes of more than 1300 specimens were carefully studied and compared. our results indicate that 90 per cent of the species form barcode clusters allowing their reliable identification. the remaining cases involve nine closely related species pairs, some whose taxonomic status is controversial or that hybridize regularly. interestingly, dna barcoding was found to be the most effective identification tool, outperforming external morphology, and being slightly better than male genitalia. romania is now the first country to have a comprehensive dna barcode reference database for butterflies. similar barcoding efforts based on comprehensive sampling of specific geographical regions can act as functional modules that will foster the early application of dna barcoding while a global system is under development.",
            "contribution_ids": [
                "R157016",
                "R136195"
            ]
        },
        {
            "instance_id": "R139567xR138300",
            "comparison_id": "R139567",
            "paper_id": "R138300",
            "text": "Bridging the Gap between Citizens and Local Administrations with Knowledge-Based Service Bundle Recommendations the italian public administration services (ipas) is a registry of services provided to italian citizens likewise the local government service list (uk), or the european service list for local authorities from other nations. unlike existing registries, ipas presents the novelty of modelling public services from the view point of the value they have for the consumers and the providers. a value-added-service (vas) is linked to a life event that requires its fruition, addresses consumer categories to identify market opportunities for private providers, and is described by non-functional-properties such as price and time of fruition. where italian local authorities leave the citizen-users in a daedalus of references to understand whether they can/have to apply for a service, the ipas model captures the necessary back-ground knowledge about the connection between administrative legislation and service specifications, life events, and application contexts to support the citizen-users to fulfill their needs. as a proof of concept, we developed an operational web environment named asso, designed to assist the citizen-user to intuitively create bundles of mandatory-by-legislation and recommended services, to accomplish his bureaucratic fulfillments. although asso is an ongoing project, domain experts gave preliminary positive feedback on the innovativeness and effectiveness of the proposed approach.",
            "contribution_ids": [
                "R138302"
            ]
        },
        {
            "instance_id": "R139567xR139313",
            "comparison_id": "R139567",
            "paper_id": "R139313",
            "text": "A hybrid Semantic driven recommender for services in the eGovernment domain in its way towards the maturity of egovernment solutions a number of paths are being explored. among them, one of the not fully explored mechanisms are the use of social features for a better provisioning of domain services. this paper explores how to provide support for the discovery of services from public administrations using folksonomies. taking advantage of these, authors develop a social site and they provide a complete mechanism to recommend new services to users using techniques from cf and cbf recommenders. also, some conclusions are presented to enlighten future practitioners and researchers.",
            "contribution_ids": [
                "R139315"
            ]
        },
        {
            "instance_id": "R139567xR139300",
            "comparison_id": "R139567",
            "paper_id": "R139300",
            "text": "Personalized recommendations in e-participation: offline experiments for the 'Decide Madrid' platform \"in e-participation platforms, citizens suggest, discuss and vote online for initiatives aimed to address a wide range of issues and problems in a city, such as economic development, public safety, budges, infrastructure, housing, environment, social rights, and health care. for a particular citizen, the number of proposals and debates may be overwhelming, and recommender systems could help filtering and ranking those that are more relevant. focusing on a particular case, the `decide madrid' platform, in this paper we empirically investigate which sources of user preferences and recommendation approaches could be more effective, in terms of several aspects, namely precision, coverage and diversity.\"",
            "contribution_ids": [
                "R139302"
            ]
        },
        {
            "instance_id": "R139585xR76567",
            "comparison_id": "R139585",
            "paper_id": "R76567",
            "text": "Individual differences and changes in subjective wellbeing during the early stages of the COVID-19 pandemic. \"the covid-19 pandemic has considerably impacted many people's lives. this study examined changes in subjective wellbeing between december 2019 and may 2020 and how stress appraisals and coping strategies relate to individual differences and changes in subjective wellbeing during the early stages of the pandemic. data were collected at 4 time points from 979 individuals in germany. results showed that, on average, life satisfaction, positive affect, and negative affect did not change significantly between december 2019 and march 2020 but decreased between march and may 2020. across the latter timespan, individual differences in life satisfaction were positively related to controllability appraisals, active coping, and positive reframing, and negatively related to threat and centrality appraisals and planning. positive affect was positively related to challenge and controllable-by-self appraisals, active coping, using emotional support, and religion, and negatively related to threat appraisal and humor. negative affect was positively related to threat and centrality appraisals, denial, substance use, and self-blame, and negatively related to controllability appraisals and emotional support. contrary to expectations, the effects of stress appraisals and coping strategies on changes in subjective wellbeing were small and mostly nonsignificant. these findings imply that the covid-19 pandemic represents not only a major medical and economic crisis, but also has a psychological dimension, as it can be associated with declines in key facets of people's subjective wellbeing. psychological practitioners should address potential declines in subjective wellbeing with their clients and attempt to enhance clients' general capability to use functional stress appraisals and effective coping strategies. (psycinfo database record (c) 2020 apa, all rights reserved).\"",
            "contribution_ids": [
                "R76571"
            ]
        },
        {
            "instance_id": "R139585xR75946",
            "comparison_id": "R139585",
            "paper_id": "R75946",
            "text": "Who is most affected by the Corona crisis? An analysis of changes in stress and well-being in Switzerland abstract this study analyses the consequences of the covid-19 crisis on stress and well-being in switzerland. in particular, we assess whether vulnerable groups in terms of social isolation, increased workload and limited socioeconomic resources are affected more than others. using longitudinal data from the swiss household panel, including a specific covid-19 study, we estimate change score models to predict changes in perceived stress and life satisfaction at the end of the semi-lockdown in comparison to before the crisis. we find no general change in life satisfaction and a small decrease in stress. yet, in line with our expectations, more vulnerable groups in terms of social isolation (young adults, covid-19 risk group members, individuals without a partner), workload (women) and socioeconomic resources (unemployed and those who experienced a deteriorating financial situation) reported a decrease in life satisfaction. stress levels decreased most strongly among high earners, workers on short-time work and the highly educated.",
            "contribution_ids": [
                "R75948",
                "R77084",
                "R77086"
            ]
        },
        {
            "instance_id": "R139585xR76554",
            "comparison_id": "R139585",
            "paper_id": "R76554",
            "text": "The COVID-19 pandemic and subjective well-being: longitudinal evidence on satisfaction with work and family \"abstract this paper provides a timely evaluation of whether the main covid-19 lockdown policies \u2013 remote work, short-time work and closure of schools and childcare \u2013 have an immediate effect on the german population in terms of changes in satisfaction with work and family life. relying on individual level panel data collected before and during the lockdown, we examine (1) how family satisfaction and work satisfaction of individuals have changed over the lockdown period, and (2) how lockdown-driven changes in the labour market situation (i.e. working remotely and being sent on short-time work) have affected satisfactions. we apply first-difference regressions for mothers, fathers, and persons without children. our results show a general decrease in family satisfaction. we also find an overall decline in work satisfaction which is most pronounced for mothers and those without children who have to switch to short-time work. in contrast, fathers' well-being is less affected negatively and their family satisfaction even increased after changing to short-time work. we conclude that while the lockdown circumstances generally have a negative effect on the satisfaction with work and family of individuals in germany, effects differ between childless persons, mothers, and fathers with the latter being least negatively affected.\"",
            "contribution_ids": [
                "R76558",
                "R77087"
            ]
        },
        {
            "instance_id": "R139585xR76559",
            "comparison_id": "R139585",
            "paper_id": "R76559",
            "text": "Socioeconomic status and well-being during COVID-19: A resource-based examination. \"the authors assess levels and within-person changes in psychological well-being (i.e., depressive symptoms and life satisfaction) from before to during the covid-19 pandemic for individuals in the united states, in general and by socioeconomic status (ses). the data is from 2 surveys of 1,143 adults from rand corporation's nationally representative american life panel, the first administered between april-june, 2019 and the second during the initial peak of the pandemic in the united states in april, 2020. depressive symptoms during the pandemic were higher than population norms before the pandemic. depressive symptoms increased from before to during covid-19 and life satisfaction decreased. individuals with higher education experienced a greater increase in depressive symptoms and a greater decrease in life satisfaction from before to during covid-19 in comparison to those with lower education. supplemental analysis illustrates that income had a curvilinear relationship with changes in well-being, such that individuals at the highest levels of income experienced a greater decrease in life satisfaction from before to during covid-19 than individuals with lower levels of income. we draw on conservation of resources theory and the theory of fundamental social causes to examine four key mechanisms (perceived financial resources, perceived control, interpersonal resources, and covid-19-related knowledge/news consumption) underlying the relationship between ses and well-being during covid-19. these resources explained changes in well-being for the sample as a whole but did not provide insight into why individuals of higher education experienced a greater decline in well-being from before to during covid-19. (psycinfo database record (c) 2020 apa, all rights reserved).\"",
            "contribution_ids": [
                "R76566"
            ]
        },
        {
            "instance_id": "R139585xR76542",
            "comparison_id": "R139585",
            "paper_id": "R76542",
            "text": "Up and About: Older Adults\u00e2\u0080\u0099 Well-being During the COVID-19 Pandemic in a Swedish Longitudinal Study abstract \\n \\n objectives \\n to investigate early effects of the covid-19 pandemic related to (a) levels of worry, risk perception, and social distancing; (b) longitudinal effects on well-being; and (c) effects of worry, risk perception, and social distancing on well-being. \\n \\n \\n methods \\n we analyzed annual changes in four aspects of well-being over 5 years (2015\u20132020): life satisfaction, financial satisfaction, self-rated health, and loneliness in a subsample (n = 1,071, aged 65\u201371) from a larger survey of swedish older adults. the 2020 wave, collected march 26\u2013april 2, included measures of worry, risk perception, and social distancing in response to covid-19. \\n \\n \\n results \\n (a) in relation to covid-19: 44.9% worried about health, 69.5% about societal consequences, 25.1% about financial consequences; 86.4% perceived a high societal risk, 42.3% a high risk of infection, and 71.2% reported high levels of social distancing. (b) well-being remained stable (life satisfaction and loneliness) or even increased (self-rated health and financial satisfaction) in 2020 compared to previous years. (c) more worry about health and financial consequences was related to lower scores in all four well-being measures. higher societal worry and more social distancing were related to higher well-being. \\n \\n \\n discussion \\n in the early stage of the pandemic, swedish older adults on average rated their well-being as high as, or even higher than, previous years. however, those who worried more reported lower well-being. our findings speak to the resilience, but also heterogeneity, among older adults during the pandemic. further research, on a broad range of health factors and long-term psychological consequences, is needed. \\n",
            "contribution_ids": [
                "R76545"
            ]
        },
        {
            "instance_id": "R139642xR139632",
            "comparison_id": "R139642",
            "paper_id": "R139632",
            "text": "Fabrication of Efficient Low-Bandgap Perovskite Solar Cells by Combining Formamidinium Tin Iodide with Methylammonium Lead Iodide mixed tin (sn)-lead (pb) perovskites with high sn content exhibit low bandgaps suitable for fabricating the bottom cell of perovskite-based tandem solar cells. in this work, we report on the fabrication of efficient mixed sn-pb perovskite solar cells using precursors combining formamidinium tin iodide (fasni3) and methylammonium lead iodide (mapbi3). the best-performing cell fabricated using a (fasni3)0.6(mapbi3)0.4 absorber with an absorption edge of \u223c1.2 ev achieved a power conversion efficiency (pce) of 15.08 (15.00)% with an open-circuit voltage of 0.795 (0.799) v, a short-circuit current density of 26.86(26.82) ma/cm(2), and a fill factor of 70.6(70.0)% when measured under forward (reverse) voltage scan. the average pce of 50 cells we have fabricated is 14.39 \u00b1 0.33%, indicating good reproducibility.",
            "contribution_ids": [
                "R139633"
            ]
        },
        {
            "instance_id": "R139642xR139623",
            "comparison_id": "R139642",
            "paper_id": "R139623",
            "text": "Hybrid Perovskite Films by a New Variant of Pulsed Excimer Laser Deposition: A Room-Temperature Dry Process a new variant of the classic pulsed laser deposition (pld) process is introduced as a room-temperature dry process for the growth and stoichiometry control of hybrid perovskite films through the use of nonstoichiometric single target ablation and off-axis growth. mixed halide hybrid perovskite films nominally represented by ch3nh3pbi3\u2013xax (a = cl or f) are also grown and are shown to reveal interesting trends in the optical properties and photoresponse. growth of good quality lead-free ch3nh3sni3 films is also demonstrated, and the corresponding optical properties are presented. finally, perovskite solar cells fabricated at room temperature (which makes the process adaptable to flexible substrates) are shown to yield a conversion efficiency of about 7.7%.",
            "contribution_ids": [
                "R139625"
            ]
        },
        {
            "instance_id": "R139642xR139629",
            "comparison_id": "R139642",
            "paper_id": "R139629",
            "text": "Stable Low-Bandgap Pb-Sn Binary Perovskites for Tandem Solar Cells a low-bandgap (1.33 ev) sn-based ma0.5 fa0.5 pb0.75 sn0.25 i3 perovskite is developed via combined compositional, process, and interfacial engineering. it can deliver a high power conversion efficiency (pce) of 14.19%. finally, a four-terminal all-perovskite tandem solar cell is demonstrated by combining this low-bandgap cell with a semitransparent mapbi3 cell to achieve a high efficiency of 19.08%.",
            "contribution_ids": [
                "R139631"
            ]
        },
        {
            "instance_id": "R139642xR139608",
            "comparison_id": "R139642",
            "paper_id": "R139608",
            "text": "Lead-Free Halide Perovskite Solar Cells with High Photocurrents Realized Through Vacancy Modulation lead free perovskite solar cells based on a cssni3 light absorber with a spectral response from 950 nm is demonstrated. the high photocurrents noted in the system are a consequence of snf2 addition which reduces defect concentrations and hence the background charge carrier density.",
            "contribution_ids": [
                "R139610"
            ]
        },
        {
            "instance_id": "R139642xR139602",
            "comparison_id": "R139642",
            "paper_id": "R139602",
            "text": "Organometal Halide Perovskites as Visible-Light Sensitizers for Photovoltaic Cells two organolead halide perovskite nanocrystals, ch(3)nh(3)pbbr(3) and ch(3)nh(3)pbi(3), were found to efficiently sensitize tio(2) for visible-light conversion in photoelectrochemical cells. when self-assembled on mesoporous tio(2) films, the nanocrystalline perovskites exhibit strong band-gap absorptions as semiconductors. the ch(3)nh(3)pbi(3)-based photocell with spectral sensitivity of up to 800 nm yielded a solar energy conversion efficiency of 3.8%. the ch(3)nh(3)pbbr(3)-based cell showed a high photovoltage of 0.96 v with an external quantum conversion efficiency of 65%.",
            "contribution_ids": [
                "R139603"
            ]
        },
        {
            "instance_id": "R139642xR139638",
            "comparison_id": "R139642",
            "paper_id": "R139638",
            "text": "Efficient perovskite solar cells by metal ion doping realizing the theoretical limiting power conversion efficiency (pce) in perovskite solar cells requires a better understanding and control over the fundamental loss processes occurring in the bulk of the perovskite layer and at the internal semiconductor interfaces in devices. one of the main challenges is to eliminate the presence of charge recombination centres throughout the film which have been observed to be most densely located at regions near the grain boundaries. here, we introduce aluminium acetylacetonate to the perovskite precursor solution, which improves the crystal quality by reducing the microstrain in the polycrystalline film. at the same time, we achieve a reduction in the non-radiative recombination rate, a remarkable improvement in the photoluminescence quantum efficiency (plqe) and a reduction in the electronic disorder deduced from an urbach energy of only 12.6 mev in complete devices. as a result, we demonstrate a pce of 19.1% with negligible hysteresis in planar heterojunction solar cells comprising all organic p and n-type charge collection layers. our work shows that an additional level of control of perovskite thin film quality is possible via impurity cation doping, and further demonstrates the continuing importance of improving the electronic quality of the perovskite absorber and the nature of the heterojunctions to further improve the solar cell performance.",
            "contribution_ids": [
                "R139641"
            ]
        },
        {
            "instance_id": "R139642xR139618",
            "comparison_id": "R139642",
            "paper_id": "R139618",
            "text": "Efficiently Improving the Stability of Inverted Perovskite Solar Cells by Employing Polyethylenimine-Modified Carbon Nanotubes as Electrodes inverted perovskite solar cells (pscs) have been becoming more and more attractive, owing to their easy-fabrication and suppressed hysteresis, while the ion diffusion between metallic electrode and perovskite layer limit the long-term stability of devices. in this work, we employed a novel polyethylenimine (pei) modified cross-stacked superaligned carbon nanotube (cscnt) film in the inverted planar pscs configurated fto/nio x/methylammonium lead tri-iodide (mapbi3)/6, 6-phenyl c61-butyric acid methyl ester (pcbm)/cscnt:pei. by modifying cscnt with a certain concentration of pei (0.5 wt %), suitable energy level alignment and promoted interfacial charge transfer have been achieved, leading to a significant enhancement in the photovoltaic performance. as a result, a champion power conversion efficiency (pce) of \u223c11% was obtained with a voc of 0.95 v, a jsc of 18.7 ma cm-2, a ff of 0.61 as well as negligible hysteresis. moreover, cscnt:pei based inverted pscs show superior durability in comparison to the standard silver based devices, remaining over 85% of the initial pce after 500 h aging under various conditions, including long-term air exposure, thermal, and humid treatment. this work opens up a new avenue of facile modified carbon electrodes for highly stable and hysteresis suppressed pscs.",
            "contribution_ids": [
                "R139622"
            ]
        },
        {
            "instance_id": "R139972xR139948",
            "comparison_id": "R139972",
            "paper_id": "R139948",
            "text": "A 2-DOF convective micro accelerometer with a low thermal stress sensing element this paper presents the development of a dual-axis convective microaccelerometer, whose working principle is based on the convective heat transfer and thermoresistive effect of lightly doped silicon. in contrast to the developed convective accelerometer, the sensor utilizes new structures of the sensing element which can reduce at least 90% of the thermally induced stress. by using a numerical method, the dimensions of the sensing chip and of the package are optimized. the sensitivity of the sensor is simulated; other characteristics such as frequency response, shock resistance and the noise problem were investigated. the sensor has been fabricated by a microelectrical mechanical systems (mems) process and characterized by experiments.",
            "contribution_ids": [
                "R139950"
            ]
        },
        {
            "instance_id": "R139972xR139969",
            "comparison_id": "R139972",
            "paper_id": "R139969",
            "text": "A Reliable Liquid-Based CMOS MEMS Micro Thermal Convective Accelerometer With Enhanced Sensitivity and Limit of Detection in this paper, a liquid-based micro thermal convective accelerometer (mtca) is optimized by the rayleigh number ( ra ) based compact model and fabricated using the $0.35\\\\mu $ m cmos mems technology. to achieve water-proof performance, the conformal parylene c coating was adopted as the isolation layer with the accelerated life-testing results of a 9-year-lifetime for liquid-based mtca. then, the device performance was characterized considering sensitivity, response time, and noise. both the theoretical and experimental results demonstrated that fluid with a larger ra number can provide better performance for the mtca. more significantly, ra based model showed its advantage to make a more accurate prediction than the simple linear model to select suitable fluid to enhance the sensitivity and balance the linear range of the device. accordingly, an alcohol-based mtca was achieved with a two-order-of magnitude increase in sensitivity (43.8 mv/g) and one-order-of-magnitude decrease in the limit of detection (lod) ( $61.9~\\\\mu \\\\text{g}$ ) compared with the air-based mtca. [2021-0092]",
            "contribution_ids": [
                "R139971"
            ]
        },
        {
            "instance_id": "R140131xR139993",
            "comparison_id": "R140131",
            "paper_id": "R139993",
            "text": "The Role of Smart City Characteristics in the Plans of Fifteen Cities abstract this paper identifies the characteristics of smart cities as they emerge from the recent literature. it then examines whether and in what way these characteristics are present in the smart city plans of 15 cities: amsterdam, barcelona, london, planit valley, stockholm, cyberjaya, singapore, king abdullah economic city, masdar, skolkovo, songdo, chicago, new york, rio de janeiro, and konza. the results are presented with respect to each smart city characteristic. as expected, most strategies emphasize the role of information and communication technologies in improving the functionality of urban systems and advancing knowledge transfer and innovation networks. however, this research yields other interesting findings that may not yet have been documented across multiple case studies; for example, most smart city strategies fail to incorporate bottom-up approaches, are poorly adapted to accommodate the local needs of their area, and consider issues of privacy and security inadequately.",
            "contribution_ids": [
                "R139995"
            ]
        },
        {
            "instance_id": "R140131xR139927",
            "comparison_id": "R140131",
            "paper_id": "R139927",
            "text": "Smart Cities and Historical Heritage the theme of smart grids will connote in the immediate future the production and distribution of electricity, integrating effectively and in a sustainable way energy deriving from large power stations with that distributed and supplied by renewable sources. in programmes of urban redevelopment, however, the historical city has not yet been subject to significant experimentation, also due to the specific safeguard on this kind of heritage. this reflection opens up interesting new perspectives of research and operations, which could significantly contribute to the pursuit of the aims of the smart city. this is the main goal of the research here presented and focused on the binomial renovation of a historical complex/enhancement and upgrading of its energy efficiency.",
            "contribution_ids": [
                "R139929"
            ]
        },
        {
            "instance_id": "R140131xR139853",
            "comparison_id": "R140131",
            "paper_id": "R139853",
            "text": "SMART CITIES AND HERITAGE CONSERVATION: DEVELOPING A SMARTHERITAGE AGENDA FOR SUSTAINABLE INCLUSIVE COMMUNITIES this paper discusses the potential of current advancements in information communication technologies (ict) for cultural heritage preservation, valorization and management within contemporary cities. the paper highlights the potential of virtual environments to assess the impacts of heritage policies on urban development. it does so by discussing the implications of virtual globes and crowdsourcing to support the participatory valuation and management of cultural heritage assets. to this purpose, a review of available valuation techniques is here presented together with a discussion on how these techniques might be coupled with ict tools to promote inclusive governance.\\xa0",
            "contribution_ids": [
                "R139855"
            ]
        },
        {
            "instance_id": "R140131xR140030",
            "comparison_id": "R140131",
            "paper_id": "R140030",
            "text": "World Heritage meets Smart City in an Urban-Educational Hackathon in Rauma \"during recent years, the \u2018smart city\u2019 concept has emerged in literature (e.g., kunttu, 2019; markkula & kune, 2018; \u00f6berg, graham, & hennelly, 2017; visvizi & lytras, 2018). inherently, the smart city concept includes urban innovation; therefore, simply developing and applying technology is not enough for success. for cities to be 'smart,' they also have to be innovative, apply new ways of thinking among businesses, citizens, and academia, as well as integrate diverse actors, especially universities, in their innovation practices (kunttu, 2019; markkula & kune, 2018).\"",
            "contribution_ids": [
                "R140034"
            ]
        },
        {
            "instance_id": "R140347xR135750",
            "comparison_id": "R140347",
            "paper_id": "R135750",
            "text": "Characterization and comparison of poorly known moth communities through DNA barcoding in two Afrotropical environments in Gabon biodiversity research in tropical ecosystems\u2014popularized as the most biodiverse habitats on earth\u2014often neglects invertebrates, yet invertebrates represent the bulk of local species richness. insect communities in particular remain strongly impeded by both linnaean and wallacean shortfalls, and identifying species often remains a formidable challenge inhibiting the use of these organisms as indicators for ecological and conservation studies. here we use dna barcoding as an alternative to the traditional taxonomic approach for characterizing and comparing the diversity of moth communities in two different ecosystems in gabon. though sampling remains very incomplete, as evidenced by the high proportion (59%) of species represented by singletons, our results reveal an outstanding diversity. with about 3500 specimens sequenced and representing 1385 bins (barcode index numbers, used as a proxy to species) in 23 families, the diversity of moths in the two sites sampled is higher than the current number of species listed for the entire country, highlighting the huge gap in biodiversity knowledge for this country. both seasonal and spatial turnovers are strikingly high (18.3% of bins shared between seasons, and 13.3% between sites) and draw attention to the need to account for these when running regional surveys. our results also highlight the richness and singularity of savannah environments and emphasize the status of central african ecosystems as hotspots of biodiversity.",
            "contribution_ids": [
                "R135752"
            ]
        },
        {
            "instance_id": "R140347xR139508",
            "comparison_id": "R140347",
            "paper_id": "R139508",
            "text": "Close congruence between Barcode Index Numbers (bins) and species boundaries in the Erebidae (Lepidoptera: Noctuoidea) of the Iberian Peninsula abstract the dna barcode reference library for lepidoptera holds much promise as a tool for taxonomic research and for providing the reliable identifications needed for conservation assessment programs. we gathered sequences for the barcode region of the mitochondrial cytochrome c oxidase subunit i gene from 160 of the 176 nominal species of erebidae moths (insecta: lepidoptera) known from the iberian peninsula. these results arise from a research project which constructing a dna barcode library for the insect species of spain. new records for 271 specimens (122 species) are coupled with preexisting data for 38 species from the iberian fauna. mean interspecific distance was 12.1%, while the mean nearest neighbour divergence was 6.4%. all 160 species possessed diagnostic barcode sequences, but one pair of congeneric taxa (eublemma rosea and eublemma rietzi) were assigned to the same bin. as well, intraspecific sequence divergences higher than 1.5% were detected in four species which likely represent species complexes. this study reinforces the effectiveness of dna barcoding as a tool for monitoring biodiversity in particular geographical areas and the strong correspondence between sequence clusters delineated by bins and species recognized through detailed taxonomic analysis.",
            "contribution_ids": [
                "R139510"
            ]
        },
        {
            "instance_id": "R140347xR109043",
            "comparison_id": "R140347",
            "paper_id": "R109043",
            "text": "A DNA barcode library for the butterflies of North America although the butterflies of north america have received considerable taxonomic attention, overlooked species and instances of hybridization continue to be revealed. the present study assembles a dna barcode reference library for this fauna to identify groups whose patterns of sequence variation suggest the need for further taxonomic study. based on 14,626 records from 814 species, dna barcodes were obtained for 96% of the fauna. the maximum intraspecific distance averaged 1/4 the minimum distance to the nearest neighbor, producing a barcode gap in 76% of the species. most species (80%) were monophyletic, the others were para- or polyphyletic. although 15% of currently recognized species shared barcodes, the incidence of such taxa was far higher in regions exposed to pleistocene glaciations than in those that were ice-free. nearly 10% of species displayed high intraspecific variation (&gt;2.5%), suggesting the need for further investigation to assess potential cryptic diversity. aside from aiding the identification of all life stages of north american butterflies, the reference library has provided new perspectives on the incidence of both cryptic and potentially over-split species, setting the stage for future studies that can further explore the evolutionary dynamics of this group.",
            "contribution_ids": [
                "R157021",
                "R109045"
            ]
        },
        {
            "instance_id": "R140347xR108960",
            "comparison_id": "R140347",
            "paper_id": "R108960",
            "text": "Use of species delimitation approaches to tackle the cryptic diversity of an assemblage of high Andean butterflies (Lepidoptera: Papilionoidea) cryptic biological diversity has generated ambiguity in taxonomic and evolutionary studies. single-locus methods and other approaches for species delimitation are useful for addressing this challenge, enabling the practical processing of large numbers of samples for identification and inventory purposes. this study analyzed an assemblage of high andean butterflies using dna barcoding and compared the identifications based on the current morphological taxonomy with three methods of species delimitation (automatic barcode gap discovery, generalized mixed yule coalescent model, and poisson tree processes). sixteen potential cryptic species were recognized using these three methods, representing a net richness increase of 11.3% in the assemblage. a well-studied taxon of the genus vanessa, which has a wide geographical distribution, appeared with the potential cryptic species that had a higher genetic differentiation at the local level than at the continental level. the analyses were useful for identifying the potential cryptic species in pedaliodes and forsterinaria complexes, which also show differentiation along altitudinal and latitudinal gradients. this genetic assessment of an entire assemblage of high andean butterflies (papilionoidea) provides baseline information for future research in a region characterized by high rates of endemism and population isolation.",
            "contribution_ids": [
                "R157029",
                "R108962"
            ]
        },
        {
            "instance_id": "R140347xR140252",
            "comparison_id": "R140347",
            "paper_id": "R140252",
            "text": "Species-Level Para- and Polyphyly in DNA Barcode Gene Trees: Strong Operational Bias in European Lepidoptera the proliferation of dna data is revolutionizing all fields of systematic research. dna barcode sequences, now available for millions of specimens and several hundred thousand species, are increasingly used in algorithmic species delimitations. this is complicated by occasional incongruences between species and gene genealogies, as indicated by situations where conspecific individuals do not form a monophyletic cluster in a gene tree. in two previous reviews, non-monophyly has been reported as being common in mitochondrial dna gene trees. we developed a novel web service \u201cmonophylizer\u201d to detect non-monophyly in phylogenetic trees and used it to ascertain the incidence of species non-monophyly in coi (a.k.a. cox1) barcode sequence data from 4977 species and 41,583 specimens of european lepidoptera, the largest data set of dna barcodes analyzed from this regard. particular attention was paid to accurate species identification to ensure data integrity. we investigated the effects of tree-building method, sampling effort, and other methodological issues, all of which can influence estimates of non-monophyly. we found a 12% incidence of non-monophyly, a value significantly lower than that observed in previous studies. neighbor joining (nj) and maximum likelihood (ml) methods yielded almost equal numbers of non-monophyletic species, but 24.1% of these cases of non-monophyly were only found by one of these methods. non-monophyletic species tend to show either low genetic distances to their nearest neighbors or exceptionally high levels of intraspecific variability. cases of polyphyly in coi trees arising as a result of deep intraspecific divergence are negligible, as the detected cases reflected misidentifications or methodological errors. taking into consideration variation in sampling effort, we estimate that the true incidence of non-monophyly is \u223c23%, but with operational factors still being included. within the operational factors, we separately assessed the frequency of taxonomic limitations (presence of overlooked cryptic and oversplit species) and identification uncertainties. we observed that operational factors are potentially present in more than half (58.6%) of the detected cases of non-monophyly. furthermore, we observed that in about 20% of non-monophyletic species and entangled species, the lineages involved are either allopatric or parapatric\u2014conditions where species delimitation is inherently subjective and particularly dependent on the species concept that has been adopted. these observations suggest that species-level non-monophyly in coi gene trees is less common than previously supposed, with many cases reflecting misidentifications, the subjectivity of species delimitation or other operational factors.",
            "contribution_ids": [
                "R140254",
                "R156759"
            ]
        },
        {
            "instance_id": "R140347xR140187",
            "comparison_id": "R140347",
            "paper_id": "R140187",
            "text": "DNA Barcoding the Geometrid Fauna of Bavaria (Lepidoptera): Successes, Surprises, and Questions background the state of bavaria is involved in a research program that will lead to the construction of a dna barcode library for all animal species within its territorial boundaries. the present study provides a comprehensive dna barcode library for the geometridae, one of the most diverse of insect families. methodology/principal findings this study reports dna barcodes for 400 bavarian geometrid species, 98 per cent of the known fauna, and approximately one per cent of all bavarian animal species. although 98.5% of these species possess diagnostic barcode sequences in bavaria, records from neighbouring countries suggest that species-level resolution may be compromised in up to 3.5% of cases. all taxa which apparently share barcodes are discussed in detail. one case of modest divergence (1.4%) revealed a species overlooked by the current taxonomic system: eupithecia goossensiata mabille, 1869 stat.n. is raised from synonymy with eupithecia absinthiata (clerck, 1759) to species rank. deep intraspecific sequence divergences (>2%) were detected in 20 traditionally recognized species. conclusions/significance the study emphasizes the effectiveness of dna barcoding as a tool for monitoring biodiversity. open access is provided to a data set that includes records for 1,395 geometrid specimens (331 species) from bavaria, with 69 additional species from neighbouring regions. taxa with deep intraspecific sequence divergences are undergoing more detailed analysis to ascertain if they represent cases of cryptic diversity.",
            "contribution_ids": [
                "R140188",
                "R156814"
            ]
        },
        {
            "instance_id": "R140347xR139497",
            "comparison_id": "R140347",
            "paper_id": "R139497",
            "text": "Congruence between morphology-based species and Barcode Index Numbers (BINs) in Neotropical Eumaeini (Lycaenidae) \\n background \\n with about 1,000 species in the neotropics, the eumaeini (theclinae) are one of the most diverse butterfly tribes. correct morphology-based identifications are challenging in many genera due to relatively little interspecific differences in wing patterns. geographic infraspecific variation is sometimes more substantial than variation between species. in this paper we present a large dna barcode dataset of south american lycaenidae. we analyze how well dna barcode bins match morphologically delimited species. \\n \\n \\n methods \\n we compare morphology-based species identifications with the clustering of molecular operational taxonomic units (motus) delimitated by the resl algorithm in bold, which assigns barcode index numbers (bins). we examine intra- and interspecific divergences for genera represented by at least four morphospecies. we discuss the existence of local barcode gaps in a genus by genus analysis. we also note differences in the percentage of species with barcode gaps in groups of lowland and high mountain genera. \\n \\n \\n results \\n we identified 2,213 specimens and obtained 1,839 sequences of 512 species in 90 genera. overall, the mean intraspecific divergence value of co1 sequences was 1.20%, while the mean interspecific divergence between nearest congeneric neighbors was 4.89%, demonstrating the presence of a barcode gap. however, the gap seemed to disappear from the entire set when comparing the maximum intraspecific distance (8.40%) with the minimum interspecific distance (0.40%). clear barcode gaps are present in many genera but absent in others. from the set of specimens that yielded coi fragment lengths of at least 650 bp, 75% of the a priori morphology-based identifications were unambiguously assigned to a single barcode index number (bin). however, after a taxonomic a posteriori review, the percentage of matched identifications rose to 85%. bin splitting was observed for 17% of the species and bin sharing for 9%. we found that genera that contain primarily lowland species show higher percentages of local barcode gaps and congruence between bins and morphology than genera that contain exclusively high montane species. the divergence values to the nearest neighbors were significantly lower in high andean species while the intra-specific divergence values were significantly lower in the lowland species. these results raise questions regarding the causes of observed low inter and high intraspecific genetic variation. we discuss incomplete lineage sorting and hybridization as most likely causes of this phenomenon, as the montane species concerned are relatively young and hybridization is probable. the release of our data set represents an essential baseline for a reference library for biological assessment studies of butterflies in mega diverse countries using modern high-throughput technologies an highlights the necessity of taxonomic revisions for various genera combining both molecular and morphological data. \\n",
            "contribution_ids": [
                "R139502",
                "R156958"
            ]
        },
        {
            "instance_id": "R140347xR138562",
            "comparison_id": "R140347",
            "paper_id": "R138562",
            "text": "Fast Census of Moth Diversity in the Neotropics: A Comparison of Field-Assigned Morphospecies and DNA Barcoding in Tiger Moths the morphological species delimitations (i.e. morphospecies) have long been the best way to avoid the taxonomic impediment and compare insect taxa biodiversity in highly diverse tropical and subtropical regions. the development of dna barcoding, however, has shown great potential to replace (or at least complement) the morphospecies approach, with the advantage of relying on automated methods implemented in computer programs or even online rather than in often subjective morphological features. we sampled moths extensively for two years using light traps in a patch of the highly endangered atlantic forest of brazil to produce a nearly complete census of arctiines (noctuoidea: erebidae), whose species richness was compared using different morphological and molecular approaches (dna barcoding). a total of 1,075 barcode sequences of 286 morphospecies were analyzed. based on the clustering method barcode index number (bin) we found a taxonomic bias of approximately 30% in our initial morphological assessment. however, a morphological reassessment revealed that the correspondence between morphospecies and molecular operational taxonomic units (motus) can be up to 94% if differences in genitalia morphology are evaluated in individuals of different motus originated from the same morphospecies (putative cases of cryptic species), and by recording if individuals of different genders in different morphospecies merge together in the same motu (putative cases of sexual dimorphism). the results of two other clustering methods (i.e. automatic barcode gap discovery and 2% threshold) were very similar to those of the bin approach. using empirical data we have shown that dna barcoding performed substantially better than the morphospecies approach, based on superficial morphology, to delimit species of a highly diverse moth taxon, and thus should be used in species inventories.",
            "contribution_ids": [
                "R156968",
                "R138564"
            ]
        },
        {
            "instance_id": "R140347xR136201",
            "comparison_id": "R140347",
            "paper_id": "R136201",
            "text": "DNA barcode analysis of butterfly species from Pakistan points towards regional endemism dna barcodes were obtained for 81 butterfly species belonging to 52 genera from sites in north\u2010central pakistan to test the utility of barcoding for their identification and to gain a better understanding of regional barcode variation. these species represent 25% of the butterfly fauna of pakistan and belong to five families, although the nymphalidae were dominant, comprising 38% of the total specimens. barcode analysis showed that maximum conspecific divergence was 1.6%, while there was 1.7\u201314.3% divergence from the nearest neighbour species. barcode records for 55 species showed <2% sequence divergence to records in the barcode of life data systems (bold), but only 26 of these cases involved specimens from neighbouring india and central asia. analysis revealed that most species showed little incremental sequence variation when specimens from other regions were considered, but a threefold increase was noted in a few cases. there was a clear gap between maximum intraspecific and minimum nearest neighbour distance for all 81 species. neighbour\u2010joining cluster analysis showed that members of each species formed a monophyletic cluster with strong bootstrap support. the barcode results revealed two provisional species that could not be clearly linked to known taxa, while 24 other species gained their first coverage. future work should extend the barcode reference library to include all butterfly species from pakistan as well as neighbouring countries to gain a better understanding of regional variation in barcode sequences in this topographically and climatically complex region.",
            "contribution_ids": [
                "R156999",
                "R136203"
            ]
        },
        {
            "instance_id": "R140347xR139538",
            "comparison_id": "R140347",
            "paper_id": "R139538",
            "text": "High resolution DNA barcode library for European butterflies reveals continental patterns of mitochondrial genetic diversity abstract the study of global biodiversity will greatly benefit from access to comprehensive dna barcode libraries at continental scale, but such datasets are still very rare. here, we assemble the first high-resolution reference library for european butterflies that provides 97% taxon coverage (459 species) and 22,306 coi sequences. we estimate that we captured 62% of the total haplotype diversity and show that most species possess a few very common haplotypes and many rare ones. specimens in the dataset have an average 95.3% probability of being correctly identified. mitochondrial diversity displayed elevated haplotype richness in southern european refugia, establishing the generality of this key biogeographic pattern for an entire taxonomic group. fifteen percent of the species are involved in barcode sharing, but two thirds of these cases may reflect the need for further taxonomic research. this dataset provides a unique resource for conservation and for studying evolutionary processes, cryptic species, phylogeography, and ecology.",
            "contribution_ids": [
                "R139543",
                "R156950"
            ]
        },
        {
            "instance_id": "R140348xR140245",
            "comparison_id": "R140348",
            "paper_id": "R140245",
            "text": "Onto2vec: joint vector-based representation of biological entities and their ontology-based annotations motivation biological knowledge is widely represented in the form of ontology\u2010based annotations: ontologies describe the phenomena assumed to exist within a domain, and the annotations associate a (kind of) biological entity with a set of phenomena within the domain. the structure and information contained in ontologies and their annotations make them valuable for developing machine learning, data analysis and knowledge extraction algorithms; notably, semantic similarity is widely used to identify relations between biological entities, and ontology\u2010based annotations are frequently used as features in machine learning applications. results we propose the onto2vec method, an approach to learn feature vectors for biological entities based on their annotations to biomedical ontologies. our method can be applied to a wide range of bioinformatics research problems such as similarity\u2010based prediction of interactions between proteins, classification of interaction types using supervised learning, or clustering. to evaluate onto2vec, we use the gene ontology (go) and jointly produce dense vector representations of proteins, the go classes to which they are annotated, and the axioms in go that constrain these classes. first, we demonstrate that onto2vec\u2010generated feature vectors can significantly improve prediction of protein\u2010protein interactions in human and yeast. we then illustrate how onto2vec representations provide the means for constructing data\u2010driven, trainable semantic similarity measures that can be used to identify particular relations between proteins. finally, we use an unsupervised clustering approach to identify protein families based on their enzyme commission numbers. our results demonstrate that onto2vec can generate high quality feature vectors from biological entities and ontologies. onto2vec has the potential to significantly outperform the state\u2010of\u2010the\u2010art in several predictive applications in which ontologies are involved. availability and implementation https://github.com/bio\u2010ontology\u2010research\u2010group/onto2vec",
            "contribution_ids": [
                "R140247"
            ]
        },
        {
            "instance_id": "R140348xR140177",
            "comparison_id": "R140348",
            "paper_id": "R140177",
            "text": "Embedding logical queries on knowledge graphs learning low-dimensional embeddings of knowledge graphs is a powerful approach used to predict unobserved or missing edges between entities. however, an open challenge in this area is developing techniques that can go beyond simple edge prediction and handle more complex logical queries, which might involve multiple unobserved edges, entities, and variables. for instance, given an incomplete biological knowledge graph, we might want to predict \"em what drugs are likely to target proteins involved with both diseases x and y?\" -- a query that requires reasoning about all possible proteins that might interact with diseases x and y. here we introduce a framework to efficiently make predictions about conjunctive logical queries -- a flexible but tractable subset of first-order logic -- on incomplete knowledge graphs. in our approach, we embed graph nodes in a low-dimensional space and represent logical operators as learned geometric operations (e.g., translation, rotation) in this embedding space. by performing logical operations within a low-dimensional embedding space, our approach achieves a time complexity that is linear in the number of query variables, compared to the exponential complexity required by a naive enumeration-based approach. we demonstrate the utility of this framework in two application studies on real-world datasets with millions of relations: predicting logical relationships in a network of drug-gene-disease interactions and in a graph-based representation of social interactions derived from a popular web forum.",
            "contribution_ids": [
                "R140179"
            ]
        },
        {
            "instance_id": "R140348xR140156",
            "comparison_id": "R140348",
            "paper_id": "R140156",
            "text": "OWL2Vec*: Embedding of OWL Ontologies abstract semantic embedding of knowledge graphs has been widely studied and used for prediction and statistical analysis tasks across various domains such as natural language processing and the semantic web. however, less attention has been paid to developing robust methods for embedding owl (web ontology language) ontologies, which contain richer semantic information than plain knowledge graphs, and have been widely adopted in domains such as bioinformatics. in this paper, we propose a random walk and word embedding based ontology embedding method named , which encodes the semantics of an owl ontology by taking into account its graph structure, lexical information and logical constructors. our empirical evaluation with three real world datasets suggests that benefits from these three different aspects of an ontology in class membership prediction and class subsumption prediction tasks. furthermore, often significantly outperforms the state-of-the-art methods in our experiments.",
            "contribution_ids": [
                "R140158"
            ]
        },
        {
            "instance_id": "R140348xR140183",
            "comparison_id": "R140348",
            "paper_id": "R140183",
            "text": "Bio-joie: Joint representation learning of biological knowledge bases abstract the widespread of coronavirus has led to a worldwide pandemic with a high mortality rate. currently, the knowledge accumulated from different studies about this virus is very limited. leveraging a wide-range of biological knowledge, such as gene on-tology and protein-protein interaction (ppi) networks from other closely related species presents a vital approach to infer the molecular impact of a new species. in this paper, we propose the transferred multi-relational embedding model bio-joie to capture the knowledge of gene ontology and ppi networks, which demonstrates superb capability in modeling the sars-cov-2-human protein interactions. bio-joie jointly trains two model components. the knowledge model encodes the relational facts from the protein and go domains into separated embedding spaces, using a hierarchy-aware encoding technique employed for the go terms. on top of that, the transfer model learns a non-linear transformation to transfer the knowledge of ppis and gene ontology annotations across their embedding spaces. by leveraging only structured knowledge, bio-joie significantly outperforms existing state-of-the-art methods in ppi type prediction on multiple species. furthermore, we also demonstrate the potential of leveraging the learned representations on clustering proteins with enzymatic function into enzyme commission families. finally, we show that bio-joie can accurately identify ppis between the sars-cov-2 proteins and human proteins, providing valuable insights for advancing research on this new disease.",
            "contribution_ids": [
                "R140185"
            ]
        },
        {
            "instance_id": "R140348xR140174",
            "comparison_id": "R140348",
            "paper_id": "R140174",
            "text": "Universal representation learning of knowledge bases by jointly embedding instances and ontological concepts many large-scale knowledge bases simultaneously represent two views of knowledge graphs (kgs): an ontology view for abstract and commonsense concepts, and an instance view for specific entities that are instantiated from ontological concepts. existing kg embedding models, however, merely focus on representing one of the two views alone. in this paper, we propose a novel two-view kg embedding model, joie, with the goal to produce better knowledge embedding and enable new applications that rely on multi-view knowledge. joie employs both cross-view and intra-view modeling that learn on multiple facets of the knowledge base. the cross-view association model is learned to bridge the embeddings of ontological concepts and their corresponding instance-view entities. the intra-view models are trained to capture the structured knowledge of instance and ontology views in separate embedding spaces, with a hierarchy-aware encoding technique enabled for ontologies with hierarchies. we explore multiple representation techniques for the two model components and investigate with nine variants of joie. our model is trained on large-scale knowledge bases that consist of massive instances and their corresponding ontological concepts connected via a (small) set of cross-view links. experimental results on public datasets show that the best variant of joie significantly outperforms previous models on instance-view triple prediction task as well as ontology population on ontology-view kg. in addition, our model successfully extends the use of kg embeddings to entity typing with promising performance.",
            "contribution_ids": [
                "R140176"
            ]
        },
        {
            "instance_id": "R140348xR140180",
            "comparison_id": "R140348",
            "paper_id": "R140180",
            "text": "Beta embeddings for multi-hop logical reasoning in knowledge graphs one of the fundamental problems in artificial intelligence is to perform complex multi-hop logical reasoning over the facts captured by a knowledge graph (kg). this problem is challenging, because kgs can be massive and incomplete. recent approaches embed kg entities in a low dimensional space and then use these embeddings to find the answer entities. however, it has been an outstanding challenge of how to handle arbitrary first-order logic (fol) queries as present methods are limited to only a subset of fol operators. in particular, the negation operator is not supported. an additional limitation of present methods is also that they cannot naturally model uncertainty. here, we present betae, a probabilistic embedding framework for answering arbitrary fol queries over kgs. betae is the first method that can handle a complete set of first-order logical operations: conjunction ($\\\\wedge$), disjunction ($\\\\vee$), and negation ($\\\\neg$). a key insight of betae is to use probabilistic distributions with bounded support, specifically the beta distribution, and embed queries/entities as distributions, which as a consequence allows us to also faithfully model uncertainty. logical operations are performed in the embedding space by neural operators over the probabilistic embeddings. we demonstrate the performance of betae on answering arbitrary fol queries on three large, incomplete kgs. while being more general, betae also increases relative performance by up to 25.4% over the current state-of-the-art kg reasoning methods that can only handle conjunctive queries without negation.",
            "contribution_ids": [
                "R140182"
            ]
        },
        {
            "instance_id": "R140348xR140153",
            "comparison_id": "R140348",
            "paper_id": "R140153",
            "text": "Clinical Concept Embeddings Learned from Massive Sources of Medical Data word embeddings have emerged as a popular approach to unsupervised learning of word relationships in machine learning and natural language processing. in this article, we benchmark two of the most popular algorithms, glove and word2vec, to assess their suitability for capturing medical relationships in large sources of biomedical data. leaning on recent theoretical insights, we provide a unified view of these algorithms and demonstrate how different sources of data can be combined to construct the largest ever set of embeddings for 108,477 medical concepts using an insurance claims database of 60 million members, 20 million clinical notes, and 1.7 million full text biomedical journal articles. we evaluate our approach, called cui2vec, on a set of clinically relevant benchmarks and in many instances demonstrate state of the art performance relative to previous results. finally, we provide a downloadable set of pre-trained embeddings for other researchers to use, as well as an online tool for interactive exploration of the cui2vec embeddings.",
            "contribution_ids": [
                "R140155"
            ]
        },
        {
            "instance_id": "R140348xR140135",
            "comparison_id": "R140348",
            "paper_id": "R140135",
            "text": "node2vec: Scalable Feature Learning for Networks \"prediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. however, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. in node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. we define a flexible notion of a node's network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations. we demonstrate the efficacy of node2vec over existing state-of-the-art techniques on multi-label classification and link prediction in several real-world networks from diverse domains. taken together, our work represents a new way for efficiently learning state-of-the-art task-independent representations in complex networks.\"",
            "contribution_ids": [
                "R140137"
            ]
        },
        {
            "instance_id": "R140465xR136201",
            "comparison_id": "R140465",
            "paper_id": "R136201",
            "text": "DNA barcode analysis of butterfly species from Pakistan points towards regional endemism dna barcodes were obtained for 81 butterfly species belonging to 52 genera from sites in north\u2010central pakistan to test the utility of barcoding for their identification and to gain a better understanding of regional barcode variation. these species represent 25% of the butterfly fauna of pakistan and belong to five families, although the nymphalidae were dominant, comprising 38% of the total specimens. barcode analysis showed that maximum conspecific divergence was 1.6%, while there was 1.7\u201314.3% divergence from the nearest neighbour species. barcode records for 55 species showed <2% sequence divergence to records in the barcode of life data systems (bold), but only 26 of these cases involved specimens from neighbouring india and central asia. analysis revealed that most species showed little incremental sequence variation when specimens from other regions were considered, but a threefold increase was noted in a few cases. there was a clear gap between maximum intraspecific and minimum nearest neighbour distance for all 81 species. neighbour\u2010joining cluster analysis showed that members of each species formed a monophyletic cluster with strong bootstrap support. the barcode results revealed two provisional species that could not be clearly linked to known taxa, while 24 other species gained their first coverage. future work should extend the barcode reference library to include all butterfly species from pakistan as well as neighbouring countries to gain a better understanding of regional variation in barcode sequences in this topographically and climatically complex region.",
            "contribution_ids": [
                "R156999",
                "R136203"
            ]
        },
        {
            "instance_id": "R140465xR138551",
            "comparison_id": "R140465",
            "paper_id": "R138551",
            "text": "Probing planetary biodiversity with DNA barcodes: The Noctuoidea of North America this study reports the assembly of a dna barcode reference library for species in the lepidopteran superfamily noctuoidea from canada and the usa. based on the analysis of 69,378 specimens, the library provides coverage for 97.3% of the noctuoid fauna (3565 of 3664 species). in addition to verifying the strong performance of dna barcodes in the discrimination of these species, the results indicate close congruence between the number of species analyzed (3565) and the number of sequence clusters (3816) recognized by the barcode index number (bin) system. distributional patterns across 12 north american ecoregions are examined for the 3251 species that have gps data while bin analysis is used to quantify overlap between the noctuoid faunas of north america and other zoogeographic regions. this analysis reveals that 90% of north american noctuoids are endemic and that just 7.5% and 1.8% of bins are shared with the neotropics and with the palearctic, respectively. one third (29) of the latter species are recent introductions and, as expected, they possess low intraspecific divergences.",
            "contribution_ids": [
                "R156994",
                "R138554"
            ]
        },
        {
            "instance_id": "R140465xR139497",
            "comparison_id": "R140465",
            "paper_id": "R139497",
            "text": "Congruence between morphology-based species and Barcode Index Numbers (BINs) in Neotropical Eumaeini (Lycaenidae) \\n background \\n with about 1,000 species in the neotropics, the eumaeini (theclinae) are one of the most diverse butterfly tribes. correct morphology-based identifications are challenging in many genera due to relatively little interspecific differences in wing patterns. geographic infraspecific variation is sometimes more substantial than variation between species. in this paper we present a large dna barcode dataset of south american lycaenidae. we analyze how well dna barcode bins match morphologically delimited species. \\n \\n \\n methods \\n we compare morphology-based species identifications with the clustering of molecular operational taxonomic units (motus) delimitated by the resl algorithm in bold, which assigns barcode index numbers (bins). we examine intra- and interspecific divergences for genera represented by at least four morphospecies. we discuss the existence of local barcode gaps in a genus by genus analysis. we also note differences in the percentage of species with barcode gaps in groups of lowland and high mountain genera. \\n \\n \\n results \\n we identified 2,213 specimens and obtained 1,839 sequences of 512 species in 90 genera. overall, the mean intraspecific divergence value of co1 sequences was 1.20%, while the mean interspecific divergence between nearest congeneric neighbors was 4.89%, demonstrating the presence of a barcode gap. however, the gap seemed to disappear from the entire set when comparing the maximum intraspecific distance (8.40%) with the minimum interspecific distance (0.40%). clear barcode gaps are present in many genera but absent in others. from the set of specimens that yielded coi fragment lengths of at least 650 bp, 75% of the a priori morphology-based identifications were unambiguously assigned to a single barcode index number (bin). however, after a taxonomic a posteriori review, the percentage of matched identifications rose to 85%. bin splitting was observed for 17% of the species and bin sharing for 9%. we found that genera that contain primarily lowland species show higher percentages of local barcode gaps and congruence between bins and morphology than genera that contain exclusively high montane species. the divergence values to the nearest neighbors were significantly lower in high andean species while the intra-specific divergence values were significantly lower in the lowland species. these results raise questions regarding the causes of observed low inter and high intraspecific genetic variation. we discuss incomplete lineage sorting and hybridization as most likely causes of this phenomenon, as the montane species concerned are relatively young and hybridization is probable. the release of our data set represents an essential baseline for a reference library for biological assessment studies of butterflies in mega diverse countries using modern high-throughput technologies an highlights the necessity of taxonomic revisions for various genera combining both molecular and morphological data. \\n",
            "contribution_ids": [
                "R139502",
                "R156958"
            ]
        },
        {
            "instance_id": "R140465xR109043",
            "comparison_id": "R140465",
            "paper_id": "R109043",
            "text": "A DNA barcode library for the butterflies of North America although the butterflies of north america have received considerable taxonomic attention, overlooked species and instances of hybridization continue to be revealed. the present study assembles a dna barcode reference library for this fauna to identify groups whose patterns of sequence variation suggest the need for further taxonomic study. based on 14,626 records from 814 species, dna barcodes were obtained for 96% of the fauna. the maximum intraspecific distance averaged 1/4 the minimum distance to the nearest neighbor, producing a barcode gap in 76% of the species. most species (80%) were monophyletic, the others were para- or polyphyletic. although 15% of currently recognized species shared barcodes, the incidence of such taxa was far higher in regions exposed to pleistocene glaciations than in those that were ice-free. nearly 10% of species displayed high intraspecific variation (&gt;2.5%), suggesting the need for further investigation to assess potential cryptic diversity. aside from aiding the identification of all life stages of north american butterflies, the reference library has provided new perspectives on the incidence of both cryptic and potentially over-split species, setting the stage for future studies that can further explore the evolutionary dynamics of this group.",
            "contribution_ids": [
                "R157021",
                "R109045"
            ]
        },
        {
            "instance_id": "R140465xR136193",
            "comparison_id": "R140465",
            "paper_id": "R136193",
            "text": "Complete DNA barcode reference library for a country's butterfly fauna reveals high performance for temperate Europe dna barcoding aims to accelerate species identification and discovery, but performance tests have shown marked differences in identification success. as a consequence, there remains a great need for comprehensive studies which objectively test the method in groups with a solid taxonomic framework. this study focuses on the 180 species of butterflies in romania, accounting for about one third of the european butterfly fauna. this country includes five eco-regions, the highest of any in the european union, and is a good representative for temperate areas. morphology and dna barcodes of more than 1300 specimens were carefully studied and compared. our results indicate that 90 per cent of the species form barcode clusters allowing their reliable identification. the remaining cases involve nine closely related species pairs, some whose taxonomic status is controversial or that hybridize regularly. interestingly, dna barcoding was found to be the most effective identification tool, outperforming external morphology, and being slightly better than male genitalia. romania is now the first country to have a comprehensive dna barcode reference database for butterflies. similar barcoding efforts based on comprehensive sampling of specific geographical regions can act as functional modules that will foster the early application of dna barcoding while a global system is under development.",
            "contribution_ids": [
                "R157016",
                "R136195"
            ]
        },
        {
            "instance_id": "R140543xR140514",
            "comparison_id": "R140543",
            "paper_id": "R140514",
            "text": "High-Performance Chemical Sensing Using Schottky-Contacted Chemical Vapor Deposition Grown Monolayer MoS2 Transistors trace chemical detection is important for a wide range of practical applications. recently emerged two-dimensional (2d) crystals offer unique advantages as potential sensing materials with high sensitivity, owing to their very high surface-to-bulk atom ratios and semiconducting properties. here, we report the first use of schottky-contacted chemical vapor deposition grown monolayer mos2 as high-performance room temperature chemical sensors. the schottky-contacted mos2 transistors show current changes by 2-3 orders of magnitude upon exposure to very low concentrations of no2 and nh3. specifically, the mos2 sensors show clear detection of no2 and nh3 down to 20 ppb and 1 ppm, respectively. we attribute the observed high sensitivity to both well-known charger transfer mechanism and, more importantly, the schottky barrier modulation upon analyte molecule adsorption, the latter of which is made possible by the schottky contacts in the transistors and is not reported previously for mos2 sensors. this study shows the potential of 2d semiconductors as high-performance sensors and also benefits the fundamental studies of interfacial phenomena and interactions between chemical species and monolayer 2d semiconductors.",
            "contribution_ids": [
                "R140516"
            ]
        },
        {
            "instance_id": "R140543xR140522",
            "comparison_id": "R140543",
            "paper_id": "R140522",
            "text": "Highly sensitive MoTe\n                    2\n                    chemical sensor with fast recovery rate through gate biasing the unique properties of two dimensional (2d) materials make them promising candidates for chemical and biological sensing applications. however, most 2d nanomaterial sensors suffer very long recovery time due to slow molecular desorption at room temperature. here, we report a highly sensitive molybdenum ditelluride (mote2) gas sensor for no2 and nh3 detection with greatly enhanced recovery rate. the effects of gate bias on sensing performance have been systematically studied. it is found that the recovery kinetics can be effectively adjusted by biasing the sensor to different gate voltages. under the optimum biasing potential, the mote2 sensor can achieve more than 90% recovery after each sensing cycle well within 10\\u2009min at room temperature. the results demonstrate the potential of mote2 as a promising candidate for high-performance chemical sensors. the idea of exploiting gate bias to adjust molecular desorption kinetics can be readily applied to much wider sensing platforms based on 2d nanomaterials.",
            "contribution_ids": [
                "R140524"
            ]
        },
        {
            "instance_id": "R140543xR140498",
            "comparison_id": "R140543",
            "paper_id": "R140498",
            "text": "Black Phosphorus Gas Sensors the utilization of black phosphorus and its monolayer (phosphorene) and few-layers in field-effect transistors has attracted a lot of attention to this elemental two-dimensional material. various studies on optimization of black phosphorus field-effect transistors, pn junctions, photodetectors, and other applications have been demonstrated. although chemical sensing based on black phosphorus devices was theoretically predicted, there is still no experimental verification of such an important study of this material. in this article, we report on chemical sensing of nitrogen dioxide (no2) using field-effect transistors based on multilayer black phosphorus. black phosphorus sensors exhibited increased conduction upon no2 exposure and excellent sensitivity for detection of no2 down to 5 ppb. moreover, when the multilayer black phosphorus field-effect transistor was exposed to no2 concentrations of 5, 10, 20, and 40 ppb, its relative conduction change followed the langmuir isotherm for molecules adsorbed on a surface. additionally, on the basis of an exponential conductance change, the rate constants for adsorption and desorption of no2 on black phosphorus were extracted for different no2 concentrations, and they were in the range of 130-840 s. these results shed light on important electronic and sensing characteristics of black phosphorus, which can be utilized in future studies and applications.",
            "contribution_ids": [
                "R140500"
            ]
        },
        {
            "instance_id": "R140543xR140535",
            "comparison_id": "R140543",
            "paper_id": "R140535",
            "text": "Physisorption-Based Charge Transfer in Two-Dimensional SnS2 for Selective and Reversible NO2 Gas Sensing nitrogen dioxide (no2) is a gas species that plays an important role in certain industrial, farming, and healthcare sectors. however, there are still significant challenges for no2 sensing at low detection limits, especially in the presence of other interfering gases. the no2 selectivity of current gas-sensing technologies is significantly traded-off with their sensitivity and reversibility as well as fabrication and operating costs. in this work, we present an important progress for selective and reversible no2 sensing by demonstrating an economical sensing platform based on the charge transfer between physisorbed no2 gas molecules and two-dimensional (2d) tin disulfide (sns2) flakes at low operating temperatures. the device shows high sensitivity and superior selectivity to no2 at operating temperatures of less than 160 \u00b0c, which are well below those of chemisorptive and ion conductive no2 sensors with much poorer selectivity. at the same time, excellent reversibility of the sensor is demonstrated, which has rarely been observed in other 2d material counterparts. such impressive features originate from the planar morphology of 2d sns2 as well as unique physical affinity and favorable electronic band positions of this material that facilitate the no2 physisorption and charge transfer at parts per billion levels. the 2d sns2-based sensor provides a real solution for low-cost and selective no2 gas sensing.",
            "contribution_ids": [
                "R140537"
            ]
        },
        {
            "instance_id": "R140543xR140509",
            "comparison_id": "R140543",
            "paper_id": "R140509",
            "text": "Sub-ppt gas detection with pristine graphene graphene is widely regarded as one of the most promising materials for sensor applications. here, we demonstrate that a pristine graphene can detect gas molecules at extremely low concentrations with detection limits as low as 158 parts-per-quadrillion (ppq) for a range of gas molecules at room temperature. the unprecedented sensitivity was achieved by applying our recently developed concept of continuous in situ cleaning of the sensing material with ultraviolet light. the simplicity of the concept, together with graphene\u2019s flexibility to be used on various platforms, is expected to intrigue more investigations to develop ever more sensitive sensors.",
            "contribution_ids": [
                "R140511"
            ]
        },
        {
            "instance_id": "R140543xR140519",
            "comparison_id": "R140543",
            "paper_id": "R140519",
            "text": "Sensing Behavior of Atomically Thin-Layered MoS2 Transistors most of recent research on layered chalcogenides is understandably focused on single atomic layers. however, it is unclear if single-layer units are the most ideal structures for enhanced gas-solid interactions. to probe this issue further, we have prepared large-area mos2 sheets ranging from single to multiple layers on 300 nm sio2/si substrates using the micromechanical exfoliation method. the thickness and layering of the sheets were identified by optical microscope, invoking recently reported specific optical color contrast, and further confirmed by afm and raman spectroscopy. the mos2 transistors with different thicknesses were assessed for gas-sensing performances with exposure to no2, nh3, and humidity in different conditions such as gate bias and light irradiation. the results show that, compared to the single-layer counterpart, transistors of few mos2 layers exhibit excellent sensitivity, recovery, and ability to be manipulated by gate bias and green light. further, our ab initio dft calculations on single-layer and bilayer mos2 show that the charge transfer is the reason for the decrease in resistance in the presence of applied field.",
            "contribution_ids": [
                "R140521"
            ]
        },
        {
            "instance_id": "R141156xR141133",
            "comparison_id": "R141156",
            "paper_id": "R141133",
            "text": "A High-Power Temperature-Stable Electrostatic RF MEMS Capacitive Switch Based on a Thermal Buckle-Beam Design this paper presents the design, fabrication and measurements of a novel vertical electrostatic rf mems switch which utilizes the lateral thermal buckle-beam actuator design in order to reduce the switch sensitivity to thermal stresses. the effect of biaxial and stress gradients are taken into consideration, and the buckle-beam designs show minimal sensitivity to these stresses. several switches with 4,8, and 12 suspension beams are presented. all the switches demonstrate a low sensitivity to temperature, and the variation in the pull-in voltage is ~ -50 mv/\u00b0c from 25-125\u00b0c. the change in the up-state capacitance for the same temperature range is 150 at 10 ghz in the up-state position is reported. the mechanical resonant frequencies and quality factors are f\u03bf = 60-160 khz and qm = 2.3-4.5, respectively. the measured switching and release times are ~ 2-5 \u03bcs and ~ 5-6.5 \u03bcs, respectively. power handling measurements show good stability with ~ 4 w of incident power at 10 ghz.",
            "contribution_ids": [
                "R141135"
            ]
        },
        {
            "instance_id": "R141156xR141127",
            "comparison_id": "R141156",
            "paper_id": "R141127",
            "text": "RF MEMS Switches With Enhanced Power-Handling Capabilities this paper reports on the experimental and theoretical characterization of rf microelectromechanical systems (mems) switches for high-power applications. first, we investigate the problem of self-actuation due to high rf power and we demonstrate switches that do not self-actuate or catastrophically fail with a measured rf power of up to 5.5 w. second, the problem of switch stiction to the down state as a function of the applied rf power is also theoretically and experimentally studied. finally, a novel switch design with a top electrode is introduced and its advantages related to rf power-handling capabilities are presented. by applying this technology, we demonstrate hot-switching measurements with a maximum power of 0.8 w. our results, backed by theory and measurements, illustrate that careful design can significantly improve the power-handling capabilities of rf mems switches.",
            "contribution_ids": [
                "R141129"
            ]
        },
        {
            "instance_id": "R141156xR141147",
            "comparison_id": "R141156",
            "paper_id": "R141147",
            "text": "RF MEMS Shunt Capacitive Switches Using AlN Compared to Si3N4 Dielectric rf microelectromechanical systems (mems) capacitive switches for two different dielectrics, aluminum nitride (aln) and silicon nitride (si3n4), are presented. the switches have been characterized and compared in terms of dc and rf performance (5-40 ghz). switches based on aln have higher down-state capacitance for similar dielectric thicknesses and provide better isolation and smaller insertion losses compared to si3n4 switches. experiments were carried out on rf mems switches with stiffening bars to prevent membrane deformation due to residual stress and with different spring and meander-type anchor designs. for a ~300-nm dielectric thickness, an air gap of 2.3 \u03bcm and identical spring-type designs, the aln switches systematically show an improvement in the isolation by more than -12 db (-35.8 db versus -23.7 db) and a better insertion loss (-0.68 db versus -0.90 db) at 40 ghz compared to si3n4. dc measurements show small leakage current densities for both dielectrics (<;10-8 a/cm2 at 1 mv/cm). however, the resulting leakage current for aln devices is ten times higher than for si3n4 when applying a larger electric field. the fabricated switches were also stressed by applying different voltages in air and vacuum, and dielectric charging effects were investigated. aln switches eliminate the residual or injected charge faster than the si3n4 devices do.",
            "contribution_ids": [
                "R141149"
            ]
        },
        {
            "instance_id": "R141156xR141139",
            "comparison_id": "R141156",
            "paper_id": "R141139",
            "text": "Fabrication of low pull-in voltage RF MEMS switches on glass substrate in recessed CPW configuration for V-band application a new technique for the fabrication of radio frequency (rf) microelectromechanical systems (mems) shunt switches in recessed coplaner waveguide (cpw) configuration on glass substrates is presented. membranes with low spring constant are used for reducing the pull-in voltage. a layer of silicon dioxide is deposited on glass wafer and is used to form the recess, which partially defines the gap between the membrane and signal line. positive photoresist s1813 is used as a sacrificial layer and gold as the membrane material. the membranes are released with the help of pirhana solution and finally rinsed in low surface tension liquid to avoid stiction during release. switches with 500 \u00b5m long two-meander membranes show very high isolation of greater than 40 db at their resonant frequency of 61 ghz and pull-in voltage less than 15 v, while switches with 700 \u00b5m long six-strip membranes show isolation greater than 30 db at the frequency of 65 ghz and pull-in voltage less than 10 v. both types of switches show insertion loss less than 0.65 db up to 65 ghz.",
            "contribution_ids": [
                "R141141"
            ]
        },
        {
            "instance_id": "R141156xR141130",
            "comparison_id": "R141156",
            "paper_id": "R141130",
            "text": "Effects of surface roughness on electromagnetic characteristics of capacitive switches this paper studies the effect of surface roughness on up-state and down-state capacitances of microelectromechanical systems (mems) capacitive switches. when the root-mean-square (rms) roughness is 10 nm, the up-state capacitance is approximately 9% higher than the theoretical value. when the metal bridge is driven down, the normalized contact area between the metal bridge and the surface of the dielectric layer is less than 1% if the rms roughness is larger than 2 nm. therefore, the down-state capacitance is actually determined by the non-contact part of the metal bridge. the normalized isolation is only 62% for rms roughness of 10 nm when the hold-down voltage is 30 v. the analysis also shows that the down-state capacitance and the isolation increase with the hold-down voltage. the normalized isolation increases from 58% to 65% when the hold-down voltage increases from 10 v to 60 v for rms roughness of 10 nm.",
            "contribution_ids": [
                "R141132"
            ]
        },
        {
            "instance_id": "R141156xR141153",
            "comparison_id": "R141156",
            "paper_id": "R141153",
            "text": "Effect of Environmental Humidity on Dielectric Charging Effect in RF MEMS Capacitive Switches Based on C\u00e2\u0080\u0093V Properties a capacitance-voltage (c- v) model is developed for rf microelectromechanical systems (mems) switches at upstate and downstate. the transient capacitance response of the rf mems switches at different switch states was measured for different humidity levels. by using the c -v model as well as the voltage shift dependent of trapped charges, the transient trapped charges at different switch states and humidity levels are obtained. charging models at different switch states are explored in detail. it is shown that the injected charges increase linearly with humidity levels and the internal polarization increases with increasing humidity at downstate. the speed of charge injection at 80% relative humidity (rh) is about ten times faster than that at 20% rh. a measurement of pull-in voltage shifts by c- v sweep cycles at 20% and 80 % rh gives a reasonable evidence. the present model is useful to understand the pull-in voltage shift of the rf mems switch.",
            "contribution_ids": [
                "R141155"
            ]
        },
        {
            "instance_id": "R141425xR141393",
            "comparison_id": "R141425",
            "paper_id": "R141393",
            "text": "Chaperna-mediated assembly of ferritin-based Middle East respiratory syndrome-coronavirus nanoparticles the folding of monomeric antigens and their subsequent assembly into higher ordered structures are crucial for robust and effective production of nanoparticle (np) vaccines in a timely and reproducible manner. despite significant advances in in silico design and structure-based assembly, most engineered nps are refractory to soluble expression and fail to assemble as designed, presenting major challenges in the manufacturing process. the failure is due to a lack of understanding of the kinetic pathways and enabling technical platforms to ensure successful folding of the monomer antigens into regular assemblages. capitalizing on a novel function of rna as a molecular chaperone (chaperna: chaperone\\u2009+\\u2009rna), we provide a robust protein-folding vehicle that may be implemented to np assembly in bacterial hosts. the receptor-binding domain (rbd) of middle east respiratory syndrome-coronavirus (mers-cov) was fused with the rna-interaction domain (rid) and bacterioferritin, and expressed in escherichia coli in a soluble form. site-specific proteolytic removal of the rid prompted the assemblage of monomers into nps, which was confirmed by electron microscopy and dynamic light scattering. the mutations that affected the rna binding to rbd significantly increased the soluble aggregation into amorphous structures, reducing the overall yield of nps of a defined size. this underscored the rna-antigen interactions during np assembly. the sera after mouse immunization effectively interfered with the binding of mers-cov rbd to the cellular receptor hdpp4. the results suggest that rna-binding controls the overall kinetic network of the antigen folding pathway in favor of enhanced assemblage of nps into highly regular and immunologically relevant conformations. the concentration of the ion fe2+, salt, and fusion linker also contributed to the assembly in vitro, and the stability of the nps. the kinetic \u201cpace-keeping\u201d role of chaperna in the super molecular assembly of antigen monomers holds promise for the development and delivery of nps and virus-like particles as recombinant vaccines and for serological detection of viral infections.",
            "contribution_ids": [
                "R141394"
            ]
        },
        {
            "instance_id": "R141425xR141417",
            "comparison_id": "R141425",
            "paper_id": "R141417",
            "text": "Multiplex Paper-Based Colorimetric DNA Sensor Using Pyrrolidinyl Peptide Nucleic Acid-Induced AgNPs Aggregation for Detecting MERS-CoV, MTB, and HPV Oligonucleotides the development of simple fluorescent and colorimetric assays that enable point-of-care dna and rna detection has been a topic of significant research because of the utility of such assays in resource limited settings. the most common motifs utilize hybridization to a complementary detection strand coupled with a sensitive reporter molecule. here, a paper-based colorimetric assay for dna detection based on pyrrolidinyl peptide nucleic acid (acpcpna)-induced nanoparticle aggregation is reported as an alternative to traditional colorimetric approaches. pna probes are an attractive alternative to dna and rna probes because they are chemically and biologically stable, easily synthesized, and hybridize efficiently with the complementary dna strands. the acpcpna probe contains a single positive charge from the lysine at c-terminus and causes aggregation of citrate anion-stabilized silver nanoparticles (agnps) in the absence of complementary dna. in the presence of target dna, formation of the anionic dna-acpcpna duplex results in dispersion of the agnps as a result of electrostatic repulsion, giving rise to a detectable color change. factors affecting the sensitivity and selectivity of this assay were investigated, including ionic strength, agnp concentration, pna concentration, and dna strand mismatches. the method was used for screening of synthetic middle east respiratory syndrome coronavirus (mers-cov), mycobacterium tuberculosis (mtb), and human papillomavirus (hpv) dna based on a colorimetric paper-based analytical device developed using the aforementioned principle. the oligonucleotide targets were detected by measuring the color change of agnps, giving detection limits of 1.53 (mers-cov), 1.27 (mtb), and 1.03 nm (hpv). the acpcpna probe exhibited high selectivity for the complementary oligonucleotides over single-base-mismatch, two-base-mismatch, and noncomplementary dna targets. the proposed paper-based colorimetric dna sensor has potential to be an alternative approach for simple, rapid, sensitive, and selective dna detection.",
            "contribution_ids": [
                "R141418"
            ]
        },
        {
            "instance_id": "R141425xR141407",
            "comparison_id": "R141425",
            "paper_id": "R141407",
            "text": "A self-adjuvanted nanoparticle based vaccine against infectious bronchitis virus infectious bronchitis virus (ibv) affects poultry respiratory, renal and reproductive systems. currently the efficacy of available live attenuated or killed vaccines against ibv has been challenged. we designed a novel ibv vaccine alternative using a highly innovative platform called self-assembling protein nanoparticle (sapn). in this vaccine, b cell epitopes derived from the second heptad repeat (hr2) region of ibv spike proteins were repetitively presented in its native trimeric conformation. in addition, flagellin was co-displayed in the sapn to achieve a self-adjuvanted effect. three groups of chickens were immunized at four weeks of age with the vaccine prototype, ibv-flagellin-sapn, a negative-control construct flagellin-sapn or a buffer control. the immunized chickens were challenged with 5x104.7 eid50 ibv m41 strain. high antibody responses were detected in chickens immunized with ibv-flagellin-sapn. in ex vivo proliferation tests, peripheral mononuclear cells (pbmcs) derived from ibv-flagellin-sapn immunized chickens had a significantly higher stimulation index than that of pbmcs from chickens receiving flagellin-sapn. chickens immunized with ibv-flagellin-sapn had a significant reduction of tracheal virus shedding and lesser tracheal lesion scores than did negative control chickens. the data demonstrated that the ibv-flagellin-sapn holds promise as a vaccine for ibv.",
            "contribution_ids": [
                "R141408"
            ]
        },
        {
            "instance_id": "R141425xR141395",
            "comparison_id": "R141425",
            "paper_id": "R141395",
            "text": "Enhanced Ability of Oligomeric Nanobodies Targeting MERS Coronavirus Receptor-Binding Domain middle east respiratory syndrome (mers) coronavirus (mers-cov), an infectious coronavirus first reported in 2012, has a mortality rate greater than 35%. therapeutic antibodies are key tools for preventing and treating mers-cov infection, but to date no such agents have been approved for treatment of this virus. nanobodies (nbs) are camelid heavy chain variable domains with properties distinct from those of conventional antibodies and antibody fragments. we generated two oligomeric nbs by linking two or three monomeric nbs (mono-nbs) targeting the mers-cov receptor-binding domain (rbd), and compared their rbd-binding affinity, rbd\u2013receptor binding inhibition, stability, and neutralizing and cross-neutralizing activity against mers-cov. relative to mono-nb, dimeric nb (di-nb) and trimeric nb (tri-nb) had significantly greater ability to bind mers-cov rbd proteins with or without mutations in the rbd, thereby potently blocking rbd\u2013mers-cov receptor binding. the engineered oligomeric nbs were very stable under extreme conditions, including low or high ph, protease (pepsin), chaotropic denaturant (urea), and high temperature. importantly, di-nb and tri-nb exerted significantly elevated broad-spectrum neutralizing activity against at least 19 human and camel mers-cov strains isolated in different countries and years. overall, the engineered nbs could be developed into effective therapeutic agents for prevention and treatment of mers-cov infection.",
            "contribution_ids": [
                "R141396"
            ]
        },
        {
            "instance_id": "R141425xR141405",
            "comparison_id": "R141425",
            "paper_id": "R141405",
            "text": "Immunomodulatory nanodiamond aggregate-based platform for the treatment of rheumatoid arthritis abstract we previously demonstrated that octadecylamine-functionalized nanodiamond (nd-oda) and dexamethasone (dex)-adsorbed nd-oda (nd-oda\u2013dex) promoted anti-inflammatory and pro-regenerative behavior in human macrophages in vitro. in this study, we performed a pilot study to investigate if these immunomodulatory effects translate when used as a treatment for rheumatoid arthritis in mice. following local injection in limbs of mice with collagen type ii-induced arthritis, microcomputed tomography showed that mice treated with a low dose of nd-oda and nd-oda\u2013dex did not experience bone loss to the levels observed in non-treated arthritic controls. a low dose of nd-oda and nd-oda\u2013dex also reduced macrophage infiltration and expression of pro-inflammatory mediators inos and tumor necrosis factor-\u03b1 compared to the arthritic control, while a high dose of nd-oda increased expression of these markers. overall, these results suggest that nd-oda may be useful as an inherently immunomodulatory platform, and support the need for an in-depth study, especially with respect to the effects of dose.",
            "contribution_ids": [
                "R141406"
            ]
        },
        {
            "instance_id": "R141425xR141397",
            "comparison_id": "R141425",
            "paper_id": "R141397",
            "text": "Chimeric camel/human heavy-chain antibodies protect against MERS-CoV infection dromedary camel heavy chain\u2013only antibodies may provide novel intervention strategies against mers coronavirus.",
            "contribution_ids": [
                "R141398"
            ]
        },
        {
            "instance_id": "R141425xR141389",
            "comparison_id": "R141425",
            "paper_id": "R141389",
            "text": "Self-assembled star-shaped chiroplasmonic gold nanoparticles for an ultrasensitive chiro-immunosensor for viruses nanoengineered chiral gold nanoparticles and quantum dots for ultrasensitive chiroptical sensing of viruses in blood samples.",
            "contribution_ids": [
                "R141390"
            ]
        },
        {
            "instance_id": "R141425xR141421",
            "comparison_id": "R141425",
            "paper_id": "R141421",
            "text": "Species-Specific Colocalization of Middle East Respiratory Syndrome Coronavirus Attachment and Entry Receptors \\n mers-cov uses the s1\\n b \\n domain of its spike protein to attach to its host receptor, dipeptidyl peptidase 4 (dpp4). the tissue localization of dpp4 has been mapped in different susceptible species. on the other hand, the s1\\n a \\n domain, the n-terminal domain of this spike protein, preferentially binds to several glycotopes of \u03b12,3-sialic acids, the attachment factor of mers-cov. here we show, using a novel method, that the s1\\n a \\n domain specifically binds to the nasal epithelium of dromedary camels, alveolar epithelium of humans, and intestinal epithelium of common pipistrelle bats. in contrast, it does not bind to the nasal epithelium of pigs or rabbits, nor does it bind to the intestinal epithelium of serotine bats and frugivorous bat species. this finding supports the importance of the s1\\n a \\n domain in mers-cov infection and tropism, suggests its role in transmission, and highlights its potential use as a component of novel vaccine candidates.\\n",
            "contribution_ids": [
                "R141422"
            ]
        },
        {
            "instance_id": "R141425xR141399",
            "comparison_id": "R141425",
            "paper_id": "R141399",
            "text": "A novel nanobody targeting Middle East respiratory syndrome coronavirus (MERS-CoV) receptor-binding domain has potent cross-neutralizing activity and protective efficacy against MERS-CoV \" \\n therapeutic development is critical for preventing and treating continual mers-cov infections in humans and camels. because of their small size, nanobodies (nbs) have advantages as antiviral therapeutics (e.g., high expression yield and robustness for storage and transportation) and also potential limitations (e.g., low antigen-binding affinity and fast renal clearance). here, we have developed novel nbs that specifically target the receptor-binding domain (rbd) of mers-cov spike protein. they bind to a conserved site on mers-cov rbd with high affinity, blocking rbd's binding to mers-cov receptor. through engineering a c-terminal human fc tag, the\\n in vivo \\n half-life of the nbs is significantly extended. moreover, the nbs can potently cross-neutralize the infections of diverse mers-cov strains isolated from humans and camels. the fc-tagged nb also completely protects humanized mice from lethal mers-cov challenge. taken together, our study has discovered novel nbs that hold promise as potent, cost-effective, and broad-spectrum anti-mers-cov therapeutic agents.\\n \"",
            "contribution_ids": [
                "R141400"
            ]
        },
        {
            "instance_id": "R141593xR108954",
            "comparison_id": "R141593",
            "paper_id": "R108954",
            "text": "Ultraviolet/vacuum-ultraviolet emission from a high power magnetron sputtering plasma with an aluminum target we report the in situ measurement of the ultraviolet/vacuum-ultraviolet (uv/vuv) emission from a plasma produced by high power impulse magnetron sputtering with aluminum target, using argon as background gas. the uv/vuv detection system is based upon the quantification of the re-emitted fluorescence from a sodium salicylate layer that is placed in a housing inside the vacuum chamber, at 11\\u2009cm from the center of the cathode. the detector is equipped with filters that allow for differentiating various spectral regions, and with a front collimating tube that provides a spatial resolution\\u2009\\u2009\u2248\\u2009\\u20090.5\\u2009cm. using various views of the plasma, the measured absolutely calibrated photon rates enable to calculate emissivities and irradiances based on a model of the ionization region. we present results that demonstrate that al+ ions are responsible for most of the vuv irradiance. we also discuss the photoelectric emission due to irradiances on the target produced by high energy photons from resonance lines of ar+.",
            "contribution_ids": [
                "R141576",
                "R141763"
            ]
        },
        {
            "instance_id": "R141593xR141535",
            "comparison_id": "R141593",
            "paper_id": "R141535",
            "text": "In situmeasurement of VUV/UV radiation from low-pressure microwave-produced plasma in Ar/O2gas mixtures ultraviolet (uv) and vacuum ultraviolet (vuv) spectral irradiance is determined in low-pressure microwave-produced plasma, which is regularly used for polymer surface treatment. the re-emitted fluorescence in the uv/vis spectral range from a sodium salicylate layer is measured. this fluorescence is related to vuv/uv radiation in different spectral bands based on cut-off filters. the background produced by direct emitted radiation in the fluorescence spectral region is quantified using a specific background filter, thus enabling the use of the whole fluorescence spectral range. a novel procedure is applied to determine the absolute value of the vuv/uv irradiance on a substrate. for that, an independent measurement of the absolute spectral emissivity of the plasma in the uv is performed. the measured irradiances on a substrate from a 25 pa ar/o2-produced plasma are in the range of 1015\u20131016 (photon s\u22121cm\u22122). these values include the contribution from impurities present in the discharge.",
            "contribution_ids": [
                "R141578",
                "R141765"
            ]
        },
        {
            "instance_id": "R141593xR108956",
            "comparison_id": "R141593",
            "paper_id": "R108956",
            "text": "VUV radiation flux from argon DC magnetron plasma vacuum ultraviolet (vuv) flux of argon plasma radiation in a dc magnetron discharge with a plane circular titanium cathode is measured. it is found that the intensity of vuv radiation, mainly indicated by the resonance lines of argon atoms at 104.8 and 106.7 nm and ions at 92 and 93.2 nm, is proportional to the discharge current and decreases with pressure. following the results of the measurements, a numerical model of resonance radiation transport is developed to determine the vuv flux to the substrate placed near the sputtering cathode where direct measurements are impossible due to the fast contamination of the detector by sputtered atoms. in the case of a substrate located 10 cm opposite the cathode surface, the upper limit of estimated vuv flux is of the order of 1015 photons\\u2009cm\u22122\\u2009s\u22121 at a coating deposition rate of 1.5 nm\\u2009s\u22121 for 2 and 12 mtorr gas pressures. based on the measurements, the damage to a porous low-k dielectric by vuv radiation during the deposition of barrier layers in the dc magnetron discharge is first estimated.",
            "contribution_ids": [
                "R141575",
                "R141762"
            ]
        },
        {
            "instance_id": "R141593xR141452",
            "comparison_id": "R141593",
            "paper_id": "R141452",
            "text": "HBr Plasma Treatment Versus VUV Light Treatment to Improve 193\u00e2\u0080\u0089nm Photoresist Pattern Linewidth Roughness we have studied the impact of hbr plasma treatment and the role of the vuv light emitted by this plasma on the chemical modifications and resulting roughness of both blanket and patterned photoresists. the experimental results show that both treatments lead to similar resist bulk chemical modifications that result in a decrease of the resist glass transition temperature (tg). this drop in tg allows polymer chain rearrangement that favors surface roughness smoothening. the smoothening effect is mainly attributed to main chain scission induced by plasma vuv light. for increased vuv light exposure time, the crosslinking mechanism dominates over main chain scission and limits surface roughness smoothening. in the case of the hbr plasma treatment, the synergy between bromine radicals and vuv light leads to the formation of dense graphitized layers on top and sidewalls surfaces of the resist pattern. the presence of a dense layer on the hbr cured resist sidewalls prevents from resist pattern reflowing but on the counter side leads to increased surface roughness and linewidth roughness compared to vuv light treatment.",
            "contribution_ids": [
                "R141588",
                "R141775"
            ]
        },
        {
            "instance_id": "R141593xR141544",
            "comparison_id": "R141593",
            "paper_id": "R141544",
            "text": "OPTIMIZATION OF A SOLAR SIMULATOR FOR PLANETARY-PHOTOCHEMICAL STUDIES low-temperature microwave-powered plasma based on hydrogen and hydrogen with noble gas mixtures are widely used as a continuous vacuum ultraviolet (vuv) source in laboratory experiments carried out to mimic the photochemistry in astrophysical environments. in this work, we present a study dedicated to optimizing such sources in terms of mono-chromaticity at ly\u03b1 (h(ly\u03b1) line at 121.6 nm \u223c 10.2 ev) and high spectral irradiance. we report the influence on the emission spectrum of a wide range of experimental conditions including gas composition (pure h2, pure he, and h2/he mixture), gas pressure, flow rates, and microwave power. the absolute spectral irradiance delivered by this vuv light source has been measured. with a microwave input power of 100 w, the best conditions for producing a quasi-monochromatic source are a 1% h2/he gas mixture at a total pressure of 5 mbar and a flow rate of 2 sccm. by changing the microwave input power from 30 to 120 w, h(ly\u03b1) increases by more than one order of magnitude. a comparison between the current measurements and the solar vuv spectral irradiance is reported over 115\u2013170 nm.",
            "contribution_ids": [
                "R141583",
                "R141770"
            ]
        },
        {
            "instance_id": "R141593xR141542",
            "comparison_id": "R141593",
            "paper_id": "R141542",
            "text": "Comparison of vacuum ultra-violet emission of Ar/CF4and Ar/CF3I capacitively coupled plasmas spectra in the vacuum-ultra violet range (vuv, 30 nm\u2013200\\u2009nm) as well as in the ultra-violet(uv) and visible ranges (uv+vis, 200 nm\u2013800\\u2009nm) were measured from ar/cf3i and ar/cf4 discharges. the discharges were generated in an industrial 300\\u2009mm capacitively coupled plasma source with 27 mhz radio-frequency power. it was seen that the measured spectra were strongly modified. this is mainly due to absorption, especially by cf3i, and ar self-trapping along the line of sight, towards the detector and in the plasma itself. the estimated unabsorbed vuv spectra were revealed from the spectra of mixtures with low fluorocarbon gas content by means of normalization with unabsorbed i* emission, at 206\\u2009nm, and cf2\u2217 band (1b1(0,v\u2032,0)\u21921a1(0,v\u2032\u2032,0)) emission between 230\\u2009nm and 430\\u2009nm. absolute fluences of uv cf2\u2217 emission were derived using hybrid 1-dimensional (1d) particle-in-cell (pic) monte-carlo (mc) model calculations. absolute calibration of the vuv emission was performed using these calculated values from the model, which has never been done previously for real etch conditions in an industrial chamber. it was seen that the argon resonant lines play a significant role in the vuv spectra. these lines are dominant in the case of etching recipes close to the standard ones. the restored unabsorbed spectra confirm that replacement of conventional cf4 etchant gas with cf3i in low-k etching recipes leads to an increase in the overall vuv emission intensity. however, emission from ar exhibited the most intense peaks. damage to low-k sicoh glasses by the estimated vuv was calculated for blanket samples with pristine k-value of 2.2. the calculations were then compared with fourier transform infrared (ftir) data for samples exposed to the similar experimental conditions in the same reactor. it was shown that ar emission plays the most significant role in vuv-induced damage.",
            "contribution_ids": [
                "R141582",
                "R141769"
            ]
        },
        {
            "instance_id": "R141593xR141550",
            "comparison_id": "R141593",
            "paper_id": "R141550",
            "text": "The effect of VUV radiation from Ar/O2plasmas on low-kSiOCH films the degradation of porous low-k materials, like sioch, under plasma processing continues to be a problem in the next generation of integrated-circuit fabrication. due to the exposure of the film to many species during plasma treatment, such as photons, ions, radicals, etc, it is difficult to identify the mechanisms responsible for plasma-induced damage. using a vacuum beam apparatus with a calibrated xe vacuum ultraviolet (vuv) lamp, we show that 147\\u2009nm vuv photons and molecular o2 alone can damage these low-k materials. using fourier-transform infrared (ftir) spectroscopy, we show that vuv/o2 exposure causes a loss of methylated species, resulting in a hydrophilic, siox-like layer that is susceptible to h2o absorption, leading to an increased dielectric constant. the effect of vuv radiation on chemical modification of porous sioch films in the vacuum beam apparatus and in ar and o2 plasma exposure was found to be a significant contributor to dielectric damage. measurements of dielectric constant change using a mercury probe are consistent with chemical modification inferred from ftir analysis. furthermore, the extent of chemical modification appears to be limited by the penetration depth of the vuv photons, which is dependent on wavelength of radiation. the creation of a siox-like layer near the surface of the material, which grows deeper as more methyl is extracted, introduces a dynamic change of vuv absorption throughout the material over time. as a result, the rate of methyl loss is continuously changing during the exposure. we present a model that attempts to capture this dynamic behaviour and compare the model predictions to experimental data through a fitting parameter that represents the effective photo-induced methyl removal. while this model accurately simulates the methyl loss through vuv exposure by the xe lamp and ar plasma, the methyl loss from vuv photons in o2 plasma are only accurately depicted at longer exposure times. we conclude that other species, such as oxygen radicals or ions, may play a major role in chemical modification at short times near the surface of the material, while vuv photons contribute to the majority of the damage in the bulk.",
            "contribution_ids": [
                "R141587",
                "R141774"
            ]
        },
        {
            "instance_id": "R141593xR108938",
            "comparison_id": "R141593",
            "paper_id": "R108938",
            "text": "Prediction of UV spectra and UV-radiation damage in actual plasma etching processes using on-wafer monitoring technique uv radiation during plasma processing affects the surface of materials. nevertheless, the interaction of uv photons with surface is not clearly understood because of the difficulty in monitoring photons during plasma processing. for this purpose, we have previously proposed an on-wafer monitoring technique for uv photons. for this study, using the combination of this on-wafer monitoring technique and a neural network, we established a relationship between the data obtained from the on-wafer monitoring technique and uv spectra. also, we obtained absolute intensities of uv radiation by calibrating arbitrary units of uv intensity with a 126 nm excimer lamp. as a result, uv spectra and their absolute intensities could be predicted with the on-wafer monitoring. furthermore, we developed a prediction system with the on-wafer monitoring technique to simulate uv-radiation damage in dielectric films during plasma etching. uv-induced damage in sioc films was predicted in this study. our prediction results of damage...",
            "contribution_ids": [
                "R141589",
                "R141776"
            ]
        },
        {
            "instance_id": "R141593xR141538",
            "comparison_id": "R141593",
            "paper_id": "R141538",
            "text": "Multifold study of volume plasma chemistry in Ar/CF4and Ar/CHF3CCP discharges low-pressure rf plasma in fluorohydrocarbon gas mixtures is widely used in modern microelectronics, e.g. in the etching of materials with a low dielectric constant (low-k) materials). the multifold experimental and theoretical study of a radio frequency capacitively coupled plasma at 81 mhz in ar/cf4/chf3 has been carried out at 50 mtorr and 150 mtorr gas pressures. a wide set of experimental diagnostics together with hybrid pic mc model calculations were applied to a detailed study of the plasmas. measurements of the f atoms, hf molecules and cfx radicals, electron density, electronegativity and positive ion composition were performed. absolutely calibrated vuv spectrometry was carried out to measure the vuv photon fluence towards the electrode. this combined experimental and model approach allowed us to establish the fundamental mechanisms of the charged and neutral species elementary reactions. dissociative charge transfer reactions and fluoride transfer reactions influence the main ion (cf 3 + , chf 2 + ) composition in ar/cf4/chf3 plasma a lot. the mechanisms of heavy ion formation in ar/chf3 are also discussed. the important role of additional attachment mechanisms (besides dissociative attachment to the feedstock gases, cf4, chf3) was analyzed. the catalytic chain mechanism, including the hf molecules, which defines the cfx kinetics in ar/chf3 plasma, was validated. this multifold approach enabled us to determine the complicated plasma chemical composition of the active species as well as the fluxes of vuv photons at the surface of the processed material, and is a result that is important for understanding low-k damage.",
            "contribution_ids": [
                "R141579",
                "R141766"
            ]
        },
        {
            "instance_id": "R141593xR108948",
            "comparison_id": "R141593",
            "paper_id": "R108948",
            "text": "A microwave plasma source for VUV atmospheric photochemistry microwave plasma discharges working at low pressure are nowadays a well-developed technique mainly used to provide radiations at different wavelengths. the aim of this work is to show that those discharges are an efficient windowless vuv photon source for planetary atmospheric photochemistry experiments. to do this, we use a surfatron-type discharge with a neon gas flow in the mbar pressure range coupled to a photochemical reactor. working in the vuv range allows to focus on nitrogen-dominated atmospheres ({\\\\lambda}<100nm). the experimental setup makes sure that no other energy sources (electrons, metastable atoms) than the vuv photons interact with the reactive medium. neon owns two resonance lines at 73.6 and 74.3 nm which behave differently regarding the pressure or power conditions. in parallel, the vuv photon flux emitted at 73.6 nm has been experimentally estimated in different conditions of pressure and power and varies in a large range between 2x1013 this http url-2 and 4x1014 this http url-2 which is comparable to a vuv synchrotron photon flux. our first case study is the atmosphere of titan and its n2-ch4 atmosphere. with this vuv source, the production of hcn and c2n2, two major titan compounds, is detected, ensuring the suitability of the source for atmospheric photochemistry experiments.",
            "contribution_ids": [
                "R141581",
                "R141768"
            ]
        },
        {
            "instance_id": "R141593xR141447",
            "comparison_id": "R141593",
            "paper_id": "R141447",
            "text": "Evaluation of Absolute Flux of Vacuum Ultraviolet Photons in an Electron Cyclotron Resonance Hydrogen Plasma: Comparison with Ion Flux we compared the absolute flux of positive ions with the flux of photons in a vacuum ultraviolet (vuv) wavelength range in an electron cyclotron resonance hydrogen plasma. the absolute flux of positive ions was measured using a langmuir probe. the absolute flux of vuv photons was evaluated on the basis of the branching ratio between the lyman and balmer lines emitted from electronic states with the same principal quantum numbers. the absolute intensities of the balmer lines were obtained by calibrating the sensitivity of the spectroscopic system using a tungsten standard lamp. it has been found that the flux of vuv photons is, at least, on the comparable order of magnitude with the positive ion flux, suggesting the importance of vuv photons in plasma-induced damage in fabrication processes of ultralarge-scale integrated circuits.",
            "contribution_ids": [
                "R141586",
                "R141773"
            ]
        },
        {
            "instance_id": "R141699xR141656",
            "comparison_id": "R141699",
            "paper_id": "R141656",
            "text": "Natural Biowaste-Cocoon-Derived Granular Activated Carbon-Coated ZnO Nanorods: A Simple Route To Synthesizing a Core\u00e2\u0080\u0093Shell Structure and Its Highly Enhanced UV and Hydrogen Sensing Properties granular activated carbon (gac) materials were prepared via simple gas activation of silkworm cocoons and were coated on zno nanorods (znrs) by the facile hydrothermal method. the present combination of gac and znrs shows a core-shell structure (where the gac is coated on the surface of znrs) and is exposed by systematic material analysis. the as-prepared samples were then fabricated as dual-functional sensors and, most fascinatingly, the as-fabricated core-shell structure exhibits better uv and h2 sensing properties than those of as-fabricated znrs and gac. thus, the present core-shell structure-based h2 sensor exhibits fast responses of 11% (10 ppm) and 23.2% (200 ppm) with ultrafast response and recovery. however, the uv sensor offers an ultrahigh photoresponsivity of 57.9 a w-1, which is superior to that of as-grown znrs (0.6 a w-1). besides this, switching photoresponse of gac/znr core-shell structures exhibits a higher switching ratio (between dark and photocurrent) of 1585, with ultrafast response and recovery, than that of as-grown znrs (40). because of the fast adsorption ability of gac, it was observed that the finest distribution of gac on znrs results in rapid electron transportation between the conduction bands of gac and znrs while sensing h2 and uv. furthermore, the present core-shell structure-based uv and h2 sensors also well-retained excellent sensitivity, repeatability, and long-term stability. thus, the salient feature of this combination is that it provides a dual-functional sensor with biowaste cocoon and zno, which is ecological and inexpensive.",
            "contribution_ids": [
                "R141660"
            ]
        },
        {
            "instance_id": "R141699xR141611",
            "comparison_id": "R141699",
            "paper_id": "R141611",
            "text": "UV-activated room-temperature gas sensing mechanism of polycrystalline ZnO the effects of uv illumination on the electronic properties and gas sensing performance of zno are reported. it is found that uv light improves the sensitivity and the sensor response and recovery rate. by investigating the photoresponse behavior of zno, we observe that the electrons generated by uv light promote the adsorption of oxygen and form the photoinduced oxygen ions [o2\u2212(hv)]. these ions [o2\u2212(hv)] are responsible for the room-temperature gas sensing phenomena and promise enhanced sensor performance through further optimization.",
            "contribution_ids": [
                "R141613"
            ]
        },
        {
            "instance_id": "R141699xR141640",
            "comparison_id": "R141699",
            "paper_id": "R141640",
            "text": "Photoluminescence based H2 and O2 gas sensing by ZnO nanowires \"gas sensing properties of zno nanowires prepared via thermal chemical vapor deposition method were investigated by analyzing change in their photoluminescence (pl) spectra. the as-synthesized nanowires show two different pl peaks positioned at 380\\u2009nm and 520\\u2009nm. the 380\\u2009nm emission is ascribed to near band edge emission, and the green peak (520\\u2009nm) appears due to the oxygen vacancy defects. the intensity of the green pl signal enhances upon hydrogen gas exposure, whereas it gets quenched upon oxygen gas loading. the zno nanowires' sensing response values were observed as about 54% for h2 gas and 9% for o2 gas at room temperature for 50\\u2009sccm h2/o2 gas flow rate. the sensor response was also analyzed as a function of sample temperature ranging from 300\\u2009k to 400\\u2009k. a conclusion was derived from the observations that the h2/o2 gases affect the adsorbed oxygen species on the surface of zno nanowires. the adsorbed species result in the band bending and hence changes the depletion region which causes variation i...\"",
            "contribution_ids": [
                "R141643"
            ]
        },
        {
            "instance_id": "R141723xR141039",
            "comparison_id": "R141723",
            "paper_id": "R141039",
            "text": "A Framework to measure the progress of societies over the last three decades, a number of frameworks have been developed to promote and measure\\nwell-being, quality of life, human development and sustainable development. some frameworks use a\\nconceptual approach while others employ a consultative approach, and different initiatives to measure\\nprogress will require different frameworks. the aim of this paper is to present a proposed framework\\nfor measuring the progress of societies, and to compare it with other progress frameworks that are\\ncurrently in use around the world. the framework does not aim to be definitive, but rather to suggest a\\ncommon starting point that the authors believe is broad-based and flexible enough to be applied in\\nmany situations around the world. it is also the intention that the framework could be used to identify\\ngaps in existing statistical standards and to guide work to fill these gaps.",
            "contribution_ids": [
                "R141041"
            ]
        },
        {
            "instance_id": "R141747xR140879",
            "comparison_id": "R141747",
            "paper_id": "R140879",
            "text": "Is Growth Obsolete? a long decade ago economic growth was the reigning fashion of political economy. it was simultaneously the hottest subject of economic theory and research, a slogan eagerly claimed by politicians of all stripes, and a serious objective of the policies of governments. the climate of opinion has changed dramatically. disillusioned critics indict both economic science and economic policy for blind obeisance to aggregate material \"progress,\" and for neglect of its costly side effects. growth, it is charged, distorts national priorities, worsens the distribution of income, and irreparably damages the environment. paul erlich speaks for a multitude when he says, \"we must acquire a life style which has as its goal maximum freedom and happiness for the individual, not a maximum gross national product.\" growth was in an important sense a discovery of economics after the second world war. of course economic development has always been the grand theme of historically minded scholars of large mind and bold concept, notably marx, schumpeter, kuznets. but the mainstream of economic analysis was not comfortable with phenomena of change and progress. the stationary state was the long-run equilibrium of classical and neoclassical theory, and comparison of alternative static equilibriums was the most powerful theoretical tool. technological change and population increase were most readily accommodated as one-time exogenous shocks; comparative static analysis could be used to tell how they altered the equilibrium of the system. the obvious fact that these \"shocks\" were occurring continuously, never allowing the",
            "contribution_ids": [
                "R140881"
            ]
        },
        {
            "instance_id": "R141752xR141211",
            "comparison_id": "R141752",
            "paper_id": "R141211",
            "text": "Smart Cities in Europe \"urban performance currently depends not only on a city's endowment of hard infrastructure (physical capital), but also, and increasingly so, on the availability and quality of knowledge communication and social infrastructure (human and social capital). the latter form of capital is decisive for urban competitiveness. against this background, the concept of the \u201csmart city\u201d has recently been introduced as a strategic device to encompass modern urban production factors in a common framework and, in particular, to highlight the importance of information and communication technologies (icts) in the last 20 years for enhancing the competitive profile of a city. the present paper aims to shed light on the often elusive definition of the concept of the \u201csmart city.\u201d we provide a focused and operational definition of this construct and present consistent evidence on the geography of smart cities in the eu27. our statistical and graphical analyses exploit in depth, for the first time to our knowledge, the most recent version of the urban audit data set in order to analyze the factors determining the performance of smart cities. we find that the presence of a creative class, the quality of and dedicated attention to the urban environment, the level of education, and the accessibility to and use of icts for public administration are all positively correlated with urban wealth. this result prompts the formulation of a new strategic agenda for european cities that will allow them to achieve sustainable urban development and a better urban landscape.\"",
            "contribution_ids": [
                "R141213",
                "R142077"
            ]
        },
        {
            "instance_id": "R141752xR141227",
            "comparison_id": "R141752",
            "paper_id": "R141227",
            "text": "Modelling the smart city performance this paper aims to offer a profound analysis of the interrelations between smart city components connecting the cornerstones of the triple helix. the triple helix model has emerged as a reference framework for the analysis of knowledge-based innovation systems, and relates the multiple and reciprocal relationships between the three main agencies in the process of knowledge creation and capitalization: university, industry and government. this analysis of the triple helix will be augmented using the analytic network process to model, cluster and begin measuring the performance of smart cities. the model obtained allows interactions and feedbacks within and between clusters, providing a process to derive ratio scales priorities from elements. this offers a more truthful and realistic representation for supporting policy-making. the application of this model is still to be developed, but a full list of indicators, available at urban level, has been identified and selected from literature review.",
            "contribution_ids": [
                "R141229",
                "R142072"
            ]
        },
        {
            "instance_id": "R141752xR141221",
            "comparison_id": "R141752",
            "paper_id": "R141221",
            "text": "Towards a smart State? Inter-agency collaboration, information integration, and beyond information technologies it can now be considered one of the key components of government administrative reform. the potential is even greater when working across organizational boundaries. unfortunately, inter-agency collaboration appears to face an even greater number of challenges than similar it initiatives within a single organization. the challenges include data and technological incompatibility, the lack of institutional incentives to collaborate, and the politics and power struggles around a pervasive silo structure in most governments, among many others. this paper argues that there are clear trends towards greater inter-organizational collaboration, information sharing, and integration, which could lead, in the near future, to what might be called a smart state. the paper starts discussing the promises and challenges that have already been identified for government information sharing and integration initiatives. then it describes two trends in terms of inter-organizational collaboration and information technologies in government settings. the paper ends by providing reflections about the technical and political feasibility, as well as the social desirability, of an integrated virtual state in which the executive, legislative, and judicial branches^1 are actively collaborating and sharing information through the use of advanced information technologies, sophisticated coordination mechanisms, shared physical infrastructure, and, potentially, new organizational and institutional arrangements.",
            "contribution_ids": [
                "R141223",
                "R142074"
            ]
        },
        {
            "instance_id": "R141752xR141265",
            "comparison_id": "R141752",
            "paper_id": "R141265",
            "text": "Distributed Framework for Electronic Democracy in Smart Cities \"architectural modules based on dual citizen and government participation platforms provide an economically viable way to implement, standardize, and scale services and information exchange-functions essential to citizens' participation in a smart city democracy.\"",
            "contribution_ids": [
                "R141267",
                "R141753",
                "R142059"
            ]
        },
        {
            "instance_id": "R141752xR141201",
            "comparison_id": "R141752",
            "paper_id": "R141201",
            "text": "Will the real smart city please stand up?: Intelligent, progressive or entrepreneurial? debates about the future of urban development in many western countries have been increasingly influenced by discussions of smart cities. yet despite numerous examples of this \u2018urban labelling\u2019 phenomenon, we know surprisingly little about so\u2010called smart cities, particularly in terms of what the label ideologically reveals as well as hides. due to its lack of definitional precision, not to mention an underlying self\u2010congratulatory tendency, the main thrust of this article is to provide a preliminary critical polemic against some of the more rhetorical aspects of smart cities. the primary focus is on the labelling process adopted by some designated smart cities, with a view to problematizing a range of elements that supposedly characterize this new urban form, as well as question some of the underlying assumptions/contradictions hidden within the concept. to aid this critique, the article explores to what extent labelled smart cities can be understood as a high\u2010tech variation of the \u2018entrepreneurial city\u2019, as well as speculates on some general principles which would make them more progressive and inclusive.",
            "contribution_ids": [
                "R141203",
                "R142080"
            ]
        },
        {
            "instance_id": "R141752xR141230",
            "comparison_id": "R141752",
            "paper_id": "R141230",
            "text": "Smart Ideas for Smart Cities: Investigating Crowdsourcing for Generating and Selecting Ideas for ICT Innovation in a City Context within this article, the strengths and weaknesses of crowdsourcing for idea generation and idea selection in the context of smart city innovation are investigated. first, smart cities are defined next to similar but different concepts such as digital cities, intelligent cities or ubiquitous cities. it is argued that the smart city-concept is in fact a more user-centered evolution of the other city-concepts which seem to be more technological deterministic in nature. the principles of crowdsourcing are explained and the different manifestations are demonstrated. by means of a case study, the generation of ideas for innovative uses of ict for city innovation by citizens through an online platform is studied, as well as the selection process. for this selection, a crowdsourcing solution is compared to a selection made by external experts. the comparison of both indicates that using the crowd as gatekeeper and selector of innovative ideas yields a long list with high user benefits. however, the generation of ideas in itself appeared not to deliver extremely innovative ideas. crowdsourcing thus appears to be a useful and effective tool in the context of smart city innovation, but should be thoughtfully used and combined with other user involvement approaches and within broader frameworks such as living labs.",
            "contribution_ids": [
                "R141232",
                "R142067"
            ]
        },
        {
            "instance_id": "R141752xR141224",
            "comparison_id": "R141752",
            "paper_id": "R141224",
            "text": "Smart cities in perspective \u00e2\u0080\u0093 a comparative European study by means of self-organizing maps cities form the heart of a dynamic society. in an open space-economy cities have to mobilize all of their resources to remain attractive and competitive. smart cities depend on creative and knowledge resources to maximize their innovation potential. this study offers a comparative analysis of nine european smart cities on the basis of an extensive database covering two time periods. after conducting a principal component analysis, a new approach, based on a self-organizing map analysis, is adopted to position the various cities under consideration according to their selected \u201csmartness\u201d performance indicators.",
            "contribution_ids": [
                "R141226",
                "R142073"
            ]
        },
        {
            "instance_id": "R141752xR141218",
            "comparison_id": "R141752",
            "paper_id": "R141218",
            "text": "Understanding Smart Cities: An Integrative Framework making a city \"smart\" is emerging as a strategy to mitigate the problems generated by the urban population growth and rapid urbanization. yet little academic research has sparingly discussed the phenomenon. to close the gap in the literature about smart cities and in response to the increasing use of the concept, this paper proposes a framework to understand the concept of smart cities. based on the exploration of a wide and extensive array of literature from various disciplinary areas we identify eight critical factors of smart city initiatives: management and organization, technology, governance, policy context, people and communities, economy, built infrastructure, and natural environment. these factors form the basis of an integrative framework that can be used to examine how local governments are envisioning smart city initiatives. the framework suggests directions and agendas for smart city research and outlines practical implications for government professionals.",
            "contribution_ids": [
                "R141220",
                "R141760",
                "R142075"
            ]
        },
        {
            "instance_id": "R141752xR141208",
            "comparison_id": "R141752",
            "paper_id": "R141208",
            "text": "Smart Cities and Sustainability Models in our age cities are complex systems and we can say systems of systems. today locality is the result of using information and communication technologies in all departments of our life, but in future all cities must to use smart systems for improve quality of life and on the other hand for sustainable development. the smart systems make daily activities more easily, efficiently and represent a real support for sustainable city development. this paper analysis the sus-tainable development and identified the key elements of future smart cities.",
            "contribution_ids": [
                "R141210",
                "R142078"
            ]
        },
        {
            "instance_id": "R141780xR141724",
            "comparison_id": "R141780",
            "paper_id": "R141724",
            "text": "Intracellular ratiometric temperature sensing using fluorescent carbon dots a self-referencing dual fluorescing carbon dot-based nanothermometer can ratiometrically sense thermal events in hela cells with very high sensitivity.",
            "contribution_ids": [
                "R141728"
            ]
        },
        {
            "instance_id": "R141780xR141748",
            "comparison_id": "R141780",
            "paper_id": "R141748",
            "text": "Dual functional highly luminescence B, N Co-doped carbon nanodots as nanothermometer and Fe3+/Fe2+ sensor abstract dual functional fluorescence nanosensors have many potential applications in biology and medicine. monitoring temperature with higher precision at localized small length scales or in a nanocavity is a necessity in various applications. as well as the detection of biologically interesting metal ions using low-cost and sensitive approach is of great importance in bioanalysis. in this paper, we describe the preparation of dual-function highly fluorescent b, n-co-doped carbon nanodots (cds) that work as chemical and thermal sensors. the cds emit blue fluorescence peaked at 450\\u2009nm and exhibit up to 70% photoluminescence quantum yield with showing excitation-independent fluorescence. we also show that water-soluble cds display temperature-dependent fluorescence and can serve as highly sensitive and reliable nanothermometers with a thermo-sensitivity 1.8% \u00b0c \u22121 , and wide range thermo-sensing between 0\u201390\\u2009\u00b0c with excellent recovery. moreover, the fluorescence emission of cds are selectively quenched after the addition of fe 2+ and fe 3+ ions while show no quenching with adding other common metal cations and anions. the fluorescence emission shows a good linear correlation with concentration of fe 2+ and fe 3+ (r 2 \\u2009=\\u20090.9908 for fe 2+ and r 2 \\u2009=\\u20090.9892 for fe 3+ ) with a detection limit of of 80.0\\u2009\u00b1\\u20090.5\\u2009nm for fe 2+ and 110.0\\u2009\u00b1\\u20090.5\\u2009nm for fe 3+ . considering the high quantum yield and selectivity, cds are exploited to design a nanoprobe towards iron detection in a biological sample. the fluorimetric assay is used to detect fe 2+ in iron capsules and total iron in serum samples successfully.",
            "contribution_ids": [
                "R141750"
            ]
        },
        {
            "instance_id": "R141780xR141701",
            "comparison_id": "R141780",
            "paper_id": "R141701",
            "text": "Carbon Dot Nanothermometry: Intracellular Photoluminescence Lifetime Thermal Sensing nanoscale biocompatible photoluminescence (pl) thermometers that can be used to accurately and reliably monitor intracellular temperatures have many potential applications in biology and medicine. ideally, such nanothermometers should be functional at physiological ph across a wide range of ionic strengths, probe concentrations, and local environments. here, we show that water-soluble n,s-co-doped carbon dots (cds) exhibit temperature-dependent photoluminescence lifetimes and can serve as highly sensitive and reliable intracellular nanothermometers. pl intensity measurements indicate that these cds have many advantages over alternative semiconductor- and cd-based nanoscale temperature sensors. importantly, their pl lifetimes remain constant over wide ranges of ph values (5-12), cd concentrations (1.5 \u00d7 10-5 to 0.5 mg/ml), and environmental ionic strengths (up to 0.7 mol\u00b7l-1 nacl). moreover, they are biocompatible and nontoxic, as demonstrated by cell viability and flow cytometry analyses using nih/3t3 and hela cell lines. n,s-cd thermal sensors also exhibit good water dispersibility, superior photo- and thermostability, extraordinary environment and concentration independence, high storage stability, and reusability-their pl decay curves at temperatures between 15 and 45 \u00b0c remained unchanged over seven sequential experiments. in vitro pl lifetime-based temperature sensing performed with human cervical cancer hela cells demonstrated the great potential of these nanosensors in biomedicine. overall, n,s-doped cds exhibit excitation-independent emission with strongly temperature-dependent monoexponential decay, making them suitable for both in vitro and in vivo luminescence lifetime thermometry.",
            "contribution_ids": [
                "R141706"
            ]
        },
        {
            "instance_id": "R141782xR141208",
            "comparison_id": "R141782",
            "paper_id": "R141208",
            "text": "Smart Cities and Sustainability Models in our age cities are complex systems and we can say systems of systems. today locality is the result of using information and communication technologies in all departments of our life, but in future all cities must to use smart systems for improve quality of life and on the other hand for sustainable development. the smart systems make daily activities more easily, efficiently and represent a real support for sustainable city development. this paper analysis the sus-tainable development and identified the key elements of future smart cities.",
            "contribution_ids": [
                "R141210",
                "R142078"
            ]
        },
        {
            "instance_id": "R141782xR141211",
            "comparison_id": "R141782",
            "paper_id": "R141211",
            "text": "Smart Cities in Europe \"urban performance currently depends not only on a city's endowment of hard infrastructure (physical capital), but also, and increasingly so, on the availability and quality of knowledge communication and social infrastructure (human and social capital). the latter form of capital is decisive for urban competitiveness. against this background, the concept of the \u201csmart city\u201d has recently been introduced as a strategic device to encompass modern urban production factors in a common framework and, in particular, to highlight the importance of information and communication technologies (icts) in the last 20 years for enhancing the competitive profile of a city. the present paper aims to shed light on the often elusive definition of the concept of the \u201csmart city.\u201d we provide a focused and operational definition of this construct and present consistent evidence on the geography of smart cities in the eu27. our statistical and graphical analyses exploit in depth, for the first time to our knowledge, the most recent version of the urban audit data set in order to analyze the factors determining the performance of smart cities. we find that the presence of a creative class, the quality of and dedicated attention to the urban environment, the level of education, and the accessibility to and use of icts for public administration are all positively correlated with urban wealth. this result prompts the formulation of a new strategic agenda for european cities that will allow them to achieve sustainable urban development and a better urban landscape.\"",
            "contribution_ids": [
                "R141213",
                "R142077"
            ]
        },
        {
            "instance_id": "R141782xR141224",
            "comparison_id": "R141782",
            "paper_id": "R141224",
            "text": "Smart cities in perspective \u00e2\u0080\u0093 a comparative European study by means of self-organizing maps cities form the heart of a dynamic society. in an open space-economy cities have to mobilize all of their resources to remain attractive and competitive. smart cities depend on creative and knowledge resources to maximize their innovation potential. this study offers a comparative analysis of nine european smart cities on the basis of an extensive database covering two time periods. after conducting a principal component analysis, a new approach, based on a self-organizing map analysis, is adopted to position the various cities under consideration according to their selected \u201csmartness\u201d performance indicators.",
            "contribution_ids": [
                "R141226",
                "R142073"
            ]
        },
        {
            "instance_id": "R141782xR141265",
            "comparison_id": "R141782",
            "paper_id": "R141265",
            "text": "Distributed Framework for Electronic Democracy in Smart Cities \"architectural modules based on dual citizen and government participation platforms provide an economically viable way to implement, standardize, and scale services and information exchange-functions essential to citizens' participation in a smart city democracy.\"",
            "contribution_ids": [
                "R141267",
                "R141753",
                "R142059"
            ]
        },
        {
            "instance_id": "R141782xR141233",
            "comparison_id": "R141782",
            "paper_id": "R141233",
            "text": "Smart networked cities? this paper aims to critically assess the lack of a global inter-urban perspective in the smart city policy framework from a conceptual standpoint. we argue here that the smart city policy agenda should be informed by and address the structure of transnational urban networks as this can affect the efficiency of such local policies. the significance of this global network structure is essential as cities do not exist in a vacuum. on the contrary, urban development is heavily based on urban interdependencies found at a global scale. after critically analyzing smart city characteristics and the world city network literature, we identify the need for global urban interdependencies to be addressed in a smart city policy framework. while this paper approaches this issue from a theoretical standpoint, some policy examples are also provided.",
            "contribution_ids": [
                "R141235",
                "R142066"
            ]
        },
        {
            "instance_id": "R141782xR141218",
            "comparison_id": "R141782",
            "paper_id": "R141218",
            "text": "Understanding Smart Cities: An Integrative Framework making a city \"smart\" is emerging as a strategy to mitigate the problems generated by the urban population growth and rapid urbanization. yet little academic research has sparingly discussed the phenomenon. to close the gap in the literature about smart cities and in response to the increasing use of the concept, this paper proposes a framework to understand the concept of smart cities. based on the exploration of a wide and extensive array of literature from various disciplinary areas we identify eight critical factors of smart city initiatives: management and organization, technology, governance, policy context, people and communities, economy, built infrastructure, and natural environment. these factors form the basis of an integrative framework that can be used to examine how local governments are envisioning smart city initiatives. the framework suggests directions and agendas for smart city research and outlines practical implications for government professionals.",
            "contribution_ids": [
                "R141220",
                "R141760",
                "R142075"
            ]
        },
        {
            "instance_id": "R141782xR141230",
            "comparison_id": "R141782",
            "paper_id": "R141230",
            "text": "Smart Ideas for Smart Cities: Investigating Crowdsourcing for Generating and Selecting Ideas for ICT Innovation in a City Context within this article, the strengths and weaknesses of crowdsourcing for idea generation and idea selection in the context of smart city innovation are investigated. first, smart cities are defined next to similar but different concepts such as digital cities, intelligent cities or ubiquitous cities. it is argued that the smart city-concept is in fact a more user-centered evolution of the other city-concepts which seem to be more technological deterministic in nature. the principles of crowdsourcing are explained and the different manifestations are demonstrated. by means of a case study, the generation of ideas for innovative uses of ict for city innovation by citizens through an online platform is studied, as well as the selection process. for this selection, a crowdsourcing solution is compared to a selection made by external experts. the comparison of both indicates that using the crowd as gatekeeper and selector of innovative ideas yields a long list with high user benefits. however, the generation of ideas in itself appeared not to deliver extremely innovative ideas. crowdsourcing thus appears to be a useful and effective tool in the context of smart city innovation, but should be thoughtfully used and combined with other user involvement approaches and within broader frameworks such as living labs.",
            "contribution_ids": [
                "R141232",
                "R142067"
            ]
        },
        {
            "instance_id": "R141782xR141236",
            "comparison_id": "R141782",
            "paper_id": "R141236",
            "text": "Mobile Business and the Smart City: Developing a Business Model Framework to Include Public Design Parameters for Mobile City Services this article proposes a new business model framework that allows the design and analysis of value networks for mobile services in a public context. it starts from a validated business model framework that relies on 12 design parameters to evaluate business models on, and expands it by eight parameters to include important aspects that come into play when a public entity (i.e. a city government) becomes (or wants to become) involved in the value network. this new framework is then applied to the case of the 311 service offered by the city of new york. given the quickly changing power relations in the mobile telecommunications industry, this framework offers both an academic and practical tool, enabling the comparison and analysis of mobile city service business models.",
            "contribution_ids": [
                "R141238",
                "R142065"
            ]
        },
        {
            "instance_id": "R141782xR141227",
            "comparison_id": "R141782",
            "paper_id": "R141227",
            "text": "Modelling the smart city performance this paper aims to offer a profound analysis of the interrelations between smart city components connecting the cornerstones of the triple helix. the triple helix model has emerged as a reference framework for the analysis of knowledge-based innovation systems, and relates the multiple and reciprocal relationships between the three main agencies in the process of knowledge creation and capitalization: university, industry and government. this analysis of the triple helix will be augmented using the analytic network process to model, cluster and begin measuring the performance of smart cities. the model obtained allows interactions and feedbacks within and between clusters, providing a process to derive ratio scales priorities from elements. this offers a more truthful and realistic representation for supporting policy-making. the application of this model is still to be developed, but a full list of indicators, available at urban level, has been identified and selected from literature review.",
            "contribution_ids": [
                "R141229",
                "R142072"
            ]
        },
        {
            "instance_id": "R141783xR108946",
            "comparison_id": "R141783",
            "paper_id": "R108946",
            "text": "Quantification of the VUV radiation in low pressure hydrogen and nitrogen plasmas hydrogen and nitrogen containing discharges emit intense radiation in a broad wavelength region in the vuv. the measured radiant power of individual molecular transitions and atomic lines between 117\\u2009nm and 280\\u2009nm are compared to those obtained in the visible spectral range and moreover to the rf power supplied to the icp discharge. in hydrogen plasmas driven at 540\\u2009w of rf power up to 110\\u2009w are radiated in the vuv, whereas less than 2\\u2009w is emitted in the vis. in nitrogen plasmas the power level of about 25\\u2009w is emitted both in the vuv and in the vis. in hydrogen\u2013nitrogen mixtures, the nh radiation increases the vuv amount. the analysis of molecular and atomic hydrogen emission supported by a collisional radiative model allowed determining plasma parameters and particle densities and thus particle fluxes. a comparison of the fluxes showed that the photon fluxes determined from the measured emission are similar to the ion fluxes, whereas the atomic hydrogen fluxes are by far dominant. photon fluxes up to 5\\u2009\\u2009\u00d7\\u2009\\u20091020 m\u22122 s\u22121 are obtained, demonstrating that the vuv radiation should not be neglected in surface modifications processes, whereas the radiant power converted to vuv photons is to be considered in power balances. varying the admixture of nitrogen to hydrogen offers a possibility to tune photon fluxes in the respective wavelength intervals.",
            "contribution_ids": [
                "R141580",
                "R141767"
            ]
        },
        {
            "instance_id": "R141783xR141535",
            "comparison_id": "R141783",
            "paper_id": "R141535",
            "text": "In situmeasurement of VUV/UV radiation from low-pressure microwave-produced plasma in Ar/O2gas mixtures ultraviolet (uv) and vacuum ultraviolet (vuv) spectral irradiance is determined in low-pressure microwave-produced plasma, which is regularly used for polymer surface treatment. the re-emitted fluorescence in the uv/vis spectral range from a sodium salicylate layer is measured. this fluorescence is related to vuv/uv radiation in different spectral bands based on cut-off filters. the background produced by direct emitted radiation in the fluorescence spectral region is quantified using a specific background filter, thus enabling the use of the whole fluorescence spectral range. a novel procedure is applied to determine the absolute value of the vuv/uv irradiance on a substrate. for that, an independent measurement of the absolute spectral emissivity of the plasma in the uv is performed. the measured irradiances on a substrate from a 25 pa ar/o2-produced plasma are in the range of 1015\u20131016 (photon s\u22121cm\u22122). these values include the contribution from impurities present in the discharge.",
            "contribution_ids": [
                "R141578",
                "R141765"
            ]
        },
        {
            "instance_id": "R141783xR141452",
            "comparison_id": "R141783",
            "paper_id": "R141452",
            "text": "HBr Plasma Treatment Versus VUV Light Treatment to Improve 193\u00e2\u0080\u0089nm Photoresist Pattern Linewidth Roughness we have studied the impact of hbr plasma treatment and the role of the vuv light emitted by this plasma on the chemical modifications and resulting roughness of both blanket and patterned photoresists. the experimental results show that both treatments lead to similar resist bulk chemical modifications that result in a decrease of the resist glass transition temperature (tg). this drop in tg allows polymer chain rearrangement that favors surface roughness smoothening. the smoothening effect is mainly attributed to main chain scission induced by plasma vuv light. for increased vuv light exposure time, the crosslinking mechanism dominates over main chain scission and limits surface roughness smoothening. in the case of the hbr plasma treatment, the synergy between bromine radicals and vuv light leads to the formation of dense graphitized layers on top and sidewalls surfaces of the resist pattern. the presence of a dense layer on the hbr cured resist sidewalls prevents from resist pattern reflowing but on the counter side leads to increased surface roughness and linewidth roughness compared to vuv light treatment.",
            "contribution_ids": [
                "R141588",
                "R141775"
            ]
        },
        {
            "instance_id": "R141783xR108942",
            "comparison_id": "R141783",
            "paper_id": "R108942",
            "text": "Comparison of surface vacuum ultraviolet emissions with resonance level number densities. I. Argon plasmas vacuum ultraviolet (vuv) photons emitted from excited atomic states are ubiquitous in material processing plasmas. the highly energetic photons can induce surface damage by driving surface reactions, disordering surface regions, and affecting bonds in the bulk material. in argon plasmas, the vuv emissions are due to the decay of the 1s4 and 1s2 principal resonance levels with emission wavelengths of 104.8 and 106.7\\u2009nm, respectively. the authors have measured the number densities of atoms in the two resonance levels using both white light optical absorption spectroscopy and radiation-trapping induced changes in the 3p54p\u21923p54s branching fractions measured via visible/near-infrared optical emission spectroscopy in an argon inductively coupled plasma as a function of both pressure and power. an emission model that takes into account radiation trapping was used to calculate the vuv emission rate. the model results were compared to experimental measurements made with a national institute of standards and techn...",
            "contribution_ids": [
                "R141585",
                "R141772"
            ]
        },
        {
            "instance_id": "R141783xR141447",
            "comparison_id": "R141783",
            "paper_id": "R141447",
            "text": "Evaluation of Absolute Flux of Vacuum Ultraviolet Photons in an Electron Cyclotron Resonance Hydrogen Plasma: Comparison with Ion Flux we compared the absolute flux of positive ions with the flux of photons in a vacuum ultraviolet (vuv) wavelength range in an electron cyclotron resonance hydrogen plasma. the absolute flux of positive ions was measured using a langmuir probe. the absolute flux of vuv photons was evaluated on the basis of the branching ratio between the lyman and balmer lines emitted from electronic states with the same principal quantum numbers. the absolute intensities of the balmer lines were obtained by calibrating the sensitivity of the spectroscopic system using a tungsten standard lamp. it has been found that the flux of vuv photons is, at least, on the comparable order of magnitude with the positive ion flux, suggesting the importance of vuv photons in plasma-induced damage in fabrication processes of ultralarge-scale integrated circuits.",
            "contribution_ids": [
                "R141586",
                "R141773"
            ]
        },
        {
            "instance_id": "R141783xR108938",
            "comparison_id": "R141783",
            "paper_id": "R108938",
            "text": "Prediction of UV spectra and UV-radiation damage in actual plasma etching processes using on-wafer monitoring technique uv radiation during plasma processing affects the surface of materials. nevertheless, the interaction of uv photons with surface is not clearly understood because of the difficulty in monitoring photons during plasma processing. for this purpose, we have previously proposed an on-wafer monitoring technique for uv photons. for this study, using the combination of this on-wafer monitoring technique and a neural network, we established a relationship between the data obtained from the on-wafer monitoring technique and uv spectra. also, we obtained absolute intensities of uv radiation by calibrating arbitrary units of uv intensity with a 126 nm excimer lamp. as a result, uv spectra and their absolute intensities could be predicted with the on-wafer monitoring. furthermore, we developed a prediction system with the on-wafer monitoring technique to simulate uv-radiation damage in dielectric films during plasma etching. uv-induced damage in sioc films was predicted in this study. our prediction results of damage...",
            "contribution_ids": [
                "R141589",
                "R141776"
            ]
        },
        {
            "instance_id": "R141783xR108954",
            "comparison_id": "R141783",
            "paper_id": "R108954",
            "text": "Ultraviolet/vacuum-ultraviolet emission from a high power magnetron sputtering plasma with an aluminum target we report the in situ measurement of the ultraviolet/vacuum-ultraviolet (uv/vuv) emission from a plasma produced by high power impulse magnetron sputtering with aluminum target, using argon as background gas. the uv/vuv detection system is based upon the quantification of the re-emitted fluorescence from a sodium salicylate layer that is placed in a housing inside the vacuum chamber, at 11\\u2009cm from the center of the cathode. the detector is equipped with filters that allow for differentiating various spectral regions, and with a front collimating tube that provides a spatial resolution\\u2009\\u2009\u2248\\u2009\\u20090.5\\u2009cm. using various views of the plasma, the measured absolutely calibrated photon rates enable to calculate emissivities and irradiances based on a model of the ionization region. we present results that demonstrate that al+ ions are responsible for most of the vuv irradiance. we also discuss the photoelectric emission due to irradiances on the target produced by high energy photons from resonance lines of ar+.",
            "contribution_ids": [
                "R141576",
                "R141763"
            ]
        },
        {
            "instance_id": "R141783xR108956",
            "comparison_id": "R141783",
            "paper_id": "R108956",
            "text": "VUV radiation flux from argon DC magnetron plasma vacuum ultraviolet (vuv) flux of argon plasma radiation in a dc magnetron discharge with a plane circular titanium cathode is measured. it is found that the intensity of vuv radiation, mainly indicated by the resonance lines of argon atoms at 104.8 and 106.7 nm and ions at 92 and 93.2 nm, is proportional to the discharge current and decreases with pressure. following the results of the measurements, a numerical model of resonance radiation transport is developed to determine the vuv flux to the substrate placed near the sputtering cathode where direct measurements are impossible due to the fast contamination of the detector by sputtered atoms. in the case of a substrate located 10 cm opposite the cathode surface, the upper limit of estimated vuv flux is of the order of 1015 photons\\u2009cm\u22122\\u2009s\u22121 at a coating deposition rate of 1.5 nm\\u2009s\u22121 for 2 and 12 mtorr gas pressures. based on the measurements, the damage to a porous low-k dielectric by vuv radiation during the deposition of barrier layers in the dc magnetron discharge is first estimated.",
            "contribution_ids": [
                "R141575",
                "R141762"
            ]
        },
        {
            "instance_id": "R141783xR141542",
            "comparison_id": "R141783",
            "paper_id": "R141542",
            "text": "Comparison of vacuum ultra-violet emission of Ar/CF4and Ar/CF3I capacitively coupled plasmas spectra in the vacuum-ultra violet range (vuv, 30 nm\u2013200\\u2009nm) as well as in the ultra-violet(uv) and visible ranges (uv+vis, 200 nm\u2013800\\u2009nm) were measured from ar/cf3i and ar/cf4 discharges. the discharges were generated in an industrial 300\\u2009mm capacitively coupled plasma source with 27 mhz radio-frequency power. it was seen that the measured spectra were strongly modified. this is mainly due to absorption, especially by cf3i, and ar self-trapping along the line of sight, towards the detector and in the plasma itself. the estimated unabsorbed vuv spectra were revealed from the spectra of mixtures with low fluorocarbon gas content by means of normalization with unabsorbed i* emission, at 206\\u2009nm, and cf2\u2217 band (1b1(0,v\u2032,0)\u21921a1(0,v\u2032\u2032,0)) emission between 230\\u2009nm and 430\\u2009nm. absolute fluences of uv cf2\u2217 emission were derived using hybrid 1-dimensional (1d) particle-in-cell (pic) monte-carlo (mc) model calculations. absolute calibration of the vuv emission was performed using these calculated values from the model, which has never been done previously for real etch conditions in an industrial chamber. it was seen that the argon resonant lines play a significant role in the vuv spectra. these lines are dominant in the case of etching recipes close to the standard ones. the restored unabsorbed spectra confirm that replacement of conventional cf4 etchant gas with cf3i in low-k etching recipes leads to an increase in the overall vuv emission intensity. however, emission from ar exhibited the most intense peaks. damage to low-k sicoh glasses by the estimated vuv was calculated for blanket samples with pristine k-value of 2.2. the calculations were then compared with fourier transform infrared (ftir) data for samples exposed to the similar experimental conditions in the same reactor. it was shown that ar emission plays the most significant role in vuv-induced damage.",
            "contribution_ids": [
                "R141582",
                "R141769"
            ]
        },
        {
            "instance_id": "R141783xR141538",
            "comparison_id": "R141783",
            "paper_id": "R141538",
            "text": "Multifold study of volume plasma chemistry in Ar/CF4and Ar/CHF3CCP discharges low-pressure rf plasma in fluorohydrocarbon gas mixtures is widely used in modern microelectronics, e.g. in the etching of materials with a low dielectric constant (low-k) materials). the multifold experimental and theoretical study of a radio frequency capacitively coupled plasma at 81 mhz in ar/cf4/chf3 has been carried out at 50 mtorr and 150 mtorr gas pressures. a wide set of experimental diagnostics together with hybrid pic mc model calculations were applied to a detailed study of the plasmas. measurements of the f atoms, hf molecules and cfx radicals, electron density, electronegativity and positive ion composition were performed. absolutely calibrated vuv spectrometry was carried out to measure the vuv photon fluence towards the electrode. this combined experimental and model approach allowed us to establish the fundamental mechanisms of the charged and neutral species elementary reactions. dissociative charge transfer reactions and fluoride transfer reactions influence the main ion (cf 3 + , chf 2 + ) composition in ar/cf4/chf3 plasma a lot. the mechanisms of heavy ion formation in ar/chf3 are also discussed. the important role of additional attachment mechanisms (besides dissociative attachment to the feedstock gases, cf4, chf3) was analyzed. the catalytic chain mechanism, including the hf molecules, which defines the cfx kinetics in ar/chf3 plasma, was validated. this multifold approach enabled us to determine the complicated plasma chemical composition of the active species as well as the fluxes of vuv photons at the surface of the processed material, and is a result that is important for understanding low-k damage.",
            "contribution_ids": [
                "R141579",
                "R141766"
            ]
        },
        {
            "instance_id": "R141783xR141544",
            "comparison_id": "R141783",
            "paper_id": "R141544",
            "text": "OPTIMIZATION OF A SOLAR SIMULATOR FOR PLANETARY-PHOTOCHEMICAL STUDIES low-temperature microwave-powered plasma based on hydrogen and hydrogen with noble gas mixtures are widely used as a continuous vacuum ultraviolet (vuv) source in laboratory experiments carried out to mimic the photochemistry in astrophysical environments. in this work, we present a study dedicated to optimizing such sources in terms of mono-chromaticity at ly\u03b1 (h(ly\u03b1) line at 121.6 nm \u223c 10.2 ev) and high spectral irradiance. we report the influence on the emission spectrum of a wide range of experimental conditions including gas composition (pure h2, pure he, and h2/he mixture), gas pressure, flow rates, and microwave power. the absolute spectral irradiance delivered by this vuv light source has been measured. with a microwave input power of 100 w, the best conditions for producing a quasi-monochromatic source are a 1% h2/he gas mixture at a total pressure of 5 mbar and a flow rate of 2 sccm. by changing the microwave input power from 30 to 120 w, h(ly\u03b1) increases by more than one order of magnitude. a comparison between the current measurements and the solar vuv spectral irradiance is reported over 115\u2013170 nm.",
            "contribution_ids": [
                "R141583",
                "R141770"
            ]
        },
        {
            "instance_id": "R141844xR141039",
            "comparison_id": "R141844",
            "paper_id": "R141039",
            "text": "A Framework to measure the progress of societies over the last three decades, a number of frameworks have been developed to promote and measure\\nwell-being, quality of life, human development and sustainable development. some frameworks use a\\nconceptual approach while others employ a consultative approach, and different initiatives to measure\\nprogress will require different frameworks. the aim of this paper is to present a proposed framework\\nfor measuring the progress of societies, and to compare it with other progress frameworks that are\\ncurrently in use around the world. the framework does not aim to be definitive, but rather to suggest a\\ncommon starting point that the authors believe is broad-based and flexible enough to be applied in\\nmany situations around the world. it is also the intention that the framework could be used to identify\\ngaps in existing statistical standards and to guide work to fill these gaps.",
            "contribution_ids": [
                "R141041"
            ]
        },
        {
            "instance_id": "R142822xR139538",
            "comparison_id": "R142822",
            "paper_id": "R139538",
            "text": "High resolution DNA barcode library for European butterflies reveals continental patterns of mitochondrial genetic diversity abstract the study of global biodiversity will greatly benefit from access to comprehensive dna barcode libraries at continental scale, but such datasets are still very rare. here, we assemble the first high-resolution reference library for european butterflies that provides 97% taxon coverage (459 species) and 22,306 coi sequences. we estimate that we captured 62% of the total haplotype diversity and show that most species possess a few very common haplotypes and many rare ones. specimens in the dataset have an average 95.3% probability of being correctly identified. mitochondrial diversity displayed elevated haplotype richness in southern european refugia, establishing the generality of this key biogeographic pattern for an entire taxonomic group. fifteen percent of the species are involved in barcode sharing, but two thirds of these cases may reflect the need for further taxonomic research. this dataset provides a unique resource for conservation and for studying evolutionary processes, cryptic species, phylogeography, and ecology.",
            "contribution_ids": [
                "R139543",
                "R156950"
            ]
        },
        {
            "instance_id": "R142822xR142517",
            "comparison_id": "R142822",
            "paper_id": "R142517",
            "text": "A DNA barcode library for 5,200 German flies and midges (Insecta: Diptera) and its implications for metabarcoding\u00e2\u0080\u0090based biomonitoring this study summarizes results of a dna barcoding campaign on german diptera, involving analysis of 45,040 specimens. the resultant dna barcode library includes records for 2,453 named species comprising a total of 5,200 barcode index numbers (bins), including 2,700 coi haplotype clusters without species\u2010level assignment, so called \u201cdark taxa.\u201d overall, 88 out of 117 families (75%) recorded from germany were covered, representing more than 50% of the 9,544 known species of german diptera. until now, most of these families, especially the most diverse, have been taxonomically inaccessible. by contrast, within a few years this study provided an intermediate taxonomic system for half of the german dipteran fauna, which will provide a useful foundation for subsequent detailed, integrative taxonomic studies. using dna extracts derived from bulk collections made by malaise traps, we further demonstrate that species delineation using bins and operational taxonomic units (otus) constitutes an effective method for biodiversity studies using dna metabarcoding. as the reference libraries continue to grow, and gaps in the species catalogue are filled, bin lists assembled by metabarcoding will provide greater taxonomic resolution. the present study has three main goals: (a) to provide a dna barcode library for 5,200 bins of diptera; (b) to demonstrate, based on the example of bulk extractions from a malaise trap experiment, that dna barcode clusters, labelled with globally unique identifiers (such as otus and/or bins), provide a pragmatic, accurate solution to the \u201ctaxonomic impediment\u201d; and (c) to demonstrate that interim names based on bins and otus obtained through metabarcoding provide an effective method for studies on species\u2010rich groups that are usually neglected in biodiversity research projects because of their unresolved taxonomy.",
            "contribution_ids": [
                "R142521",
                "R155788"
            ]
        },
        {
            "instance_id": "R142822xR140197",
            "comparison_id": "R142822",
            "paper_id": "R140197",
            "text": "DNA barcodes distinguish species of tropical Lepidoptera although central to much biological research, the identification of species is often difficult. the use of dna barcodes, short dna sequences from a standardized region of the genome, has recently been proposed as a tool to facilitate species identification and discovery. however, the effectiveness of dna barcoding for identifying specimens in species-rich tropical biotas is unknown. here we show that cytochrome c oxidase i dna barcodes effectively discriminate among species in three lepidoptera families from area de conservaci\u00f3n guanacaste in northwestern costa rica. we found that 97.9% of the 521 species recognized by prior taxonomic work possess distinctive cytochrome c oxidase i barcodes and that the few instances of interspecific sequence overlap involve very similar species. we also found two or more barcode clusters within each of 13 supposedly single species. covariation between these clusters and morphological and/or ecological traits indicates overlooked species complexes. if these results are general, dna barcoding will significantly aid species identification and discovery in tropical settings.",
            "contribution_ids": [
                "R140199",
                "R156766"
            ]
        },
        {
            "instance_id": "R142822xR109043",
            "comparison_id": "R142822",
            "paper_id": "R109043",
            "text": "A DNA barcode library for the butterflies of North America although the butterflies of north america have received considerable taxonomic attention, overlooked species and instances of hybridization continue to be revealed. the present study assembles a dna barcode reference library for this fauna to identify groups whose patterns of sequence variation suggest the need for further taxonomic study. based on 14,626 records from 814 species, dna barcodes were obtained for 96% of the fauna. the maximum intraspecific distance averaged 1/4 the minimum distance to the nearest neighbor, producing a barcode gap in 76% of the species. most species (80%) were monophyletic, the others were para- or polyphyletic. although 15% of currently recognized species shared barcodes, the incidence of such taxa was far higher in regions exposed to pleistocene glaciations than in those that were ice-free. nearly 10% of species displayed high intraspecific variation (&gt;2.5%), suggesting the need for further investigation to assess potential cryptic diversity. aside from aiding the identification of all life stages of north american butterflies, the reference library has provided new perspectives on the incidence of both cryptic and potentially over-split species, setting the stage for future studies that can further explore the evolutionary dynamics of this group.",
            "contribution_ids": [
                "R157021",
                "R109045"
            ]
        },
        {
            "instance_id": "R142822xR136201",
            "comparison_id": "R142822",
            "paper_id": "R136201",
            "text": "DNA barcode analysis of butterfly species from Pakistan points towards regional endemism dna barcodes were obtained for 81 butterfly species belonging to 52 genera from sites in north\u2010central pakistan to test the utility of barcoding for their identification and to gain a better understanding of regional barcode variation. these species represent 25% of the butterfly fauna of pakistan and belong to five families, although the nymphalidae were dominant, comprising 38% of the total specimens. barcode analysis showed that maximum conspecific divergence was 1.6%, while there was 1.7\u201314.3% divergence from the nearest neighbour species. barcode records for 55 species showed <2% sequence divergence to records in the barcode of life data systems (bold), but only 26 of these cases involved specimens from neighbouring india and central asia. analysis revealed that most species showed little incremental sequence variation when specimens from other regions were considered, but a threefold increase was noted in a few cases. there was a clear gap between maximum intraspecific and minimum nearest neighbour distance for all 81 species. neighbour\u2010joining cluster analysis showed that members of each species formed a monophyletic cluster with strong bootstrap support. the barcode results revealed two provisional species that could not be clearly linked to known taxa, while 24 other species gained their first coverage. future work should extend the barcode reference library to include all butterfly species from pakistan as well as neighbouring countries to gain a better understanding of regional variation in barcode sequences in this topographically and climatically complex region.",
            "contribution_ids": [
                "R156999",
                "R136203"
            ]
        },
        {
            "instance_id": "R142822xR142471",
            "comparison_id": "R142822",
            "paper_id": "R142471",
            "text": "DNA barcoding of Northern Nearctic Muscidae (Diptera) reveals high correspondence between morphological and molecular species limits abstract \\n \\n background \\n various methods have been proposed to assign unknown specimens to known species using their dna barcodes, while others have focused on using genetic divergence thresholds to estimate \u201cspecies\u201d diversity for a taxon, without a well-developed taxonomy and/or an extensive reference library of dna barcodes. the major goals of the present work were to: a) conduct the largest species-level barcoding study of the muscidae to date and characterize the range of genetic divergence values in the northern nearctic fauna; b) evaluate the correspondence between morphospecies and barcode groupings defined using both clustering-based and threshold-based approaches; and c) use the reference library produced to address taxonomic issues. \\n \\n \\n results \\n our data set included 1114 individuals and their coi sequences (951 from churchill, manitoba), representing 160 morphologically-determined species from 25 genera, covering 89% of the known fauna of churchill and 23% of the nearctic fauna. following an iterative process through which all specimens belonging to taxa with anomalous divergence values and/or monophyly issues were re-examined, identity was modified for 9 taxa, including the reinstatement of phaonia luteva (walker) stat. nov. as a species distinct from phaonia errans (meigen). in the post-reassessment data set, no distinct gap was found between maximum pairwise intraspecific distances (range 0.00-3.01%) and minimum interspecific distances (range: 0.77-11.33%). nevertheless, using a clustering-based approach, all individuals within 98% of species grouped with their conspecifics with high (&gt;95%) bootstrap support; in contrast, a maximum species discrimination rate of 90% was obtained at the optimal threshold of 1.2%. dna barcoding enabled the determination of females from 5 ambiguous species pairs and confirmed that 16 morphospecies were genetically distinct from named taxa. there were morphological differences among all distinct genetic clusters; thus, no cases of cryptic species were detected. \\n \\n \\n conclusions \\n our findings reveal the great utility of building a well-populated, species-level reference barcode database against which to compare unknowns. when such a library is unavailable, it is still possible to obtain a fairly accurate (within ~10%) rapid assessment of species richness based upon a barcode divergence threshold alone, but this approach is most accurate when the threshold is tuned to a particular taxon. \\n",
            "contribution_ids": [
                "R142473",
                "R155793"
            ]
        },
        {
            "instance_id": "R142822xR139546",
            "comparison_id": "R142822",
            "paper_id": "R139546",
            "text": "A DNA barcode reference library for Swiss butterflies and forester moths as a tool for species identification, systematics and conservation butterfly monitoring and red list programs in switzerland rely on a combination of observations and collection records to document changes in species distributions through time. while most butterflies can be identified using morphology, some taxa remain challenging, making it difficult to accurately map their distributions and develop appropriate conservation measures. in this paper, we explore the use of the dna barcode (a fragment of the mitochondrial gene coi) as a tool for the identification of swiss butterflies and forester moths (rhopalocera and zygaenidae). we present a national dna barcode reference library including 868 sequences representing 217 out of 224 resident species, or 96.9% of swiss fauna. dna barcodes were diagnostic for nearly 90% of swiss species. the remaining 10% represent cases of para- and polyphyly likely involving introgression or incomplete lineage sorting among closely related taxa. we demonstrate that integrative taxonomic methods incorporating a combination of morphological and genetic techniques result in a rate of species identification of over 96% in females and over 98% in males, higher than either morphology or dna barcodes alone. we explore the use of the dna barcode for exploring boundaries among taxa, understanding the geographical distribution of cryptic diversity and evaluating the status of purportedly endemic taxa. finally, we discuss how dna barcodes may be used to improve field practices and ultimately enhance conservation strategies.",
            "contribution_ids": [
                "R139549",
                "R156861"
            ]
        },
        {
            "instance_id": "R142822xR140252",
            "comparison_id": "R142822",
            "paper_id": "R140252",
            "text": "Species-Level Para- and Polyphyly in DNA Barcode Gene Trees: Strong Operational Bias in European Lepidoptera the proliferation of dna data is revolutionizing all fields of systematic research. dna barcode sequences, now available for millions of specimens and several hundred thousand species, are increasingly used in algorithmic species delimitations. this is complicated by occasional incongruences between species and gene genealogies, as indicated by situations where conspecific individuals do not form a monophyletic cluster in a gene tree. in two previous reviews, non-monophyly has been reported as being common in mitochondrial dna gene trees. we developed a novel web service \u201cmonophylizer\u201d to detect non-monophyly in phylogenetic trees and used it to ascertain the incidence of species non-monophyly in coi (a.k.a. cox1) barcode sequence data from 4977 species and 41,583 specimens of european lepidoptera, the largest data set of dna barcodes analyzed from this regard. particular attention was paid to accurate species identification to ensure data integrity. we investigated the effects of tree-building method, sampling effort, and other methodological issues, all of which can influence estimates of non-monophyly. we found a 12% incidence of non-monophyly, a value significantly lower than that observed in previous studies. neighbor joining (nj) and maximum likelihood (ml) methods yielded almost equal numbers of non-monophyletic species, but 24.1% of these cases of non-monophyly were only found by one of these methods. non-monophyletic species tend to show either low genetic distances to their nearest neighbors or exceptionally high levels of intraspecific variability. cases of polyphyly in coi trees arising as a result of deep intraspecific divergence are negligible, as the detected cases reflected misidentifications or methodological errors. taking into consideration variation in sampling effort, we estimate that the true incidence of non-monophyly is \u223c23%, but with operational factors still being included. within the operational factors, we separately assessed the frequency of taxonomic limitations (presence of overlooked cryptic and oversplit species) and identification uncertainties. we observed that operational factors are potentially present in more than half (58.6%) of the detected cases of non-monophyly. furthermore, we observed that in about 20% of non-monophyletic species and entangled species, the lineages involved are either allopatric or parapatric\u2014conditions where species delimitation is inherently subjective and particularly dependent on the species concept that has been adopted. these observations suggest that species-level non-monophyly in coi gene trees is less common than previously supposed, with many cases reflecting misidentifications, the subjectivity of species delimitation or other operational factors.",
            "contribution_ids": [
                "R140254",
                "R156759"
            ]
        },
        {
            "instance_id": "R142822xR139497",
            "comparison_id": "R142822",
            "paper_id": "R139497",
            "text": "Congruence between morphology-based species and Barcode Index Numbers (BINs) in Neotropical Eumaeini (Lycaenidae) \\n background \\n with about 1,000 species in the neotropics, the eumaeini (theclinae) are one of the most diverse butterfly tribes. correct morphology-based identifications are challenging in many genera due to relatively little interspecific differences in wing patterns. geographic infraspecific variation is sometimes more substantial than variation between species. in this paper we present a large dna barcode dataset of south american lycaenidae. we analyze how well dna barcode bins match morphologically delimited species. \\n \\n \\n methods \\n we compare morphology-based species identifications with the clustering of molecular operational taxonomic units (motus) delimitated by the resl algorithm in bold, which assigns barcode index numbers (bins). we examine intra- and interspecific divergences for genera represented by at least four morphospecies. we discuss the existence of local barcode gaps in a genus by genus analysis. we also note differences in the percentage of species with barcode gaps in groups of lowland and high mountain genera. \\n \\n \\n results \\n we identified 2,213 specimens and obtained 1,839 sequences of 512 species in 90 genera. overall, the mean intraspecific divergence value of co1 sequences was 1.20%, while the mean interspecific divergence between nearest congeneric neighbors was 4.89%, demonstrating the presence of a barcode gap. however, the gap seemed to disappear from the entire set when comparing the maximum intraspecific distance (8.40%) with the minimum interspecific distance (0.40%). clear barcode gaps are present in many genera but absent in others. from the set of specimens that yielded coi fragment lengths of at least 650 bp, 75% of the a priori morphology-based identifications were unambiguously assigned to a single barcode index number (bin). however, after a taxonomic a posteriori review, the percentage of matched identifications rose to 85%. bin splitting was observed for 17% of the species and bin sharing for 9%. we found that genera that contain primarily lowland species show higher percentages of local barcode gaps and congruence between bins and morphology than genera that contain exclusively high montane species. the divergence values to the nearest neighbors were significantly lower in high andean species while the intra-specific divergence values were significantly lower in the lowland species. these results raise questions regarding the causes of observed low inter and high intraspecific genetic variation. we discuss incomplete lineage sorting and hybridization as most likely causes of this phenomenon, as the montane species concerned are relatively young and hybridization is probable. the release of our data set represents an essential baseline for a reference library for biological assessment studies of butterflies in mega diverse countries using modern high-throughput technologies an highlights the necessity of taxonomic revisions for various genera combining both molecular and morphological data. \\n",
            "contribution_ids": [
                "R139502",
                "R156958"
            ]
        },
        {
            "instance_id": "R142822xR108960",
            "comparison_id": "R142822",
            "paper_id": "R108960",
            "text": "Use of species delimitation approaches to tackle the cryptic diversity of an assemblage of high Andean butterflies (Lepidoptera: Papilionoidea) cryptic biological diversity has generated ambiguity in taxonomic and evolutionary studies. single-locus methods and other approaches for species delimitation are useful for addressing this challenge, enabling the practical processing of large numbers of samples for identification and inventory purposes. this study analyzed an assemblage of high andean butterflies using dna barcoding and compared the identifications based on the current morphological taxonomy with three methods of species delimitation (automatic barcode gap discovery, generalized mixed yule coalescent model, and poisson tree processes). sixteen potential cryptic species were recognized using these three methods, representing a net richness increase of 11.3% in the assemblage. a well-studied taxon of the genus vanessa, which has a wide geographical distribution, appeared with the potential cryptic species that had a higher genetic differentiation at the local level than at the continental level. the analyses were useful for identifying the potential cryptic species in pedaliodes and forsterinaria complexes, which also show differentiation along altitudinal and latitudinal gradients. this genetic assessment of an entire assemblage of high andean butterflies (papilionoidea) provides baseline information for future research in a region characterized by high rates of endemism and population isolation.",
            "contribution_ids": [
                "R157029",
                "R108962"
            ]
        },
        {
            "instance_id": "R142822xR138551",
            "comparison_id": "R142822",
            "paper_id": "R138551",
            "text": "Probing planetary biodiversity with DNA barcodes: The Noctuoidea of North America this study reports the assembly of a dna barcode reference library for species in the lepidopteran superfamily noctuoidea from canada and the usa. based on the analysis of 69,378 specimens, the library provides coverage for 97.3% of the noctuoid fauna (3565 of 3664 species). in addition to verifying the strong performance of dna barcodes in the discrimination of these species, the results indicate close congruence between the number of species analyzed (3565) and the number of sequence clusters (3816) recognized by the barcode index number (bin) system. distributional patterns across 12 north american ecoregions are examined for the 3251 species that have gps data while bin analysis is used to quantify overlap between the noctuoid faunas of north america and other zoogeographic regions. this analysis reveals that 90% of north american noctuoids are endemic and that just 7.5% and 1.8% of bins are shared with the neotropics and with the palearctic, respectively. one third (29) of the latter species are recent introductions and, as expected, they possess low intraspecific divergences.",
            "contribution_ids": [
                "R156994",
                "R138554"
            ]
        },
        {
            "instance_id": "R142850xR142744",
            "comparison_id": "R142850",
            "paper_id": "R142744",
            "text": "Hybrid Nanocrystals: Achieving Concurrent Therapeutic and Bioimaging Functionalities toward Solid Tumors bioimaging and therapeutic agents accumulated in ectopic tumors following intravenous administration of hybrid nanocrystals to tumor-bearing mice. solid, nanosized paclitaxel crystals physically incorporated fluorescent molecules throughout the crystal lattice and retained fluorescent properties in the solid state. hybrid nanocrystals were significantly localized in solid tumors and remained in the tumor for several days. an anticancer effect is expected of these hybrid nanocrystals.",
            "contribution_ids": [
                "R142746"
            ]
        },
        {
            "instance_id": "R142850xR142718",
            "comparison_id": "R142850",
            "paper_id": "R142718",
            "text": "Cellular Uptake Mechanism of Paclitaxel Nanocrystals Determined by Confocal Imaging and Kinetic Measurement nanocrystal formulation has become a viable solution for delivering poorly soluble drugs including chemotherapeutic agents. the purpose of this study was to examine cellular uptake of paclitaxel nanocrystals by confocal imaging and concentration measurement. it was found that drug nanocrystals could be internalized by kb cells at much higher concentrations than a conventional, solubilized formulation. the imaging and quantitative results suggest that nanocrystals could be directly taken up by cells as solid particles, likely via endocytosis. moreover, it was found that polymer treatment to drug nanocrystals, such as surface coating and lattice entrapment, significantly influenced the cellular uptake. while drug molecules are in the most stable physical state, nanocrystals of a poorly soluble drug are capable of achieving concentrated intracellular presence enabling needed therapeutic effects.",
            "contribution_ids": [
                "R142720"
            ]
        },
        {
            "instance_id": "R144121xR144100",
            "comparison_id": "R144121",
            "paper_id": "R144100",
            "text": "Towards Ontology Learning from Folksonomies a folksonomy refers to a collection of user-defined tags with which users describe contents published on the web. with the flourish of web 2.0, folksonomies have become an important mean to develop the semantic web. because tags in folksonomies are authored freely, there is a need to understand the structure and semantics of these tags in various applications. in this paper, we propose a learning approach to create an ontology that captures the hierarchical semantic structure of folksonomies. our experimental results on two different genres of real world data sets show that our method can effectively learn the ontology structure from the folksonomies.",
            "contribution_ids": [
                "R144102",
                "R144109",
                "R144110"
            ]
        },
        {
            "instance_id": "R144121xR143899",
            "comparison_id": "R144121",
            "paper_id": "R143899",
            "text": "An Integrated Approach to Drive Ontological Structure from Folksonomie web 2.0 is an evolution toward a more social, interactive and collaborative web, where user is at the center of service in terms of publications and reactions. this transforms the user from his old status as a consumer to a new one as a producer. folksonomies are one of the technologies of web 2.0 that permit users to annotate resources on the web. this is done by allowing users to use any keyword or tag that they find relevant. although folksonomies require a context-independent and inter-subjective definition of meaning, many researchers have proven the existence of an implicit semantics in these unstructured data. in this paper, we propose an improvement of our previous approach to extract ontological structures from folksonomies. the major contributions of this paper are a normalized co-occurrences in distinct users (ncdu) similarity measure, and a new algorithm to define context of tags and detect ambiguous ones. we compared our similarity measure to a widely used method for identifying similar tags based on the cosine measure. we also compared the new algorithm with the fuzzy clustering algorithm (fcm) used in our original approach. the evaluation shows promising results and emphasizes the advantage of our approach.",
            "contribution_ids": [
                "R143901",
                "R143914",
                "R143915"
            ]
        },
        {
            "instance_id": "R144512xR144491",
            "comparison_id": "R144512",
            "paper_id": "R144491",
            "text": "Curcumin Loaded-PLGA Nanoparticles Conjugated with Tet-1 Peptide for Potential Use in Alzheimer's Disease \"alzheimer's disease is a growing concern in the modern world. as the currently available medications are not very promising, there is an increased need for the fabrication of newer drugs. curcumin is a plant derived compound which has potential activities beneficial for the treatment of alzheimer's disease. anti-amyloid activity and anti-oxidant activity of curcumin is highly beneficial for the treatment of alzheimer's disease. the insolubility of curcumin in water restricts its use to a great extend, which can be overcome by the synthesis of curcumin nanoparticles. in our work, we have successfully synthesized water-soluble plga coated- curcumin nanoparticles and characterized it using different techniques. as drug targeting to diseases of cerebral origin are difficult due to the stringency of blood-brain barrier, we have coupled the nanoparticle with tet-1 peptide, which has the affinity to neurons and possess retrograde transportation properties. our results suggest that curcumin encapsulated-plga nanoparticles are able to destroy amyloid aggregates, exhibit anti-oxidative property and are non-cytotoxic. the encapsulation of the curcumin in plga does not destroy its inherent properties and so, the plga-curcumin nanoparticles can be used as a drug with multiple functions in treating alzheimer's disease proving it to be a potential therapeutic tool against this dreaded disease.\"",
            "contribution_ids": [
                "R144492"
            ]
        },
        {
            "instance_id": "R144512xR144485",
            "comparison_id": "R144512",
            "paper_id": "R144485",
            "text": "PLGA nanoparticles modified with a BBB-penetrating peptide co-delivering A\u00ce\u00b2 generation inhibitor and curcumin attenuate memory deficits and neuropathology in Alzheimer's disease mice \"alzheimer's disease (ad) is the most common form of dementia, characterized by the formation of extracellular senile plaques and neuronal loss caused by amyloid \u03b2 (a\u03b2) aggregates in the brains of ad patients. conventional strategies failed to treat ad in clinical trials, partly due to the poor solubility, low bioavailability and ineffectiveness of the tested drugs to cross the blood-brain barrier (bbb). moreover, ad is a complex, multifactorial neurodegenerative disease; one-target strategies may be insufficient to prevent the processes of ad. here, we designed novel kind of poly(lactide-co-glycolic acid) (plga) nanoparticles by loading with a\u03b2 generation inhibitor s1 (pqvghl peptide) and curcumin to target the detrimental factors in ad development and by conjugating with brain targeting peptide crt (cyclic crtigpsvc peptide), an iron-mimic peptide that targets transferrin receptor (tfr), to improve bbb penetration. the average particle size of drug-loaded plga nanoparticles and crt-conjugated plga nanoparticles were 128.6 nm and 139.8 nm, respectively. the results of y-maze and new object recognition test demonstrated that our plga nanoparticles significantly improved the spatial memory and recognition in transgenic ad mice. moreover, plga nanoparticles remarkably decreased the level of a\u03b2, reactive oxygen species (ros), tnf-\u03b1 and il-6, and enhanced the activities of super oxide dismutase (sod) and synapse numbers in the ad mouse brains. compared with other plga nanoparticles, crt peptide modified-plga nanoparticles co-delivering s1 and curcumin exhibited most beneficial effect on the treatment of ad mice, suggesting that conjugated crt peptide, and encapsulated s1 and curcumin exerted their corresponding functions for the treatment.\"",
            "contribution_ids": [
                "R144487"
            ]
        },
        {
            "instance_id": "R145685xR145222",
            "comparison_id": "R145685",
            "paper_id": "R145222",
            "text": "On the Stark Broadening of Be II Spectral Lines stark broadening parameters, full widths at half maximum (fwhm) and shifts for 13 os ii lines have been calculated. the plasma parameters are: electron density of 1017 cm-3 and temperatures from 5 000 k to 80 000 k. calculations have been performed with the simplified modified semiempirical (smse) approach. the results are also used for the consideration of strak width and shift regularities within the os ii 6s6d-6p6do multiplet.",
            "contribution_ids": [
                "R145242"
            ]
        },
        {
            "instance_id": "R145685xR145171",
            "comparison_id": "R145685",
            "paper_id": "R145171",
            "text": "General Impact Theory of Pressure Broadening the work of two previous papers is extended and a theory of pressure broadening is developed which treats the perturbers quantum mechanically and allows fur inelastic collisions, degeneracy, and overlapping lines. the impact approximation is used. it consists in assuming that it takes, on the average, many collisions to produce an appreciable disturbance in the wave function of the atom, and it results in an isolated line having a lorentz shape. validity criteria are given. when the approximation is valid, it is allowable to replace the exact, fluctuating interaction of the perturbers with the atom by a constant effective interaction. the effective interaction is expressed in terms of the one-perturber quantum mechanical transition amplitudes on and near the energy shell and its close relationship to the scattering matrix is stressed. the calculation of the line shape in terms of the effective interaction is the same as when the perturbers move on classical paths. results are written explicitly fur isolated lines. if the interaction of the perturbers with the final state can be neglected, the shift and width are proportional to the real and imaginary part of the forward elastic scattering amplitude, respectively. by the optical theorem, the width can alsomore\\xa0\u00bb be written in terms of the total cross section. when the interaction in the final state cannot be neglected, the shift and width are still given in terms of the elastic scattering amplitudes, in a slightly more complicated fashion. finally, rules are given for taking into account rotational degeneracy of the radiating states. (auth)\u00ab\\xa0less",
            "contribution_ids": [
                "R145224"
            ]
        },
        {
            "instance_id": "R145685xR145191",
            "comparison_id": "R145685",
            "paper_id": "R145191",
            "text": "A theoretical study of the plasma broadening of helium-like transitions for high-Z emitters calculations of the spectral line broadening for 1s2 1s-1snp 1p transitions in helium-like ions have been performed for emitters with relatively high z (silicon and argon). these calculations illustrate the plasma dependent shifts and asymmetries which are due to the high emitter charge. a discussion of the effects is presented, with particular reference to the deviations from the corresponding hydrogenic line profiles.",
            "contribution_ids": [
                "R145231"
            ]
        },
        {
            "instance_id": "R145685xR145219",
            "comparison_id": "R145685",
            "paper_id": "R145219",
            "text": "Stark broadening and atomic data for Ar XVI stark broadening and atomic data calculations have been developed for the recent years, especially atomic and line broadening data for highly ionized ions of argon. we present in this paper atomic data (such as energy levels, line strengths, oscillator strengths and radiative decay rates) for ar xvi ion and quantum stark broadening calculations for 10 ar xvi lines. radiative atomic data for this ion have been calculated using the university college london (ucl) codes (superstructure, distorted wave, jajom) and have been compared with other results. using our quantum mechanical method, our stark broadening calculations for ar xvi lines are performed at electron density ne = 10 20 cm\u22123 and for electron temperature varying from 7.5\u00d710 to 7.5\u00d710 k. no stark broadening results in the literature to compare with. so, our results come to fill this lack of data.",
            "contribution_ids": [
                "R145241"
            ]
        },
        {
            "instance_id": "R145685xR145188",
            "comparison_id": "R145685",
            "paper_id": "R145188",
            "text": "Stark-profile calculations for Lyman-series lines of one-electron ions in dense plasmas the frequency distributions of the first six lyman lines of hydrogen-like carbon, oxygen, neon, magnesium, aluminum, and silicon ions broadened by the local fields of both ions and electrons are calculated for dense plasmas. the electron collisions are treated by an impact theory allowing (approximately) for level splittings caused by the ion fields, finite duration of the collisions, and screening of the electron fields. ion effects are calculated in the quasistatic, linear stark-effect approximation, using distribution functions of hooper and tighe which include correlation and shielding effects. theoretical uncertainties from the various approximations are estimated, and the scaling of the profiles with density, temperature and nuclear charge is discussed. a correction for the effects caused by low frequency field fluctuations is suggested.",
            "contribution_ids": [
                "R145230"
            ]
        },
        {
            "instance_id": "R145685xR145177",
            "comparison_id": "R145685",
            "paper_id": "R145177",
            "text": "Stark Broadening of Hydrogen Lines in a Plasma the frequency distributions of hydrogen lines broadened by the local fields of both ions and electrons in a plasma are calculated in the classical path approximation. the electron collisions are treated by an impact theory which takes into account the stark splitting caused by the quasistatic ion fields. the ion field-strength distribution function used includes the effect of electron shielding and ion-ion correlations. the various approximations that were employed are examined for self-consistency and an accuracy of about 10% in the resulting line profiles is expected. good agreement with experimental h/sub beta / profiles is obtained while there are deviations of factors of two with the usual holtsmark theory. asymptotic distributions for the line wings are given for astrophysical applications. also here the electron effects are generally as important as the ion effects for all values of the electron density and in some cases the electron broadening is larger than the ion broadening. (auth)",
            "contribution_ids": [
                "R145226"
            ]
        },
        {
            "instance_id": "R145685xR145205",
            "comparison_id": "R145685",
            "paper_id": "R145205",
            "text": "Atomic data for opacity calculations. VIII. Line-profile parameters for 42 transitions in Li-like and Be-like ions widths and shifts are calculated in the electron impact approximation, using close-coupling theory, for the transitions 2s-2p, 2s-3p, 2p-3s, 2p-3d, 3s-3p and 3p-3d in be ii, b iii, c iv, o vi and ne viii, and the transitions 2s2 1s-2s2p 1po, 2s2p 3po-2p2 3p, 2s2p 1po-2p2 1d and 1s in c iii, o v and ne vii. results are compared with those from previous calculations and from experiments. approximate formulae must be used to estimate linewidths for some 106 transitions which are of importance for the calculation of stellar envelope opacities. results for the quantum mechanical calculations for 42 transitions are used to obtain provisional best estimates for the parameters in these formulae.",
            "contribution_ids": [
                "R145236"
            ]
        },
        {
            "instance_id": "R145685xR145216",
            "comparison_id": "R145685",
            "paper_id": "R145216",
            "text": "Relativistic quantum mechanical calculations of electron-impact broadening for spectral lines in Be-like ions aims. we present relativistic quantum mechanical calculations of electron-impact broadening of the singlet and triplet transition 2s3s \u2190 2s3p in four be-like ions from niv to nevii. methods. in our theoretical calculations, the k-matrix and related symmetry information determined by the colliding systems are generated by the darc codes. results. a careful comparison between our calculations and experimental results shows good agreement. our calculated widths of spectral lines also agree with earlier theoretical results. our investigations provide new methods of calculating electron-impact broadening parameters for plasma diagnostics.",
            "contribution_ids": [
                "R145240"
            ]
        },
        {
            "instance_id": "R145685xR145200",
            "comparison_id": "R145685",
            "paper_id": "R145200",
            "text": "Line shapes of lithium-like ions emitted from plasmas the calculation of the spectral line broadening of lithium-like ions is presented. the motivation for these calculations is to extend present theoretical calculations to more complex atomic structures and provide further diagnostic possibilities. the profiles of li i, ti xx and br xxxiii are shown as a representative sampling of the possible effects which can occur. the calculations are performed for all level 2 to level 3 and 4 transitions, with dipole-forbidden and overlapping components fully taken into account.",
            "contribution_ids": [
                "R145234"
            ]
        },
        {
            "instance_id": "R145950xR142721",
            "comparison_id": "R145950",
            "paper_id": "R142721",
            "text": "The SEAS Knowledge Model this deliverable concentrates on the results of task 2.2 of work package 2. it describes the seas knowledge model as a basis for semantic interoperability in the seas ecosystem. the seas knowledge model consists of an innovative web ontology that is designed to: (i) meet the current best practices in terms of quality, metadata, and publication, (ii) reuse or align to existing standards, and (iii) cover the required expressivity for the seas use cases, while being extensible to other use cases and domains (gas, water, air, waste management). this document is a snapshot of the situation at the end of the seas project. up-to-date information can be found at the following websites: https://w3id.org/seas/ for the seas knowledge model, and contributing to it; https://w3id.org/pep/ for the process executor platform ontology. deliverable d2.2 seas knowledge model 2 19 december 2016 version 1.0 smart energy aware systems itea2 \u2013 12004",
            "contribution_ids": [
                "R142723",
                "R142755",
                "R143941",
                "R143943",
                "R144802",
                "R144803"
            ]
        },
        {
            "instance_id": "R145950xR142729",
            "comparison_id": "R145950",
            "paper_id": "R142729",
            "text": "CityPulse: Large Scale Data Analytics Framework for Smart Cities \"our world and our lives are changing in many ways. communication, networking, and computing technologies are among the most influential enablers that shape our lives today. digital data and connected worlds of physical objects, people, and devices are rapidly changing the way we work, travel, socialize, and interact with our surroundings, and they have a profound impact on different domains, such as healthcare, environmental monitoring, urban systems, and control and management applications, among several other areas. cities currently face an increasing demand for providing services that can have an impact on people's everyday lives. the citypulse framework supports smart city service creation by means of a distributed system for semantic discovery, data analytics, and interpretation of large-scale (near-)real-time internet of things data and social media data streams. to goal is to break away from silo applications and enable cross-domain data integration. the citypulse framework integrates multimodal, mixed quality, uncertain and incomplete data to create reliable, dependable information and continuously adapts data processing techniques to meet the quality of information requirements from end users. different than existing solutions that mainly offer unified views of the data, the citypulse framework is also equipped with powerful data analytics modules that perform intelligent data aggregation, event detection, quality assessment, contextual filtering, and decision support. this paper presents the framework, describes its components, and demonstrates how they interact to support easy development of custom-made applications for citizens. the benefits and the effectiveness of the framework are demonstrated in a use-case scenario implementation presented in this paper.\"",
            "contribution_ids": [
                "R142731",
                "R143938",
                "R144797"
            ]
        },
        {
            "instance_id": "R145950xR142756",
            "comparison_id": "R145950",
            "paper_id": "R142756",
            "text": "Smart City Ontologies: Improving the effectiveness of smart city applications this paper addresses the problem of low impact of smart city applications observed in the fields of energy and transport, which constitute high-priority domains for the development of smart cities. however, these are not the only fields where the impact of smart cities has been limited. the paper provides an explanation for the low impact of various individual applications of smart cities and discusses ways of improving their effectiveness. we argue that the impact of applications depends primarily on their ontology, and secondarily on smart technology and programming features. consequently, we start by creating an overall ontology for the smart city, defining the building blocks of this ontology with respect to the most cited definitions of smart cities, and structuring this ontology with the prot\u00e9g\u00e9 5.0 editor, defining entities, class hierarchy, object properties, and data type properties. we then analyze how the ontologies of a sample of smart city applications fit into the overall smart city ontology, the consistency between digital spaces, knowledge processes, city domains targeted by the applications, and the types of innovation that determine their impact. in conclusion, we underline the relationships between innovation and ontology, and discuss how we can improve the effectiveness of smart city applications, combining expert and user-driven ontology design with the integration and or-chestration of applications over platforms and larger city entities such as neighborhoods, districts, clusters, and sectors of city activities.",
            "contribution_ids": [
                "R142758",
                "R143685",
                "R144786"
            ]
        },
        {
            "instance_id": "R145950xR142764",
            "comparison_id": "R145950",
            "paper_id": "R142764",
            "text": "The modular SSN ontology: A joint W3C and OGC standard specifying the semantics of sensors, observations, sampling, and actuation the joint w3c (world wide web consortium) and ogc (open geospatial consortium) spatial data on the web (sdw) working group developed a set of ontologies to describe sensors, actuators, samplers as well as their observations, actuation, and sampling activities. the ontologies have been published both as a w3c recommendation and as an ogc implementation standard. the set includes a lightweight core module called sosa (sensor, observation, sampler, and actuator) available at: http://www.w3.org/ns/sosa/, and a more expressive extension module called ssn (semantic sensor network) available at: http://www.w3.org/ns/ssn/. together they describe systems of sensors and actuators, observations, the used procedures, the subjects and their properties being observed or acted upon, samples and the process of sampling, and so forth. the set of ontologies adopts a modular architecture with sosa as a self-contained core that is extended by ssn and other modules to add expressivity and breadth. the sosa/ssn ontologies are able to support a wide range of applications and use cases, including satellite imagery, large-scale scientific monitoring, industrial and household infrastructures, social sensing, citizen science, observation-driven ontology engineering, and the internet of things. in this paper we give an overview of the ontologies and discuss the rationale behind key design decisions, reporting on the differences between the new ssn ontology presented here and its predecessor [9] developed by the w3c semantic sensor network incubator group (the ssn-xg). we present usage examples and describe alignment modules that foster interoperability with other ontologies.",
            "contribution_ids": [
                "R142766",
                "R143680",
                "R144783"
            ]
        },
        {
            "instance_id": "R145951xR142729",
            "comparison_id": "R145951",
            "paper_id": "R142729",
            "text": "CityPulse: Large Scale Data Analytics Framework for Smart Cities \"our world and our lives are changing in many ways. communication, networking, and computing technologies are among the most influential enablers that shape our lives today. digital data and connected worlds of physical objects, people, and devices are rapidly changing the way we work, travel, socialize, and interact with our surroundings, and they have a profound impact on different domains, such as healthcare, environmental monitoring, urban systems, and control and management applications, among several other areas. cities currently face an increasing demand for providing services that can have an impact on people's everyday lives. the citypulse framework supports smart city service creation by means of a distributed system for semantic discovery, data analytics, and interpretation of large-scale (near-)real-time internet of things data and social media data streams. to goal is to break away from silo applications and enable cross-domain data integration. the citypulse framework integrates multimodal, mixed quality, uncertain and incomplete data to create reliable, dependable information and continuously adapts data processing techniques to meet the quality of information requirements from end users. different than existing solutions that mainly offer unified views of the data, the citypulse framework is also equipped with powerful data analytics modules that perform intelligent data aggregation, event detection, quality assessment, contextual filtering, and decision support. this paper presents the framework, describes its components, and demonstrates how they interact to support easy development of custom-made applications for citizens. the benefits and the effectiveness of the framework are demonstrated in a use-case scenario implementation presented in this paper.\"",
            "contribution_ids": [
                "R142731",
                "R143938",
                "R144797"
            ]
        },
        {
            "instance_id": "R145951xR142756",
            "comparison_id": "R145951",
            "paper_id": "R142756",
            "text": "Smart City Ontologies: Improving the effectiveness of smart city applications this paper addresses the problem of low impact of smart city applications observed in the fields of energy and transport, which constitute high-priority domains for the development of smart cities. however, these are not the only fields where the impact of smart cities has been limited. the paper provides an explanation for the low impact of various individual applications of smart cities and discusses ways of improving their effectiveness. we argue that the impact of applications depends primarily on their ontology, and secondarily on smart technology and programming features. consequently, we start by creating an overall ontology for the smart city, defining the building blocks of this ontology with respect to the most cited definitions of smart cities, and structuring this ontology with the prot\u00e9g\u00e9 5.0 editor, defining entities, class hierarchy, object properties, and data type properties. we then analyze how the ontologies of a sample of smart city applications fit into the overall smart city ontology, the consistency between digital spaces, knowledge processes, city domains targeted by the applications, and the types of innovation that determine their impact. in conclusion, we underline the relationships between innovation and ontology, and discuss how we can improve the effectiveness of smart city applications, combining expert and user-driven ontology design with the integration and or-chestration of applications over platforms and larger city entities such as neighborhoods, districts, clusters, and sectors of city activities.",
            "contribution_ids": [
                "R142758",
                "R143685",
                "R144786"
            ]
        },
        {
            "instance_id": "R145951xR142764",
            "comparison_id": "R145951",
            "paper_id": "R142764",
            "text": "The modular SSN ontology: A joint W3C and OGC standard specifying the semantics of sensors, observations, sampling, and actuation the joint w3c (world wide web consortium) and ogc (open geospatial consortium) spatial data on the web (sdw) working group developed a set of ontologies to describe sensors, actuators, samplers as well as their observations, actuation, and sampling activities. the ontologies have been published both as a w3c recommendation and as an ogc implementation standard. the set includes a lightweight core module called sosa (sensor, observation, sampler, and actuator) available at: http://www.w3.org/ns/sosa/, and a more expressive extension module called ssn (semantic sensor network) available at: http://www.w3.org/ns/ssn/. together they describe systems of sensors and actuators, observations, the used procedures, the subjects and their properties being observed or acted upon, samples and the process of sampling, and so forth. the set of ontologies adopts a modular architecture with sosa as a self-contained core that is extended by ssn and other modules to add expressivity and breadth. the sosa/ssn ontologies are able to support a wide range of applications and use cases, including satellite imagery, large-scale scientific monitoring, industrial and household infrastructures, social sensing, citizen science, observation-driven ontology engineering, and the internet of things. in this paper we give an overview of the ontologies and discuss the rationale behind key design decisions, reporting on the differences between the new ssn ontology presented here and its predecessor [9] developed by the w3c semantic sensor network incubator group (the ssn-xg). we present usage examples and describe alignment modules that foster interoperability with other ontologies.",
            "contribution_ids": [
                "R142766",
                "R143680",
                "R144783"
            ]
        },
        {
            "instance_id": "R145951xR142749",
            "comparison_id": "R145951",
            "paper_id": "R142749",
            "text": "From RESTful to SPARQL: A Case Study on Generating Semantic Sensor Data the recent years have seen a vast increase in the amount of environmental sensor data that is being published on the web. semantic enrichment of sensor data addresses the problems of (re-)use, integration, and discovery. a critical issue is how to generate semantic sensor data from existing data sources. in this paper, we present our approach to semantically augment an existing sensor data infrastructure, in which data is published via a restful api as inter-linked json documents. in particular, we describe and discuss the use of ontologies and the design and development of seraw, a system that transforms a set of json documents into an rdf graph augmented with links to other resources in the linked open data cloud. this transformation is based on user-provided mappings and supported by a library of purpose-built functions. we discuss lessons learned during development and outline remaining open problems.",
            "contribution_ids": [
                "R142751",
                "R143931",
                "R144791"
            ]
        },
        {
            "instance_id": "R146458xR146060",
            "comparison_id": "R146458",
            "paper_id": "R146060",
            "text": "Tools of quality economics: sustainable development of a \u00e2\u0080\u0098smart city\u00e2\u0080\u0099 under conditions of digital transformation of the economy the article covers the issues of ensuring sustainable city development based on the achievements of digitalization. attention is also paid to the use of quality economy tools in managing \u2018smart\u2019 cities under conditions of the digital transformation of the national economy. the current state of \u2018smart\u2019 cities and the main factors contributing to their sustainable development, including the digitalization requirements is analyzed. based on the analysis of statistical material, the main prospects to form the \u2018smart city\u2019 concept, the possibility to assess such parameters as \u2018life quality\u2019, \u2018comfort\u2019, \u2018rational organization\u2019, \u2018opportunities\u2019, \u2018sustainable development\u2019, \u2018city environment accessibility\u2019, \u2018use of communication technologies\u2019. the role of tools for quality economics is revealed in ensuring the big city life under conditions of digital economy. the concept of \u2018life quality\u2019 is considered, which currently is becoming one of the fundamental vectors of the human civilization development, a criterion that is increasingly used to compare countries and territories. special attention is paid to such tools and methods of quality economics as standardization, metrology and quality management. it is proposed to consider these tools as a mechanism for solving the most important problems in the national economy development under conditions of digital transformation.",
            "contribution_ids": [
                "R146062"
            ]
        },
        {
            "instance_id": "R146458xR146070",
            "comparison_id": "R146458",
            "paper_id": "R146070",
            "text": "Smart city initiatives in the context of digital transformation: scope, services and technologies digital transformation is an emerging trend in developing the way how the work is being done, and it is present in the private and public sector, in all industries and fields of work. smart cities, as one of the concepts related to digital transformation, is usually seen as a matter of local governments, as it is their responsibility to ensure a better quality of life for the citizens. some cities have already taken advantages of possibilities offered by the concept of smart cities, creating new values to all stakeholders interacting in the living city ecosystems, thus serving as examples of good practice, while others are still developing and growing on their intentions to become smart. this paper provides a structured literature analysis and investigates key scope, services and technologies related to smart cities and digital transformation as concepts of empowering social and collaboration interactions, in order to identify leading factors in most smart city initiatives.",
            "contribution_ids": [
                "R146074"
            ]
        },
        {
            "instance_id": "R146458xR146032",
            "comparison_id": "R146458",
            "paper_id": "R146032",
            "text": "Digital transformation of existing cities the article focuses on the range of problems arising on the way of innovative technologies implementation in the structure of existing cities. the concept of intellectualization of historic cities, as illustrated by samara, is offered, which was chosen for the realization of a large russian project \u201csmart city. successful region\u201d in 2018. one of the problems was to study the experience of information hubs projecting with the purpose of determination of their priority functional directions. the following typology of information hubs was made: scientific and research ones, scientific and technical ones, innovative and cultural ones, cultural and informational ones, scientific and informational ones, technological ones, centres for data processing, scientific centres with experimental and production laboratories. as a result of the conducted research, a suggestion on smart city\u2019s infrastructure is developed, the final levels of innovative technologies implementation in the structure of historic territories are determined. a model suggestion on the formation of a scientific and project centre with experimental and production laboratories branded as named \u201cpark-plant\u201d is developed. smart (as well as real) city technologies, which are supposed to be placed on the territory of \u201cpark-plant\u201d, are systematized. the organizational structure of the promotion of model projects is offered according to the concept of \u201ctriad of development agents\u201d, in which the flagship university \u2013 urban community \u2013 park-plant interact within the project programme. the effects of the development of the being renovated territory of the historic city centre are enumerated.",
            "contribution_ids": [
                "R146034"
            ]
        },
        {
            "instance_id": "R146458xR146039",
            "comparison_id": "R146458",
            "paper_id": "R146039",
            "text": "The Evolving Enterprise Architecture: A Digital Transformation Perspective the advancement of technology has influenced all the enterprises. enterprises should come up with the evolving approaches to face the challenges. with an evolving approach, the enterprise will be able to adapt to successive changes. enterprise architecture is introduced as an approach to confront these challenges. the main issue is the generalization of this evolving approach to enterprise architecture. in an evolving approach, all aspects of the enterprise, as well as the ecosystem of the enterprise are considered. in this study, the notion of internet of things is considered as a transition factor in enterprise and enterprise architecture. industry 4.0 and digital transformation have also been explored in the enterprise. common challenges are extracted and defined.",
            "contribution_ids": [
                "R146041"
            ]
        },
        {
            "instance_id": "R146458xR146122",
            "comparison_id": "R146458",
            "paper_id": "R146122",
            "text": "Evolution of Enterprise Architecture for Digital Transformation the digital transformation of our life changes the way we work, learn, communicate, and collaborate. enterprises are presently transforming their strategy, culture, processes, and their information systems to become digital. the digital transformation deeply disrupts existing enterprises and economies. digitization fosters the development of it systems with many rather small and distributed structures, like internet of things, microservices and mobile services. since years a lot of new business opportunities appear using the potential of services computing, internet of things, mobile systems, big data with analytics, cloud computing, collaboration networks, and decision support. biological metaphors of living and adaptable ecosystems provide the logical foundation for self-optimizing and resilient run-time environments for intelligent business services and adaptable distributed information systems with service-oriented enterprise architectures. this has a strong impact for architecting digital services and products following both a value-oriented and a service perspective. the change from a closed-world modeling world to a more flexible open-world composition and evolution of enterprise architectures defines the moving context for adaptable and high distributed systems, which are essential to enable the digital transformation. the present research paper investigates the evolution of enterprise architecture considering new defined value-oriented mappings between digital strategies, digital business models and an improved digital enterprise architecture.",
            "contribution_ids": [
                "R146124"
            ]
        },
        {
            "instance_id": "R146458xR146112",
            "comparison_id": "R146458",
            "paper_id": "R146112",
            "text": "Industry 4.0 Complemented with EA Approach: A Proposal for Digital Transformation Success manufacturing industry based on steam know as industry 1.0 is evolving to industry 4.0 a digital ecosystem consisting of an interconnected automated system with real-time data. this paper investigates and proposes, how the digital ecosystem complemented with enterprise architecture practice will ensure the success of digital transformation.",
            "contribution_ids": [
                "R146114"
            ]
        },
        {
            "instance_id": "R146458xR146150",
            "comparison_id": "R146458",
            "paper_id": "R146150",
            "text": "A Roadmap on Improved Performance-centric Cloud Storage Estimation Approach for Database System Deployment in Cloud Environment cloud computing has taken the limelight with respect to the present industry scenario due to its multi-tenant and pay-as-you-use models, where users need not bother about buying resources like hardware, software, infrastructure, etc. on an permanently basis. as much as the technological benefits, cloud computing also has its downside. by looking at its financial benefits, customers who cannot afford initial investments, choose cloud by compromising on its concerns, like security, performance, estimation, availability, etc. at the same time due to its risks, customers - relatively majority in number, avoid migration towards cloud. considering this fact, performance and estimation are being the major critical factors for any application deployment in cloud environment; this paper brings the roadmap for an improved performance-centric cloud storage estimation approach, which is based on balanced pctfree allocation technique for database systems deployment in cloud environment. objective of this approach is to highlight the set of key activities that have to be jointly done by the database technical team and business users of the software system in order to perform an accurate analysis to arrive at estimation for sizing of the database. for the evaluation of this approach, an experiment has been performed through varied-size pctfree allocations on an experimental setup with 100000 data records. the result of this experiment shows the impact of pctfree configuration on database performance. basis this fact, we propose an improved performance-centric cloud storage estimation approach in cloud. further, this paper applies our improved performance-centric storage estimation approach on decision support system (dss) as a case study.",
            "contribution_ids": [
                "R146152"
            ]
        },
        {
            "instance_id": "R146851xR146244",
            "comparison_id": "R146851",
            "paper_id": "R146244",
            "text": "Improvements in Timeliness Resulting from Implementation of Electronic Laboratory Reporting and an Electronic Disease Surveillance System objectives. electronic laboratory reporting (elr) reduces the time between communicable disease diagnosis and case reporting to local health departments (lhds). however, it also imposes burdens on public health agencies, such as increases in the number of unique and duplicate case reports. we assessed how elr affects the timeliness and accuracy of case report processing within public health agencies. methods. using data from may\u2013august 2010 and january\u2013march 2012, we assessed timeliness by calculating the time between receiving a case at the lhd and reporting the case to the state (first stage of reporting) and between submitting the report to the state and submitting it to the centers for disease control and prevention (second stage of reporting). we assessed accuracy by calculating the proportion of cases returned to the lhd for changes or additional information. we compared timeliness and accuracy for elr and non-elr cases. results. elr was associated with decreases in case processing time (median = 40 days for elr cases vs. 52 days for non-elr cases in 2010; median = 20 days for elr cases vs. 25 days for non-elr cases in 2012; both p<0.001). elr also allowed time to reduce the backlog of unreported cases. finally, elr was associated with higher case reporting accuracy (in 2010, 2% of elr case reports vs. 8% of non-elr case reports were returned; in 2012, 2% of elr case reports vs. 6% of non-elr case reports were returned; both p<0.001). conclusion. the overall impact of increased elr is more efficient case processing at both local and state levels.",
            "contribution_ids": [
                "R146246"
            ]
        },
        {
            "instance_id": "R146851xR146600",
            "comparison_id": "R146851",
            "paper_id": "R146600",
            "text": "Coronavirus disease 2019 (COVID-19) surveillance system: Development of COVID-19 minimum data set and interoperable reporting framework introduction: the 2019 coronavirus disease (covid-19) is a major global health concern. joint efforts for effective surveillance of covid-19 require immediate transmission of reliable data. in this regard, a standardized and interoperable reporting framework is essential in a consistent and timely manner. thus, this research aimed at to determine data requirements towards interoperability. materials and methods: in this cross-sectional and descriptive study, a combination of literature study and expert consensus approach was used to design covid-19 minimum data set (mds). a mds checklist was extracted and validated. the definitive data elements of the mds were determined by applying the delphi technique. then, the existing messaging and data standard templates (health level seven-clinical document architecture [hl7-cda] and snomed-ct) were used to design the surveillance interoperable framework. results: the proposed mds was divided into administrative and clinical sections with three and eight data classes and 29 and 40 data fields, respectively. then, for each data field, structured data values along with snomed-ct codes were defined and structured according hl7-cda standard. discussion and conclusion: the absence of effective and integrated system for covid-19 surveillance can delay critical public health measures, leading to increased disease prevalence and mortality. the heterogeneity of reporting templates and lack of uniform data sets hamper the optimal information exchange among multiple systems. thus, developing a unified and interoperable reporting framework is more effective to prompt reaction to the covid-19 outbreak.",
            "contribution_ids": [
                "R146602"
            ]
        },
        {
            "instance_id": "R146851xR145301",
            "comparison_id": "R146851",
            "paper_id": "R145301",
            "text": "Electronic Surveillance System for Monitoring Surgical Antimicrobial Prophylaxis objectives. antimicrobial surgical prophylaxis comprises one third of all antibiotic use in pediatric hospitals and 80% of all antibiotic use in surgery. previous studies reported that antimicrobial surgical prophylaxis is often inconsistent with recommended guidelines. an electronic surveillance system was developed to measure antimicrobial utilization and to identify opportunities to improve and monitor the administration of antibiotics for surgical prophylaxis. methods. a retrospective cohort study was conducted on patients with selected inpatient surgical procedures performed from may 1999 to april 2000 at 4 us children\u2019s hospitals. international classification of diseases, ninth revision surgical procedure codes were divided into clean or unclean categories, and an electronic surveillance system was designed using antibiotic and microbiologic culture utilization data to measure appropriate antimicrobial use associated with the surgical procedure. a medical chart review was conducted to validate the electronic system. results. ninety percent of cases were classified properly by the electronic surveillance system as confirmed by medical chart review. surgical antibiotic prophylaxis was not in accordance with the american academy of pediatrics (aap) guidelines for almost half of all procedures. prolonged antimicrobial administration in clean surgical procedures was the most frequent deviation from guidelines. statistical differences between the index hospital and the comparison hospitals reflect both over- and underutilization of surgical prophylaxis with significant opportunity to improve prophylaxis for all hospitals. conclusions. antimicrobial surgical prophylaxis at the children\u2019s hospitals studied is not always consistent with published aap guidelines. this electronic surveillance system provides a rapid, reproducible, and validated tool to measure easily the efforts to improve adherence to aap surgical prophylaxis guidelines.",
            "contribution_ids": [
                "R145303"
            ]
        },
        {
            "instance_id": "R146851xR145039",
            "comparison_id": "R146851",
            "paper_id": "R145039",
            "text": "Statewide System of Electronic Notifiable Disease Reporting From Clinical Laboratories: Comparing Automated Reporting With Conventional Methods context\\nnotifiable disease surveillance is essential to rapidly identify and respond to outbreaks so that further illness can be prevented. automating reports from clinical laboratories has been proposed to reduce underreporting and delays.\\n\\n\\nobjective\\nto compare the timeliness and completeness of a prototypal electronic reporting system with that of conventional laboratory reporting.\\n\\n\\ndesign\\nlaboratory-based reports for 5 conditions received at a state health department between july 1 and december 31, 1998, were reviewed. completeness of coverage for each reporting system was estimated using capture-recapture methods.\\n\\n\\nsetting\\nthree statewide private clinical laboratories in hawaii.\\n\\n\\nmain outcome measures\\nthe number and date of reports received, by reporting system, laboratory, and pathogen; completeness of data fields.\\n\\n\\nresults\\na total of 357 unique reports of illness were identified; 201 (56%) were received solely through the automated electronic system, 32 (9%) through the conventional system only, and 124 (35%) through both. thus, electronic reporting resulted in a 2.3-fold (95% confidence interval [ci], 2.0-2.6) increase in reports. electronic reports arrived an average of 3.8 (95% ci, 2.6-5.0) days earlier than conventional reports. of 21 data fields common to paper and electronic formats, electronic reports were significantly more likely to be complete for 12 and for 1 field with the conventional system. the estimated completeness of coverage for electronic reporting was 80% (95% ci, 75%-85%) [corrected] compared with 38% (95% ci, 36%-41%) [corrected] for the conventional system.\\n\\n\\nconclusions\\nin this evaluation, electronic reporting more than doubled the total number of laboratory-based reports received. on average, the electronic reports were more timely and more complete, suggesting that electronic reporting may ultimately facilitate more rapid and comprehensive institution of disease control measures.",
            "contribution_ids": [
                "R145041",
                "R145042"
            ]
        },
        {
            "instance_id": "R146851xR146576",
            "comparison_id": "R146851",
            "paper_id": "R146576",
            "text": "Comparative evaluation of three surveillance systems for infectious equine diseases in France and implications for future synergies summary it is necessary to assess surveillance systems for infectious animal diseases to ensure they meet their objectives and provide high-quality health information. each system is generally dedicated to one disease and often comprises various components. in many animal industries, several surveillance systems are implemented separately even if they are based on similar components. this lack of synergy may prevent optimal surveillance. the purpose of this study was to assess several surveillance systems within the same industry using the semi-quantitative oasis method and to compare the results of the assessments in order to propose improvements, including future synergies. we have focused on the surveillance of three major equine diseases in france. we have identified the mutual and specific strengths and weaknesses of each surveillance system. furthermore, the comparative assessment has highlighted many possible synergies that could improve the effectiveness and efficiency of surveillance as a whole, including the implementation of new joint tools or the pooling of existing teams, tools or skills. our approach is an original application of the oasis method, which requires minimal financial resources and is not very time-consuming. such a comparative evaluation could conceivably be applied to other surveillance systems, other industries and other countries. this approach would be especially relevant to enhance the efficiency of surveillance activities when resources are limited.",
            "contribution_ids": [
                "R146578"
            ]
        },
        {
            "instance_id": "R146851xR146490",
            "comparison_id": "R146851",
            "paper_id": "R146490",
            "text": "Rapid implementation of mobile technology for real-time epidemiology of COVID-19 mobile symptom tracking \\n \\n the rapidity with which severe acute respiratory syndrome coronavirus 2 (sars-cov-2) spreads through a population is defying attempts at tracking it, and quantitative polymerase chain reaction testing so far has been too slow for real-time epidemiology. taking advantage of existing longitudinal health care and research patient cohorts, drew\\n et al. \\n pushed software updates to participants to encourage reporting of potential coronavirus disease 2019 (covid-19) symptoms. the authors recruited about 2 million users (including health care workers) to the covid symptom study (previously known as the covid symptom tracker) from across the united kingdom and the united states. the prevalence of combinations of symptoms (three or more), including fatigue and cough, followed by diarrhea, fever, and/or anosmia, was predictive of a positive test verification for sars-cov-2. as exemplified by data from wales, united kingdom, mathematical modeling predicted geographical hotspots of incidence 5 to 7 days in advance of official public health reports.\\n \\n \\n science \\n , this issue p.\\n 1362 \\n",
            "contribution_ids": [
                "R146501",
                "R146502"
            ]
        },
        {
            "instance_id": "R146851xR145065",
            "comparison_id": "R146851",
            "paper_id": "R145065",
            "text": "Description and validation of a new automated surveillance system for Clostridium difficile in Denmark summary the surveillance of clostridium difficile (cd) in denmark consists of laboratory based data from departments of clinical microbiology (dcms) sent to the national registry of enteric pathogens (nrep). we validated a new surveillance system for cd based on the danish microbiology database (miba). miba automatically collects microbiological test results from all danish dcms. we built an algorithm to identify positive test results for cd recorded in miba. a cd case was defined as a person with a positive culture for cd or pcr detection of toxin a and/or b and/or binary toxin. we compared cd cases identified through the miba-based surveillance with those reported to nrep and locally in five dcms representing different danish regions. during 2010\u20132014, nrep reported 13 896 cd cases, and the miba-based surveillance 21 252 cd cases. there was a 99\u00b79% concordance between the local datasets and the miba-based surveillance. surveillance based on miba was superior to the current surveillance system, and the findings show that the number of cd cases in denmark hitherto has been under-reported. there were only minor differences between local data and the miba-based surveillance, showing the completeness and validity of cd data in miba. this nationwide electronic system can greatly strengthen surveillance and research in various applications.",
            "contribution_ids": [
                "R145068"
            ]
        },
        {
            "instance_id": "R146851xR146321",
            "comparison_id": "R146851",
            "paper_id": "R146321",
            "text": "Introduction of software tools for epidemiological surveillance in infection control in Colombia introduction:\\n\\nhealthcare-associated infections (hai) are a challenge for patient safety in the hospitals. infection control committees (icc) should follow cdc definitions when monitoring hai. the handmade method of epidemiological surveillance (es) may affect the sensitivity and specificity of the monitoring system, while electronic surveillance can improve the performance, quality and traceability of recorded information.\\nobjective:\\n\\nto assess the implementation of a strategy for electronic surveillance of hai, bacterial resistance and antimicrobial consumption by the icc of 23 high-complexity clinics and hospitals in colombia, during the period 2012-2013.\\nmethods:\\n\\nan observational study evaluating the introduction of electronic tools in the icc was performed; we evaluated the structure and operation of the icc, the degree of incorporation of the software hai solutions and the adherence to record the required information.\\nresults:\\n\\nthirty-eight percent of hospitals (8/23) had active surveillance strategies with standard criteria of the cdc, and 87% of institutions adhered to the module of identification of cases using the hai solutions software. in contrast, compliance with the diligence of the risk factors for device-associated hais was 33%.\\nconclusions:\\n\\nthe introduction of es could achieve greater adherence to a model of active surveillance, standardized and prospective, helping to improve the validity and quality of the recorded information.",
            "contribution_ids": [
                "R146323",
                "R146330"
            ]
        },
        {
            "instance_id": "R147040xR145495",
            "comparison_id": "R147040",
            "paper_id": "R145495",
            "text": "DNA Barcoding for the Identification of Sand Fly Species (Diptera, Psychodidae, Phlebotominae) in Colombia sand flies include a group of insects that are of medical importance and that vary in geographic distribution, ecology, and pathogen transmission. approximately 163 species of sand flies have been reported in colombia. surveillance of the presence of sand fly species and the actualization of species distribution are important for predicting risks for and monitoring the expansion of diseases which sand flies can transmit. currently, the identification of phlebotomine sand flies is based on morphological characters. however, morphological identification requires considerable skills and taxonomic expertise. in addition, significant morphological similarity between some species, especially among females, may cause difficulties during the identification process. dna-based approaches have become increasingly useful and promising tools for estimating sand fly diversity and for ensuring the rapid and accurate identification of species. a partial sequence of the mitochondrial cytochrome oxidase gene subunit i (coi) is currently being used to differentiate species in different animal taxa, including insects, and it is referred as a barcoding sequence. the present study explored the utility of the dna barcode approach for the identification of phlebotomine sand flies in colombia. we sequenced 700 bp of the coi gene from 36 species collected from different geographic localities. the coi barcode sequence divergence within a single species was <2% in most cases, whereas this divergence ranged from 9% to 26.6% among different species. these results indicated that the barcoding gene correctly discriminated among the previously morphologically identified species with an efficacy of nearly 100%. analyses of the generated sequences indicated that the observed species groupings were consistent with the morphological identifications. in conclusion, the barcoding gene was useful for species discrimination in sand flies from colombia.",
            "contribution_ids": [
                "R145496",
                "R155723"
            ]
        },
        {
            "instance_id": "R147040xR146938",
            "comparison_id": "R147040",
            "paper_id": "R146938",
            "text": "Evaluation of DNA barcoding and identification of new haplomorphs in Canadian deerflies and horseflies this paper reports the first tests of the suitability of the standardized mitochondrial cytochrome c oxidase subunit i (coi) barcoding system for the identification of canadian deerflies and horseflies. two additional mitochondrial molecular markers were used to determine whether unambiguous species recognition in tabanids can be achieved. our 332 canadian tabanid samples yielded 650 sequences from five genera and 42 species. standard coi barcodes demonstrated a strong a + t bias (mean 68.1%), especially at third codon positions (mean 93.0%). our preliminary test of this system showed that the standard coi barcode worked well for canadian tabanidae: the target dna can be easily recovered from small amounts of insect tissue and aligned for all tabanid taxa. each tabanid species possessed distinctive sets of coi haplotypes which discriminated well among species. average conspecific kimura two\u2010parameter (k2p) divergence (0.49%) was 12 times lower than the average divergence within species. both the neighbour\u2010joining and the bayesian methods produced trees with identical monophyletic species groups. two species, chrysops dawsoni philip and chrysops montanus osten sacken (diptera: tabanidae), showed relatively deep intraspecific sequence divergences (\u223c10 times the average) for all three mitochondrial gene regions analysed. we suggest provisional differentiation of ch. montanus into two haplotypes, namely, ch. montanus haplomorph 1 and ch. montanus haplomorph 2, both defined by their molecular sequences and by newly discovered differences in structural features near their ocelli.",
            "contribution_ids": [
                "R146940",
                "R149512"
            ]
        },
        {
            "instance_id": "R147040xR145491",
            "comparison_id": "R147040",
            "paper_id": "R145491",
            "text": "DNA barcoding of tropical black flies (Diptera: Simuliidae) of Thailand the ecological and medical importance of black flies drives the need for rapid and reliable identification of these minute, structurally uniform insects. we assessed the efficiency of dna barcoding for species identification of tropical black flies. a total of 351 cytochrome c oxidase subunit 1 sequences were obtained from 41 species in six subgenera of the genus simulium in thailand. despite high intraspecific genetic divergence (mean = 2.00%, maximum = 9.27%), dna barcodes provided 96% correct identification. barcodes also differentiated cytoforms of selected species complexes, albeit with varying levels of success. perfect differentiation was achieved for two cytoforms of simulium feuerborni, and 91% correct identification was obtained for the simulium angulistylum complex. low success (33%), however, was obtained for the simulium siamense complex. the differential efficiency of dna barcodes to discriminate cytoforms was attributed to different levels of genetic structure and demographic histories of the taxa. dna barcode trees were largely congruent with phylogenies based on previous molecular, chromosomal and morphological analyses, but revealed inconsistencies that will require further evaluation.",
            "contribution_ids": [
                "R145493",
                "R155729"
            ]
        },
        {
            "instance_id": "R147040xR145506",
            "comparison_id": "R147040",
            "paper_id": "R145506",
            "text": "Identification of Nearctic black flies using DNA barcodes (Diptera: Simuliidae) dna barcoding has gained increased recognition as a molecular tool for species identification in various groups of organisms. in this preliminary study, we tested the efficacy of a 615\u2010bp fragment of the cytochrome c oxidase i (coi) as a dna barcode in the medically important family simuliidae, or black flies. a total of 65 (25%) morphologically distinct species and sibling species in species complexes of the 255 recognized nearctic black fly species were used to create a preliminary barcode profile for the family. genetic divergence among congeners averaged 14.93% (range 2.83\u201315.33%), whereas intraspecific genetic divergence between morphologically distinct species averaged 0.72% (range 0\u20133.84%). dna barcodes correctly identified nearly 100% of the morphologically distinct species (87% of the total sampled taxa), whereas in species complexes (13% of the sampled taxa) maximum values of divergence were comparatively higher (max. 4.58\u20136.5%), indicating cryptic diversity. the existence of sibling species in prosimulium travisi and p. neomacropyga was also demonstrated, thus confirming previous cytological evidence about the existence of such cryptic diversity in these two taxa. we conclude that dna barcoding is an effective method for species identification and discovery of cryptic diversity in black flies.",
            "contribution_ids": [
                "R145508",
                "R155698"
            ]
        },
        {
            "instance_id": "R147040xR145502",
            "comparison_id": "R147040",
            "paper_id": "R145502",
            "text": "Barcoding of biting midges in the genus Culicoides: a tool for species determination biting midges of the genus culicoides (diptera: ceratopogonidae) are insect vectors of economically important veterinary diseases such as african horse sickness virus and bluetongue virus. however, the identification of culicoides based on morphological features is difficult. the sequencing of mitochondrial cytochrome oxidase subunit i (coi), referred to as dna barcoding, has been proposed as a tool for rapid identification to species. hence, a study was undertaken to establish dna barcodes for all morphologically determined culicoides species in swedish collections. in total, 237 specimens of culicoides representing 37 morphologically distinct species were used. the barcoding generated 37 supported clusters, 31 of which were in agreement with the morphological determination. however, two pairs of closely related species could not be separated using the dna barcode approach. moreover, culicoides obsoletus meigen and culicoides newsteadi austen showed relatively deep intraspecific divergence (more than 10 times the average), which led to the creation of two cryptic species within each of c. obsoletus and c. newsteadi. the use of coi barcodes as a tool for the species identification of biting midges can differentiate 95% of species studied. identification of some closely related species should employ a less conserved region, such as a ribosomal internal transcribed spacer.",
            "contribution_ids": [
                "R145504",
                "R155704"
            ]
        },
        {
            "instance_id": "R147040xR145509",
            "comparison_id": "R147040",
            "paper_id": "R145509",
            "text": "Identifying Canadian mosquito species through DNA barcodes abstract a short fragment of mt dna from the cytochrome c oxidase 1 (co1) region was used to provide the first co1 barcodes for 37 species of canadian mosquitoes (diptera: culicidae) from the provinces ontario and new brunswick. sequence variation was analysed in a 617\u2010bp fragment from the 5\u2032 end of the co1 region. sequences of each mosquito species formed barcode clusters with tight cohesion that were usually clearly distinct from those of allied species. co1 sequence divergences were, on average, nearly 20 times higher for congeneric species than for members of a species; divergences between congeneric species averaged 10.4% (range 0.2\u201317.2%), whereas those for conspecific individuals averaged 0.5% (range 0.0\u20133.9%).",
            "contribution_ids": [
                "R145511",
                "R155693"
            ]
        },
        {
            "instance_id": "R147040xR145497",
            "comparison_id": "R147040",
            "paper_id": "R145497",
            "text": "Half of the European fruit fly species barcoded (Diptera, Tephritidae); a feasibility test for molecular identification abstract a feasibility test of molecular identification of european fruit flies (diptera: tephritidae) based on coi barcode sequences has been executed. a dataset containing 555 sequences of 135 ingroup species from three subfamilies and 42 genera and one single outgroup species has been analysed. 73.3% of all included species could be identified based on their coi barcode gene, based on similarity and distances. the low success rate is caused by singletons as well as some problematic groups: several species groups within the genus terellia and especially the genus urophora. with slightly more than 100 sequences \u2013 almost 20% of the total \u2013 this genus alone constitutes the larger part of the failure for molecular identification for this dataset. deleting the singletons and urophora results in a success-rate of 87.1% of all queries and 93.23% of the not discarded queries as correctly identified. urophora is of special interest due to its economic importance as beneficial species for weed control, therefore it is desirable to have alternative markers for molecular identification. we demonstrate that the success of dna barcoding for identification purposes strongly depends on the contents of the database used to blast against. especially the necessity of including multiple specimens per species of geographically distinct populations and different ecologies for the understanding of the intra- versus interspecific variation is demonstrated. furthermore thresholds and the distinction between true and false positives and negatives should not only be used to increase the reliability of the success of molecular identification but also to point out problematic groups, which should then be flagged in the reference database suggesting alternative methods for identification.",
            "contribution_ids": [
                "R145499",
                "R155710"
            ]
        },
        {
            "instance_id": "R147040xR146643",
            "comparison_id": "R147040",
            "paper_id": "R146643",
            "text": "Revision of Nearctic Dasysyrphus Enderlein (Diptera: Syrphidae) dasysyrphus enderlein (diptera: syrphidae) has posed taxonomic challenges to researchers in the past, primarily due to their lack of interspecific diagnostic characters. in the present study, dna data (mitochondrial cytochrome c oxidase sub-unit i\u2014coi) were combined with morphology to help delimit species. this led to two species being resurrected from synonymy (d. laticaudus and d. pacificus) and the discovery of one new species (d. occidualis sp. nov.). an additional new species was described based on morphology alone (d. richardi sp. nov.), as the specimens were too old to obtain coi. part of the taxonomic challenge presented by this group arises from missing type specimens. neotypes are designated here for d. pauxillus and d. pinastri to bring stability to these names. an illustrated key to 13 nearctic species is presented, along with descriptions, maps and supplementary data. a phylogeny based on coi is also presented and discussed.",
            "contribution_ids": [
                "R146645",
                "R155663"
            ]
        },
        {
            "instance_id": "R147040xR142535",
            "comparison_id": "R147040",
            "paper_id": "R142535",
            "text": "DNA Barcodes for the Northern European Tachinid Flies (Diptera: Tachinidae) this data release provides coi barcodes for 366 species of parasitic flies (diptera: tachinidae), enabling the dna based identification of the majority of northern european species and a large proportion of palearctic genera, regardless of the developmental stage. the data will provide a tool for taxonomists and ecologists studying this ecologically important but challenging parasitoid family. a comparison of minimum distances between the nearest neighbors revealed the mean divergence of 5.52% that is approximately the same as observed earlier with comparable sampling in lepidoptera, but clearly less than in coleoptera. full barcode-sharing was observed between 13 species pairs or triplets, equaling to 7.36% of all species. delimitation based on barcode index number (bin) system was compared with traditional classification of species and interesting cases of possible species oversplits and cryptic diversity are discussed. overall, dna barcodes are effective in separating tachinid species and provide novel insight into the taxonomy of several genera.",
            "contribution_ids": [
                "R142537",
                "R155773"
            ]
        },
        {
            "instance_id": "R147040xR146639",
            "comparison_id": "R147040",
            "paper_id": "R146639",
            "text": "DNA barcodes for species delimitation in Chironomidae (Diptera): a case study on the genus Labrundinia abstract in this study, we analysed the applicability of dna barcodes for delimitation of 79 specimens of 13 species of nonbiting midges in the subfamily tanypodinae (diptera: chironomidae) from s\u00e3o paulo state, brazil. our results support dna barcoding as an excellent tool for species identification and for solving taxonomic conflicts in genus labrundinia. molecular analysis of cytochrome c oxidase subunit i (coi) gene sequences yielded taxon identification trees, supporting 13 cohesive species clusters, of which three similar groups were subsequently linked to morphological variation at the larval and pupal stage. additionally, another cluster previously described by means of morphology was linked to molecular markers. we found a distinct barcode gap, and in some species substantial interspecific pairwise divergences (up to 19.3%) were observed, which permitted identification of all analysed species. the results also indicated that barcodes can be used to associate life stages of chironomids since coi was easily amplified and sequenced from different life stages with universal barcode primers.",
            "contribution_ids": [
                "R146641",
                "R155674"
            ]
        },
        {
            "instance_id": "R147040xR146646",
            "comparison_id": "R147040",
            "paper_id": "R146646",
            "text": "Comprehensive evaluation of DNA barcoding for the molecular species identification of forensically important Australian Sarcophagidae (Diptera) carrion-breeding sarcophagidae (diptera) can be used to estimate the post-mortem interval in forensic cases. difficulties with accurate morphological identifications at any life stage and a lack of documented thermobiological profiles have limited their current usefulness. the molecular-based approach of dna barcoding, which utilises a 648-bp fragment of the mitochondrial cytochrome oxidase subuniti gene, was evaluated in a pilot study for discrimination between 16 australian sarcophagids. the current study comprehensively evaluated barcoding for a larger taxon set of 588 australian sarcophagids. in total, 39 of the 84 known australian species were represented by 580 specimens, which includes 92% of potentially forensically important species. a further eight specimens could not be identified, but were included nonetheless as six unidentifiable taxa. a neighbour-joining tree was generated and nucleotide sequence divergences were calculated. all species except sarcophaga (fergusonimyia) bancroftorum, known for high morphological variability, were resolved as monophyletic (99.2% of cases), with bootstrap support of 100. excluding s. bancroftorum, the mean intraspecific and interspecific variation ranged from 1.12% and 2.81\u201311.23%, respectively, allowing for species discrimination. dna barcoding was therefore validated as a suitable method for molecular identification of australian sarcophagidae, which will aid in the implementation of this fauna in forensic entomology.",
            "contribution_ids": [
                "R146648",
                "R155647"
            ]
        },
        {
            "instance_id": "R147040xR142517",
            "comparison_id": "R147040",
            "paper_id": "R142517",
            "text": "A DNA barcode library for 5,200 German flies and midges (Insecta: Diptera) and its implications for metabarcoding\u00e2\u0080\u0090based biomonitoring this study summarizes results of a dna barcoding campaign on german diptera, involving analysis of 45,040 specimens. the resultant dna barcode library includes records for 2,453 named species comprising a total of 5,200 barcode index numbers (bins), including 2,700 coi haplotype clusters without species\u2010level assignment, so called \u201cdark taxa.\u201d overall, 88 out of 117 families (75%) recorded from germany were covered, representing more than 50% of the 9,544 known species of german diptera. until now, most of these families, especially the most diverse, have been taxonomically inaccessible. by contrast, within a few years this study provided an intermediate taxonomic system for half of the german dipteran fauna, which will provide a useful foundation for subsequent detailed, integrative taxonomic studies. using dna extracts derived from bulk collections made by malaise traps, we further demonstrate that species delineation using bins and operational taxonomic units (otus) constitutes an effective method for biodiversity studies using dna metabarcoding. as the reference libraries continue to grow, and gaps in the species catalogue are filled, bin lists assembled by metabarcoding will provide greater taxonomic resolution. the present study has three main goals: (a) to provide a dna barcode library for 5,200 bins of diptera; (b) to demonstrate, based on the example of bulk extractions from a malaise trap experiment, that dna barcode clusters, labelled with globally unique identifiers (such as otus and/or bins), provide a pragmatic, accurate solution to the \u201ctaxonomic impediment\u201d; and (c) to demonstrate that interim names based on bins and otus obtained through metabarcoding provide an effective method for studies on species\u2010rich groups that are usually neglected in biodiversity research projects because of their unresolved taxonomy.",
            "contribution_ids": [
                "R142521",
                "R155788"
            ]
        },
        {
            "instance_id": "R147040xR146932",
            "comparison_id": "R147040",
            "paper_id": "R146932",
            "text": "DNA barcodes reveal cryptic genetic diversity within the blackfly subgenus Trichodagmia Enderlein (Diptera: Simuliidae: Simulium) and related taxa in the New World in this paper we investigate the utility of the coi dna barcoding region for species identification and for revealing hidden diversity within the subgenus trichodagmia and related taxa in the new world. in total, 24 morphospecies within the current expanded taxonomic concept of trichodagmia were analyzed. three species in the subgenus aspathia and 10 species in the subgenus simulium s.str. were also included in the analysis because of their putative phylogenetic relationship with trichodagmia. in the neighbour joining analysis tree (nj) derived from the dna barcodes most of the specimens grouped together according to species or species groups as recognized by other morphotaxonomic studies. the interspecific genetic divergence averaged 11.2% (range 2.8\u201319.5%), whereas intraspecific genetic divergence within morphologically distinct species averaged 0.5% (range 0\u20131.2%). higher values of genetic divergence (3.2\u20133.7%) in species complexes suggest the presence of cryptic diversity. the existence of well defined groups within s. piperi, s. duodenicornium, s. canadense and s. rostratum indicate the possible presence of cryptic species within these taxa. also, the suspected presence of a sibling species in s. tarsatum and s. paynei is supported. dna barcodes also showed that specimens from species that were taxonomically difficult to delimit such as s. hippovorum, s. rubrithorax, s. paynei, and other related taxa (s. solarii), grouped together in the nj analysis, confirming the validity of their species status. the recovery of partial barcodes from specimens in collections was time consuming and pcr success was low from specimens more than 10 years old. however, when a sequence was obtained, it provided good resolution for species identification. larvae preserved in \u2018weak\u2019 carnoy\u2019s solution (9:1 ethanol:acetic acid) provided full dna barcodes. adding legs directly to the pcr mix from recently collected and preserved adults was an inexpensive, fast methodology to obtain full barcodes. in summary, dna barcoding combined with a sound morphotaxonomic framework provides an effective approach for the delineation of species and for the discovery of hidden diversity in the subgenus trichodagmia.",
            "contribution_ids": [
                "R146934",
                "R155628"
            ]
        },
        {
            "instance_id": "R147040xR145434",
            "comparison_id": "R147040",
            "paper_id": "R145434",
            "text": "DNA Barcoding of Neotropical Sand Flies (Diptera, Psychodidae, Phlebotominae): Species Identification and Discovery within Brazil dna barcoding has been an effective tool for species identification in several animal groups. here, we used dna barcoding to discriminate between 47 morphologically distinct species of brazilian sand flies. dna barcodes correctly identified approximately 90% of the sampled taxa (42 morphologically distinct species) using clustering based on neighbor-joining distance, of which four species showed comparatively higher maximum values of divergence (range 4.23\u201319.04%), indicating cryptic diversity. the dna barcodes also corroborated the resurrection of two species within the shannoni complex and provided an efficient tool to differentiate between morphologically indistinguishable females of closely related species. taken together, our results validate the effectiveness of dna barcoding for species identification and the discovery of cryptic diversity in sand flies from brazil.",
            "contribution_ids": [
                "R145435",
                "R155758"
            ]
        },
        {
            "instance_id": "R148381xR147032",
            "comparison_id": "R148381",
            "paper_id": "R147032",
            "text": "Glycosylated Sertraline-Loaded Liposomes for Brain Targeting: QbD Study of Formulation Variabilities and Brain Transport effectiveness of cns-acting drugs depends on the localization, targeting, and capacity to be transported through the blood\u2013brain barrier (bbb) which can be achieved by designing brain-targeting delivery vectors. hence, the objective of this study was to screen the formulation and process variables affecting the performance of sertraline (ser-hcl)-loaded pegylated and glycosylated liposomes. the prepared vectors were characterized for ser-hcl entrapment, size, surface charge, release behavior, and in vitro transport through the bbb. furthermore, the compatibility among liposomal components was assessed using sem, ftir, and dsc analysis. through a thorough screening study, enhancement of ser-hcl entrapment, nanosized liposomes with low skewness, maximized stability, and controlled drug leakage were attained. the solid-state characterization revealed remarkable interaction between ser-hcl and the charging agent to determine drug entrapment and leakage. moreover, results of liposomal transport through mouse brain endothelialpolyoma cells demonstrated greater capacity of the proposed glycosylated liposomes to target the cerebellar due to its higher density of glut1 and higher glucose utilization. this transport capacity was confirmed by the inhibiting action of both cytochalasin b and phenobarbital. using c6 glioma cells model, flow cytometry, time-lapse live cell imaging, and in vivo nir fluorescence imaging demonstrated that optimized glycosylated liposomes can be transported through the bbb by classical endocytosis, as well as by specific transcytosis. in conclusion, the current study proposed a thorough screening of important formulation and process variabilities affecting brain-targeting liposomes for further scale-up processes.",
            "contribution_ids": [
                "R147034"
            ]
        },
        {
            "instance_id": "R148381xR148280",
            "comparison_id": "R148381",
            "paper_id": "R148280",
            "text": "Lactoferrin bioconjugated solid lipid nanoparticles: a new drug delivery system for potential brain targeting abstract background: delivery of drugs to brain is a subtle task in the therapy of many severe neurological disorders. solid lipid nanoparticles (sln) easily diffuse the blood\u2013brain barrier (bbb) due to their lipophilic nature. furthermore, ligand conjugation on sln surface enhances the targeting efficiency. lactoferin (lf) conjugated sln system is first time attempted for effective brain targeting in this study. purpose: preparation of lf-modified docetaxel (dtx)-loaded sln for proficient delivery of dtx to brain. methods: dtx-loaded sln were prepared using emulsification and solvent evaporation method and conjugation of lf on sln surface (c-sln) was attained through carbodiimide chemistry. these lipidic nanoparticles were evaluated by dls, afm, ftir, xrd techniques and in vitro release studies. colloidal stability study was performed in biologically simulated environment (normal saline and serum). these lipidic nanoparticles were further evaluated for its targeting mechanism for uptake in brain tumour cells and brain via receptor saturation studies and distribution studies in brain, respectively. results: particle size of lipidic nanoparticles was found to be optimum. surface morphology (zeta potential, afm) and surface chemistry (ftir) confirmed conjugation of lf on sln surface. cytotoxicity studies revealed augmented apoptotic activity of c-sln than sln and dtx. enhanced cytotoxicity was demonstrated by receptor saturation and uptake studies. brain concentration of dtx was elevated significantly with c-sln than marketed formulation. conclusions: it is evident from the cytotoxicity, uptake that sln has potential to deliver drug to brain than marketed formulation but conjugating lf on sln surface (c-sln) further increased the targeting potential for brain tumour. moreover, brain distribution studies corroborated the use of c-sln as a viable vehicle to target drug to brain. hence, c-sln was demonstrated to be a promising dtx delivery system to brain as it possessed remarkable biocompatibility, stability and efficacy than other reported delivery systems.",
            "contribution_ids": [
                "R148282"
            ]
        },
        {
            "instance_id": "R148381xR148275",
            "comparison_id": "R148381",
            "paper_id": "R148275",
            "text": "Galantamine-loaded solid\u00e2\u0080\u0093lipid nanoparticles for enhanced brain delivery: preparation, characterization, in vitro and in vivo evaluations abstract galantamine hydrobromide, a promising acetylcholinesterase inhibitor is reported to be associated with cholinergic side effects. its poor brain penetration results in lower bioavailability to the target site. with an aim to overcome these limitations, solid\u2013lipid nanoparticulate formulation of galantamine hydrobromide was developed employing biodegradable and biocompatible components. the selected galantamine hydrobromide-loaded solid\u2013lipid nanoparticles offered nanocolloidal with size lower than 100\\u2009nm and maximum drug entrapment 83.42\\u2009\u00b1\\u20090.63%. in vitro drug release from these spherical drug-loaded nanoparticles was observed to be greater than 90% for a period of 24\\u2009h in controlled manner. in vivo evaluations demonstrated significant memory restoration capability in cognitive deficit rats in comparison with naive drug. the developed carriers offered approximately twice bioavailability to that of plain drug. hence, the galantamine hydrobromide-loaded solid\u2013lipid nanoparticles can be a promising vehicle for safe and effective delivery especially in disease like alzheimer\u2019s.",
            "contribution_ids": [
                "R148277"
            ]
        },
        {
            "instance_id": "R149847xR145495",
            "comparison_id": "R149847",
            "paper_id": "R145495",
            "text": "DNA Barcoding for the Identification of Sand Fly Species (Diptera, Psychodidae, Phlebotominae) in Colombia sand flies include a group of insects that are of medical importance and that vary in geographic distribution, ecology, and pathogen transmission. approximately 163 species of sand flies have been reported in colombia. surveillance of the presence of sand fly species and the actualization of species distribution are important for predicting risks for and monitoring the expansion of diseases which sand flies can transmit. currently, the identification of phlebotomine sand flies is based on morphological characters. however, morphological identification requires considerable skills and taxonomic expertise. in addition, significant morphological similarity between some species, especially among females, may cause difficulties during the identification process. dna-based approaches have become increasingly useful and promising tools for estimating sand fly diversity and for ensuring the rapid and accurate identification of species. a partial sequence of the mitochondrial cytochrome oxidase gene subunit i (coi) is currently being used to differentiate species in different animal taxa, including insects, and it is referred as a barcoding sequence. the present study explored the utility of the dna barcode approach for the identification of phlebotomine sand flies in colombia. we sequenced 700 bp of the coi gene from 36 species collected from different geographic localities. the coi barcode sequence divergence within a single species was <2% in most cases, whereas this divergence ranged from 9% to 26.6% among different species. these results indicated that the barcoding gene correctly discriminated among the previously morphologically identified species with an efficacy of nearly 100%. analyses of the generated sequences indicated that the observed species groupings were consistent with the morphological identifications. in conclusion, the barcoding gene was useful for species discrimination in sand flies from colombia.",
            "contribution_ids": [
                "R145496",
                "R155723"
            ]
        },
        {
            "instance_id": "R149847xR145434",
            "comparison_id": "R149847",
            "paper_id": "R145434",
            "text": "DNA Barcoding of Neotropical Sand Flies (Diptera, Psychodidae, Phlebotominae): Species Identification and Discovery within Brazil dna barcoding has been an effective tool for species identification in several animal groups. here, we used dna barcoding to discriminate between 47 morphologically distinct species of brazilian sand flies. dna barcodes correctly identified approximately 90% of the sampled taxa (42 morphologically distinct species) using clustering based on neighbor-joining distance, of which four species showed comparatively higher maximum values of divergence (range 4.23\u201319.04%), indicating cryptic diversity. the dna barcodes also corroborated the resurrection of two species within the shannoni complex and provided an efficient tool to differentiate between morphologically indistinguishable females of closely related species. taken together, our results validate the effectiveness of dna barcoding for species identification and the discovery of cryptic diversity in sand flies from brazil.",
            "contribution_ids": [
                "R145435",
                "R155758"
            ]
        },
        {
            "instance_id": "R149847xR145468",
            "comparison_id": "R149847",
            "paper_id": "R145468",
            "text": "DNA barcoding of Neotropical black flies (Diptera: Simuliidae): Species identification and discovery of cryptic diversity in Mesoamerica although correct taxonomy is paramount for disease control programs and epidemiological studies, morphology-based taxonomy of black flies is extremely difficult. in the present study, the utility of a partial sequence of the coi gene, the dna barcoding region, for the identification of species of black flies from mesoamerica was assessed. a total of 32 morphospecies were analyzed, one belonging to the genus gigantodax and 31 species to the genus simulium and six of its subgenera (aspathia, eusimulium, notolepria, psaroniocompsa, psilopelmia, trichodagmia). the neighbour joining tree (nj) derived from the dna barcodes grouped most specimens according to species or species groups recognized by morphotaxonomic studies. intraspecific sequence divergences within morphologically distinct species ranged from 0.07% to 1.65%, while higher divergences (2.05%-6.13%) in species complexes suggested the presence of cryptic diversity. the existence of well-defined groups within s. callidum (dyar & shannon), s. quadrivittatum loew, and s. samboni jennings revealed the likely inclusion of cryptic species within these taxa. in addition, the suspected presence of sibling species within s. paynei vargas and s. tarsatum macquart was supported. dna barcodes also showed that specimens of species that are difficult to delimit morphologically such as s. callidum, s. pseudocallidum d\u00edaz n\u00e1jera, s. travisi vargas, vargas & ram\u00edrez-p\u00e9rez, relatives of the species complexes such as s. metallicum bellardi s.l. (e.g., s. horacioi okazawa & onishi, s. jobbinsi vargas, mart\u00ednez palacios, d\u00edaz n\u00e1jera, and s. puigi vargas, mart\u00ednez palacios & d\u00edaz n\u00e1jera), and s. virgatum coquillett complex (e.g., s. paynei and s. tarsatum) grouped together in the nj analysis, suggesting they represent valid species. dna barcoding combined with a sound morphotaxonomic framework provided an effective approach for the identification of medically important black flies species in mesoamerica and for the discovery of hidden diversity within this group.",
            "contribution_ids": [
                "R145470",
                "R155739"
            ]
        },
        {
            "instance_id": "R149847xR108960",
            "comparison_id": "R149847",
            "paper_id": "R108960",
            "text": "Use of species delimitation approaches to tackle the cryptic diversity of an assemblage of high Andean butterflies (Lepidoptera: Papilionoidea) cryptic biological diversity has generated ambiguity in taxonomic and evolutionary studies. single-locus methods and other approaches for species delimitation are useful for addressing this challenge, enabling the practical processing of large numbers of samples for identification and inventory purposes. this study analyzed an assemblage of high andean butterflies using dna barcoding and compared the identifications based on the current morphological taxonomy with three methods of species delimitation (automatic barcode gap discovery, generalized mixed yule coalescent model, and poisson tree processes). sixteen potential cryptic species were recognized using these three methods, representing a net richness increase of 11.3% in the assemblage. a well-studied taxon of the genus vanessa, which has a wide geographical distribution, appeared with the potential cryptic species that had a higher genetic differentiation at the local level than at the continental level. the analyses were useful for identifying the potential cryptic species in pedaliodes and forsterinaria complexes, which also show differentiation along altitudinal and latitudinal gradients. this genetic assessment of an entire assemblage of high andean butterflies (papilionoidea) provides baseline information for future research in a region characterized by high rates of endemism and population isolation.",
            "contribution_ids": [
                "R157029",
                "R108962"
            ]
        },
        {
            "instance_id": "R149847xR140197",
            "comparison_id": "R149847",
            "paper_id": "R140197",
            "text": "DNA barcodes distinguish species of tropical Lepidoptera although central to much biological research, the identification of species is often difficult. the use of dna barcodes, short dna sequences from a standardized region of the genome, has recently been proposed as a tool to facilitate species identification and discovery. however, the effectiveness of dna barcoding for identifying specimens in species-rich tropical biotas is unknown. here we show that cytochrome c oxidase i dna barcodes effectively discriminate among species in three lepidoptera families from area de conservaci\u00f3n guanacaste in northwestern costa rica. we found that 97.9% of the 521 species recognized by prior taxonomic work possess distinctive cytochrome c oxidase i barcodes and that the few instances of interspecific sequence overlap involve very similar species. we also found two or more barcode clusters within each of 13 supposedly single species. covariation between these clusters and morphological and/or ecological traits indicates overlooked species complexes. if these results are general, dna barcoding will significantly aid species identification and discovery in tropical settings.",
            "contribution_ids": [
                "R140199",
                "R156766"
            ]
        },
        {
            "instance_id": "R149847xR138562",
            "comparison_id": "R149847",
            "paper_id": "R138562",
            "text": "Fast Census of Moth Diversity in the Neotropics: A Comparison of Field-Assigned Morphospecies and DNA Barcoding in Tiger Moths the morphological species delimitations (i.e. morphospecies) have long been the best way to avoid the taxonomic impediment and compare insect taxa biodiversity in highly diverse tropical and subtropical regions. the development of dna barcoding, however, has shown great potential to replace (or at least complement) the morphospecies approach, with the advantage of relying on automated methods implemented in computer programs or even online rather than in often subjective morphological features. we sampled moths extensively for two years using light traps in a patch of the highly endangered atlantic forest of brazil to produce a nearly complete census of arctiines (noctuoidea: erebidae), whose species richness was compared using different morphological and molecular approaches (dna barcoding). a total of 1,075 barcode sequences of 286 morphospecies were analyzed. based on the clustering method barcode index number (bin) we found a taxonomic bias of approximately 30% in our initial morphological assessment. however, a morphological reassessment revealed that the correspondence between morphospecies and molecular operational taxonomic units (motus) can be up to 94% if differences in genitalia morphology are evaluated in individuals of different motus originated from the same morphospecies (putative cases of cryptic species), and by recording if individuals of different genders in different morphospecies merge together in the same motu (putative cases of sexual dimorphism). the results of two other clustering methods (i.e. automatic barcode gap discovery and 2% threshold) were very similar to those of the bin approach. using empirical data we have shown that dna barcoding performed substantially better than the morphospecies approach, based on superficial morphology, to delimit species of a highly diverse moth taxon, and thus should be used in species inventories.",
            "contribution_ids": [
                "R156968",
                "R138564"
            ]
        },
        {
            "instance_id": "R149849xR108983",
            "comparison_id": "R149849",
            "paper_id": "R108983",
            "text": "Barcoding the butterflies of southern South America: Species delimitation efficacy, cryptic diversity and geographic patterns of divergence because the tropical regions of america harbor the highest concentration of butterfly species, its fauna has attracted considerable attention. much less is known about the butterflies of southern south america, particularly argentina, where over 1,200 species occur. to advance understanding of this fauna, we assembled a dna barcode reference library for 417 butterfly species of argentina, focusing on the atlantic forest, a biodiversity hotspot. we tested the efficacy of this library for specimen identification, used it to assess the frequency of cryptic species, and examined geographic patterns of genetic variation, making this study the first large-scale genetic assessment of the butterflies of southern south america. the average sequence divergence to the nearest neighbor (i.e. minimum interspecific distance) was 6.91%, ten times larger than the mean distance to the furthest conspecific (0.69%), with a clear barcode gap present in all but four of the species represented by two or more specimens. as a consequence, the dna barcode library was extremely effective in the discrimination of these species, allowing a correct identification in more than 95% of the cases. singletons (i.e. species represented by a single sequence) were also distinguishable in the gene trees since they all had unique dna barcodes, divergent from those of the closest non-conspecific. the clustering algorithms implemented recognized from 416 to 444 barcode clusters, suggesting that the actual diversity of butterflies in argentina is 3%\u20139% higher than currently recognized. furthermore, our survey added three new records of butterflies for the country (eurema agave, mithras hannelore, melanis hillapana). in summary, this study not only supported the utility of dna barcoding for the identification of the butterfly species of argentina, but also highlighted several cases of both deep intraspecific and shallow interspecific divergence that should be studied in more detail.",
            "contribution_ids": [
                "R157025",
                "R108986"
            ]
        },
        {
            "instance_id": "R149849xR145304",
            "comparison_id": "R149849",
            "paper_id": "R145304",
            "text": "Analyzing Mosquito (Diptera: Culicidae) Diversity in Pakistan by DNA Barcoding background although they are important disease vectors mosquito biodiversity in pakistan is poorly known. recent epidemics of dengue fever have revealed the need for more detailed understanding of the diversity and distributions of mosquito species in this region. dna barcoding improves the accuracy of mosquito inventories because morphological differences between many species are subtle, leading to misidentifications. methodology/principal findings sequence variation in the barcode region of the mitochondrial coi gene was used to identify mosquito species, reveal genetic diversity, and map the distribution of the dengue-vector species in pakistan. analysis of 1684 mosquitoes from 491 sites in punjab and khyber pakhtunkhwa during 2010\u20132013 revealed 32 species with the assemblage dominated by culex quinquefasciatus (61% of the collection). the genus aedes (stegomyia) comprised 15% of the specimens, and was represented by six taxa with the two dengue vector species, ae. albopictus and ae. aegypti, dominant and broadly distributed. anopheles made up another 6% of the catch with an. subpictus dominating. barcode sequence divergence in conspecific specimens ranged from 0\u20132.4%, while congeneric species showed from 2.3\u201317.8% divergence. a global haplotype analysis of disease-vectors showed the presence of multiple haplotypes, although a single haplotype of each dengue-vector species was dominant in most countries. geographic distribution of ae. aegypti and ae. albopictus showed the later species was dominant and found in both rural and urban environments. conclusions as the first dna-based analysis of mosquitoes in pakistan, this study has begun the construction of a barcode reference library for the mosquitoes of this region. levels of genetic diversity varied among species. because of its capacity to differentiate species, even those with subtle morphological differences, dna barcoding aids accurate tracking of vector populations.",
            "contribution_ids": [
                "R145305",
                "R155763"
            ]
        },
        {
            "instance_id": "R149849xR109043",
            "comparison_id": "R149849",
            "paper_id": "R109043",
            "text": "A DNA barcode library for the butterflies of North America although the butterflies of north america have received considerable taxonomic attention, overlooked species and instances of hybridization continue to be revealed. the present study assembles a dna barcode reference library for this fauna to identify groups whose patterns of sequence variation suggest the need for further taxonomic study. based on 14,626 records from 814 species, dna barcodes were obtained for 96% of the fauna. the maximum intraspecific distance averaged 1/4 the minimum distance to the nearest neighbor, producing a barcode gap in 76% of the species. most species (80%) were monophyletic, the others were para- or polyphyletic. although 15% of currently recognized species shared barcodes, the incidence of such taxa was far higher in regions exposed to pleistocene glaciations than in those that were ice-free. nearly 10% of species displayed high intraspecific variation (&gt;2.5%), suggesting the need for further investigation to assess potential cryptic diversity. aside from aiding the identification of all life stages of north american butterflies, the reference library has provided new perspectives on the incidence of both cryptic and potentially over-split species, setting the stage for future studies that can further explore the evolutionary dynamics of this group.",
            "contribution_ids": [
                "R157021",
                "R109045"
            ]
        },
        {
            "instance_id": "R149849xR142517",
            "comparison_id": "R149849",
            "paper_id": "R142517",
            "text": "A DNA barcode library for 5,200 German flies and midges (Insecta: Diptera) and its implications for metabarcoding\u00e2\u0080\u0090based biomonitoring this study summarizes results of a dna barcoding campaign on german diptera, involving analysis of 45,040 specimens. the resultant dna barcode library includes records for 2,453 named species comprising a total of 5,200 barcode index numbers (bins), including 2,700 coi haplotype clusters without species\u2010level assignment, so called \u201cdark taxa.\u201d overall, 88 out of 117 families (75%) recorded from germany were covered, representing more than 50% of the 9,544 known species of german diptera. until now, most of these families, especially the most diverse, have been taxonomically inaccessible. by contrast, within a few years this study provided an intermediate taxonomic system for half of the german dipteran fauna, which will provide a useful foundation for subsequent detailed, integrative taxonomic studies. using dna extracts derived from bulk collections made by malaise traps, we further demonstrate that species delineation using bins and operational taxonomic units (otus) constitutes an effective method for biodiversity studies using dna metabarcoding. as the reference libraries continue to grow, and gaps in the species catalogue are filled, bin lists assembled by metabarcoding will provide greater taxonomic resolution. the present study has three main goals: (a) to provide a dna barcode library for 5,200 bins of diptera; (b) to demonstrate, based on the example of bulk extractions from a malaise trap experiment, that dna barcode clusters, labelled with globally unique identifiers (such as otus and/or bins), provide a pragmatic, accurate solution to the \u201ctaxonomic impediment\u201d; and (c) to demonstrate that interim names based on bins and otus obtained through metabarcoding provide an effective method for studies on species\u2010rich groups that are usually neglected in biodiversity research projects because of their unresolved taxonomy.",
            "contribution_ids": [
                "R142521",
                "R155788"
            ]
        },
        {
            "instance_id": "R149849xR138551",
            "comparison_id": "R149849",
            "paper_id": "R138551",
            "text": "Probing planetary biodiversity with DNA barcodes: The Noctuoidea of North America this study reports the assembly of a dna barcode reference library for species in the lepidopteran superfamily noctuoidea from canada and the usa. based on the analysis of 69,378 specimens, the library provides coverage for 97.3% of the noctuoid fauna (3565 of 3664 species). in addition to verifying the strong performance of dna barcodes in the discrimination of these species, the results indicate close congruence between the number of species analyzed (3565) and the number of sequence clusters (3816) recognized by the barcode index number (bin) system. distributional patterns across 12 north american ecoregions are examined for the 3251 species that have gps data while bin analysis is used to quantify overlap between the noctuoid faunas of north america and other zoogeographic regions. this analysis reveals that 90% of north american noctuoids are endemic and that just 7.5% and 1.8% of bins are shared with the neotropics and with the palearctic, respectively. one third (29) of the latter species are recent introductions and, as expected, they possess low intraspecific divergences.",
            "contribution_ids": [
                "R156994",
                "R138554"
            ]
        },
        {
            "instance_id": "R149849xR139538",
            "comparison_id": "R149849",
            "paper_id": "R139538",
            "text": "High resolution DNA barcode library for European butterflies reveals continental patterns of mitochondrial genetic diversity abstract the study of global biodiversity will greatly benefit from access to comprehensive dna barcode libraries at continental scale, but such datasets are still very rare. here, we assemble the first high-resolution reference library for european butterflies that provides 97% taxon coverage (459 species) and 22,306 coi sequences. we estimate that we captured 62% of the total haplotype diversity and show that most species possess a few very common haplotypes and many rare ones. specimens in the dataset have an average 95.3% probability of being correctly identified. mitochondrial diversity displayed elevated haplotype richness in southern european refugia, establishing the generality of this key biogeographic pattern for an entire taxonomic group. fifteen percent of the species are involved in barcode sharing, but two thirds of these cases may reflect the need for further taxonomic research. this dataset provides a unique resource for conservation and for studying evolutionary processes, cryptic species, phylogeography, and ecology.",
            "contribution_ids": [
                "R139543",
                "R156950"
            ]
        },
        {
            "instance_id": "R149849xR139497",
            "comparison_id": "R149849",
            "paper_id": "R139497",
            "text": "Congruence between morphology-based species and Barcode Index Numbers (BINs) in Neotropical Eumaeini (Lycaenidae) \\n background \\n with about 1,000 species in the neotropics, the eumaeini (theclinae) are one of the most diverse butterfly tribes. correct morphology-based identifications are challenging in many genera due to relatively little interspecific differences in wing patterns. geographic infraspecific variation is sometimes more substantial than variation between species. in this paper we present a large dna barcode dataset of south american lycaenidae. we analyze how well dna barcode bins match morphologically delimited species. \\n \\n \\n methods \\n we compare morphology-based species identifications with the clustering of molecular operational taxonomic units (motus) delimitated by the resl algorithm in bold, which assigns barcode index numbers (bins). we examine intra- and interspecific divergences for genera represented by at least four morphospecies. we discuss the existence of local barcode gaps in a genus by genus analysis. we also note differences in the percentage of species with barcode gaps in groups of lowland and high mountain genera. \\n \\n \\n results \\n we identified 2,213 specimens and obtained 1,839 sequences of 512 species in 90 genera. overall, the mean intraspecific divergence value of co1 sequences was 1.20%, while the mean interspecific divergence between nearest congeneric neighbors was 4.89%, demonstrating the presence of a barcode gap. however, the gap seemed to disappear from the entire set when comparing the maximum intraspecific distance (8.40%) with the minimum interspecific distance (0.40%). clear barcode gaps are present in many genera but absent in others. from the set of specimens that yielded coi fragment lengths of at least 650 bp, 75% of the a priori morphology-based identifications were unambiguously assigned to a single barcode index number (bin). however, after a taxonomic a posteriori review, the percentage of matched identifications rose to 85%. bin splitting was observed for 17% of the species and bin sharing for 9%. we found that genera that contain primarily lowland species show higher percentages of local barcode gaps and congruence between bins and morphology than genera that contain exclusively high montane species. the divergence values to the nearest neighbors were significantly lower in high andean species while the intra-specific divergence values were significantly lower in the lowland species. these results raise questions regarding the causes of observed low inter and high intraspecific genetic variation. we discuss incomplete lineage sorting and hybridization as most likely causes of this phenomenon, as the montane species concerned are relatively young and hybridization is probable. the release of our data set represents an essential baseline for a reference library for biological assessment studies of butterflies in mega diverse countries using modern high-throughput technologies an highlights the necessity of taxonomic revisions for various genera combining both molecular and morphological data. \\n",
            "contribution_ids": [
                "R139502",
                "R156958"
            ]
        },
        {
            "instance_id": "R150058xR69288",
            "comparison_id": "R150058",
            "paper_id": "R69288",
            "text": "Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction we introduce a multi-task setup of identifying entities, relations, and coreference clusters in scientific articles. we create scierc, a dataset that includes annotations for all three tasks and develop a unified framework called sciie with shared span representations. the multi-task setup reduces cascading errors between tasks and leverages cross-sentence relations through coreference links. experiments show that our multi-task model outperforms previous models in scientific information extraction without using any domain-specific features. we further show that the framework supports construction of a scientific knowledge graph, which we use to analyze information in scientific literature.",
            "contribution_ids": [
                "R69289"
            ]
        },
        {
            "instance_id": "R150058xR147657",
            "comparison_id": "R150058",
            "paper_id": "R147657",
            "text": "Concept-based analysis of scientific literature \"this paper studies the importance of identifying and categorizing scientific concepts as a way to achieve a deeper understanding of the research literature of a scientific community. to reach this goal, we propose an unsupervised bootstrapping algorithm for identifying and categorizing mentions of concepts. we then propose a new clustering algorithm that uses citations' context as a way to cluster the extracted mentions into coherent concepts. our evaluation of the algorithms against gold standards shows significant improvement over state-of-the-art results. more importantly, we analyze the computational linguistic literature using the proposed algorithms and show four different ways to summarize and understand the research community which are difficult to obtain using existing techniques.\"",
            "contribution_ids": [
                "R147659",
                "R147707"
            ]
        },
        {
            "instance_id": "R150058xR74026",
            "comparison_id": "R150058",
            "paper_id": "R74026",
            "text": "Task 11 at SemEval-2021: NLPContributionGraph - Structuring Scholarly NLP Contributions for a Research Knowledge Graph there is currently a gap between the natural language expression of scholarly publications and their structured semantic content modeling to enable intelligent content search. with the volume of research growing exponentially every year, a search feature operating over semantically structured content is compelling. the semeval-2021 shared task nlpcontributiongraph (a.k.a. \u2018the ncg task\u2019) tasks participants to develop automated systems that structure contributions from nlp scholarly articles in the english language. being the first-of-its-kind in the semeval series, the task released structured data from nlp scholarly articles at three levels of information granularity, i.e. at sentence-level, phrase-level, and phrases organized as triples toward knowledge graph (kg) building. the sentence-level annotations comprised the few sentences about the article\u2019s contribution. the phrase-level annotations were scientific term and predicate phrases from the contribution sentences. finally, the triples constituted the research overview kg. for the shared task, participating systems were then expected to automatically classify contribution sentences, extract scientific terms and relations from the sentences, and organize them as kg triples. overall, the task drew a strong participation demographic of seven teams and 27 participants. the best end-to-end task system classified contribution sentences at 57.27% f1, phrases at 46.41% f1, and triples at 22.28% f1. while the absolute performance to generate triples remains low, as conclusion to the article, the difficulty of producing such data and as a consequence of modeling it is highlighted.",
            "contribution_ids": [
                "R74028",
                "R74031",
                "R74032",
                "R74033",
                "R74034",
                "R74035",
                "R74036",
                "R75321"
            ]
        },
        {
            "instance_id": "R150058xR146872",
            "comparison_id": "R150058",
            "paper_id": "R146872",
            "text": "Identification of Tasks, Datasets, Evaluation Metrics, and Numeric Scores for Scientific Leaderboards Construction while the fast-paced inception of novel tasks and new datasets helps foster active research in a community towards interesting directions, keeping track of the abundance of research activity in different areas on different datasets is likely to become increasingly difficult. the community could greatly benefit from an automatic system able to summarize scientific results, e.g., in the form of a leaderboard. in this paper we build two datasets and develop a framework (tdms-ie) aimed at automatically extracting task, dataset, metric and score from nlp papers, towards the automatic construction of leaderboards. experiments show that our model outperforms several baselines by a large margin. our model is a first step towards automatic leaderboard construction, e.g., in the nlp domain.",
            "contribution_ids": [
                "R146874"
            ]
        },
        {
            "instance_id": "R150058xR146357",
            "comparison_id": "R150058",
            "paper_id": "R146357",
            "text": "The STEM-ECR Dataset: Grounding Scientific Entity References in STEM Scholarly Content to Authoritative Encyclopedic and Lexicographic Sources we introduce the stem (science, technology, engineering, and medicine) dataset for scientific entity extraction, classification, and resolution, version 1.0 (stem-ecr v1.0). the stem-ecr v1.0 dataset has been developed to provide a benchmark for the evaluation of scientific entity extraction, classification, and resolution tasks in a domain-independent fashion. it comprises abstracts in 10 stem disciplines that were found to be the most prolific ones on a major publishing platform. we describe the creation of such a multidisciplinary corpus and highlight the obtained findings in terms of the following features: 1) a generic conceptual formalism for scientific entities in a multidisciplinary scientific context; 2) the feasibility of the domain-independent human annotation of scientific entities under such a generic formalism; 3) a performance benchmark obtainable for automatic extraction of multidisciplinary scientific entities using bert-based neural models; 4) a delineated 3-step entity resolution procedure for human annotation of the scientific entities via encyclopedic entity linking and lexicographic word sense disambiguation; and 5) human evaluations of babelfy returned encyclopedic links and lexicographic senses for our entities. our findings cumulatively indicate that human annotation and automatic learning of multidisciplinary scientific concepts as well as their semantic disambiguation in a wide-ranging setting as stem is reasonable.",
            "contribution_ids": [
                "R146359",
                "R146379"
            ]
        },
        {
            "instance_id": "R150058xR69291",
            "comparison_id": "R150058",
            "paper_id": "R69291",
            "text": "The ACL RD-TEC 2.0: A Language Resource for Evaluating Term Extraction and Entity Recognition Methods this paper introduces the acl reference dataset for terminology extraction and classification, version 2.0 (acl rd-tec 2.0). the acl rd-tec 2.0 has been developed with the aim of providing a benchmark for the evaluation of term and entity recognition tasks based on specialised text from the computational linguistics domain. this release of the corpus consists of 300 abstracts from articles in the acl anthology reference corpus, published between 1978\u20132006. in these abstracts, terms (i.e., single or multi-word lexical units with a specialised meaning) are manually annotated. in addition to their boundaries in running text, annotated terms are classified into one of the seven categories method, tool, language resource (lr), lr product, model, measures and measurements, and other. to assess the quality of the annotations and to determine the difficulty of this annotation task, more than 171 of the abstracts are annotated twice, independently, by each of the two annotators. in total, 6,818 terms are identified and annotated in more than 1300 sentences, resulting in a specialised vocabulary made of 3,318 lexical forms, mapped to 3,471 concepts. we explain the development of the annotation guidelines and discuss some of the challenges we encountered in this annotation task.",
            "contribution_ids": [
                "R69292"
            ]
        },
        {
            "instance_id": "R150058xR146081",
            "comparison_id": "R150058",
            "paper_id": "R146081",
            "text": "Analyzing the Dynamics of Research by Extracting Key Aspects of Scientific Papers we present a method for characterizing a research work in terms of its focus, domain of application, and techniques used. we show how tracing these aspects over time provides a novel measure of the influence of research communities on each other. we extract these characteristics by matching semantic extraction patterns, learned using bootstrapping, to the dependency trees of sentences in an article\u2019s",
            "contribution_ids": [
                "R146083"
            ]
        },
        {
            "instance_id": "R150570xR148131",
            "comparison_id": "R150570",
            "paper_id": "R148131",
            "text": "Construction of an annotated corpus to support biomedical information extraction abstract \\n \\n background \\n information extraction (ie) is a component of text mining that facilitates knowledge discovery by automatically locating instances of interesting biomedical events from huge document collections. as events are usually centred on verbs and nominalised verbs, understanding the syntactic and semantic behaviour of these words is highly important. corpora annotated with information concerning this behaviour can constitute a valuable resource in the training of ie components and resources. \\n \\n \\n results \\n we have defined a new scheme for annotating sentence-bound gene regulation events, centred on both verbs and nominalised verbs. for each event instance, all participants ( arguments ) in the same sentence are identified and assigned a semantic role from a rich set of 13 roles tailored to biomedical research articles, together with a biological concept type linked to the gene regulation ontology. to our knowledge, our scheme is unique within the biomedical field in terms of the range of event arguments identified. using the scheme, we have created the gene regulation event corpus (grec), consisting of 240 medline abstracts, in which events relating to gene regulation and expression have been annotated by biologists. a novel method of evaluating various different facets of the annotation task showed that average inter-annotator agreement rates fall within the range of 66% - 90%. \\n \\n \\n conclusion \\n the grec is a unique resource within the biomedical field, in that it annotates not only core relationships between entities, but also a range of other important details about these relationships, e.g., location, temporal, manner and environmental conditions. as such, it is specifically designed to support bio-specific tool and resource development. it has already been used to acquire semantic frames for inclusion within the biolexicon (a lexical, terminological resource to aid biomedical text mining). initial experiments have also shown that the corpus may viably be used to train ie components, such as semantic role labellers. the corpus and annotation guidelines are freely available for academic purposes. \\n",
            "contribution_ids": [
                "R148133"
            ]
        },
        {
            "instance_id": "R150570xR148576",
            "comparison_id": "R150570",
            "paper_id": "R148576",
            "text": "Exploiting syntax when detecting protein names in text this paper presents work on a method to detect names of proteins in running text. \\n \\nour system - yapex - uses a combination of lexical and syntactic knowledge, heuristic filters and a local dynamic dictionary. the syntactic information given by a general-purpose off-the-shelf parser supports the correct identification of the boundaries of protein names, and the local dynamic dictionary finds protein names in positions incompletely analysed by the parser. \\n \\nwe present the different steps involved in our approach to protein tagging, and show how combinations of them influence recall and precision. \\n \\nwe evaluate the system on a corpus of medline abstracts and compare it with the kex system (fukuda et al., 1998) along four different notions of correctness.",
            "contribution_ids": [
                "R148578"
            ]
        },
        {
            "instance_id": "R150570xR148501",
            "comparison_id": "R150570",
            "paper_id": "R148501",
            "text": "Integrated Annotation for Biomedical Information Extraction we describe an approach to two areas of biomedical information extraction, drug development and cancer genomics. we have developed a framework which includes corpus annotation integrated at multiple levels: a treebank containing syntactic structure, a propbank containing predicate-argument structure, and annotation of entities and relations among the entities. crucial to this approach is the proper characterization of entities as relation components, which allows the integration of the entity annotation with the syntactic structure while retaining the capacity to annotate and extract more complex events. we are training statistical taggers using this annotation for such extraction as well as using them for improving the annotation process.",
            "contribution_ids": [
                "R148503"
            ]
        },
        {
            "instance_id": "R150570xR148050",
            "comparison_id": "R150570",
            "paper_id": "R148050",
            "text": "Tagging gene and protein names in biomedical text motivation\\nthe medline database of biomedical abstracts contains scientific knowledge about thousands of interacting genes and proteins. automated text processing can aid in the comprehension and synthesis of this valuable information. the fundamental task of identifying gene and protein names is a necessary first step towards making full use of the information encoded in biomedical text. this remains a challenging task due to the irregularities and ambiguities in gene and protein nomenclature. we propose to approach the detection of gene and protein names in scientific abstracts as part-of-speech tagging, the most basic form of linguistic corpus annotation.\\n\\n\\nresults\\nwe present a method for tagging gene and protein names in biomedical text using a combination of statistical and knowledge-based strategies. this method incorporates automatically generated rules from a transformation-based part-of-speech tagger, and manually generated rules from morphological clues, low frequency trigrams, indicator terms, suffixes and part-of-speech information. results of an experiment on a test corpus of 56k medline documents demonstrate that our method to extract gene and protein names can be applied to large sets of medline abstracts, without the need for special conditions or human experts to predetermine relevant subsets.\\n\\n\\navailability\\nthe programs are available on request from the authors.",
            "contribution_ids": [
                "R148052"
            ]
        },
        {
            "instance_id": "R150570xR148039",
            "comparison_id": "R150570",
            "paper_id": "R148039",
            "text": "GENETAG: a tagged corpus for gene/protein named entity recognition abstract \\n \\n background \\n named entity recognition (ner) is an important first step for text mining the biomedical literature. evaluating the performance of biomedical ner systems is impossible without a standardized test corpus. the annotation of such a corpus for gene/protein name ner is a difficult process due to the complexity of gene/protein names. we describe the construction and annotation of genetag, a corpus of 20k medline \u00ae sentences for gene/protein ner. 15k genetag sentences were used for the biocreative task 1a competition. \\n \\n \\n results \\n to ensure heterogeneity of the corpus, medline sentences were first scored for term similarity to documents with known gene names, and 10k high- and 10k low-scoring sentences were chosen at random. the original 20k sentences were run through a gene/protein name tagger, and the results were modified manually to reflect a wide definition of gene/protein names subject to a specificity constraint, a rule that required the tagged entities to refer to specific entities. each sentence in genetag was annotated with acceptable alternatives to the gene/protein names it contained, allowing for partial matching with semantic constraints. semantic constraints are rules requiring the tagged entity to contain its true meaning in the sentence context. application of these constraints results in a more meaningful measure of the performance of an ner system than unrestricted partial matching. \\n \\n \\n conclusion \\n the annotation of genetag required intricate manual judgments by annotators which hindered tagging consistency. the data were pre-segmented into words, to provide indices supporting comparison of system responses to the \"gold standard\". however, character-based indices would have been more robust than word-based indices. genetag train, test and round1 data and ancillary programs are freely available at ftp://ftp.ncbi.nlm.nih.gov/pub/tanabe/genetag.tar.gz . a newer version of genetag-05, will be released later this year. \\n",
            "contribution_ids": [
                "R148041"
            ]
        },
        {
            "instance_id": "R150570xR148112",
            "comparison_id": "R150570",
            "paper_id": "R148112",
            "text": "2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text abstract \\n the 2010 i2b2/va workshop on natural language processing challenges for clinical records presented three tasks: a concept extraction task focused on the extraction of medical concepts from patient reports; an assertion classification task focused on assigning assertion types for medical problem concepts; and a relation classification task focused on assigning relation types that hold between medical problems, tests, and treatments. i2b2 and the va provided an annotated reference standard corpus for the three tasks. using this reference standard, 22 systems were developed for concept extraction, 21 for assertion classification, and 16 for relation classification. \\n these systems showed that machine learning approaches could be augmented with rule-based systems to determine concepts, assertions, and relations. depending on the task, the rule-based systems can either provide input for machine learning or post-process the output of machine learning. ensembles of classifiers, information from unlabeled data, and external knowledge sources can help when the training data are inadequate.",
            "contribution_ids": [
                "R148114"
            ]
        },
        {
            "instance_id": "R150570xR148032",
            "comparison_id": "R150570",
            "paper_id": "R148032",
            "text": "MedTag: A Collection of Biomedical Annotations we present a database of annotated biomedical text corpora merged into a portable data structure with uniform conventions. medtag combines three corpora, medpost, abgene and genetag, within a common relational database data model. the genetag corpus has been modified to reflect new definitions of genes and proteins. the medpost corpus has been updated to include 1,000 additional sentences from the clinical medicine domain. all data have been updated with original medline text excerpts, pubmed identifiers, and tokenization independence to facilitate data accuracy, consistency and usability. \\n \\nthe data are available in flat files along with software to facilitate loading the data into a relational sql database from ftp://ftp.ncbi.nlm.nih.gov/pub/lsmith/medtag/medtag.tar.gz.",
            "contribution_ids": [
                "R148034"
            ]
        },
        {
            "instance_id": "R151005xR149916",
            "comparison_id": "R151005",
            "paper_id": "R149916",
            "text": "Image domain ontology fusion approach using multi-level inference mechanism one of the main challenges in content-based or semantic image retrieval is still to bridge the gap between low-level features and semantic information. in this paper, an approach is presented using integrated multi-level image features in ontology fusion construction by a fusion framework, which based on the latent semantic analysis. the proposed method promotes images ontology fusion efficiently and broadens the application fields of image ontology retrieval system. the relevant experiment shows that this method ameliorates the problem, such as too many redundant data and relations, in the traditional ontology system construction, as well as improves the performance of semantic images retrieval.",
            "contribution_ids": [
                "R149918",
                "R150730",
                "R150931",
                "R150936",
                "R150937",
                "R150948",
                "R150953",
                "R150966",
                "R150974",
                "R150980",
                "R150985",
                "R150990",
                "R150995"
            ]
        },
        {
            "instance_id": "R151435xR151382",
            "comparison_id": "R151435",
            "paper_id": "R151382",
            "text": "A novel amperometric biosensor based on ZnO nanoparticles-modified carbon paste electrode for determination of glucose in human serum abstract zinc oxide nanoparticles-(znonps)modified carbon paste enzyme electrodes (znonpsmcpe) were developed for determination of glucose. the determination of glucose was carried out by oxidation of h2o2 at +0.4 v. znonpsmcpe provided biocompatible microenvironment for gox and necessary pathway of electron transfer between gox and electrode. the response of gox/znonpsmcpe was proportional to glucose concentration and detection limit was 9.1 \u00d7 10\u20133 mm. km and imax, were calculated as 0.124 mm and 2.033 \u03bca. the developed biosensor exhibits high analytical performance with wide linear range (9.1 \u00d7 10\u20133\u201314.5 mm), selectivity and reproducibility. serum glucose results allow us to ascertain practical utility of gox/znonpsmcpe biosensor.",
            "contribution_ids": [
                "R151384"
            ]
        },
        {
            "instance_id": "R151435xR151357",
            "comparison_id": "R151435",
            "paper_id": "R151357",
            "text": "Zinc oxide nanocomb biosensor for glucose detection single crystal zinc oxide nanocombs were synthesized in bulk quantity by vapor phase transport. a glucose biosensor was constructed using these nanocombs as supporting materials for glucose oxidase (gox) loading. the zinc oxide nanocomb glucose biosensor showed a high sensitivity (15.33\u03bca\u2215cm2mm) for glucose detection and high affinity of gox to glucose (the apparent michaelis-menten constant kmapp=2.19mm). the detection limit measured was 0.02mm. these results demonstrate that zinc oxide nanostructures have potential applications in biosensors.",
            "contribution_ids": [
                "R151359"
            ]
        },
        {
            "instance_id": "R151435xR151360",
            "comparison_id": "R151435",
            "paper_id": "R151360",
            "text": "ZnO Nanotube Arrays as Biosensors for Glucose highly oriented single-crystal zno nanotube (znt) arrays were prepared by a two-step electrochemical/chemical process on indium-doped tin oxide (ito) coated glass in an aqueous solution. the prepared znt arrays were further used as a working electrode to fabricate an enzyme-based glucose biosensor through immobilizing glucose oxidase in conjunction with a nafion coating. the present znt arrays-based biosensor exhibits high sensitivity of 30.85 \u03bca cm\u22122 mm\u22121 at an applied potential of +0.8 v vs. sce, wide linear calibration ranges from 10 \u03bcm to 4.2 mm, and a low limit of detection (lod) at 10 \u03bcm (measured) for sensing of glucose. the apparent michaelis\u2212menten constant kmapp was calculated to be 2.59 mm, indicating a higher bioactivity for the biosensor.",
            "contribution_ids": [
                "R151362"
            ]
        },
        {
            "instance_id": "R152186xR151898",
            "comparison_id": "R152186",
            "paper_id": "R151898",
            "text": "XUV Amplification in a Recombiningz-Pinch Plasma amplification of extreme ultraviolet (xuv) radiation at wavelengths about 50 nm in a recombining {ital z}-pinch plasma is reported. discharge currents of 40 ka were used to produce highly uniform plasma columns with a diameter of less than 500 {mu}m and a length of up to 9 cm. during the expansion of the pinch plasma, amplification at the 4{ital f}-3{ital d} and 4{ital d}-3{ital p} transitions of lithiumlike oxygen o vi was observed. the gain-length products were determined to be 2.5 (4{ital f}-3{ital d}) and 2.2 (4{ital d}-3{ital p}), corresponding to gain coefficients of 0.28 and 0.24 cm{sup {minus}1}, respectively. {copyright} {ital 1996 the american physical society.}",
            "contribution_ids": [
                "R151900"
            ]
        },
        {
            "instance_id": "R152186xR151852",
            "comparison_id": "R152186",
            "paper_id": "R151852",
            "text": "Efficient generation of highly ionized calcium and titanium plasma columns for collisionally excited soft-x-ray lasers in a fast capillary discharge fast discharges through 1.5-mm-diam capillaries have produced dense ca and ti plasma columns with an abundance of ne-like ions, which are of interest for the development of small-scale, collisionally excited soft-x-ray lasers. current pulses of 30 ns full width at half maximum and peak currents of less than 70 ka produced plasmas with line emission from ions with charge up to the f-like state. line emission at the wavelengths of the 3[ital p]-3[ital s] and 3[ital d]-3[ital p] transitions of the ne-like ions has been observed.",
            "contribution_ids": [
                "R151854"
            ]
        },
        {
            "instance_id": "R152186xR151925",
            "comparison_id": "R152186",
            "paper_id": "R151925",
            "text": "Optical gain for the Ne VIII 4-3 transition by capillary discharge pumping in order to investigate the potential of a capillary discharge as a pumping source for soft x-ray lasers the transitions in lithium-like neon were investigated. the discharge with a maximum current of 100 ka through 0.4-0.6 cm diameter gas-filled alumina tubes leads to two fluorescence maxima. the first is due to the collapse of the shock wave, whereas the second, appearing about 60 ns later, is ascribed to the recombination of ions and is enhanced by stimulated emission of radiation. by measuring at different tube lengths, the maximum gain-length product for the 29.2 nm transition was determined to be . a semi-empirical model for the discharge indicates that only part of the current drives a shock wave into the centre, while the other part flows through the surface region of the insulator. this plays an important role insofar as (i) it limits the maximum obtainable plasma temperature and (ii) it supplies sufficient ablated matter for a rapid cooling of the plasma necessary to obtain an inversion in the excited states of the ions. gain appears after the electron temperature in the centre of the plasma has dropped below about 15 ev. this is reached during the falling edge of the recombination phase.",
            "contribution_ids": [
                "R151926"
            ]
        },
        {
            "instance_id": "R152186xR151970",
            "comparison_id": "R152186",
            "paper_id": "R151970",
            "text": "Extreme Degree of Ionization in Homogenous Micro-Capillary Plasma Columns Heated by Ultrafast Current Pulses homogeneous plasma columns with ionization levels typical of megaampere discharges are created by rapidly heating gas-filled 520-\u03bcm-diameter channels with nanosecond rise time current pulses of 40\\xa0ka. current densities of up to 0.3\\u2009\\u2009ga\\u2009cm^{-2} greatly increase joule heating with respect to conventional capillary discharge z pinches, reaching unprecedented degrees of ionization for a high-z plasma column heated by a current pulse of remarkably low amplitude. dense xenon plasmas are ionized to xe^{28+}, while xenon impurities in hydrogen discharges reach xe^{30+}. the unique characteristics of these hot, \u223c300:1 length-to-diameter aspect ratio plasmas allow the observation of unexpected spectroscopic phenomena. axial spectra show the unusual dominance of the intercombination line over the resonance line of he-like al by nearly an order of magnitude, caused by differences in opacities in the axial and radial directions. these plasma columns could enable the development of sub-10-nm x-ray lasers.",
            "contribution_ids": [
                "R151972"
            ]
        },
        {
            "instance_id": "R152282xR149200",
            "comparison_id": "R152282",
            "paper_id": "R149200",
            "text": "Does E-government Education Meet Competency Requirements? An Analysis of the German University System from International Perspective necessary competencies in the context of e-government and the lack thereof have received some academic attention in the last years. questions remain, whether study programs for public administration pick up the topic, how it is conceptualized and taught in order to develop e-government competencies. this article analyzes which fundamental conceptualizations of e-government underlie study programs for public administration in germany and which e-government- and it-related topics are taught. against the background of two international study programs in e-government, the article discloses a parallelism of it-related and non-it-related topics within study programs, a technical bias in e-government programs, and outlines essentials for e-government education.",
            "contribution_ids": [
                "R149202"
            ]
        },
        {
            "instance_id": "R152282xR149031",
            "comparison_id": "R152282",
            "paper_id": "R149031",
            "text": "Developing E-Government Coursework through the NASPAA Competencies Framework information technology (it) is often less emphasized in coursework related to public administration education, despite the growing need for technological capabilities in those joining the public sector workforce. this coupled with a lesser emphasis on e-government/it skills by accreditation standards adds to the widening gap between theory and practice in the field. this study examines the emphasis placed on e-government/it concepts in master of public administration (mpa) and master of public policy (mpp) programs, either through complete course offerings or through related courses such as public management, strategic planning, performance measurement and organization theory. based on a content analysis of their syllabi, the paper analyzes the extent to which the it/e-government courses in mpa/master of public policy programs address the network of schools of public policy, affairs, and administration competency standards, and further discuss the orientation of the courses with two of the competencies: management and policy. specifically, are e-government/it courses more management-oriented or policy-oriented? do public management, strategic planning, performance measurement, and organization theory courses address it concerns?",
            "contribution_ids": [
                "R149033"
            ]
        },
        {
            "instance_id": "R152282xR149787",
            "comparison_id": "R152282",
            "paper_id": "R149787",
            "text": "Identifying Collaborative Competencies increasingly, federal organizations must work together with other organizations to jointly produce public value. thus, it is important for public employees to develop critical collaborative skills. the national academy of public administration affirmed this by calling for a focus on collaborative competencies, but the question remained: what are collaborative competencies? many skills are theoretically connected to collaboration, but these links have not been tested empirically. following the methodology developed by mcclelland and furthered by spencer and spencer, this article presents the results of a collaborative competency study. this investigation involved the use of matched criterion samples (superior versus average collaborators) from the federal government. individuals in the criterion samples were interviewed using the behavioral event interview design to identify differentiating competencies and create a competency model for future validation.",
            "contribution_ids": [
                "R149789"
            ]
        },
        {
            "instance_id": "R152282xR149807",
            "comparison_id": "R152282",
            "paper_id": "R149807",
            "text": "E-Government at Work Level: Skilling or De-skilling? essential competences, i.e. abilities, skills, knowledge and motivation, are an aspect of e-government that is neglected in the scientific debate as well as in practice. the background is that manual operations are still carried out in an it-based public administration. with regard to the work organization, the article investigates how the competences for employees have transformed at the operative level. based on the results of case studies it becomes evident that neither a skilling nor de-skilling process is taking place, but rather a re-skilling process. this means that competence requirements at a workplace are increasing and decreasing at the same time. it becomes particularly apparent that the social skill requirements are growing as the socio-technical networking is expanding. even though it supports the interaction at the organizational interfaces, it cannot replace the social competence requirements and new meta competences. this presents a major limitation for implementing networked forms of organization which are enabled by it.",
            "contribution_ids": [
                "R149809"
            ]
        },
        {
            "instance_id": "R152282xR149715",
            "comparison_id": "R152282",
            "paper_id": "R149715",
            "text": "Government chief information officer (GCIO) ontology: a tool to formalize the GCIO function information technology (it) leadership is essential for the successful utilization of information and communication technology (ict) in any organizational context. in particular, it leadership is a critical success factor for every electronic government (e-government) initiative. most of the leading countries in e-government development have adopted the chief information officer (gcio) function to lead and coordinate their technology-related projects. in addition, most influential international e-government rankings -- like those conducted by united nations and waseda university; include the presence of the function in their assessment criteria. however, the adoption of the function entails broader actions than the merely establishment of the position itself. several prerequisites, such as qualified human resources, coordination and collaboration capabilities, and governance mechanisms, among others, need to be available in government for the proper establishment and sustainability of the function. despite its broader adoption in practice, there is scarce literature to assist governments in understanding the complexities of the gcio function and making the prerequisites available. this paper presents the development of ontology to formally define the gcio function. the main contribution of this work is to offer a tool for sharing and reusing the existing knowledge in the gcio domain, filling the research-practice gap identified above.",
            "contribution_ids": [
                "R149717"
            ]
        },
        {
            "instance_id": "R152282xR149034",
            "comparison_id": "R152282",
            "paper_id": "R149034",
            "text": "E-governance competence: a framework while there is abundance of research on e-governance readiness and convergence, there is lack of research and theoretical understanding of competencies that governments must have to develop and deploy effective e-services and ensure usage of the deployed e-services in a manner that leads to effective e-governance. in this research, we draw from business/it alignment framework, innovation literature, and coordination theory and propose a framework of e-governance competence that highlights the importance of technical and administrative alignment capability at strategic and operational levels for effective e-governance. we validate the proposed model in the context of immigration-related e-services provided by the hong kong sar, p.r.c. the theoretical and practical implications are discussed.",
            "contribution_ids": [
                "R149036"
            ]
        },
        {
            "instance_id": "R152282xR149028",
            "comparison_id": "R152282",
            "paper_id": "R149028",
            "text": "e-Government: People and Skills in Europe&amp;#146;s Administrations this paper outlines the findings of a study entitled \"organisational changes, skills and the role of leadership required by egovernment\" carried out within the european public administration network (epan) in the first half of 2005. the study aims to provide a basis for discussion among the director-generals responsible for public administration in the member states of the european union; to identify learning points from selected good practice cases in the member states; and to make recommendations with a focus on the skills and competences required for public sector employees to manage and govern change in the public administrations of the member states of the european union. the paper also takes into account the discussions of a follow-up workshop at the european institute of public administration, in maastricht, the netherlands, on 24 june 2005.",
            "contribution_ids": [
                "R149030"
            ]
        },
        {
            "instance_id": "R152282xR149043",
            "comparison_id": "R152282",
            "paper_id": "R149043",
            "text": "The gap between CIO core competencies and the real roles of CIOs \"our lives have become more convenient than before due to the advanced technology. we are blessed by the benefits of the information society. new industry has been developed by open data. promotion of e-government leads to cost reduction by utilizing cloud computing. on the other hand, by evolution of the information society, we expose ourselves to the threat of viruses and cyber-attack. under these circumstances, cios are responsible for various competencies such as ict strategies for e-government, risk management, information assurance and cyber security, ict budget, ict investment and compliance. this paper analyzes the new trend of cio's functions in the aspect of cio core competencies. cio core competencies were identified in the us in 1996. this paper prioritizes cio core competencies and finds that there is a gap between the core competencies and real roles of cios. as a result cios do not play an effective role in their organizations. the methodology of this paper is data analysis of surveys done in 2006, 2009, 2012 and 2014. the 2014 survey on the preferred core competencies was conducted in cooperation with george mason university (gmu) in the us, one of the 6 cio universities certified by the us federal government.\"",
            "contribution_ids": [
                "R149045"
            ]
        },
        {
            "instance_id": "R152282xR149730",
            "comparison_id": "R152282",
            "paper_id": "R149730",
            "text": "Towards a set of specific competences for academic degree programmes in Public Administration in Europe the authors present results of the first phase of \u201ctuning\u2010pa\u201d, a research project of eapaa in collabo\u2010 ration with egpa and nispacee on identifying and assessing competences relevant for academic degree programmes in public administration throughout europe. the project is based on results of an eu\u2010funded research programme called tuning\u2010initiative. the initiative collected competences and learning outcomes in a variety of academic disciplines but not in pa. the authors introduce the ter\u2010 minology of tuning\u2010pa, present a proposal of pa\u2010specific competence domains and of sub\u2010domains of these domains and discuss the empirical findings of an online survey about competences in use of altogether 46 pa\u2010programmes across europe. finally, the next steps of the research project are in\u2010 troduced.",
            "contribution_ids": [
                "R149731"
            ]
        },
        {
            "instance_id": "R152282xR149239",
            "comparison_id": "R152282",
            "paper_id": "R149239",
            "text": "Leadership competencies for effective public administration: a study of Indian Administrative Service officers abstract public administrative service occupies a strategic position in the public governance system of any nation. contemporary public administration needs competent public managers who are able to make sense of the ambiguity inherent in the job. this study presents an attempt to identify important competencies needed for public administrators (specifically district magistrates in india, a peak leadership role in the public service). based on focused-group discussions and a survey of 218 indian administrative service officers, the study identified eight competencies, namely people first; leading others; integrity; decision-making; planning, coordination and implementation; problem-solving; self-awareness and self-control; and innovative thinking. the eight competencies were further clubbed under four meta-competencies, namely stakeholder analysis and decision-making, managing change and innovation, team building and positive administrator personality. a detailed description of the behaviours included within each competency and meta-competency is provided. implications for theory and practice are discussed.",
            "contribution_ids": [
                "R149242"
            ]
        },
        {
            "instance_id": "R152282xR149040",
            "comparison_id": "R152282",
            "paper_id": "R149040",
            "text": "Looking for a five-legged sheep: identifying enterprise architects' skills and competencies \"enterprise architecture (ea) is a holistic approach to comprehend the organization's business objectives and processes, data resources, information systems and information technologies. to advance ea activities, organizations need a myriad of different skills and competences both from individual enterprise architects and from architect teams. however, research on these skills and competences is scarce. not knowing what skills are actually needed might be one of the reasons why public sector ea endeavors have been very problematic. in this paper, we conduct a qualitative survey among enterprise architects themselves to identify which skills they consider essential for ea work. our results indicate that the range of skills is great, and finding an expert with all appropriate competencies is like looking for a five-legged sheep.\"",
            "contribution_ids": [
                "R149042"
            ]
        },
        {
            "instance_id": "R152282xR149229",
            "comparison_id": "R152282",
            "paper_id": "R149229",
            "text": "Professional sense\u00e2\u0080\u0090makers: managerial competencies amidst ambiguity in this article, managerial competencies are derived from observations of public managers in action. based on institutional theory, it is assumed that public managers are competent when they know how to play the game of public management and how to apply the rules of the game. this assumption is legitimated by the use of the concept of ambiguity, which underscores the fuzzy, contested and equivocal nature of real life policy issues. when issues are fuzzy and equivocal, multiple ways of behaving are thinkable, so public managers will not do what is \u201cbest\u201d, but what is considered to be \u201cappropriate\u201d. in a study of 12 public managers in action, it was observed how they allocated their attention amid different kinds of ambiguity which included unstable issue linkages, unclear impacts, continuous contestation and unpredictable exposure. individual public managers handled these conditions by being able to do three things: they interpreted signals and events; institutionalized issues by creating issue labels, meetings, meeting items and texts and by establishing political back up; and they produced appropriate texts, in time, in order to take away unnecessary \u201cheat\u201d.",
            "contribution_ids": [
                "R149231"
            ]
        },
        {
            "instance_id": "R152282xR149735",
            "comparison_id": "R152282",
            "paper_id": "R149735",
            "text": "Professionalism of Civil Servants as the Factor of Public Administration Efficiency Growth the problems of efficiency growth of state run public authorities and governmental authorities are considered in the article. professionalism of civil servants is the focus of the authors. based on an analysis of the current practice of public administration they come to the conclusion that the human resource \u2013knowledge and skills of management activity parties \u2013 is in the basis of its performance. the experience of using the competency approach in civil service in the republic of tatarstan is summarized in the article. doi: 10.5901/mjss.2015.v6n1s3p481",
            "contribution_ids": [
                "R149737"
            ]
        },
        {
            "instance_id": "R152282xR149795",
            "comparison_id": "R152282",
            "paper_id": "R149795",
            "text": "Developing Benchmarks for Guiding CAO Performance this article reviews a research study on developing performance benchmarks to guide chief administrative officer performance in nova scotia. the study collected examples of excellent and substandard performance from 22 individuals who were caos, members of council, or provincial advisors. the information was content analysed, revealing 13 competency areas, illustrating four types of competencies. a practical aspect of this study is the suggestion that the competencies might be arranged in a semicausal logic model (or competency scorecard, similar to the balanced scorecard) and that performance measures might include outcome and activity measures. the framework might guide researchers in calibrating the linkage between competencies and organisational performance measures.",
            "contribution_ids": [
                "R149797"
            ]
        },
        {
            "instance_id": "R152282xR149803",
            "comparison_id": "R152282",
            "paper_id": "R149803",
            "text": "Enabling the Cream to Rise to the Top: A Cross-Jurisdictional Comparison of Competencies for Senior Managers in the Public Sector the use of competencies to identify and target leaders in organizations has picked up steam in the past decade or so. drawing from the private sector, the public sectors of several advanced countries have comprehensively employed the competency approach within their own governance and management systems. this article looks at the employment of competencies in the senior public services of five jurisdictions and concludes that cross-jurisdictional similarity is evident only on \u201cvision and strategy,\u201d although people-related skills also appear as core competencies for enior managers. the article also argues that further research is necessary to understand why competencies in use in the senior public services differ so markedly from those in other organizations and settings.",
            "contribution_ids": [
                "R149805"
            ]
        },
        {
            "instance_id": "R152282xR149792",
            "comparison_id": "R152282",
            "paper_id": "R149792",
            "text": "Changing competences of public managers: tensions in commitment the literature on managerial competences has not sufficiently addressed the value contents of competences and the generic features of public managers. this article presents a model of five competence areas: task competence, professional competence in substantive policy field, professional competence in administration, political competence and ethical competence. each competence area includes both value and instrumental competences. relatively permanent value competences are understood as commitments. the assumptions of new public management question not only the instrumental competences but also the commitments of traditional public service. the efficacy of human resource development is limited in learning new commitments. apart from structural reforms that speed up the process, the friction in the change of commitments is seen as slow cultural change in many public organisations. this is expressed by transitional tensions in task commitment, professional commitment, political commitment, and ethical commitment of public managers.",
            "contribution_ids": [
                "R149794"
            ]
        },
        {
            "instance_id": "R152282xR149732",
            "comparison_id": "R152282",
            "paper_id": "R149732",
            "text": "Training the IT-Savvy Public Manager: Priorities and Strategies for Public Management Education abstract despite big budgets, political endorsement, and formal frameworks for information policy, technology, and management, government information technology (it) projects continue to falter or fail. this paper argues that public management education must include information strategy and management topics as core concerns. mpa programs should be teaching the next generation of public managers to appreciate how deeply embedded it is in every aspect of government\u2014and to appreciate their own roles and responsibilities in it. the paper reviews practical experience and academic research on information systems in government and identifies five kinds of competencies that are most needed to build successful information strategies and systems in the public sector.these include strategic thinking and evaluation, system-oriented analytical skills, information stewardship, technical concepts, and complex project management skills.the article concludes with a variety of approaches for bringing these competencies into the master of public administration curriculum.",
            "contribution_ids": [
                "R149734"
            ]
        },
        {
            "instance_id": "R152282xR149244",
            "comparison_id": "R152282",
            "paper_id": "R149244",
            "text": "Building new competencies for government administrators and managers in an era of public sector reforms: the case of Mozambique african public administration today is mixed with elements of the old bureaucratic model continuing alongside the new public management (npm). the increasing application of the npm approach has placed public administration and management systems in the spotlight and raised a number of challenges. among them are the relevance of policy importation and the availability of civil servants with the requisite competence to perform the very critical responsibilities of government that reforms introduce. using the case of mozambique, this article shows that implementation of public sector reforms has brought in its trail considerable gaps between reform strategies and the competences needed to execute them. convinced that competences of public administrators are a vital prerequisite for the success of reforms, the government of mozambique has instituted a series of training programmes to provide the kind of competences that would reflect the new demands and realities facing the public sector. though it is too early to expect results, the article concludes that the technical, managerial and leadership skills of public administrators and managers are being improved through better training curricula than were provided in the past. points for practitioners the structure, functions, and processes of public administration and management have undergone remarkable changes as a result of npm approaches. but as new approaches are being introduced, government managers have found themselves trying very hard to manage using old skills. in almost every profession, new circumstances require the development of new, or a redefinition of existing, skills. institutionalizing new training curricula to provide technical, managerial and leadership competence for government administrators has become imperative now more than ever before. the caveat is that building new competencies will not necessarily fix all the problems unless other structural problems such as remuneration, promotion and utilization of ex-trainees are also addressed.",
            "contribution_ids": [
                "R149246"
            ]
        },
        {
            "instance_id": "R152282xR149778",
            "comparison_id": "R152282",
            "paper_id": "R149778",
            "text": "Aligning leadership and competences in recruitment and staff development: an empirical analysis in the context of regional public administration in the last decade, competences have gained a special interest in all pillars of the triple-helix model, namely academia, administration and business. several competence models have been developed and put into practice in different public administration contexts. leadership is one of the most important valued competences in business. including competences and high-value leadership in the public administration is part of a process conducive to a more professional service. the empirical evidences come from a survey conducted recently. during the present study, personal and professional profiles as well as leadership styles of the target population are analysed on a sample of 160 managers in different departments of the autonomous government of catalonia (spain) engaged in the local public administration of the city of girona. our results show that competences highlighted as most important in the selection of managerial positions are commitment, professional ethics, understanding, and self-control of ones behaviour or actions related to values and professional ethics in general. aspects related to teamwork or focused on people, with specific importance placed on the self-control of emotions are also important, followed by efficient time management, tenacity and perseverance, as well as the adaptability to deal with different, changing conditions in the workplace.",
            "contribution_ids": [
                "R149780"
            ]
        },
        {
            "instance_id": "R152282xR149799",
            "comparison_id": "R152282",
            "paper_id": "R149799",
            "text": "Collaborative Leadership Development For Local Government Officials: Exploring Competencies and Program Impact introduction one hundred years after frederick taylor\\'s seminal work, the principles of scientific management (1911), it is worthwhile to observe how much the concept of leadership has evolved. core themes of motivation, performance, and human interaction have developed and become more sophisticated (yukl, 2010). \"great man\" or \"trait\" theories have been replaced by more complex, interactive theories of leadership. however, the traditional notion of leadership focusing on hierarchical leaders and followers remains dominant in popular conceptions of leadership and in programs that seek to develop leaders. what characterized leadership in 20th-century organizations shaped by taylor\\'s scientific management paradigm contrasts with emerging, contemporary organizational priorities of the 21st century. today\\'s leadership context, particularly in the public sector, is interorganizational. in public administration in particular, this shift corresponds with an emerging collaborative governance paradigm that is reorienting the field away from a focus on hierarchy, toward a focus on networks and partnerships that cross traditional boundaries (emerson, nabatchi & balogh, 2012). this new focus highlights the need to develop leadership competencies that extend beyond traditional, hierarchical, managerial functions (morse, 2008; sullivan, williams & jeffares, 2012). while it is important to understand how the definition of leadership has transformed over time, it is equally important to consider the connected task of developing leaders. iles and preece (2006) highlighted this need by noting that public leadership development programs must expand their efforts to build the competencies that create value both within organizations and beyond. considering how these competencies align with leadership training components is necessary to assess training gaps and opportunities for improvement. the transition from leading within organizations to leading beyond them places new demands on leadership development programs. drawing upon the growing body of literature on collaborative competencies, as well as the literature on leadership development, along with experiences and data from two local government leadership development programs, this article addresses the call to develop leaders who can achieve results both within traditional organizational structures and also across organizational and sectoral boundaries. this article utilizes program-specific information to offer insights and respond to the question presented in getha-taylor, holmes, jacobson, morse and sowa (2011, p. i92): \"which programs, strategies, and curricula are most appropriate to build and nurture leadership skills for public leadership \\'across boundaries\\'?\" to this end, three related questions of interest are explored: 1) what additional leadership competencies are required of local government managers for collaborative governance? 2) which programmatic components are best suited to develop collaborative competencies? 3) what are the most appropriate methods to evaluate the expected outcomes of collaborative leadership development programs? the article is organized accordingly. first, we review literature on collaborative leadership and collaborative competencies and examine arguments calling for the development of those competencies in public leaders. next, we consider how training curricula should adapt to develop collaborative competency development. we present insights from local government executive development programs in north carolina and kansas and examine data collected from program participants to consider which programmatic components are best suited to develop collaborative leadership competencies. we then turn to the question of how to evaluate program impact on collaborative competency, again utilizing data from the two programs being studied. finally, we conclude with a discussion of the implications of this research and offer advice for others engaged in training public sector executives. \u2026",
            "contribution_ids": [
                "R149801"
            ]
        },
        {
            "instance_id": "R152282xR149224",
            "comparison_id": "R152282",
            "paper_id": "R149224",
            "text": "Competency Requirements for Transformational E-Government \"one key aspect of e-government is its potential for an ict enabled transformation of the public sector. through ict, new forms of collaboration and inter-organizational public service networks become feasible, making it possible to carry out the public sector's tasks more efficiently and effectively. however, a rather significant gap exists between this transformational potential and the tangible results that have been achieved so far. one reason for this slow and cumbersome implementation seems to be that public managers lack the necessary competencies to bring the promises of e-government to fruition. this article analyzes the changing competency requirements for public managers that accompany e-government and describes the first steps in the development of an e-government competency framework for public managers. the article sums up the results of a literature review on e-government competencies, a survey carried out for the article, and data gathered in focus group workshops. based on these results, a first set of e-government competencies is then outlined that goes beyond pure ict skills. the article concludes with a discussion of the framework and its implications for human resource management in the public sector.\"",
            "contribution_ids": [
                "R149226"
            ]
        },
        {
            "instance_id": "R154289xR147125",
            "comparison_id": "R154289",
            "paper_id": "R147125",
            "text": "WWW'18 Open Challenge: Financial Opinion Mining and Question Answering the growing maturity of natural language processing (nlp) techniques and resources is dramatically changing the landscape of many application domains which are dependent on the analysis of unstructured data at scale. the finance domain, with its reliance on the interpretation of multiple unstructured and structured data sources and its demand for fast and comprehensive decision making is already emerging as a primary ground for the experimentation of nlp, web mining and information retrieval (ir) techniques for the automatic analysis of financial news and opinions online. this challenge focuses on advancing the state-of-the-art of aspect-based sentiment analysis and opinion-based question answering for the financial domain.",
            "contribution_ids": [
                "R147127"
            ]
        },
        {
            "instance_id": "R154289xR147133",
            "comparison_id": "R154289",
            "paper_id": "R147133",
            "text": "SemEval-2017 Task 3: Community Question Answering we describe semeval\u20132017 task 3 on community question answering. this year, we reran the four subtasks from semeval-2016: (a) question\u2013comment similarity, (b) question\u2013question similarity, (c) question\u2013external comment similarity, and (d) rerank the correct answers for a new question in arabic, providing all the data from 2015 and 2016 for training, and fresh data for testing. additionally, we added a new subtask e in order to enable experimentation with multi-domain question duplicate detection in a larger-scale scenario, using stackexchange subforums. a total of 23 teams participated in the task, and submitted a total of 85 runs (36 primary and 49 contrastive) for subtasks a\u2013d. unfortunately, no teams participated in subtask e. a variety of approaches and features were used by the participating systems to address the different subtasks. the best systems achieved an official score (map) of 88.43, 47.22, 15.46, and 61.16 in subtasks a, b, c, and d, respectively. these scores are better than the baselines, especially for subtasks a\u2013c.",
            "contribution_ids": [
                "R147135"
            ]
        },
        {
            "instance_id": "R154289xR147113",
            "comparison_id": "R154289",
            "paper_id": "R147113",
            "text": "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset this paper presents our recent work on the design and development of a new, large scale dataset, which we name ms marco, for machine reading comprehension. this new dataset is aimed to overcome a number of well-known weaknesses of previous publicly available datasets for the same task of reading comprehension and question answering. in ms marco, all questions are sampled from real anonymized user queries. the context passages, from which answers in the dataset are derived, are extracted from real web documents using the most advanced version of the bing search engine. the answers to the queries are human generated. finally, a subset of these queries has multiple answers. we aim to release one million queries and the corresponding answers in the dataset, which, to the best of our knowledge, is the most comprehensive real-world dataset of its kind in both quantity and quality. we are currently releasing 100,000 queries with their corresponding answers to inspire work in reading comprehension and question answering along with gathering feedback from the research community.",
            "contribution_ids": [
                "R147115"
            ]
        },
        {
            "instance_id": "R154289xR147106",
            "comparison_id": "R154289",
            "paper_id": "R147106",
            "text": "SQuAD: 100,000+ Questions for Machine Comprehension of Text we present the stanford question answering dataset (squad), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. we analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. we build a strong logistic regression model, which achieves an f1 score of 51.0%, a significant improvement over a simple baseline (20%). however, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. \\nthe dataset is freely available at this https url",
            "contribution_ids": [
                "R147108"
            ]
        },
        {
            "instance_id": "R155101xR154823",
            "comparison_id": "R155101",
            "paper_id": "R154823",
            "text": "Characteristics of a Saturated 18.9-nm Tabletop Laser Operating at 5-Hz Repetition Rate \"we report the characteristics of a saturated high-repetition rate ni-like mo laser at 18.9 nm. this table-top soft x-ray laser was pumped at a 5-hz repetition rate by 8-ps 1-j optical laser pulses impinging at grazing incidence into a precreated mo plasma. the variation of the laser output intensity as a function of the grazing incidence angle of the main pump beam is reported. the maximum laser output intensity was observed for an angle of 20/spl deg/, at which we measured a small signal gain of 65 cm/sup -1/ and a gain-length product g/spl times/l>15. spatial coherence measurements resulting from a young's double-slit interference experiment show the equivalent incoherent source diameter is about 11 /spl mu/m. the peak spectral brightness is estimated to be of the order of 1/spl times/10/sup 24/ photons s/sup -1/ mm/sup -2/ mrad/sup -2/ within 0.01% spectral bandwidth. this type of practical, small scale, high-repetition soft x-ray laser is of interest for many applications.\"",
            "contribution_ids": [
                "R154825"
            ]
        },
        {
            "instance_id": "R155101xR154715",
            "comparison_id": "R155101",
            "paper_id": "R154715",
            "text": "Saturated high-repetition-rate 189-nm tabletop laser in nickellike molybdenum we report saturated operation of an 18.9-nm laser at 5-hz repetition rate. an amplification with a gain-length product gl of 15.5 is obtained in the 4d 1s0-4p 1p1 laser line of ni-like mo in plasmas heated at grazing incidence with approximately 1-j pulses of 8.1-ps duration from a tabletop laser system. lasing is obtained over a broad range of time delays and pumping conditions. we also measure a gl of 13.5 in the 22.6-nm transition of the same ion. the results are of interest for numerous applications requiring high-repetition-rate lasers at wavelengths below 20 nm.",
            "contribution_ids": [
                "R154717"
            ]
        },
        {
            "instance_id": "R155101xR154299",
            "comparison_id": "R155101",
            "paper_id": "R154299",
            "text": "Demonstration of Soft X-Ray Lasing to Ground State in Li III soft x-ray lasing with a gain length gl{approx_equal}5.5 was demonstrated in hydrogenlike liiii at 13.5 nm (2-1 transition) in a 5 mm long lif microcapillary using a 50 mj, 250 fs uv laser beam at a 2 hz repetition rate. the initial plasma was created in the 0.3 mm diameter microcapillary by a low power nd/yag laser. the strongly nonlinear increase of the 13.5 nm line intensity with increasing microcapillary length was compared with a linear increase of the liiii 11.4 nm (3-1 transition) line intensity. {copyright} {ital 1996 the american physical society.}",
            "contribution_ids": [
                "R154300"
            ]
        },
        {
            "instance_id": "R155101xR155003",
            "comparison_id": "R155101",
            "paper_id": "R155003",
            "text": "1\u00e2\u0080\u0089\u00e2\u0080\u0089J, 05\u00e2\u0080\u0089\u00e2\u0080\u0089kHz repetition rate picosecond laser we report the demonstration of a diode-pumped chirped pulse amplification yb:yag laser that produces \u03bb=1.03\\u2009\\u2009\u03bcm pulses of up to 1.5 j energy compressible to sub-5 ps duration at a repetition rate of 500 hz (750 w average power). amplification to high energy takes place in cryogenically cooled yb:yag active mirrors designed for kilowatt average power laser operation. this compact laser system will enable new advances in high-average-power ultrashort-pulse lasers and high-repetition-rate tabletop soft x-ray lasers. as a first application, the laser was used to pump a 400 hz \u03bb=18.9\\u2009\\u2009nm laser.",
            "contribution_ids": [
                "R155005"
            ]
        },
        {
            "instance_id": "R155101xR154866",
            "comparison_id": "R155101",
            "paper_id": "R154866",
            "text": "High-energy 139\u00e2\u0080\u0089nm table-top soft-x-ray laser at 25\u00e2\u0080\u0089Hz repetition rate excited by a slab-pumped Ti:sapphire laser we have demonstrated repetitive operation of a table-top lambda=13.9 nm ni-like ag soft-x-ray laser that generates laser pulses with 10 microj energy. the soft-x-ray laser is enabled by a ti:sapphire laser pumped by high-repetition-rate frequency-doubled high-energy nd:glass slab amplifiers. soft-x-ray laser operation at 2.5 hz repetition rate resulted in 20 microwatt average power.",
            "contribution_ids": [
                "R154868"
            ]
        },
        {
            "instance_id": "R155101xR154764",
            "comparison_id": "R155101",
            "paper_id": "R154764",
            "text": "Demonstration of high-repetition-rate tabletop soft-x-ray lasers with saturated output at wavelengths down to13.9nmand gain down to10.9nm saturated tabletop lasers operating at 5 hz repetition rate with average powers 1 w were demonstrated at wavelengths between 16.5 and 13.9 nm in the 4d 1 s 0 \u20134 p 1 p 1 transitions of ni-like ions. the results were obtained using picosecond laser heating pulses with an energy of only 1 j by optimizing the angle of incidence for maximum energy deposition. lasing was also observed for shorter wavelength transitions of the same isoelectronic sequence, with amplification in the 11.9 nm line of ni-like sn approaching gain saturation, and progressively reduced gain for wavelengths as low as 10.9 nm for ni-like te. these high repetition rate soft x-ray lasers will enable new applications in science and the development of unique metrology and processing tools for industry.",
            "contribution_ids": [
                "R154765"
            ]
        },
        {
            "instance_id": "R155101xR154909",
            "comparison_id": "R155101",
            "paper_id": "R154909",
            "text": "Demonstration of a 100\u00c2\u00a0Hz repetition rate gain-saturated diode-pumped table-top soft x-ray laser we demonstrate the operation of a gain-saturated table-top soft x-ray laser at 100 hz repetition rate. the laser generates an average power of 0.15 mw at \u03bb=18.9\\u2009\\u2009nm, the highest laser power reported to date from a sub-20-nm wavelength compact source. picosecond laser pulses of 1.5 \u03bcj energy were produced at \u03bb=18.9\\u2009\\u2009nm by amplification in a mo plasma created by tailoring the temporal intensity profile of single pump pulses with 1 j energy produced by a diode-pumped chirped pulse amplification yb:yag laser. lasing was also obtained in the 13.9 nm line of ni-like ag. these results increase by an order of magnitude the repetition rate of plasma-based soft x-ray lasers opening the path to milliwatt average power table-top lasers at sub-20 nm wavelengths.",
            "contribution_ids": [
                "R154911"
            ]
        },
        {
            "instance_id": "R155621xR155603",
            "comparison_id": "R155621",
            "paper_id": "R155603",
            "text": "Effect of dimethyl\u00e2\u0080\u0090\u00ce\u00b2\u00e2\u0080\u0090cyclodextrin concentrations on the pulmonary delivery of recombinant human growth hormone dry powder in rats the aim of this article is to prepare and characterize inhalable dry powders of recombinant human growth hormone (rhgh), and assess their efficacy for systemic delivery of the protein in rats. the powders were prepared by spray drying using dimethyl-beta-cyclodextrin (dmbetacd) at different molar ratios in the initial feeds. size exclusive chromatography was performed in order to determine protecting effect of dmbetacd on the rhgh aggregation during spray drying. by increasing the concentration of dmbetacd, rhgh aggregation was decreased from 9.67 (in the absence of dmbetacd) to 0.84% (using dmbetacd at 1000 molar ratio in the spray solution). the aerosol performance of the spray dried (sd) powders was evaluated using andersen cascade impactor. fine particle fraction values of 53.49%, 33.40%, and 23.23% were obtained using dmbetacd at 10, 100, and 1000 molar ratio, respectively. in vivo studies showed the absolute bioavailability of 25.38%, 76.52%, and 63.97% after intratracheal insufflation of the powders produced after spray drying of the solutions containing dmbetacd at 10, 100, and 1000 molar ratio, respectively in rat. in conclusion, appropriate cyclodextrin concentration was achieved considering the protein aggregation and aerosol performance of the sd powders and the systemic absorption following administration through the rat lung.",
            "contribution_ids": [
                "R155605"
            ]
        },
        {
            "instance_id": "R155621xR155595",
            "comparison_id": "R155621",
            "paper_id": "R155595",
            "text": "Encapsulation of insulin\u00e2\u0080\u0093cyclodextrin complex in PLGA microspheres: a new approach for prolonged pulmonary insulin delivery the insulin administration by pulmonary route has been investigated in the last years with good perspectives as alternative for parenteral administration. however, it has been reported that insulin absorption after pulmonary administration is limited by various factors. moreover, in the related studies one daily injection of long-acting insulin was necessary for a correct glycemic control. to abolish the insulin injection, the present study aimed to develop a new formulation for prolonged pulmonary insulin delivery based on the encapsulation of an insulin:dimethyl-\u03b2-cyclodextrin (ins:dm-\u03b2-cd) complex into plga microspheres. the molar ratio of insulin/cyclodextrin in the complex was equal to 1:5. the particles were obtained by the w/o/w solvent evaporation method. the inner aqueous phase of the w/o/w multiple emulsion contained the ins:dm-\u03b2-cd complex. the characteristics of the ins:dm-\u03b2-cd complex obtained were assessed by 1h-nmr spectroscopy and circular dichroism study. the average diameter of the microspheres prepared, evaluated by laser diffractometry, was 2.53\\u2009\u00b1\\u20091.8\\u2009\u00b5m and the percentage of insulin loading was 14.76\\u2009\u00b1\\u20091.1. the hypoglycemic response after intratracheal administration (3.0\\u2009i.u.\\u2009kg\u22121) of ins:dm-\u03b2-cd complex-loaded microspheres to diabetic rats indicated an efficient and prolonged release of the hormone compared with others insulin formulations essayed.",
            "contribution_ids": [
                "R155597"
            ]
        },
        {
            "instance_id": "R155621xR151609",
            "comparison_id": "R155621",
            "paper_id": "R151609",
            "text": "Current Ocular Drug Delivery Challenges for N-acetylcarnosine: Novel Patented Routes and Modes of Delivery, Design for Enhancement of Therapeutic Activity and Drug Delivery Relationships this review article explores the functional activity and development aspects of n-acetylcarnosine for the visual system as revealed by the use of a variety of biophysical, physiological and therapeutic ophthalmic methods. it is designed for pharmacists and more advanced ophthalmology, optometry and pharmacology researchers who wish to gain a basic understanding of the biological effects of n-acetylcarnosine for vision and to share in the excitement of the latest developments in this field. topics under the consideration include: ophthalmic drug delivery of n-acetylcarnosine eye drops and challenging endeavors facing the pharmaceutical scientist; clinical and functional types of activity of the developed and patented n-acetylcarnosine lubricant eye drops designed as 1% n-acetylcarnosine prodrug of l-carnosine containing a mucoadhesive cellulose-based compound combined with corneal absorption promoters in a drug delivery system; management of age-related serious or disabling eye diseases in humans with n-acetylcarnosine eye drop therapeutic platform (age-related cataracts, ocular inflammation, age-related macular degeneration , macular dystrophies, ocular manifestations of diabetes , hypertonic retinopathy, primary open angle glaucoma, vitreous lesions) ; development and molecular mechanisms of ocular therapeutic activities of carnosine derivatives in the visual system. through this article we can perceive some helpful recent patents according to the title of the issue. the biologically significant applications of carnosine mimetics including those in ophthalmology were patented by dr. babizhayev and the alliance groups (wo 2004/028536 a1; wo 94/19325; wo 95/12581; wo 2004/064866 a1).",
            "contribution_ids": [
                "R151611"
            ]
        },
        {
            "instance_id": "R155621xR151529",
            "comparison_id": "R155621",
            "paper_id": "R151529",
            "text": "Topical drug delivery to the posterior segment of the eye: anatomical and physiological considerations drug delivery to the posterior segment of the eye is important for potentially treating various disorders in retina, choroid, vitreous humor and optic nerve. due to anatomic membrane barriers and the lacrimal drainage it can be quite challenging to obtain therapeutic drug concentrations in the posterior parts of the eye after topical drug administration. since the membrane barriers cannot be altered with non-invasive methods invasive methods such as direct drug injection into the vitreous humor and subconjunctival, subtenons capsule or suprascleral injections are gaining popularity. however, invasive methods can cause discomfort for the patient and can also lead to complications that are even more serious than the disease being treated. alternatively, novel ophthalmic formulations can be developed that specifically target topical drug delivery to the posterior segment of the eye. anatomical and physiological barriers in the eye are reviewed as well as the theoretical model of passive drug diffusion from the eye surface into the eye. it is shown that enhanced drug delivery through conjunctiva/sclera to retina can be obtained by formulating lipophilic drugs as hydrophilic drug/cyclodextrin complex solutions. optimization of the delivery system by formulating the drug as a low-viscosity aqueous drug/cyclodextrin complex suspension results in sustained high concentrations of dissolved drug in the tear fluid which further increases the targeted drug delivery to the posterior segment.",
            "contribution_ids": [
                "R151530"
            ]
        },
        {
            "instance_id": "R155621xR151520",
            "comparison_id": "R155621",
            "paper_id": "R151520",
            "text": "Topical and systemic absorption in delivery of dexamethasone to the anterior and posterior segments of the eye purpose\\nthis study aimed to: (1) determine the relative efficiencies of topical and systemic absorption of drugs delivered by eyedrops to the anterior and posterior segments of the eye; (2) establish whether dexamethasone-cyclodextrin eyedrops deliver significant levels of drug to the retina and vitreous in the rabbit eye, and (3) compare systemic absorption following topical application to the eye versus intranasal or intravenous delivery.\\n\\n\\nmethods\\nin order to distinguish between topical and systemic absorption in the eye, we applied 0.5% dexamethasone-cyclodextrin eyedrops to one (study) eye of rabbits and not to the contralateral (control) eye. drug levels were measured in each eye. the study eye showed the result of the combination of topical and systemic absorption, whereas the control eye showed the result of systemic absorption only. systemic absorption was also examined after intranasal and intravenous administration of the same dose of dexamethasone.\\n\\n\\nresults\\nin the aqueous humour dexamethasone levels were 170 +/- 76 ng/g (mean +/- standard deviation) in the study eye and 6 +/- 2 ng/g in the control eye. similar ratios were seen in the iris and ciliary body. in the retina the dexamethasone level was 33 +/- 7 ng/g in the study eye and 14 +/- 3 ng/g in the control eye. similar ratios were seen in the vitreous humour. systemic absorption was similar from ocular, intranasal and intravenous administration.\\n\\n\\nconclusions\\nabsorption after topical application dominates in the anterior segment. topical absorption also plays a significant role in delivering dexamethasone to the posterior segment of the rabbit eye. in medication administered to the retina, 40% of the drug reaches the retina via the systemic route and 60% via topical penetration. dexamethasone-cyclodextrin eyedrops deliver a significant amount of drug to the rabbit retina.",
            "contribution_ids": [
                "R151522"
            ]
        },
        {
            "instance_id": "R155621xR155585",
            "comparison_id": "R155621",
            "paper_id": "R155585",
            "text": "A cyclosporin A/maltosyl-\u00c2\u00a0-cyclodextrin complex for inhalation therapy of asthma the inhalation of cyclosporin (cs)a to the lung is limited by its hydrophobic properties. in order to improve the poor solubility of csa, cyclodextrin (cd) was evaluated for its suitability for dry powder inhaler formation, and the benefit of an inhaled csa/cd complex in vivo was demonstrated. the solubilising effect of cds on csa was measured by high-performance liquid chromatography. ciliostatic activity and haemolysis were determined to assess some safety profiles of cds. the efficacy of an inhaled csa/cd complex was evaluated by eosinophil infiltration into the bronchoalveolar lavage fluid in actively sensitised mice. cds markedly improved the poor solubility of csa. the ciliostatic and haemolytic activities of maltosyl\u2010\u03b1\u2010cd were the weakest of all the tested cds. csa inhaled alone showed inhibitory effects on allergen-induced eosinophilia. inhalation of the complex of csa with maltosyl\u2010\u03b1\u2010cd, where the dose of csa was approximately nine-times less than that of csa inhaled alone, also inhibited eosinophil accumulation significantly, with a longer duration of action in comparison with the response to csa alone. thus the effective dose of cyclosporin a could be reduced by formation of a complex with maltosyl\u2010\u03b1\u2010cyclodextrin, and a wider therapeutic safety margin by inhalation of cyclosporin a as a complex with maltosyl\u2010\u03b1\u2010cyclodextrin could be expected.",
            "contribution_ids": [
                "R155587"
            ]
        },
        {
            "instance_id": "R155621xR155615",
            "comparison_id": "R155621",
            "paper_id": "R155615",
            "text": "Inhaled Voriconazole for Prevention of Invasive Pulmonary Aspergillosis abstract \\n \\n targeted airway delivery of antifungals as prophylaxis against invasive aspergillosis may lead to high lung drug concentrations while avoiding toxicities associated with systemically administered agents. we evaluated the effectiveness of aerosolizing the intravenous formulation of voriconazole as prophylaxis against invasive pulmonary aspergillosis caused by\\n aspergillus fumigatus \\n in an established murine model. inhaled voriconazole significantly improved survival and limited the extent of invasive disease, as assessed by histopathology, compared to control and amphotericin b treatments.\\n",
            "contribution_ids": [
                "R155617"
            ]
        },
        {
            "instance_id": "R155621xR151506",
            "comparison_id": "R155621",
            "paper_id": "R151506",
            "text": "Topically effective ocular hypotensive acetazolamide and ethoxyzolamide formulations in rabbits abstract \\n the effect of topically active 2-hydroxypropyl-\u03b2-cyclodextrin (hp-\u03b2-cyd) eye-drop formulations containing solutions of acetazolamide, ethoxyzolamide or timolol on the intra-ocular pressure (iop) was investigated in normotensive conscious rabbits. both acetazolamide and ethoxyzolamide were active but their iop-lowering effect was less than that of timolol. the iop-lowering effects of acetazolamide and ethoxyzolamide and that of timolol appeared to be to some extent additive. combination of acetazolamide and timolol or ethoxyzolamide and timolol in one hp-\u03b2-cyd formulation resulted in a significant increase in the duration of activity compared with hp-\u03b2-cyd formulations containing only acetazolamide, ethoxyzolamide or timolol. also, it was possible to increase the iop-lowering effect of acetazolamide by formulating the drug as a suspension in an aqueous hp-\u03b2-cyd vehicle.",
            "contribution_ids": [
                "R151508"
            ]
        },
        {
            "instance_id": "R155800xR145502",
            "comparison_id": "R155800",
            "paper_id": "R145502",
            "text": "Barcoding of biting midges in the genus Culicoides: a tool for species determination biting midges of the genus culicoides (diptera: ceratopogonidae) are insect vectors of economically important veterinary diseases such as african horse sickness virus and bluetongue virus. however, the identification of culicoides based on morphological features is difficult. the sequencing of mitochondrial cytochrome oxidase subunit i (coi), referred to as dna barcoding, has been proposed as a tool for rapid identification to species. hence, a study was undertaken to establish dna barcodes for all morphologically determined culicoides species in swedish collections. in total, 237 specimens of culicoides representing 37 morphologically distinct species were used. the barcoding generated 37 supported clusters, 31 of which were in agreement with the morphological determination. however, two pairs of closely related species could not be separated using the dna barcode approach. moreover, culicoides obsoletus meigen and culicoides newsteadi austen showed relatively deep intraspecific divergence (more than 10 times the average), which led to the creation of two cryptic species within each of c. obsoletus and c. newsteadi. the use of coi barcodes as a tool for the species identification of biting midges can differentiate 95% of species studied. identification of some closely related species should employ a less conserved region, such as a ribosomal internal transcribed spacer.",
            "contribution_ids": [
                "R145504",
                "R155704"
            ]
        },
        {
            "instance_id": "R155800xR145497",
            "comparison_id": "R155800",
            "paper_id": "R145497",
            "text": "Half of the European fruit fly species barcoded (Diptera, Tephritidae); a feasibility test for molecular identification abstract a feasibility test of molecular identification of european fruit flies (diptera: tephritidae) based on coi barcode sequences has been executed. a dataset containing 555 sequences of 135 ingroup species from three subfamilies and 42 genera and one single outgroup species has been analysed. 73.3% of all included species could be identified based on their coi barcode gene, based on similarity and distances. the low success rate is caused by singletons as well as some problematic groups: several species groups within the genus terellia and especially the genus urophora. with slightly more than 100 sequences \u2013 almost 20% of the total \u2013 this genus alone constitutes the larger part of the failure for molecular identification for this dataset. deleting the singletons and urophora results in a success-rate of 87.1% of all queries and 93.23% of the not discarded queries as correctly identified. urophora is of special interest due to its economic importance as beneficial species for weed control, therefore it is desirable to have alternative markers for molecular identification. we demonstrate that the success of dna barcoding for identification purposes strongly depends on the contents of the database used to blast against. especially the necessity of including multiple specimens per species of geographically distinct populations and different ecologies for the understanding of the intra- versus interspecific variation is demonstrated. furthermore thresholds and the distinction between true and false positives and negatives should not only be used to increase the reliability of the success of molecular identification but also to point out problematic groups, which should then be flagged in the reference database suggesting alternative methods for identification.",
            "contribution_ids": [
                "R145499",
                "R155710"
            ]
        },
        {
            "instance_id": "R155800xR142535",
            "comparison_id": "R155800",
            "paper_id": "R142535",
            "text": "DNA Barcodes for the Northern European Tachinid Flies (Diptera: Tachinidae) this data release provides coi barcodes for 366 species of parasitic flies (diptera: tachinidae), enabling the dna based identification of the majority of northern european species and a large proportion of palearctic genera, regardless of the developmental stage. the data will provide a tool for taxonomists and ecologists studying this ecologically important but challenging parasitoid family. a comparison of minimum distances between the nearest neighbors revealed the mean divergence of 5.52% that is approximately the same as observed earlier with comparable sampling in lepidoptera, but clearly less than in coleoptera. full barcode-sharing was observed between 13 species pairs or triplets, equaling to 7.36% of all species. delimitation based on barcode index number (bin) system was compared with traditional classification of species and interesting cases of possible species oversplits and cryptic diversity are discussed. overall, dna barcodes are effective in separating tachinid species and provide novel insight into the taxonomy of several genera.",
            "contribution_ids": [
                "R142537",
                "R155773"
            ]
        },
        {
            "instance_id": "R155800xR142471",
            "comparison_id": "R155800",
            "paper_id": "R142471",
            "text": "DNA barcoding of Northern Nearctic Muscidae (Diptera) reveals high correspondence between morphological and molecular species limits abstract \\n \\n background \\n various methods have been proposed to assign unknown specimens to known species using their dna barcodes, while others have focused on using genetic divergence thresholds to estimate \u201cspecies\u201d diversity for a taxon, without a well-developed taxonomy and/or an extensive reference library of dna barcodes. the major goals of the present work were to: a) conduct the largest species-level barcoding study of the muscidae to date and characterize the range of genetic divergence values in the northern nearctic fauna; b) evaluate the correspondence between morphospecies and barcode groupings defined using both clustering-based and threshold-based approaches; and c) use the reference library produced to address taxonomic issues. \\n \\n \\n results \\n our data set included 1114 individuals and their coi sequences (951 from churchill, manitoba), representing 160 morphologically-determined species from 25 genera, covering 89% of the known fauna of churchill and 23% of the nearctic fauna. following an iterative process through which all specimens belonging to taxa with anomalous divergence values and/or monophyly issues were re-examined, identity was modified for 9 taxa, including the reinstatement of phaonia luteva (walker) stat. nov. as a species distinct from phaonia errans (meigen). in the post-reassessment data set, no distinct gap was found between maximum pairwise intraspecific distances (range 0.00-3.01%) and minimum interspecific distances (range: 0.77-11.33%). nevertheless, using a clustering-based approach, all individuals within 98% of species grouped with their conspecifics with high (&gt;95%) bootstrap support; in contrast, a maximum species discrimination rate of 90% was obtained at the optimal threshold of 1.2%. dna barcoding enabled the determination of females from 5 ambiguous species pairs and confirmed that 16 morphospecies were genetically distinct from named taxa. there were morphological differences among all distinct genetic clusters; thus, no cases of cryptic species were detected. \\n \\n \\n conclusions \\n our findings reveal the great utility of building a well-populated, species-level reference barcode database against which to compare unknowns. when such a library is unavailable, it is still possible to obtain a fairly accurate (within ~10%) rapid assessment of species richness based upon a barcode divergence threshold alone, but this approach is most accurate when the threshold is tuned to a particular taxon. \\n",
            "contribution_ids": [
                "R142473",
                "R155793"
            ]
        },
        {
            "instance_id": "R155800xR145437",
            "comparison_id": "R155800",
            "paper_id": "R145437",
            "text": "DNA Barcoding to Improve the Taxonomy of the Afrotropical Hoverflies (Insecta: Diptera: Syrphidae) the identification of afrotropical hoverflies is very difficult because of limited recent taxonomic revisions and the lack of comprehensive identification keys. in order to assist in their identification, and to improve the taxonomy of this group, we constructed a reference dataset of 513 coi barcodes of 90 of the more common nominal species from ghana, togo, benin and nigeria (w africa) and added ten publically available coi barcodes from nine nominal afrotropical species to this (total: 523 coi barcodes; 98 nominal species; 26 genera). the identification accuracy of this dataset was evaluated with three methods (k2p distance-based, neighbor-joining (nj) / maximum likelihood (ml) analysis, and using speciesidentifier). results of the three methods were highly congruent and showed a high identification success. nine species pairs showed a low ( 0.03) maximum intraspecific k2p distance was observed in eight species and barcodes of these species not always formed single clusters in the nj / ml analayses which may indicate the occurrence of cryptic species. optimal k2p thresholds to differentiate intra- from interspecific k2p divergence were highly different among the three subfamilies (eristalinae: 0.037, syrphinae: 0.06, microdontinae: 0.007\u20130.02), and among the different general suggesting that optimal thresholds are better defined at the genus level. in addition to providing an alternative identification tool, our study indicates that dna barcoding improves the taxonomy of afrotropical hoverflies by selecting (groups of) taxa that deserve further taxonomic study, and by attributing the unknown sex to species for which only one of the sexes is known.",
            "contribution_ids": [
                "R145438",
                "R155749"
            ]
        },
        {
            "instance_id": "R155800xR146639",
            "comparison_id": "R155800",
            "paper_id": "R146639",
            "text": "DNA barcodes for species delimitation in Chironomidae (Diptera): a case study on the genus Labrundinia abstract in this study, we analysed the applicability of dna barcodes for delimitation of 79 specimens of 13 species of nonbiting midges in the subfamily tanypodinae (diptera: chironomidae) from s\u00e3o paulo state, brazil. our results support dna barcoding as an excellent tool for species identification and for solving taxonomic conflicts in genus labrundinia. molecular analysis of cytochrome c oxidase subunit i (coi) gene sequences yielded taxon identification trees, supporting 13 cohesive species clusters, of which three similar groups were subsequently linked to morphological variation at the larval and pupal stage. additionally, another cluster previously described by means of morphology was linked to molecular markers. we found a distinct barcode gap, and in some species substantial interspecific pairwise divergences (up to 19.3%) were observed, which permitted identification of all analysed species. the results also indicated that barcodes can be used to associate life stages of chironomids since coi was easily amplified and sequenced from different life stages with universal barcode primers.",
            "contribution_ids": [
                "R146641",
                "R155674"
            ]
        },
        {
            "instance_id": "R155800xR145434",
            "comparison_id": "R155800",
            "paper_id": "R145434",
            "text": "DNA Barcoding of Neotropical Sand Flies (Diptera, Psychodidae, Phlebotominae): Species Identification and Discovery within Brazil dna barcoding has been an effective tool for species identification in several animal groups. here, we used dna barcoding to discriminate between 47 morphologically distinct species of brazilian sand flies. dna barcodes correctly identified approximately 90% of the sampled taxa (42 morphologically distinct species) using clustering based on neighbor-joining distance, of which four species showed comparatively higher maximum values of divergence (range 4.23\u201319.04%), indicating cryptic diversity. the dna barcodes also corroborated the resurrection of two species within the shannoni complex and provided an efficient tool to differentiate between morphologically indistinguishable females of closely related species. taken together, our results validate the effectiveness of dna barcoding for species identification and the discovery of cryptic diversity in sand flies from brazil.",
            "contribution_ids": [
                "R145435",
                "R155758"
            ]
        },
        {
            "instance_id": "R155800xR145304",
            "comparison_id": "R155800",
            "paper_id": "R145304",
            "text": "Analyzing Mosquito (Diptera: Culicidae) Diversity in Pakistan by DNA Barcoding background although they are important disease vectors mosquito biodiversity in pakistan is poorly known. recent epidemics of dengue fever have revealed the need for more detailed understanding of the diversity and distributions of mosquito species in this region. dna barcoding improves the accuracy of mosquito inventories because morphological differences between many species are subtle, leading to misidentifications. methodology/principal findings sequence variation in the barcode region of the mitochondrial coi gene was used to identify mosquito species, reveal genetic diversity, and map the distribution of the dengue-vector species in pakistan. analysis of 1684 mosquitoes from 491 sites in punjab and khyber pakhtunkhwa during 2010\u20132013 revealed 32 species with the assemblage dominated by culex quinquefasciatus (61% of the collection). the genus aedes (stegomyia) comprised 15% of the specimens, and was represented by six taxa with the two dengue vector species, ae. albopictus and ae. aegypti, dominant and broadly distributed. anopheles made up another 6% of the catch with an. subpictus dominating. barcode sequence divergence in conspecific specimens ranged from 0\u20132.4%, while congeneric species showed from 2.3\u201317.8% divergence. a global haplotype analysis of disease-vectors showed the presence of multiple haplotypes, although a single haplotype of each dengue-vector species was dominant in most countries. geographic distribution of ae. aegypti and ae. albopictus showed the later species was dominant and found in both rural and urban environments. conclusions as the first dna-based analysis of mosquitoes in pakistan, this study has begun the construction of a barcode reference library for the mosquitoes of this region. levels of genetic diversity varied among species. because of its capacity to differentiate species, even those with subtle morphological differences, dna barcoding aids accurate tracking of vector populations.",
            "contribution_ids": [
                "R145305",
                "R155763"
            ]
        },
        {
            "instance_id": "R155800xR145495",
            "comparison_id": "R155800",
            "paper_id": "R145495",
            "text": "DNA Barcoding for the Identification of Sand Fly Species (Diptera, Psychodidae, Phlebotominae) in Colombia sand flies include a group of insects that are of medical importance and that vary in geographic distribution, ecology, and pathogen transmission. approximately 163 species of sand flies have been reported in colombia. surveillance of the presence of sand fly species and the actualization of species distribution are important for predicting risks for and monitoring the expansion of diseases which sand flies can transmit. currently, the identification of phlebotomine sand flies is based on morphological characters. however, morphological identification requires considerable skills and taxonomic expertise. in addition, significant morphological similarity between some species, especially among females, may cause difficulties during the identification process. dna-based approaches have become increasingly useful and promising tools for estimating sand fly diversity and for ensuring the rapid and accurate identification of species. a partial sequence of the mitochondrial cytochrome oxidase gene subunit i (coi) is currently being used to differentiate species in different animal taxa, including insects, and it is referred as a barcoding sequence. the present study explored the utility of the dna barcode approach for the identification of phlebotomine sand flies in colombia. we sequenced 700 bp of the coi gene from 36 species collected from different geographic localities. the coi barcode sequence divergence within a single species was <2% in most cases, whereas this divergence ranged from 9% to 26.6% among different species. these results indicated that the barcoding gene correctly discriminated among the previously morphologically identified species with an efficacy of nearly 100%. analyses of the generated sequences indicated that the observed species groupings were consistent with the morphological identifications. in conclusion, the barcoding gene was useful for species discrimination in sand flies from colombia.",
            "contribution_ids": [
                "R145496",
                "R155723"
            ]
        },
        {
            "instance_id": "R155800xR142517",
            "comparison_id": "R155800",
            "paper_id": "R142517",
            "text": "A DNA barcode library for 5,200 German flies and midges (Insecta: Diptera) and its implications for metabarcoding\u00e2\u0080\u0090based biomonitoring this study summarizes results of a dna barcoding campaign on german diptera, involving analysis of 45,040 specimens. the resultant dna barcode library includes records for 2,453 named species comprising a total of 5,200 barcode index numbers (bins), including 2,700 coi haplotype clusters without species\u2010level assignment, so called \u201cdark taxa.\u201d overall, 88 out of 117 families (75%) recorded from germany were covered, representing more than 50% of the 9,544 known species of german diptera. until now, most of these families, especially the most diverse, have been taxonomically inaccessible. by contrast, within a few years this study provided an intermediate taxonomic system for half of the german dipteran fauna, which will provide a useful foundation for subsequent detailed, integrative taxonomic studies. using dna extracts derived from bulk collections made by malaise traps, we further demonstrate that species delineation using bins and operational taxonomic units (otus) constitutes an effective method for biodiversity studies using dna metabarcoding. as the reference libraries continue to grow, and gaps in the species catalogue are filled, bin lists assembled by metabarcoding will provide greater taxonomic resolution. the present study has three main goals: (a) to provide a dna barcode library for 5,200 bins of diptera; (b) to demonstrate, based on the example of bulk extractions from a malaise trap experiment, that dna barcode clusters, labelled with globally unique identifiers (such as otus and/or bins), provide a pragmatic, accurate solution to the \u201ctaxonomic impediment\u201d; and (c) to demonstrate that interim names based on bins and otus obtained through metabarcoding provide an effective method for studies on species\u2010rich groups that are usually neglected in biodiversity research projects because of their unresolved taxonomy.",
            "contribution_ids": [
                "R142521",
                "R155788"
            ]
        },
        {
            "instance_id": "R155800xR145491",
            "comparison_id": "R155800",
            "paper_id": "R145491",
            "text": "DNA barcoding of tropical black flies (Diptera: Simuliidae) of Thailand the ecological and medical importance of black flies drives the need for rapid and reliable identification of these minute, structurally uniform insects. we assessed the efficiency of dna barcoding for species identification of tropical black flies. a total of 351 cytochrome c oxidase subunit 1 sequences were obtained from 41 species in six subgenera of the genus simulium in thailand. despite high intraspecific genetic divergence (mean = 2.00%, maximum = 9.27%), dna barcodes provided 96% correct identification. barcodes also differentiated cytoforms of selected species complexes, albeit with varying levels of success. perfect differentiation was achieved for two cytoforms of simulium feuerborni, and 91% correct identification was obtained for the simulium angulistylum complex. low success (33%), however, was obtained for the simulium siamense complex. the differential efficiency of dna barcodes to discriminate cytoforms was attributed to different levels of genetic structure and demographic histories of the taxa. dna barcode trees were largely congruent with phylogenies based on previous molecular, chromosomal and morphological analyses, but revealed inconsistencies that will require further evaluation.",
            "contribution_ids": [
                "R145493",
                "R155729"
            ]
        },
        {
            "instance_id": "R155800xR146646",
            "comparison_id": "R155800",
            "paper_id": "R146646",
            "text": "Comprehensive evaluation of DNA barcoding for the molecular species identification of forensically important Australian Sarcophagidae (Diptera) carrion-breeding sarcophagidae (diptera) can be used to estimate the post-mortem interval in forensic cases. difficulties with accurate morphological identifications at any life stage and a lack of documented thermobiological profiles have limited their current usefulness. the molecular-based approach of dna barcoding, which utilises a 648-bp fragment of the mitochondrial cytochrome oxidase subuniti gene, was evaluated in a pilot study for discrimination between 16 australian sarcophagids. the current study comprehensively evaluated barcoding for a larger taxon set of 588 australian sarcophagids. in total, 39 of the 84 known australian species were represented by 580 specimens, which includes 92% of potentially forensically important species. a further eight specimens could not be identified, but were included nonetheless as six unidentifiable taxa. a neighbour-joining tree was generated and nucleotide sequence divergences were calculated. all species except sarcophaga (fergusonimyia) bancroftorum, known for high morphological variability, were resolved as monophyletic (99.2% of cases), with bootstrap support of 100. excluding s. bancroftorum, the mean intraspecific and interspecific variation ranged from 1.12% and 2.81\u201311.23%, respectively, allowing for species discrimination. dna barcoding was therefore validated as a suitable method for molecular identification of australian sarcophagidae, which will aid in the implementation of this fauna in forensic entomology.",
            "contribution_ids": [
                "R146648",
                "R155647"
            ]
        },
        {
            "instance_id": "R155800xR145296",
            "comparison_id": "R155800",
            "paper_id": "R145296",
            "text": "Molecular identification of mosquitoes (Diptera: Culicidae) in southeastern Australia abstract dna barcoding is a modern species identification technique that can be used to distinguish morphologically similar species, and is particularly useful when using small amounts of starting material from partial specimens or from immature stages. in order to use dna barcoding in a surveillance program, a database containing mosquito barcode sequences is required. this study obtained cytochrome oxidase i (coi) sequences for 113 morphologically identified specimens, representing 29 species, six tribes and 12 genera; 17 of these species have not been previously barcoded. three of the 29 species \u2500 culex palpalis, macleaya macmillani, and an unknown species originally identified as tripteroides atripes \u2500 were initially misidentified as they are difficult to separate morphologically, highlighting the utility of dna barcoding. while most species grouped separately (reciprocally monophyletic), the cx. pipiens subgroup could not be genetically separated using coi. the average conspecific and congeneric p\u2010distance was 0.8% and 7.6%, respectively. in our study, we also demonstrate the utility of dna barcoding in distinguishing exotics from endemic mosquitoes by identifying a single intercepted stegomyia aegypti egg at an international airport. the use of dna barcoding dramatically reduced the identification time required compared with rearing specimens through to adults, thereby demonstrating the value of this technique in biosecurity surveillance. the dna barcodes produced by this study have been uploaded to the \u2018mosquitoes of australia\u2013victoria\u2019 project on the barcode of life database (bold), which will serve as a resource for the victorian arbovirus disease control program and other national and international mosquito surveillance programs.",
            "contribution_ids": [
                "R145298",
                "R155768"
            ]
        },
        {
            "instance_id": "R155804xR149947",
            "comparison_id": "R155804",
            "paper_id": "R149947",
            "text": "Image based mammographie ontology learning understanding the content of an image is one of the challenges in the image processing field. recently, the content based image retrieval (cbir) and especially semantic content based image retrieval (scbir) are the main goal of many research works. in medical field, understanding the content of an image is very helpful in the automatic decision making. in fact, analyzing the semantic information in an image support can assist the doctor to make the adequate diagnosis. this paper presents a new method for mammographic ontology learning from a set of mammographic images. the approach is based on four main modules: (1) the mammography segmentation, (2) the features extraction (3) the local ontology modeling and (4) the global ontology construction basing on merging the local ones. the first module allows detecting the pathological regions in the represented breast. the second module consists on extracting the most important features from the pathological zones. the third module allows modeling a local ontology by representing the pertinent entities (conceptual entities) as well as their correspondent features (shape, size, form, etc.) discovered in the previous step. the last module consists on merging the local ontologies extracted from a set of mammographies in order to obtain a global and exhaustive one. our approach attempts to fully describe the semantic content of mammographic images in order to perform the domain knowledge modeling.",
            "contribution_ids": [
                "R149949"
            ]
        },
        {
            "instance_id": "R155836xR149916",
            "comparison_id": "R155836",
            "paper_id": "R149916",
            "text": "Image domain ontology fusion approach using multi-level inference mechanism one of the main challenges in content-based or semantic image retrieval is still to bridge the gap between low-level features and semantic information. in this paper, an approach is presented using integrated multi-level image features in ontology fusion construction by a fusion framework, which based on the latent semantic analysis. the proposed method promotes images ontology fusion efficiently and broadens the application fields of image ontology retrieval system. the relevant experiment shows that this method ameliorates the problem, such as too many redundant data and relations, in the traditional ontology system construction, as well as improves the performance of semantic images retrieval.",
            "contribution_ids": [
                "R149918",
                "R150730",
                "R150931",
                "R150936",
                "R150937",
                "R150948",
                "R150953",
                "R150966",
                "R150974",
                "R150980",
                "R150985",
                "R150990",
                "R150995"
            ]
        },
        {
            "instance_id": "R157074xR140197",
            "comparison_id": "R157074",
            "paper_id": "R140197",
            "text": "DNA barcodes distinguish species of tropical Lepidoptera although central to much biological research, the identification of species is often difficult. the use of dna barcodes, short dna sequences from a standardized region of the genome, has recently been proposed as a tool to facilitate species identification and discovery. however, the effectiveness of dna barcoding for identifying specimens in species-rich tropical biotas is unknown. here we show that cytochrome c oxidase i dna barcodes effectively discriminate among species in three lepidoptera families from area de conservaci\u00f3n guanacaste in northwestern costa rica. we found that 97.9% of the 521 species recognized by prior taxonomic work possess distinctive cytochrome c oxidase i barcodes and that the few instances of interspecific sequence overlap involve very similar species. we also found two or more barcode clusters within each of 13 supposedly single species. covariation between these clusters and morphological and/or ecological traits indicates overlooked species complexes. if these results are general, dna barcoding will significantly aid species identification and discovery in tropical settings.",
            "contribution_ids": [
                "R140199",
                "R156766"
            ]
        },
        {
            "instance_id": "R157074xR109043",
            "comparison_id": "R157074",
            "paper_id": "R109043",
            "text": "A DNA barcode library for the butterflies of North America although the butterflies of north america have received considerable taxonomic attention, overlooked species and instances of hybridization continue to be revealed. the present study assembles a dna barcode reference library for this fauna to identify groups whose patterns of sequence variation suggest the need for further taxonomic study. based on 14,626 records from 814 species, dna barcodes were obtained for 96% of the fauna. the maximum intraspecific distance averaged 1/4 the minimum distance to the nearest neighbor, producing a barcode gap in 76% of the species. most species (80%) were monophyletic, the others were para- or polyphyletic. although 15% of currently recognized species shared barcodes, the incidence of such taxa was far higher in regions exposed to pleistocene glaciations than in those that were ice-free. nearly 10% of species displayed high intraspecific variation (&gt;2.5%), suggesting the need for further investigation to assess potential cryptic diversity. aside from aiding the identification of all life stages of north american butterflies, the reference library has provided new perspectives on the incidence of both cryptic and potentially over-split species, setting the stage for future studies that can further explore the evolutionary dynamics of this group.",
            "contribution_ids": [
                "R157021",
                "R109045"
            ]
        },
        {
            "instance_id": "R157074xR138551",
            "comparison_id": "R157074",
            "paper_id": "R138551",
            "text": "Probing planetary biodiversity with DNA barcodes: The Noctuoidea of North America this study reports the assembly of a dna barcode reference library for species in the lepidopteran superfamily noctuoidea from canada and the usa. based on the analysis of 69,378 specimens, the library provides coverage for 97.3% of the noctuoid fauna (3565 of 3664 species). in addition to verifying the strong performance of dna barcodes in the discrimination of these species, the results indicate close congruence between the number of species analyzed (3565) and the number of sequence clusters (3816) recognized by the barcode index number (bin) system. distributional patterns across 12 north american ecoregions are examined for the 3251 species that have gps data while bin analysis is used to quantify overlap between the noctuoid faunas of north america and other zoogeographic regions. this analysis reveals that 90% of north american noctuoids are endemic and that just 7.5% and 1.8% of bins are shared with the neotropics and with the palearctic, respectively. one third (29) of the latter species are recent introductions and, as expected, they possess low intraspecific divergences.",
            "contribution_ids": [
                "R156994",
                "R138554"
            ]
        },
        {
            "instance_id": "R157074xR157062",
            "comparison_id": "R157074",
            "paper_id": "R157062",
            "text": "A Comprehensive DNA Barcode Library for the Looper Moths (Lepidoptera: Geometridae) of British Columbia, Canada background the construction of comprehensive reference libraries is essential to foster the development of dna barcoding as a tool for monitoring biodiversity and detecting invasive species. the looper moths of british columbia (bc), canada present a challenging case for species discrimination via dna barcoding due to their considerable diversity and limited taxonomic maturity. methodology/principal findings by analyzing specimens held in national and regional natural history collections, we assemble barcode records from representatives of 400 species from bc and surrounding provinces, territories and states. sequence variation in the barcode region unambiguously discriminates over 93% of these 400 geometrid species. however, a final estimate of resolution success awaits detailed taxonomic analysis of 48 species where patterns of barcode variation suggest cases of cryptic species, unrecognized synonymy as well as young species. conclusions/significance a catalog of these taxa meriting further taxonomic investigation is presented as well as the supplemental information needed to facilitate these investigations.",
            "contribution_ids": [
                "R157063"
            ]
        },
        {
            "instance_id": "R157074xR138562",
            "comparison_id": "R157074",
            "paper_id": "R138562",
            "text": "Fast Census of Moth Diversity in the Neotropics: A Comparison of Field-Assigned Morphospecies and DNA Barcoding in Tiger Moths the morphological species delimitations (i.e. morphospecies) have long been the best way to avoid the taxonomic impediment and compare insect taxa biodiversity in highly diverse tropical and subtropical regions. the development of dna barcoding, however, has shown great potential to replace (or at least complement) the morphospecies approach, with the advantage of relying on automated methods implemented in computer programs or even online rather than in often subjective morphological features. we sampled moths extensively for two years using light traps in a patch of the highly endangered atlantic forest of brazil to produce a nearly complete census of arctiines (noctuoidea: erebidae), whose species richness was compared using different morphological and molecular approaches (dna barcoding). a total of 1,075 barcode sequences of 286 morphospecies were analyzed. based on the clustering method barcode index number (bin) we found a taxonomic bias of approximately 30% in our initial morphological assessment. however, a morphological reassessment revealed that the correspondence between morphospecies and molecular operational taxonomic units (motus) can be up to 94% if differences in genitalia morphology are evaluated in individuals of different motus originated from the same morphospecies (putative cases of cryptic species), and by recording if individuals of different genders in different morphospecies merge together in the same motu (putative cases of sexual dimorphism). the results of two other clustering methods (i.e. automatic barcode gap discovery and 2% threshold) were very similar to those of the bin approach. using empirical data we have shown that dna barcoding performed substantially better than the morphospecies approach, based on superficial morphology, to delimit species of a highly diverse moth taxon, and thus should be used in species inventories.",
            "contribution_ids": [
                "R156968",
                "R138564"
            ]
        },
        {
            "instance_id": "R157074xR108960",
            "comparison_id": "R157074",
            "paper_id": "R108960",
            "text": "Use of species delimitation approaches to tackle the cryptic diversity of an assemblage of high Andean butterflies (Lepidoptera: Papilionoidea) cryptic biological diversity has generated ambiguity in taxonomic and evolutionary studies. single-locus methods and other approaches for species delimitation are useful for addressing this challenge, enabling the practical processing of large numbers of samples for identification and inventory purposes. this study analyzed an assemblage of high andean butterflies using dna barcoding and compared the identifications based on the current morphological taxonomy with three methods of species delimitation (automatic barcode gap discovery, generalized mixed yule coalescent model, and poisson tree processes). sixteen potential cryptic species were recognized using these three methods, representing a net richness increase of 11.3% in the assemblage. a well-studied taxon of the genus vanessa, which has a wide geographical distribution, appeared with the potential cryptic species that had a higher genetic differentiation at the local level than at the continental level. the analyses were useful for identifying the potential cryptic species in pedaliodes and forsterinaria complexes, which also show differentiation along altitudinal and latitudinal gradients. this genetic assessment of an entire assemblage of high andean butterflies (papilionoidea) provides baseline information for future research in a region characterized by high rates of endemism and population isolation.",
            "contribution_ids": [
                "R157029",
                "R108962"
            ]
        },
        {
            "instance_id": "R157074xR139538",
            "comparison_id": "R157074",
            "paper_id": "R139538",
            "text": "High resolution DNA barcode library for European butterflies reveals continental patterns of mitochondrial genetic diversity abstract the study of global biodiversity will greatly benefit from access to comprehensive dna barcode libraries at continental scale, but such datasets are still very rare. here, we assemble the first high-resolution reference library for european butterflies that provides 97% taxon coverage (459 species) and 22,306 coi sequences. we estimate that we captured 62% of the total haplotype diversity and show that most species possess a few very common haplotypes and many rare ones. specimens in the dataset have an average 95.3% probability of being correctly identified. mitochondrial diversity displayed elevated haplotype richness in southern european refugia, establishing the generality of this key biogeographic pattern for an entire taxonomic group. fifteen percent of the species are involved in barcode sharing, but two thirds of these cases may reflect the need for further taxonomic research. this dataset provides a unique resource for conservation and for studying evolutionary processes, cryptic species, phylogeography, and ecology.",
            "contribution_ids": [
                "R139543",
                "R156950"
            ]
        },
        {
            "instance_id": "R157074xR136193",
            "comparison_id": "R157074",
            "paper_id": "R136193",
            "text": "Complete DNA barcode reference library for a country's butterfly fauna reveals high performance for temperate Europe dna barcoding aims to accelerate species identification and discovery, but performance tests have shown marked differences in identification success. as a consequence, there remains a great need for comprehensive studies which objectively test the method in groups with a solid taxonomic framework. this study focuses on the 180 species of butterflies in romania, accounting for about one third of the european butterfly fauna. this country includes five eco-regions, the highest of any in the european union, and is a good representative for temperate areas. morphology and dna barcodes of more than 1300 specimens were carefully studied and compared. our results indicate that 90 per cent of the species form barcode clusters allowing their reliable identification. the remaining cases involve nine closely related species pairs, some whose taxonomic status is controversial or that hybridize regularly. interestingly, dna barcoding was found to be the most effective identification tool, outperforming external morphology, and being slightly better than male genitalia. romania is now the first country to have a comprehensive dna barcode reference database for butterflies. similar barcoding efforts based on comprehensive sampling of specific geographical regions can act as functional modules that will foster the early application of dna barcoding while a global system is under development.",
            "contribution_ids": [
                "R157016",
                "R136195"
            ]
        },
        {
            "instance_id": "R157074xR157051",
            "comparison_id": "R157074",
            "paper_id": "R157051",
            "text": "A Transcontinental Challenge \u00e2\u0080\u0094 A Test of DNA Barcode Performance for 1,541 Species of Canadian Noctuoidea (Lepidoptera) this study provides a first, comprehensive, diagnostic use of dna barcodes for the canadian fauna of noctuoids or \u201cowlet\u201d moths (lepidoptera: noctuoidea) based on vouchered records for 1,541 species (99.1% species coverage), and more than 30,000 sequences. when viewed from a canada-wide perspective, dna barcodes unambiguously discriminate 90% of the noctuoid species recognized through prior taxonomic study, and resolution reaches 95.6% when considered at a provincial scale. barcode sharing is concentrated in certain lineages with 54% of the cases involving 1.8% of the genera. deep intraspecific divergence exists in 7.7% of the species, but further studies are required to clarify whether these cases reflect an overlooked species complex or phylogeographic variation in a single species. non-native species possess higher nearest-neighbour (nn) distances than native taxa, whereas generalist feeders have lower nn distances than those with more specialized feeding habits. we found high concordance between taxonomic names and sequence clusters delineated by the barcode index number (bin) system with 1,082 species (70%) assigned to a unique bin. the cases of discordance involve both bin mergers and bin splits with 38 species falling into both categories, most likely reflecting bidirectional introgression. one fifth of the species are involved in a bin merger reflecting the presence of 158 species sharing their barcode sequence with at least one other taxon, and 189 species with low, but diagnostic coi divergence. a very few cases (13) involved species whose members fell into both categories. most of the remaining 140 species show a split into two or three bins per species, while virbia ferruginosa was divided into 16. the overall results confirm that dna barcodes are effective for the identification of canadian noctuoids. this study also affirms that bins are a strong proxy for species, providing a pathway for a rapid, accurate estimation of animal diversity.",
            "contribution_ids": [
                "R157052"
            ]
        },
        {
            "instance_id": "R157074xR108983",
            "comparison_id": "R157074",
            "paper_id": "R108983",
            "text": "Barcoding the butterflies of southern South America: Species delimitation efficacy, cryptic diversity and geographic patterns of divergence because the tropical regions of america harbor the highest concentration of butterfly species, its fauna has attracted considerable attention. much less is known about the butterflies of southern south america, particularly argentina, where over 1,200 species occur. to advance understanding of this fauna, we assembled a dna barcode reference library for 417 butterfly species of argentina, focusing on the atlantic forest, a biodiversity hotspot. we tested the efficacy of this library for specimen identification, used it to assess the frequency of cryptic species, and examined geographic patterns of genetic variation, making this study the first large-scale genetic assessment of the butterflies of southern south america. the average sequence divergence to the nearest neighbor (i.e. minimum interspecific distance) was 6.91%, ten times larger than the mean distance to the furthest conspecific (0.69%), with a clear barcode gap present in all but four of the species represented by two or more specimens. as a consequence, the dna barcode library was extremely effective in the discrimination of these species, allowing a correct identification in more than 95% of the cases. singletons (i.e. species represented by a single sequence) were also distinguishable in the gene trees since they all had unique dna barcodes, divergent from those of the closest non-conspecific. the clustering algorithms implemented recognized from 416 to 444 barcode clusters, suggesting that the actual diversity of butterflies in argentina is 3%\u20139% higher than currently recognized. furthermore, our survey added three new records of butterflies for the country (eurema agave, mithras hannelore, melanis hillapana). in summary, this study not only supported the utility of dna barcoding for the identification of the butterfly species of argentina, but also highlighted several cases of both deep intraspecific and shallow interspecific divergence that should be studied in more detail.",
            "contribution_ids": [
                "R157025",
                "R108986"
            ]
        },
        {
            "instance_id": "R157074xR157056",
            "comparison_id": "R157074",
            "paper_id": "R157056",
            "text": "A DNA Barcode Library for North American Pyraustinae (Lepidoptera: Pyraloidea: Crambidae) although members of the crambid subfamily pyraustinae are frequently important crop pests, their identification is often difficult because many species lack conspicuous diagnostic morphological characters. dna barcoding employs sequence diversity in a short standardized gene region to facilitate specimen identifications and species discovery. this study provides a dna barcode reference library for north american pyraustines based upon the analysis of 1589 sequences recovered from 137 nominal species, 87% of the fauna. data from 125 species were barcode compliant (>500bp, <1% n), and 99 of these taxa formed a distinct cluster that was assigned to a single bin. the other 26 species were assigned to 56 bins, reflecting frequent cases of deep intraspecific sequence divergence and a few instances of barcode sharing, creating a total of 155 bins. two systems for otu designation, abgd and bin, were examined to check the correspondence between current taxonomy and sequence clusters. the bin system performed better than abgd in delimiting closely related species, while otu counts with abgd were influenced by the value employed for relative gap width. different species with low or no interspecific divergence may represent cases of unrecognized synonymy, whereas those with high intraspecific divergence require further taxonomic scrutiny as they may involve cryptic diversity. the barcode library developed in this study will also help to advance understanding of relationships among species of pyraustinae.",
            "contribution_ids": [
                "R157057"
            ]
        },
        {
            "instance_id": "R157326xR156819",
            "comparison_id": "R157326",
            "paper_id": "R156819",
            "text": "A Saturated X-ray Laser Beam at 7 Nanometers a saturated nickel-like samarium x-ray laser beam at 7 nanometers has been demonstrated with an output energy of 0.3 millijoule in 50-picosecond pulses, demonstrating that saturated operation of a laser at wavelengths shorter than 10 nanometers can be achieved. the narrow divergence, short wavelength, short pulse duration, high efficiency, and high brightness of this samarium laser make it an ideal candidate for many x-ray laser applications.",
            "contribution_ids": [
                "R156821"
            ]
        },
        {
            "instance_id": "R157326xR156620",
            "comparison_id": "R157326",
            "paper_id": "R156620",
            "text": "Demonstration of population inversion by resonant photopumping in a neon gas cell irradiated by a sodiumZpinch the broadband radiation emitted from a na z pinch is used to photoionize ne to the he-like ground state and radiation from the na 1s 2 -1s2p 1 p 1 transition is used to resonantly photoexcite the ne 1s 2 -1s4p 1 p 1 transition. time-resolved and time-integrated spectral measurements of the ne k-shell emission demonstrate the first population inversion driven by a z pinch",
            "contribution_ids": [
                "R156621"
            ]
        },
        {
            "instance_id": "R157326xR156448",
            "comparison_id": "R157326",
            "paper_id": "R156448",
            "text": "Soft x-ray lasing in neonlike germanium and copper plasmas soft x-ray 3p\\\\ensuremath{\\\\rightarrow}3s lasing in neonlike germanium (${\\\\mathrm{ge}}^{22+}$) and copper (${\\\\mathrm{cu}}^{19+}$) in the wavelength interval of 195 to 285 a\\\\r{} is observed for the first time, with gain coefficients ranging from 1.7 to 4.1 ${\\\\mathrm{cm}}^{\\\\mathrm{\\\\ensuremath{-}}1}$, the higher gain with germanium. the lasing plasmas are produced by focusing a driving laser beam (\\\\ensuremath{\\\\lambda}=1.05 \\\\ensuremath{\\\\mu}m, 2-ns fwhm) into an 18-mm-long line onto thin films and slab targets. the measured j=0 to 1 gain coefficients are comparable to those of the j=2 to 1 transitions. the measured wavelengths of the six lasing lines compared favorably with recent calculations.",
            "contribution_ids": [
                "R156449"
            ]
        },
        {
            "instance_id": "R157326xR156770",
            "comparison_id": "R157326",
            "paper_id": "R156770",
            "text": "Femtosecond-pulse-driven 10-Hz 418-nm laser in Xe ix we report the observation of extreme uv lasing at 41.81 nm on the 4d95d1s0\u22124d95p1p1 transition in xe ix, as proposed by lemoff [ opt. lett.19, 569 ( 1994)]. a 10-hz circularly polarized 800-nm laser pulse with an energy of \u223c70 mj and a duration of \u223c40 fs is longitudinally focused to a peak intensity of >3 \u00d7 1016 w/cm2 over a length of 8.4 nm in a differentially pumped cell containing 12 torr of xe gas. laser amplification was observed with an estimated gain coefficient of 13 cm\u22121 and a total gain of exp(11).",
            "contribution_ids": [
                "R156772"
            ]
        },
        {
            "instance_id": "R157326xR156576",
            "comparison_id": "R157326",
            "paper_id": "R156576",
            "text": "Demonstration of x-ray amplifiers near the carbonKedge \"the ni-like 4d-4p laser scheme has been extended to wavelengths near the k absorption edge of carbon. a gain of 2.3 ${\\\\mathrm{cm}}^{\\\\mathrm{\\\\ensuremath{-}}1}$ with a duration of 250 psec was observed in ni-like ta at 44.83 \\\\aa{} (a wavelength close to optimal for holographic imaging of live cells). ni-like w produced a gain of 2.6 ${\\\\mathrm{cm}}^{\\\\mathrm{\\\\ensuremath{-}}1}$ with a total of seven gainlengths of amplification at 43.18 \\\\aa{}. this is the first demonstration of an x-ray amplifier on the short-wavelength side of the carbon k edge, within the ``water window.'' both lasers should be scalable to coherent power sufficient for holographic imaging and other applications.\"",
            "contribution_ids": [
                "R156577"
            ]
        },
        {
            "instance_id": "R157326xR156490",
            "comparison_id": "R157326",
            "paper_id": "R156490",
            "text": "Soft-x-ray amplification by lithiumlike ions in recombining hot plasmas this paper describes calculations and experiments about soft-x-ray amplification by lithiumlike ions in recombining laser-produced plasmas. time- and space-dependent population inversion densities calculated with a collisional-radiative model used as the postprocessor of a hydrodynamic code are reported. amplification diagnostic accuracy in plasma experiments is discussed. time-integrated and time-resolved measurements of gain are presented, especially at 105.7 a in lithiumlike aluminum. it is shown that, in a plasma produced by a 3-nsec laser pulse, the peak of amplified radiation occurs about 7 nsec after the top of the pulse. the maximum gain\u2013length product measured previously was 2\u20132.5. a short description of a future experiment designed for producing a much larger gain is presented.",
            "contribution_ids": [
                "R156492"
            ]
        },
        {
            "instance_id": "R157326xR156404",
            "comparison_id": "R157326",
            "paper_id": "R156404",
            "text": "Amplification of stimulated soft x-ray emission in a confined plasma column \"une amplification atteignant 100 de l'emission stimulee sur l'emission spontanee de la raie cvi 182 a a ete mesuree dans une colonne de plasma magnetiquement confinee, par deux methodes independantes utilisant des monochromateurs uv extreme etalonnes en intensite. une confirmation supplementaire que l'amplification est due a l'emission stimulee a ete obtenue avec un miroir rx mou: avec 12% de reflectivite du miroir effective mesuree, une augmentation de 120% de l'intensite de la raie cvi 182 a dans la direction axiale a ete observee\"",
            "contribution_ids": [
                "R156405"
            ]
        },
        {
            "instance_id": "R159398xR154694",
            "comparison_id": "R159398",
            "paper_id": "R154694",
            "text": "Dynamic resource allocation optimization for digital twin-driven smart shopfloor smart manufacturing is the core in the 4th industrial revolution. it is very important that how to realize the intelligent interaction between hardware and software in smart manufacturing. the paper proposes the architecture of digital twin-driven smart shopfloor (dtsf), as a contribution to the research of the research discussion about digital twin concept. then the scheme for dynamic resource allocation optimization (drao) is designed for dtsf, as an application of the proposed architecture. furthermore, a case study is given to illustrate the detailed method of drao. the experimental result shows that the proposed scheme is effective.",
            "contribution_ids": [
                "R154696"
            ]
        },
        {
            "instance_id": "R159398xR154626",
            "comparison_id": "R159398",
            "paper_id": "R154626",
            "text": "A Digital Twin-Based Approach for Designing and Multi-Objective Optimization of Hollow Glass Production Line various new national advanced manufacturing strategies, such as industry 4.0, industrial internet, and made in china 2025, are issued to achieve smart manufacturing, resulting in the increasing number of newly designed production lines in both developed and developing countries. under the individualized designing demands, more realistic virtual models mirroring the real worlds of production lines are essential to bridge the gap between design and operation. this paper presents a digital twin-based approach for rapid individualized designing of the hollow glass production line. the digital twin merges physics-based system modeling and distributed real-time process data to generate an authoritative digital design of the system at pre-production phase. a digital twin-based analytical decoupling framework is also developed to provide engineering analysis capabilities and support the decision-making over the system designing and solution evaluation. three key enabling techniques as well as a case study in hollow glass production line are addressed to validate the proposed approach.",
            "contribution_ids": [
                "R154630"
            ]
        },
        {
            "instance_id": "R159398xR154620",
            "comparison_id": "R159398",
            "paper_id": "R154620",
            "text": "Production Rate Analysis of Fractured Horizontal Well considering Multitransport Mechanisms in Shale Gas Reservoir shale gas reservoir has been aggressively exploited around the world, which has complex pore structure with multiple transport mechanisms according to the reservoir characteristics. in this paper, a new comprehensive mathematical model is established to analyze the production performance of multiple fractured horizontal well (mfhw) in box-shaped shale gas reservoir considering multiscaled flow mechanisms (ad/desorption and fick diffusion). in the model, the adsorbed gas is assumed not directly diffused into the natural macrofractures but into the macropores of matrix first and then flows into the natural fractures. the ad/desorption phenomenon of shale gas on the matrix particles is described by a combination of the langmuir\u2019s isothermal adsorption equation, continuity equation, gas state equation, and the motion equation in matrix system. on the basis of the green\u2019s function theory, the point source solution is derived under the assumption that gas flow from macropores into natural fractures follows transient interporosity and absorbed gas diffused into macropores from nanopores follows unsteady-state diffusion. the production rate expression of a mfhw producing at constant bottomhole pressure is obtained by using duhamel\u2019s principle. moreover, the curves of well production rate and cumulative production vs. time are plotted by stehfest numerical inversion algorithm and also the effects of influential factors on well production performance are analyzed. the results derived in this paper have significance to the guidance of shale gas reservoir development.",
            "contribution_ids": [
                "R154624"
            ]
        },
        {
            "instance_id": "R159398xR154687",
            "comparison_id": "R159398",
            "paper_id": "R154687",
            "text": "Towards an extended model-based definition for the digital twin abstractthe concept of the digital twin calls for virtual replicas of real world products. achieving this requires a sophisticated network of models that have a level of interconnectivity. the authors attempted to improve model interconnectivity by enhancing the computer-aided design model with spatially related non-geometric data. a tool was created to store, visualize, and search for spatial data within the computer-aided design tool. this enables both model authors, and consumers to utilize information inside the cad tool which traditionally would have existed in separate software.",
            "contribution_ids": [
                "R154692"
            ]
        },
        {
            "instance_id": "R159398xR154649",
            "comparison_id": "R159398",
            "paper_id": "R154649",
            "text": "Digital Twin of Manufacturing Systems the digitization of manufacturing systems is at the crux of the next industrial revolutions. the digital representation of the \u201cphysical twin,\u201d also known as the \u201cdigital twin,\u201d will help in maintaining the process quality effectively by allowing easy visualization and incorporation of cognitive capability in the system. in this technical report, we tackle two issues regarding the digital twin: (1) modeling the digital twin by extracting information from the side-channel emissions, and (2) making sure that the digital twin is up-to-date (or \u201calive\u201d). we will first analyze various analog emissions to figure out if they behave as side-channels, informing about the various states of both cyber and physical domains. then, we will present a dynamic data-driven application system enabled digital twin, which is able to check if it is the most up-to-date version of the physical twin. index terms digital twin, cyber-physical systems, digitization, additive manufacturing, machine learning, sensor fusion, dynamic data-driven application systems",
            "contribution_ids": [
                "R154651"
            ]
        },
        {
            "instance_id": "R159398xR151426",
            "comparison_id": "R159398",
            "paper_id": "R151426",
            "text": "Equipment energy consumption management in digital twin shop-floor: A framework and potential applications with increasing attentions focused on the energy consumption (ec) in manufacturing, it is imperative to realize the equipment energy consumption management (eecm) to reduce the ec and improve the energy efficiency. recently, with the developments of digital twin (dt) and digital twin shop-floor (dts), the data and models are enriched greatly and a physical-virtual convergence environment is provided. accordingly, the new chances emerge for improving the eecm in ec monitoring, analysis and optimization. in this situation, the paper proposes the framework of eecm in dts and discusses the potential applications, aiming at studying the improvements and providing a guideline for the future works.",
            "contribution_ids": [
                "R151428"
            ]
        },
        {
            "instance_id": "R159398xR154617",
            "comparison_id": "R159398",
            "paper_id": "R154617",
            "text": "The Digital Twin Paradigm for Future NASA and U.S. Air Force Vehicles future generations of nasa and u.s. air force vehicles will require lighter mass while being subjected to higher loads and more extreme service conditions over longer time periods than the present generation. current approaches for certification, fleet management and sustainment are largely based on statistical distributions of material properties, heuristic design philosophies, physical testing and assumed similitude between testing and operational conditions and will likely be unable to address these extreme requirements. to address the shortcomings of conventional approaches, a fundamental paradigm shift is needed. this paradigm shift, the digital twin, integrates ultra-high fidelity simulation with the vehicle s on-board integrated vehicle health management system, maintenance history and all available historical and fleet data to mirror the life of its flying twin and enable unprecedented levels of safety and reliability.",
            "contribution_ids": [
                "R154619"
            ]
        },
        {
            "instance_id": "R159490xR154698",
            "comparison_id": "R159490",
            "paper_id": "R154698",
            "text": "A DIGITAL TWIN FOR ROOT CAUSE ANALYSIS AND PRODUCT QUALITY MONITORING mass customization and increasing product complexity require new methods to ensure a continuously high product quality. in the case of product failures it has to be determined what distinguishes flawed products. the data generated by cybertronic products over their lifecycle offers new possibilities to find such distinctions. to manage this data for individual product instances the concept of a digital twin has been proposed. this paper introduces the elements of a digital twin for root cause analysis and product quality monitoring and suggests a data structure that enables data analytics.",
            "contribution_ids": [
                "R154700"
            ]
        },
        {
            "instance_id": "R159490xR151420",
            "comparison_id": "R159490",
            "paper_id": "R151420",
            "text": "Digital twins technolgy and its data fusion in iron and steel product life cycle the related models in iron and steel product life cycle (is-plc), from order, design, purchase, scheduling to specific manufacturing processes (i.e., coking, sintering, blast furnace iron-making, converter, steel-making, continuous steel casting, rolling) is characterized by large-scale, multi-objective, multi-physics, dynamic uncertainty and complicated constraint. to achieve complex task in is-plc, involved models need be interrelated and interact, but how to build digital twin models in each is-plc stage, and carry out fusion between models and data to achieve virtual space (vs) and physical space (ps) intercorrelation, is a key technology in is-plc. in this paper, digital twins modeling and its fusion data problem in each is-plc stage are preliminary discussed.",
            "contribution_ids": [
                "R151422"
            ]
        },
        {
            "instance_id": "R159490xR154694",
            "comparison_id": "R159490",
            "paper_id": "R154694",
            "text": "Dynamic resource allocation optimization for digital twin-driven smart shopfloor smart manufacturing is the core in the 4th industrial revolution. it is very important that how to realize the intelligent interaction between hardware and software in smart manufacturing. the paper proposes the architecture of digital twin-driven smart shopfloor (dtsf), as a contribution to the research of the research discussion about digital twin concept. then the scheme for dynamic resource allocation optimization (drao) is designed for dtsf, as an application of the proposed architecture. furthermore, a case study is given to illustrate the detailed method of drao. the experimental result shows that the proposed scheme is effective.",
            "contribution_ids": [
                "R154696"
            ]
        },
        {
            "instance_id": "R159490xR154617",
            "comparison_id": "R159490",
            "paper_id": "R154617",
            "text": "The Digital Twin Paradigm for Future NASA and U.S. Air Force Vehicles future generations of nasa and u.s. air force vehicles will require lighter mass while being subjected to higher loads and more extreme service conditions over longer time periods than the present generation. current approaches for certification, fleet management and sustainment are largely based on statistical distributions of material properties, heuristic design philosophies, physical testing and assumed similitude between testing and operational conditions and will likely be unable to address these extreme requirements. to address the shortcomings of conventional approaches, a fundamental paradigm shift is needed. this paradigm shift, the digital twin, integrates ultra-high fidelity simulation with the vehicle s on-board integrated vehicle health management system, maintenance history and all available historical and fleet data to mirror the life of its flying twin and enable unprecedented levels of safety and reliability.",
            "contribution_ids": [
                "R154619"
            ]
        },
        {
            "instance_id": "R159490xR154687",
            "comparison_id": "R159490",
            "paper_id": "R154687",
            "text": "Towards an extended model-based definition for the digital twin abstractthe concept of the digital twin calls for virtual replicas of real world products. achieving this requires a sophisticated network of models that have a level of interconnectivity. the authors attempted to improve model interconnectivity by enhancing the computer-aided design model with spatially related non-geometric data. a tool was created to store, visualize, and search for spatial data within the computer-aided design tool. this enables both model authors, and consumers to utilize information inside the cad tool which traditionally would have existed in separate software.",
            "contribution_ids": [
                "R154692"
            ]
        },
        {
            "instance_id": "R159490xR154620",
            "comparison_id": "R159490",
            "paper_id": "R154620",
            "text": "Production Rate Analysis of Fractured Horizontal Well considering Multitransport Mechanisms in Shale Gas Reservoir shale gas reservoir has been aggressively exploited around the world, which has complex pore structure with multiple transport mechanisms according to the reservoir characteristics. in this paper, a new comprehensive mathematical model is established to analyze the production performance of multiple fractured horizontal well (mfhw) in box-shaped shale gas reservoir considering multiscaled flow mechanisms (ad/desorption and fick diffusion). in the model, the adsorbed gas is assumed not directly diffused into the natural macrofractures but into the macropores of matrix first and then flows into the natural fractures. the ad/desorption phenomenon of shale gas on the matrix particles is described by a combination of the langmuir\u2019s isothermal adsorption equation, continuity equation, gas state equation, and the motion equation in matrix system. on the basis of the green\u2019s function theory, the point source solution is derived under the assumption that gas flow from macropores into natural fractures follows transient interporosity and absorbed gas diffused into macropores from nanopores follows unsteady-state diffusion. the production rate expression of a mfhw producing at constant bottomhole pressure is obtained by using duhamel\u2019s principle. moreover, the curves of well production rate and cumulative production vs. time are plotted by stehfest numerical inversion algorithm and also the effects of influential factors on well production performance are analyzed. the results derived in this paper have significance to the guidance of shale gas reservoir development.",
            "contribution_ids": [
                "R154624"
            ]
        },
        {
            "instance_id": "R159490xR154672",
            "comparison_id": "R159490",
            "paper_id": "R154672",
            "text": "Digital Twin and Big Data Towards Smart Manufacturing and Industry 4.0: 360 Degree Comparison with the advances in new-generation information technologies, especially big data and digital twin, smart manufacturing is becoming the focus of global manufacturing transformation and upgrading. intelligence comes from data. integrated analysis for the manufacturing big data is beneficial to all aspects of manufacturing. besides, the digital twin paves a way for the cyber-physical integration of manufacturing, which is an important bottleneck to achieve smart manufacturing. in this paper, the big data and digital twin in manufacturing are reviewed, including their concept as well as their applications in product design, production planning, manufacturing, and predictive maintenance. on this basis, the similarities and differences between big data and digital twin are compared from the general and data perspectives. since the big data and digital twin can be complementary, how they can be integrated to promote smart manufacturing are discussed.",
            "contribution_ids": [
                "R154674"
            ]
        },
        {
            "instance_id": "R160742xR160725",
            "comparison_id": "R160742",
            "paper_id": "R160725",
            "text": "Inverse estimates of anthropogenic CO2uptake, transport, and storage by the ocean: AIR-SEA EXCHANGE OF ANTHROPOGENIC CARBON \"regional air\u2010sea fluxes of anthropogenic co2 are estimated using a green's function inversion method that combines data\u2010based estimates of anthropogenic co2 in the ocean with information about ocean transport and mixing from a suite of ocean general circulation models (ogcms). in order to quantify the uncertainty associated with the estimated fluxes owing to modeled transport and errors in the data, we employ 10 ogcms and three scenarios representing biases in the data\u2010based anthropogenic co2 estimates. on the basis of the prescribed anthropogenic co2 storage, we find a global uptake of 2.2 \u00b1 0.25 pg c yr\u22121, scaled to 1995. this error estimate represents the standard deviation of the models weighted by a cfc\u2010based model skill score, which reduces the error range and emphasizes those models that have been shown to reproduce observed tracer concentrations most accurately. the greatest anthropogenic co2 uptake occurs in the southern ocean and in the tropics. the flux estimates imply vigorous northward transport in the southern hemisphere, northward cross\u2010equatorial transport, and equatorward transport at high northern latitudes. compared with forward simulations, we find substantially more uptake in the southern ocean, less uptake in the pacific ocean, and less global uptake. the large\u2010scale spatial pattern of the estimated flux is generally insensitive to possible biases in the data and the models employed. however, the global uptake scales approximately linearly with changes in the global anthropogenic co2 inventory. considerable uncertainties remain in some regions, particularly the southern ocean.\"",
            "contribution_ids": [
                "R160726"
            ]
        },
        {
            "instance_id": "R160742xR160712",
            "comparison_id": "R160742",
            "paper_id": "R160712",
            "text": "Sea\u00e2\u0080\u0093air CO&lt;sub&gt;2&lt;/sub&gt; fluxes in the Indian Ocean between 1990 and 2009 abstract. the indian ocean (44\u00b0 s\u201330\u00b0 n) plays an important role in the global carbon cycle, yet it remains one of the most poorly sampled ocean regions. several approaches have been used to estimate net sea\u2013air co2 fluxes in this region: interpolated observations, ocean biogeochemical models, atmospheric and ocean inversions. as part of the reccap (regional carbon cycle assessment and processes) project, we combine these different approaches to quantify and assess the magnitude and variability in indian ocean sea\u2013air co2 fluxes between 1990 and 2009. using all of the models and inversions, the median annual mean sea\u2013air co2 uptake of \u22120.37 \u00b1 0.06 pgc yr\u22121 is consistent with the \u22120.24 \u00b1 0.12 pgc yr\u22121 calculated from observations. the fluxes from the southern indian ocean (18\u201344\u00b0 s; \u22120.43 \u00b1 0.07 pgc yr\u22121 are similar in magnitude to the annual uptake for the entire indian ocean. all models capture the observed pattern of fluxes in the indian ocean with the following exceptions: underestimation of upwelling fluxes in the northwestern region (off oman and somalia), overestimation in the northeastern region (bay of bengal) and underestimation of the co2 sink in the subtropical convergence zone. these differences were mainly driven by lack of atmospheric co2 data in atmospheric inversions, and poor simulation of monsoonal currents and freshwater discharge in ocean biogeochemical models. overall, the models and inversions do capture the phase of the observed seasonality for the entire indian ocean but overestimate the magnitude. the predicted sea\u2013air co2 fluxes by ocean biogeochemical models (obgms) respond to seasonal variability with strong phase lags with reference to climatological co2 flux, whereas the atmospheric inversions predicted an order of magnitude higher seasonal flux than obgms. the simulated interannual variability by the obgms is weaker than that found by atmospheric inversions. prediction of such weak interannual variability in co2 fluxes by atmospheric inversions was mainly caused by a lack of atmospheric data in the indian ocean. the obgm models suggest a small strengthening of the sink over the period 1990\u20132009 of \u22120.01 pgc decade\u22121. this is inconsistent with the observations in the southwestern indian ocean that shows the growth rate of oceanic pco2 was faster than the observed atmospheric co2 growth, a finding attributed to the trend of the southern annular mode (sam) during the 1990s.\\n",
            "contribution_ids": [
                "R160714"
            ]
        },
        {
            "instance_id": "R160742xR160735",
            "comparison_id": "R160742",
            "paper_id": "R160735",
            "text": "Strong CO2emissions from the Arabian Sea during south-west monsoon the partial pressure of co2 (pco2) was measured during the 1995 south\u2010west monsoon in the arabian sea. the arabian sea was characterized throughout by a moderate supersaturation of 12\u201330 \u00b5atm. the stable atmospheric pco2 level was around 345 \u00b5atm. an extreme supersaturation was found in areas of coastal upwelling off the omani coast with pco2 peak values in surface waters of 750 \u00b5atm. such two\u2010fold saturation (218%) is rarely found elsewhere in open ocean environments. we also encountered cold upwelled water 300 nm off the omani coast in the region of ekman pumping, which was also characterized by a strongly elevated seawater pco2 of up to 525 \u00b5atm. due to the strong monsoonal wind forcing the arabian sea as a whole and the areas of upwelling in particular represent a significant source of atmospheric co2 with flux densities from around 2 mmol m\u22122 d\u22121 in the open ocean to 119 mmol m\u22122 d\u22121 in coastal upwelling. local air masses passing the area of coastal upwelling showed increasing co2 concentrations, which are consistent with such strong emissions.",
            "contribution_ids": [
                "R160736"
            ]
        },
        {
            "instance_id": "R160847xR160813",
            "comparison_id": "R160847",
            "paper_id": "R160813",
            "text": "Development of In Vitro\u00e2\u0080\u0093In Vivo Correlation for Amorphous Solid Dispersion Immediate-Release Suvorexant Tablets and Application to Clinically Relevant Dissolution Specifications and In-Process Controls although in vitro-in vivo correlations (ivivcs) are commonly pursued for modified-release products, there are limited reports of successful ivivcs for immediate-release (ir) formulations. this manuscript details the development of a multiple level c ivivc for the amorphous solid dispersion formulation of suvorexant, a bcs class ii compound, and its application to establishing dissolution specifications and in-process controls. four different 40 mg batches were manufactured at different tablet hardnesses to produce distinct dissolution profiles. these batches were evaluated in a relative bioavailability clinical study in healthy volunteers. although no differences were observed for the total exposure (auc) of the different batches, a clear relationship between dissolution and cmax was observed. a validated multiple level c ivivc against cmax was developed for the 10, 15, 20, 30, and 45 min dissolution time points and the tablet disintegration time. the relationship established between tablet tensile strength and dissolution was subsequently used to inform suitable tablet hardness ranges within acceptable cmax limits. this is the first published report for a validated multiple level c ivivc for an ir solid dispersion formulation demonstrating how this approach can facilitate quality by design in formulation development and help toward clinically relevant specifications and in-process controls.",
            "contribution_ids": [
                "R160815"
            ]
        },
        {
            "instance_id": "R160847xR160791",
            "comparison_id": "R160847",
            "paper_id": "R160791",
            "text": "Mechanochemical Synthesis of Pharmaceutical Cocrystal Suspensions via Hot Melt Extrusion: Feasibility Studies and Physicochemical Characterization engineered cocrystals offer an alternative solid drug form with tailored physicochemical properties. interestingly, although cocrystals provide many new possibilities, they also present new challenges, particularly in regard to their design and large-scale manufacture. current literature has primarily focused on the preparation and characterization of novel cocrystals typically containing only the drug and coformer, leaving the subsequent formulation less explored. in this paper we propose, for the first time, the use of hot melt extrusion for the mechanochemical synthesis of pharmaceutical cocrystals in the presence of a meltable binder. in this approach, we examine excipients that are amenable to hot melt extrusion, forming a suspension of cocrystal particulates embedded in a pharmaceutical matrix. using ibuprofen and isonicotinamide as a model cocrystal reagent pair, formulations extruded with a small molecular matrix carrier (xylitol) were examined to be intimate mixtures wherein the newly formed cocrystal particulates were physically suspended in a matrix. with respect to formulations extruded using polymeric carriers (soluplus and eudragit epo, respectively), however, there was no evidence within pxrd patterns of either crystalline ibuprofen or the cocrystal. importantly, it was established in this study that an appropriate carrier for a cocrystal reagent pair during hme processing should satisfy certain criteria including limited interaction with parent reagents and cocrystal product, processing temperature sufficiently lower than the onset of cocrystal tm, low melt viscosity, and rapid solidification upon cooling.",
            "contribution_ids": [
                "R160793",
                "R160795"
            ]
        },
        {
            "instance_id": "R160847xR160835",
            "comparison_id": "R160847",
            "paper_id": "R160835",
            "text": "The Influence of Drug Physical State on the Dissolution Enhancement of Solid Dispersions Prepared Via Hot-Melt Extrusion: A Case Study Using Olanzapine in this study, we examine the relationship between the physical structure and dissolution behavior of olanzapine (olz) prepared via hot-melt extrusion in three polymers [polyvinylpyrrolidone (pvp) k30, polyvinylpyrrolidone-co-vinyl acetate (pvpva) 6:4, and soluplus\u00ae (slp)]. in particular, we examine whether full amorphicity is necessary to achieve a favorable dissolution profile. drug\u2013polymer miscibility was estimated using melting point depression and hansen solubility parameters. solid dispersions were characterized using differential scanning calorimetry, x-ray powder diffraction, and scanning electron microscopy. all the polymers were found to be miscible with olz in a decreasing order of pvp>pvpva>slp. at a lower extrusion temperature (160\u00b0c), pvp generated fully amorphous dispersions with olz, whereas the formulations with pvpva and slp contained 14%\u201316% crystalline olz. increasing the extrusion temperature to 180\u00b0c allowed the preparation of fully amorphous systems with pvpva and slp. despite these differences, the dissolution rates of these preparations were comparable, with pvp showing a lower release rate despite being fully amorphous. these findings suggested that, at least in the particular case of olz, the absence of crystalline material may not be critical to the dissolution performance. we suggest alternative key factors determining dissolution, particularly the dissolution behavior of the polymers themselves.",
            "contribution_ids": [
                "R160837"
            ]
        },
        {
            "instance_id": "R161728xR160306",
            "comparison_id": "R161728",
            "paper_id": "R160306",
            "text": "Mobile Mapping, Machine Learning and Digital Twin for Road Infrastructure Monitoring and Maintenance: Case Study of Mohammed VI Bridge in Morocco the concepts of digital twin has been recently introduced, it refers to functional connections between a complex physical system and its high-fidelity digital replica. digital twin process workflow is proposed in case of mohammed vi bridge modeling in morocco. the current maintenance of a road infrastructure is based on a manual inspection and a system based on traditional tools. aging infrastructures require a new approach to maintenance in terms of inspection, bridge maintenance system, simulation and systematic evaluation. this system now exists and is called the digital twin. digital twin can be thought of as a virtual prototype in service that changes dynamically in near real time as its physical twin changes. an urban infrastructure digital twin is a virtual instance of his physical twin that is continuously updated with multisource, multisensor and multitemporal data that can be used for monitoring, simulating and forecasting any potential problem that may appear in the structure and proposing planning for repair and maintenance of health status throughout the life cycle of this infrastructure. this work presents a general vision and a justification for integrating dt technology with geospatial data. the paper examines the benefits of integrating 3d gis data acquired by automated mobile mapping (mms) workflows for modeling the reality of a major bridge infrastructure in morocco. this allowed to study the future performance of this bridge structure on virtual twin structures under different environmental conditions. cloud point data are acquired by a mobile mapping system on mohammed vi bridge and converted in bim model by a scan to bim process and is integrated in a gis and bim virtual environment and shows the efficiency of volumetric auscultation in terms of surface flatness and distortion inspection. this project provides a new bridge maintenance system using the concept of a digital twin. this digital model is a platform that allows to collect, organize and share the maintenance history of this important road infrastructure in morocco.",
            "contribution_ids": [
                "R160308"
            ]
        },
        {
            "instance_id": "R161728xR160415",
            "comparison_id": "R161728",
            "paper_id": "R160415",
            "text": "Digital Twins: From Personalised Medicine to Precision Public Health a digital twin is a virtual model of a physical entity, with dynamic, bi-directional links between the physical entity and its corresponding twin in the digital domain. digital twins are increasingly used today in different industry sectors. applied to medicine and public health, digital twin technology can drive a much-needed radical transformation of traditional electronic health/medical records (focusing on individuals) and their aggregates (covering populations) to make them ready for a new era of precision (and accuracy) medicine and public health. digital twins enable learning and discovering new knowledge, new hypothesis generation and testing, and in silico experiments and comparisons. they are poised to play a key role in formulating highly personalised treatments and interventions in the future. this paper provides an overview of the technology\u2019s history and main concepts. a number of application examples of digital twins for personalised medicine, public health, and smart healthy cities are presented, followed by a brief discussion of the key technical and other challenges involved in such applications, including ethical issues that arise when digital twins are applied to model humans.",
            "contribution_ids": [
                "R160418"
            ]
        },
        {
            "instance_id": "R161728xR160323",
            "comparison_id": "R161728",
            "paper_id": "R160323",
            "text": "Circular cities a circular approach to the way in which we manage the resources consumed and produced in cities \u2013 materials, energy, water and land \u2013 will significantly reduce the consumption of finite resources globally. it will also help to address urban problems including resource security, waste disposal, greenhouse gas emissions, pollution, heating, drought and flooding. taking a circular approach can also tackle many other socio-economic problems afflicting cities, for example, providing access to affordable accommodation, expanding and diversifying the economic base, building more engaged and collaborative communities in cities. thus it has great potential to improve our urban living environments. to date, the industrial ecologists and economists have tended to dominate the circularity debate, focusing on closed-loop industrial systems and circular economy (circular businesses and systems of provision). in this paper i investigate why the current state-of-the-art conceptualisation for circular economy (resolve) is inadequate when applied to a city. through this critique and a broader review of the literature i identify the principles and components which are lacking from the circular economy (ce) conceptualisation when applied to a city. i then use this to develop my own definition and conceptualisation of a circular approach to urban resource management.",
            "contribution_ids": [
                "R160325"
            ]
        },
        {
            "instance_id": "R161728xR160291",
            "comparison_id": "R161728",
            "paper_id": "R160291",
            "text": "A Smart Campus\u00e2\u0080\u0099 Digital Twin for Sustainable Comfort Monitoring interdisciplinary cross-cultural and cross-organizational research offers great opportunities for innovative breakthroughs in the field of smart cities, yet it also presents organizational and knowledge development hurdles. smart cities must be large towns able to sustain the needs of their citizens while promoting environmental sustainability. smart cities foment the widespread use of novel information and communication technologies (icts); however, experimenting with these technologies in such a large geographical area is unfeasible. consequently, smart campuses (scs), which are universities where technological devices and applications create new experiences or services and facilitate operational efficiency, allow experimentation on a smaller scale, the concept of scs as a testbed for a smart city is gaining momentum in the research community. nevertheless, while universities acknowledge the academic role of a smart and sustainable approach to higher education, campus life and other student activities remain a mystery, which have never been universally solved. this paper proposes a sc concept to investigate the integration of building information modeling tools with internet of things- (iot)-based wireless sensor networks in the fields of environmental monitoring and emotion detection to provide insights into the level of comfort. additionally, it explores the ability of universities to contribute to local sustainability projects by sharing knowledge and experience across a multi-disciplinary team. preliminary results highlight the significance of monitoring workspaces because productivity has been proven to be directly influenced by environment parameters. the comfort-monitoring infrastructure could also be reused to monitor physical parameters from educational premises to increase energy efficiency.",
            "contribution_ids": [
                "R160297"
            ]
        },
        {
            "instance_id": "R161728xR160301",
            "comparison_id": "R161728",
            "paper_id": "R160301",
            "text": "Digital Twin Aided Vulnerability Assessment and Risk-Based Maintenance Planning of Bridge Infrastructures Exposed to Extreme Conditions over the past centuries, millions of bridge infrastructures have been constructed globally. many of those bridges are ageing and exhibit significant potential risks. frequent risk-based inspection and maintenance management of highway bridges is particularly essential for public safety. at present, most bridges rely on manual inspection methods for management. the efficiency is extremely low, causing the risk of bridge deterioration and defects to increase day by day, reducing the load-bearing capacity of bridges, and restricting the normal and safe use of them. at present, the applications of digital twins in the construction industry have gained significant momentum and the industry has gradually entered the information age. in order to obtain and share relevant information, engineers and decision makers have adopted digital twins over the entire life cycle of a project, but their applications are still limited to data sharing and visualization. this study has further demonstrated the unprecedented applications of digital twins to sustainability and vulnerability assessments, which can enable the next generation risk-based inspection and maintenance framework. this study adopts the data obtained from a constructor of zhongcheng village bridge in zhejiang province, china as a case study. the applications of digital twins to bridge model establishment, information collection and sharing, data processing, inspection and maintenance planning have been highlighted. then, the integration of \u201cdigital twins (or building information modelling, bim) + bridge risk inspection model\u201d has been established, which will become a more effective information platform for all stakeholders to mitigate risks and uncertainties of exposure to extreme weather conditions over the entire life cycle.",
            "contribution_ids": [
                "R160305"
            ]
        },
        {
            "instance_id": "R161728xR159481",
            "comparison_id": "R161728",
            "paper_id": "R159481",
            "text": "The Digital Twin of the City of Zurich for Urban Planning abstract population growth will confront the city of zurich with a variety of challenges in the coming years, as the increase in the number of inhabitants and jobs will lead to densification and competing land uses. the tasks for the city administration have become more complex, whereas tools and methods are often based on traditional, static approaches while involving a limited number of citizens and stakeholders in relevant decisions. the digital transformation of more and more\\xa0pieces of the planning and decision-making process will make both increasingly more illustrative, easier to understand and more comprehensible. an important data basis for these processes is the digital twin of the city of zurich. 3d spatial data and their models transform themes of the city, such as buildings, bridges, vegetation, etc., to the digital world, are being updated when required, and create advantages in digital space. these benefits need to be highlighted and published. an important step in public awareness is the release of 3d spatial data under open government data. this allows the development of applications, the promotion of understanding, and the simplification of the creation of different collaborative platforms. by\\xa0visualization and analysis of digital prototypes and the demonstration of interactions with the built environment, scenarios can be digitally developed and discussed in decision-making bodies. questions about the urban climate can be simulated with the help of the digital twin and results can be linked to the existing 3d spatial data. thus, the 3d spatial data set, the models and their descriptions through\\xa0metadata become the reference and must be updated according to the requirements. depending on requirements and questions, further 3d spatial data must be added. the description of the 3d spatial data and their models or the lifecycle management of the digital twin must be carried out with great care. only in this way, decision processes can be supported in a comprehensible way.",
            "contribution_ids": [
                "R159483",
                "R160407"
            ]
        },
        {
            "instance_id": "R161728xR160349",
            "comparison_id": "R161728",
            "paper_id": "R160349",
            "text": "Leveraging Digital Twin for Sustainability Assessment of an Educational Building the eu green deal, beginning in 2019, promoted a roadmap for operating the transition to a sustainable eu economy by turning climate issues and environmental challenges into opportunities in all policy areas and making the transition fair and inclusive for all. focusing on the built environment, the voluntary adoption of rating systems for sustainability assessment is growing, with an increasing market value, and is perceived as a social responsibility both by public administration and by private companies. this paper proposes a framework for shifting from a static sustainability assessment to a digital twin (dt)-based and internet of things (iot)-enabled dynamic approach. this new approach allows for a real-time evaluation and control of a wide range of sustainability criteria with a user-centered point of view. a pilot building, namely, the elux lab cognitive building in the university of brescia, was used to test the framework with some sample applications. the educational building accommodates the daily activities of the engineering students by constantly interacting with the sensorized asset monitoring indoor comfort and air quality conditions as well as the energy behavior of the building in order to optimize the trade-off with renewable energy production. the framework is the cornerstone of a methodology exploiting the digital twin approach to support the decision processes related to sustainability through the whole building\u2019s life cycle.",
            "contribution_ids": [
                "R160353"
            ]
        },
        {
            "instance_id": "R161728xR160340",
            "comparison_id": "R161728",
            "paper_id": "R160340",
            "text": "Integrating Virtual Reality and Digital Twin in Circular Economy Practices: A Laboratory Application Case the increasing awareness of customers toward climate change effects, the high demand instability affecting several industrial sectors, and the fast automation and digitalization of production systems are forcing companies to re-think their business strategies and models in view of both the circular economy (ce) and industry 4.0 (i4.0) paradigms. some studies have already assessed the relations between ce and i4.0, their benefits, and barriers. however, a practical demonstration of their potential impact in real contexts is still lacking. the aim of this paper is to present a laboratory application case showing how i4.0-based technologies can support ce practices by virtually testing a waste from electrical and electronic equipment (weee) disassembly plant configuration through a set of dedicated simulation tools. our results highlight that service-oriented, event-driven processing and information models can support the integration of smart and digital solutions in current ce practices at the factory level.",
            "contribution_ids": [
                "R160344"
            ]
        },
        {
            "instance_id": "R161728xR160363",
            "comparison_id": "R161728",
            "paper_id": "R160363",
            "text": "Beyond the State of the Art of Electric Vehicles: A Fact-Based Paper of the Current and Prospective Electric Vehicle Technologies today, there are many recent developments that focus on improving the electric vehicles and their components, particularly regarding advances in batteries, energy management systems, autonomous features and charging infrastructure. this plays an important role in developing next electric vehicle generations, and encourages more efficient and sustainable eco-system. this paper not only provides insights in the latest knowledge and developments of electric vehicles (evs), but also the new promising and novel ev technologies based on scientific facts and figures\u2014which could be from a technological point of view feasible by 2030. in this paper, potential design and modelling tools, such as digital twin with connected internet-of-things (iot), are addressed. furthermore, the potential technological challenges and research gaps in all ev aspects from hard-core battery material sciences, power electronics and powertrain engineering up to environmental assessments and market considerations are addressed. the paper is based on the knowledge of the 140+ fte counting multidisciplinary research centre mobi-vub, that has a 40-year track record in the field of electric vehicles and e-mobility.",
            "contribution_ids": [
                "R160373"
            ]
        },
        {
            "instance_id": "R161728xR160422",
            "comparison_id": "R161728",
            "paper_id": "R160422",
            "text": "A Novel Cloud-Based Framework for the Elderly Healthcare Services Using Digital Twin with the development of technologies, such as big data, cloud computing, and the internet of things (iot), digital twin is being applied in industry as a precision simulation technology from concept to practice. further, simulation plays a very important role in the healthcare field, especially in research on medical pathway planning, medical resource allocation, medical activity prediction, etc. by combining digital twin and healthcare, there will be a new and efficient way to provide more accurate and fast services for elderly healthcare. however, how to achieve personal health management throughout the entire lifecycle of elderly patients, and how to converge the medical physical world and the virtual world to realize real smart healthcare, are still two key challenges in the era of precision medicine. in this paper, a framework of the cloud healthcare system is proposed based on digital twin healthcare (clouddth). this is a novel, generalized, and extensible framework in the cloud environment for monitoring, diagnosing and predicting aspects of the health of individuals using, for example, wearable medical devices, toward the goal of personal health management, especially for the elderly. clouddth aims to achieve interaction and convergence between medical physical and virtual spaces. accordingly, a novel concept of digital twin healthcare (dth) is proposed and discussed, and a dth model is implemented. next, a reference framework of clouddth based on dth is constructed, and its key enabling technologies are explored. finally, the feasibility of some application scenarios and a case study for real-time supervision are demonstrated.",
            "contribution_ids": [
                "R160427"
            ]
        },
        {
            "instance_id": "R161728xR160428",
            "comparison_id": "R161728",
            "paper_id": "R160428",
            "text": "An ISO/IEEE 11073 Standardized Digital Twin Framework for Health and Well-Being in Smart Cities the use of the digital twin has been quickly adopted in industry in recent years and continues to gain momentum. the recent redefinition of the digital twin from the digital replica of a physical asset to the replica of a living or nonliving entity has increased its potential. the digital twin not only disrupts industrial processes, but also expands the domain of health and well-being towards fostering smart healthcare services in smart cities. in this paper, we propose an iso/ieee 11073 standardized digital twin framework architecture for health and well-being. this framework encompasses the process of data collection from personal health devices, the analysis of this data, and conveying the feedback to the user in a loop cycle. the framework proposes a solution to include not only x73 compliant devices, but also noncompliant health devices, by interfacing them with an x73 wrapper module as we explain in this paper. besides, we propose a configurable x73 mobile application, designed to work with any x73 compliant device. we designed and implemented the proposed framework, and the x73 mobile app, and conducted an experiment as a proof of concept of the digital twin in the domain of health and well-being in smart cities. the experiment shows promising results and the potential of benefiting from the proposed framework, by gaining insights on the health and well-being of individuals, and providing feedback to the individual and caregiver.",
            "contribution_ids": [
                "R160433"
            ]
        },
        {
            "instance_id": "R161728xR160263",
            "comparison_id": "R161728",
            "paper_id": "R160263",
            "text": "Evaluation of Urban-Scale Building Energy-Use Models and Tools\u00e2\u0080\u0094Application for the City of Fribourg, Switzerland building energy-use models and tools can simulate and represent the distribution of energy consumption of buildings located in an urban area. the aim of these models is to simulate the energy performance of buildings at multiple temporal and spatial scales, taking into account both the building shape and the surrounding urban context. this paper investigates existing models by simulating the hourly space heating consumption of residential buildings in an urban environment. existing bottom-up urban-energy models were applied to the city of fribourg in order to evaluate the accuracy and flexibility of energy simulations. two common energy-use models\u2014a machine learning model and a gis-based engineering model\u2014were compared and evaluated against anonymized monitoring data. the study shows that the simulations were quite precise with an annual mean absolute percentage error of 12.8 and 19.3% for the machine learning and the gis-based engineering model, respectively, on residential buildings built in different periods of construction. moreover, a sensitivity analysis using the morris method was carried out on the gis-based engineering model in order to assess the impact of input variables on space heating consumption and to identify possible optimization opportunities of the existing model.",
            "contribution_ids": [
                "R160269"
            ]
        },
        {
            "instance_id": "R161728xR160381",
            "comparison_id": "R161728",
            "paper_id": "R160381",
            "text": "Roads Infrastructure Digital Twin: A Step Toward Smarter Cities Realization digital twin is a new concept that consists of creating an up-to-date virtual asset in cyberspace which mimics the original physical asset in most of its aspects, ultimately to monitor, analyze, test, and optimize the physical asset. in this article, we investigate and discuss the use of the digital twin concept of the roads as a step toward realizing the dream of smart cities. to this end, we propose the deployment of a digital twin box to the roads that is composed of a 360\u00b0 camera and a set of iot devices connected to a single onboard computer. the digital twin box creates a digital twin of the physical road asset by constantly sending real-time data to the edge/cloud, including the 360\u00b0 live stream, gps location, and measurements of the temperature and humidity. this data will be used for realtime monitoring and other purposes by displaying the live stream via head-mounted devices or using a 360\u00b0 web-based player. additionally, we perform an object detection process to extract all possible objects from the captured stream. for some specific objects (person and vehicle), an identification module and a tracking module are employed to identify the corresponding objects and keep track of all video frames where these objects appeared. the outcome of the latter step would be of utmost importance to many other services and domains such as national security. to show the viability of the proposed solution, we have implemented and conducted real-world experiments where we focus more on the detection and recognition processes. the achieved results show the effectiveness of the proposed solution in creating a digital twin of the roads, a step forward to enable self-driving vehicles as a crucial component of smart mobility, using the digital twin box.",
            "contribution_ids": [
                "R160383"
            ]
        },
        {
            "instance_id": "R161728xR159473",
            "comparison_id": "R161728",
            "paper_id": "R159473",
            "text": "Participatory Sensing and Digital Twin City: Updating Virtual City Models for Enhanced Risk-Informed Decision-Making abstractthe benefits of a digital twin city have been assessed based on real-time data collected from preinstalled internet of things (iot) sensors (e.g.,\\xa0traffic, energy use, air pollution, water ...",
            "contribution_ids": [
                "R159477",
                "R160389"
            ]
        },
        {
            "instance_id": "R161728xR160319",
            "comparison_id": "R161728",
            "paper_id": "R160319",
            "text": "The Circular Economy: A New Development Strategy in China activities over the past several years, however, clearly show that ce is emerging as an economic strategy rather than a purely environmental strategy. the major objective of the government is to promote the sustainable development of economy and society, while it also helps to achieve sustainable environmental protection. powers, increasing the wealth of the population and providing employment and business opportunities. the rapid economic growth, however, has engendered serious natural resource depletion and environmental pollution, and the continuing increase of population has exacerbated this situation greatly. recent research has pointed out that growth of the gross domestic product (gdp) in china has significantly reduced the opportunities of future generations to enjoy natural and environmental resources.1 the central government promised in 2002 to build a prosperous society in a comprehensive way by 2020. by then, gdp per capita is anticipated to reach u.s. $3,000 and the total gdp to quadruple. obviously, it is unrealistic for china to expect to realize this ambitious objective in terms of natural resource use if it continues its current development pathway, with population increasing to 1.45 billion in 2020 (qu 2004), low productivity, and the absence of eco-efficiency.",
            "contribution_ids": [
                "R160321"
            ]
        },
        {
            "instance_id": "R161728xR160377",
            "comparison_id": "R161728",
            "paper_id": "R160377",
            "text": "Time series behavior modeling with digital twin for Internet of Vehicles abstract electric vehicle (ev) is considered eco-friendly with low carbon emission and maintenance costs. given the current battery and charging technology, driving experience of evs relies heavily on the availability and reachability of ev charging infrastructure. as the number of charging piles increases, carefully designed arrangement of resources and efficient utilization of the infrastructure is essential to the future development of ev industry. the mobility and distribution of evs determine the charging demand and the load of power distribution grid. then, dynamic traffic pattern of numerous interconnected evs poses great impact on charging plans and charging infrastructure. in this paper, we introduce the digital twin of a real-world ev by modeling the mobility based on a time series behaviors of evs to evaluate the charging algorithm and pile arrangement policy. the introduced digital twin ev is a virtually simulated equivalence with same traffic behaviors and charging activities as the ev in real world. the behavior and route choice of evs is dynamically simulated base on the time-varying driving operations, travel intent, and charging plan in a simulated large-scale charging scenario composed of concurrently moving evs and correspondingly equipped charging piles. different ev navigation algorithms and charging algorithms of internet of vehicle can be exactly evaluated in the dynamic simulation of the digital twins of the moving evs and charging infrastructure. then we analyze the collected data such as energy consumption, charging capacity, charging frequency, and waiting time in queue on both the ev side and the charging pile side to evaluate the charging efficiency. the simulation is used to study the relations between the scheduled charging operation of evs and the deployment of piles. the proposed model helps evaluate and validate the design of the charging recommendation and the deployment plan regarding to the arrangement and distribution of charging piles.",
            "contribution_ids": [
                "R160380"
            ]
        },
        {
            "instance_id": "R161728xR160311",
            "comparison_id": "R161728",
            "paper_id": "R160311",
            "text": "Digital Twin and CyberGIS for Improving Connectivity and Measuring the Impact of Infrastructure Construction Planning in Smart Cities smart technologies are advancing, and smart cities can be made smarter by increasing the connectivity and interactions of humans, the environment, and smart devices. this paper discusses selective technologies that can potentially contribute to developing an intelligent environment and smarter cities. while the connectivity and efficiency of smart cities is important, the analysis of the impact of construction development and large projects in the city is crucial to decision and policy makers, before the project is approved. this raises the question of assessing the impact of a new infrastructure project on the community prior to its commencement\u2014what type of technologies can potentially be used for creating a virtual representation of the city? how can a smart city be improved by utilizing these technologies? there are a wide range of technologies and applications available but understanding their function, interoperability, and compatibility with the community requires more discussion around system designs and architecture. these questions can be the basis of developing an agenda for further investigations. in particular, the need for advanced tools such as mobile scanners, geospatial artificial intelligence, unmanned aerial vehicles, geospatial augmented reality apps, light detection, and ranging in smart cities is discussed. in line with smart city technology development, this special issue includes eight accepted articles covering trending topics, which are briefly reviewed.",
            "contribution_ids": [
                "R160315"
            ]
        },
        {
            "instance_id": "R161728xR160337",
            "comparison_id": "R161728",
            "paper_id": "R160337",
            "text": "Digital Twin in Circular Economy: Remanufacturing in Construction abstract \\n global warming attracts increasing public attention. however, in the past few decades, the contribution of construction to greenhouse gas emissions is around 40% of total emissions. the promotion of construction waste remanufacturing faces challenges. the application of digital twins in the remanufacturing of construction waste contributes to the tracking, recycling and management of construction waste. this article reviews the current research on construction waste remanufacturing and the application of digital twin in construction and remanufacturing, aiming at finding the current challenge of construction waste remanufacturing and the opportunity of digital twin to solve it. then, the digital twin platform concept for construction waste remanufacturing is provided as a solution for the current challenges. theoretically, this paper points out the shortcomings of the current research in construction waste remanufacturing based on literature review. meanwhile, this article proposes the application of digital twin in construction waste remanufacturing, which expands the research scope of circular economy in construction. in fact, this research has driven the digital twin application in more industries. besides, this research proposes a concept of potential solutions for the current challenges of construction waste in circular economy.",
            "contribution_ids": [
                "R160339"
            ]
        },
        {
            "instance_id": "R161728xR159450",
            "comparison_id": "R161728",
            "paper_id": "R159450",
            "text": "Urban Digital Twins for Smart Cities and Citizens: The Case Study of Herrenberg, Germany cities are complex systems connected to economic, ecological, and demographic conditions and change. they are also characterized by diverging perceptions and interests of citizens and stakeholders. thus, in the arena of urban planning, we are in need of approaches that are able to cope not only with urban complexity but also allow for participatory and collaborative processes to empower citizens. this to create democratic cities. connected to the field of smart cities and citizens, we present in this paper, the prototype of an urban digital twin for the 30,000-people town of herrenberg in germany. urban digital twins are sophisticated data models allowing for collaborative processes. the herein presented prototype comprises (1) a 3d model of the built environment, (2) a street network model using the theory and method of space syntax, (3) an urban mobility simulation, (4) a wind flow simulation, and (5) a number of empirical quantitative and qualitative data using volunteered geographic information (vgi). in addition, the urban digital twin was implemented in a visualization platform for virtual reality and was presented to the general public during diverse public participatory processes, as well as in the framework of the \u201cmorgenstadt werkstatt\u201d (tomorrow\u2019s cities workshop). the results of a survey indicated that this method and technology could significantly aid in participatory and collaborative processes. further understanding of how urban digital twins support urban planners, urban designers, and the general public as a collaboration and communication tool and for decision support allows us to be more intentional when creating smart cities and sustainable cities with the help of digital twins. we conclude the paper with a discussion of the presented results and further research directions.",
            "contribution_ids": [
                "R159455",
                "R160405"
            ]
        },
        {
            "instance_id": "R161728xR160408",
            "comparison_id": "R161728",
            "paper_id": "R160408",
            "text": "Using Smart City Technology to Make Healthcare Smarter smart cities use information and communication technologies (icts) to scale services include utilities and transportation to a growing population. in this paper, we discuss how smart city icts can also improve healthcare effectiveness and lower healthcare cost for smart city residents. we survey current literature and introduce original research to offer an overview of how smart city infrastructure supports strategic healthcare using both mobile and ambient sensors combined with machine learning. finally, we consider challenges that will be faced as healthcare providers make use of these opportunities.",
            "contribution_ids": [
                "R160413"
            ]
        },
        {
            "instance_id": "R161728xR160298",
            "comparison_id": "R161728",
            "paper_id": "R160298",
            "text": "A Digital Twin of Bridges for Structural Health Monitoring \"\u00a9 international workshop on structural health monitoring. all rights reserved. bridges are critical infrastructure systems connecting different regions and providing widespread social and economic benefits. it is therefore essential that they are designed, constructed and maintained properly to adapt to changing conditions of use and climate-driven events. with the rapid development in capability of collecting bridge monitoring data, a data challenge emerges due to insufficient capability in managing, processing and interpreting large monitoring datasets to extract useful information which is of practical value to the industry. one emerging area of research which focuses on addressing this challenge is the creation of 'digital twins' for bridges. a digital twin serves as a virtual representation of the physical infrastructure (i.e. the physical twin), which can be updated in near real time as new data is collected, provide feedback into the physical twin and perform 'what-if scenarios for assessing asset risks and predicting asset performance. this paper presents and broadly discusses two years of exploratory study towards creating a digital twin of bridges for structural health monitoring purposes. in particular, it has involved an interdisciplinary collaboration between civil engineers at the cambridge centre for smart infrastructure and construction (csic) and statisticians at the alan turing institute (ati), using two monitored railway bridges in staffordshire, uk as a case study. four areas of research were investigated: (i) real-time data management using bim, (ii) physics-based approaches, (iii) data-driven approaches, and (iv) data-centric engineering approaches (i.e. synthesis of physics-based and data-driven approaches). a framework for creating a digital twin of bridges, particularly for structural health monitoring purposes, is proposed and briefly discussed.\"",
            "contribution_ids": [
                "R160300"
            ]
        },
        {
            "instance_id": "R161729xR159465",
            "comparison_id": "R161729",
            "paper_id": "R159465",
            "text": "A Socio-Technical Perspective on Urban Analytics: The Case of City-Scale Digital Twins abstract this paper demonstrates that a shift from a purely technical to a more socio-technical perspective has significant implications for the conceptualization, design, and implementation of smart city technologies. such implications are discussed and illustrated through the case of an emerging urban analytics tool, the city-scale digital twin. based on interdisciplinary insights and a participatory knowledge co-production and tool co-development process, including both researchers and prospective users, we conclude that in order to move beyond a mere \u201chype technology,\u201d city-scale digital twins must reflect the specifics of the urban and socio-political context.",
            "contribution_ids": [
                "R159469",
                "R160399"
            ]
        },
        {
            "instance_id": "R161729xR160211",
            "comparison_id": "R161729",
            "paper_id": "R160211",
            "text": "Architecting Smart City Digital Twins: Combined Semantic Model and Machine Learning Approach abstractthis work was motivated by the premise that next-generation smart city systems will be enabled by widespread adoption of sensing and communication technologies deeply embedded within the ph...",
            "contribution_ids": [
                "R160215",
                "R160261"
            ]
        },
        {
            "instance_id": "R161729xR159484",
            "comparison_id": "R161729",
            "paper_id": "R159484",
            "text": "Smart city dvelopment with digital twin technology growing urban areas are major consumers of natural resources, energy and raw materials. understanding cities\u00b4 urban metabolism is salient when developing sustainable and resilient cities. this paper addresses concepts of smart city and digital twin technology as means to foster more sustainable urban development. smart city has globally been well adopted concept in urban development. with smart city development cities aim to optimize overall performance of the city, its infrastructures, processes and services, but also to improve socio-economic wellbeing. dynamic digital twins are constituted to form real-time connectivity between virtual and physical objects. digital twin combines virtual objects to its physical counterparts. this conceptual paper provides additionally examples from dynamic digital twin platforms and digital twin of helsinki, finland.",
            "contribution_ids": [
                "R159486"
            ]
        },
        {
            "instance_id": "R161729xR160231",
            "comparison_id": "R161729",
            "paper_id": "R160231",
            "text": "Using big data analytics and IoT principles to keep an eye on underground infrastructure a concept development study by the open geospatial consortium (ogc) has highlighted the importance of high-quality feature data for underground urban infrastructure (ugi). analysis of large survey datasets, including both visual and non-visual methods, is essential for creating and maintaining ugi geodata. connecting hidden features with diverse, high-velocity sensing streams and realistic predictive models that effectively characterize them is key to lower construction costs, efficient infrastructure operation, sound disaster preparedness, and new smart city services. iot principles that combine ogc geodata and sensor web observation standards may offer the best chance for working towards functional \u201cdigital twins\u201d of such hidden infrastructure that are both cost effective and scalable with the increasing complexity and instrumentation of the underground built environment. technical and policy challenges remain, however, before this can be achieved.",
            "contribution_ids": [
                "R160233"
            ]
        },
        {
            "instance_id": "R161729xR160247",
            "comparison_id": "R161729",
            "paper_id": "R160247",
            "text": "Smart city digital twins \"driven by the challenges of rapid urbanization, cities are determined to implement advanced socio-technological changes and transform into smarter cities. the success of such transformation, however, greatly relies on a thorough understanding of the city's states of spatiotemporal flux. the ability to understand such fluctuations in context and in terms of interdependencies that exist among various entities across time and space is crucial, if cities are to maintain their smart growth. here, we introduce a smart city digital twin paradigm that can enable increased visibility into cities' human-infrastructure-technology interactions, in which spatiotemporal fluctuations of the city are integrated into an analytics platform at the real-time intersection of reality-virtuality. through learning and exchange of spatiotemporal information with the city, enabled through virtualization and the connectivity offered by internet of things (iot), this digital twin of the city becomes smarter over time, able to provide predictive insights into the city's smarter performance and growth.\"",
            "contribution_ids": [
                "R160249"
            ]
        },
        {
            "instance_id": "R161729xR160244",
            "comparison_id": "R161729",
            "paper_id": "R160244",
            "text": "Hybrid Automaton Implementation For Intelligent Agents\u00e2\u0080\u0099 Behavior Modelling it is predicted that the future of our world might be considered as an urban future, and this future should be happy, or, at least, livable. to describe ways and conditions for creating this future, the \u201csmart city\u201d concept has been worked out. \u201csmart city\u201d in this concept is under consideration as a cyber-physical system. digital twins have become the main elements of these systems, while computer simulation is to be the main technology for these systems investigation. in this paper, the process of a hybrid (continuous-discrete) automaton implementation for the aim of intelligent agents\u2019 behavior modelling is under discussion.",
            "contribution_ids": [
                "R160246"
            ]
        },
        {
            "instance_id": "R161729xR159459",
            "comparison_id": "R161729",
            "paper_id": "R159459",
            "text": "RESEARCH ON CONSTRUCTION OF SPATIO-TEMPORAL DATA VISUALIZATION PLATFORM FOR GIS AND BIM FUSION abstract. the visualization model of gis and bim fusion can provide data bearing platform and main technical support for future urban operation centers, digital twin cities, and smart cities. based on the analysis of the features and advantages of gis and bim fusion, this paper proposes a construction method of the spatio-temporal data visualization platform for gis and bim fusion. it expounds and analyzes the overall architecture design of platform, multi-dimensional and multi-spatial scales visualization, space analysis for gis and bim fusion, and platform applications and so on. the urban virtual simulation spatio-temporal data platform project of teda new district in tianjin has verified and demonstrated that the effect of application is good. this provides a feasible solution for the construction of spatio-temporal data visualization platform.\\n",
            "contribution_ids": [
                "R159461"
            ]
        },
        {
            "instance_id": "R161729xR159487",
            "comparison_id": "R161729",
            "paper_id": "R159487",
            "text": "Urban Intelligence: a Modular, Fully Integrated, and Evolving Model for Cities Digital Twinning the urban intelligence (ui) paradigm proposes an ecosystem of technologies to improve urban environment, wellbeing, quality of life and smart city systems. it fosters the definition of a digital twin of the city, namely a cyber-physical counterpart of all the city systems and sub-systems. here we propose a novel approach to ui that extends available frameworks combining advanced multidisciplinary modelling of the city, simulation and learning tools with numerical optimization techniques, each of them specialized for the digital representation of city systems and subsystems, including not only city infrastructures, but also city users and their interactions. ui provides sets of candidate policies in complex scenarios and supports policy makers and stakeholders in designing sustainable and personalized solutions. the main characteristics of the proposed ui architecture are (a) fully multidisciplinary integration of city layers, (b) connection and evolution with the city, (c) integration of participative strategies to include \u201chuman-oriented\u201d information, and (d) modularity of application.",
            "contribution_ids": [
                "R159489"
            ]
        },
        {
            "instance_id": "R161729xR160241",
            "comparison_id": "R161729",
            "paper_id": "R160241",
            "text": "AUTOMATIC 3D BUILDINGS COMPACT RECONSTRUCTION FROM LIDAR POINT CLOUDS abstract. point clouds generated from aerial lidar and photogrammetric techniques are great ways to obtain valuable spatial insights over large scale. however, their nature hinders the direct extraction and sharing of underlying information. the generation of consistent large-scale 3d city models from this real-world data is a major challenge. specifically, the integration in workflows usable by decision-making scenarios demands that the data is structured, rich and exchangeable. citygml permits new advances in terms of interoperable endeavour to use city models in a collaborative way. efforts have led to render good-looking digital twins of cities but few of them take into account their potential use in finite elements simulations (wind, floods, heat radiation model, etc.). in this paper, we target the automatic reconstruction of consistent 3d city buildings highlighting closed solids, coherent surface junctions, perfect snapping of vertices, etc. it specifically investigates the topological and geometrical consistency of generated models from aerial lidar point cloud, formatted following the cityjson specifications. these models are then usable to store relevant information and provides geometries usable within complex computations such as computational fluid dynamics, free of local inconsistencies (e.g. holes and unclosed solids).\\n",
            "contribution_ids": [
                "R160243"
            ]
        },
        {
            "instance_id": "R161729xR160253",
            "comparison_id": "R161729",
            "paper_id": "R160253",
            "text": "The Potential of Digital Twin Model Integrated With Artificial Intelligence Systems the paper explores the use of a \u201cdigital twin model\u201d applied to the case study of a residential district, and organized as a three-dimensional data system able to participate to the intelligent optimization and automation of the energy management and efficiency of the building system. the case study focuses on the area called rinascimento iii in rome, consisting of 16 eight-floor building hosting 216 apartment units with an overall percentage of self-renewable energy produced by the building complex equal to 70%. this already quite high percentage means that the building complex can be defined as a near zero energy building (nzeb), i.e. a building that has a very high energy performance, and the nearly-zero or very low amount of energy required should be covered to a very significant extent by energy from renewable sources, including energy from renewable source produced on-site or nearby.",
            "contribution_ids": [
                "R160255"
            ]
        },
        {
            "instance_id": "R161729xR159450",
            "comparison_id": "R161729",
            "paper_id": "R159450",
            "text": "Urban Digital Twins for Smart Cities and Citizens: The Case Study of Herrenberg, Germany cities are complex systems connected to economic, ecological, and demographic conditions and change. they are also characterized by diverging perceptions and interests of citizens and stakeholders. thus, in the arena of urban planning, we are in need of approaches that are able to cope not only with urban complexity but also allow for participatory and collaborative processes to empower citizens. this to create democratic cities. connected to the field of smart cities and citizens, we present in this paper, the prototype of an urban digital twin for the 30,000-people town of herrenberg in germany. urban digital twins are sophisticated data models allowing for collaborative processes. the herein presented prototype comprises (1) a 3d model of the built environment, (2) a street network model using the theory and method of space syntax, (3) an urban mobility simulation, (4) a wind flow simulation, and (5) a number of empirical quantitative and qualitative data using volunteered geographic information (vgi). in addition, the urban digital twin was implemented in a visualization platform for virtual reality and was presented to the general public during diverse public participatory processes, as well as in the framework of the \u201cmorgenstadt werkstatt\u201d (tomorrow\u2019s cities workshop). the results of a survey indicated that this method and technology could significantly aid in participatory and collaborative processes. further understanding of how urban digital twins support urban planners, urban designers, and the general public as a collaboration and communication tool and for decision support allows us to be more intentional when creating smart cities and sustainable cities with the help of digital twins. we conclude the paper with a discussion of the presented results and further research directions.",
            "contribution_ids": [
                "R159455",
                "R160405"
            ]
        },
        {
            "instance_id": "R162329xR162132",
            "comparison_id": "R162329",
            "paper_id": "R162132",
            "text": "Coherent imaging of biological samples with femtosecond pulses at the free-electron laser FLASH coherent x-ray imaging represents a new window to imaging non-crystalline, biological specimens at unprecedented resolutions. the advent of free-electron lasers (fel) allows extremely high flux densities to be delivered to a specimen resulting in stronger scattered signal from these samples to be measured. in the best case scenario, the diffraction pattern is measured before the sample is destroyed by these intense pulses, as the processes involved in radiation damage may be substantially slower than the pulse duration. in this case, the scattered signal can be interpreted and reconstructed to yield a faithful image of the sample at a resolution beyond the conventional radiation damage limit. we employ coherent x-ray diffraction imaging (cxdi) using the free-electron laser in hamburg (flash) in a non-destructive regime to compare images of a biological sample reconstructed using different, single, femtosecond pulses of fel radiation. furthermore, for the first time, we demonstrate cxdi, in-line holography and fourier transform holography (fth) of the same unicellular marine organism using an fel and present diffraction data collected using the third harmonic of flash, reaching into the water window. we provide quantitative results for the resolution of the cxdi images as a function of pulse intensity, and compare this with the resolutions achieved with in-line holography and fth.",
            "contribution_ids": [
                "R162134"
            ]
        },
        {
            "instance_id": "R162329xR161940",
            "comparison_id": "R162329",
            "paper_id": "R161940",
            "text": "Picosecond Snapshot of the Speckles from FerroelectricBaTiO3by Means of X-Ray Lasers a picosecond x-ray laser speckle has been conducted to study the dynamics of a disordered surface domain structure (batio3 with 90 degrees c/a domains) as a function of temperature for the first time. the transient surface structures induced by ferroelectric domains decrease as temperature increases towards the curie temperature t(c) and completely disappear above t(c). the dramatic change of the spatial configuration of the c/a domains was observed to occur from a temperature 2 degrees c below t(c), near which the average correlated domain size at equilibrium decreases as (t(c)-t)(0.37+/-0.02).",
            "contribution_ids": [
                "R161941"
            ]
        },
        {
            "instance_id": "R162329xR162160",
            "comparison_id": "R162329",
            "paper_id": "R162160",
            "text": "Temporal coherence and spectral linewidth of an injection-seeded transient collisional soft x-ray laser the temporal coherence of an injection-seeded transient 18.9 nm molybdenum soft x-ray laser was measured using a wavefront division interferometer and compared to model simulations. the seeded laser is found to have a coherence time similar to that of the unseeded amplifier, ~1 ps, but a significantly larger degree of temporal coherence. the measured coherence time for the unseeded amplifier is only a small fraction of the pulsewidth, while in the case of the seeded laser it approaches full temporal coherence. the measurements confirm that the bandwidth of the solid target amplifiers is significantly wider than that of soft x-ray lasers that use gaseous targets, an advantage for the development of sub-picosecond soft x-ray lasers.",
            "contribution_ids": [
                "R162162"
            ]
        },
        {
            "instance_id": "R162329xR161856",
            "comparison_id": "R162329",
            "paper_id": "R161856",
            "text": "Science with Soft X Rays synchrotron radiation with photon energies at or below 1 kev is giving new insights into such areas as wet cell biology, condensed matter physics and extreme ultraviolet optics technology.",
            "contribution_ids": [
                "R161858"
            ]
        },
        {
            "instance_id": "R162329xR161811",
            "comparison_id": "R162329",
            "paper_id": "R161811",
            "text": "Beam optics of exploding foil plasma x\u00e2\u0080\u0090ray lasers in soft x\u2010ray lasers, amplification is achieved as the x rays propagate down a long narrow plasma column. refraction, due to electron density gradients, tends to direct the x\u2010rays out of high density regions. this can have the undesirable effect of shortening the distance that the x ray stay within the plasma, thereby limiting the amount of amplification. the exploding foil design lessens refraction, but does not eliminate it. in this paper, a quantitative analysis of propagation and amplification in an exploding foil x\u2010ray laser is presented. the density and gain profiles within the plasma are modeled in an approximate manner, which enables considerable analytic progress. it is found that refraction introduces a loss term to the laser amplification. the beam pattern from a parabolic gain profile laser has a dominant peak on the x\u2010ray laser axis. the pattern from a quartic gain profile having a dip on\u2010axis can produce a profile with off\u2010axis peaks, in better agreement with recent experimental data.",
            "contribution_ids": [
                "R161813"
            ]
        },
        {
            "instance_id": "R162329xR162188",
            "comparison_id": "R162329",
            "paper_id": "R162188",
            "text": "Sequential single-shot imaging of nanoscale dynamic interactions with a table-top soft x-ray laser we demonstrate the first real-space recording of nanoscale dynamic interactions using single-shot soft x-ray (sxr) full-field laser microscopy. a sequence of real-space flash images acquired with a table-top sxr laser was used to capture the motion of a rapidly oscillating magnetic nanoprobe. changes of 30 nm in the oscillation amplitude were detected when the nanoprobe was made to interact with stray fields from a magnetic sample. the table-top visualization of nanoscale dynamics in real space can significantly contribute to the understanding of nanoscale processes and can accelerate the development of new nanodevices.",
            "contribution_ids": [
                "R162190"
            ]
        },
        {
            "instance_id": "R162329xR161886",
            "comparison_id": "R162329",
            "paper_id": "R161886",
            "text": "Picosecond X-Ray Laser Interferometry of Dense Plasmas we present the first results from picosecond interferometry of dense laser-produced plasmas using a soft x-ray laser. the picosecond duration and short wavelength of the 14.7 nm ni-like pd laser mitigates effects associated with motion blurring and refraction through millimeter-scale plasmas. this enables direct measurement of the electron-density profile to within 10 microm of the target surface. a series of high-quality two-dimensional (2d) density measurements provide unambiguous characterization of the time evolution in a fast-evolving plasma suitable for validation of existing 1d and 2d hydrodynamic codes.",
            "contribution_ids": [
                "R161887"
            ]
        },
        {
            "instance_id": "R162329xR162216",
            "comparison_id": "R162329",
            "paper_id": "R162216",
            "text": "Defect-tolerant extreme ultraviolet nanoscale printing we present a defect-free lithography method for printing periodic features with nanoscale resolution using coherent extreme ultraviolet light. this technique is based on the self-imaging effect known as the talbot effect, which is produced when coherent light is diffracted by a periodic mask. we present a numerical simulation and an experimental verification of the method with a compact extreme ultraviolet laser. furthermore, we explore the extent of defect tolerance by testing masks with different defect layouts. the experimental results are in good agreement with theoretical calculations.",
            "contribution_ids": [
                "R162217"
            ]
        },
        {
            "instance_id": "R162329xR162049",
            "comparison_id": "R162329",
            "paper_id": "R162049",
            "text": "High-Brightness Injection-Seeded Soft-X-Ray-Laser Amplifier Using a Solid Target we demonstrate the generation of an intense soft-x-ray-laser beam by saturated amplification of high harmonic seed pulses in a dense transient collisional soft-x-ray-laser plasma amplifier created by heating a titanium target. amplification in the 32.6 nm line of ne-like ti generates laser pulses of subpicosecond duration that are measured to approach full spatial coherence. the peak spectral brightness is estimated to be approximately 2 x 10(26) photons/(s mm(2) mrad(2) 0.01% bandwidth). the scheme is scalable to produce extremely bright lasers at very short wavelengths with full temporal and spatial coherence.",
            "contribution_ids": [
                "R162050"
            ]
        },
        {
            "instance_id": "R162574xR162540",
            "comparison_id": "R162574",
            "paper_id": "R162540",
            "text": "The extraction of complex relationships and their conversion to biological expression language (BEL) overview of the BioCreative VI (2017) BEL track abstract \\n knowledge of the molecular interactions of biological and chemical entities and their involvement in biological processes or clinical phenotypes is important for data interpretation. unfortunately, this knowledge is mostly embedded in the literature in such a way that it is unavailable for automated data analysis procedures. biological expression language (bel) is a syntax representation allowing for the structured representation of a broad range of biological relationships. it is used in various situations to extract such knowledge and transform it into bel networks. to support the tedious and time-intensive extraction work of curators with automated methods, we developed the bel track within the framework of biocreative challenges. within the bel track, we provide training data and an evaluation environment to encourage the text mining community to tackle the automatic extraction of complex bel relationships. in 2017 biocreative vi, the 2015 bel track was repeated with new test data. although only minor improvements in text snippet retrieval for given statements were achieved during this second bel task iteration, a significant increase of bel statement extraction performance from provided sentences could be seen. the best performing system reached a 32% f-score for the extraction of complete bel statements and with the given named entities this increased to 49%. this time, besides rule-based systems, new methods involving hierarchical sequence labeling and neural networks were applied for bel statement extraction.",
            "contribution_ids": [
                "R162542"
            ]
        },
        {
            "instance_id": "R162574xR162546",
            "comparison_id": "R162574",
            "paper_id": "R162546",
            "text": "Overview of the BioCreative VI Precision Medicine Track: mining protein interactions and mutations for precision medicine abstract the precision medicine initiative is a multicenter effort aiming at formulating personalized treatments leveraging on individual patient data (clinical, genome sequence and functional genomic data) together with the information in large knowledge bases (kbs) that integrate genome annotation, disease association studies, electronic health records and other data types. the biomedical literature provides a rich foundation for populating these kbs, reporting genetic and molecular interactions that provide the scaffold for the cellular regulatory systems and detailing the influence of genetic variants in these interactions. the goal of biocreative vi precision medicine track was to extract this particular type of information and was organized in two tasks: (i) document triage task, focused on identifying scientific literature containing experimentally verified protein\u2013protein interactions (ppis) affected by genetic mutations and (ii) relation extraction task, focused on extracting the affected interactions (protein pairs). to assist system developers and task participants, a large-scale corpus of pubmed documents was manually annotated for this task. ten teams worldwide contributed 22 distinct text-mining models for the document triage task, and six teams worldwide contributed 14 different text-mining systems for the relation extraction task. when comparing the text-mining system predictions with human annotations, for the triage task, the best f-score was 69.06%, the best precision was 62.89%, the best recall was 98.0% and the best average precision was 72.5%. for the relation extraction task, when taking homologous genes into account, the best f-score was 37.73%, the best precision was 46.5% and the best recall was 54.1%. submitted systems explored a wide range of methods, from traditional rule-based, statistical and machine learning systems to state-of-the-art deep learning methods. given the level of participation and the individual team results we find the precision medicine track to be successful in engaging the text-mining research community. in the meantime, the track produced a manually annotated corpus of 5509 pubmed documents developed by biogrid curators and relevant for precision medicine. the data set is freely available to the community, and the specific interactions have been integrated into the biogrid data set. in addition, this challenge provided the first results of automatically identifying pubmed articles that describe ppi affected by mutations, as well as extracting the affected relations from those articles. still, much progress is needed for computer-assisted precision medicine text mining to become mainstream. future work should focus on addressing the remaining technical challenges and incorporating the practical benefits of text-mining tools into real-world precision medicine information-related curation.",
            "contribution_ids": [
                "R162553",
                "R172061",
                "R172064"
            ]
        },
        {
            "instance_id": "R162574xR162352",
            "comparison_id": "R162574",
            "paper_id": "R162352",
            "text": "Evaluation of BioCreAtIvE assessment of task 2 abstract \\n \\n background \\n molecular biology accumulated substantial amounts of data concerning functions of genes and proteins. information relating to functional descriptions is generally extracted manually from textual data and stored in biological databases to build up annotations for large collections of gene products. those annotation databases are crucial for the interpretation of large scale analysis approaches using bioinformatics or experimental techniques. due to the growing accumulation of functional descriptions in biomedical literature the need for text mining tools to facilitate the extraction of such annotations is urgent. in order to make text mining tools useable in real world scenarios, for instance to assist database curators during annotation of protein function, comparisons and evaluations of different approaches on full text articles are needed. \\n \\n \\n results \\n the critical assessment for information extraction in biology (biocreative) contest consists of a community wide competition aiming to evaluate different strategies for text mining tools, as applied to biomedical literature. we report on task two which addressed the automatic extraction and assignment of gene ontology (go) annotations of human proteins, using full text articles. the predictions of task 2 are based on triplets of protein \u2013 go term \u2013 article passage . the annotation-relevant text passages were returned by the participants and evaluated by expert curators of the go annotation (goa) team at the european institute of bioinformatics (ebi). each participant could submit up to three results for each sub-task comprising task 2. in total more than 15,000 individual results were provided by the participants. the curators evaluated in addition to the annotation itself, whether the protein and the go term were correctly predicted and traceable through the submitted text fragment. \\n \\n \\n conclusion \\n concepts provided by go are currently the most extended set of terms used for annotating gene products, thus they were explored to assess how effectively text mining tools are able to extract those annotations automatically. although the obtained results are promising, they are still far from reaching the required performance demanded by real world applications. among the principal difficulties encountered to address the proposed task, were the complex nature of the go terms and protein names (the large range of variants which are used to express proteins and especially go terms in free text), and the lack of a standard training set. a range of very different strategies were used to tackle this task. the dataset generated in line with the biocreative challenge is publicly available and will allow new possibilities for training information extraction methods in the domain of molecular biology. \\n",
            "contribution_ids": [
                "R162353",
                "R166359",
                "R166394"
            ]
        },
        {
            "instance_id": "R162574xR162568",
            "comparison_id": "R162574",
            "paper_id": "R162568",
            "text": "Overview of the BioCreative VII LitCovid Track: multi-label topic classification for COVID-19 literature annotation the biocreative litcovid track calls for a community effort to tackle automated topic annotation for covid-19 literature. the number of covid-19-related articles in the literature is growing by about 10,000 articles per month, significantly challenging curation efforts and downstream interpretation. litcovid is a literature database of covid-19related articles in pubmed, which has accumulated more than 180,000 articles with millions of accesses each month by users worldwide. the rapid literature growth significantly increases the burden of litcovid curation, especially for topic annotations. topic annotation in litcovid assigns one or more (up to eight) labels to articles. the annotated topics have been widely used both directly in litcovid (e.g., accounting for ~20% of total uses) and downstream studies such as knowledge network generation and citation analysis. it is, therefore, important to develop innovative text mining methods to tackle the challenge. we organized the biocreative litcovid track to call for a community effort to tackle automated topic annotation for covid-19 literature. this article summarizes the biocreative litcovid track in terms of data collection and team participation. the dataset is publicly available via https://ftp.ncbi.nlm.nih.gov/pub/lu/litcovid/biocreative/. it consists of over 30k pubmed articles, one of the largest multilabel classification datasets on biomedical literature. there were 80 submissions in total from 19 teams worldwide. the highestperforming submissions achieved 0.8875, 0.9181, and 0.9394 for macro f1-score, micro f1-score, and instance-based f1-score, respectively. we look forward to further participation in developing biomedical text mining methods in response to the rapid growth of the covid-19 literature. keywords\u2014biomedical text mining; natural language processing; artificial intelligence; machine learning; deep learning; multi-label classification; covid-19; litcovid;",
            "contribution_ids": [
                "R162570"
            ]
        },
        {
            "instance_id": "R162574xR162482",
            "comparison_id": "R162574",
            "paper_id": "R162482",
            "text": "BioCreative V track 4: a shared task for the extraction of causal network information using the Biological Expression Language automatic extraction of biological network information is one of the most desired and most complex tasks in biological and medical text mining. track 4 at biocreative v attempts to approach this complexity using fragments of large-scale manually curated biological networks, represented in biological expression language (bel), as training and test data. bel is an advanced knowledge representation format which has been designed to be both human readable and machine processable. the specific goal of track 4 was to evaluate text mining systems capable of automatically constructing bel statements from given evidence text, and of retrieving evidence text for given bel statements. given the complexity of the task, we designed an evaluation methodology which gives credit to partially correct statements. we identified various levels of information expressed by bel statements, such as entities, functions, relations, and introduced an evaluation framework which rewards systems capable of delivering useful bel fragments at each of these levels. the aim of this evaluation method is to help identify the characteristics of the systems which, if combined, would be most useful for achieving the overall goal of automatically constructing causal biological networks from text.",
            "contribution_ids": [
                "R162484",
                "R172014",
                "R172015"
            ]
        },
        {
            "instance_id": "R162574xR162426",
            "comparison_id": "R162574",
            "paper_id": "R162426",
            "text": "BioCreative V BioC track overview: collaborative biocurator assistant task for BioGRID bioc is a simple xml format for text, annotations and relations, and was developed to achieve interoperability for biomedical text processing. following the success of bioc in biocreative iv, the biocreative v bioc track addressed a collaborative task to build an assistant system for biogrid curation. in this paper, we describe the framework of the collaborative bioc task and discuss our findings based on the user survey. this track consisted of eight subtasks including gene/protein/organism named entity recognition, protein\u2013protein/genetic interaction passage identification and annotation visualization. using bioc as their data-sharing and communication medium, nine teams, world-wide, participated and contributed either new methods or improvements of existing tools to address different subtasks of the bioc track. results from different teams were shared in bioc and made available to other teams as they addressed different subtasks of the track. in the end, all submitted runs were merged using a machine learning classifier to produce an optimized output. the biocurator assistant system was evaluated by four biogrid curators in terms of practical usability. the curators\u2019 feedback was overall positive and highlighted the user-friendly design and the convenient gene/protein curation tool based on text mining. database url: http://www.biocreative.org/tasks/biocreative-v/track-1-bioc/",
            "contribution_ids": [
                "R162428"
            ]
        },
        {
            "instance_id": "R162574xR162349",
            "comparison_id": "R162574",
            "paper_id": "R162349",
            "text": "BioCreAtIvE Task 1A: gene mention finding evaluation abstract \\n \\n background \\n the biological research literature is a major repository of knowledge. as the amount of literature increases, it will get harder to find the information of interest on a particular topic. there has been an increasing amount of work on text mining this literature, but comparing this work is hard because of a lack of standards for making comparisons. to address this, we worked with colleagues at the protein design group, cnb-csic, madrid to develop biocreative (critical assessment for information extraction in biology), an open common evaluation of systems on a number of biological text mining tasks. we report here on task 1a, which deals with finding mentions of genes and related entities in text. \"finding mentions\" is a basic task, which can be used as a building block for other text mining tasks. the task makes use of data and evaluation software provided by the (us) national center for biotechnology information (ncbi). \\n \\n \\n results \\n 15 teams took part in task 1a. a number of teams achieved scores over 80% f-measure (balanced precision and recall). the teams that tried to use their task 1a systems to help on other biocreative tasks reported mixed results. \\n \\n \\n conclusion \\n the 80% plus f-measure results are good, but still somewhat lag the best scores achieved in some other domains such as newswire, due in part to the complexity and length of gene names, compared to person or organization names in newswire. \\n",
            "contribution_ids": [
                "R162350",
                "R166331"
            ]
        },
        {
            "instance_id": "R162574xR162526",
            "comparison_id": "R162574",
            "paper_id": "R162526",
            "text": "Overview of the BioCreative VI text-mining services for Kinome Curation Track abstract the text-mining services for kinome curation track, part of biocreative vi, proposed a competition to assess the effectiveness of text mining to perform literature triage. the track has exploited an unpublished curated data set from the nextprot database. this data set contained comprehensive annotations for 300 human protein kinases. for a given protein and a given curation axis [diseases or gene ontology (go) biological processes], participants\u2019 systems had to identify and rank relevant articles in a collection of 5.2 m medline citations (task 1) or 530 000 full-text articles (task 2). explored strategies comprised named-entity recognition and machine-learning frameworks. for that latter approach, participants developed methods to derive a set of negative instances, as the databases typically do not store articles that were judged as irrelevant by curators. the supervised approaches proposed by the participating groups achieved significant improvements compared to the baseline established in a previous study and compared to a basic pubmed search.",
            "contribution_ids": [
                "R162528",
                "R172056",
                "R172038",
                "R172039"
            ]
        },
        {
            "instance_id": "R162575xR162400",
            "comparison_id": "R162575",
            "paper_id": "R162400",
            "text": "Overview of the gene ontology task at BioCreative IV gene ontology (go) annotation is a common task among model organism databases (mods) for capturing gene function data from journal articles. it is a time-consuming and labor-intensive task, and is thus often considered as one of the bottlenecks in literature curation. there is a growing need for semiautomated or fully automated go curation techniques that will help database curators to rapidly and accurately identify gene function information in full-length articles. despite multiple attempts in the past, few studies have proven to be useful with regard to assisting real-world go curation. the shortage of sentence-level training data and opportunities for interaction between text-mining developers and go curators has limited the advances in algorithm development and corresponding use in practical circumstances. to this end, we organized a text-mining challenge task for literature-based go annotation in biocreative iv. more specifically, we developed two subtasks: (i) to automatically locate text passages that contain go-relevant information (a text retrieval task) and (ii) to automatically identify relevant go terms for the genes in a given article (a concept-recognition task). with the support from five mods, we provided teams with >4000 unique text passages that served as the basis for each go annotation in our task data. such evidence text information has long been recognized as critical for text-mining algorithm development but was never made available because of the high cost of curation. in total, seven teams participated in the challenge task. from the team results, we conclude that the state of the art in automatically mining go terms from literature has improved over the past decade while much progress is still needed for computer-assisted go curation. future work should focus on addressing remaining technical challenges for improved performance of automatic go concept recognition and incorporating practical benefits of text-mining tools into real-world go annotation. database url: http://www.biocreative.org/tasks/biocreative-iv/track-4-go/.",
            "contribution_ids": [
                "R162402"
            ]
        },
        {
            "instance_id": "R162575xR162352",
            "comparison_id": "R162575",
            "paper_id": "R162352",
            "text": "Evaluation of BioCreAtIvE assessment of task 2 abstract \\n \\n background \\n molecular biology accumulated substantial amounts of data concerning functions of genes and proteins. information relating to functional descriptions is generally extracted manually from textual data and stored in biological databases to build up annotations for large collections of gene products. those annotation databases are crucial for the interpretation of large scale analysis approaches using bioinformatics or experimental techniques. due to the growing accumulation of functional descriptions in biomedical literature the need for text mining tools to facilitate the extraction of such annotations is urgent. in order to make text mining tools useable in real world scenarios, for instance to assist database curators during annotation of protein function, comparisons and evaluations of different approaches on full text articles are needed. \\n \\n \\n results \\n the critical assessment for information extraction in biology (biocreative) contest consists of a community wide competition aiming to evaluate different strategies for text mining tools, as applied to biomedical literature. we report on task two which addressed the automatic extraction and assignment of gene ontology (go) annotations of human proteins, using full text articles. the predictions of task 2 are based on triplets of protein \u2013 go term \u2013 article passage . the annotation-relevant text passages were returned by the participants and evaluated by expert curators of the go annotation (goa) team at the european institute of bioinformatics (ebi). each participant could submit up to three results for each sub-task comprising task 2. in total more than 15,000 individual results were provided by the participants. the curators evaluated in addition to the annotation itself, whether the protein and the go term were correctly predicted and traceable through the submitted text fragment. \\n \\n \\n conclusion \\n concepts provided by go are currently the most extended set of terms used for annotating gene products, thus they were explored to assess how effectively text mining tools are able to extract those annotations automatically. although the obtained results are promising, they are still far from reaching the required performance demanded by real world applications. among the principal difficulties encountered to address the proposed task, were the complex nature of the go terms and protein names (the large range of variants which are used to express proteins and especially go terms in free text), and the lack of a standard training set. a range of very different strategies were used to tackle this task. the dataset generated in line with the biocreative challenge is publicly available and will allow new possibilities for training information extraction methods in the domain of molecular biology. \\n",
            "contribution_ids": [
                "R162353",
                "R166359",
                "R166394"
            ]
        },
        {
            "instance_id": "R162575xR162526",
            "comparison_id": "R162575",
            "paper_id": "R162526",
            "text": "Overview of the BioCreative VI text-mining services for Kinome Curation Track abstract the text-mining services for kinome curation track, part of biocreative vi, proposed a competition to assess the effectiveness of text mining to perform literature triage. the track has exploited an unpublished curated data set from the nextprot database. this data set contained comprehensive annotations for 300 human protein kinases. for a given protein and a given curation axis [diseases or gene ontology (go) biological processes], participants\u2019 systems had to identify and rank relevant articles in a collection of 5.2 m medline citations (task 1) or 530 000 full-text articles (task 2). explored strategies comprised named-entity recognition and machine-learning frameworks. for that latter approach, participants developed methods to derive a set of negative instances, as the databases typically do not store articles that were judged as irrelevant by curators. the supervised approaches proposed by the participating groups achieved significant improvements compared to the baseline established in a previous study and compared to a basic pubmed search.",
            "contribution_ids": [
                "R162528",
                "R172056",
                "R172038",
                "R172039"
            ]
        },
        {
            "instance_id": "R162575xR162349",
            "comparison_id": "R162575",
            "paper_id": "R162349",
            "text": "BioCreAtIvE Task 1A: gene mention finding evaluation abstract \\n \\n background \\n the biological research literature is a major repository of knowledge. as the amount of literature increases, it will get harder to find the information of interest on a particular topic. there has been an increasing amount of work on text mining this literature, but comparing this work is hard because of a lack of standards for making comparisons. to address this, we worked with colleagues at the protein design group, cnb-csic, madrid to develop biocreative (critical assessment for information extraction in biology), an open common evaluation of systems on a number of biological text mining tasks. we report here on task 1a, which deals with finding mentions of genes and related entities in text. \"finding mentions\" is a basic task, which can be used as a building block for other text mining tasks. the task makes use of data and evaluation software provided by the (us) national center for biotechnology information (ncbi). \\n \\n \\n results \\n 15 teams took part in task 1a. a number of teams achieved scores over 80% f-measure (balanced precision and recall). the teams that tried to use their task 1a systems to help on other biocreative tasks reported mixed results. \\n \\n \\n conclusion \\n the 80% plus f-measure results are good, but still somewhat lag the best scores achieved in some other domains such as newswire, due in part to the complexity and length of gene names, compared to person or organization names in newswire. \\n",
            "contribution_ids": [
                "R162350",
                "R166331"
            ]
        },
        {
            "instance_id": "R162575xR162568",
            "comparison_id": "R162575",
            "paper_id": "R162568",
            "text": "Overview of the BioCreative VII LitCovid Track: multi-label topic classification for COVID-19 literature annotation the biocreative litcovid track calls for a community effort to tackle automated topic annotation for covid-19 literature. the number of covid-19-related articles in the literature is growing by about 10,000 articles per month, significantly challenging curation efforts and downstream interpretation. litcovid is a literature database of covid-19related articles in pubmed, which has accumulated more than 180,000 articles with millions of accesses each month by users worldwide. the rapid literature growth significantly increases the burden of litcovid curation, especially for topic annotations. topic annotation in litcovid assigns one or more (up to eight) labels to articles. the annotated topics have been widely used both directly in litcovid (e.g., accounting for ~20% of total uses) and downstream studies such as knowledge network generation and citation analysis. it is, therefore, important to develop innovative text mining methods to tackle the challenge. we organized the biocreative litcovid track to call for a community effort to tackle automated topic annotation for covid-19 literature. this article summarizes the biocreative litcovid track in terms of data collection and team participation. the dataset is publicly available via https://ftp.ncbi.nlm.nih.gov/pub/lu/litcovid/biocreative/. it consists of over 30k pubmed articles, one of the largest multilabel classification datasets on biomedical literature. there were 80 submissions in total from 19 teams worldwide. the highestperforming submissions achieved 0.8875, 0.9181, and 0.9394 for macro f1-score, micro f1-score, and instance-based f1-score, respectively. we look forward to further participation in developing biomedical text mining methods in response to the rapid growth of the covid-19 literature. keywords\u2014biomedical text mining; natural language processing; artificial intelligence; machine learning; deep learning; multi-label classification; covid-19; litcovid;",
            "contribution_ids": [
                "R162570"
            ]
        },
        {
            "instance_id": "R162575xR162540",
            "comparison_id": "R162575",
            "paper_id": "R162540",
            "text": "The extraction of complex relationships and their conversion to biological expression language (BEL) overview of the BioCreative VI (2017) BEL track abstract \\n knowledge of the molecular interactions of biological and chemical entities and their involvement in biological processes or clinical phenotypes is important for data interpretation. unfortunately, this knowledge is mostly embedded in the literature in such a way that it is unavailable for automated data analysis procedures. biological expression language (bel) is a syntax representation allowing for the structured representation of a broad range of biological relationships. it is used in various situations to extract such knowledge and transform it into bel networks. to support the tedious and time-intensive extraction work of curators with automated methods, we developed the bel track within the framework of biocreative challenges. within the bel track, we provide training data and an evaluation environment to encourage the text mining community to tackle the automatic extraction of complex bel relationships. in 2017 biocreative vi, the 2015 bel track was repeated with new test data. although only minor improvements in text snippet retrieval for given statements were achieved during this second bel task iteration, a significant increase of bel statement extraction performance from provided sentences could be seen. the best performing system reached a 32% f-score for the extraction of complete bel statements and with the given named entities this increased to 49%. this time, besides rule-based systems, new methods involving hierarchical sequence labeling and neural networks were applied for bel statement extraction.",
            "contribution_ids": [
                "R162542"
            ]
        },
        {
            "instance_id": "R162575xR162489",
            "comparison_id": "R162575",
            "paper_id": "R162489",
            "text": "Overview of the interactive task in BioCreative V fully automated text mining (tm) systems promote efficient literature searching, retrieval, and review but are not sufficient to produce ready-to-consume curated documents. these systems are not meant to replace biocurators, but instead to assist them in one or more literature curation steps. to do so, the user interface is an important aspect that needs to be considered for tool adoption. the biocreative interactive task (iat) is a track designed for exploring user-system interactions, promoting development of useful tm tools, and providing a communication channel between the biocuration and the tm communities. in biocreative v, the iat track followed a format similar to previous interactive tracks, where the utility and usability of tm tools, as well as the generation of use cases, have been the focal points. the proposed curation tasks are user-centric and formally evaluated by biocurators. in biocreative v iat, seven tm systems and 43 biocurators participated. two levels of user participation were offered to broaden curator involvement and obtain more feedback on usability aspects. the full level participation involved training on the system, curation of a set of documents with and without tm assistance, tracking of time-on-task, and completion of a user survey. the partial level participation was designed to focus on usability aspects of the interface and not the performance per se. in this case, biocurators navigated the system by performing pre-designed tasks and then were asked whether they were able to achieve the task and the level of difficulty in completing the task. in this manuscript, we describe the development of the interactive task, from planning to execution and discuss major findings for the systems tested. database url: http://www.biocreative.org",
            "contribution_ids": [
                "R162491"
            ]
        },
        {
            "instance_id": "R162575xR162482",
            "comparison_id": "R162575",
            "paper_id": "R162482",
            "text": "BioCreative V track 4: a shared task for the extraction of causal network information using the Biological Expression Language automatic extraction of biological network information is one of the most desired and most complex tasks in biological and medical text mining. track 4 at biocreative v attempts to approach this complexity using fragments of large-scale manually curated biological networks, represented in biological expression language (bel), as training and test data. bel is an advanced knowledge representation format which has been designed to be both human readable and machine processable. the specific goal of track 4 was to evaluate text mining systems capable of automatically constructing bel statements from given evidence text, and of retrieving evidence text for given bel statements. given the complexity of the task, we designed an evaluation methodology which gives credit to partially correct statements. we identified various levels of information expressed by bel statements, such as entities, functions, relations, and introduced an evaluation framework which rewards systems capable of delivering useful bel fragments at each of these levels. the aim of this evaluation method is to help identify the characteristics of the systems which, if combined, would be most useful for achieving the overall goal of automatically constructing causal biological networks from text.",
            "contribution_ids": [
                "R162484",
                "R172014",
                "R172015"
            ]
        },
        {
            "instance_id": "R163265xR148112",
            "comparison_id": "R163265",
            "paper_id": "R148112",
            "text": "2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text abstract \\n the 2010 i2b2/va workshop on natural language processing challenges for clinical records presented three tasks: a concept extraction task focused on the extraction of medical concepts from patient reports; an assertion classification task focused on assigning assertion types for medical problem concepts; and a relation classification task focused on assigning relation types that hold between medical problems, tests, and treatments. i2b2 and the va provided an annotated reference standard corpus for the three tasks. using this reference standard, 22 systems were developed for concept extraction, 21 for assertion classification, and 16 for relation classification. \\n these systems showed that machine learning approaches could be augmented with rule-based systems to determine concepts, assertions, and relations. depending on the task, the rule-based systems can either provide input for machine learning or post-process the output of machine learning. ensembles of classifiers, information from unlabeled data, and external knowledge sources can help when the training data are inadequate.",
            "contribution_ids": [
                "R148114"
            ]
        },
        {
            "instance_id": "R163265xR148032",
            "comparison_id": "R163265",
            "paper_id": "R148032",
            "text": "MedTag: A Collection of Biomedical Annotations we present a database of annotated biomedical text corpora merged into a portable data structure with uniform conventions. medtag combines three corpora, medpost, abgene and genetag, within a common relational database data model. the genetag corpus has been modified to reflect new definitions of genes and proteins. the medpost corpus has been updated to include 1,000 additional sentences from the clinical medicine domain. all data have been updated with original medline text excerpts, pubmed identifiers, and tokenization independence to facilitate data accuracy, consistency and usability. \\n \\nthe data are available in flat files along with software to facilitate loading the data into a relational sql database from ftp://ftp.ncbi.nlm.nih.gov/pub/lsmith/medtag/medtag.tar.gz.",
            "contribution_ids": [
                "R148034"
            ]
        },
        {
            "instance_id": "R163265xR148450",
            "comparison_id": "R163265",
            "paper_id": "R148450",
            "text": "The ITI TXM corpora: Tissue expressions and protein-protein interactions we report on two large corpora of semantically annotated full-text biomedical research papers created in order to devel op information extraction ( ie) tools for the txm project. both corpora have been annotated with a range of entities (cellline, complex, developmentalstage, disease, drugcompound, experimentalmethod, fragment, fusion, gomop, gene, modification, mrnacdna, mutant, protein, tissue), normalisations of selected entities to the ncbi taxonomy, refseq, entrezgene, chebi and mesh and enriched relations (protein-protein interactions, tissue expressions and fr agment- or mutant-protein relations). while one corpus targets protein-protein interactions ( ppis), the focus of other is on tissue expressions ( tes). this paper describes the selected markables and the annotation process of the iti txm corpora, and provides a detailed breakdown of the inter-annotator agreement (iaa).",
            "contribution_ids": [
                "R148452"
            ]
        },
        {
            "instance_id": "R163265xR148501",
            "comparison_id": "R163265",
            "paper_id": "R148501",
            "text": "Integrated Annotation for Biomedical Information Extraction we describe an approach to two areas of biomedical information extraction, drug development and cancer genomics. we have developed a framework which includes corpus annotation integrated at multiple levels: a treebank containing syntactic structure, a propbank containing predicate-argument structure, and annotation of entities and relations among the entities. crucial to this approach is the proper characterization of entities as relation components, which allows the integration of the entity annotation with the syntactic structure while retaining the capacity to annotate and extract more complex events. we are training statistical taggers using this annotation for such extraction as well as using them for improving the annotation process.",
            "contribution_ids": [
                "R148503"
            ]
        },
        {
            "instance_id": "R163265xR163224",
            "comparison_id": "R163265",
            "paper_id": "R163224",
            "text": "An empirical evaluation of resources for the identification of diseases and adverse effects in biomedical literature the mentions of human health perturbations such as the diseases and adverse effects denote a special entity class in the biomedical \\nliterature. they help in understanding the underlying risk factors and develop a preventive rationale. the recognition of these named \\nentities in texts through dictionary-based approaches relies on the availability of appropriate terminological resources. although few \\nresources are publicly available, not all are suitable for the text mining needs. therefore, this work provides an overview of the well \\nknown resources with respect to human diseases and adverse effects such as the mesh, meddra, icd-10, snomed ct, and umls. \\nindividual dictionaries are generated from these resources and their performance in recognizing the named entities is evaluated over a \\nmanually annotated corpus. in addition, the steps for curating the dictionaries, rule-based acronym disambiguation and their impact \\non the dictionary performance is discussed. the results show that the meddra and umls achieve the best recall. besides this, \\nmeddra provides an additional benefit of achieving a higher precision. the combination of search results of all the dictionaries achieve \\na considerably high recall. the corpus is available on http://www.scai.fraunhofer.de/disease-ae-corpus.html",
            "contribution_ids": [
                "R163226"
            ]
        },
        {
            "instance_id": "R163265xR148050",
            "comparison_id": "R163265",
            "paper_id": "R148050",
            "text": "Tagging gene and protein names in biomedical text motivation\\nthe medline database of biomedical abstracts contains scientific knowledge about thousands of interacting genes and proteins. automated text processing can aid in the comprehension and synthesis of this valuable information. the fundamental task of identifying gene and protein names is a necessary first step towards making full use of the information encoded in biomedical text. this remains a challenging task due to the irregularities and ambiguities in gene and protein nomenclature. we propose to approach the detection of gene and protein names in scientific abstracts as part-of-speech tagging, the most basic form of linguistic corpus annotation.\\n\\n\\nresults\\nwe present a method for tagging gene and protein names in biomedical text using a combination of statistical and knowledge-based strategies. this method incorporates automatically generated rules from a transformation-based part-of-speech tagger, and manually generated rules from morphological clues, low frequency trigrams, indicator terms, suffixes and part-of-speech information. results of an experiment on a test corpus of 56k medline documents demonstrate that our method to extract gene and protein names can be applied to large sets of medline abstracts, without the need for special conditions or human experts to predetermine relevant subsets.\\n\\n\\navailability\\nthe programs are available on request from the authors.",
            "contribution_ids": [
                "R148052"
            ]
        },
        {
            "instance_id": "R163265xR148131",
            "comparison_id": "R163265",
            "paper_id": "R148131",
            "text": "Construction of an annotated corpus to support biomedical information extraction abstract \\n \\n background \\n information extraction (ie) is a component of text mining that facilitates knowledge discovery by automatically locating instances of interesting biomedical events from huge document collections. as events are usually centred on verbs and nominalised verbs, understanding the syntactic and semantic behaviour of these words is highly important. corpora annotated with information concerning this behaviour can constitute a valuable resource in the training of ie components and resources. \\n \\n \\n results \\n we have defined a new scheme for annotating sentence-bound gene regulation events, centred on both verbs and nominalised verbs. for each event instance, all participants ( arguments ) in the same sentence are identified and assigned a semantic role from a rich set of 13 roles tailored to biomedical research articles, together with a biological concept type linked to the gene regulation ontology. to our knowledge, our scheme is unique within the biomedical field in terms of the range of event arguments identified. using the scheme, we have created the gene regulation event corpus (grec), consisting of 240 medline abstracts, in which events relating to gene regulation and expression have been annotated by biologists. a novel method of evaluating various different facets of the annotation task showed that average inter-annotator agreement rates fall within the range of 66% - 90%. \\n \\n \\n conclusion \\n the grec is a unique resource within the biomedical field, in that it annotates not only core relationships between entities, but also a range of other important details about these relationships, e.g., location, temporal, manner and environmental conditions. as such, it is specifically designed to support bio-specific tool and resource development. it has already been used to acquire semantic frames for inclusion within the biolexicon (a lexical, terminological resource to aid biomedical text mining). initial experiments have also shown that the corpus may viably be used to train ie components, such as semantic role labellers. the corpus and annotation guidelines are freely available for academic purposes. \\n",
            "contribution_ids": [
                "R148133"
            ]
        },
        {
            "instance_id": "R163742xR163616",
            "comparison_id": "R163742",
            "paper_id": "R163616",
            "text": "CRAFT Shared Tasks 2019 Overview \u00e2\u0080\u0093- Integrated Structure, Semantics, and Coreference as part of the bionlp open shared tasks 2019, the craft shared tasks 2019 provides a platform to gauge the state of the art for three fundamental language processing tasks \u2014 dependency parse construction, coreference resolution, and ontology concept identification \u2014 over full-text biomedical articles. the structural annotation task requires the automatic generation of dependency parses for each sentence of an article given only the article text. the coreference resolution task focuses on linking coreferring base noun phrase mentions into chains using the symmetrical and transitive identity relation. the ontology concept annotation task involves the identification of concept mentions within text using the classes of ten distinct ontologies in the biomedical domain, both unmodified and augmented with extension classes. this paper provides an overview of each task, including descriptions of the data provided to participants and the evaluation metrics used, and discusses participant results relative to baseline performances for each of the three tasks.",
            "contribution_ids": [
                "R163618",
                "R163634",
                "R163635",
                "R164619",
                "R164621",
                "R165606",
                "R165608",
                "R165612",
                "R165613",
                "R165617",
                "R165618",
                "R165622",
                "R165624",
                "R165627",
                "R165629",
                "R165636",
                "R165637",
                "R165641",
                "R165642",
                "R165647",
                "R165648",
                "R165652",
                "R165653",
                "R165654",
                "R165655",
                "R165878",
                "R165910"
            ]
        },
        {
            "instance_id": "R163742xR163666",
            "comparison_id": "R163742",
            "paper_id": "R163666",
            "text": "An Overview of the Active Gene Annotation Corpus and the BioNLP OST 2019 AGAC Track Tasks the active gene annotation corpus (agac) was developed to support knowledge discovery for drug repurposing. based on the corpus, the agac track of the bionlp open shared tasks 2019 was organized, to facilitate cross-disciplinary collaboration across bionlp and pharmacoinformatics communities, for drug repurposing. the agac track consists of three subtasks: 1) named entity recognition, 2) thematic relation extraction, and 3) loss of function (lof) / gain of function (gof) topic classification. the agac track was participated by five teams, of which the performance are compared and analyzed. the the results revealed a substantial room for improvement in the design of the task, which we analyzed in terms of \u201cimbalanced data\u201d, \u201cselective annotation\u201d and \u201clatent topic annotation\u201d.",
            "contribution_ids": [
                "R163668",
                "R164647",
                "R165696",
                "R165911"
            ]
        },
        {
            "instance_id": "R163742xR163499",
            "comparison_id": "R163742",
            "paper_id": "R163499",
            "text": "Overview of the Pathway Curation (PC) task of BioNLP Shared Task 2013 we present the pathway curation (pc) task, a main event extraction task of the bionlp shared task (st) 2013. the pc task concerns the automatic extraction of biomolecular reactions from text. the task setting, representation and semantics are defined with respect to pathway model standards and ontologies (sbml, biopax, sbo) and documents selected by relevance to specific model reactions. two bionlp st 2013 participants successfully completed the pc task. the highest achieved fscore, 52.8%, indicates that event extraction is a promising approach to supporting pathway curation efforts. the pc task continues as an open challenge with data, resources and tools available from http://2013.bionlp-st.org/",
            "contribution_ids": [
                "R163501",
                "R164525",
                "R165834",
                "R165835",
                "R165901"
            ]
        },
        {
            "instance_id": "R163742xR163595",
            "comparison_id": "R163742",
            "paper_id": "R163595",
            "text": "Overview of the Bacteria Biotope Task at BioNLP Shared Task 2016 this paper presents the bacteria biotope task of the bionlp shared task 2016, which follows the previous 2013 and 2011 editions. the task focuses on the extraction of the locations (biotopes and geographical places) of bacteria from pubme abstracts and the characterization of bacteria and their associated habitats with\\nrespect to reference knowledge sources (ncbi taxonomy, ontobiotope ontology). the task is motivated by the importance of the knowledge on bacteria habitats for fundamental research and applications in microbiology. the paper describes the different proposed subtasks, the corpus characteristics, the challenge organization, and the evaluation metrics. we also provide an analysis of the results obtained by participants.",
            "contribution_ids": [
                "R163597",
                "R164582",
                "R165603",
                "R165604",
                "R165855",
                "R165871"
            ]
        },
        {
            "instance_id": "R163742xR163702",
            "comparison_id": "R163742",
            "paper_id": "R163702",
            "text": "Bacteria Biotope at BioNLP Open Shared Tasks 2019 this paper presents the fourth edition of the bacteria biotope task at bionlp open shared tasks 2019. the task focuses on the extraction of the locations and phenotypes of microorganisms from pubmed abstracts and full-text excerpts, and the characterization of these entities with respect to reference knowledge sources (ncbi taxonomy, ontobiotope ontology). the task is motivated by the importance of the knowledge on biodiversity for fundamental research and applications in microbiology. the paper describes the different proposed subtasks, the corpus characteristics, and the challenge organization. we also provide an analysis of the results obtained by participants, and inspect the evolution of the results since the last edition in 2016.",
            "contribution_ids": [
                "R163704",
                "R165699",
                "R165701",
                "R165886",
                "R165914"
            ]
        },
        {
            "instance_id": "R163742xR163319",
            "comparison_id": "R163742",
            "paper_id": "R163319",
            "text": "Overview of the Infectious Diseases (ID) task of BioNLP Shared Task 2011 \"this paper presents the preparation, resources, results and analysis of the infectious diseases (id) information extraction task, a main task of the bionlp shared task 2011. the id task represents an application and extension of the bionlp'09 shared task event extraction approach to full papers on infectious diseases. seven teams submitted final results to the task, with the highest-performing system achieving 56% f-score in the full task, comparable to state-of-the-art performance in the established bionlp'09 task. the results indicate that event extraction methods generalize well to new domains and full-text publications and are applicable to the extraction of events relevant to the molecular mechanisms of infectious diseases.\"",
            "contribution_ids": [
                "R163321",
                "R164438",
                "R165806",
                "R165808"
            ]
        },
        {
            "instance_id": "R163742xR163542",
            "comparison_id": "R163742",
            "paper_id": "R163542",
            "text": "Overview of the Regulatory Network of Plant Seed Development\n            (SeeDev) Task at the BioNLP Shared Task 2016. this paper presents the seedev task of the bionlp shared task 2016. the purpose of the seedev task is the extraction from scientific articles of the descriptions of genetic and molecular mechanisms involved in seed development of the model plant, arabidopsis thaliana. the seedev task consists in the extraction of many different event types that involve a wide range of entity types so that they accurately reflect the complexity of the biological mechanisms. the corpus is composed of paragraphs selected from the full-texts of relevant scientific articles. in this paper, we describe the organization of the seedev task, the corpus characteristics, and the metrics used for the evaluation of participant systems. we analyze and discuss the final results of the seven participant systems to the test. the best f-score is 0.432, which is similar to the scores achieved in similar tasks on molecular biology.",
            "contribution_ids": [
                "R163544",
                "R164587",
                "R165862",
                "R165908"
            ]
        },
        {
            "instance_id": "R163742xR163609",
            "comparison_id": "R163742",
            "paper_id": "R163609",
            "text": "Refactoring the Genia Event Extraction Shared Task Toward a General\n            Framework for IE-Driven KB Development for its fourth organization, the genia event extraction (ge) shared task is refactored toward a general platform for shared information extraction (ie) tasks, and for an iedriven knowledge base (kb) system. on the newly implemented shared task platform, the ge task is run as an experimental task. the task and the platform has been tested by two teams who cooperated with the organizers. the paper presents the new shared task system and discusses on the experimental submissions.",
            "contribution_ids": [
                "R163611"
            ]
        },
        {
            "instance_id": "R163742xR163406",
            "comparison_id": "R163742",
            "paper_id": "R163406",
            "text": "Overview of the Cancer Genetics (CG) task of BioNLP Shared Task 2013 we present the design, preparation, results and analysis of the cancer genetics (cg) event extraction task, a main task of the bionlp shared task (st) 2013. the cg task is an information extraction task targeting the recognition of events in text, represented as structured n-ary associations of given physical entities. in addition to addressing the cancer domain, the cg task is differentiated from previous event extraction tasks in the bionlp st series in addressing a wide range of pathological processes and multiple levels of biological organization, ranging from the molecular through the cellular and organ levels up to whole organisms. final test set submissions were accepted from six teams. the highest-performing system achieved an fscore of 55.4%. this level of performance is broadly comparable with the state of the art for established molecular-level extraction tasks, demonstrating that event extraction resources and methods generalize well to higher levels of biological organization and are applicable to the analysis of scientific texts on cancer. the cg task continues as an open challenge to all interested parties, with tools and resources available from http://2013. bionlp-st.org/.",
            "contribution_ids": [
                "R163408",
                "R164522",
                "R165824",
                "R165825",
                "R165899"
            ]
        },
        {
            "instance_id": "R164231xR164130",
            "comparison_id": "R164231",
            "paper_id": "R164130",
            "text": "A RE-EVALUATION OF BIOMEDICAL NAMED ENTITY\u00e2\u0080\u0093TERM RELATIONS text mining can support the interpretation of the enormous quantity of textual data produced in biomedical field. recent developments in biomedical text mining include advances in the reliability of the recognition of named entities (nes) such as specific genes and proteins, as well as movement toward richer representations of the associations of nes. we argue that this shift in representation should be accompanied by the adoption of a more detailed model of the relations holding between nes and other relevant domain terms. as a step toward this goal, we study ne\u2013term relations with the aim of defining a detailed, broadly applicable set of relation types based on accepted domain standard concepts for use in corpus annotation and domain information extraction approaches.",
            "contribution_ids": [
                "R164132"
            ]
        },
        {
            "instance_id": "R164231xR164170",
            "comparison_id": "R164231",
            "paper_id": "R164170",
            "text": "Coreference Resolution in Biomedical Texts: a Machine Learning Approach motivation: coreference resolution, the process of identifying different mentions of an entity, is a very important component in a text-mining system. compared with the work in news articles, the existing study of coreference resolution in biomedical texts is quite preliminary by only focusing on specific types of anaphors like pronouns or definite noun phrases, using heuristic methods, and running on small data sets. therefore, there is a need for an in-depth exploration of this task in the biomedical domain. results: in this article, we presented a learning-based approach to coreference resolution in the biomedical domain. we made three contributions in our study. firstly, we annotated a large scale coreference corpus, medco, which consists of 1,999 medline abstracts in the genia data set. secondly, we proposed a detailed framework for the coreference resolution task, in which we augmented the traditional learning model by incorporating non-anaphors into training. lastly, we explored various sources of knowledge for coreference resolution, particularly, those that can deal with the complexity of biomedical texts. the evaluation on the medco corpus showed promising results. our coreference resolution system achieved a high precision of 85.2% with a reasonable recall of 65.3%, obtaining an f-measure of 73.9%. the results also suggested that our augmented learning model significantly boosted precision (up to 24.0%) without much loss in recall (less than 5%), and brought a gain of over 8% in f-measure.",
            "contribution_ids": [
                "R164172"
            ]
        },
        {
            "instance_id": "R164231xR164218",
            "comparison_id": "R164231",
            "paper_id": "R164218",
            "text": "The GENIA corpus: an annotated research abstract corpus in molecular biology domain with the information overload in genome-related field, there is an increasing need for natural language processing technology to extract information from literature and various attempts of information extraction using nlp has been being made. we are developing the necessary resources including domain ontology and annotated corpus from research abstracts in medline database (genia corpus). we are building the ontology and the corpus simultaneously, using each other. in this paper we report on our new corpus, its ontological basis, annotation scheme, and statistics of annotated objects. we also describe the tools used for corpus annotation and management.",
            "contribution_ids": [
                "R164220"
            ]
        },
        {
            "instance_id": "R164231xR163869",
            "comparison_id": "R164231",
            "paper_id": "R163869",
            "text": "Syntax Annotation for the GENIA Corpus linguistically annotated corpus based on texts in biomedical domain has been constructed to tune natural language processing (nlp) tools for biotextmining. as the focus of information extraction is shifting from \"nominal\" information such as named entity to \"verbal\" information such as function and interaction of substances, application of parsers has become one of the key technologies and thus the corpus annotated for syntactic structure of sentences is in demand. a subset of the genia corpus consisting of 500 medline abstracts has been annotated for syntactic structure in an xmlbased format based on penn treebank ii (ptb) scheme. inter-annotator agreement test indicated that the writing style rather than the contents of the research abstracts is the source of the difficulty in tree annotation, and that annotation can be stably done by linguists without much knowledge of biology with appropriate guidelines regarding to linguistic phenomena particular to scientific texts.",
            "contribution_ids": [
                "R163871"
            ]
        },
        {
            "instance_id": "R164670xR163294",
            "comparison_id": "R164670",
            "paper_id": "R163294",
            "text": "Overview of Genia Event Task in BioNLP Shared Task 2011 the genia event task, a bio-molecular event extraction task, is arranged as one of the main tasks of bionlp shared task 2011. as its second time to be arranged for community-wide focused efforts, it aimed to measure the advance of the community since 2009, and to evaluate generalization of the technology to full text papers. after a 3-month system development period, 15 teams submitted their performance results on test cases. the results show the community has made a significant advancement in terms of both performance improvement and generalization.",
            "contribution_ids": [
                "R163296",
                "R164410",
                "R165741",
                "R165742",
                "R165743"
            ]
        },
        {
            "instance_id": "R164670xR163499",
            "comparison_id": "R164670",
            "paper_id": "R163499",
            "text": "Overview of the Pathway Curation (PC) task of BioNLP Shared Task 2013 we present the pathway curation (pc) task, a main event extraction task of the bionlp shared task (st) 2013. the pc task concerns the automatic extraction of biomolecular reactions from text. the task setting, representation and semantics are defined with respect to pathway model standards and ontologies (sbml, biopax, sbo) and documents selected by relevance to specific model reactions. two bionlp st 2013 participants successfully completed the pc task. the highest achieved fscore, 52.8%, indicates that event extraction is a promising approach to supporting pathway curation efforts. the pc task continues as an open challenge with data, resources and tools available from http://2013.bionlp-st.org/",
            "contribution_ids": [
                "R163501",
                "R164525",
                "R165834",
                "R165835",
                "R165901"
            ]
        },
        {
            "instance_id": "R164670xR163406",
            "comparison_id": "R164670",
            "paper_id": "R163406",
            "text": "Overview of the Cancer Genetics (CG) task of BioNLP Shared Task 2013 we present the design, preparation, results and analysis of the cancer genetics (cg) event extraction task, a main task of the bionlp shared task (st) 2013. the cg task is an information extraction task targeting the recognition of events in text, represented as structured n-ary associations of given physical entities. in addition to addressing the cancer domain, the cg task is differentiated from previous event extraction tasks in the bionlp st series in addressing a wide range of pathological processes and multiple levels of biological organization, ranging from the molecular through the cellular and organ levels up to whole organisms. final test set submissions were accepted from six teams. the highest-performing system achieved an fscore of 55.4%. this level of performance is broadly comparable with the state of the art for established molecular-level extraction tasks, demonstrating that event extraction resources and methods generalize well to higher levels of biological organization and are applicable to the analysis of scientific texts on cancer. the cg task continues as an open challenge to all interested parties, with tools and resources available from http://2013. bionlp-st.org/.",
            "contribution_ids": [
                "R163408",
                "R164522",
                "R165824",
                "R165825",
                "R165899"
            ]
        },
        {
            "instance_id": "R164670xR163595",
            "comparison_id": "R164670",
            "paper_id": "R163595",
            "text": "Overview of the Bacteria Biotope Task at BioNLP Shared Task 2016 this paper presents the bacteria biotope task of the bionlp shared task 2016, which follows the previous 2013 and 2011 editions. the task focuses on the extraction of the locations (biotopes and geographical places) of bacteria from pubme abstracts and the characterization of bacteria and their associated habitats with\\nrespect to reference knowledge sources (ncbi taxonomy, ontobiotope ontology). the task is motivated by the importance of the knowledge on bacteria habitats for fundamental research and applications in microbiology. the paper describes the different proposed subtasks, the corpus characteristics, the challenge organization, and the evaluation metrics. we also provide an analysis of the results obtained by participants.",
            "contribution_ids": [
                "R163597",
                "R164582",
                "R165603",
                "R165604",
                "R165855",
                "R165871"
            ]
        },
        {
            "instance_id": "R164670xR163616",
            "comparison_id": "R164670",
            "paper_id": "R163616",
            "text": "CRAFT Shared Tasks 2019 Overview \u00e2\u0080\u0093- Integrated Structure, Semantics, and Coreference as part of the bionlp open shared tasks 2019, the craft shared tasks 2019 provides a platform to gauge the state of the art for three fundamental language processing tasks \u2014 dependency parse construction, coreference resolution, and ontology concept identification \u2014 over full-text biomedical articles. the structural annotation task requires the automatic generation of dependency parses for each sentence of an article given only the article text. the coreference resolution task focuses on linking coreferring base noun phrase mentions into chains using the symmetrical and transitive identity relation. the ontology concept annotation task involves the identification of concept mentions within text using the classes of ten distinct ontologies in the biomedical domain, both unmodified and augmented with extension classes. this paper provides an overview of each task, including descriptions of the data provided to participants and the evaluation metrics used, and discusses participant results relative to baseline performances for each of the three tasks.",
            "contribution_ids": [
                "R163618",
                "R163634",
                "R163635",
                "R164619",
                "R164621",
                "R165606",
                "R165608",
                "R165612",
                "R165613",
                "R165617",
                "R165618",
                "R165622",
                "R165624",
                "R165627",
                "R165629",
                "R165636",
                "R165637",
                "R165641",
                "R165642",
                "R165647",
                "R165648",
                "R165652",
                "R165653",
                "R165654",
                "R165655",
                "R165878",
                "R165910"
            ]
        },
        {
            "instance_id": "R164670xR163656",
            "comparison_id": "R164670",
            "paper_id": "R163656",
            "text": "PharmaCoNER: Pharmacological Substances, Compounds and proteins Named Entity Recognition track one of the biomedical entity types of relevance for medicine or biosciences are chemical compounds and drugs. the correct detection these entities is critical for other text mining applications building on them, such as adverse drug-reaction detection, medication-related fake news or drug-target extraction. although a significant effort was made to detect mentions of drugs/chemicals in english texts, so far only very limited attempts were made to recognize them in medical documents in other languages. taking into account the growing amount of medical publications and clinical records written in spanish, we have organized the first shared task on detecting drug and chemical entities in spanish medical documents. additionally, we included a clinical concept-indexing sub-track asking teams to return snomed-ct identifiers related to drugs/chemicals for a collection of documents. for this task, named pharmaconer, we generated annotation guidelines together with a corpus of 1,000 manually annotated clinical case studies. a total of 22 teams participated in the sub-track 1, (77 system runs), and 7 teams in the sub-track 2 (19 system runs). top scoring teams used sophisticated deep learning approaches yielding very competitive results with f-measures above 0.91. these results indicate that there is a real interest in promoting biomedical text mining efforts beyond english. we foresee that the pharmaconer annotation guidelines, corpus and participant systems will foster the development of new resources for clinical and biomedical text mining systems of spanish medical data.",
            "contribution_ids": [
                "R163658",
                "R164640",
                "R165689",
                "R165882"
            ]
        },
        {
            "instance_id": "R164670xR163666",
            "comparison_id": "R164670",
            "paper_id": "R163666",
            "text": "An Overview of the Active Gene Annotation Corpus and the BioNLP OST 2019 AGAC Track Tasks the active gene annotation corpus (agac) was developed to support knowledge discovery for drug repurposing. based on the corpus, the agac track of the bionlp open shared tasks 2019 was organized, to facilitate cross-disciplinary collaboration across bionlp and pharmacoinformatics communities, for drug repurposing. the agac track consists of three subtasks: 1) named entity recognition, 2) thematic relation extraction, and 3) loss of function (lof) / gain of function (gof) topic classification. the agac track was participated by five teams, of which the performance are compared and analyzed. the the results revealed a substantial room for improvement in the design of the task, which we analyzed in terms of \u201cimbalanced data\u201d, \u201cselective annotation\u201d and \u201clatent topic annotation\u201d.",
            "contribution_ids": [
                "R163668",
                "R164647",
                "R165696",
                "R165911"
            ]
        },
        {
            "instance_id": "R164670xR141057",
            "comparison_id": "R164670",
            "paper_id": "R141057",
            "text": "Overview of the Epigenetics and Post-translational Modifications (EPI) task of BioNLP Shared Task 2011 this paper presents the preparation, resources, results and analysis of the epigenetics and post-translational modifications (epi) task, a main task of the bionlp shared task 2011. the task concerns the extraction of detailed representations of 14 protein and dna modification events, the catalysis of these reactions, and the identification of instances of negated or speculatively stated event instances. seven teams submitted final results to the epi task in the shared task, with the highest-performing system achieving 53% f-score in the full task and 69% f-score in the extraction of a simplified set of core event arguments.",
            "contribution_ids": [
                "R141059",
                "R164428",
                "R165801",
                "R165803",
                "R165891"
            ]
        },
        {
            "instance_id": "R164670xR163542",
            "comparison_id": "R164670",
            "paper_id": "R163542",
            "text": "Overview of the Regulatory Network of Plant Seed Development\n            (SeeDev) Task at the BioNLP Shared Task 2016. this paper presents the seedev task of the bionlp shared task 2016. the purpose of the seedev task is the extraction from scientific articles of the descriptions of genetic and molecular mechanisms involved in seed development of the model plant, arabidopsis thaliana. the seedev task consists in the extraction of many different event types that involve a wide range of entity types so that they accurately reflect the complexity of the biological mechanisms. the corpus is composed of paragraphs selected from the full-texts of relevant scientific articles. in this paper, we describe the organization of the seedev task, the corpus characteristics, and the metrics used for the evaluation of participant systems. we analyze and discuss the final results of the seven participant systems to the test. the best f-score is 0.432, which is similar to the scores achieved in similar tasks on molecular biology.",
            "contribution_ids": [
                "R163544",
                "R164587",
                "R165862",
                "R165908"
            ]
        },
        {
            "instance_id": "R164670xR164551",
            "comparison_id": "R164670",
            "paper_id": "R164551",
            "text": "BioNLP shared Task 2013 \u00e2\u0080\u0093 An Overview of the Bacteria Biotope Task this paper presents the bacteria biotope task of the bionlp shared task 2013, which follows bionlp-st-11. the bacteria biotope task aims to extract the location of bacteria from scientific web pages and to characterize these locations with respect to the ontobiotope ontology. bacteria locations are crucil knowledge in biology for phenotype studies. the paper details the corpus specifications, the evaluation metrics, and it summarizes and discusses the participant results.",
            "contribution_ids": [
                "R164553",
                "R164575",
                "R165593",
                "R165905"
            ]
        },
        {
            "instance_id": "R165700xR163702",
            "comparison_id": "R165700",
            "paper_id": "R163702",
            "text": "Bacteria Biotope at BioNLP Open Shared Tasks 2019 this paper presents the fourth edition of the bacteria biotope task at bionlp open shared tasks 2019. the task focuses on the extraction of the locations and phenotypes of microorganisms from pubmed abstracts and full-text excerpts, and the characterization of these entities with respect to reference knowledge sources (ncbi taxonomy, ontobiotope ontology). the task is motivated by the importance of the knowledge on biodiversity for fundamental research and applications in microbiology. the paper describes the different proposed subtasks, the corpus characteristics, and the challenge organization. we also provide an analysis of the results obtained by participants, and inspect the evolution of the results since the last edition in 2016.",
            "contribution_ids": [
                "R163704",
                "R165699",
                "R165701",
                "R165886",
                "R165914"
            ]
        },
        {
            "instance_id": "R165700xR163616",
            "comparison_id": "R165700",
            "paper_id": "R163616",
            "text": "CRAFT Shared Tasks 2019 Overview \u00e2\u0080\u0093- Integrated Structure, Semantics, and Coreference as part of the bionlp open shared tasks 2019, the craft shared tasks 2019 provides a platform to gauge the state of the art for three fundamental language processing tasks \u2014 dependency parse construction, coreference resolution, and ontology concept identification \u2014 over full-text biomedical articles. the structural annotation task requires the automatic generation of dependency parses for each sentence of an article given only the article text. the coreference resolution task focuses on linking coreferring base noun phrase mentions into chains using the symmetrical and transitive identity relation. the ontology concept annotation task involves the identification of concept mentions within text using the classes of ten distinct ontologies in the biomedical domain, both unmodified and augmented with extension classes. this paper provides an overview of each task, including descriptions of the data provided to participants and the evaluation metrics used, and discusses participant results relative to baseline performances for each of the three tasks.",
            "contribution_ids": [
                "R163618",
                "R163634",
                "R163635",
                "R164619",
                "R164621",
                "R165606",
                "R165608",
                "R165612",
                "R165613",
                "R165617",
                "R165618",
                "R165622",
                "R165624",
                "R165627",
                "R165629",
                "R165636",
                "R165637",
                "R165641",
                "R165642",
                "R165647",
                "R165648",
                "R165652",
                "R165653",
                "R165654",
                "R165655",
                "R165878",
                "R165910"
            ]
        },
        {
            "instance_id": "R165700xR164455",
            "comparison_id": "R165700",
            "paper_id": "R164455",
            "text": "BioNLP Shared Task 2011 - Bacteria Biotope this paper presents the bacteria biotope task as part of the bionlp shared tasks 2011. the bacteria biotope task aims at extracting the location of bacteria from scientific web pages. bacteria location is a crucial knowledge in biology for phenotype studies. the paper details the corpus specification, the evaluation metrics, summarizes and discusses the participant results.",
            "contribution_ids": [
                "R164457",
                "R164467",
                "R165270",
                "R165466",
                "R165867",
                "R165893"
            ]
        },
        {
            "instance_id": "R165700xR163294",
            "comparison_id": "R165700",
            "paper_id": "R163294",
            "text": "Overview of Genia Event Task in BioNLP Shared Task 2011 the genia event task, a bio-molecular event extraction task, is arranged as one of the main tasks of bionlp shared task 2011. as its second time to be arranged for community-wide focused efforts, it aimed to measure the advance of the community since 2009, and to evaluate generalization of the technology to full text papers. after a 3-month system development period, 15 teams submitted their performance results on test cases. the results show the community has made a significant advancement in terms of both performance improvement and generalization.",
            "contribution_ids": [
                "R163296",
                "R164410",
                "R165741",
                "R165742",
                "R165743"
            ]
        },
        {
            "instance_id": "R165700xR141057",
            "comparison_id": "R165700",
            "paper_id": "R141057",
            "text": "Overview of the Epigenetics and Post-translational Modifications (EPI) task of BioNLP Shared Task 2011 this paper presents the preparation, resources, results and analysis of the epigenetics and post-translational modifications (epi) task, a main task of the bionlp shared task 2011. the task concerns the extraction of detailed representations of 14 protein and dna modification events, the catalysis of these reactions, and the identification of instances of negated or speculatively stated event instances. seven teams submitted final results to the epi task in the shared task, with the highest-performing system achieving 53% f-score in the full task and 69% f-score in the extraction of a simplified set of core event arguments.",
            "contribution_ids": [
                "R141059",
                "R164428",
                "R165801",
                "R165803",
                "R165891"
            ]
        },
        {
            "instance_id": "R165700xR163656",
            "comparison_id": "R165700",
            "paper_id": "R163656",
            "text": "PharmaCoNER: Pharmacological Substances, Compounds and proteins Named Entity Recognition track one of the biomedical entity types of relevance for medicine or biosciences are chemical compounds and drugs. the correct detection these entities is critical for other text mining applications building on them, such as adverse drug-reaction detection, medication-related fake news or drug-target extraction. although a significant effort was made to detect mentions of drugs/chemicals in english texts, so far only very limited attempts were made to recognize them in medical documents in other languages. taking into account the growing amount of medical publications and clinical records written in spanish, we have organized the first shared task on detecting drug and chemical entities in spanish medical documents. additionally, we included a clinical concept-indexing sub-track asking teams to return snomed-ct identifiers related to drugs/chemicals for a collection of documents. for this task, named pharmaconer, we generated annotation guidelines together with a corpus of 1,000 manually annotated clinical case studies. a total of 22 teams participated in the sub-track 1, (77 system runs), and 7 teams in the sub-track 2 (19 system runs). top scoring teams used sophisticated deep learning approaches yielding very competitive results with f-measures above 0.91. these results indicate that there is a real interest in promoting biomedical text mining efforts beyond english. we foresee that the pharmaconer annotation guidelines, corpus and participant systems will foster the development of new resources for clinical and biomedical text mining systems of spanish medical data.",
            "contribution_ids": [
                "R163658",
                "R164640",
                "R165689",
                "R165882"
            ]
        },
        {
            "instance_id": "R165700xR163666",
            "comparison_id": "R165700",
            "paper_id": "R163666",
            "text": "An Overview of the Active Gene Annotation Corpus and the BioNLP OST 2019 AGAC Track Tasks the active gene annotation corpus (agac) was developed to support knowledge discovery for drug repurposing. based on the corpus, the agac track of the bionlp open shared tasks 2019 was organized, to facilitate cross-disciplinary collaboration across bionlp and pharmacoinformatics communities, for drug repurposing. the agac track consists of three subtasks: 1) named entity recognition, 2) thematic relation extraction, and 3) loss of function (lof) / gain of function (gof) topic classification. the agac track was participated by five teams, of which the performance are compared and analyzed. the the results revealed a substantial room for improvement in the design of the task, which we analyzed in terms of \u201cimbalanced data\u201d, \u201cselective annotation\u201d and \u201clatent topic annotation\u201d.",
            "contribution_ids": [
                "R163668",
                "R164647",
                "R165696",
                "R165911"
            ]
        },
        {
            "instance_id": "R165700xR163499",
            "comparison_id": "R165700",
            "paper_id": "R163499",
            "text": "Overview of the Pathway Curation (PC) task of BioNLP Shared Task 2013 we present the pathway curation (pc) task, a main event extraction task of the bionlp shared task (st) 2013. the pc task concerns the automatic extraction of biomolecular reactions from text. the task setting, representation and semantics are defined with respect to pathway model standards and ontologies (sbml, biopax, sbo) and documents selected by relevance to specific model reactions. two bionlp st 2013 participants successfully completed the pc task. the highest achieved fscore, 52.8%, indicates that event extraction is a promising approach to supporting pathway curation efforts. the pc task continues as an open challenge with data, resources and tools available from http://2013.bionlp-st.org/",
            "contribution_ids": [
                "R163501",
                "R164525",
                "R165834",
                "R165835",
                "R165901"
            ]
        },
        {
            "instance_id": "R165700xR163382",
            "comparison_id": "R165700",
            "paper_id": "R163382",
            "text": "The Genia Event Extraction Shared Task, 2013 Edition - Overview the genia event extraction task is organized for the third time, in bionlp shared task 2013. toward knowledge based construction, the task is modified in a number of points. as the final results, it received 12 submissions, among which 2 were withdrawn from the final report. this paper presents the task setting, data sets, and the final results with discussion for possible future directions.",
            "contribution_ids": [
                "R163384",
                "R164510",
                "R165814",
                "R165815",
                "R165816"
            ]
        },
        {
            "instance_id": "R165700xR163595",
            "comparison_id": "R165700",
            "paper_id": "R163595",
            "text": "Overview of the Bacteria Biotope Task at BioNLP Shared Task 2016 this paper presents the bacteria biotope task of the bionlp shared task 2016, which follows the previous 2013 and 2011 editions. the task focuses on the extraction of the locations (biotopes and geographical places) of bacteria from pubme abstracts and the characterization of bacteria and their associated habitats with\\nrespect to reference knowledge sources (ncbi taxonomy, ontobiotope ontology). the task is motivated by the importance of the knowledge on bacteria habitats for fundamental research and applications in microbiology. the paper describes the different proposed subtasks, the corpus characteristics, the challenge organization, and the evaluation metrics. we also provide an analysis of the results obtained by participants.",
            "contribution_ids": [
                "R163597",
                "R164582",
                "R165603",
                "R165604",
                "R165855",
                "R165871"
            ]
        },
        {
            "instance_id": "R165700xR163319",
            "comparison_id": "R165700",
            "paper_id": "R163319",
            "text": "Overview of the Infectious Diseases (ID) task of BioNLP Shared Task 2011 \"this paper presents the preparation, resources, results and analysis of the infectious diseases (id) information extraction task, a main task of the bionlp shared task 2011. the id task represents an application and extension of the bionlp'09 shared task event extraction approach to full papers on infectious diseases. seven teams submitted final results to the task, with the highest-performing system achieving 56% f-score in the full task, comparable to state-of-the-art performance in the established bionlp'09 task. the results indicate that event extraction methods generalize well to new domains and full-text publications and are applicable to the extraction of events relevant to the molecular mechanisms of infectious diseases.\"",
            "contribution_ids": [
                "R163321",
                "R164438",
                "R165806",
                "R165808"
            ]
        },
        {
            "instance_id": "R165702xR163595",
            "comparison_id": "R165702",
            "paper_id": "R163595",
            "text": "Overview of the Bacteria Biotope Task at BioNLP Shared Task 2016 this paper presents the bacteria biotope task of the bionlp shared task 2016, which follows the previous 2013 and 2011 editions. the task focuses on the extraction of the locations (biotopes and geographical places) of bacteria from pubme abstracts and the characterization of bacteria and their associated habitats with\\nrespect to reference knowledge sources (ncbi taxonomy, ontobiotope ontology). the task is motivated by the importance of the knowledge on bacteria habitats for fundamental research and applications in microbiology. the paper describes the different proposed subtasks, the corpus characteristics, the challenge organization, and the evaluation metrics. we also provide an analysis of the results obtained by participants.",
            "contribution_ids": [
                "R163597",
                "R164582",
                "R165603",
                "R165604",
                "R165855",
                "R165871"
            ]
        },
        {
            "instance_id": "R165702xR163656",
            "comparison_id": "R165702",
            "paper_id": "R163656",
            "text": "PharmaCoNER: Pharmacological Substances, Compounds and proteins Named Entity Recognition track one of the biomedical entity types of relevance for medicine or biosciences are chemical compounds and drugs. the correct detection these entities is critical for other text mining applications building on them, such as adverse drug-reaction detection, medication-related fake news or drug-target extraction. although a significant effort was made to detect mentions of drugs/chemicals in english texts, so far only very limited attempts were made to recognize them in medical documents in other languages. taking into account the growing amount of medical publications and clinical records written in spanish, we have organized the first shared task on detecting drug and chemical entities in spanish medical documents. additionally, we included a clinical concept-indexing sub-track asking teams to return snomed-ct identifiers related to drugs/chemicals for a collection of documents. for this task, named pharmaconer, we generated annotation guidelines together with a corpus of 1,000 manually annotated clinical case studies. a total of 22 teams participated in the sub-track 1, (77 system runs), and 7 teams in the sub-track 2 (19 system runs). top scoring teams used sophisticated deep learning approaches yielding very competitive results with f-measures above 0.91. these results indicate that there is a real interest in promoting biomedical text mining efforts beyond english. we foresee that the pharmaconer annotation guidelines, corpus and participant systems will foster the development of new resources for clinical and biomedical text mining systems of spanish medical data.",
            "contribution_ids": [
                "R163658",
                "R164640",
                "R165689",
                "R165882"
            ]
        },
        {
            "instance_id": "R165702xR163666",
            "comparison_id": "R165702",
            "paper_id": "R163666",
            "text": "An Overview of the Active Gene Annotation Corpus and the BioNLP OST 2019 AGAC Track Tasks the active gene annotation corpus (agac) was developed to support knowledge discovery for drug repurposing. based on the corpus, the agac track of the bionlp open shared tasks 2019 was organized, to facilitate cross-disciplinary collaboration across bionlp and pharmacoinformatics communities, for drug repurposing. the agac track consists of three subtasks: 1) named entity recognition, 2) thematic relation extraction, and 3) loss of function (lof) / gain of function (gof) topic classification. the agac track was participated by five teams, of which the performance are compared and analyzed. the the results revealed a substantial room for improvement in the design of the task, which we analyzed in terms of \u201cimbalanced data\u201d, \u201cselective annotation\u201d and \u201clatent topic annotation\u201d.",
            "contribution_ids": [
                "R163668",
                "R164647",
                "R165696",
                "R165911"
            ]
        },
        {
            "instance_id": "R165702xR164455",
            "comparison_id": "R165702",
            "paper_id": "R164455",
            "text": "BioNLP Shared Task 2011 - Bacteria Biotope this paper presents the bacteria biotope task as part of the bionlp shared tasks 2011. the bacteria biotope task aims at extracting the location of bacteria from scientific web pages. bacteria location is a crucial knowledge in biology for phenotype studies. the paper details the corpus specification, the evaluation metrics, summarizes and discusses the participant results.",
            "contribution_ids": [
                "R164457",
                "R164467",
                "R165270",
                "R165466",
                "R165867",
                "R165893"
            ]
        },
        {
            "instance_id": "R165866xR163595",
            "comparison_id": "R165866",
            "paper_id": "R163595",
            "text": "Overview of the Bacteria Biotope Task at BioNLP Shared Task 2016 this paper presents the bacteria biotope task of the bionlp shared task 2016, which follows the previous 2013 and 2011 editions. the task focuses on the extraction of the locations (biotopes and geographical places) of bacteria from pubme abstracts and the characterization of bacteria and their associated habitats with\\nrespect to reference knowledge sources (ncbi taxonomy, ontobiotope ontology). the task is motivated by the importance of the knowledge on bacteria habitats for fundamental research and applications in microbiology. the paper describes the different proposed subtasks, the corpus characteristics, the challenge organization, and the evaluation metrics. we also provide an analysis of the results obtained by participants.",
            "contribution_ids": [
                "R163597",
                "R164582",
                "R165603",
                "R165604",
                "R165855",
                "R165871"
            ]
        },
        {
            "instance_id": "R165866xR141057",
            "comparison_id": "R165866",
            "paper_id": "R141057",
            "text": "Overview of the Epigenetics and Post-translational Modifications (EPI) task of BioNLP Shared Task 2011 this paper presents the preparation, resources, results and analysis of the epigenetics and post-translational modifications (epi) task, a main task of the bionlp shared task 2011. the task concerns the extraction of detailed representations of 14 protein and dna modification events, the catalysis of these reactions, and the identification of instances of negated or speculatively stated event instances. seven teams submitted final results to the epi task in the shared task, with the highest-performing system achieving 53% f-score in the full task and 69% f-score in the extraction of a simplified set of core event arguments.",
            "contribution_ids": [
                "R141059",
                "R164428",
                "R165801",
                "R165803",
                "R165891"
            ]
        },
        {
            "instance_id": "R165866xR163294",
            "comparison_id": "R165866",
            "paper_id": "R163294",
            "text": "Overview of Genia Event Task in BioNLP Shared Task 2011 the genia event task, a bio-molecular event extraction task, is arranged as one of the main tasks of bionlp shared task 2011. as its second time to be arranged for community-wide focused efforts, it aimed to measure the advance of the community since 2009, and to evaluate generalization of the technology to full text papers. after a 3-month system development period, 15 teams submitted their performance results on test cases. the results show the community has made a significant advancement in terms of both performance improvement and generalization.",
            "contribution_ids": [
                "R163296",
                "R164410",
                "R165741",
                "R165742",
                "R165743"
            ]
        },
        {
            "instance_id": "R165866xR163382",
            "comparison_id": "R165866",
            "paper_id": "R163382",
            "text": "The Genia Event Extraction Shared Task, 2013 Edition - Overview the genia event extraction task is organized for the third time, in bionlp shared task 2013. toward knowledge based construction, the task is modified in a number of points. as the final results, it received 12 submissions, among which 2 were withdrawn from the final report. this paper presents the task setting, data sets, and the final results with discussion for possible future directions.",
            "contribution_ids": [
                "R163384",
                "R164510",
                "R165814",
                "R165815",
                "R165816"
            ]
        },
        {
            "instance_id": "R165866xR164531",
            "comparison_id": "R165866",
            "paper_id": "R164531",
            "text": "BioNLP Shared Task 2013 \u00e2\u0080\u0093 An overview of the Genic Regulation Network Task the goal of the genic regulation network task (grn) is to extract a regulation network that links and integrates a v a r i e y o f m o l e a interactions between genes and proteins of the well-studied model bacterium bacillus subtilis. it is an extension of the bi task of bionlp-st\u201911. the corpus is composed of sentences selected from publicly available pubmed scientific",
            "contribution_ids": [
                "R164533",
                "R164534",
                "R165851",
                "R165902"
            ]
        },
        {
            "instance_id": "R165866xR163406",
            "comparison_id": "R165866",
            "paper_id": "R163406",
            "text": "Overview of the Cancer Genetics (CG) task of BioNLP Shared Task 2013 we present the design, preparation, results and analysis of the cancer genetics (cg) event extraction task, a main task of the bionlp shared task (st) 2013. the cg task is an information extraction task targeting the recognition of events in text, represented as structured n-ary associations of given physical entities. in addition to addressing the cancer domain, the cg task is differentiated from previous event extraction tasks in the bionlp st series in addressing a wide range of pathological processes and multiple levels of biological organization, ranging from the molecular through the cellular and organ levels up to whole organisms. final test set submissions were accepted from six teams. the highest-performing system achieved an fscore of 55.4%. this level of performance is broadly comparable with the state of the art for established molecular-level extraction tasks, demonstrating that event extraction resources and methods generalize well to higher levels of biological organization and are applicable to the analysis of scientific texts on cancer. the cg task continues as an open challenge to all interested parties, with tools and resources available from http://2013. bionlp-st.org/.",
            "contribution_ids": [
                "R163408",
                "R164522",
                "R165824",
                "R165825",
                "R165899"
            ]
        },
        {
            "instance_id": "R165916xR163499",
            "comparison_id": "R165916",
            "paper_id": "R163499",
            "text": "Overview of the Pathway Curation (PC) task of BioNLP Shared Task 2013 we present the pathway curation (pc) task, a main event extraction task of the bionlp shared task (st) 2013. the pc task concerns the automatic extraction of biomolecular reactions from text. the task setting, representation and semantics are defined with respect to pathway model standards and ontologies (sbml, biopax, sbo) and documents selected by relevance to specific model reactions. two bionlp st 2013 participants successfully completed the pc task. the highest achieved fscore, 52.8%, indicates that event extraction is a promising approach to supporting pathway curation efforts. the pc task continues as an open challenge with data, resources and tools available from http://2013.bionlp-st.org/",
            "contribution_ids": [
                "R163501",
                "R164525",
                "R165834",
                "R165835",
                "R165901"
            ]
        },
        {
            "instance_id": "R165916xR163542",
            "comparison_id": "R165916",
            "paper_id": "R163542",
            "text": "Overview of the Regulatory Network of Plant Seed Development\n            (SeeDev) Task at the BioNLP Shared Task 2016. this paper presents the seedev task of the bionlp shared task 2016. the purpose of the seedev task is the extraction from scientific articles of the descriptions of genetic and molecular mechanisms involved in seed development of the model plant, arabidopsis thaliana. the seedev task consists in the extraction of many different event types that involve a wide range of entity types so that they accurately reflect the complexity of the biological mechanisms. the corpus is composed of paragraphs selected from the full-texts of relevant scientific articles. in this paper, we describe the organization of the seedev task, the corpus characteristics, and the metrics used for the evaluation of participant systems. we analyze and discuss the final results of the seven participant systems to the test. the best f-score is 0.432, which is similar to the scores achieved in similar tasks on molecular biology.",
            "contribution_ids": [
                "R163544",
                "R164587",
                "R165862",
                "R165908"
            ]
        },
        {
            "instance_id": "R165916xR163702",
            "comparison_id": "R165916",
            "paper_id": "R163702",
            "text": "Bacteria Biotope at BioNLP Open Shared Tasks 2019 this paper presents the fourth edition of the bacteria biotope task at bionlp open shared tasks 2019. the task focuses on the extraction of the locations and phenotypes of microorganisms from pubmed abstracts and full-text excerpts, and the characterization of these entities with respect to reference knowledge sources (ncbi taxonomy, ontobiotope ontology). the task is motivated by the importance of the knowledge on biodiversity for fundamental research and applications in microbiology. the paper describes the different proposed subtasks, the corpus characteristics, and the challenge organization. we also provide an analysis of the results obtained by participants, and inspect the evolution of the results since the last edition in 2016.",
            "contribution_ids": [
                "R163704",
                "R165699",
                "R165701",
                "R165886",
                "R165914"
            ]
        },
        {
            "instance_id": "R165916xR163666",
            "comparison_id": "R165916",
            "paper_id": "R163666",
            "text": "An Overview of the Active Gene Annotation Corpus and the BioNLP OST 2019 AGAC Track Tasks the active gene annotation corpus (agac) was developed to support knowledge discovery for drug repurposing. based on the corpus, the agac track of the bionlp open shared tasks 2019 was organized, to facilitate cross-disciplinary collaboration across bionlp and pharmacoinformatics communities, for drug repurposing. the agac track consists of three subtasks: 1) named entity recognition, 2) thematic relation extraction, and 3) loss of function (lof) / gain of function (gof) topic classification. the agac track was participated by five teams, of which the performance are compared and analyzed. the the results revealed a substantial room for improvement in the design of the task, which we analyzed in terms of \u201cimbalanced data\u201d, \u201cselective annotation\u201d and \u201clatent topic annotation\u201d.",
            "contribution_ids": [
                "R163668",
                "R164647",
                "R165696",
                "R165911"
            ]
        },
        {
            "instance_id": "R165916xR164551",
            "comparison_id": "R165916",
            "paper_id": "R164551",
            "text": "BioNLP shared Task 2013 \u00e2\u0080\u0093 An Overview of the Bacteria Biotope Task this paper presents the bacteria biotope task of the bionlp shared task 2013, which follows bionlp-st-11. the bacteria biotope task aims to extract the location of bacteria from scientific web pages and to characterize these locations with respect to the ontobiotope ontology. bacteria locations are crucil knowledge in biology for phenotype studies. the paper details the corpus specifications, the evaluation metrics, and it summarizes and discusses the participant results.",
            "contribution_ids": [
                "R164553",
                "R164575",
                "R165593",
                "R165905"
            ]
        },
        {
            "instance_id": "R165916xR164478",
            "comparison_id": "R165916",
            "paper_id": "R164478",
            "text": "BioNLP Shared Task 2011 \u00e2\u0080\u0093 Bacteria Gene Interactions and Renaming \"we present two related tasks of the bionlp shared tasks 2011: bacteria gene renaming (rename) and bacteria gene interactions (gi). we detail the objectives, the corpus specification, the evaluation metrics, and we summarize the participants' results. both issued from pubmed scientific literature abstracts, the rename task aims at extracting gene name synonyms, and the gi task aims at extracting genic interaction events, mainly about gene transcriptional regulations in bacteria.\"",
            "contribution_ids": [
                "R164480",
                "R164481",
                "R164484",
                "R164485",
                "R165896"
            ]
        },
        {
            "instance_id": "R165916xR141057",
            "comparison_id": "R165916",
            "paper_id": "R141057",
            "text": "Overview of the Epigenetics and Post-translational Modifications (EPI) task of BioNLP Shared Task 2011 this paper presents the preparation, resources, results and analysis of the epigenetics and post-translational modifications (epi) task, a main task of the bionlp shared task 2011. the task concerns the extraction of detailed representations of 14 protein and dna modification events, the catalysis of these reactions, and the identification of instances of negated or speculatively stated event instances. seven teams submitted final results to the epi task in the shared task, with the highest-performing system achieving 53% f-score in the full task and 69% f-score in the extraction of a simplified set of core event arguments.",
            "contribution_ids": [
                "R141059",
                "R164428",
                "R165801",
                "R165803",
                "R165891"
            ]
        },
        {
            "instance_id": "R166240xR166181",
            "comparison_id": "R166240",
            "paper_id": "R166181",
            "text": "Multilingual named entity recognition using parallel data and metadata from wikipedia in this paper we propose a method to automatically label multi-lingual data with named entity tags. we build on prior work utilizing wikipedia metadata and show how to effectively combine the weak annotations stemming from wikipedia metadata with information obtained through english-foreign language parallel wikipedia sentences. the combination is achieved using a novel semi-crf model for foreign sentence tagging in the context of a parallel english sentence. the model outperforms both standard annotation projection methods and methods based solely on wikipedia metadata.",
            "contribution_ids": [
                "R166183"
            ]
        },
        {
            "instance_id": "R166240xR163186",
            "comparison_id": "R166240",
            "paper_id": "R163186",
            "text": "WikiNEuRal: Combined Neural and Knowledge-based Silver Data Creation for Multilingual NER multilingual named entity recognition (ner) is a key intermediate task which is needed in many areas of nlp. in this paper, we address the well-known issue of data scarcity in ner, especially relevant when moving to a multilingual scenario, and go beyond current approaches to the creation of multilingual silver data for the task. we exploit the texts of wikipedia and introduce a new methodology based on the effective combination of knowledge-based approaches and neural models, together with a novel domain adaptation technique, to produce high-quality training corpora for ner. we evaluate our datasets extensively on standard benchmarks for ner, yielding substantial improvements of up to 6 span-based f1-score points over previous state-of-the-art systems for data creation.",
            "contribution_ids": [
                "R163188"
            ]
        },
        {
            "instance_id": "R166240xR166184",
            "comparison_id": "R166240",
            "paper_id": "R166184",
            "text": "Mining Wiki Resources for Multilingual Named Entity Recognition \"in this paper, we describe a system by which the multilingual characteristics of wikipedia can be utilized to annotate a large corpus of text with named entity recognition (ner) tags requiring minimal human intervention and no linguistic expertise. this process, though of value in languages for which resources exist, is particularly useful for less commonly taught languages. we show how the wikipedia format can be used to identify possible named entities and discuss in detail the process by which we use the category structure inherent to wikipedia to determine the named entity type of a proposed entity. we further describe the methods by which english language data can be used to bootstrap the ner process in other languages. we demonstrate the system by using the generated corpus as training sets for a variant of bbn's identifinder in french, ukrainian, spanish, polish, russian, and portuguese, achieving overall f-scores as high as 84.7% on independent, human-annotated corpora, comparable to a system trained on up to 40,000 words of human-annotated newswire.\"",
            "contribution_ids": [
                "R166186"
            ]
        },
        {
            "instance_id": "R166240xR166235",
            "comparison_id": "R166240",
            "paper_id": "R166235",
            "text": "WEXEA: Wikipedia EXhaustive Entity Annotation building predictive models for information extraction from text, such as named entity recognition or the extraction of semantic relationships between named entities in text, requires a large corpus of annotated text. wikipedia is often used as a corpus for these tasks where the annotation is a named entity linked by a hyperlink to its article. however, editors on wikipedia are only expected to link these mentions in order to help the reader to understand the content, but are discouraged from adding links that do not add any benefit for understanding an article. therefore, many mentions of popular entities (such as countries or popular events in history), or previously linked articles, as well as the article\u2019s entity itself, are not linked. in this paper, we discuss wexea, a wikipedia exhaustive entity annotation system, to create a text corpus based on wikipedia with exhaustive annotations of entity mentions, i.e. linking all mentions of entities to their corresponding articles. this results in a huge potential for additional annotations that can be used for downstream nlp tasks, such as relation extraction. we show that our annotations are useful for creating distantly supervised datasets for this task. furthermore, we publish all code necessary to derive a corpus from a raw wikipedia dump, so that it can be reproduced by everyone.",
            "contribution_ids": [
                "R166237"
            ]
        },
        {
            "instance_id": "R166240xR165926",
            "comparison_id": "R166240",
            "paper_id": "R165926",
            "text": "Transforming Wikipedia into Named Entity Training Data statistical named entity recognisers require costly hand-labelled training data and, as a result, most existing corpora are small. we exploit wikipedia to create a massive corpus of named entity annotated text. we transform wikipedia\u2019s links into named entity annotations by classifying the target articles into common entity types (e.g. person, organisation and location). comparing to muc, conll and bbn corpora, wikipedia generally performs better than other cross-corpus train/test pairs.",
            "contribution_ids": [
                "R165928"
            ]
        },
        {
            "instance_id": "R166240xR166174",
            "comparison_id": "R166240",
            "paper_id": "R166174",
            "text": "POLYGLOT-NER: Massive Multilingual Named Entity Recognition the increasing diversity of languages used on the web introduces a new level of complexity to information retrieval (ir) systems. we can no longer assume that textual content is written in one language or even the same language family. in this paper, we demonstrate how to build massive multilingual annotators with minimal human expertise and intervention. we describe a system that builds named entity recognition (ner) annotators for 40 major languages using wikipedia and freebase. our approach does not require ner human annotated datasets or language specific resources like treebanks, parallel corpora, and orthographic rules. the novelty of approach lies therein - using only language agnostic techniques, while achieving competitive performance. \\nour method learns distributed word representations (word embeddings) which encode semantic and syntactic features of words in each language. then, we automatically generate datasets from wikipedia link structure and freebase attributes. finally, we apply two preprocessing stages (oversampling and exact surface form matching) which do not require any linguistic expertise. \\nour evaluation is two fold: first, we demonstrate the system performance on human annotated datasets. second, for languages where no gold-standard benchmarks are available, we propose a new method, distant evaluation, based on statistical machine translation.",
            "contribution_ids": [
                "R166176"
            ]
        },
        {
            "instance_id": "R166240xR163190",
            "comparison_id": "R166240",
            "paper_id": "R163190",
            "text": "Cross-lingual Name Tagging and Linking for 282 Languages the ambitious goal of this work is to develop a cross-lingual name tagging and linking framework for 282 languages that exist in wikipedia. given a document in any of these languages, our framework is able to identify name mentions, assign a coarse-grained or fine-grained type to each mention, and link it to an english knowledge base (kb) if it is linkable. we achieve this goal by performing a series of new kb mining methods: generating \u201csilver-standard\u201d annotations by transferring annotations from english to other languages through cross-lingual links and kb properties, refining annotations through self-training and topic selection, deriving language-specific morphology features from anchor links, and mining word translation pairs from cross-lingual links. both name tagging and linking results for 282 languages are promising on wikipedia data and on-wikipedia data.",
            "contribution_ids": [
                "R163192"
            ]
        },
        {
            "instance_id": "R172155xR171917",
            "comparison_id": "R172155",
            "paper_id": "R171917",
            "text": "Web services-based text-mining demonstrates broad impacts for interoperability and process simplification \"the critical assessment of information extraction systems in biology (biocreative) challenge evaluation tasks collectively represent a community-wide effort to evaluate a variety of text-mining and information extraction systems applied to the biological domain. the biocreative iv workshop included five independent subject areas, including track 3, which focused on named-entity recognition (ner) for the comparative toxicogenomics database (ctd; http://ctdbase.org). previously, ctd had organized document ranking and ner-related tasks for the biocreative workshop 2012; a key finding of that effort was that interoperability and integration complexity were major impediments to the direct application of the systems to ctd's text-mining pipeline. this underscored a prevailing problem with software integration efforts. major interoperability-related issues included lack of process modularity, operating system incompatibility, tool configuration complexity and lack of standardization of high-level inter-process communications. one approach to potentially mitigate interoperability and general integration issues is the use of web services to abstract implementation details; rather than integrating ner tools directly, http-based calls from ctd's asynchronous, batch-oriented text-mining pipeline could be made to remote ner web services for recognition of specific biological terms using bioc (an emerging family of xml formats) for inter-process communications. to test this concept, participating groups developed representational state transfer /bioc-compliant web services tailored to ctd's ner requirements. participants were provided with a comprehensive set of training materials. ctd evaluated results obtained from the remote web service-based urls against a test data set of 510 manually curated scientific articles. twelve groups participated in the challenge. recall, precision, balanced f-scores and response times were calculated. top balanced f-scores for gene, chemical and disease ner were 61, 74 and 51%, respectively. response times ranged from fractions-of-a-second to over a minute per article. we present a description of the challenge and summary of results, demonstrating how curation groups can effectively use interoperable ner technologies to simplify text-mining pipeline implementation. database url: http://ctdbase.org/\"",
            "contribution_ids": [
                "R171919"
            ]
        },
        {
            "instance_id": "R172155xR162474",
            "comparison_id": "R172155",
            "paper_id": "R162474",
            "text": "Assessing the state of the art in biomedical relation extraction: overview of the BioCreative V chemical-disease relation (CDR) task manually curating chemicals, diseases and their relationships is significantly important to biomedical research, but it is plagued by its high cost and the rapid growth of the biomedical literature. in recent years, there has been a growing interest in developing computational approaches for automatic chemical-disease relation (cdr) extraction. despite these attempts, the lack of a comprehensive benchmarking dataset has limited the comparison of different techniques in order to assess and advance the current state-of-the-art. to this end, we organized a challenge task through biocreative v to automatically extract cdrs from the literature. we designed two challenge tasks: disease named entity recognition (dner) and chemical-induced disease (cid) relation extraction. to assist system development and assessment, we created a large annotated text corpus that consisted of human annotations of chemicals, diseases and their interactions from 1500 pubmed articles. 34 teams worldwide participated in the cdr task: 16 (dner) and 18 (cid). the best systems achieved an f-score of 86.46% for the dner task\u2014a result that approaches the human inter-annotator agreement (0.8875)\u2014and an f-score of 57.03% for the cid task, the highest results ever reported for such tasks. when combining team results via machine learning, the ensemble system was able to further improve over the best team results by achieving 88.89% and 62.80% in f-score for the dner and cid task, respectively. additionally, another novel aspect of our evaluation is to test each participating system\u2019s ability to return real-time results: the average response time for each team\u2019s dner and cid web service systems were 5.6 and 9.3\\u2009s, respectively. most teams used hybrid systems for their submissions based on machining learning. given the level of participation and results, we found our task to be successful in engaging the text-mining research community, producing a large annotated corpus and improving the results of automatic disease recognition and cdr extraction. database url: http://www.biocreative.org/tasks/biocreative-v/track-3-cdr/",
            "contribution_ids": [
                "R162476",
                "R172005",
                "R172006"
            ]
        },
        {
            "instance_id": "R172155xR162349",
            "comparison_id": "R172155",
            "paper_id": "R162349",
            "text": "BioCreAtIvE Task 1A: gene mention finding evaluation abstract \\n \\n background \\n the biological research literature is a major repository of knowledge. as the amount of literature increases, it will get harder to find the information of interest on a particular topic. there has been an increasing amount of work on text mining this literature, but comparing this work is hard because of a lack of standards for making comparisons. to address this, we worked with colleagues at the protein design group, cnb-csic, madrid to develop biocreative (critical assessment for information extraction in biology), an open common evaluation of systems on a number of biological text mining tasks. we report here on task 1a, which deals with finding mentions of genes and related entities in text. \"finding mentions\" is a basic task, which can be used as a building block for other text mining tasks. the task makes use of data and evaluation software provided by the (us) national center for biotechnology information (ncbi). \\n \\n \\n results \\n 15 teams took part in task 1a. a number of teams achieved scores over 80% f-measure (balanced precision and recall). the teams that tried to use their task 1a systems to help on other biocreative tasks reported mixed results. \\n \\n \\n conclusion \\n the 80% plus f-measure results are good, but still somewhat lag the best scores achieved in some other domains such as newswire, due in part to the complexity and length of gene names, compared to person or organization names in newswire. \\n",
            "contribution_ids": [
                "R162350",
                "R166331"
            ]
        },
        {
            "instance_id": "R172689xR145732",
            "comparison_id": "R172689",
            "paper_id": "R145732",
            "text": "Tribological Study on Tailored-Formed Axial Bearing Washers to enhance tribological contacts under cyclic load, high performance materials are required. utilizing the same high-strength material for the whole machine element is not resource-efficient. in order to manufacture machine elements with extended functionality and specific properties, a combination of different materials can be used in a single component for a more efficient material utilization. by combining different joining techniques with subsequent forming, multi-material or tailored components can be manufactured. to reduce material costs and energy consumption during the component service life, a less expensive lightweight material should be used for regions remote from the highly stressed zones. the scope is not only to obtain the desired shape and dimensions for the finishing process, but also to improve properties like the bond strength between different materials and the microscopic structure of the material. the multi-material approach can be applied to all components requiring different properties in separate component regions such as shafts, bearings or bushes. the current study exemplarily presents the process route for the production of an axial bearing washer by means of tailored forming technology. the bearing washers were chosen to fit axial roller bearings (type 81212). the manufacturing process starts with the laser wire cladding of a hard facing made of martensitic chromium silicon steel (1.4718) on a base substrate of s235 (1.0038) steel. subsequently, the bearing washers are forged. after finishing, the surfaces of the bearing washers were tested in thrust bearings on an fe-8 test rig. the operational test of the bearings consists in a run-in phase at 250 rpm. a bearing failure is determined by a condition monitoring system. before and after this, the bearings were inspected by optical and ultrasonic microscopy in order to examine whether the bond of the coat is resistant against rolling contact fatigue. the feasibility of the approach could be proven by endurance test. the joining zone was able to withstand the rolling contact stresses and the bearing failed due to material-induced fatigue with high cycle stability.",
            "contribution_ids": [
                "R145734"
            ]
        },
        {
            "instance_id": "R172689xR145720",
            "comparison_id": "R172689",
            "paper_id": "R145720",
            "text": "Investigations on Tailored Forming of AISI 52100 as Rolling Bearing Raceway hybrid cylindrical roller thrust bearing washers of type 81212 were manufactured by tailored forming. an aisi 1022m base material, featuring a sufficient strength for structural loads, was cladded with the bearing steel aisi 52100 by plasma transferred arc welding (pta). though aisi 52100 is generally regarded as non-weldable, it could be applied as a cladding material by adjusting pta parameters. the cladded parts were investigated after each individual process step and subsequently tested under rolling contact load. welding defects that could not be completely eliminated by the subsequent hot forming were characterized by means of scanning acoustic microscopy and micrographs. below the surface, pores with a typical size of ten \u00b5m were found to a depth of about 0.45 mm. in the material transition zone and between individual weld seams, larger voids were observed. grinding of the surface after heat treatment caused compressive residual stresses near the surface with a relatively small depth. fatigue tests were carried out on an fe8 test rig. eighty-two percent of the calculated rating life for conventional bearings was achieved. a high failure slope of the weibull regression was determined. a relationship between the weld defects and the fatigue behavior is likely.",
            "contribution_ids": [
                "R145728"
            ]
        },
        {
            "instance_id": "R172689xR171846",
            "comparison_id": "R172689",
            "paper_id": "R171846",
            "text": "Investigation of the material combination 20MnCr5 and X45CrSi9-3 in the Tailored Forming of shafts with bearing seats abstract the tailored forming process chain is used to manufacture hybrid components and consists of a joining process or additive manufacturing for various materials (e.g. deposition welding), subsequent hot forming, machining and heat treatment. in this way, components can be produced with materials adapted to the load case. for this paper, hybrid shafts are produced by deposition welding of a cladding made of x45crsi9-3 onto a workpiece made from 20mncr5. the hybrid shafts are then formed by means of cross-wedge rolling. it is investigated, how the thickness of the cladding and the type of cooling after hot forming (in air or in water) affect the properties of the cladding. the hybrid shafts are formed without layer separation. however, slight core loosening occurres in the area of the bearing seat due to the mannesmann effect. the microhardness of the cladding is only slightly effected by the cooling strategy, while the microhardness of the base material is significantly higher in water cooled shafts. the microstructure of the cladding after both cooling strategies consists mainly of martensite. in the base material, air cooling results in a mainly ferritic microstructure with grains of ferrite-pearlite. quenching in water results in a microstructure containing mainly martensite.",
            "contribution_ids": [
                "R171849",
                "R172160",
                "R172247",
                "R172322"
            ]
        },
        {
            "instance_id": "R172886xR145729",
            "comparison_id": "R172886",
            "paper_id": "R145729",
            "text": "Manufacturing and Evaluation of Multi-Material Axial-Bearing Washers by Tailored Forming components subject to rolling contact fatigue, such as gears and rolling bearings, are among the fundamental machine elements in mechanical and vehicle engineering. rolling bearings are generally not designed to be fatigue-resistant, as the necessary oversizing is not technically and economically marketable. in order to improve the load-bearing capacity, resource efficiency and application possibilities of rolling bearings and other possible multi-material solid components, a new process chain was developed at leibniz university hannover as a part of the collaborative research centre 1153 \u201ctailored forming\u201d. semi-finished products, already joined before the forming process, are used here to allow a further optimisation of joint quality by forming and finishing. in this paper, a plasma-powder-deposition welding process is presented, which enables precise material deposition and control of the welding depth. for this study, bearing washers (serving as rolling bearing raceways) of a cylindrical roller thrust bearing, similar to type 81212 with a multi-layer structure, were manufactured. a previously non-weldable high-performance material, steel aisi 5140, was used as the cladding layer. depending on the degree of forming, grain-refinement within the welded material was achieved by thermo-mechanical treatment of the joining zone during the forming process. this grain-refinements lead to an improvement of the mechanical properties and thus, to a higher lifetime for washers of an axial cylindrical roller bearing, which were examined as an exemplary component on a fatigue test bench. to evaluate the bearing washers, the results of the bearing tests were compared with industrial bearings and deposition welded axial-bearing washers without subsequent forming. in addition, the bearing washers were analysed micro-tribologically and by scanning acoustic microscopy both after welding and after the forming process. nano-scratch tests were carried out on the bearing washers to analyse the layer properties. together with the results of additional microscopic images of the surface and cross-sections, the causes of failure due to fatigue and wear were identified.",
            "contribution_ids": [
                "R145731"
            ]
        },
        {
            "instance_id": "R172886xR145720",
            "comparison_id": "R172886",
            "paper_id": "R145720",
            "text": "Investigations on Tailored Forming of AISI 52100 as Rolling Bearing Raceway hybrid cylindrical roller thrust bearing washers of type 81212 were manufactured by tailored forming. an aisi 1022m base material, featuring a sufficient strength for structural loads, was cladded with the bearing steel aisi 52100 by plasma transferred arc welding (pta). though aisi 52100 is generally regarded as non-weldable, it could be applied as a cladding material by adjusting pta parameters. the cladded parts were investigated after each individual process step and subsequently tested under rolling contact load. welding defects that could not be completely eliminated by the subsequent hot forming were characterized by means of scanning acoustic microscopy and micrographs. below the surface, pores with a typical size of ten \u00b5m were found to a depth of about 0.45 mm. in the material transition zone and between individual weld seams, larger voids were observed. grinding of the surface after heat treatment caused compressive residual stresses near the surface with a relatively small depth. fatigue tests were carried out on an fe8 test rig. eighty-two percent of the calculated rating life for conventional bearings was achieved. a high failure slope of the weibull regression was determined. a relationship between the weld defects and the fatigue behavior is likely.",
            "contribution_ids": [
                "R145728"
            ]
        },
        {
            "instance_id": "R172886xR162731",
            "comparison_id": "R172886",
            "paper_id": "R162731",
            "text": "Cross-wedge rolling of PTA-welded hybrid steel billets with rolling bearing steel and hard material coatings within the collaborative research centre 1153 \u201ctailored forming\u201c a process chain for the manufacturing of hybrid high performance components is developed. exemplary process steps consist of deposit welding of high performance steel on low-cost steel, pre-shaping by cross-wedge rolling and finishing by milling.hard material coatings such as stellite 6 or delcrome 253 are used as wear or corrosion protection coatings in industrial applications. scientists of the institute of material science welded these hard material alloys onto a base material, in this case c22.8, to create a hybrid workpiece. scientists of the institut fur integrierte produktion hannover have shown that these hybrid workpieces can be formed without defects (e.g. detachment of the coating) by cross-wedge rolling. after forming, the properties of the coatings are retained or in some cases even improved (e.g. the transition zone between base material and coating). by adjustments in the welding process, it was possible to apply the 100cr6 rolling bearing steel, as of now declared as non-weldable, on the low-cost steel c22.8. 100cr6 was formed afterwards in its hybrid bonding state with c22.8 by cross-wedge rolling, thus a component-integrated bearing seat was produced. even after welding and forming, the rolling bearing steel coating could still be quench-hardened to a hardness of over 60 hrc. this paper shows the potential of forming hybrid billets to tailored parts. since industrially available standard materials can be used for hard material coatings by this approach, even though they are not weldable by conventional methods, it is not necessary to use expensive, for welding designed materials to implement a hybrid component concept.within the collaborative research centre 1153 \u201ctailored forming\u201c a process chain for the manufacturing of hybrid high performance components is developed. exemplary process steps consist of deposit welding of high performance steel on low-cost steel, pre-shaping by cross-wedge rolling and finishing by milling.hard material coatings such as stellite 6 or delcrome 253 are used as wear or corrosion protection coatings in industrial applications. scientists of the institute of material science welded these hard material alloys onto a base material, in this case c22.8, to create a hybrid workpiece. scientists of the institut fur integrierte produktion hannover have shown that these hybrid workpieces can be formed without defects (e.g. detachment of the coating) by cross-wedge rolling. after forming, the properties of the coatings are retained or in some cases even improved (e.g. the transition zone between base material and coating). by adjustments in the welding process, it was possible to apply the 100cr6 ro...",
            "contribution_ids": [
                "R162733",
                "R162788",
                "R162790"
            ]
        },
        {
            "instance_id": "R172927xR162731",
            "comparison_id": "R172927",
            "paper_id": "R162731",
            "text": "Cross-wedge rolling of PTA-welded hybrid steel billets with rolling bearing steel and hard material coatings within the collaborative research centre 1153 \u201ctailored forming\u201c a process chain for the manufacturing of hybrid high performance components is developed. exemplary process steps consist of deposit welding of high performance steel on low-cost steel, pre-shaping by cross-wedge rolling and finishing by milling.hard material coatings such as stellite 6 or delcrome 253 are used as wear or corrosion protection coatings in industrial applications. scientists of the institute of material science welded these hard material alloys onto a base material, in this case c22.8, to create a hybrid workpiece. scientists of the institut fur integrierte produktion hannover have shown that these hybrid workpieces can be formed without defects (e.g. detachment of the coating) by cross-wedge rolling. after forming, the properties of the coatings are retained or in some cases even improved (e.g. the transition zone between base material and coating). by adjustments in the welding process, it was possible to apply the 100cr6 rolling bearing steel, as of now declared as non-weldable, on the low-cost steel c22.8. 100cr6 was formed afterwards in its hybrid bonding state with c22.8 by cross-wedge rolling, thus a component-integrated bearing seat was produced. even after welding and forming, the rolling bearing steel coating could still be quench-hardened to a hardness of over 60 hrc. this paper shows the potential of forming hybrid billets to tailored parts. since industrially available standard materials can be used for hard material coatings by this approach, even though they are not weldable by conventional methods, it is not necessary to use expensive, for welding designed materials to implement a hybrid component concept.within the collaborative research centre 1153 \u201ctailored forming\u201c a process chain for the manufacturing of hybrid high performance components is developed. exemplary process steps consist of deposit welding of high performance steel on low-cost steel, pre-shaping by cross-wedge rolling and finishing by milling.hard material coatings such as stellite 6 or delcrome 253 are used as wear or corrosion protection coatings in industrial applications. scientists of the institute of material science welded these hard material alloys onto a base material, in this case c22.8, to create a hybrid workpiece. scientists of the institut fur integrierte produktion hannover have shown that these hybrid workpieces can be formed without defects (e.g. detachment of the coating) by cross-wedge rolling. after forming, the properties of the coatings are retained or in some cases even improved (e.g. the transition zone between base material and coating). by adjustments in the welding process, it was possible to apply the 100cr6 ro...",
            "contribution_ids": [
                "R162733",
                "R162788",
                "R162790"
            ]
        },
        {
            "instance_id": "R172927xR171846",
            "comparison_id": "R172927",
            "paper_id": "R171846",
            "text": "Investigation of the material combination 20MnCr5 and X45CrSi9-3 in the Tailored Forming of shafts with bearing seats abstract the tailored forming process chain is used to manufacture hybrid components and consists of a joining process or additive manufacturing for various materials (e.g. deposition welding), subsequent hot forming, machining and heat treatment. in this way, components can be produced with materials adapted to the load case. for this paper, hybrid shafts are produced by deposition welding of a cladding made of x45crsi9-3 onto a workpiece made from 20mncr5. the hybrid shafts are then formed by means of cross-wedge rolling. it is investigated, how the thickness of the cladding and the type of cooling after hot forming (in air or in water) affect the properties of the cladding. the hybrid shafts are formed without layer separation. however, slight core loosening occurres in the area of the bearing seat due to the mannesmann effect. the microhardness of the cladding is only slightly effected by the cooling strategy, while the microhardness of the base material is significantly higher in water cooled shafts. the microstructure of the cladding after both cooling strategies consists mainly of martensite. in the base material, air cooling results in a mainly ferritic microstructure with grains of ferrite-pearlite. quenching in water results in a microstructure containing mainly martensite.",
            "contribution_ids": [
                "R171849",
                "R172160",
                "R172247",
                "R172322"
            ]
        },
        {
            "instance_id": "R172927xR145732",
            "comparison_id": "R172927",
            "paper_id": "R145732",
            "text": "Tribological Study on Tailored-Formed Axial Bearing Washers to enhance tribological contacts under cyclic load, high performance materials are required. utilizing the same high-strength material for the whole machine element is not resource-efficient. in order to manufacture machine elements with extended functionality and specific properties, a combination of different materials can be used in a single component for a more efficient material utilization. by combining different joining techniques with subsequent forming, multi-material or tailored components can be manufactured. to reduce material costs and energy consumption during the component service life, a less expensive lightweight material should be used for regions remote from the highly stressed zones. the scope is not only to obtain the desired shape and dimensions for the finishing process, but also to improve properties like the bond strength between different materials and the microscopic structure of the material. the multi-material approach can be applied to all components requiring different properties in separate component regions such as shafts, bearings or bushes. the current study exemplarily presents the process route for the production of an axial bearing washer by means of tailored forming technology. the bearing washers were chosen to fit axial roller bearings (type 81212). the manufacturing process starts with the laser wire cladding of a hard facing made of martensitic chromium silicon steel (1.4718) on a base substrate of s235 (1.0038) steel. subsequently, the bearing washers are forged. after finishing, the surfaces of the bearing washers were tested in thrust bearings on an fe-8 test rig. the operational test of the bearings consists in a run-in phase at 250 rpm. a bearing failure is determined by a condition monitoring system. before and after this, the bearings were inspected by optical and ultrasonic microscopy in order to examine whether the bond of the coat is resistant against rolling contact fatigue. the feasibility of the approach could be proven by endurance test. the joining zone was able to withstand the rolling contact stresses and the bearing failed due to material-induced fatigue with high cycle stability.",
            "contribution_ids": [
                "R145734"
            ]
        },
        {
            "instance_id": "R175013xR171846",
            "comparison_id": "R175013",
            "paper_id": "R171846",
            "text": "Investigation of the material combination 20MnCr5 and X45CrSi9-3 in the Tailored Forming of shafts with bearing seats abstract the tailored forming process chain is used to manufacture hybrid components and consists of a joining process or additive manufacturing for various materials (e.g. deposition welding), subsequent hot forming, machining and heat treatment. in this way, components can be produced with materials adapted to the load case. for this paper, hybrid shafts are produced by deposition welding of a cladding made of x45crsi9-3 onto a workpiece made from 20mncr5. the hybrid shafts are then formed by means of cross-wedge rolling. it is investigated, how the thickness of the cladding and the type of cooling after hot forming (in air or in water) affect the properties of the cladding. the hybrid shafts are formed without layer separation. however, slight core loosening occurres in the area of the bearing seat due to the mannesmann effect. the microhardness of the cladding is only slightly effected by the cooling strategy, while the microhardness of the base material is significantly higher in water cooled shafts. the microstructure of the cladding after both cooling strategies consists mainly of martensite. in the base material, air cooling results in a mainly ferritic microstructure with grains of ferrite-pearlite. quenching in water results in a microstructure containing mainly martensite.",
            "contribution_ids": [
                "R171849",
                "R172160",
                "R172247",
                "R172322"
            ]
        },
        {
            "instance_id": "R175013xR145720",
            "comparison_id": "R175013",
            "paper_id": "R145720",
            "text": "Investigations on Tailored Forming of AISI 52100 as Rolling Bearing Raceway hybrid cylindrical roller thrust bearing washers of type 81212 were manufactured by tailored forming. an aisi 1022m base material, featuring a sufficient strength for structural loads, was cladded with the bearing steel aisi 52100 by plasma transferred arc welding (pta). though aisi 52100 is generally regarded as non-weldable, it could be applied as a cladding material by adjusting pta parameters. the cladded parts were investigated after each individual process step and subsequently tested under rolling contact load. welding defects that could not be completely eliminated by the subsequent hot forming were characterized by means of scanning acoustic microscopy and micrographs. below the surface, pores with a typical size of ten \u00b5m were found to a depth of about 0.45 mm. in the material transition zone and between individual weld seams, larger voids were observed. grinding of the surface after heat treatment caused compressive residual stresses near the surface with a relatively small depth. fatigue tests were carried out on an fe8 test rig. eighty-two percent of the calculated rating life for conventional bearings was achieved. a high failure slope of the weibull regression was determined. a relationship between the weld defects and the fatigue behavior is likely.",
            "contribution_ids": [
                "R145728"
            ]
        },
        {
            "instance_id": "R175013xR162731",
            "comparison_id": "R175013",
            "paper_id": "R162731",
            "text": "Cross-wedge rolling of PTA-welded hybrid steel billets with rolling bearing steel and hard material coatings within the collaborative research centre 1153 \u201ctailored forming\u201c a process chain for the manufacturing of hybrid high performance components is developed. exemplary process steps consist of deposit welding of high performance steel on low-cost steel, pre-shaping by cross-wedge rolling and finishing by milling.hard material coatings such as stellite 6 or delcrome 253 are used as wear or corrosion protection coatings in industrial applications. scientists of the institute of material science welded these hard material alloys onto a base material, in this case c22.8, to create a hybrid workpiece. scientists of the institut fur integrierte produktion hannover have shown that these hybrid workpieces can be formed without defects (e.g. detachment of the coating) by cross-wedge rolling. after forming, the properties of the coatings are retained or in some cases even improved (e.g. the transition zone between base material and coating). by adjustments in the welding process, it was possible to apply the 100cr6 rolling bearing steel, as of now declared as non-weldable, on the low-cost steel c22.8. 100cr6 was formed afterwards in its hybrid bonding state with c22.8 by cross-wedge rolling, thus a component-integrated bearing seat was produced. even after welding and forming, the rolling bearing steel coating could still be quench-hardened to a hardness of over 60 hrc. this paper shows the potential of forming hybrid billets to tailored parts. since industrially available standard materials can be used for hard material coatings by this approach, even though they are not weldable by conventional methods, it is not necessary to use expensive, for welding designed materials to implement a hybrid component concept.within the collaborative research centre 1153 \u201ctailored forming\u201c a process chain for the manufacturing of hybrid high performance components is developed. exemplary process steps consist of deposit welding of high performance steel on low-cost steel, pre-shaping by cross-wedge rolling and finishing by milling.hard material coatings such as stellite 6 or delcrome 253 are used as wear or corrosion protection coatings in industrial applications. scientists of the institute of material science welded these hard material alloys onto a base material, in this case c22.8, to create a hybrid workpiece. scientists of the institut fur integrierte produktion hannover have shown that these hybrid workpieces can be formed without defects (e.g. detachment of the coating) by cross-wedge rolling. after forming, the properties of the coatings are retained or in some cases even improved (e.g. the transition zone between base material and coating). by adjustments in the welding process, it was possible to apply the 100cr6 ro...",
            "contribution_ids": [
                "R162733",
                "R162788",
                "R162790"
            ]
        },
        {
            "instance_id": "R175019xR145720",
            "comparison_id": "R175019",
            "paper_id": "R145720",
            "text": "Investigations on Tailored Forming of AISI 52100 as Rolling Bearing Raceway hybrid cylindrical roller thrust bearing washers of type 81212 were manufactured by tailored forming. an aisi 1022m base material, featuring a sufficient strength for structural loads, was cladded with the bearing steel aisi 52100 by plasma transferred arc welding (pta). though aisi 52100 is generally regarded as non-weldable, it could be applied as a cladding material by adjusting pta parameters. the cladded parts were investigated after each individual process step and subsequently tested under rolling contact load. welding defects that could not be completely eliminated by the subsequent hot forming were characterized by means of scanning acoustic microscopy and micrographs. below the surface, pores with a typical size of ten \u00b5m were found to a depth of about 0.45 mm. in the material transition zone and between individual weld seams, larger voids were observed. grinding of the surface after heat treatment caused compressive residual stresses near the surface with a relatively small depth. fatigue tests were carried out on an fe8 test rig. eighty-two percent of the calculated rating life for conventional bearings was achieved. a high failure slope of the weibull regression was determined. a relationship between the weld defects and the fatigue behavior is likely.",
            "contribution_ids": [
                "R145728"
            ]
        },
        {
            "instance_id": "R175019xR162731",
            "comparison_id": "R175019",
            "paper_id": "R162731",
            "text": "Cross-wedge rolling of PTA-welded hybrid steel billets with rolling bearing steel and hard material coatings within the collaborative research centre 1153 \u201ctailored forming\u201c a process chain for the manufacturing of hybrid high performance components is developed. exemplary process steps consist of deposit welding of high performance steel on low-cost steel, pre-shaping by cross-wedge rolling and finishing by milling.hard material coatings such as stellite 6 or delcrome 253 are used as wear or corrosion protection coatings in industrial applications. scientists of the institute of material science welded these hard material alloys onto a base material, in this case c22.8, to create a hybrid workpiece. scientists of the institut fur integrierte produktion hannover have shown that these hybrid workpieces can be formed without defects (e.g. detachment of the coating) by cross-wedge rolling. after forming, the properties of the coatings are retained or in some cases even improved (e.g. the transition zone between base material and coating). by adjustments in the welding process, it was possible to apply the 100cr6 rolling bearing steel, as of now declared as non-weldable, on the low-cost steel c22.8. 100cr6 was formed afterwards in its hybrid bonding state with c22.8 by cross-wedge rolling, thus a component-integrated bearing seat was produced. even after welding and forming, the rolling bearing steel coating could still be quench-hardened to a hardness of over 60 hrc. this paper shows the potential of forming hybrid billets to tailored parts. since industrially available standard materials can be used for hard material coatings by this approach, even though they are not weldable by conventional methods, it is not necessary to use expensive, for welding designed materials to implement a hybrid component concept.within the collaborative research centre 1153 \u201ctailored forming\u201c a process chain for the manufacturing of hybrid high performance components is developed. exemplary process steps consist of deposit welding of high performance steel on low-cost steel, pre-shaping by cross-wedge rolling and finishing by milling.hard material coatings such as stellite 6 or delcrome 253 are used as wear or corrosion protection coatings in industrial applications. scientists of the institute of material science welded these hard material alloys onto a base material, in this case c22.8, to create a hybrid workpiece. scientists of the institut fur integrierte produktion hannover have shown that these hybrid workpieces can be formed without defects (e.g. detachment of the coating) by cross-wedge rolling. after forming, the properties of the coatings are retained or in some cases even improved (e.g. the transition zone between base material and coating). by adjustments in the welding process, it was possible to apply the 100cr6 ro...",
            "contribution_ids": [
                "R162733",
                "R162788",
                "R162790"
            ]
        },
        {
            "instance_id": "R175019xR145729",
            "comparison_id": "R175019",
            "paper_id": "R145729",
            "text": "Manufacturing and Evaluation of Multi-Material Axial-Bearing Washers by Tailored Forming components subject to rolling contact fatigue, such as gears and rolling bearings, are among the fundamental machine elements in mechanical and vehicle engineering. rolling bearings are generally not designed to be fatigue-resistant, as the necessary oversizing is not technically and economically marketable. in order to improve the load-bearing capacity, resource efficiency and application possibilities of rolling bearings and other possible multi-material solid components, a new process chain was developed at leibniz university hannover as a part of the collaborative research centre 1153 \u201ctailored forming\u201d. semi-finished products, already joined before the forming process, are used here to allow a further optimisation of joint quality by forming and finishing. in this paper, a plasma-powder-deposition welding process is presented, which enables precise material deposition and control of the welding depth. for this study, bearing washers (serving as rolling bearing raceways) of a cylindrical roller thrust bearing, similar to type 81212 with a multi-layer structure, were manufactured. a previously non-weldable high-performance material, steel aisi 5140, was used as the cladding layer. depending on the degree of forming, grain-refinement within the welded material was achieved by thermo-mechanical treatment of the joining zone during the forming process. this grain-refinements lead to an improvement of the mechanical properties and thus, to a higher lifetime for washers of an axial cylindrical roller bearing, which were examined as an exemplary component on a fatigue test bench. to evaluate the bearing washers, the results of the bearing tests were compared with industrial bearings and deposition welded axial-bearing washers without subsequent forming. in addition, the bearing washers were analysed micro-tribologically and by scanning acoustic microscopy both after welding and after the forming process. nano-scratch tests were carried out on the bearing washers to analyse the layer properties. together with the results of additional microscopic images of the surface and cross-sections, the causes of failure due to fatigue and wear were identified.",
            "contribution_ids": [
                "R145731"
            ]
        },
        {
            "instance_id": "R175409xR145720",
            "comparison_id": "R175409",
            "paper_id": "R145720",
            "text": "Investigations on Tailored Forming of AISI 52100 as Rolling Bearing Raceway hybrid cylindrical roller thrust bearing washers of type 81212 were manufactured by tailored forming. an aisi 1022m base material, featuring a sufficient strength for structural loads, was cladded with the bearing steel aisi 52100 by plasma transferred arc welding (pta). though aisi 52100 is generally regarded as non-weldable, it could be applied as a cladding material by adjusting pta parameters. the cladded parts were investigated after each individual process step and subsequently tested under rolling contact load. welding defects that could not be completely eliminated by the subsequent hot forming were characterized by means of scanning acoustic microscopy and micrographs. below the surface, pores with a typical size of ten \u00b5m were found to a depth of about 0.45 mm. in the material transition zone and between individual weld seams, larger voids were observed. grinding of the surface after heat treatment caused compressive residual stresses near the surface with a relatively small depth. fatigue tests were carried out on an fe8 test rig. eighty-two percent of the calculated rating life for conventional bearings was achieved. a high failure slope of the weibull regression was determined. a relationship between the weld defects and the fatigue behavior is likely.",
            "contribution_ids": [
                "R145728"
            ]
        },
        {
            "instance_id": "R175409xR162731",
            "comparison_id": "R175409",
            "paper_id": "R162731",
            "text": "Cross-wedge rolling of PTA-welded hybrid steel billets with rolling bearing steel and hard material coatings within the collaborative research centre 1153 \u201ctailored forming\u201c a process chain for the manufacturing of hybrid high performance components is developed. exemplary process steps consist of deposit welding of high performance steel on low-cost steel, pre-shaping by cross-wedge rolling and finishing by milling.hard material coatings such as stellite 6 or delcrome 253 are used as wear or corrosion protection coatings in industrial applications. scientists of the institute of material science welded these hard material alloys onto a base material, in this case c22.8, to create a hybrid workpiece. scientists of the institut fur integrierte produktion hannover have shown that these hybrid workpieces can be formed without defects (e.g. detachment of the coating) by cross-wedge rolling. after forming, the properties of the coatings are retained or in some cases even improved (e.g. the transition zone between base material and coating). by adjustments in the welding process, it was possible to apply the 100cr6 rolling bearing steel, as of now declared as non-weldable, on the low-cost steel c22.8. 100cr6 was formed afterwards in its hybrid bonding state with c22.8 by cross-wedge rolling, thus a component-integrated bearing seat was produced. even after welding and forming, the rolling bearing steel coating could still be quench-hardened to a hardness of over 60 hrc. this paper shows the potential of forming hybrid billets to tailored parts. since industrially available standard materials can be used for hard material coatings by this approach, even though they are not weldable by conventional methods, it is not necessary to use expensive, for welding designed materials to implement a hybrid component concept.within the collaborative research centre 1153 \u201ctailored forming\u201c a process chain for the manufacturing of hybrid high performance components is developed. exemplary process steps consist of deposit welding of high performance steel on low-cost steel, pre-shaping by cross-wedge rolling and finishing by milling.hard material coatings such as stellite 6 or delcrome 253 are used as wear or corrosion protection coatings in industrial applications. scientists of the institute of material science welded these hard material alloys onto a base material, in this case c22.8, to create a hybrid workpiece. scientists of the institut fur integrierte produktion hannover have shown that these hybrid workpieces can be formed without defects (e.g. detachment of the coating) by cross-wedge rolling. after forming, the properties of the coatings are retained or in some cases even improved (e.g. the transition zone between base material and coating). by adjustments in the welding process, it was possible to apply the 100cr6 ro...",
            "contribution_ids": [
                "R162733",
                "R162788",
                "R162790"
            ]
        },
        {
            "instance_id": "R175409xR171846",
            "comparison_id": "R175409",
            "paper_id": "R171846",
            "text": "Investigation of the material combination 20MnCr5 and X45CrSi9-3 in the Tailored Forming of shafts with bearing seats abstract the tailored forming process chain is used to manufacture hybrid components and consists of a joining process or additive manufacturing for various materials (e.g. deposition welding), subsequent hot forming, machining and heat treatment. in this way, components can be produced with materials adapted to the load case. for this paper, hybrid shafts are produced by deposition welding of a cladding made of x45crsi9-3 onto a workpiece made from 20mncr5. the hybrid shafts are then formed by means of cross-wedge rolling. it is investigated, how the thickness of the cladding and the type of cooling after hot forming (in air or in water) affect the properties of the cladding. the hybrid shafts are formed without layer separation. however, slight core loosening occurres in the area of the bearing seat due to the mannesmann effect. the microhardness of the cladding is only slightly effected by the cooling strategy, while the microhardness of the base material is significantly higher in water cooled shafts. the microstructure of the cladding after both cooling strategies consists mainly of martensite. in the base material, air cooling results in a mainly ferritic microstructure with grains of ferrite-pearlite. quenching in water results in a microstructure containing mainly martensite.",
            "contribution_ids": [
                "R171849",
                "R172160",
                "R172247",
                "R172322"
            ]
        },
        {
            "instance_id": "R182358xR182336",
            "comparison_id": "R182358",
            "paper_id": "R182336",
            "text": "A Food Recognition System for Diabetic Patients Based on an Optimized Bag-of-Features Model \"computer vision-based food recognition could be used to estimate a meal's carbohydrate content for diabetic patients. this study proposes a methodology for automatic food recognition, based on the bag-of-features (bof) model. an extensive technical investigation was conducted for the identification and optimization of the best performing components involved in the bof architecture, as well as the estimation of the corresponding parameters. for the design and evaluation of the prototype system, a visual dataset with nearly 5000 food images was created and organized into 11 classes. the optimized system computes dense local features, using the scale-invariant feature transform on the hsv color space, builds a visual dictionary of 10000 visual words by using the hierarchical k-means clustering and finally classifies the food images with a linear support vector machine classifier. the system achieved classification accuracy of the order of 78%, thus proving the feasibility of the proposed approach in a very challenging image dataset.\"",
            "contribution_ids": [
                "R182338"
            ]
        },
        {
            "instance_id": "R182358xR182290",
            "comparison_id": "R182358",
            "paper_id": "R182290",
            "text": "PFID: Pittsburgh fast-food image dataset we introduce the first visual dataset of fast foods with a total of 4,545 still images, 606 stereo pairs, 303 360\u00b0 videos for structure from motion, and 27 privacy-preserving videos of eating events of volunteers. this work was motivated by research on fast food recognition for dietary assessment. the data was collected by obtaining three instances of 101 foods from 11 popular fast food chains, and capturing images and videos in both restaurant conditions and a controlled lab setting. we benchmark the dataset using two standard approaches, color histogram and bag of sift features in conjunction with a discriminative classifier. our dataset and the benchmarks are designed to stimulate research in this area and will be released freely to the research community.",
            "contribution_ids": [
                "R182292"
            ]
        },
        {
            "instance_id": "R182358xR182302",
            "comparison_id": "R182358",
            "paper_id": "R182302",
            "text": "Personal dietary assessment using mobile devices dietary intake provides valuable insights for mounting intervention programs for prevention of disease. with growing concern for adolescent obesity, the need to accurately measure diet becomes imperative. assessment among adolescents is problematic as this group has irregular eating patterns and have less enthusiasm for recording food intake. preliminary studies among adolescents suggest that innovative use of technology may improve the accuracy of diet information from young people. in this paper we describe further development of a novel dietary assessment system using mobile devices. this system will generate an accurate account of daily food and nutrient intake among adolescents. the mobile computing device provides a unique vehicle for collecting dietary information that reduces burden on records that are obtained using more classical approaches. images before and after foods are eaten can be used to estimate the amount of food consumed.",
            "contribution_ids": [
                "R182304"
            ]
        },
        {
            "instance_id": "R182358xR182238",
            "comparison_id": "R182358",
            "paper_id": "R182238",
            "text": "Food Recognition: A New Dataset, Experiments, and Results we propose a new dataset for the evaluation of food recognition algorithms that can be used in dietary monitoring applications. each image depicts a real canteen tray with dishes and foods arranged in different ways. each tray contains multiple instances of food classes. the dataset contains 1027 canteen trays for a total of 3616 food instances belonging to 73 food classes. the food on the tray images has been manually segmented using carefully drawn polygonal boundaries. we have benchmarked the dataset by designing an automatic tray analysis pipeline that takes a tray image as input, finds the regions of interest, and predicts for each region the corresponding food class. we have experimented with three different classification strategies using also several visual descriptors. we achieve about 79% of food and tray recognition accuracy using convolutional-neural-networks-based features. the dataset, as well as the benchmark framework, are available to the research community.",
            "contribution_ids": [
                "R182240"
            ]
        },
        {
            "instance_id": "R182358xR182194",
            "comparison_id": "R182358",
            "paper_id": "R182194",
            "text": "Food Image Recognition and Calorie Prediction with the increasing number of health issues reported due to obesity and overeating, people have become cautious about their diet intake to prevent themselves from the diseases such as hypertension, diabetes, and other heart related problem which are caused due to obesity. as per the data shared by who, at least 2.8 million people are dying each year because of being overweight or obese. the important part of any healthy diet plan is its calories intake. hence, we propose a deep learning-based technique to calculate the calories of the food items present in the image captured by the user. we used a layer-based approach to predict calorie in the food item which include image acquisition, food item classification, surface area detection and calorie prediction.",
            "contribution_ids": [
                "R182196",
                "R182198",
                "R182205"
            ]
        },
        {
            "instance_id": "R182358xR182311",
            "comparison_id": "R182358",
            "paper_id": "R182311",
            "text": "Image Recognition of 85 Food Categories by Feature Fusion recognition of food images is challenging due to their diversity and practical for health care on foods for people. in this paper, we propose an automatic food image recognition system for 85 food categories by fusing various kinds of image features including bag-of-features~(bof), color histogram, gabor features and gradient histogram with multiple kernel learning~(mkl). in addition, we implemented a prototype system to recognize food images taken by cellular-phone cameras. in the experiment, we have achieved the 62.52% classification rate for 85 food categories.",
            "contribution_ids": [
                "R182313"
            ]
        },
        {
            "instance_id": "R182358xR182258",
            "comparison_id": "R182358",
            "paper_id": "R182258",
            "text": "A food image recognition system with Multiple Kernel Learning \"since health care on foods is drawing people's attention recently, a system that can record everyday meals easily is being awaited. in this paper, we propose an automatic food image recognition system for recording people's eating habits. in the proposed system, we use the multiple kernel learning (mkl) method to integrate several kinds of image features such as color, texture and sift adaptively. mkl enables to estimate optimal weights to combine image features for each category. in addition, we implemented a prototype system to recognize food images taken by cellular-phone cameras. in the experiment, we have achieved the 61.34% classification rate for 50 kinds of foods. to the best of our knowledge, this is the first report of a food image classification system which can be applied for practical use.\"",
            "contribution_ids": [
                "R182264"
            ]
        },
        {
            "instance_id": "R182415xR181000",
            "comparison_id": "R182415",
            "paper_id": "R181000",
            "text": "Image-Based Food Calorie Estimation Using Knowledge on Food Categories, Ingredients and Cooking Directions image-based food calorie estimation is crucial to diverse mobile applications for recording everyday meal. however, some of them need human help for calorie estimation, and even if it is automatic, food categories are often limited or images from multiple viewpoints are required. then, it is not yet achieved to estimate food calorie with practical accuracy and estimating food calories from a food photo is an unsolved problem. therefore, in this paper, we propose estimating food calorie from a food photo by simultaneous learning of food calories, categories, ingredients and cooking directions using deep learning. since there exists a strong correlation between food calories and food categories, ingredients and cooking directions information in general, we expect that simultaneous training of them brings performance boosting compared to independent single training. to this end, we use a multi-task cnn [1]. in addition, in this research, we construct two kinds of datasets that is a dataset of calorie-annotated recipe collected from japanese recipe sites on the web and a dataset collected from an american recipe site. in this experiment, we trained multi-task and single-task cnns. as a result, the multi-task cnn achieved the better performance on both food category estimation and food calorie estimation than single-task cnns. for the japanese recipe dataset, by introducing a multi-task cnn, 0.039 were improved on the correlation coefficient, while for the american recipe dataset, 0.090 were raised compared to the result by the single-task cnn.",
            "contribution_ids": [
                "R181002",
                "R182078",
                "R182079",
                "R182083",
                "R182084",
                "R182086",
                "R182102",
                "R182105",
                "R182360",
                "R182361",
                "R182362",
                "R182363",
                "R182364",
                "R182365",
                "R182366",
                "R182367",
                "R182368",
                "R182369",
                "R182370",
                "R182371",
                "R182372",
                "R182373",
                "R182411"
            ]
        },
        {
            "instance_id": "R184018xR182393",
            "comparison_id": "R184018",
            "paper_id": "R182393",
            "text": "The association between crop and income diversity and farmer intra-household dietary diversity in India abstract this paper investigates the associations between crop and income diversity and dietary diversity among men, women, adolescents, and children of farmer households in india. we examine crop, income, and dietary data collected from 1106 farmer households across gujarat and haryana, two states that represent different livelihood transition pathways in india. regression results suggest that crop diversity had a positive association with dietary diversity among adults (both men and women) in both states, and among adolescents and children in haryana. higher family education and annual income were the two most important factors associated with higher dietary diversity score (dds) in gujarat whereas, higher family education, greater crop diversity, and increased distance traveled to markets were the most important factors associated with higher individual dds in haryana. specifically, for children, crop diversity emerged as one of the most important factors associated with dietary diversity in both states. interestingly, we find that even in these two relatively prosperous states, the pathways to dietary diversity vary across sites and within households, suggesting that policies to improve dietary diversity should be tailored to a given location and context.",
            "contribution_ids": [
                "R182395"
            ]
        },
        {
            "instance_id": "R184018xR182153",
            "comparison_id": "R184018",
            "paper_id": "R182153",
            "text": "Agricultural Diversity, Dietary Diversity and Nutritional Intake: An Evidence on Inter-linkages from Village Level Studies in Eastern India the linkage between agriculture and nutrition is complex and often debated in the policy discourse in india. the enigma of fastest growing economy and yet the largest home of under- and mal-nourished population takes away the sheen from the glory of economic achievements of india. in this context, the study has examined the food consumption patterns, assessed the relationship between agricultural production and dietary diversity, and analysed the impact of dietary diversity on nutritional intake. the study is based on a household level panel data from 12 villages of bihar, jharkhand and odisha in eastern india. the study has shown that agricultural production diversity is a major determinant of dietary diversity which in turn has a strong effect on calorie and protein intake. the study has suggested that efforts to promote agricultural diversification will be helpful to enhance food and nutrition security in the country. agricultural programmes and policies oriented towards reducing under-nutrition should promote diversity in agricultural production rather than emphasizing on increasing production through focusing on selected staple crops as has been observed in several states of india. the huge fertilizer subsidies and government procurement schemes limited to a few crops provide little incentives for farmers to diversity their production portfolio.",
            "contribution_ids": [
                "R182155"
            ]
        },
        {
            "instance_id": "R184018xR184000",
            "comparison_id": "R184018",
            "paper_id": "R184000",
            "text": "Agricultural Food Production Diversity and Dietary Diversity among Female Small Holder Farmers in a Region of the Ecuadorian Andes Experiencing Nutrition Transition some rural areas of ecuador, including the imbabura province of the andes highlands, are experiencing a double burden of malnutrition where micronutrient deficiencies persist at the same time obesity is increasing as many traditional home-grown foods are being replaced with more commercially prepared convenience foods. thus, the relationships among agricultural food production diversity (fpd), dietary diversity (dd), and household food insecurity (hfi) of the rural small holder farmers need further study. therefore, we examined these associations in small holder farmers residing in this province in the andes highlands (elevation &gt; 2500 m). non-pregnant maternal home managers (n = 558, x age = 44.1, sd = 16.5 y) were interviewed regarding the number of different agricultural food crops cultivated and domestic animals raised in their family farm plots. dd was determined using the minimum dietary diversity for women score (mdd-w) based on the number of 10 different food groups consumed, and household food insecurity (hfi) was determined using the 8-item household food insecurity experience scale. the women reported consuming an average of 53% of their total food from what they cultivated or raised. women with higher dd [mmd-w score \u2265 5 food groups (79% of total sample)] were on farms that cultivated a greater variety of crops (x = 8.7 vs. 6.7), raised more animals (x = 17.9 vs. 12.7, p &lt; 0.05), and reported lower hfi and significantly higher intakes of energy, protein, iron, zinc, and vitamin a (all p &lt; 0.05). multiple regression analyses demonstrated that fpd was only modestly related to dd, which together with years of education, per capita family income, and hfi accounted for 26% of dd variance. in rural areas of the imbabura province, small holder farmers still rely heavily on consumption of self-cultivated foods, but greater diversity of crops grown in family farm plots is only weakly associated with greater dd and lower hfi among the female caretakers.",
            "contribution_ids": [
                "R184004"
            ]
        },
        {
            "instance_id": "R184018xR182161",
            "comparison_id": "R184018",
            "paper_id": "R182161",
            "text": "Agroecological practices of legume residue management and crop diversification for improved smallholder food security, dietary diversity and sustainable land use in Malawi abstract the role of agroecological practices in addressing food security has had limited investigation, particularly in sub-saharan africa. quasi-experimental methods were used to assess the role of agroecological practices in reducing food insecurity in smallholder households in malawi. two key practices \u2013 crop diversification and the incorporation of organic matter into soil \u2013 were examined. the quasi-experimental study of an agroecological intervention included survey data from 303 households and in-depth interviews with 33 households. the survey sampled 210 intervention households participating in the agroecological intervention, and 93 control households in neighboring villages. regression analysis of food security indicators found that both agroecological practices significantly predicted higher food security and dietary diversity for smallholder households: the one-third of farming households who incorporated legume residue soon after harvest were almost three times more likely to be food secure than those who had not incorporated crop residue. qualitative semi-structured interviews with 33 households identified several pathways through which crop diversification and crop residue incorporation contributed to household food security: direct consumption, agricultural income, and changes in underlying production relations. these findings provide evidence of agroecology\u2019s potential to address food insecurity while supporting sustainable food systems.",
            "contribution_ids": [
                "R182165"
            ]
        },
        {
            "instance_id": "R184018xR184009",
            "comparison_id": "R184018",
            "paper_id": "R184009",
            "text": "Market Access, Production Diversity, and Diet Diversity: Evidence From India background: recent literature, largely from africa, shows mixed effects of own-production on diet diversity. however, the role of own-production, relative to markets, in influencing food consumption becomes more pronounced as market integration increases. objective: this paper investigates the relative importance of two factors - production diversity and household market integration - for the intake of a nutritious diet by women and households in rural india. methods: data analysis is based on primary data from an extensive agriculture-nutrition survey of 3600 indian households that was collected in 2017. dietary diversity scores are constructed for women and households is based on 24-hour and 7-day recall periods. household market integration is measured as monthly household expenditure on key non-staple food groups. we measure production diversity in two ways - field-level and on-farm production diversity - in order to account for the cereal centric rice-wheat cropping system found in our study locations. the analysis is based on ordinary least squares regressions where we control for a variety of village, household, and individual level covariates that affect food consumption, and village fixed effects. robustness checks are done by way of using a poisson regression specifications and 7-day recall period. results: conventional measures of field-level production diversity, like the number of crops or food groups grown, have no significant association with diet diversity. in contrast, it is on-farm production diversity (the field-level cultivation of pulses and on-farm livestock management, and kitchen gardens in the longer run) that is significantly associated with improved dietary diversity scores, thus suggesting the importance of non-staples in improving both individual and household dietary diversity. furthermore, market purchases of non-staples like pulses and dairy products are associated with a significantly higher dietary diversity. other significant determinants of dietary diversity include women\u2019s literacy and awareness of nutrition. these results mostly remain robust to changes in the recall period of the diet diversity measure and the nature of the empirical specification. conclusions: this study contributes to the scarce empirical evidence related to diets in india. additionally, our results indicate some key intervention areas - promoting livestock rearing, strengthening households\u2019 market integration (for purchase of non-staples) and increasing women\u2019s awareness about nutrition. these are more impactful than raising production diversity.",
            "contribution_ids": [
                "R184011"
            ]
        },
        {
            "instance_id": "R184018xR182376",
            "comparison_id": "R184018",
            "paper_id": "R182376",
            "text": "Relationship between agricultural biodiversity and dietary diversity of children aged 6-36 months in rural areas of Northern Ghana abstract in this study, we investigated the relationship between agricultural biodiversity and dietary diversity of children and whether factors such as economic access may affect this relationship. this paper is based on data collected in a baseline cross-sectional survey in november 2013.the study population comprising 1200 mother-child pairs was selected using a two-stage cluster sampling. dietary diversity was defined as the number of food groups consumed 24 h prior to the assessment. the number of crop and livestock species produced on a farm was used as the measure of production diversity. hierarchical regression analysis was used to identify predictors and test for interactions. whereas the average production diversity score was 4.7 \u00b1 1.6, only 42.4% of households consumed at least four food groups out of seven over the preceding 24-h recall period. agricultural biodiversity (i.e. variety of animals kept and food groups produced) associated positively with dietary diversity of children aged 6\u201336 months but the relationship was moderated by household socioeconomic status. the interaction term was also statistically significant [\u03b2 = \u22120.08 (95% ci: \u22120.05, \u22120.01, p = 0.001)]. spearman correlation (rho) analysis showed that agricultural biodiversity was positively associated with individual dietary diversity of the child more among children of low socioeconomic status in rural households compared to children of high socioeconomic status (r = 0.93, p < 0.001 versus r = 0.08, p = 0.007). socioeconomic status of the household also partially mediated the link between agricultural biodiversity and dietary diversity of a child\u2019s diet. the effect of increased agricultural biodiversity on dietary diversity was significantly higher in households of lower socioeconomic status. therefore, improvement of agricultural biodiversity could be one of the best approaches for ensuring diverse diets especially for households of lower socioeconomic status in rural areas of northern ghana.",
            "contribution_ids": [
                "R182380"
            ]
        },
        {
            "instance_id": "R184018xR182148",
            "comparison_id": "R184018",
            "paper_id": "R182148",
            "text": "Farm production, market access and dietary diversity in Malawi abstract objective the association between farm production diversity and dietary diversity in rural smallholder households was recently analysed. most existing studies build on household-level dietary diversity indicators calculated from 7d food consumption recalls. herein, this association is revisited with individual-level 24 h recall data. the robustness of the results is tested by comparing household- and individual-level estimates. the role of other factors that may influence dietary diversity, such as market access and agricultural technology, is also analysed. design a survey of smallholder farm households was carried out in malawi in 2014. dietary diversity scores are calculated from 24 h recall data. production diversity scores are calculated from farm production data covering a period of 12 months. individual- and household-level regression models are developed and estimated. setting data were collected in sixteen districts of central and southern malawi. subjects smallholder farm households ( n 408), young children ( n 519) and mothers ( n 408). results farm production diversity is positively associated with dietary diversity. however, the estimated effects are small. access to markets for buying food and selling farm produce and use of chemical fertilizers are shown to be more important for dietary diversity than diverse farm production. results with household- and individual-level dietary data are very similar. conclusions further increasing production diversity may not be the most effective strategy to improve diets in smallholder farm households. improving access to markets, productivity-enhancing inputs and technologies seems to be more promising.",
            "contribution_ids": [
                "R182150"
            ]
        },
        {
            "instance_id": "R185262xR184054",
            "comparison_id": "R185262",
            "paper_id": "R184054",
            "text": "Theoretical energies for the <i>n</i>\u00e2\u0080\u0082=\u00e2\u0080\u00821 and 2 states of the helium isoelectronic sequence up to <i>Z</i>\u00e2\u0080\u0082=\u00e2\u0080\u0082100 the unified method described previously for combining high-precision nonrelativistic variational calculations with relativistic and quantum electrodynamic corrections is applied to the 1s 2 \\u2002 1 s 0 , 1s2s\\u2002 1 s 0 , 1s2s\\u2002 3 s 1 , 1s2p\\u2002 1 p 1 , and 1s2p\\u2002 3 p 0,1,2 staters of helium-like ions. detailed tabulations are presented for all ions in the range 2\\u2002\u2264\\u2002z\\u2002\u2264\\u2002100 and are compared with a wide range of experimental data up to 34 kr + . the results for 90 u + significantly alter the recent lamb shift measurement of munger and gould from 70.4\\u2002\u00b1\\u20028.3 to 71.0\\u2002\u00b1\\u20028.3\\u2002ev, in comparison with a revised theoretical value of 74.3\\u2002\u00b1\\u20020.4\\u2002ev. the improved agreement is due to the inclusion of higher order two-electron corrections in the present work.",
            "contribution_ids": [
                "R184056"
            ]
        },
        {
            "instance_id": "R185262xR185065",
            "comparison_id": "R185262",
            "paper_id": "R185065",
            "text": "Fe XXV Drake 1/2 the unified method described previously for combining high-precision nonrelativistic variational calculations with relativistic and quantum electrodynamic corrections is applied to the 1s 2 \\u2002 1 s 0 , 1s2s\\u2002 1 s 0 , 1s2s\\u2002 3 s 1 , 1s2p\\u2002 1 p 1 , and 1s2p\\u2002 3 p 0,1,2 staters of helium-like ions. detailed tabulations are presented for all ions in the range 2\\u2002\u2264\\u2002z\\u2002\u2264\\u2002100 and are compared with a wide range of experimental data up to 34 kr + . the results for 90 u + significantly alter the recent lamb shift measurement of munger and gould from 70.4\\u2002\u00b1\\u20028.3 to 71.0\\u2002\u00b1\\u20028.3\\u2002ev, in comparison with a revised theoretical value of 74.3\\u2002\u00b1\\u20020.4\\u2002ev. the improved agreement is due to the inclusion of higher order two-electron corrections in the present work.",
            "contribution_ids": [
                "R185067"
            ]
        },
        {
            "instance_id": "R185267xR185065",
            "comparison_id": "R185267",
            "paper_id": "R185065",
            "text": "Fe XXV Drake 1/2 the unified method described previously for combining high-precision nonrelativistic variational calculations with relativistic and quantum electrodynamic corrections is applied to the 1s 2 \\u2002 1 s 0 , 1s2s\\u2002 1 s 0 , 1s2s\\u2002 3 s 1 , 1s2p\\u2002 1 p 1 , and 1s2p\\u2002 3 p 0,1,2 staters of helium-like ions. detailed tabulations are presented for all ions in the range 2\\u2002\u2264\\u2002z\\u2002\u2264\\u2002100 and are compared with a wide range of experimental data up to 34 kr + . the results for 90 u + significantly alter the recent lamb shift measurement of munger and gould from 70.4\\u2002\u00b1\\u20028.3 to 71.0\\u2002\u00b1\\u20028.3\\u2002ev, in comparison with a revised theoretical value of 74.3\\u2002\u00b1\\u20020.4\\u2002ev. the improved agreement is due to the inclusion of higher order two-electron corrections in the present work.",
            "contribution_ids": [
                "R185067"
            ]
        },
        {
            "instance_id": "R185267xR184054",
            "comparison_id": "R185267",
            "paper_id": "R184054",
            "text": "Theoretical energies for the <i>n</i>\u00e2\u0080\u0082=\u00e2\u0080\u00821 and 2 states of the helium isoelectronic sequence up to <i>Z</i>\u00e2\u0080\u0082=\u00e2\u0080\u0082100 the unified method described previously for combining high-precision nonrelativistic variational calculations with relativistic and quantum electrodynamic corrections is applied to the 1s 2 \\u2002 1 s 0 , 1s2s\\u2002 1 s 0 , 1s2s\\u2002 3 s 1 , 1s2p\\u2002 1 p 1 , and 1s2p\\u2002 3 p 0,1,2 staters of helium-like ions. detailed tabulations are presented for all ions in the range 2\\u2002\u2264\\u2002z\\u2002\u2264\\u2002100 and are compared with a wide range of experimental data up to 34 kr + . the results for 90 u + significantly alter the recent lamb shift measurement of munger and gould from 70.4\\u2002\u00b1\\u20028.3 to 71.0\\u2002\u00b1\\u20028.3\\u2002ev, in comparison with a revised theoretical value of 74.3\\u2002\u00b1\\u20020.4\\u2002ev. the improved agreement is due to the inclusion of higher order two-electron corrections in the present work.",
            "contribution_ids": [
                "R184056"
            ]
        },
        {
            "instance_id": "R186048xR185271",
            "comparison_id": "R186048",
            "paper_id": "R185271",
            "text": "Multimedia ontology learning for automatic annotation and video browsing in this work, we offer an approach to combine standard multimedia analysis techniques with knowledge drawn from conceptual metadata provided by domain experts of a specialized scholarly domain, to learn a domain-specific multimedia ontology from a set of annotated examples. a standard bayesian network learning algorithm that learns structure and parameters of a bayesian network is extended to include media observables in the learning. an expert group provides domain knowledge to construct a basic ontology of the domain as well as to annotate a set of training videos. these annotations help derive the associations between high-level semantic concepts of the domain and low-level mpeg-7 based features representing audio-visual content of the videos. we construct a more robust and refined version of this ontology by learning from this set of conceptually annotated videos. to encode this knowledge, we use mowl, a multimedia extension of web ontology language (owl) which is capable of describing domain concepts in terms of their media properties and of capturing the inherent uncertainties involved. we use the ontology specified knowledge for recognizing concepts relevant to a video to annotate fresh addition to the video database with relevant concepts in the ontology. these conceptual annotations are used to create hyperlinks in the video collection, to provide an effective video browsing interface to the user.",
            "contribution_ids": [
                "R185273",
                "R185292",
                "R185293",
                "R185294",
                "R185295",
                "R185296",
                "R185297",
                "R185298",
                "R185299"
            ]
        },
        {
            "instance_id": "R186111xR186081",
            "comparison_id": "R186111",
            "paper_id": "R186081",
            "text": "Metrics Based Verification and Validation Maturity Model (MB-V2M2) verification and validation (v&v) is only marginally addressed in software process improvement models like cmm and cmmi. a roadmap for the establishment of a sound verification and validation process in software development organizations is badly needed. this paper presents a basis for a roadmap; it describes a framework for improvement of the v&v process, based on the testing maturity model (tmm), but with considerable enhancements. the model, tentatively named mb-v/sup 2/m/sup 2/ (metrics based verification and validation maturity model), has been initiated by a consortium of industrial companies, consultancy & service agencies and an academic institute, operating and residing in the netherlands. mb-v/sup 2/m/sup 2/ is designed to be universally applicable, to unite the strengths of known (verification and validation) improvement models and to reflect proven work practices. it recommends a metrics base to select process improvements and to track and control implementation of improvement actions. this paper outlines the model and addresses the current status.",
            "contribution_ids": [
                "R186083"
            ]
        },
        {
            "instance_id": "R186184xR145732",
            "comparison_id": "R186184",
            "paper_id": "R145732",
            "text": "Tribological Study on Tailored-Formed Axial Bearing Washers to enhance tribological contacts under cyclic load, high performance materials are required. utilizing the same high-strength material for the whole machine element is not resource-efficient. in order to manufacture machine elements with extended functionality and specific properties, a combination of different materials can be used in a single component for a more efficient material utilization. by combining different joining techniques with subsequent forming, multi-material or tailored components can be manufactured. to reduce material costs and energy consumption during the component service life, a less expensive lightweight material should be used for regions remote from the highly stressed zones. the scope is not only to obtain the desired shape and dimensions for the finishing process, but also to improve properties like the bond strength between different materials and the microscopic structure of the material. the multi-material approach can be applied to all components requiring different properties in separate component regions such as shafts, bearings or bushes. the current study exemplarily presents the process route for the production of an axial bearing washer by means of tailored forming technology. the bearing washers were chosen to fit axial roller bearings (type 81212). the manufacturing process starts with the laser wire cladding of a hard facing made of martensitic chromium silicon steel (1.4718) on a base substrate of s235 (1.0038) steel. subsequently, the bearing washers are forged. after finishing, the surfaces of the bearing washers were tested in thrust bearings on an fe-8 test rig. the operational test of the bearings consists in a run-in phase at 250 rpm. a bearing failure is determined by a condition monitoring system. before and after this, the bearings were inspected by optical and ultrasonic microscopy in order to examine whether the bond of the coat is resistant against rolling contact fatigue. the feasibility of the approach could be proven by endurance test. the joining zone was able to withstand the rolling contact stresses and the bearing failed due to material-induced fatigue with high cycle stability.",
            "contribution_ids": [
                "R145734"
            ]
        },
        {
            "instance_id": "R186184xR145729",
            "comparison_id": "R186184",
            "paper_id": "R145729",
            "text": "Manufacturing and Evaluation of Multi-Material Axial-Bearing Washers by Tailored Forming components subject to rolling contact fatigue, such as gears and rolling bearings, are among the fundamental machine elements in mechanical and vehicle engineering. rolling bearings are generally not designed to be fatigue-resistant, as the necessary oversizing is not technically and economically marketable. in order to improve the load-bearing capacity, resource efficiency and application possibilities of rolling bearings and other possible multi-material solid components, a new process chain was developed at leibniz university hannover as a part of the collaborative research centre 1153 \u201ctailored forming\u201d. semi-finished products, already joined before the forming process, are used here to allow a further optimisation of joint quality by forming and finishing. in this paper, a plasma-powder-deposition welding process is presented, which enables precise material deposition and control of the welding depth. for this study, bearing washers (serving as rolling bearing raceways) of a cylindrical roller thrust bearing, similar to type 81212 with a multi-layer structure, were manufactured. a previously non-weldable high-performance material, steel aisi 5140, was used as the cladding layer. depending on the degree of forming, grain-refinement within the welded material was achieved by thermo-mechanical treatment of the joining zone during the forming process. this grain-refinements lead to an improvement of the mechanical properties and thus, to a higher lifetime for washers of an axial cylindrical roller bearing, which were examined as an exemplary component on a fatigue test bench. to evaluate the bearing washers, the results of the bearing tests were compared with industrial bearings and deposition welded axial-bearing washers without subsequent forming. in addition, the bearing washers were analysed micro-tribologically and by scanning acoustic microscopy both after welding and after the forming process. nano-scratch tests were carried out on the bearing washers to analyse the layer properties. together with the results of additional microscopic images of the surface and cross-sections, the causes of failure due to fatigue and wear were identified.",
            "contribution_ids": [
                "R145731"
            ]
        },
        {
            "instance_id": "R186184xR171846",
            "comparison_id": "R186184",
            "paper_id": "R171846",
            "text": "Investigation of the material combination 20MnCr5 and X45CrSi9-3 in the Tailored Forming of shafts with bearing seats abstract the tailored forming process chain is used to manufacture hybrid components and consists of a joining process or additive manufacturing for various materials (e.g. deposition welding), subsequent hot forming, machining and heat treatment. in this way, components can be produced with materials adapted to the load case. for this paper, hybrid shafts are produced by deposition welding of a cladding made of x45crsi9-3 onto a workpiece made from 20mncr5. the hybrid shafts are then formed by means of cross-wedge rolling. it is investigated, how the thickness of the cladding and the type of cooling after hot forming (in air or in water) affect the properties of the cladding. the hybrid shafts are formed without layer separation. however, slight core loosening occurres in the area of the bearing seat due to the mannesmann effect. the microhardness of the cladding is only slightly effected by the cooling strategy, while the microhardness of the base material is significantly higher in water cooled shafts. the microstructure of the cladding after both cooling strategies consists mainly of martensite. in the base material, air cooling results in a mainly ferritic microstructure with grains of ferrite-pearlite. quenching in water results in a microstructure containing mainly martensite.",
            "contribution_ids": [
                "R171849",
                "R172160",
                "R172247",
                "R172322"
            ]
        },
        {
            "instance_id": "R187049xR145732",
            "comparison_id": "R187049",
            "paper_id": "R145732",
            "text": "Tribological Study on Tailored-Formed Axial Bearing Washers to enhance tribological contacts under cyclic load, high performance materials are required. utilizing the same high-strength material for the whole machine element is not resource-efficient. in order to manufacture machine elements with extended functionality and specific properties, a combination of different materials can be used in a single component for a more efficient material utilization. by combining different joining techniques with subsequent forming, multi-material or tailored components can be manufactured. to reduce material costs and energy consumption during the component service life, a less expensive lightweight material should be used for regions remote from the highly stressed zones. the scope is not only to obtain the desired shape and dimensions for the finishing process, but also to improve properties like the bond strength between different materials and the microscopic structure of the material. the multi-material approach can be applied to all components requiring different properties in separate component regions such as shafts, bearings or bushes. the current study exemplarily presents the process route for the production of an axial bearing washer by means of tailored forming technology. the bearing washers were chosen to fit axial roller bearings (type 81212). the manufacturing process starts with the laser wire cladding of a hard facing made of martensitic chromium silicon steel (1.4718) on a base substrate of s235 (1.0038) steel. subsequently, the bearing washers are forged. after finishing, the surfaces of the bearing washers were tested in thrust bearings on an fe-8 test rig. the operational test of the bearings consists in a run-in phase at 250 rpm. a bearing failure is determined by a condition monitoring system. before and after this, the bearings were inspected by optical and ultrasonic microscopy in order to examine whether the bond of the coat is resistant against rolling contact fatigue. the feasibility of the approach could be proven by endurance test. the joining zone was able to withstand the rolling contact stresses and the bearing failed due to material-induced fatigue with high cycle stability.",
            "contribution_ids": [
                "R145734"
            ]
        },
        {
            "instance_id": "R187049xR171846",
            "comparison_id": "R187049",
            "paper_id": "R171846",
            "text": "Investigation of the material combination 20MnCr5 and X45CrSi9-3 in the Tailored Forming of shafts with bearing seats abstract the tailored forming process chain is used to manufacture hybrid components and consists of a joining process or additive manufacturing for various materials (e.g. deposition welding), subsequent hot forming, machining and heat treatment. in this way, components can be produced with materials adapted to the load case. for this paper, hybrid shafts are produced by deposition welding of a cladding made of x45crsi9-3 onto a workpiece made from 20mncr5. the hybrid shafts are then formed by means of cross-wedge rolling. it is investigated, how the thickness of the cladding and the type of cooling after hot forming (in air or in water) affect the properties of the cladding. the hybrid shafts are formed without layer separation. however, slight core loosening occurres in the area of the bearing seat due to the mannesmann effect. the microhardness of the cladding is only slightly effected by the cooling strategy, while the microhardness of the base material is significantly higher in water cooled shafts. the microstructure of the cladding after both cooling strategies consists mainly of martensite. in the base material, air cooling results in a mainly ferritic microstructure with grains of ferrite-pearlite. quenching in water results in a microstructure containing mainly martensite.",
            "contribution_ids": [
                "R171849",
                "R172160",
                "R172247",
                "R172322"
            ]
        },
        {
            "instance_id": "R187049xR145729",
            "comparison_id": "R187049",
            "paper_id": "R145729",
            "text": "Manufacturing and Evaluation of Multi-Material Axial-Bearing Washers by Tailored Forming components subject to rolling contact fatigue, such as gears and rolling bearings, are among the fundamental machine elements in mechanical and vehicle engineering. rolling bearings are generally not designed to be fatigue-resistant, as the necessary oversizing is not technically and economically marketable. in order to improve the load-bearing capacity, resource efficiency and application possibilities of rolling bearings and other possible multi-material solid components, a new process chain was developed at leibniz university hannover as a part of the collaborative research centre 1153 \u201ctailored forming\u201d. semi-finished products, already joined before the forming process, are used here to allow a further optimisation of joint quality by forming and finishing. in this paper, a plasma-powder-deposition welding process is presented, which enables precise material deposition and control of the welding depth. for this study, bearing washers (serving as rolling bearing raceways) of a cylindrical roller thrust bearing, similar to type 81212 with a multi-layer structure, were manufactured. a previously non-weldable high-performance material, steel aisi 5140, was used as the cladding layer. depending on the degree of forming, grain-refinement within the welded material was achieved by thermo-mechanical treatment of the joining zone during the forming process. this grain-refinements lead to an improvement of the mechanical properties and thus, to a higher lifetime for washers of an axial cylindrical roller bearing, which were examined as an exemplary component on a fatigue test bench. to evaluate the bearing washers, the results of the bearing tests were compared with industrial bearings and deposition welded axial-bearing washers without subsequent forming. in addition, the bearing washers were analysed micro-tribologically and by scanning acoustic microscopy both after welding and after the forming process. nano-scratch tests were carried out on the bearing washers to analyse the layer properties. together with the results of additional microscopic images of the surface and cross-sections, the causes of failure due to fatigue and wear were identified.",
            "contribution_ids": [
                "R145731"
            ]
        },
        {
            "instance_id": "R187060xR187043",
            "comparison_id": "R187060",
            "paper_id": "R187043",
            "text": "COVID-19 Surveillance in a Primary Care Sentinel Network: In-Pandemic Development of an Application Ontology background creating an ontology for covid-19 surveillance should help ensure transparency and consistency. ontologies formalize conceptualizations at either the domain or application level. application ontologies cross domains and are specified through testable use cases. our use case was an extension of the role of the oxford royal college of general practitioners (rcgp) research and surveillance centre (rsc) to monitor the current pandemic and become an in-pandemic research platform. objective this study aimed to develop an application ontology for covid-19 that can be deployed across the various use-case domains of the rcgp rsc research and surveillance activities. methods we described our domain-specific use case. the actor was the rcgp rsc sentinel network, the system was the course of the covid-19 pandemic, and the outcomes were the spread and effect of mitigation measures. we used our established 3-step method to develop the ontology, separating ontological concept development from code mapping and data extract validation. we developed a coding system\u2013independent covid-19 case identification algorithm. as there were no gold-standard pandemic surveillance ontologies, we conducted a rapid delphi consensus exercise through the international medical informatics association primary health care informatics working group and extended networks. results our use-case domains included primary care, public health, virology, clinical research, and clinical informatics. our ontology supported (1) case identification, microbiological sampling, and health outcomes at an individual practice and at the national level; (2) feedback through a dashboard; (3) a national observatory; (4) regular updates for public health england; and (5) transformation of a sentinel network into a trial platform. we have identified a total of 19,115 people with a definite covid-19 status, 5226 probable cases, and 74,293 people with possible covid-19, within the rcgp rsc network (n=5,370,225). conclusions the underpinning structure of our ontological approach has coped with multiple clinical coding challenges. at a time when there is uncertainty about international comparisons, clarity about the basis on which case definitions and outcomes are made from routine data is essential.",
            "contribution_ids": [
                "R187045"
            ]
        },
        {
            "instance_id": "R187060xR187041",
            "comparison_id": "R187060",
            "paper_id": "R187041",
            "text": "Drugs4Covid: Drug-driven Knowledge Exploitation based on Scientific Publications in the absence of sufficient medication for covid patients due to the increased demand, disused drugs have been employed or the doses of those available were modified by hospital pharmacists. some evidences for the use of alternative drugs can be found in the existing scientific literature that could assist in such decisions. however, exploiting large corpus of documents in an efficient manner is not easy, since drugs may not appear explicitly related in the texts and could be mentioned under different brand names. drugs4covid combines word embedding techniques and semantic web technologies to enable a drug-oriented exploration of large medical literature. drugs and diseases are identified according to the atc classification and mesh categories respectively. more than 60k articles and 2m paragraphs have been processed from the cord-19 corpus with information of covid-19, sars, and other related coronaviruses. an open catalogue of drugs has been created and results are publicly available through a drug browser, a keyword-guided text explorer, and a knowledge graph.",
            "contribution_ids": [
                "R187042"
            ]
        },
        {
            "instance_id": "R189691xR189569",
            "comparison_id": "R189691",
            "paper_id": "R189569",
            "text": "Hierarchical Nacre Mimetics with Synergistic Mechanical Properties by Control of Molecular Interactions in Self-Healing Polymers designing the reversible interactions of biopolymers remains a grand challenge for an integral mimicry of mechanically superior biological composites. yet, they are the key to synergistic combinations of stiffness and toughness by providing sacrificial bonds with hidden length scales. to address this challenge, dynamic polymers were designed with low glass-transition temperature t(g) and bonded by quadruple hydrogen-bonding motifs, and subsequently assembled with high-aspect-ratio synthetic nanoclays to generate nacre-mimetic films. the high dynamics and self-healing of the polymers render transparent films with a near-perfectly aligned structure. varying the polymer composition allows molecular control over the mechanical properties up to very stiff and very strong films (e\u224845\\u2005gpa, \u03c3(uts)\u2248270\\u2005mpa). stable crack propagation and multiple toughening mechanisms occur in situations of balanced dynamics, enabling synergistic combinations of stiffness and toughness. excellent gas barrier properties complement the multifunctional property profile.",
            "contribution_ids": [
                "R189571"
            ]
        },
        {
            "instance_id": "R189691xR189554",
            "comparison_id": "R189691",
            "paper_id": "R189554",
            "text": "A Constrained Assembly Strategy for High-Strength Natural Nanoclay Film developing high-performance materials from existing natural materials is highly desired because of their environmental friendliness and low cost; two-dimensional nanoclay exfoliated from layered silicate minerals is a good building block to construct multilayered macroscopic assemblies for achieving high mechanical and functional properties. nevertheless, the efforts have been frustrated by insufficient inter-nanosheet stress transfer and nanosheet misalignment caused by capillary force during solution-based spontaneous assembly, degrading the mechanical strength of clay-based materials. herein, a constrained assembly strategy that is implemented by in-plane stretching a robust water-containing nanoclay network with hydrogen and ionic bonding is developed to adjust the 2d topography of nanosheets within multilayered nanoclay film. in-plane stretching overcomes capillary force during water removal and thus restrains nanosheet conformation transition from nearly flat to wrinkled, leading to a highly aligned multilayered nanostructure with synergistic hydrogen and ionic bonding. it is proved that inter-nanosheet hydrogen and ionic bonding and nanosheet conformation extension generate profound mechanical reinforcement. the tensile strength and modulus of natural nanoclay film reach up to 429.0 mpa and 43.8 gpa and surpass the counterparts fabricated by normal spontaneous assembly. additionally, improved heat insulation function and good nonflammability are shown for the natural nanoclay film and extend its potential for realistic uses.",
            "contribution_ids": [
                "R189557"
            ]
        },
        {
            "instance_id": "R189691xR189567",
            "comparison_id": "R189691",
            "paper_id": "R189567",
            "text": "Synergistic Toughening of Bioinspired Poly(vinyl alcohol)\u00e2\u0080\u0093Clay\u00e2\u0080\u0093Nanofibrillar Cellulose Artificial Nacre inspired by the layered aragonite platelet/nanofibrillar chitin/protein ternary structure and integration of extraordinary strength and toughness of natural nacre, artificial nacre based on clay platelet/nanofibrillar cellulose/poly(vinyl alcohol) is constructed through an evaporation-induced self-assembly technique. the synergistic toughening effect from clay platelets and nanofibrillar cellulose is successfully demonstrated. the artificial nacre achieves an excellent balance of strength and toughness and a fatigue-resistant property, superior to natural nacre and other conventional layered clay/polymer binary composites.",
            "contribution_ids": [
                "R189568"
            ]
        },
        {
            "instance_id": "R189691xR189679",
            "comparison_id": "R189691",
            "paper_id": "R189679",
            "text": "Thermochromic Artificial Nacre Based on Montmorillonite nacre-inspired nanocomposites have attracted a great deal of attention in recent years because of their special mechanical properties and universality of the underlying principles of materials engineering. the ability to respond to external stimuli will augment the high toughness and high strength of artificial nacre-like composites and open new technological horizons for these materials. herein, we fabricated robust artificial nacre based on montmorillonite (mmt) that combines robustness with reversible thermochromism. our artificial nacre shows great potential in various fields such as aerospace and sensors and opens an avenue to fabricate artificial nacre responsive to other external stimuli in the future.",
            "contribution_ids": [
                "R189681"
            ]
        },
        {
            "instance_id": "R189691xR189682",
            "comparison_id": "R189691",
            "paper_id": "R189682",
            "text": "Artificial Nacre-like Bionanocomposite Films from the Self-Assembly of Chitosan-Montmorillonite Hybrid Building Blocks in the last decade, there has been a trend in chemistry to reduce the human impact on the environment. special attention has been paid to the replacement of conventional petroleum-based plastics by materials based on biopolymers. however, the mechanical and thermal properties and functionalities of these biopolymers have to be enhanced to be competitive with the petroleum-based plastics from the viewpoint of practical applications. one of the most promising solutions to overcome these drawbacks is the elaboration of bionanocomposite, namely the dispersion of nanosized filler into a biopolymer matrix. because of their functional properties, bionanocomposites as green nanocomposites based on biopolymers and layered silicates (clays) have received intensive attention in materials science. 4] chitosan and montmorillonite (mtm), an abundant polysaccharide and a natural clay respectively, have been widely used as the constituents of bionanocomposites. the intercalation of chitosan into mtm and the dispersion of mtm nanosheets in the chitosan matrix have been systematically investigated. bionanocomposites based on chitosan intercalation into mtm can be used as a sensor applied in the potentiometric determination of several anions. bionanocomposite films formed through the dispersion of mtm nanosheets in the chitosan matrix have shown enhancement of the mechanical and thermal properties compared with the pure chitosan film. unfortunately, the enhancement of the tensile strength and thermal stability of the chitosan\u2013mtm bionanocomposite film is still low far from the expectations in industry. systematic studies are carried out in materials science on natural materials with the objective of duplicating their properties in artificial materials. natural nanocomposites provide prime design models of lightweight, strong, stiff, and tough materials due to the hierarchical organization of the micro and nanostructures. one attractive biological model for artificial material design is nacre (mother-of-pearl). the microscopic architecture of nacre has been classically illustrated as a \u201cbrick-and-mortar\u201d arrangement that plays an important role in the amazing mechanical properties of the nacre. this arrangement is constituted of highly aligned inorganic aragonite platelets surrounded by a protein matrix, which serves as a glue between the platelets. recently, the microstructure of the nacre has been mimicked by several innovative techniques to fabricate the artificial nacre-like materials with high mechanical performance. for example, layer-by-layer (lbl) deposition combining with cross-linking yielded poly(vinyl alcohol)/mtm nacre-like nanocomposites with a tensile strength of up to 400 mpa; the ice-crystal templates of the microscopic layers were designed to form a brick-and-mortar microstructured al2o3/poly(methyl methacrylate) composite that is 300 times tougher than its constituents; the assembly of al2o3 platelets on the air/water interface and sequent spincoating was developed into the fabrication of lamellar al2o3/ chitosan hybrid films with high flaw tolerance and ductility; the self-assembly of nanoclays with polymers coating by a paper-making method resulted in the nacre-mimetic films; and nacre-like structural mtm\u2013polyimide nanocomposites were fabricated by centrifugation deposition-assisted assembly. our group has also fabricated nacre-like chitosanlayered double hydroxide hybrid films with a tensile strength of up to 160mpa by sequential dipping coating and the lbl technique. the concept of mimicking nacre and recently developed innovative techniques inspired us to fabricate the highly sustainable artificial nacre-like chitosan\u2013mtm bionanocomposite film with high performance to seek a promising material for the replacement of conventional petroleumbased plastics. herein, we introduce a novel approach to fabricate artificial nacre-like chitosan\u2013mtm bionanocomposite films by self-assembly of chitosan\u2013mtm hybrid building blocks (scheme 1). the chitosan molecules are very easily coated onto exfoliated mtm nanosheets to yield the hybrid building blocks by strong electrostatic and hydrogen-bonding interactions. these hybrid building blocks can be dispersed in distilled water and then aligned to a nacre-like lamellar microstructure by vacuum-filtrationor water-evaporationinduced self-assembly because of the role that the orientation of the nanosheets and linking of the chitosan play. the fabrication process is simple, fast, time-saving, and easily scaled up compared with the lbl, ice-crystal-template, and other techniques. [*] h. b. yao, z. h. tan, h. y. fang, prof. dr. s. h. yu division of nanomaterials and chemistry hefei national laboratory for physical sciences at microscale department of chemistry national synchrotron radiation laboratory university of science and technology of china hefei, anhui 230026 (p.r. china) fax: (+ 86)551-360-3040 e-mail: shyu@ustc.edu.cn homepage: http://staff.ustc.edu.cn/~ yulab/",
            "contribution_ids": [
                "R189684"
            ]
        },
        {
            "instance_id": "R189691xR189665",
            "comparison_id": "R189691",
            "paper_id": "R189665",
            "text": "Supramolecular Control of Stiffness and Strength in Lightweight High-Performance Nacre-Mimetic Paper with Fire-Shielding Properties taking the heat: hard/soft core/shell colloidal building blocks allow large-scale self-assembly to form nacre-mimetic paper. the strength and stiffness of this material can be tailored by supramolecular ionic bonds. these lightweight biomimetic materials show excellent and tunable mechanical properties and heat and fire-shielding capabilities.",
            "contribution_ids": [
                "R189667"
            ]
        },
        {
            "instance_id": "R189691xR189565",
            "comparison_id": "R189691",
            "paper_id": "R189565",
            "text": "Facile Access to Large-Scale, Self-Assembled, Nacre-Inspired, High-Performance Materials with Tunable Nanoscale Periodicities although advances have been reported to mimic the mechanically excellent structure of natural nacre, larger-scale applications are still limited due to time and energy-intensive preparation pathways. herein, we demonstrate that simple high-shear homogenization of dispersions containing biobased high molecular weight sodium carboxymethyl cellulose (700 kg/mol, cmc) and natural sodium montmorillonite (mtm), serving as the soft energy-dissipating phase and reinforcing platelets, respectively, can be used to prepare large-area and thick films with well-aligned hard/soft nacre-mimetic mesostructure. during this process, core-shell nanoplatelets with intrinsic hard/soft structure form, which then self-assemble into a layered nanocomposite during water removal. the nanoscale periodicities of the alternating hard/soft layers can be precisely tuned by changing the ratio of cmc to mtm, which allows studying the evolution of mechanical properties as a function of the lamellar nanoscale periodicity and fractions of hard to soft material. remarkable mechanical stiffness (25 gpa) and strength (320 mpa) can be obtained placing these materials among the top end of nacre-inspired materials reported so far. mechanical homogenization also allows direct preparation of concentrated, yet homogeneous, gel-like dispersions of high nanoclay content, suited to doctor-blade large-area and thick films with essentially the same properties as films cast from dilute dispersions. in terms of functional properties, we report high-transparency, shape-persistent fire-blocking and the ability to surface-pattern via inkjet printing. considering the simple, fully scalable, waterborne preparation pathway, and the use of nature-based components, we foresee applications as ecofriendly, bioinspired materials to promote sustainable engineering materials and novel types of functional barrier coatings and substrates.",
            "contribution_ids": [
                "R189566"
            ]
        },
        {
            "instance_id": "R189691xR189578",
            "comparison_id": "R189691",
            "paper_id": "R189578",
            "text": "High strength, flexible and transparent nanofibrillated cellulose\u00e2\u0080\u0093nanoclay biohybrid films with tunable oxygen and water vapor permeability a novel, technically and economically benign procedure to combine vermiculite nanoplatelets with nanocellulose fibre dispersions into functional biohybrid films is presented. nanocellulose fibres of 20 nm diameters and several micrometers in length are mixed with high aspect ratio exfoliated vermiculite nanoplatelets through high-pressure homogenization. the resulting hybrid films obtained after solvent evaporation are stiff (tensile modulus of 17.3 gpa), strong (strength up to 257 mpa), and transparent. scanning electron microscopy (sem) shows that the hybrid films consist of stratified nacre-like layers with a homogenous distribution of nanoplatelets within the nanocellulose matrix. the oxygen barrier properties of the biohybrid films outperform commercial packaging materials and pure nanocellulose films showing an oxygen permeability of 0.07 cm(3) \u03bcm m(-2) d(-1) kpa(-1) at 50% relative humidity. the oxygen permeability of the hybrid films can be tuned by adjusting the composition of the films. furthermore, the water vapor barrier properties of the biohybrid films were also significantly improved by the addition of nanoclay. the unique combination of excellent oxygen barrier behavior and optical transparency suggests the potential of these biohybrid materials as an alternative in flexible packaging of oxygen sensitive devices such as thin-film transistors or organic light-emitting diode displays, gas storage applications and as barrier coatings/laminations in large volume packaging applications.",
            "contribution_ids": [
                "R189580"
            ]
        },
        {
            "instance_id": "R189691xR189587",
            "comparison_id": "R189691",
            "paper_id": "R189587",
            "text": "Effects on the Mechanical Properties of Nacre-Like Bio-Hybrid Membranes with Inter-Penetrating Petal Structure Based on Magadiite rigid biological systems are increasingly becoming a source of inspiration for the fabrication of the advanced functional materials due to their diverse hierarchical structures and remarkable engineering properties. as a bionic biomaterial with a clear layered structure, excellent mechanical properties, and interesting rainbow colors, nacre has become one of the most attractive models for novel artificial materials design. in this research paper, the tough and strong nacre-like bio-hybrid membranes with an interpenetrating petals structure were fabricated from chitosan (cs) and magadiite (mag) clay nanosheets through the gel-casting self-assembling method. the analyses from x-ray diffraction (xrd), scanning electron microscope (sem), and observations of water droplets on membranes indicated that the nacre-like hybrid membranes had a layered compact structure. fourier transforms infrared spectroscopy (ftir) analyses suggested that the cs molecular chains formed chemical bonds and hydrogen bonds with mag layers. the inter-penetrating petal layered structure had a good effect on the mechanical properties of a nacre-like bio-hybrid membranes and the tensile strength of the hybrid membranes could reach at 78.6 mpa. however, the transmission analyses of the results showed that the hybrid membranes still had a certain visible light transmittance. finally, the hybrid membranes possessed an intriguing efficient fire-shielding property during exposure to the flame of alcohol burner. consequently, the great biocompatibility and excellent mechanical properties of the bio-hybrid membranes with the special interpenetrating petals structure provides a great opportunity for these composites to be widely applied in biomaterial research.",
            "contribution_ids": [
                "R189590"
            ]
        },
        {
            "instance_id": "R190010xR178407",
            "comparison_id": "R190010",
            "paper_id": "R178407",
            "text": "WINDS: A Wavelet-Based Intrusion Detection System for Controller Area Network (CAN) vehicles are equipped with electronic control units (ecus) to increase their overall system functionality and connectivity. however, the rising connectivity exposes a defenseless internal controller area network (can) to cyberattacks. an intrusion detection system (ids) is a supervisory module, proposed for identifying can network malicious messages, without modifying legacy ecus and causing high traffic overhead. the traditional ids approaches rely on time and frequency thresholding, leading to high false alarm rates, whereas state-of-the-art solutions may suffer from vehicle dependency. this paper presents a wavelet-based approach to locating the behavior change in the can traffic by analyzing the can network\u2019s transmission pattern. the proposed wavelet-based intrusion detection system (winds) is tested on various attack scenarios, using real vehicle traffic from two independent research centers, while being expanded toward more comprehensive attack scenarios using synthetic attacks. the technique is evaluated and compared against the state-of-the-art solutions and the baseline frequency method. experimental results show that winds offers a vehicle-independent solution applicable for various vehicles through a unique approach while generating low false alarms.",
            "contribution_ids": [
                "R178411",
                "R190003"
            ]
        },
        {
            "instance_id": "R190010xR189607",
            "comparison_id": "R190010",
            "paper_id": "R189607",
            "text": "Sliding Window Optimized Information Entropy Analysis Method for Intrusion Detection on In-Vehicle Networks with the considerable growth of cybersecurity risks in modern automobiles, cybersecurity issues in the in-vehicle network environment have attracted significant attention from security researchers in recent years. enhancing the cybersecurity ability of in-vehicle networks while considering the computing resource and cost constraints become an urgent issue. to address this problem, a novel information entropy-based method is proposed in this paper, which uses a fixed number of messages as sliding windows. by improving the sliding window strategy and optimizing the decision conditions, the detection accuracy is increased and the false positive rate is reduced. experimental results demonstrate that the proposed method can provide real-time response to attacks with a considerably improved detection precision for intrusion detection in the in-vehicle network environment.",
            "contribution_ids": [
                "R189611"
            ]
        },
        {
            "instance_id": "R190010xR189549",
            "comparison_id": "R190010",
            "paper_id": "R189549",
            "text": "Frequency-based anomaly detection for the automotive CAN bus the modern automobile is controlled by networked computers. the security of these networks was historically of little concern, but researchers have in recent years demonstrated their many vulnerabilities to attack. as part of a defence against these attacks, we evaluate an anomaly detector for the automotive controller area network (can) bus. the majority of attacks are based on inserting extra packets onto the network. but most normal packets arrive at a strict frequency. this motivates an anomaly detector that compares current and historical packet timing. we present an algorithm that measures inter-packet timing over a sliding window. the average times are compared to historical averages to yield an anomaly signal. we evaluate this approach over a range of insertion frequencies and demonstrate the limits of its effectiveness. we also show how a similar measure of the data contents of packets is not effective for identifying anomalies. finally we show how a one-class support vector machine can use the same information to detect anomalies with high confidence.",
            "contribution_ids": [
                "R189551"
            ]
        },
        {
            "instance_id": "R190010xR188875",
            "comparison_id": "R190010",
            "paper_id": "R188875",
            "text": "CANet: An Unsupervised Intrusion Detection System for High Dimensional CAN Bus Data we propose a neural network architecture for detecting intrusions on the controller area network (can). the latter is the standard communication method between the electronic control units (ecus) of automobiles. however, can lacks security mechanisms and it has recently been shown that it can be attacked remotely. hence, it is desirable to monitor can traffic to detect intrusions. in order to find both, known and unknown intrusion scenarios, we consider a novel unsupervised learning approach which we call canet. to our knowledge, this is the first deep learning based intrusion detection system (ids) that naturally handles the data structure of the high dimensional can bus, where different message types are sent at different times. our method is evaluated on real and synthetic can data. a comparison with previous machine learning based methods shows that canet outperforms them by a significant margin. for reproducibility of the method, our synthetic data is publicly available.",
            "contribution_ids": [
                "R188880",
                "R189617"
            ]
        },
        {
            "instance_id": "R190010xR189547",
            "comparison_id": "R190010",
            "paper_id": "R189547",
            "text": "Design and implementation of an intrusion detection system (IDS)for in-vehicle networks the controller area network (can) was specified with no regards to security mechanisms\\nat all. this fact in combination with the widespread adoption of the can\\nstandard for connecting more than a hundred electrical control units (ecus),\\nwhich control almost every aspect of modern cars, makes the can bus a valuable\\ntarget for adversaries. as vehicles are safety-critical systems and the physical\\nintegrity of the driver has the highest priority, it is necessary to invent suitable\\ncountermeasures to limit can\u2019s security risks. as a matter of fact, the close resemblances\\nof in-vehicle networks to traditional computer networks, enables the use of\\nconventional countermeasures, e.g. intrusion detection systems (ids).\\nwe propose a software-based light-weight ids relying on properties extracted from\\nthe signal database of a can domain. further, we suggest two anomaly-based\\nalgorithms based on message cycle time analysis and plausibility analysis of messages\\n(e.g. speed messages). we evaluate our ids on a simulated setup, as well as a real\\nin-vehicle network, by performing attacks on different parts of the network. our\\nevaluation shows that the proposed ids successfully detects malicious events such\\nas injection of malformed can frames, unauthorized can frames, speedometer\\nplausibility detection and denial of service (dos) attacks.\\nbased on our experience of implementing an in-vehicle ids, we discuss potential\\nchallenges and constraints that engineers might face during the process of implementing\\nan ids system for in-vehicle networks. we believe that the results of this\\nwork can contribute to more advanced research in the field of intrusion detection\\nsystems for in-vehicle networks and thereby add to a safer driving experience.",
            "contribution_ids": [
                "R189548"
            ]
        },
        {
            "instance_id": "R190010xR189613",
            "comparison_id": "R190010",
            "paper_id": "R189613",
            "text": "Behavior Analysis for Safety and Security in Automotive Systems the connection of automotive systems with other systems such as road-side units, other vehicles, and various servers in the internet opens up new ways for attackers to remotely access safety relevant subsystems within connected cars. the security of connected cars and the whole vehicular ecosystem is thus of utmost importance for consumer trust and acceptance of this emerging technology. this paper describes an approach for on-board detection of unanticipated sequences of events in order to identify suspicious activities. the results show that this approach is fast enough for in-vehicle application at runtime. several behavior models and synchronization strategies are analyzed in order to narrow down suspicious sequences of events to be sent in a privacy respecting way to a global security operations center for further in-depth analysis.",
            "contribution_ids": [
                "R189615"
            ]
        },
        {
            "instance_id": "R190010xR189537",
            "comparison_id": "R190010",
            "paper_id": "R189537",
            "text": "Fingerprinting Electronic Control Units for Vehicle Intrusion Detection \"as more software modules and external interfaces are getting added on vehicles, new attacks and vulnerabilities are emerging. researchers have demonstrated how to compromise in-vehicle electronic control units (ecus) and control the vehicle maneuver. to counter these vulnerabilities, various types of defense mechanisms have been proposed, but they have not been able to meet the need of strong protection for safety-critical ecus against in-vehicle network attacks. to mitigate this deficiency, we propose an anomaly-based intrusion detection system (ids), called clock-based ids (cids). it measures and then exploits the intervals of periodic in-vehicle messages for fingerprinting ecus. the thus-derived fingerprints are then used for constructing a baseline of ecus' clock behaviors with the recursive least squares (rls) algorithm. based on this baseline, cids uses cumulative sum (cusum) to detect any abnormal shifts in the identification errors - a clear sign of intrusion. this allows quick identification of in-vehicle network intrusions with a low false-positive rate of 0.055%. unlike state-of-the-art idss, if an attack is detected, cids's fingerprinting of ecus also facilitates a rootcause analysis; identifying which ecu mounted the attack. our experiments on a can bus prototype and on real vehicles have shown cids to be able to detect a wide range of in-vehicle network attacks.\"",
            "contribution_ids": [
                "R189539"
            ]
        },
        {
            "instance_id": "R191054xR189997",
            "comparison_id": "R191054",
            "paper_id": "R189997",
            "text": "Correlation between gastrointestinal symptoms and disease severity in patients with COVID-19: a systematic review and meta-analysis objective to study the correlation between gastrointestinal (gi) symptoms and disease severity in patients with covid-19. design we searched six databases including three chinese and three english databases for all the published articles on covid-19. studies were screened according to inclusion and exclusion criteria. the relevant data were extracted and all the statistical analyses were performed using revman5.3. result in a meta-analysis of 9 studies, comprising 3022 patients, 479 patients (13.7%, 95%\\u2009ci 0.125 to 0.149) had severe disease and 624 patients (14.7%, 95%\\u2009ci 0.136 to 0.159) had gi symptoms. of 624 patients with gi symptoms, 118 patients had severe disease (20.5%, 95%\\u2009ci 0.133 to 0.276) and of 2397 cases without gi symptoms, 361 patients had severe disease (18.2%, 95%\\u2009ci 0.129 to 0.235). comparing disease severity of patients with and without gi symptoms, the results indicated: i\u00b2=62%, or=1.21, 95%\\u2009ci 0.94 to 1.56, p=0.13; there was no statistically significant difference between the two groups. the funnel plot was symmetrical with no publication bias. conclusion current results are not sufficient to demonstrate a significant correlation between gi symptoms and disease severity in patients with covid-19.",
            "contribution_ids": [
                "R190000"
            ]
        },
        {
            "instance_id": "R191054xR189866",
            "comparison_id": "R191054",
            "paper_id": "R189866",
            "text": "Gastrointestinal symptoms and digestive comorbidities in an Italian cohort of patients with COVID-19 \"objective\\nthe coronavirus disease 2019 (covid-19) pandemic mainly involves respiratory symptoms, though gastrointestinal (gi) symptoms are increasingly being recognized. in this context, the presence of comorbidities appears to be associated with adverse outcomes. however, the role of digestive manifestations is not yet well defined. the primary aim of this study was to assess the prevalence of gi symptoms and digestive comorbidities in a cohort of patients with covid-19 compared to controls. the secondary aim was to determine the association of gi-symptoms and digestive comorbidities with clinical outcomes.\\n\\n\\npatients and methods\\ninpatients with covid-19 and controls with similar symptoms and/or radiological findings were enrolled. symptoms at admission and throughout hospitalization were collected as they were comorbidities. the measured clinical outcomes were mortality, intensive care unit admission and cumulative endpoint.\\n\\n\\nresults\\na total of 105 patients were included: 34 with covid-19 and 71 controls. at admission, the prevalence of gi symptoms among covid-19 patients was 8.8%. during hospitalization, the frequency of gi symptoms was higher in patients with covid-19 than in controls (p=0.004). among patients with covid-19, the mortality and a cumulative endpoint rates of those with gi symptoms were both lower than for those without gi symptoms (p=0.016 and p=0.000, respectively). finally, we found digestive comorbidities to be associated with a milder course of covid-19 (p=0.039 for cumulative endpoint).\\n\\n\\nconclusions\\nour results highlighted the non-negligible frequency of gi symptoms in patients with covid-19, partly attributable to the therapies implemented. in addition, the presence of gi symptoms and digestive comorbidities is associated with better outcomes. most likely, digestive comorbidities do not hinder the host's immune response against sars-cov-2, and the occurrence of gi symptoms might be linked to a faster reduction of the viral load via the faecal route.\"",
            "contribution_ids": [
                "R189868"
            ]
        },
        {
            "instance_id": "R191054xR189870",
            "comparison_id": "R191054",
            "paper_id": "R189870",
            "text": "Epidemiological, clinical and virological characteristics of 74 cases of coronavirus-infected disease 2019 (COVID-19) with gastrointestinal symptoms objective the sars-cov-2-infected disease (covid-19) outbreak is a major threat to human beings. previous studies mainly focused on wuhan and typical symptoms. we analysed 74 confirmed covid-19 cases with gi symptoms in the zhejiang province to determine epidemiological, clinical and virological characteristics. design covid-19 hospital patients were admitted in the zhejiang province from 17 january 2020 to 8 february 2020. epidemiological, demographic, clinical, laboratory, management and outcome data of patients with gi symptoms were analysed using multivariate analysis for risk of severe/critical type. bioinformatics were used to analyse features of sars-cov-2 from zhejiang province. results among enrolled 651 patients, 74 (11.4%) presented with at least one gi symptom (nausea, vomiting or diarrhoea), average age of 46.14 years, 4-day incubation period and 10.8% had pre-existing liver disease. of patients with covid-19 with gi symptoms, 17 (22.97%) and 23 (31.08%) had severe/critical types and family clustering, respectively, significantly higher than those without gi symptoms, 47 (8.14%) and 118 (20.45%). of patients with covid-19 with gi symptoms, 29 (39.19%), 23 (31.08%), 8 (10.81%) and 16 (21.62%) had significantly higher rates of fever &gt;38.5\u00b0c, fatigue, shortness of breath and headache, respectively. low-dose glucocorticoids and antibiotics were administered to 14.86% and 41.89% of patients, respectively. sputum production and increased lactate dehydrogenase/glucose levels were risk factors for severe/critical type. bioinformatics showed sequence mutation of sars-cov-2 with m 6 a methylation and changed binding capacity with ace2. conclusion we report covid-19 cases with gi symptoms with novel features outside wuhan. attention to patients with covid-19 with non-classic symptoms should increase to protect health providers.",
            "contribution_ids": [
                "R189874"
            ]
        },
        {
            "instance_id": "R191054xR189856",
            "comparison_id": "R191054",
            "paper_id": "R189856",
            "text": "Gastrointestinal symptoms of 95 cases with SARS-CoV-2 infection objective to study the gi symptoms in severe acute respiratory syndrome coronavirus 2 (sars-cov-2) infected patients. design we analysed epidemiological, demographic, clinical and laboratory data of 95 cases with sars-cov-2 caused coronavirus disease 2019. real-time reverse transcriptase pcr was used to detect the presence of sars-cov-2 in faeces and gi tissues. results among the 95 patients, 58 cases exhibited gi symptoms of which 11 (11.6%) occurred on admission and 47 (49.5%) developed during hospitalisation. diarrhoea (24.2%), anorexia (17.9%) and nausea (17.9%) were the main symptoms with five (5.3%), five (5.3%) and three (3.2%) cases occurred on the illness onset, respectively. a substantial proportion of patients developed diarrhoea during hospitalisation, potentially aggravated by various drugs including antibiotics. faecal samples of 65 hospitalised patients were tested for the presence of sars-cov-2, including 42 with and 23 without gi symptoms, of which 22 (52.4%) and 9 (39.1%) were positive, respectively. six patients with gi symptoms were subjected to endoscopy, revealing oesophageal bleeding with erosions and ulcers in one severe patient. sars-cov-2 rna was detected in oesophagus, stomach, duodenum and rectum specimens for both two severe patients. in contrast, only duodenum was positive in one of the four non-severe patients. conclusions gi tract may be a potential transmission route and target organ of sars-cov-2.",
            "contribution_ids": [
                "R189860"
            ]
        },
        {
            "instance_id": "R191054xR190036",
            "comparison_id": "R191054",
            "paper_id": "R190036",
            "text": "Gastrointestinal Symptoms and Outcomes in Hospitalized Coronavirus Disease 2019 Patients &lt;b&gt;&lt;i&gt;introduction:&lt;/i&gt;&lt;/b&gt; gastrointestinal (gi) symptoms are increasingly being recognized in coronavirus disease 2019 (covid-19). it is unclear if the presence of gi symptoms is associated with poor outcomes in covid-19. we aim to assess if gi symptoms could be used for prognostication in hospitalized patients with covid-19. &lt;b&gt;&lt;i&gt;methods:&lt;/i&gt;&lt;/b&gt; we retrospectively analyzed patients admitted to a tertiary medical center in brooklyn, ny, from march 18, 2020, to march 31, 2020, with covid-19. the patients\u2019 medical charts were reviewed for the presence of gi symptoms at admission, including nausea, vomiting, diarrhea, and abdominal pain. covid-19 patients with gi symptoms (cases) were compared with covid-19 patients without gi symptoms (control). &lt;b&gt;&lt;i&gt;results:&lt;/i&gt;&lt;/b&gt; a total of 150 hospitalized covid-19 patients were included, of which 31 (20.6%) patients had at least 1 or more of the gi symptoms (cases). they were compared with the 119 covid-19 patients without gi symptoms (controls). the average age among cases was 57.6 years (sd 17.2) and control was 63.3 years (sd 14.6). no statistically significant difference was noted in comorbidities and laboratory findings. the primary outcome was mortality, which did not differ between cases and controls (41.9 vs. 37.8%, &lt;i&gt;p&lt;/i&gt; = 0.68). no statistically significant differences were noted in secondary outcomes, including the length of stay (los, 7.8 vs. 7.9 days, &lt;i&gt;p&lt;/i&gt; = 0.87) and need for mechanical ventilation (29 vs. 26.9%, &lt;i&gt;p&lt;/i&gt; = 0.82). &lt;b&gt;&lt;i&gt;discussion:&lt;/i&gt;&lt;/b&gt; in our study, the presence of gi manifestations in covid-19 at the time of admission was not associated with increased mortality, los, or mechanical ventilation.",
            "contribution_ids": [
                "R190038"
            ]
        },
        {
            "instance_id": "R191054xR190027",
            "comparison_id": "R191054",
            "paper_id": "R190027",
            "text": "Gastrointestinal manifestations of COVID-19 in a single center in the Eastern Province of Saudi Arabia background: several gastrointestinal (gi) symptoms have been associated with novel coronavirus disease-2019 (covid-19). their prevalence and relation to the severity and hospital outcome of covid-19 have not been well reported in the middle east and saudi arabia. we aimed to examine the gi manifestations of covid-19 and their association with the severity and hospital outcome of covid-19 infection. methods: we conducted a retrospective observational study of hospitalized covid-19 patients who had a positive sars-cov2 pcr test and were admitted at a university hospital in saudi arabia, from march to september 2020. the primary objective of the study was to describe the gi manifestations of covid-19. the secondary objective was to investigate the association of gi manifestations with severity and outcome of covid-19 infection. results: we included 390 patients, of which 111 (28.5%) presented with gi manifestations. the most common presentation was diarrhea followed by nausea, vomiting, and abdominal pain. patients without gi manifestations had a higher risk of severe-critical covid-19 infection evident by the development of lung infiltration in more than 50% of lung fields within 24\u201348 h, acute respiratory distress syndrome, altered mental status, multiorgan failure, and cytokine storm syndrome (p < 0.05). these patients had a higher mortality rate compared to patients with gi manifestations (p = 0.01). a lower odds of death was seen among patients with gi symptoms (aor 0.36; 95% ci, 0.158\u20130.82; p = 0.01). conclusion: covid-19 infection presents commonly with gi manifestations. patients with gi manifestations have less severe covid-19 disease and lower mortality rates.",
            "contribution_ids": [
                "R190029"
            ]
        },
        {
            "instance_id": "R191054xR189960",
            "comparison_id": "R191054",
            "paper_id": "R189960",
            "text": "Prevalence and Characteristics of Gastrointestinal Symptoms in Patients With Severe Acute Respiratory Syndrome Coronavirus 2 Infection in the United States: A Multicenter Cohort Study although anecdotally coronavirus disease 2019 (covid-19) presents most commonly with respiratory symptoms, severe acute respiratory syndrome coronavirus 2 (sars-cov-2) obtains cellular entry via the widely expressed angiotensin-converting enzyme 2 (ace2) receptors, thus increasing the risk of not only respiratory but also alimentary tract involvement.1, 2, 3 early reports from china have described gastrointestinal symptoms in as many as half of patients diagnosed with covid-19; however, data regarding the potential gastrointestinal implications of covid-19 among the us patient population remain limited.4, 5, 6 therefore, we aimed to systematically characterize the prevalence and features of gastrointestinal manifestations associated with sars-cov-2 infection and evaluate gastrointestinal-specific health outcomes among a cohort of us adults.",
            "contribution_ids": [
                "R189963"
            ]
        },
        {
            "instance_id": "R191407xR191355",
            "comparison_id": "R191407",
            "paper_id": "R191355",
            "text": "Domain Adaptive Fake News Detection via Reinforcement Learning with social media being a major force in information consumption, accelerated propagation of fake news has presented new challenges for platforms to distinguish between legitimate and fake news. effective fake news detection is a non-trivial task due to the diverse nature of news domains and expensive annotation costs. in this work, we address the limitations of existing automated fake news detection models by incorporating auxiliary information (e.g., user comments and user-news interactions) into a novel reinforcement learning-based model called reinforced adaptive learning fake news detection (real-fnd). real-fnd exploits cross-domain and within-domain knowledge that makes it robust in a target domain, despite being trained in a different source domain. extensive experiments on real-world datasets illustrate the effectiveness of the proposed model, especially when limited labeled data is available in the target domain.",
            "contribution_ids": [
                "R191357"
            ]
        },
        {
            "instance_id": "R191407xR191344",
            "comparison_id": "R191407",
            "paper_id": "R191344",
            "text": "Unsupervised Fake News Detection on Social Media: A Generative Approach social media has become one of the main channels for people to access and consume news, due to the rapidness and low cost of news dissemination on it. however, such properties of social media also make it a hotbed of fake news dissemination, bringing negative impacts on both individuals and society. therefore, detecting fake news has become a crucial problem attracting tremendous research effort. most existing methods of fake news detection are supervised, which require an extensive amount of time and labor to build a reliably annotated dataset. in search of an alternative, in this paper, we investigate if we could detect fake news in an unsupervised manner. we treat truths of news and users\u2019 credibility as latent random variables, and exploit users\u2019 engagements on social media to identify their opinions towards the authenticity of news. we leverage a bayesian network model to capture the conditional dependencies among the truths of news, the users\u2019 opinions, and the users\u2019 credibility. to solve the inference problem, we propose an efficient collapsed gibbs sampling approach to infer the truths of news and the users\u2019 credibility without any labelled data. experiment results on two datasets show that the proposed method significantly outperforms the compared unsupervised methods.",
            "contribution_ids": [
                "R191346"
            ]
        },
        {
            "instance_id": "R191407xR191201",
            "comparison_id": "R191407",
            "paper_id": "R191201",
            "text": "Hierarchical Propagation Networks for Fake News Detection: Investigation and Exploitation consuming news from social media is becoming increasingly popular. however, social media also enables the widespread of fake news. because of its detrimental effects brought by social media, fake news detection has attracted increasing attention. however, the performance of detecting fake news only from news content is generally limited as fake news pieces are written to mimic true news. in the real world, news pieces spread through propagation networks on social media. the news propagation networks usually involve multi-levels. in this paper, we study the challenging problem of investigating and exploiting news hierarchical propagation network on social media for fake news detection. \\nin an attempt to understand the correlations between news propagation networks and fake news, first, we build a hierarchical propagation network from macro-level and micro-level of fake news and true news; second, we perform a comparative analysis of the propagation network features of linguistic, structural and temporal perspectives between fake and real news, which demonstrates the potential of utilizing these features to detect fake news; third, we show the effectiveness of these propagation network features for fake news detection. we further validate the effectiveness of these features from feature important analysis. altogether, this work presents a data-driven view of hierarchical propagation network and fake news and paves the way towards a healthier online news ecosystem.",
            "contribution_ids": [
                "R191203"
            ]
        },
        {
            "instance_id": "R191407xR191209",
            "comparison_id": "R191407",
            "paper_id": "R191209",
            "text": "EANN: Event Adversarial Neural Networks for Multi-Modal Fake News Detection as news reading on social media becomes more and more popular, fake news becomes a major issue concerning the public and government. the fake news can take advantage of multimedia content to mislead readers and get dissemination, which can cause negative effects or even manipulate the public events. one of the unique challenges for fake news detection on social media is how to identify fake news on newly emerged events. unfortunately, most of the existing approaches can hardly handle this challenge, since they tend to learn event-specific features that can not be transferred to unseen events. in order to address this issue, we propose an end-to-end framework named event adversarial neural network (eann), which can derive event-invariant features and thus benefit the detection of fake news on newly arrived events. it consists of three main components: the multi-modal feature extractor, the fake news detector, and the event discriminator. the multi-modal feature extractor is responsible for extracting the textual and visual features from posts. it cooperates with the fake news detector to learn the discriminable representation for the detection of fake news. the role of event discriminator is to remove the event-specific features and keep shared features among events. extensive experiments are conducted on multimedia datasets collected from weibo and twitter. the experimental results show our proposed eann model can outperform the state-of-the-art methods, and learn transferable feature representations.",
            "contribution_ids": [
                "R191211"
            ]
        },
        {
            "instance_id": "R191407xR191251",
            "comparison_id": "R191407",
            "paper_id": "R191251",
            "text": "Neural User Response Generator: Fake News Detection with Collective User Intelligence fake news on social media is a major challenge and studies have shown that fake news can propagate exponentially quickly in early stages. therefore, we focus on early detection of fake news, and consider that only news article text is available at the time of detection, since additional information such as user responses and propagation patterns can be obtained only after the news spreads. however, we find historical user responses to previous articles are available and can be treated as soft semantic labels, that enrich the binary label of an article, by providing insights into why the article must be labeled as fake. we propose a novel two-level convolutional neural network with user response generator (tcnn-urg) where tcnn captures semantic information from article text by representing it at the sentence and word level, and urg learns a generative model of user response to article text from historical user responses which it can use to generate responses to new articles in order to assist fake news detection. we conduct experiments on one available dataset and a larger dataset collected by ourselves. experimental results show that tcnn-urg outperforms the baselines based on prior approaches that detect fake news from article text alone.",
            "contribution_ids": [
                "R191253"
            ]
        },
        {
            "instance_id": "R191407xR191366",
            "comparison_id": "R191407",
            "paper_id": "R191366",
            "text": "Beyond News Contents: The Role of Social Context for Fake News Detection social media is becoming popular for news consumption due to its fast dissemination, easy access, and low cost. however, it also enables the wide propagation of fake news, i.e., news with intentionally false information. detecting fake news is an important task, which not only ensures users receive authentic information but also helps maintain a trustworthy news ecosystem. the majority of existing detection algorithms focus on finding clues from news contents, which are generally not effective because fake news is often intentionally written to mislead users by mimicking true news. therefore, we need to explore auxiliary information to improve detection. the social context during news dissemination process on social media forms the inherent tri-relationship, the relationship among publishers, news pieces, and users, which has the potential to improve fake news detection. for example, partisan-biased publishers are more likely to publish fake news, and low-credible users are more likely to share fake news. in this paper, we study the novel problem of exploiting social context for fake news detection. we propose a tri-relationship embedding framework trifn, which models publisher-news relations and user-news interactions simultaneously for fake news classification. we conduct experiments on two real-world datasets, which demonstrate that the proposed approach significantly outperforms other baseline methods for fake news detection.",
            "contribution_ids": [
                "R191368"
            ]
        },
        {
            "instance_id": "R191655xR187041",
            "comparison_id": "R191655",
            "paper_id": "R187041",
            "text": "Drugs4Covid: Drug-driven Knowledge Exploitation based on Scientific Publications in the absence of sufficient medication for covid patients due to the increased demand, disused drugs have been employed or the doses of those available were modified by hospital pharmacists. some evidences for the use of alternative drugs can be found in the existing scientific literature that could assist in such decisions. however, exploiting large corpus of documents in an efficient manner is not easy, since drugs may not appear explicitly related in the texts and could be mentioned under different brand names. drugs4covid combines word embedding techniques and semantic web technologies to enable a drug-oriented exploration of large medical literature. drugs and diseases are identified according to the atc classification and mesh categories respectively. more than 60k articles and 2m paragraphs have been processed from the cord-19 corpus with information of covid-19, sars, and other related coronaviruses. an open catalogue of drugs has been created and results are publicly available through a drug browser, a keyword-guided text explorer, and a knowledge graph.",
            "contribution_ids": [
                "R187042"
            ]
        },
        {
            "instance_id": "R191655xR187043",
            "comparison_id": "R191655",
            "paper_id": "R187043",
            "text": "COVID-19 Surveillance in a Primary Care Sentinel Network: In-Pandemic Development of an Application Ontology background creating an ontology for covid-19 surveillance should help ensure transparency and consistency. ontologies formalize conceptualizations at either the domain or application level. application ontologies cross domains and are specified through testable use cases. our use case was an extension of the role of the oxford royal college of general practitioners (rcgp) research and surveillance centre (rsc) to monitor the current pandemic and become an in-pandemic research platform. objective this study aimed to develop an application ontology for covid-19 that can be deployed across the various use-case domains of the rcgp rsc research and surveillance activities. methods we described our domain-specific use case. the actor was the rcgp rsc sentinel network, the system was the course of the covid-19 pandemic, and the outcomes were the spread and effect of mitigation measures. we used our established 3-step method to develop the ontology, separating ontological concept development from code mapping and data extract validation. we developed a coding system\u2013independent covid-19 case identification algorithm. as there were no gold-standard pandemic surveillance ontologies, we conducted a rapid delphi consensus exercise through the international medical informatics association primary health care informatics working group and extended networks. results our use-case domains included primary care, public health, virology, clinical research, and clinical informatics. our ontology supported (1) case identification, microbiological sampling, and health outcomes at an individual practice and at the national level; (2) feedback through a dashboard; (3) a national observatory; (4) regular updates for public health england; and (5) transformation of a sentinel network into a trial platform. we have identified a total of 19,115 people with a definite covid-19 status, 5226 probable cases, and 74,293 people with possible covid-19, within the rcgp rsc network (n=5,370,225). conclusions the underpinning structure of our ontological approach has coped with multiple clinical coding challenges. at a time when there is uncertainty about international comparisons, clarity about the basis on which case definitions and outcomes are made from routine data is essential.",
            "contribution_ids": [
                "R187045"
            ]
        },
        {
            "instance_id": "R191656xR187017",
            "comparison_id": "R191656",
            "paper_id": "R187017",
            "text": "The Infectious Disease Ontology in the age of COVID-19 background: effective response to public health emergencies, such as we are now experiencing with covid-19, requires data sharing across multiple disciplines and data systems. ontologies offer a powerful data sharing tool, and this holds especially for those ontologies built on the design principles of the open biomedical ontologies foundry. these principles are exemplified by the infectious disease ontology (ido), a suite of interoperable ontology modules aiming to provide coverage of all aspects of the infectious disease domain. at its center is ido core, a disease- and pathogen-neutral ontology covering just those types of entities and relations that are relevant to infectious diseases generally. ido core is extended by disease and pathogen-specific ontology modules.results: to assist the integration and analysis of covid-19 data, and viral infectious disease data more generally, we have recently developed three new ido extensions: ido virus (vido); the coronavirus infectious disease ontology (cido); and an extension of cido focusing on covid-19 (ido-covid-19). reflecting the fact that viruses lack cellular parts, we have introduced to ido core the term acellular structure to cover viruses and other acellular entities studied by virologists. we now distinguish between infectious agents \u2013 organisms with an infectious disposition \u2013 and infectious structures \u2013 acellular structures with an infectious disposition. this in turn has led to various updates and refinements of ido core\u2019s content. we believe that our work on vido, cido, and ido-covid-19 can serve as a model for yielding greater conformance with ontology building best practices.conclusions: ido provides a simple recipe for building new pathogen-specific ontologies in a way that allows data about novel diseases to be easily compared, along multiple dimensions, with data represented by existing disease ontologies. the ido strategy, moreover, supports ontology coordination, providing a powerful method of data integration and sharing that allows physicians, researchers, and public health organizations to respond rapidly and efficiently to current and future public health crises.",
            "contribution_ids": [
                "R187019"
            ]
        },
        {
            "instance_id": "R191656xR187043",
            "comparison_id": "R191656",
            "paper_id": "R187043",
            "text": "COVID-19 Surveillance in a Primary Care Sentinel Network: In-Pandemic Development of an Application Ontology background creating an ontology for covid-19 surveillance should help ensure transparency and consistency. ontologies formalize conceptualizations at either the domain or application level. application ontologies cross domains and are specified through testable use cases. our use case was an extension of the role of the oxford royal college of general practitioners (rcgp) research and surveillance centre (rsc) to monitor the current pandemic and become an in-pandemic research platform. objective this study aimed to develop an application ontology for covid-19 that can be deployed across the various use-case domains of the rcgp rsc research and surveillance activities. methods we described our domain-specific use case. the actor was the rcgp rsc sentinel network, the system was the course of the covid-19 pandemic, and the outcomes were the spread and effect of mitigation measures. we used our established 3-step method to develop the ontology, separating ontological concept development from code mapping and data extract validation. we developed a coding system\u2013independent covid-19 case identification algorithm. as there were no gold-standard pandemic surveillance ontologies, we conducted a rapid delphi consensus exercise through the international medical informatics association primary health care informatics working group and extended networks. results our use-case domains included primary care, public health, virology, clinical research, and clinical informatics. our ontology supported (1) case identification, microbiological sampling, and health outcomes at an individual practice and at the national level; (2) feedback through a dashboard; (3) a national observatory; (4) regular updates for public health england; and (5) transformation of a sentinel network into a trial platform. we have identified a total of 19,115 people with a definite covid-19 status, 5226 probable cases, and 74,293 people with possible covid-19, within the rcgp rsc network (n=5,370,225). conclusions the underpinning structure of our ontological approach has coped with multiple clinical coding challenges. at a time when there is uncertainty about international comparisons, clarity about the basis on which case definitions and outcomes are made from routine data is essential.",
            "contribution_ids": [
                "R187045"
            ]
        },
        {
            "instance_id": "R191658xR185000",
            "comparison_id": "R191658",
            "paper_id": "R185000",
            "text": "Absolute measurement of the resonance lines in heliumlike vanadium on an electron-beam ion trap trap are reported. the 1 s2p 1 p1!1s 2 ,1 s2p 3 p2!1s 2 ~1s2p 3 p1!1s 2 and 1s2p 3 p0!1s 2 ! blend and 1s2s 3 s1!1s 2 transitions are 5205.10 6 0.14 ev, 5189.12 6 0.21 ev, 5180.22 6 0.17 ev, and 5153.82 6 0.14 ev, respectively. this agrees with recent theoretical calculations and the experimental precision lies at the same level as the current uncertainty in theory ~0.1 ev!. these measurements represent a 5.7\u20108% determination of the qed contribution to the transition energies and are the most precise measurements of heliumlike resonance lines in the z519\u2010 31 range. the measurement of the 1s2s 3 s1!1s 2 transition is also sensitive to the 1 s2s 3 s1 qed contribution at the 40% level. the intensity of the strong 1 s2p 3 p1!1s 2 component of the blend compared to the total blend intensity is 94%612%. this is in accord with current theoretical predictions but disagrees with an earlier reported ratio.",
            "contribution_ids": [
                "R185001"
            ]
        },
        {
            "instance_id": "R191658xR184047",
            "comparison_id": "R191658",
            "paper_id": "R184047",
            "text": "Theoretical energies for the n\u00e2\u0080\u0082=\u00e2\u0080\u00821 and 2 states of the helium isoelectronic sequence up to Z\u00e2\u0080\u0082=\u00e2\u0080\u0082100 the unified method described previously for combining high-precision nonrelativistic variational calculations with relativistic and quantum electrodynamic corrections is applied to the 1s 2 \\u2002 1 s 0 , 1s2s\\u2002 1 s 0 , 1s2s\\u2002 3 s 1 , 1s2p\\u2002 1 p 1 , and 1s2p\\u2002 3 p 0,1,2 staters of helium-like ions. detailed tabulations are presented for all ions in the range 2\\u2002\u2264\\u2002z\\u2002\u2264\\u2002100 and are compared with a wide range of experimental data up to 34 kr + . the results for 90 u + significantly alter the recent lamb shift measurement of munger and gould from 70.4\\u2002\u00b1\\u20028.3 to 71.0\\u2002\u00b1\\u20028.3\\u2002ev, in comparison with a revised theoretical value of 74.3\\u2002\u00b1\\u20020.4\\u2002ev. the improved agreement is due to the inclusion of higher order two-electron corrections in the present work.",
            "contribution_ids": [
                "R184049",
                "R184056",
                "R185067",
                "R185100",
                "R185174",
                "R185213"
            ]
        },
        {
            "instance_id": "R191976xR190553",
            "comparison_id": "R191976",
            "paper_id": "R190553",
            "text": "High-precision spectroscopic study of heliumlike iron the x-ray spectrum emitted by high-velocity heliumlike iron ions has been studied with a crystal spectrometer. the absolute energies of the n = 2..-->..n = 1 lines have been measured with a precision of 40 ppm. a very good agreement has been found between our experimental values and a very accurate multiconfiguration dirac-fock calculation. the precision of the measurement and the calculation of the energies are such that for the first time the magnetic correlation energy (spin-spin) as well as the screening of quantum-electrodynamic effects can now be appreciated. the contamination of the considered lines by the so-called dielectronic recombination satellites has been studied in great detail by varying the nature and the thickness of the targets.",
            "contribution_ids": [
                "R190554"
            ]
        },
        {
            "instance_id": "R191976xR190520",
            "comparison_id": "R191976",
            "paper_id": "R190520",
            "text": "High Precision Spectroscopic Studies of Few Electron Ions in this report some experiments are described in which the lyman ..cap alpha.. lines of hydrogen-like and helium-like argon and iron ions have been measured. the principle of all these experiments was to study with a crystal spectrometer the x rays emitted in flight by the ions, at 90/sup 0/ with respect to the direction of the beam. 5 references, 14 figures, 9 tables.",
            "contribution_ids": [
                "R190522"
            ]
        },
        {
            "instance_id": "R191976xR189910",
            "comparison_id": "R191976",
            "paper_id": "R189910",
            "text": "Spectroscopy of hydrogenlike and heliumlike argon the x-ray transitions ($n=2\\\\ensuremath{\\\\rightarrow}n=1$) emitted by fast hydrogenlike and heliumlike argon ions have been studied. the absolute energy of the lyman $\\\\ensuremath{\\\\alpha}$ lines of hydrogenlike ions has been measured and the value of the ($1s$) lamb shift of argon evaluated for the first time. the $^{3}p_{1,2}$ and $^{1}p_{1}$ transitions of heliumlike argon have also been studied at very high precision and their energies compared to multiconfiguration dirac-fock calculations. the energies of lyman $\\\\ensuremath{\\\\alpha}$ lines are of 3323.2\\\\ifmmode\\\\pm\\\\else\\\\textpm\\\\fi{}0.5 ev ($\\\\mathrm{ly}{\\\\ensuremath{\\\\alpha}}_{1}$) and 3318.1\\\\ifmmode\\\\pm\\\\else\\\\textpm\\\\fi{}0.5 ev ($\\\\mathrm{ly}{\\\\ensuremath{\\\\alpha}}_{2}$), and those of $n=2\\\\ensuremath{\\\\rightarrow}n=1$ transitions for heliumlike argon are of 3123.6\\\\ifmmode\\\\pm\\\\else\\\\textpm\\\\fi{}0.25 ev ($^{3}p_{1}$), 3126.4\\\\ifmmode\\\\pm\\\\else\\\\textpm\\\\fi{}0.4 ev ($^{3}p_{2}$), and 3139.6\\\\ifmmode\\\\pm\\\\else\\\\textpm\\\\fi{}0.25 ev ($^{1}p_{1}$).",
            "contribution_ids": [
                "R189911"
            ]
        },
        {
            "instance_id": "R191976xR190165",
            "comparison_id": "R191976",
            "paper_id": "R190165",
            "text": "Precision measurement of the K_\u00ce\u00b1 transitions in heliumlike Ge^30+ a measurement of the 1{ital s}2{ital p} {sup 1}{ital p}{sub 1}{r arrow}1{ital s}{sup 2} {ital s}{sub 0} resonance transition in heliumlike germanium (ge{sup 30+}) has been made on the lawrence livermore national laboratory electron-beam ion trap to a precision of 21 ppm. the result is compared with theoretical values and confirms a trend previously seen in the differences between experiment and theory for this transition as a function of {ital z}. results for the 1{ital s}2{ital p} {sup 3}{ital p}{sub 1}{r arrow}1{ital s}{sup 2} {ital s}{sub 0} and 1{ital s}2{ital p} {sup 3}{ital p}{sub 2}{r arrow}1{ital s}{sup 2} {ital s}{sub 0} intercombination lines and for the 1{ital s}2{ital s} {sup 3}{ital s}{sub 1}{r arrow}1{ital s}{sup 2} {sup 1}{ital s}{sub 0} forbidden line are also presented and show similar differences with theoretical predictions.",
            "contribution_ids": [
                "R190166",
                "R190198",
                "R190229",
                "R190260"
            ]
        },
        {
            "instance_id": "R191984xR191923",
            "comparison_id": "R191984",
            "paper_id": "R191923",
            "text": "An Optimization Method for Encrypting CAN Messages the electric vehicles nowadays are managed by networked controllers. because of the advantages of fast, reliable, simple wiring, and light weight, can bus has become one of the most widely used field buses in the world. most of the networks were designed with little concern about security which has recently motivated researchers to demonstrate various kinds of attacks against the system. this paper proposes an optimization method for encrypting can messages. in addition, a single frame can message can only transmit 64-bit valid data, it is often necessary to complete the communication task by sending a multi-frame message with the same id. the aes algorithm has become the first choice for encrypting multi-frame can messages with its extremely high reliability and fast encryption and decryption speed. in this paper, a method of encrypting multi-frame can messages based on the aes algorithm is proposed, and on the basis of which a hash value is optimized to ensure the security of data transmitted on the can bus.",
            "contribution_ids": [
                "R191925"
            ]
        },
        {
            "instance_id": "R191984xR191965",
            "comparison_id": "R191984",
            "paper_id": "R191965",
            "text": "An In-Vehicle Network Security Protocol Based on Dynamic Encryption vehicles are developing toward intelligence and networking, automotive electronic systems are facing more and more attack threats. in view of the multi-functional mixedcriticality characteristics of automotive electronic system, a security protocol for vehicle can network based on dynamic encryption is proposed to save system computing resources and reduce the impact on real-time performance. the encryption algorithm level table is designed according to the functional safety level, and the correspondence relationship between the functional criticality, security level and encryption algorithm. then, we modify the message format and construct a security protocol based on dynamic encryption. in addition, the timing logic of the received messages is judged with the synchronous counter, an anti-replay attack method is represented. finally, a simple in-vehicle network system is modeled with canoe, the dynamic encryption mechanism is realized and its effectiveness is verified.",
            "contribution_ids": [
                "R191967"
            ]
        },
        {
            "instance_id": "R191984xR191960",
            "comparison_id": "R191984",
            "paper_id": "R191960",
            "text": "Design and Validation of CAN Protocol with Double Encryption for Electric Vehicle Applications the security of the electric vehicle can be ensured by incorporating encryption features in sent/received data in the vehicle. by providing encryption to the data in the electric vehicle, it is ensured that it cannot be accessed by intruders. so, even if the vehicle is hacked no damage could happen for the vehicle. here, two symmetric algorithms (rc6 and blowfish) are used for encryption which provides double security and is named as double encryption. rc6 and blowfish both are symmetric-cryptographic algorithm with variable block size and variable key size. since both are symmetric algorithm there is no requirement of key-generation. the performance of proposed algorithms is validated using software and software simulation. python programming is used in software simulation time calculation for encryption and decryption process. hardware simulation is carried out by proteus with arduino as controller. results show that algorithms are implementable in hardware with minimum processing time. hence the proposed algorithms are applicable for electric vehicle application where the security is ensured in practical environment.",
            "contribution_ids": [
                "R191962"
            ]
        },
        {
            "instance_id": "R191984xR191979",
            "comparison_id": "R191984",
            "paper_id": "R191979",
            "text": "LEAP: A Lightweight Encryption and Authentication Protocol for In-Vehicle Communications the controller area network (can) is considered as the de-facto standard for the in-vehicle communications due to its real-time performance and high reliability. unfortunately, the lack of security protection on the can bus gives attackers the opportunity to remotely compromise a vehicle. in this paper, we propose a lightweight encryption and authentication protocol (leap) with low cost and high efficiency to address the security issue of the can bus. leap exploits the security-enhanced stream cipher primitive to provide encryption and authentication for the can messages. compared with the state-of-the-art message authentication code (mac) based approaches, leap requires less memory, is 8x faster, and thwarts the most recently proposed attacks.",
            "contribution_ids": [
                "R191981"
            ]
        },
        {
            "instance_id": "R191984xR191952",
            "comparison_id": "R191984",
            "paper_id": "R191952",
            "text": "Analyzing CAN's Timing under Periodically Authenticated Encryption \"with increasing connectivity, it has become easier to remotely access in-vehicle buses like can (controller area network). this not only jeopardizes security, but it also exposes can's limitations. in particular, to reject replay and spoofing attacks, messages need to be authenticated, i.e., an authentication tag has to be included. as a result, messages become larger and need to be split in at least two frames due to can's restrictive payload. this increases the delay on the bus and, thus, some deadlines may start being missed compromising safety. in this paper, we propose a periodically authenticated encryption (pae) based on the observation that we do not need to send authentication tags with every single message on the bus, but only with a configurable frequency that allows meeting both safety and security requirements. plausibility checks can then be used to detect whether non-authenticated messages sent in between two authenticated ones have been altered or are being replayed, e.g., the transmitted values exceed a given range or are not in accordance with previous ones. we extend can's known schedulability analysis to consider pae and analyze its timing behavior based on an implementation on real hardware and on extensive simulations.\"",
            "contribution_ids": [
                "R191954"
            ]
        },
        {
            "instance_id": "R193278xR193258",
            "comparison_id": "R193278",
            "paper_id": "R193258",
            "text": "BGPSEC protocol specification this document describes bgpsec, an extension to the border gateway\\nprotocol (bgp) that provides security for the path of autonomous\\nsystems (ases) through which a bgp update message passes. bgpsec is\\nimplemented via an optional non-transitive bgp path attribute that\\ncarries digital signatures produced by each as that propagates the\\nupdate message. the digital signatures provide confidence that every\\nas on the path of ases listed in the update message has explicitly\\nauthorized the advertisement of the route.",
            "contribution_ids": [
                "R193260"
            ]
        },
        {
            "instance_id": "R193278xR193187",
            "comparison_id": "R193278",
            "paper_id": "R193187",
            "text": "Architecture and Deployment Considerations for Secure Origin BGP (soBGP) there is a great deal of concern over the security of internetworks\\nbuilt using the border gateway protocol to provide routing information\\nto autonomous systems connected to the internetwork. this draft\\nprovides an architecture for a secure distributed registry of routing\\ninformation to address these concerns. the draft begins with an\\noverview of the operation of this system, and then follows with\\nvarious deployment scenarios, starting with what we believe will be\\nthe most common deployment option.",
            "contribution_ids": [
                "R193189"
            ]
        },
        {
            "instance_id": "R193278xR193246",
            "comparison_id": "R193278",
            "paper_id": "R193246",
            "text": "Listen and whisper: Security mechanisms for BGP bgp, the current inter-domain routing protocol, assumes that the routing information propagated by authenticated routers is correct. this assumption renders the current infrastructure vulnerable to both accidental misconfigurations and deliberate attacks. to reduce this vulnerability, we present a combination of two mechanisms: listen and whisper. listen passively probes the data plane and checks whether the underlying routes to different destinations work. whisper uses cryptographic functions along with routing redundancy to detect bogus route advertisements in the control plane. these mechanisms are easily deployable, and do not rely on either a public key infrastructure or a central authority like icann. \\n \\nthe combination of listen and whisper eliminates a large number of problems due to router misconfigurations, and restricts (though not eliminates) the damage that deliberate attackers can cause. moreover, these mechanisms can detect and contain isolated adversaries that propagate even a few invalid route announcements. colluding adversaries pose a more stringent challenge, and we propose simple changes to the bgp policy mechanism to limit the damage colluding adversaries can cause. we demonstrate the utility of listen and whisper through real-world deployment, measurements and empirical analysis. for example, a randomly placed isolated adversary, in the worst case can affect reachability to only 1% of the nodes.",
            "contribution_ids": [
                "R193250"
            ]
        },
        {
            "instance_id": "R193278xR193230",
            "comparison_id": "R193278",
            "paper_id": "R193230",
            "text": "Pretty good BGP: Improving BGP by cautiously adopting routes \"the internet's interdomain routing protocol, bgp, is vulnerable to a number of damaging attacks, which often arise from operator misconfiguration. proposed solutions with strong guarantees require a public-key infrastructure, accurate routing registries, and changes to bgp. however, bgp routers can avoid selecting and propagating these routes if they are cautious about adopting new reachability information. we describe a protocol- preserving enhancement to bgp, pretty good bgp (pgbgp), that slows the dissemination of bogus routes, providing network operators time to respond before problems escalate into large- scale internet attacks. simulation results show that realistic deployments of pgbgp could provide 99% of autonomous systems with 24 hours to investigate and repair bogus routes without affecting prefix reachability. we also show that without pgbgp, 40% of ass cannot avoid selecting bogus routes; with pgbgp, this number drops to less than 1%. finally, we show that pgbgp is incrementally deployable and offers significant security benefits to early adopters and their customers.\"",
            "contribution_ids": [
                "R193232"
            ]
        },
        {
            "instance_id": "R193278xR193219",
            "comparison_id": "R193278",
            "paper_id": "R193219",
            "text": "Detection of invalid routing announcement in the Internet \"network measurement has shown that a specific ip address prefix may be announced by more than one autonomous system (as), a phenomenon commonly referred to as multiple origin as, or moas. moas can be due to either operational need to support multi-homing, or false route announcements due to configuration or implementation errors, or even by intentional attacks. packets following such bogus routes will be either dropped or in the case of an intentional attack, delivered to a machine of the attacker's choosing. the paper presents a protocol enhancement to bgp which enables bgp to detect bogus route announcements from false origins. rather than imposing cryptography-based authentication and encryption to secure routing message exchanges, our solution makes use of the rich connectivity among ass that exists in the internet. simulation results show that this simple solution can effectively detect false routing announcements even in the presence of multiple compromised routers, become more robust in larger topologies, and can substantially reduce the impact of false routing announcements even with a partial deployment.\"",
            "contribution_ids": [
                "R193221"
            ]
        },
        {
            "instance_id": "R193278xR193206",
            "comparison_id": "R193278",
            "paper_id": "R193206",
            "text": "Aggregated path authentication for efficient BGP security \"the border gateway protocol (bgp) controls inter-domain routing in the internet. bgp is vulnerable to many attacks, since routers rely on hearsay information from neighbors. secure bgp (s-bgp) uses dsa to provide route authentication and mitigate many of these risks. however, many performance and deployment issues prevent s-bgp's real-world deployment. previous work has explored improving s-bgp processing latencies, but space problems, such as increased message size and memory cost, remain the major obstacles. in this paper, we design aggregated path authentication schemes by combining two efficient cryptographic techniques---signature amortization and aggregate signatures. we propose six constructions for aggregated path authentication that substantially improve efficiency of s-bgp's path authentication on both speed and space criteria. our performance evaluation shows that the new schemes achieve such an efficiency that they may overcome the space obstacles and provide a real-world practical solution for bgp security.\"",
            "contribution_ids": [
                "R193208"
            ]
        },
        {
            "instance_id": "R193278xR193182",
            "comparison_id": "R193278",
            "paper_id": "R193182",
            "text": "Secure border gateway protocol (S-BGP) \"the border gateway protocol (bgp), which is used to distribute routing information between autonomous systems (ases), is a critical component of the internet's routing infrastructure. it is highly vulnerable to a variety of malicious attacks, due to the lack of a secure means of verifying the authenticity and legitimacy of bgp control traffic. this paper describes a secure, scalable, deployable architecture (s-bgp) for an authorization and authentication system that addresses most of the security problems associated with bgp. the paper discusses the vulnerabilities and security requirements associated with bgp, describes the s-bgp countermeasures, and explains how they address these vulnerabilities and requirements. in addition, this paper provides a comparison of this architecture to other approaches that have been proposed, analyzes the performance implications of the proposed countermeasures, and addresses operational issues.\"",
            "contribution_ids": [
                "R193184"
            ]
        },
        {
            "instance_id": "R193278xR193145",
            "comparison_id": "R193278",
            "paper_id": "R193145",
            "text": "BGP routing policies in ISP networks \"the internet has quickly evolved into a vast global network owned and operated by thousands of different administrative entities. during this time, it became apparent that vanilla shortest path routing would be insufficient to handle the myriad operational, economic, and political factors involved in routing. isps began to modify routing configurations to support routing policies - goals held by the router's owner that controlled which routes were chosen and which routes were propagated to neighbors. bgp, originally a simple path vector protocol, was incrementally modified over time with a number of mechanisms to support policies, adding substantially to the complexity. much of the mystery in bgp comes not only from the protocol complexity, but also from a lack of understanding of the underlying policies and the problems isps face that are addressed by these policies. in this article we shed light on goals operators have and their resulting routing policies, why bgp evolved the way it did, and how common policies are implemented using bgp. we also discuss recent and current work in the field that aims to address problems that arise in applying and supporting routing policies.\"",
            "contribution_ids": [
                "R193147"
            ]
        },
        {
            "instance_id": "R193278xR193233",
            "comparison_id": "R193278",
            "paper_id": "R193233",
            "text": "Accurate real-time identification of IP prefix hijacking \"we present novel and practical techniques to accurately detect ip prefix hijacking attacks in real time to facilitate mitigation. attacks may hijack victim's address space to disrupt network services or perpetrate malicious activities such as spamming and dos attacks without disclosing identity. we propose novel ways to significantly improve the detection accuracy by combining analysis of passively collected bgp routing updates with data plane fingerprints of suspicious prefixes. the key insight is to use data plane information in the form of edge network fingerprinting to disambiguate suspect ip hijacking incidences based on routing anomaly detection. conflicts in data plane fingerprints provide much more definitive evidence of successful ip prefix hijacking. utilizing multiple real-time bgp feeds, we demonstrate the ability of our system to distinguish between legitimate routing changes and actual attacks. strong correlation with addresses that originate spam emails from a spam honeypot confirms the accuracy of our techniques.\"",
            "contribution_ids": [
                "R193235"
            ]
        },
        {
            "instance_id": "R193278xR193213",
            "comparison_id": "R193278",
            "paper_id": "R193213",
            "text": "On interdomain routing security and pretty secure BGP (psBGP) \\n it is well known that the border gateway protocol (bgp), the ietf standard interdomain routing protocol, is vulnerable to a variety of attacks, and that a single misconfigured or malicious bgp speaker could result in large-scale service disruption. in this paper, we present\\n pretty secure bgp (psbgp) \\n ---a proposal for securing bgp, including an architectural overview, design details for significant aspects, and preliminary security and operational analysis. psbgp differs from other security proposals (e.g., s-bgp and sobgp) in that it makes use of a single-level pki for as number authentication, a decentralized trust model for verifying the propriety of ip prefix origin, and a rating-based stepwise approach for as_path (integrity) verification. psbgp trades off the strong security guarantees of s-bgp for presumed-simpler operation, e.g., using a pki with a simple structure, with a small number of certificate types, and of manageable size. psbgp is designed to successfully defend against various (nonmalicious and malicious) threats from uncoordinated bgp speakers, and to be incrementally deployed with incremental benefits.\\n",
            "contribution_ids": [
                "R193215"
            ]
        },
        {
            "instance_id": "R193505xR178482",
            "comparison_id": "R193505",
            "paper_id": "R178482",
            "text": "Viral load dynamics and disease severity in patients infected with SARS-CoV-2 in Zhejiang province, China, January-March 2020: retrospective cohort study abstract objective to evaluate viral loads at different stages of disease progression in patients infected with the 2019 severe acute respiratory syndrome coronavirus 2 (sars-cov-2) during the first four months of the epidemic in zhejiang province, china. design retrospective cohort study. setting a designated hospital for patients with covid-19 in zhejiang province, china. participants 96 consecutively admitted patients with laboratory confirmed sars-cov-2 infection: 22 with mild disease and 74 with severe disease. data were collected from 19 january 2020 to 20 march 2020. main outcome measures ribonucleic acid (rna) viral load measured in respiratory, stool, serum, and urine samples. cycle threshold values, a measure of nucleic acid concentration, were plotted onto the standard curve constructed on the basis of the standard product. epidemiological, clinical, and laboratory characteristics and treatment and outcomes data were obtained through data collection forms from electronic medical records, and the relation between clinical data and disease severity was analysed. results 3497 respiratory, stool, serum, and urine samples were collected from patients after admission and evaluated for sars-cov-2 rna viral load. infection was confirmed in all patients by testing sputum and saliva samples. rna was detected in the stool of 55 (59%) patients and in the serum of 39 (41%) patients. the urine sample from one patient was positive for sars-cov-2. the median duration of virus in stool (22 days, interquartile range 17-31 days) was significantly longer than in respiratory (18 days, 13-29 days; p=0.02) and serum samples (16 days, 11-21 days; p&lt;0.001). the median duration of virus in the respiratory samples of patients with severe disease (21 days, 14-30 days) was significantly longer than in patients with mild disease (14 days, 10-21 days; p=0.04). in the mild group, the viral loads peaked in respiratory samples in the second week from disease onset, whereas viral load continued to be high during the third week in the severe group. virus duration was longer in patients older than 60 years and in male patients. conclusion the duration of sars-cov-2 is significantly longer in stool samples than in respiratory and serum samples, highlighting the need to strengthen the management of stool samples in the prevention and control of the epidemic, and the virus persists longer with higher load and peaks later in the respiratory tissue of patients with severe disease.",
            "contribution_ids": [
                "R178485",
                "R178491",
                "R178498"
            ]
        },
        {
            "instance_id": "R193505xR191082",
            "comparison_id": "R193505",
            "paper_id": "R191082",
            "text": "SARS-CoV-2 Viral Load in Upper Respiratory Specimens of Infected Patients sars-cov-2 viral load in upper respiratory specimens the authors report results of an analysis of nasal and throat swabs from 17 patients in zhuhai, china, who had received a diagnosis of covid-19....",
            "contribution_ids": [
                "R191084",
                "R191085"
            ]
        },
        {
            "instance_id": "R193505xR193018",
            "comparison_id": "R193505",
            "paper_id": "R193018",
            "text": "Comparison of Upper Respiratory Viral Load Distributions in Asymptomatic and Symptomatic Children Diagnosed with SARS-CoV-2 Infection in Pediatric Hospital Testing Programs the distribution of upper respiratory viral loads (vl) in asymptomatic children infected with severe acute respiratory syndrome coronavirus 2 (sars-cov-2) is unknown. we assessed pcr cycle threshold (ct) values and estimated vl in infected asymptomatic children diagnosed in nine pediatric hospital testing programs. records for asymptomatic and symptomatic patients with positive clinical sars-cov-2 tests were reviewed. ct values were (i) adjusted by centering each value around the institutional median ct value from symptomatic children tested with that assay and (ii) converted to estimated vl (numbers of copies per milliliter) using internal or manufacturer data.",
            "contribution_ids": [
                "R193020"
            ]
        },
        {
            "instance_id": "R193505xR193003",
            "comparison_id": "R193505",
            "paper_id": "R193003",
            "text": "SARS-CoV-2 Viral Load Predicts Mortality in Patients with and Without Cancer Who are Hospitalized with Coronavirus Disease 2019 patients with cancer may be at increased risk of severe coronavirus disease 2019 (covid-19), but the role of viral load on this risk is unknown we measured sars-cov-2 viral load using cycle threshold (ct) values from reverse transcription-polymerase chain reaction assays applied to nasopharyngeal swab specimens in 100 patients with cancer and 2914 without cancer admitted to three new york city hospitals overall, the in-hospital mortality rate was 39 5% among patients with a high viral load (ct25), 25 6% among patients with a medium viral load (ct 25-30), and 15 7% among patients with a low viral load (ct30;p0 001) similar findings were observed in patients with cancer (high, 45 0% mortality;medium, 29 2%;low, 13 9%;p=0 003) patients with hematologic malignancies had higher median viral loads (ct=25 0) than patients without cancer (ct=29 2;p=0 0039) sars-cov-2 viral load results may offer vital prognostic information for patients with and without cancer who are hospitalied with covid-19",
            "contribution_ids": [
                "R193005"
            ]
        },
        {
            "instance_id": "R193505xR191449",
            "comparison_id": "R193505",
            "paper_id": "R191449",
            "text": "SARS-CoV-2 PCR cycle threshold at hospital admission associated with patient mortality background severe acute respiratory syndrome coronavirus 2 (sars-cov-2) cycle threshold (ct) has been suggested as an approximate measure of initial viral burden. the utility of cycle threshold, at admission, as a predictor of disease severity has not been thoroughly investigated. methods and findings we conducted a retrospective study of sars-cov-2 positive, hospitalized patients from 3/26/2020 to 8/5/2020 who had sars-cov-2 ct data within 48 hours of admission (n = 1044). only patients with complete survival data, discharged (n = 774) or died in hospital (n = 270), were included in our analysis. laboratory, demographic, and clinical data were extracted from electronic medical records. multivariable logistic regression was applied to examine the relationship of patient mortality with ct values while adjusting for established risk factors. ct was analyzed as continuous variable and subdivided into quartiles to better illustrate its relationship with outcome. cumulative incidence curves were created to assess whether there was a survival difference in the setting of the competing risks of death versus patient discharge. mean ct at admission was higher for survivors (28.6, sd = 5.8) compared to non-survivors (24.8, sd = 6.0, p&lt;0.001). in-hospital mortality significantly differed (p&lt;0.05) by ct quartile. after adjusting for age, gender, bmi, hypertension and diabetes, increased cycle threshold was associated with decreased odds of in-hospital mortality (0.91, ci 0.89\u20130.94, p&lt;0.001). compared to the 4 th quartile, patients with ct values in the 1st quartile (ct &lt;22.9) and 2nd quartile (ct 23.0\u201327.3) had an adjusted odds ratio of in-hospital mortality of 3.8 and 2.6 respectively (p&lt;0.001). the discriminative ability of ct to predict inpatient mortality was found to be limited, possessing an area under the curve (auc) of 0.68 (ci 0.63\u20130.71). conclusion sars-cov-2 ct was found to be an independent predictor of patient mortality. however, further study is needed on how to best clinically utilize such information given the result variation due to specimen quality, phase of disease, and the limited discriminative ability of the test.",
            "contribution_ids": [
                "R191450"
            ]
        },
        {
            "instance_id": "R193505xR191162",
            "comparison_id": "R193505",
            "paper_id": "R191162",
            "text": "Is Higher Viral Load in SARS-CoV-2 Associated with Death? abstract background there is no proven prognostic marker or adequate number of studies in patients hospitalized for coronavirus disease 2019 (covid-19). methods we conducted a retrospective cohort study of patients hospitalized with covid-19 from march 14 to june 17, 2020, at s\u00e3o paulo hospital. sars-cov-2 viral load was assessed using the cycle threshold (ct) values obtained from an rt-pcr assay applied to the nasopharyngeal swab samples. disease severity and patient outcomes were compared. results among the 875 patients, 50.1% (439/875) had mild, 30.4% (266/875) moderate, and 19.5% (170/875) severe disease. a ct value of &lt;25 (472/875) indicated a high viral load, which was independently associated with mortality (or: 0,34; 95% ci: 0,217\u20130,533; p &lt; 0.0001). conclusions admission sars-cov-2 viral load is an important surrogate biomarker of infectivity and is independently associated with mortality among patients hospitalized with covid-19.",
            "contribution_ids": [
                "R191164"
            ]
        },
        {
            "instance_id": "R193505xR191087",
            "comparison_id": "R193505",
            "paper_id": "R191087",
            "text": "The association between real-time reverse transcriptase polymerase chain reaction cycle threshold values, symptoms and disease severity among COVID-19 patients in the community: a retrospective cohort study abstract background covid-19 continues to spread throughout the world. real-time reverse transcriptase polymerase chain reaction (rt-pcr) is used to diagnose covid-19, with its cycle threshold (ct) value inversely related to the viral load. the association between ct values and covid-19 related outcomes has been studied in the hospital setting but less so in the community. we aimed to estimate the association between ct values and the severity of community-diagnosed covid-19 to provide evidence on the utility of ct testing in this setting. methods this was a retrospective cohort study based on data from israel\u2019s largest health organization. the study population included 34,658 individuals who tested positive for covid-19 by rt-pcr and had available ct values between june 1st and december 21st, 2020. outcomes included covid-19 related symptoms, hospitalization, severe disease, and death. ct values were modelled both as discrete and continuous exposures. results after adjusting for known risk factors for severe covid-19, low ct values were associated with symptomatic disease (odds ratio [or]: 1.51; 95% confidence interval [ci]:1.21\u20131.84), hospitalization (or: 1.27; 95%ci: 1.12\u20131.49), severe disease (or: 1.80; 95%ci: 1.43\u20132.27), and death (or: 1.64; 95%ci: 1.06\u20132.59). by modelling the exposure as continuous, we noticed a dose-response relationship, with the risk gradually rising with lower ct values. conclusions this study found a significant association between low ct values and severe covid-19 related outcomes, with a dose-response relationship. this suggests that ct values could be helpful in identifying high-risk patients diagnosed in the community.",
            "contribution_ids": [
                "R191089"
            ]
        },
        {
            "instance_id": "R193505xR193124",
            "comparison_id": "R193505",
            "paper_id": "R193124",
            "text": "Presymptomatic SARS-CoV-2 Infections and Transmission in a Skilled Nursing Facility abstract background severe acute respiratory syndrome coronavirus 2 (sars-cov-2) infection can spread rapidly within skilled nursing facilities. after identification of a case of covid-19 in a skilled nursing facility, we assessed transmission and evaluated the adequacy of symptom-based screening to identify infections in residents. methods we conducted two serial point-prevalence surveys, 1 week apart, in which assenting residents of the facility underwent nasopharyngeal and oropharyngeal testing for sars-cov-2, including real-time reverse-transcriptase polymerase chain reaction (rrt-pcr), viral culture, and sequencing. symptoms that had been present during the preceding 14 days were recorded. asymptomatic residents who tested positive were reassessed 7 days later. residents with sars-cov-2 infection were categorized as symptomatic with typical symptoms (fever, cough, or shortness of breath), symptomatic with only atypical symptoms, presymptomatic, or asymptomatic. results twenty-three days after the first positive test result in a resident at this skilled nursing facility, 57 of 89 residents (64%) tested positive for sars-cov-2. among 76 residents who participated in point-prevalence surveys, 48 (63%) tested positive. of these 48 residents, 27 (56%) were asymptomatic at the time of testing; 24 subsequently developed symptoms (median time to onset, 4 days). samples from these 24 presymptomatic residents had a median rrt-pcr cycle threshold value of 23.1, and viable virus was recovered from 17 residents. as of april 3, of the 57 residents with sars-cov-2 infection, 11 had been hospitalized (3 in the intensive care unit) and 15 had died (mortality, 26%). of the 34 residents whose specimens were sequenced, 27 (79%) had sequences that fit into two clusters with a difference of one nucleotide. conclusions rapid and widespread transmission of sars-cov-2 was demonstrated in this skilled nursing facility. more than half of residents with positive test results were asymptomatic at the time of testing and most likely contributed to transmission. infection-control strategies focused solely on symptomatic residents were not sufficient to prevent transmission after sars-cov-2 introduction into this facility.",
            "contribution_ids": [
                "R193126"
            ]
        },
        {
            "instance_id": "R193505xR193067",
            "comparison_id": "R193505",
            "paper_id": "R193067",
            "text": "Severe Acute Respiratory Syndrome Coronavirus 2 RNA in Plasma Is Associated With Intensive Care Unit Admission and Mortality in Patients Hospitalized With Coronavirus Disease 2019 abstract \\n the clinical significance of severe acute respiratory syndrome coronavirus 2 rna in the circulation is unknown. in this prospective cohort study, we detected viral rna in the plasma of 58 of 123 (47%) patients hospitalized with coronavirus disease 2019. rna was detected more frequently, and levels were higher, in patients who were admitted to the intensive care unit and/or died.",
            "contribution_ids": [
                "R193069",
                "R193076"
            ]
        },
        {
            "instance_id": "R193505xR191093",
            "comparison_id": "R193505",
            "paper_id": "R191093",
            "text": "Using COVID\u00e2\u0080\u009019 cycle threshold and other lab values as predictors of hospitalization need sars\u2010cov\u20102 (covid\u201019) is a novel virus that has caused over 28 million cases worldwide and over 900,000 deaths since early 2020, rightfully being classified as a pandemic. covid\u201019 is diagnosed via polymerase chain reaction testing which looks at cycle threshold (ct) values of two genes, n2 and e. this study examined ct values of covid\u2010positive patients at the va hospital in reno as well as other lab values and comorbidities to determine if any could aid clinicians in predicting the need for hospitalization and higher levels of care. multiple variables, including n2 ct value, absolute lymphocyte count (alc), d\u2010dimer, erythrocyte sedimentation rate, c\u2010reactive protein, fibrinogen, and ferritin were evaluated for potential associations with n2 ct value as well as required level of care (based on world health organization [who] ordinal score). the results suggest that patients with a n2 ct value less than 34 are four times more likely to have who ordinal scores of 4\u20138 (p\\u2009=\\u2009.0021) while controlling for age and comorbidities (dm, cardiac, kidney, and lung disease). patients of age 55 or greater were 15.18 times more likely to have who ordinal scores of 4\u20138 (p\\u2009=\\u2009.012) controlling for n2 ct value and comorbidities. furthermore, patients with alc less than 1 were 5.88 times more likely to have who ordinal score of 4\u20138 (p\\u2009=\\u2009.00024). n2 ct values also appear to be associated with many commonly obtained markers such as alc, white blood cell count, c\u2010reactive protein, and d\u2010dimer. patients with n2 ct values less than 34 were 3.49 times more likely to have alc values less than 1, controlling for age and comorbidities (p\\u2009=\\u2009.0072) while patients 55 or older were 6.66 times more likely to have alc less than 1 (p\\u2009=\\u2009.027). finally, this study confirms previous conclusions that patients with advanced age had more severe infections and thus will likely require higher levels of care.",
            "contribution_ids": [
                "R191096"
            ]
        },
        {
            "instance_id": "R193505xR193118",
            "comparison_id": "R193505",
            "paper_id": "R193118",
            "text": "Chronological Changes of Viral Shedding in Adult Inpatients with COVID-19 in Wuhan, China abstract \\n \\n background \\n in december 2019, the coronavirus disease 2019 (covid-19) caused by severe acute respiratory syndrome coronavirus 2 (sars-cov-2) broke out in wuhan. epidemiological and clinical characteristics of patients with covid-19 have been reported, but the relationships between laboratory features and viral load has not been comprehensively described. \\n \\n \\n methods \\n adult inpatients (\u226518 years old) with covid-19 who underwent multiple (\u22655 times) nucleic acid tests with nasal and pharyngeal swabs were recruited from renmin hospital of wuhan university, including general patients (n = 70), severe patients (n = 195), and critical patients (n = 43). laboratory data, demographic data, and clinical data were extracted from electronic medical records. the fitted polynomial curve was used to explore the association between serial viral loads and illness severity. \\n \\n \\n results \\n viral load of sars-cov-2 peaked within the first few days (2\u20134 days) after admission, then decreased rapidly along with virus rebound under treatment. critical patients had the highest viral loads, in contrast to the general patients showing the lowest viral loads. the viral loads were higher in sputum compared with nasal and pharyngeal swab (p = .026). the positive rate of respiratory tract samples was significantly higher than that of gastrointestinal tract samples (p &amp;lt; .001). the sars-cov-2 viral load was negatively correlated with portion parameters of blood routine and lymphocyte subsets and was positively associated with laboratory features of cardiovascular system. \\n \\n \\n conclusions \\n the serial viral loads of patients revealed whole viral shedding during hospitalization and the resurgence of virus during the treatment, which could be used for early warning of illness severity, thus improve antiviral interventions. \\n",
            "contribution_ids": [
                "R193120"
            ]
        },
        {
            "instance_id": "R193565xR192137",
            "comparison_id": "R193565",
            "paper_id": "R192137",
            "text": "Benders decomposition with alternative multiple cuts for a multi-product closed-loop supply chain network design model in this article, we consider a multi\u2010product closed\u2010loop supply chain network design problem where we locate collection centers and remanufacturing facilities while coordinating the forward and reverse flows in the network so as to minimize the processing, transportation, and fixed location costs. the problem of interest is motivated by the practice of an original equipment manufacturer in the automotive industry that provides service parts for vehicle maintenance and repair. we provide an effective problem formulation that is amenable to efficient benders reformulation and an exact solution approach. more specifically, we develop an efficient dual solution approach to generate strong benders cuts, and, in addition to the classical single benders cut approach, we propose three different approaches for adding multiple benders cuts. these cuts are obtained via dual problem disaggregation based either on the forward and reverse flows, or the products, or both. we present computational results which illustrate the superior performance of the proposed solution methodology with multiple benders cuts in comparison to the branch\u2010and\u2010cut approach as well as the traditional benders decomposition approach with a single cut. in particular, we observe that the use of multiple benders cuts generates stronger lower bounds and promotes faster convergence to optimality. we also observe that if the model parameters are such that the different costs are not balanced, but, rather, are biased towards one of the major cost categories (processing, transportation or fixed location costs), the time required to obtain the optimal solution decreases considerably when using the proposed solution methodology as well as the branch\u2010and\u2010cut approach. \u00a9 2007 wiley periodicals, inc. naval research logistics, 2007",
            "contribution_ids": [
                "R192139"
            ]
        },
        {
            "instance_id": "R193700xR193665",
            "comparison_id": "R193700",
            "paper_id": "R193665",
            "text": "Blockchain technology for enhancing swift-trust, collaboration and resilience within a humanitarian supply chain setting there has been tremendous interest in blockchain technology (bt) (also known as distributed ledger technology) around the globe and across sectors. following significant success in the financial sector, other sectors, such as humanitarian sector, have started deploying bt at various levels. although the use of bt in the humanitarian sector is in its infancy, donors and government agencies are increasingly calling for building bt-enabled swift-trust (st) and more collaborative relationships among various humanitarian actors in order to improve the transparency and traceability of disaster relief materials, information exchanges and flow of funds in disaster relief supply chains. our study, which is informed by organisational information processing theory and relational view, proposes a theoretical model to understand how bt can influence operational supply chain transparency (ostc) and st among actors engaged in disaster relief operations. our model also shows how bt-enabled st can further improve collaboration (co) among actors engaged in disaster relief operations and enhance supply chain resilience (scr). we formulated and tested six research hypotheses, using data gathered from international non-governmental organisations with the help of the coordinator for humanitarian affairs (ocha) database. we received 256 usable responses using a pre-tested survey-based instrument designed for key informants. our results confirm that our six hypotheses were supported. our study offers significant and valid contributions to the literature on st, co and scr and bt/distributed ledger technology. we have also noted the limitations of our study and have offered future research directions.",
            "contribution_ids": [
                "R193669"
            ]
        },
        {
            "instance_id": "R193700xR193687",
            "comparison_id": "R193700",
            "paper_id": "R193687",
            "text": "An examination of the generative mechanisms of value in big data-enabled supply chain management research big data technologies (bdt) are the latest instalments in a long line of technological disruptions credited with advancing the field of supply chain management (scm) from a purely clerical function to a strategic necessity. yet, despite the wave of optimism about the utility of bdt in scm, the origins of value in a bdt-enabled supply chain are not well understood. this study examines the generative mechanisms of value creation in such a supply chain by a two-pronged approach. first, we interrogate the theoretical raisons d\u2019\u00eatre of bdt in scm. second, we examine the evidence that support the value-added potential of bdt in scm informed by extant empirical and quantitative studies (eqs). taken together, our analyses reveal three key findings. first, in extending the dynamic capabilities perspective, we deduced that micro-founded rather than macro-founded studies tend to be more instructive to practice. second, we discovered that the generative mechanisms of value in a bdt-enabled supply chain operate at the level of supply chain processes. and thirdly, we found that resilience and agility are the most important dynamic capabilities that have emerged from current bdt-enabled scm research. insights for policy, practice, theory, and future research are discussed.",
            "contribution_ids": [
                "R193690"
            ]
        },
        {
            "instance_id": "R193700xR193662",
            "comparison_id": "R193700",
            "paper_id": "R193662",
            "text": "Do blockchain and circular economy practices improve post COVID-19 supply chains? A resource-based and resource dependence perspective purpose using the resource-based and the resource dependence theoretical approaches of the firm, the paper explores firm responses to supply chain disruptions during covid-19. the paper explores how firms develop localization, agility and digitization (l-a-d) capabilities by applying (or not applying) their critical circular economy (ce) and blockchain technology (bct)-related resources and capabilities that they either already possess or acquire from external agents. design/methodology/approach an abductive approach, applying exploratory qualitative research was conducted over a sample of 24 firms. the sample represented different industries to study their critical bct and ce resources and capabilities and the l-a-d capabilities. firm resources and capabilities were classified using the technology, organization and environment (toe) framework. findings findings show significant patterns on adoption levels of the blockchain-enabled circular economy system (bces) and l-a-d capability development. the greater the bces adoption capabilities, the greater the l-a-d capabilities. organizational size and industry both influence the relationship between bces and l-a-d. accordingly, research propositions and a research framework are proposed. research limitations/implications given the limited sample size, the generalizability of the findings is limited. our findings extend supply chain resiliency research. a series of propositions provide opportunities for future research. the resource-based view and resource-dependency theories are useful frameworks to better understanding the relationship between firm resources and supply chain resilience. practical implications the results and discussion of this study serve as useful guidance for practitioners to create ce and bct resources and capabilities for improving supply chain resiliency. social implications the study shows the socio-economic and socio-environmental importance of bces in the covid-19 or similar crises. originality/value the study is one of the initial attempts that highlights the possibilities of bces across multiple industries and their value during pandemics and disruptions.",
            "contribution_ids": [
                "R193664"
            ]
        },
        {
            "instance_id": "R193700xR193680",
            "comparison_id": "R193700",
            "paper_id": "R193680",
            "text": "Logistics and cloud computing service providers\u00e2\u0080\u0099 cooperation: a resilience perspective abstract cloud computing (cc) services can offer substantial cost-effective global operational and relationship benefits if the cooperation between logistics and cc services are resilient. potential vulnerabilities to cooperation of cc and logistics service providers can occur with respect to vital factors such as security and trust. extant studies have demonstrated cc benefits as well as few challenges associated with cc services application. however, no extant study has examined the inter-organisational benefits based on cooperative resilience between cc and logistics service providers in terms of both capability and trust vulnerability factors. this study examines the cooperative resilience of logistics and cc service providers based on innovation diffusion theory within a supply chain risk assessment framework. using structural equation modelling techniques, we investigate the relationship between the vulnerability factor (trust), capability factor (security) and collaboration benefits (relationship and operational) offered by cc service providers based on 236 chinese logistics service firms\u2019 perceptions of cc adoption. the results indicate chinese logistics companies perceive security impediments as a major factor affecting cooperative resilience between logistics service and cc service providers.",
            "contribution_ids": [
                "R193683"
            ]
        },
        {
            "instance_id": "R193945xR187017",
            "comparison_id": "R193945",
            "paper_id": "R187017",
            "text": "The Infectious Disease Ontology in the age of COVID-19 background: effective response to public health emergencies, such as we are now experiencing with covid-19, requires data sharing across multiple disciplines and data systems. ontologies offer a powerful data sharing tool, and this holds especially for those ontologies built on the design principles of the open biomedical ontologies foundry. these principles are exemplified by the infectious disease ontology (ido), a suite of interoperable ontology modules aiming to provide coverage of all aspects of the infectious disease domain. at its center is ido core, a disease- and pathogen-neutral ontology covering just those types of entities and relations that are relevant to infectious diseases generally. ido core is extended by disease and pathogen-specific ontology modules.results: to assist the integration and analysis of covid-19 data, and viral infectious disease data more generally, we have recently developed three new ido extensions: ido virus (vido); the coronavirus infectious disease ontology (cido); and an extension of cido focusing on covid-19 (ido-covid-19). reflecting the fact that viruses lack cellular parts, we have introduced to ido core the term acellular structure to cover viruses and other acellular entities studied by virologists. we now distinguish between infectious agents \u2013 organisms with an infectious disposition \u2013 and infectious structures \u2013 acellular structures with an infectious disposition. this in turn has led to various updates and refinements of ido core\u2019s content. we believe that our work on vido, cido, and ido-covid-19 can serve as a model for yielding greater conformance with ontology building best practices.conclusions: ido provides a simple recipe for building new pathogen-specific ontologies in a way that allows data about novel diseases to be easily compared, along multiple dimensions, with data represented by existing disease ontologies. the ido strategy, moreover, supports ontology coordination, providing a powerful method of data integration and sharing that allows physicians, researchers, and public health organizations to respond rapidly and efficiently to current and future public health crises.",
            "contribution_ids": [
                "R187019"
            ]
        },
        {
            "instance_id": "R193945xR187043",
            "comparison_id": "R193945",
            "paper_id": "R187043",
            "text": "COVID-19 Surveillance in a Primary Care Sentinel Network: In-Pandemic Development of an Application Ontology background creating an ontology for covid-19 surveillance should help ensure transparency and consistency. ontologies formalize conceptualizations at either the domain or application level. application ontologies cross domains and are specified through testable use cases. our use case was an extension of the role of the oxford royal college of general practitioners (rcgp) research and surveillance centre (rsc) to monitor the current pandemic and become an in-pandemic research platform. objective this study aimed to develop an application ontology for covid-19 that can be deployed across the various use-case domains of the rcgp rsc research and surveillance activities. methods we described our domain-specific use case. the actor was the rcgp rsc sentinel network, the system was the course of the covid-19 pandemic, and the outcomes were the spread and effect of mitigation measures. we used our established 3-step method to develop the ontology, separating ontological concept development from code mapping and data extract validation. we developed a coding system\u2013independent covid-19 case identification algorithm. as there were no gold-standard pandemic surveillance ontologies, we conducted a rapid delphi consensus exercise through the international medical informatics association primary health care informatics working group and extended networks. results our use-case domains included primary care, public health, virology, clinical research, and clinical informatics. our ontology supported (1) case identification, microbiological sampling, and health outcomes at an individual practice and at the national level; (2) feedback through a dashboard; (3) a national observatory; (4) regular updates for public health england; and (5) transformation of a sentinel network into a trial platform. we have identified a total of 19,115 people with a definite covid-19 status, 5226 probable cases, and 74,293 people with possible covid-19, within the rcgp rsc network (n=5,370,225). conclusions the underpinning structure of our ontological approach has coped with multiple clinical coding challenges. at a time when there is uncertainty about international comparisons, clarity about the basis on which case definitions and outcomes are made from routine data is essential.",
            "contribution_ids": [
                "R187045"
            ]
        },
        {
            "instance_id": "R194697xR191261",
            "comparison_id": "R194697",
            "paper_id": "R191261",
            "text": "LinkBERT: Pretraining Language Models with Document Links language model (lm) pretraining captures various knowledge from text corpora, helping downstream tasks. however, existing methods such as bert model a single document, and do not capture dependencies or knowledge that span across documents. in this work, we propose linkbert, an lm pretraining method that leverages links between documents, e.g., hyperlinks. given a text corpus, we view it as a graph of documents and create lm inputs by placing linked documents in the same context. we then pretrain the lm with two joint self-supervised objectives: masked language modeling and our new proposal, document relation prediction. we show that linkbert outperforms bert on various downstream tasks across two domains: the general domain (pretrained on wikipedia with hyperlinks) and biomedical domain (pretrained on pubmed with citation links). linkbert is especially effective for multi-hop reasoning and few-shot qa (+5% absolute improvement on hotpotqa and triviaqa), and our biomedical linkbert sets new states of the art on various bionlp tasks (+7% on bioasq and usmle). we release our pretrained models, linkbert and biolinkbert, as well as code and data.",
            "contribution_ids": [
                "R194643",
                "R191272",
                "R191278",
                "R191281",
                "R191283"
            ]
        },
        {
            "instance_id": "R196613xR196561",
            "comparison_id": "R196613",
            "paper_id": "R196561",
            "text": "A MapReduce Opinion Mining for COVID-19-Related Tweets Classification Using Enhanced ID3 Decision Tree Classifier opinion mining (om) is a field of natural language processing (nlp) that aims to capture human sentiment in the given text. with the ever-spreading of online purchasing websites, micro-blogging sites, and social media platforms, om in online social media platforms has picked the interest of thousands of scientific researchers. because the reviews, tweets and blogs acquired from these social media networks, act as a significant source for enhancing the decision making process. the obtained textual data (reviews, tweets, or blogs) are classified into three different class labels which are negative, neutral and positive for analyzing and extracting relevant information from the given dataset. in this contribution, we introduce an innovative mapreduce improved weighted id3 decision tree classification approach for om, which consists mainly of three aspects: firstly we have used several feature extractors to efficiently detect and capture the relevant data from the given tweets, including n-grams or character-level, bag-of-words, word embedding (glove, word2vec), fasttext, and tf-idf. secondly, we have applied a multiple feature selector to reduce the high feature\u2019s dimensionality, including chi-square, gain ratio, information gain, and gini index. finally, we have employed the obtained features to carry out the classification task using an improved id3 decision tree classifier, which aims to calculate the weighted information gain instead of information gain used in traditional id3. in other words, to measure the weighted information gain for the current conditioned feature, we follow two steps: first, we compute the weighted correlation function of the current conditioned feature. second, we multiply the obtained weighted correlation function by the information gain of this current conditioned feature. this work is implemented in a distributed environment using the hadoop framework, with its programming framework mapreduce and its distributed file system hdfs. its primary goal is to enhance the performance of a well-known id3 classifier in terms of accuracy, execution time, and ability to handle the massive datasets. we have carried out several experiences that aims to assess the effectiveness of our suggested classifier compared to some other contributions chosen from the literature. the experimental results demonstrated that our id3 classifier works better on covid-19_sentiments dataset than other classifiers in terms of recall (85.72 %), specificity (86.51 %), error rate (11.18 %), false-positive rate (13.49 %), execution time (15.95s), kappa statistic (87.69 %), f1-score (85.54 %), classification rate (88.82 %), false-negative rate (14.28 %), precision rate (86.67 %), convergence (it convergent towards the iteration 90), stability (it is more stable with mean deviation standard equal to 0.12 %), and complexity (it requires much lower time and space computational complexity).",
            "contribution_ids": [
                "R196569"
            ]
        },
        {
            "instance_id": "R196613xR196556",
            "comparison_id": "R196613",
            "paper_id": "R196556",
            "text": "A Hybrid Bidirectional Recurrent Convolutional Neural Network Attention-Based Model for Text Classification the text classification task is an important application in natural language processing. at present, deep learning models, such as convolutional neural network and recurrent neural network, have achieved good results for this task, but the multi-class text classification and the fine-grained sentiment analysis are still challenging. in this paper, we propose a hybrid bidirectional recurrent convolutional neural network attention-based model to address this issue, which named brcan. the model combines the bidirectional long short-term memory and the convolutional neural network with the attention mechanism and word2vec to achieve the fine-grained text classification task. in our model, we apply word2vec to generate word vectors automatically and a bidirectional recurrent structure to capture contextual information and long-term dependence of sentences. we also employ a maximum pool layer of convolutional neural network that judges which words play an essential role in text classification, and use the attention mechanism to give them higher weights to capture the key components in texts. we conduct experiments on four datasets, including yahoo! answers, sogou news of the topic classification, yelp reviews, and douban movies top250 short reviews of the sentiment analysis. and the experimental results show that the brcan outperforms the state-of-the-art models.",
            "contribution_ids": [
                "R196559"
            ]
        },
        {
            "instance_id": "R196613xR196574",
            "comparison_id": "R196613",
            "paper_id": "R196574",
            "text": "A Novel Deep Learning-Based Multilevel Parallel Attention Neural (MPAN) Model for Multidomain Arabic Sentiment Analysis over the past few years, much work has been done to develop machine learning models that perform arabic sentiment analysis (asa) tasks at various levels and in different domains. however, most of this work has been based on shallow machine learning, with little attention given to deep learning approaches. furthermore, the deep learning models used for asa have been based on noncontextualized embedding schemes that negatively impact model performances. this article proposes a novel deep learning-based multilevel parallel attention neural (mpan) model that uses a simple positioning binary embedding scheme (pbes) to simultaneously compute contextualized embeddings at the character, word, and sentence levels. the mpan model then computes multilevel attention vectors and concatenates them at the output level to produce competitive accuracies. specifically, the mpan model produces state-of-the-art results that outperform all established asa baselines using 34 publicly available asa datasets. the proposed model is further shown to produce new state-of-the-art accuracies for two multidomain collections: 95.61% for a binary classification collection and 94.25% for a tertiary classification collection. finally, the performance of the mpan model is further validated using the public imdb movie review dataset, on which it produces an accuracy of 96.13%, placing it in second position on the global imdb leaderboard.",
            "contribution_ids": [
                "R196576"
            ]
        },
        {
            "instance_id": "R196613xR196541",
            "comparison_id": "R196613",
            "paper_id": "R196541",
            "text": "A Deep Learning Sentiment Analyser for Social Media Comments in Low-Resource Languages during the pandemic, when people needed to physically distance, social media platforms have been one of the outlets where people expressed their opinions, thoughts, sentiments, and emotions regarding the pandemic situation. the core object of this research study is the sentiment analysis of peoples\u2019 opinions expressed on facebook regarding the current pandemic situation in low-resource languages. to do this, we have created a large-scale dataset comprising of 10,742 manually classified comments in the albanian language. furthermore, in this paper we report our efforts on the design and development of a sentiment analyser that relies on deep learning. as a result, we report the experimental findings obtained from our proposed sentiment analyser using various classifier models with static and contextualized word embeddings, that is, fasttext and bert, trained and validated on our collected and curated dataset. specifically, the findings reveal that combining the bilstm with an attention mechanism achieved the highest performance on our sentiment analysis task, with an f1 score of 72.09%.",
            "contribution_ids": [
                "R196546"
            ]
        },
        {
            "instance_id": "R197259xR197233",
            "comparison_id": "R197259",
            "paper_id": "R197233",
            "text": "Median infectious dose of human norovirus GII.4 in gnotobiotic pigs is decreased by simvastatin treatment and increased by age human noroviruses (novs), a major cause of viral gastroenteritis, are difficult to study due to the lack of a cell-culture and a small-animal model. pigs share with humans the types a and h histo-blood group antigens on the intestinal epithelium and have been suggested as a potential model for studies of nov pathogenesis, immunity and vaccines. in this study, the effects of age and a cholesterol-lowering drug, simvastatin, on the susceptibility of pigs to nov infection were evaluated. the median infectious dose (id 50 ) of a genogroup ii, genotype 4 (gii.4) 2006b variant was determined. the id 50 in neonatal (4\u20135 days of age) pigs was \u22642.74\u00d710 3 viral rna copies. in older pigs (33\u201334 days of age), the id 50 was 6.43\u00d710 4 but decreased to &lt;2.74\u00d710 3 in simvastatin-fed older pigs. evidence of nov infection was obtained by increased virus load in the intestinal contents, cytopathological changes in the small intestine, including irregular microvilli, necrosis and apoptosis, and detection of viral antigen in the tip of villi in duodenum. this gii.4 variant was isolated in 2008 from a patient from whom a large volume of stool was collected. gii.4 novs are continuously subjected to selective pressure by human immunity, and antigenically different gii.4 nov variants emerge every 1\u20132 years. the determination of the id 50 of this challenge virus is valuable for evaluation of protection against different gii.4 variants conferred by nov vaccines in concurrence with other gii.4 variants in the gnotobiotic pig model.",
            "contribution_ids": [
                "R197235"
            ]
        },
        {
            "instance_id": "R197259xR197147",
            "comparison_id": "R197259",
            "paper_id": "R197147",
            "text": "Pathogenesis of a Genogroup II Human Norovirus in Gnotobiotic Pigs abstract \\n \\n we\\nevaluated the gnotobiotic (gn) pig as a model to study the pathogenesis\\nof human norovirus (hunov) and to determine the target cells for viral\\nreplication. sixty-five gn pigs were inoculated with fecal filtrates of\\nthe nov/gii/4/hs66/2001/us strain or with pig-passaged intestinal\\ncontents (ic) and euthanized acutely (\\n n \\n = 43) or after\\nconvalescence (\\n n \\n = 22). age-matched gn piglets\\n(\\n n \\n = 14) served as mock-inoculated controls.\\nseventy-four percent (48/65) of the inoculated animals developed mild\\ndiarrhea compared to 0 of 14 controls. pigs from postinoculation days\\n(pid) 1 to 4 tested positive for hunov by reverse\\ntranscription-pcr of rectal swab fluids (29/65) and ic\\n(9/43) and by antigen (ag) enzyme-linked immunosorbent assay (elisa)\\nusing antiserum to virus-like particles of hunov gii/4. no\\ncontrol pigs were positive. histopathologic examination showed mild\\nlesions in the proximal small intestine of only one pig (1/7).\\nseroconversion after pid 21 was detected by antibody elisa in 13 of 22\\nvirus-inoculated pigs (titers, 1:20 to 1:200) but not in controls.\\nimmunofluorescent microscopy using a monoclonal antibody to hunov gii\\ncapsid revealed patchy infection of duodenal and jejunal enterocytes of\\n18 of 31 hunov-inoculated pigs with a few stained cells in the ileum\\nand no immunofluorescence (if) in mock-inoculated controls.\\nimmunofluorescent detection of the viral nonstructural n-terminal\\nprotein antigen in enterocytes confirmed translation. transmission\\nelectron microscopy of intestines from hunov-inoculated pigs showed\\ndisrupted enterocytes, with cytoplasmic membrane vesicles containing\\ncalicivirus-like particles of 25 to 40 nm in diameter. in summary,\\nserial passage of hunov in pigs, with occurrence of mild diarrhea and\\nshedding, and immunofluorescent detection of the hunov structural and\\nnonstructural proteins in enterocytes confirm hunov replication in gn\\npigs.\\n",
            "contribution_ids": [
                "R197149",
                "R197151",
                "R197152",
                "R197160"
            ]
        },
        {
            "instance_id": "R197259xR196998",
            "comparison_id": "R197259",
            "paper_id": "R196998",
            "text": "Replication of human noroviruses in stem cell-derived human enteroids the major barrier to research and development of effective interventions for human noroviruses (hunovs) has been the lack of a robust and reproducible in vitro cultivation system. hunovs are the leading cause of gastroenteritis worldwide. we report the successful cultivation of multiple hunov strains in enterocytes in stem cell\u2013derived, nontransformed human intestinal enteroid monolayer cultures. bile, a critical factor of the intestinal milieu, is required for strain-dependent hunov replication. lack of appropriate histoblood group antigen expression in intestinal cells restricts virus replication, and infectivity is abrogated by inactivation (e.g., irradiation, heating) and serum neutralization. this culture system recapitulates the human intestinal epithelium, permits human host-pathogen studies of previously noncultivatable pathogens, and allows the assessment of methods to prevent and treat hunov infections.",
            "contribution_ids": [
                "R197000"
            ]
        },
        {
            "instance_id": "R197259xR197188",
            "comparison_id": "R197259",
            "paper_id": "R197188",
            "text": "Experimental miniature piglet model for the infection of human norovirus GII ten yucatan miniature piglets were challenged with the human norovirus (nov) gii.12/gii.3 cau140599 strain and five piglets were used as negative controls. stool, serum, and organs were collected and processed from two nov\u2010infected piglets and one negative piglet at 1, 2, 3, 5, and 7 days post\u2010inoculation (dpi). nov was detected in stool and serum samples by real\u2010time rt\u2010pcr. mild diarrhea was observed at 1\u20103 dpi. fecal shedding and viremia were detected intermittently at 1, 3, and 7 dpi. while interferon\u2010\u03b1 was significantly elevated at 2\u20103 dpi, interferon\u2010\u03b3 was not changed. immunohistochemistry demonstrated that the nov capsid antigen was present in macrophages, lymphocytes, and dendritic cells of the stomach, intestines, lymph nodes, spleen, and tonsils. intestinal epithelium did not exhibit a positive signal for nov. in addition, negative\u2010sense viral rna was confirmed in immune cells by fluorescence in situ hybridization. therefore, nov might be associated with macrophages and lymphocytes in gastrointestinal tract and immune organs of experimentally infected miniature piglets.",
            "contribution_ids": [
                "R197192",
                "R197202"
            ]
        },
        {
            "instance_id": "R197259xR197177",
            "comparison_id": "R197259",
            "paper_id": "R197177",
            "text": "Pathogenesis and Immune Responses in Gnotobiotic Calves after Infection with the Genogroup II.4-HS66 Strain of Human Norovirus \" abstract \\n \\n we previously characterized the pathogenesis of two host-specific bovine enteric caliciviruses (bec), the giii.2 norovirus (nov) strain cv186-oh and the phylogenetically unassigned nb strain, in gnotobiotic (gn) calves. in this study we evaluated the gn calf as an alternative animal model to study the pathogenesis and host immune responses to the human norovirus (hunov) strain gii.4-hs66. the hunov hs66 strain caused diarrhea (five/five calves) and intestinal lesions (one/two calves tested) in the proximal small intestine (duodenum and jejunum) of gn calves, with lesions similar to, but less severe than, those described for the newbury agent 2 (na-2) and nb bec. viral capsid antigen was also detected in the jejunum of the proximal small intestine of one of two calves tested by immunohistochemistry. all inoculated calves shed virus in feces (five/five calves), and one/five had viremia. antibodies and cytokine (proinflammatory, tumor necrosis factor alpha [tnf-\u03b1]; th1, interleukin-12 [il-12] and gamma interferon [ifn-\u03b3]; th2, il-4; th2/t-regulatory, il-10) profiles were determined in serum, feces, and intestinal contents (ic) of the hunov-hs66-inoculated calves (\\n n \\n = 5) and controls (\\n n \\n = 4) by enzyme-linked immunosorbent assay in the acute (postinoculation day 3 [pid 3]) and convalescent (pid 28) stages of infection. the hunov-hs66-specific antibody and cytokine-secreting cells (cscs) were quantitated by elispot in mononuclear cells of local and systemic tissues at pid 28. sixty-seven percent of the hunov-hs66-inoculated calves seroconverted, and 100% coproconverted with immunoglobulin a (iga) and/or igg antibodies to hunov-hs66, at low titers. the highest numbers of antibody-secreting cells (asc), both iga and igg, were detected locally in intestine, but systemic iga and igg asc responses also occurred in the hunov-hs66-inoculated calves. in serum, hunov-hs66 induced higher peaks of tnf-\u03b1 and ifn-\u03b3 at pids 2, 7, and 10; of il-4 and il-10 at pid 4; and of il-12 at pids 7 and 10, compared to controls. in feces, cytokines increased earlier (pid 1) than in serum and tnf-\u03b1 and il-10 were elevated acutely in the ic of the hs66-inoculated calves. compared to controls, at pid 28 higher numbers of ifn-\u03b3 and tnf-\u03b1 cscs were detected in mesenteric lymph nodes (mln) or spleen and th2 (il-4) cscs were elevated in intestine; il-10 cscs were highest in spleen. our study provides new data confirming hunov-hs66 replication and enteropathogenicity in gn calves and reveals important and comprehensive aspects of the host's local (intestine and mln) and systemic (spleen and blood) immune responses to hunov-hs66.\\n \"",
            "contribution_ids": [
                "R197179"
            ]
        },
        {
            "instance_id": "R197259xR197236",
            "comparison_id": "R197259",
            "paper_id": "R197236",
            "text": "A Mouse Model for Human Norovirus abstract \\n \\n human noroviruses (hunovs) cause significant morbidity and mortality worldwide. however, despite substantial efforts, a small-animal model for hunov has not been described to date. since \u201chumanized\u201d mice have been successfully used to study human-tropic pathogens in the past, we challenged balb/c mice deficient in recombination activation gene (rag) 1 or 2 and common gamma chain (\u03b3c) (rag-\u03b3c) engrafted with human cd34\\n + \\n hematopoietic stem cells, nonengrafted siblings, and immunocompetent wild-type controls with pooled stool isolates from patients positive for hunov. surprisingly, both humanized and nonhumanized balb/c rag-\u03b3c-deficient mice supported replication of a gii.4 strain of hunov, as indicated by increased viral loads over input. in contrast, immunocompetent wild-type balb/c mice were not infected. an intraperitoneal route of infection and the balb/c genetic background were important for facilitating a subclinical hunov infection of rag-\u03b3c-deficient mice. expression of structural and nonstructural proteins was detected in cells with macrophage-like morphology in the spleens and livers of balb/c rag-\u03b3c-deficient mice, confirming the ability of hunov to replicate in a mouse model. in summary, hunov replication in balb/c rag-\u03b3c-deficient mice is dependent on the immune-deficient status of the host but not on the presence of human immune cells and provides the first genetically manipulable small-animal model for studying hunov infection.\\n \\n \\n importance \\n human noroviruses are a significant cause of viral gastroenteritis worldwide, resulting in significant morbidity and mortality. antivirals and vaccines are currently not available, in part due to the inability to study these viruses in a genetically manipulable, small-animal model. herein, we report the first mouse model for human noroviruses. this model will accelerate our understanding of human norovirus biology and provide a useful resource for evaluating antiviral therapies.\\n",
            "contribution_ids": [
                "R197238",
                "R197245",
                "R197250"
            ]
        },
        {
            "instance_id": "R197375xR193573",
            "comparison_id": "R197375",
            "paper_id": "R193573",
            "text": "Impact of COVID-19 Lockdown on Wildlife-Vehicle Collisions in NW of Spain wildlife\u2013vehicle collisions (wvcs) in many places have a significant impact on wildlife management and road safety. the covid-19 lockdown enabled the study of the specific impact that traffic has on these events. wvc variation in the asturias and cantabria regions (nw of spain) because of the covid-19 lockdown reached a maximum reduction of \u221264.77% during strict confinement but it was minimal or nonexistent during \u201csoft\u201d confinement. the global average value was \u221230.22% compared with the wvcs registered in the same period in 2019, but only \u22124.69% considering the average throughout the period 2010\u20132019. there are huge differences between conventional roads, where the traffic reduction was greater, and highways, where the traffic reduction was lesser during the covid-19 lockdown. the results depend on the season, the day of the week and the time of day, but mainly on the traffic reduction occurring. the results obtained highlight the need to include the traffic factor in wvc reduction strategies.",
            "contribution_ids": [
                "R193574"
            ]
        },
        {
            "instance_id": "R197375xR193556",
            "comparison_id": "R197375",
            "paper_id": "R193556",
            "text": "Elevated wildlife-vehicle collision rates during the COVID-19 pandemic abstract wildlife-vehicle collisions threaten both humans and wildlife, but we still lack information about the relationship between traffic volume and wildlife-vehicle collisions. the covid-19 pandemic allowed us to investigate the effects of traffic volume on wildlife-vehicle collisions in the united states. we observed decreased traffic nationwide, particularly in densely populated states with low or high disease burdens. despite reduced traffic, total collisions were unchanged; wildlife-vehicle collisions did decline at the start of the pandemic, but increased as the pandemic progressed, ultimately exceeding collisions in the previous year. as a result, nationwide collision rates were higher during the pandemic. we suggest that increased wildlife road use offsets the effects of decreased traffic volume on wildlife-vehicle collisions. thus, decreased traffic volume will not always reduce wildlife-vehicle collisions.",
            "contribution_ids": [
                "R193557"
            ]
        },
        {
            "instance_id": "R198562xR197437",
            "comparison_id": "R198562",
            "paper_id": "R197437",
            "text": "Traffic Impacts of the COVID-19 Pandemic: Statewide Analysis of Social Separation and Activity Restriction abstractthe covid-19 pandemic resulted in significant social and economic impacts throughout the world. in addition to the health consequences, the impacts on travel behavior have also been sudden ...",
            "contribution_ids": [
                "R197442"
            ]
        },
        {
            "instance_id": "R198562xR197510",
            "comparison_id": "R198562",
            "paper_id": "R197510",
            "text": "Has COVID-19 Lockdown Affected on Air Quality?\u00e2\u0080\u0094Different Time Scale Case Study in Wroc\u00c5\u0082aw, Poland due to the covid-19 pandemic, there are series of negative economic consequences, however, in limiting mobility and reducing the number of vehicles, positive effects can also be observed, i.e., improvement of air quality. the paper presents an analysis of air quality measured by concentrations of no2, nox and pm2.5 during the most restrictive lockdown from 10 march to 31 may 2020 on the case of wroc\u0142aw. the results were compared with the reference period\u20142016\u20132019. a significant reduction in traffic volume was identified, on average by 26.3%. the greatest reduction in the concentration of no2 and nox was recorded at the station farthest from the city center, characterized by the lowest concentrations: 20.1% and 22.4%. lower reduction in the average concentrations of no2 and nox was recorded at the municipal station (7.9% and 7.7%) and the communication station (6.7% and 10.2%). concentrations of pms in 2020 were on average 15% and 13.4% lower than in the reference period for the traffic station and the background station. the long-term impact of the lockdown on air quality was also examined. the analysis of the concentrations of the pollutants throughout 2020, and in the analyzed period of 2021, indicated that the reduction of concentrations and the improvement in air quality caused by the restrictions should be considered as a temporary anomaly, without affecting long-term changes and trends.",
            "contribution_ids": [
                "R197514",
                "R201083",
                "R201090"
            ]
        },
        {
            "instance_id": "R198562xR193556",
            "comparison_id": "R198562",
            "paper_id": "R193556",
            "text": "Elevated wildlife-vehicle collision rates during the COVID-19 pandemic abstract wildlife-vehicle collisions threaten both humans and wildlife, but we still lack information about the relationship between traffic volume and wildlife-vehicle collisions. the covid-19 pandemic allowed us to investigate the effects of traffic volume on wildlife-vehicle collisions in the united states. we observed decreased traffic nationwide, particularly in densely populated states with low or high disease burdens. despite reduced traffic, total collisions were unchanged; wildlife-vehicle collisions did decline at the start of the pandemic, but increased as the pandemic progressed, ultimately exceeding collisions in the previous year. as a result, nationwide collision rates were higher during the pandemic. we suggest that increased wildlife road use offsets the effects of decreased traffic volume on wildlife-vehicle collisions. thus, decreased traffic volume will not always reduce wildlife-vehicle collisions.",
            "contribution_ids": [
                "R193557"
            ]
        },
        {
            "instance_id": "R198562xR196764",
            "comparison_id": "R198562",
            "paper_id": "R196764",
            "text": "Unexpected Impact of COVID-19 Lockdown on the Air Quality in the Metro Atlanta, USA Using Ground-based and Satellite Observations we studied the impact of covid-19 (coronavirus disease 2019) lockdown on the air quality over the atlanta area using satellite and ground-based observations, meteorological reanalysis data and traffic information. unlike other cities, we found the air quality has improved slightly over the atlanta area during the 2020 covid-19 lockdown period (march 14\u2013april 30, 2020), compared to the analogous period of 2019 (march 14\u2013april 30, 2019). ground no2 concentrations have decreased slightly 10.8% and 8.2% over the near-road (nr) and urban ambient (ua) stations, respectively. tropospheric no2 columns have reduced 13%\u201349% over the atlanta area from space-borne observations of tropospheric monitoring instrument (tropomi). ground ozone and pm2.5 have decreased 15.7% and ~5%, respectively. this slight air quality improvement is primarily caused by the reduced human activities, as covid-19 lockdowns have reduced ~50% human activities, measured by traffic volume. higher wind speed and precipitations also make the meteorological conditions favorable to this slight air quality improvement. we have not found a significant improvement in air quality over atlanta amid the lockdown when human activities have reduced ~50%. further studies are needed to understand the impacts of reduced human activities on atmospheric chemistry. we also found tropomi and ground measurements have disagreements on no2 reductions, as collocated tropomi observations revealed ~23% and ~21% reductions of tropospheric no2 columns over nr and ua stations, respectively. several factors may explain this disagreement: first, tropospheric no2 columns and ground no2 concentrations are not necessarily the same, although they are highly correlated in the afternoon;second, meteorological conditions may have different impacts on tropmi and ground measurements. third, tropomi may underestimate tropospheric no2 due to uncertainties from air mass factors. fourth, the uncertainties of chemiluminescence no2 measurements used by ground stations. consequently, studies using space-borne tropospheric no2 column and ground no2 measurements should take these factors into account. \u00a9 the author(s).",
            "contribution_ids": [
                "R196766",
                "R201018",
                "R201025",
                "R201028",
                "R201030"
            ]
        },
        {
            "instance_id": "R198562xR195612",
            "comparison_id": "R198562",
            "paper_id": "R195612",
            "text": "Road Traffic Injury During the COVID-19 Pandemic: Cured or a Continued Threat? road traffic injury, one of the leading causes of preventable morbidity and mortality in canada, declined substantially as an indirect outcome of the first wave of the covid-19 pandemic. public health policies encouraging people to \u2018stay at home\u2019 and \u2018practice physical distancing\u2019 precipitated shifts in vehicle volumes and speed, transportation mode, and collision rates. toronto data from january to june 2020 showed a decrease in road transportation, and a simultaneous decrease in road traffic collisions. however, reduced traffic volumes also led to increased vehicle speeds which can result in an increase in injury severity involving pedestrians and cyclists. as the pandemic progresses, an emphasis on safe, active transportation and equitable distribution of street infrastructure throughout the city is essential. a public health approach to road safety includes implementation of evidence-based road safety infrastructure enabled by access to timely transportation data to evaluate changes made.",
            "contribution_ids": [
                "R195614"
            ]
        },
        {
            "instance_id": "R198562xR196754",
            "comparison_id": "R198562",
            "paper_id": "R196754",
            "text": "Quantification of Non-Exhaust Particulate Matter Traffic Emissions and the Impact of COVID-19 Lockdown at London Marylebone Road this research quantifies current sources of non-exhaust particulate matter traffic emissions in london using simultaneous, highly time-resolved, atmospheric particulate matter mass and chemical composition measurements. the measurement campaign ran at marylebone road (roadside) and honor oak park (background) urban monitoring sites over a 12-month period between 1 september 2019 and 31 august 2020. the measurement data were used to determine the traffic increment (roadside\u2013background) and covered a range of meteorological conditions, seasons, and driving styles, as well as the influence of the covid-19 \u201clockdown\u201d on non-exhaust concentrations. non-exhaust particulate matter (pm)10 concentrations were calculated using chemical tracer scaling factors for brake wear (barium), tyre wear (zinc), and resuspension (silicon) and as average vehicle fleet non-exhaust emission factors, using a co2 \u201cdilution approach\u201d. the effect of lockdown, which saw a 32% reduction in traffic volume and a 15% increase in average speed on marylebone road, resulted in lower pm10 and pm2.5 traffic increments and brake wear concentrations but similar tyre and resuspension concentrations, confirming that factors that determine non-exhaust emissions are complex. brake wear was found to be the highest average non-exhaust emission source. in addition, results indicate that non-exhaust emission factors were dependent upon speed and road surface wetness conditions. further statistical analysis incorporating a wider variability in vehicle mix, speeds, and meteorological conditions, as well as advanced source apportionment of the pm measurement data, were undertaken to enhance our understanding of these important vehicle sources.",
            "contribution_ids": [
                "R196759",
                "R200075",
                "R200131"
            ]
        },
        {
            "instance_id": "R199173xR197543",
            "comparison_id": "R199173",
            "paper_id": "R197543",
            "text": "Tackling Neural Architecture Search With Quality Diversity Optimization neural architecture search (nas) has been studied extensively and has grown to become 5 a research field with substantial impact. while classical single-objective nas searches 6 for the architecture with the best performance, multi-objective nas considers multiple 7 objectives that should be optimized simultaneously, e.g., minimizing resource usage along 8 the validation error. although considerable progress has been made in the field of multi-9 objective nas, we argue that there is some discrepancy between the actual optimization 10 problem of practical interest and the optimization problem that multi-objective nas tries to 11 solve. we resolve this discrepancy by formulating the multi-objective nas problem as a 12 quality diversity optimization (qdo) problem and introduce three quality diversity nas 13 optimizers (two of them belonging to the group of multifidelity optimizers), which search for 14 high-performing yet diverse architectures that are optimal for application-specific niches, 15 e.g., hardware constraints. we compare these optimizers to their multi-objective counterparts 16 and demonstrate that quality diversity nas in general outperforms multi-objective nas 17 with respect to quality of solutions and efficiency. using model compression, we show how 18 qdo can be applied to obtain a set of sparser yet high-performing architectures.",
            "contribution_ids": [
                "R197544"
            ]
        },
        {
            "instance_id": "R199173xR197527",
            "comparison_id": "R199173",
            "paper_id": "R197527",
            "text": "BERT-Sort: A Zero-shot MLM Semantic Encoder on Ordinal Features for AutoML data pre-processing is one of the key steps in creating machine learning pipelines for tabular 5 data. one of the common data pre-processing operations implemented in automl systems 6 is to encode categorical features as numerical features. typically, this is implemented using 7 a simple alphabetical sort on the categorical values, using functions such as ordinalencoder , labelencoder in scikit-learn and h2o . however, often there exist semantic ordinal rela-9 tionships among the categorical values, such as: quality level (i.e., [\u2019very good\u2019 > \u2019good\u2019 > 10 \u2019normal\u2019> \u2019poor\u2019]), or month (i.e., [\u2019jan\u2019< \u2019feb\u2019 < \u2019mar\u2019]). such semantic relationships are not 11 exploited by previous automl approaches. in this paper, we introduce bert-sort, a novel 12 approach to semantically encode ordinal categorical values via zero-shot masked language 13 models (mlm) and apply it to automl for tabular data. we created a new benchmark of 14 42 features from 10 public data sets for sorting categorical ordinal values for the first time, 15 where bert-sort significantly improves semantic encoding of ordinal values in comparison 16 to the existing approaches with 27% improvement. we perform a comprehensive evaluation 17 of bert-sort on different public mlms, such as roberta, xlm and distilbert. we also 18 compare the performance of raw data sets against encoded data sets through bert-sort 19 in different automl platforms including autogluon, flaml, h2o, mljar and tpot to 20 evaluate the proposed approach in an end-to-end scenario. bert-sort successfully improves 21 the performance of models in 4 different automl tools with 10.61% performance gain.",
            "contribution_ids": [
                "R197528"
            ]
        },
        {
            "instance_id": "R199173xR197576",
            "comparison_id": "R199173",
            "paper_id": "R197576",
            "text": "DIFER: Differentiable Automated Feature Engineering feature engineering, a crucial step of machine learning, aims to extract useful features from raw data to improve data quality. in recent years, great efforts have been devoted to automated feature engineering (autofe) to replace expensive human labor. however, existing methods are computationally demanding due to treating autofe as a coarse-grained black-box optimization problem over a discrete space. in this work, we propose an efficient gradient-based method called difer to perform differentiable automated feature engineering in a continuous vector space. difer selects potential features based on evolutionary algorithm and leverages an encoder-predictor-decoder controller to optimize existing features. we map features into the continuous vector space via the encoder, optimize the embedding along the gradient direction induced by the predicted score, and recover better features from the optimized embedding by the decoder. extensive experiments on classification and regression datasets demonstrate that difer can significantly improve the performance of various machine learning algorithms and outperform current state-of-the-art autofe methods in terms of both efficiency and performance.",
            "contribution_ids": [
                "R197577"
            ]
        },
        {
            "instance_id": "R199173xR197523",
            "comparison_id": "R199173",
            "paper_id": "R197523",
            "text": "Automated Super-Network Generation for Scalable Neural Architecture Search weight-sharing neural architecture search (nas) solutions often discover neural network architectures that outperform their human-crafted counterparts. weight-sharing allows the creation and training of super-networks that contain many smaller and more efficient child models, a.k.a., sub-networks. for an average deep learning practitioner, generating and training one of these super-networks for an arbitrary neural network architecture design space can be a daunting experience. in this paper, we present bootstrapnas, a software framework that addresses this challenge by automating the generation and training of super-networks. developers can use this solution to convert a pre-trained model into a super-network. bootstrapnas then trains the super-network using a weight-sharing nas technique available in the framework or provided by the user. finally, a search component discovers high-performing sub-networks that are returned to the end-user. we demonstrate bootstrapnas by automatically generating super-networks from popular pre-trained models (mobilenetv2, mobilenetv3, efficientnet, resnet50 and hyperseg), available from torchvision and other repositories. bootstrapnas can achieve up to 9 . 87 \u00d7 improvement in throughput in comparison to the pre-trained torchvision resnet-50 (fp32) on intel xeon platform. our code is available at https://github.com/jpablomch/bootstrapnas presents a comparison of predicted versus measured latency from optimal sub-networks identified during a nsga-ii search using the simple example latency predictor. although error is introduced when using predictors, the discovered sub-networks tend to outperform the ones found with random search.",
            "contribution_ids": [
                "R197524"
            ]
        },
        {
            "instance_id": "R199173xR197556",
            "comparison_id": "R199173",
            "paper_id": "R197556",
            "text": "When, where, and how to add new neurons to ANNs neurogenesis in anns is an understudied and difficult problem, even compared to other forms of structural learning like pruning. by decomposing it into triggers and initializations, we introduce a framework for studying the various facets of neurogenesis: when, where, and how to add neurons during the learning process. we present the neural orthogonality (north*) suite of neurogenesis strategies, combining layer-wise triggers and initializations based on the orthogonality of activations or weights to dynamically grow performant networks that converge to an efficient size. we evaluate our contributions against other recent neurogenesis works across a variety of supervised learning tasks. 1",
            "contribution_ids": [
                "R197557"
            ]
        },
        {
            "instance_id": "R199173xR197535",
            "comparison_id": "R199173",
            "paper_id": "R197535",
            "text": "AutoCoG: A Unified Data-Model Co-Search Framework for Graph Neural Networks neural architecture search (nas) has demonstrated success in discovering promising ar-5 chitectures for vision or language modeling tasks, and it has recently been introduced to 6 searching for graph neural networks (gnns) as well. despite the preliminary success, gnns 7 struggle in dealing with heterophily or low-homophily graphs where connected nodes may have different class labels and dissimilar features. to this end, we propose co-optimizing both the input graph topology and the model\u2019s architecture topology simultaneously. that yields autocog , the first unified data-model co-search nas framework for gnns. by defining a 11 highly flexible data-model co-search space, autocog is gracefully formulated as a principled 12 bi-level optimization that can be end-to-end solved by the differentiable search methods. 13 experiments show autocog achieves an average performance gain across all datasets of 14 3.18% over the following best approach and ranks best against all other state-of-the-art 15 methods with an average ranking of 2.5.",
            "contribution_ids": [
                "R197536"
            ]
        },
        {
            "instance_id": "R199176xR195718",
            "comparison_id": "R199176",
            "paper_id": "R195718",
            "text": "NAct: The Nutrition &amp; Activity Ontology for Healthy Living this paper presents the nact (nutrition &amp; activity) ontology, designed to drive personalised nutritional and physical activity recommendations and effectively support healthy living, through a reasoning-based ai decision support system. nact coalesces nutritional, medical, behavioural and lifestyle indicators with potential dietary and physical activity directives. the paper presents the first version of the ontology, including its co-design and engineering methodology, along with usage examples in supporting healthy nutritional and physical activity choices. lastly, the plan for future improvements and extensions is discussed.",
            "contribution_ids": [
                "R195720",
                "R195751",
                "R195752"
            ]
        },
        {
            "instance_id": "R199176xR194910",
            "comparison_id": "R199176",
            "paper_id": "R194910",
            "text": "An example of food ontology for diabetes control this paper describes our experience in the rapid prototyping of a food ontology oriented to the nutritional and health care domain that is used to share knowledge between the different stakeholders involved in the pips project.",
            "contribution_ids": [
                "R194912",
                "R194913",
                "R194914"
            ]
        },
        {
            "instance_id": "R199176xR198620",
            "comparison_id": "R199176",
            "paper_id": "R198620",
            "text": "Ontology and semantic matching for diabetic food recommendations \"foods recommendation for diabetes patients is indispensable for controlling blood sugar levels. currently, the foods preparation is done by a nutrition expert. the patient's dependence on the nutrition experts is very high, thus the selection of foods could not be done independently. the automation system to determine foods combination for diabetic patients is needed to solve these problems. in this study, the automation system has been designed and implemented. the technologies used in this research are the owl and swrl. there are few researches that explore an automation process of foods recommendation for diabetes patients using the technology of owl and swrl. domain knowledge based on ontology is needed to process foods composition automatically. however, using swrl and owl technology is not enough, because the accuracy of the words required. a semantic ontology understanding was added using weighted tree similarity method to specify the composition of foods for diabetic patients. 73% data were able to be correctly predicted by this method.\"",
            "contribution_ids": [
                "R198622",
                "R198623",
                "R198624"
            ]
        },
        {
            "instance_id": "R199176xR195342",
            "comparison_id": "R199176",
            "paper_id": "R195342",
            "text": "Constructing Cooking Ontology for Live Streams we build a cooking domain knowledge by using an ontology schema that reflects natural language processing and enhances ontology instances with semantic query. our research helps audiences to better understand live streaming, especially when they just switch to a show. the practical contribution of our research is to use cooking ontology, so we may map clips of cooking live stream video and instructions of recipes. the architecture of our study presents three sections: ontology construction, ontology enhancement, and mapping cooking video to cooking ontology. also, our preliminary evaluations consist of three hierarchies\u2014nodes, ordered-pairs, and 3-tuples\u2014that we use to referee (1) ontology enhancement performance for our first experiment evaluation and (2) the accuracy ratio of mapping between video clips and cooking ontology for our second experiment evaluation. our results indicate that ontology enhancement is effective and heightens accuracy ratios on matching pairs with cooking ontology and video clips.",
            "contribution_ids": [
                "R195344",
                "R195345",
                "R195346",
                "R195347",
                "R195355",
                "R195374"
            ]
        },
        {
            "instance_id": "R199176xR198205",
            "comparison_id": "R199176",
            "paper_id": "R198205",
            "text": "FTTO: An example of Food Ontology for traceability purpose this paper describes our experience in the development of the food track&trace ontology (ftto), an ontology oriented to the domain of food traceability. ftto is used to share knowledge between agents involved in the food supply chain and intends to be a reference that permits to work with information obtained through the matching and merging of different controlled vocabularies. as part of a bigger research project, the ftto has been designed to be connected with a global traceability information systems obtained through the modelling of the food supply chain and of data required for internal and chain traceability. the paper presents the project milestones and the creation of the core ontology emphasizing on the development of the main classes.",
            "contribution_ids": [
                "R198207",
                "R198208"
            ]
        },
        {
            "instance_id": "R199177xR194910",
            "comparison_id": "R199177",
            "paper_id": "R194910",
            "text": "An example of food ontology for diabetes control this paper describes our experience in the rapid prototyping of a food ontology oriented to the nutritional and health care domain that is used to share knowledge between the different stakeholders involved in the pips project.",
            "contribution_ids": [
                "R194912",
                "R194913",
                "R194914"
            ]
        },
        {
            "instance_id": "R199177xR198117",
            "comparison_id": "R199177",
            "paper_id": "R198117",
            "text": "FOODS: A Food-Oriented Ontology-Driven System in this paper the authors present the design and development of a counseling system for food or menu planning in a restaurant, clinic/hospital, or at home, the food-oriented ontology-driven system (foods). foods comprises (a) a food ontology, (b) an expert system using the ontology, and some knowledge about cooking methods and prices, and (c) a user interface suitable for novices in computers and diets as well as for experts. the ontology contains specifications of ingredients, substances, nutrition facts, recommended daily intakes for different regions, dishes, and menus. the expert system assists in finding the appropriate dish or menu for the consumer, client or customer, who use foods by entering their favorite ingredients, ingredients to avoid, favorite flavors, and so on. in the health section users can provide their gender, age, height and weight, which will be used to calculate such data as the body mass index. with foods enterprises can assist customers through an appropriate suggestion of dishes and meals with the help of individual nutritional profiles. smes that might be interested in using foods are institutions for training and instruction of cooking, restaurants, clinics, hospitals, together with clinical and therapeutical dietitians and nutritional therapists. in the long run such systems might become part of the emerging consumer health informatics portfolio.",
            "contribution_ids": [
                "R198119",
                "R198120",
                "R198121"
            ]
        },
        {
            "instance_id": "R199177xR195342",
            "comparison_id": "R199177",
            "paper_id": "R195342",
            "text": "Constructing Cooking Ontology for Live Streams we build a cooking domain knowledge by using an ontology schema that reflects natural language processing and enhances ontology instances with semantic query. our research helps audiences to better understand live streaming, especially when they just switch to a show. the practical contribution of our research is to use cooking ontology, so we may map clips of cooking live stream video and instructions of recipes. the architecture of our study presents three sections: ontology construction, ontology enhancement, and mapping cooking video to cooking ontology. also, our preliminary evaluations consist of three hierarchies\u2014nodes, ordered-pairs, and 3-tuples\u2014that we use to referee (1) ontology enhancement performance for our first experiment evaluation and (2) the accuracy ratio of mapping between video clips and cooking ontology for our second experiment evaluation. our results indicate that ontology enhancement is effective and heightens accuracy ratios on matching pairs with cooking ontology and video clips.",
            "contribution_ids": [
                "R195344",
                "R195345",
                "R195346",
                "R195347",
                "R195355",
                "R195374"
            ]
        },
        {
            "instance_id": "R199177xR195718",
            "comparison_id": "R199177",
            "paper_id": "R195718",
            "text": "NAct: The Nutrition &amp; Activity Ontology for Healthy Living this paper presents the nact (nutrition &amp; activity) ontology, designed to drive personalised nutritional and physical activity recommendations and effectively support healthy living, through a reasoning-based ai decision support system. nact coalesces nutritional, medical, behavioural and lifestyle indicators with potential dietary and physical activity directives. the paper presents the first version of the ontology, including its co-design and engineering methodology, along with usage examples in supporting healthy nutritional and physical activity choices. lastly, the plan for future improvements and extensions is discussed.",
            "contribution_ids": [
                "R195720",
                "R195751",
                "R195752"
            ]
        },
        {
            "instance_id": "R199177xR198205",
            "comparison_id": "R199177",
            "paper_id": "R198205",
            "text": "FTTO: An example of Food Ontology for traceability purpose this paper describes our experience in the development of the food track&trace ontology (ftto), an ontology oriented to the domain of food traceability. ftto is used to share knowledge between agents involved in the food supply chain and intends to be a reference that permits to work with information obtained through the matching and merging of different controlled vocabularies. as part of a bigger research project, the ftto has been designed to be connected with a global traceability information systems obtained through the modelling of the food supply chain and of data required for internal and chain traceability. the paper presents the project milestones and the creation of the core ontology emphasizing on the development of the main classes.",
            "contribution_ids": [
                "R198207",
                "R198208"
            ]
        },
        {
            "instance_id": "R199178xR195342",
            "comparison_id": "R199178",
            "paper_id": "R195342",
            "text": "Constructing Cooking Ontology for Live Streams we build a cooking domain knowledge by using an ontology schema that reflects natural language processing and enhances ontology instances with semantic query. our research helps audiences to better understand live streaming, especially when they just switch to a show. the practical contribution of our research is to use cooking ontology, so we may map clips of cooking live stream video and instructions of recipes. the architecture of our study presents three sections: ontology construction, ontology enhancement, and mapping cooking video to cooking ontology. also, our preliminary evaluations consist of three hierarchies\u2014nodes, ordered-pairs, and 3-tuples\u2014that we use to referee (1) ontology enhancement performance for our first experiment evaluation and (2) the accuracy ratio of mapping between video clips and cooking ontology for our second experiment evaluation. our results indicate that ontology enhancement is effective and heightens accuracy ratios on matching pairs with cooking ontology and video clips.",
            "contribution_ids": [
                "R195344",
                "R195345",
                "R195346",
                "R195347",
                "R195355",
                "R195374"
            ]
        },
        {
            "instance_id": "R199178xR198620",
            "comparison_id": "R199178",
            "paper_id": "R198620",
            "text": "Ontology and semantic matching for diabetic food recommendations \"foods recommendation for diabetes patients is indispensable for controlling blood sugar levels. currently, the foods preparation is done by a nutrition expert. the patient's dependence on the nutrition experts is very high, thus the selection of foods could not be done independently. the automation system to determine foods combination for diabetic patients is needed to solve these problems. in this study, the automation system has been designed and implemented. the technologies used in this research are the owl and swrl. there are few researches that explore an automation process of foods recommendation for diabetes patients using the technology of owl and swrl. domain knowledge based on ontology is needed to process foods composition automatically. however, using swrl and owl technology is not enough, because the accuracy of the words required. a semantic ontology understanding was added using weighted tree similarity method to specify the composition of foods for diabetic patients. 73% data were able to be correctly predicted by this method.\"",
            "contribution_ids": [
                "R198622",
                "R198623",
                "R198624"
            ]
        },
        {
            "instance_id": "R199178xR195718",
            "comparison_id": "R199178",
            "paper_id": "R195718",
            "text": "NAct: The Nutrition &amp; Activity Ontology for Healthy Living this paper presents the nact (nutrition &amp; activity) ontology, designed to drive personalised nutritional and physical activity recommendations and effectively support healthy living, through a reasoning-based ai decision support system. nact coalesces nutritional, medical, behavioural and lifestyle indicators with potential dietary and physical activity directives. the paper presents the first version of the ontology, including its co-design and engineering methodology, along with usage examples in supporting healthy nutritional and physical activity choices. lastly, the plan for future improvements and extensions is discussed.",
            "contribution_ids": [
                "R195720",
                "R195751",
                "R195752"
            ]
        },
        {
            "instance_id": "R199196xR189554",
            "comparison_id": "R199196",
            "paper_id": "R189554",
            "text": "A Constrained Assembly Strategy for High-Strength Natural Nanoclay Film developing high-performance materials from existing natural materials is highly desired because of their environmental friendliness and low cost; two-dimensional nanoclay exfoliated from layered silicate minerals is a good building block to construct multilayered macroscopic assemblies for achieving high mechanical and functional properties. nevertheless, the efforts have been frustrated by insufficient inter-nanosheet stress transfer and nanosheet misalignment caused by capillary force during solution-based spontaneous assembly, degrading the mechanical strength of clay-based materials. herein, a constrained assembly strategy that is implemented by in-plane stretching a robust water-containing nanoclay network with hydrogen and ionic bonding is developed to adjust the 2d topography of nanosheets within multilayered nanoclay film. in-plane stretching overcomes capillary force during water removal and thus restrains nanosheet conformation transition from nearly flat to wrinkled, leading to a highly aligned multilayered nanostructure with synergistic hydrogen and ionic bonding. it is proved that inter-nanosheet hydrogen and ionic bonding and nanosheet conformation extension generate profound mechanical reinforcement. the tensile strength and modulus of natural nanoclay film reach up to 429.0 mpa and 43.8 gpa and surpass the counterparts fabricated by normal spontaneous assembly. additionally, improved heat insulation function and good nonflammability are shown for the natural nanoclay film and extend its potential for realistic uses.",
            "contribution_ids": [
                "R189557"
            ]
        },
        {
            "instance_id": "R199196xR189578",
            "comparison_id": "R199196",
            "paper_id": "R189578",
            "text": "High strength, flexible and transparent nanofibrillated cellulose\u00e2\u0080\u0093nanoclay biohybrid films with tunable oxygen and water vapor permeability a novel, technically and economically benign procedure to combine vermiculite nanoplatelets with nanocellulose fibre dispersions into functional biohybrid films is presented. nanocellulose fibres of 20 nm diameters and several micrometers in length are mixed with high aspect ratio exfoliated vermiculite nanoplatelets through high-pressure homogenization. the resulting hybrid films obtained after solvent evaporation are stiff (tensile modulus of 17.3 gpa), strong (strength up to 257 mpa), and transparent. scanning electron microscopy (sem) shows that the hybrid films consist of stratified nacre-like layers with a homogenous distribution of nanoplatelets within the nanocellulose matrix. the oxygen barrier properties of the biohybrid films outperform commercial packaging materials and pure nanocellulose films showing an oxygen permeability of 0.07 cm(3) \u03bcm m(-2) d(-1) kpa(-1) at 50% relative humidity. the oxygen permeability of the hybrid films can be tuned by adjusting the composition of the films. furthermore, the water vapor barrier properties of the biohybrid films were also significantly improved by the addition of nanoclay. the unique combination of excellent oxygen barrier behavior and optical transparency suggests the potential of these biohybrid materials as an alternative in flexible packaging of oxygen sensitive devices such as thin-film transistors or organic light-emitting diode displays, gas storage applications and as barrier coatings/laminations in large volume packaging applications.",
            "contribution_ids": [
                "R189580"
            ]
        },
        {
            "instance_id": "R199196xR189565",
            "comparison_id": "R199196",
            "paper_id": "R189565",
            "text": "Facile Access to Large-Scale, Self-Assembled, Nacre-Inspired, High-Performance Materials with Tunable Nanoscale Periodicities although advances have been reported to mimic the mechanically excellent structure of natural nacre, larger-scale applications are still limited due to time and energy-intensive preparation pathways. herein, we demonstrate that simple high-shear homogenization of dispersions containing biobased high molecular weight sodium carboxymethyl cellulose (700 kg/mol, cmc) and natural sodium montmorillonite (mtm), serving as the soft energy-dissipating phase and reinforcing platelets, respectively, can be used to prepare large-area and thick films with well-aligned hard/soft nacre-mimetic mesostructure. during this process, core-shell nanoplatelets with intrinsic hard/soft structure form, which then self-assemble into a layered nanocomposite during water removal. the nanoscale periodicities of the alternating hard/soft layers can be precisely tuned by changing the ratio of cmc to mtm, which allows studying the evolution of mechanical properties as a function of the lamellar nanoscale periodicity and fractions of hard to soft material. remarkable mechanical stiffness (25 gpa) and strength (320 mpa) can be obtained placing these materials among the top end of nacre-inspired materials reported so far. mechanical homogenization also allows direct preparation of concentrated, yet homogeneous, gel-like dispersions of high nanoclay content, suited to doctor-blade large-area and thick films with essentially the same properties as films cast from dilute dispersions. in terms of functional properties, we report high-transparency, shape-persistent fire-blocking and the ability to surface-pattern via inkjet printing. considering the simple, fully scalable, waterborne preparation pathway, and the use of nature-based components, we foresee applications as ecofriendly, bioinspired materials to promote sustainable engineering materials and novel types of functional barrier coatings and substrates.",
            "contribution_ids": [
                "R189566"
            ]
        },
        {
            "instance_id": "R199196xR189682",
            "comparison_id": "R199196",
            "paper_id": "R189682",
            "text": "Artificial Nacre-like Bionanocomposite Films from the Self-Assembly of Chitosan-Montmorillonite Hybrid Building Blocks in the last decade, there has been a trend in chemistry to reduce the human impact on the environment. special attention has been paid to the replacement of conventional petroleum-based plastics by materials based on biopolymers. however, the mechanical and thermal properties and functionalities of these biopolymers have to be enhanced to be competitive with the petroleum-based plastics from the viewpoint of practical applications. one of the most promising solutions to overcome these drawbacks is the elaboration of bionanocomposite, namely the dispersion of nanosized filler into a biopolymer matrix. because of their functional properties, bionanocomposites as green nanocomposites based on biopolymers and layered silicates (clays) have received intensive attention in materials science. 4] chitosan and montmorillonite (mtm), an abundant polysaccharide and a natural clay respectively, have been widely used as the constituents of bionanocomposites. the intercalation of chitosan into mtm and the dispersion of mtm nanosheets in the chitosan matrix have been systematically investigated. bionanocomposites based on chitosan intercalation into mtm can be used as a sensor applied in the potentiometric determination of several anions. bionanocomposite films formed through the dispersion of mtm nanosheets in the chitosan matrix have shown enhancement of the mechanical and thermal properties compared with the pure chitosan film. unfortunately, the enhancement of the tensile strength and thermal stability of the chitosan\u2013mtm bionanocomposite film is still low far from the expectations in industry. systematic studies are carried out in materials science on natural materials with the objective of duplicating their properties in artificial materials. natural nanocomposites provide prime design models of lightweight, strong, stiff, and tough materials due to the hierarchical organization of the micro and nanostructures. one attractive biological model for artificial material design is nacre (mother-of-pearl). the microscopic architecture of nacre has been classically illustrated as a \u201cbrick-and-mortar\u201d arrangement that plays an important role in the amazing mechanical properties of the nacre. this arrangement is constituted of highly aligned inorganic aragonite platelets surrounded by a protein matrix, which serves as a glue between the platelets. recently, the microstructure of the nacre has been mimicked by several innovative techniques to fabricate the artificial nacre-like materials with high mechanical performance. for example, layer-by-layer (lbl) deposition combining with cross-linking yielded poly(vinyl alcohol)/mtm nacre-like nanocomposites with a tensile strength of up to 400 mpa; the ice-crystal templates of the microscopic layers were designed to form a brick-and-mortar microstructured al2o3/poly(methyl methacrylate) composite that is 300 times tougher than its constituents; the assembly of al2o3 platelets on the air/water interface and sequent spincoating was developed into the fabrication of lamellar al2o3/ chitosan hybrid films with high flaw tolerance and ductility; the self-assembly of nanoclays with polymers coating by a paper-making method resulted in the nacre-mimetic films; and nacre-like structural mtm\u2013polyimide nanocomposites were fabricated by centrifugation deposition-assisted assembly. our group has also fabricated nacre-like chitosanlayered double hydroxide hybrid films with a tensile strength of up to 160mpa by sequential dipping coating and the lbl technique. the concept of mimicking nacre and recently developed innovative techniques inspired us to fabricate the highly sustainable artificial nacre-like chitosan\u2013mtm bionanocomposite film with high performance to seek a promising material for the replacement of conventional petroleumbased plastics. herein, we introduce a novel approach to fabricate artificial nacre-like chitosan\u2013mtm bionanocomposite films by self-assembly of chitosan\u2013mtm hybrid building blocks (scheme 1). the chitosan molecules are very easily coated onto exfoliated mtm nanosheets to yield the hybrid building blocks by strong electrostatic and hydrogen-bonding interactions. these hybrid building blocks can be dispersed in distilled water and then aligned to a nacre-like lamellar microstructure by vacuum-filtrationor water-evaporationinduced self-assembly because of the role that the orientation of the nanosheets and linking of the chitosan play. the fabrication process is simple, fast, time-saving, and easily scaled up compared with the lbl, ice-crystal-template, and other techniques. [*] h. b. yao, z. h. tan, h. y. fang, prof. dr. s. h. yu division of nanomaterials and chemistry hefei national laboratory for physical sciences at microscale department of chemistry national synchrotron radiation laboratory university of science and technology of china hefei, anhui 230026 (p.r. china) fax: (+ 86)551-360-3040 e-mail: shyu@ustc.edu.cn homepage: http://staff.ustc.edu.cn/~ yulab/",
            "contribution_ids": [
                "R189684"
            ]
        },
        {
            "instance_id": "R199196xR189665",
            "comparison_id": "R199196",
            "paper_id": "R189665",
            "text": "Supramolecular Control of Stiffness and Strength in Lightweight High-Performance Nacre-Mimetic Paper with Fire-Shielding Properties taking the heat: hard/soft core/shell colloidal building blocks allow large-scale self-assembly to form nacre-mimetic paper. the strength and stiffness of this material can be tailored by supramolecular ionic bonds. these lightweight biomimetic materials show excellent and tunable mechanical properties and heat and fire-shielding capabilities.",
            "contribution_ids": [
                "R189667"
            ]
        },
        {
            "instance_id": "R199196xR189569",
            "comparison_id": "R199196",
            "paper_id": "R189569",
            "text": "Hierarchical Nacre Mimetics with Synergistic Mechanical Properties by Control of Molecular Interactions in Self-Healing Polymers designing the reversible interactions of biopolymers remains a grand challenge for an integral mimicry of mechanically superior biological composites. yet, they are the key to synergistic combinations of stiffness and toughness by providing sacrificial bonds with hidden length scales. to address this challenge, dynamic polymers were designed with low glass-transition temperature t(g) and bonded by quadruple hydrogen-bonding motifs, and subsequently assembled with high-aspect-ratio synthetic nanoclays to generate nacre-mimetic films. the high dynamics and self-healing of the polymers render transparent films with a near-perfectly aligned structure. varying the polymer composition allows molecular control over the mechanical properties up to very stiff and very strong films (e\u224845\\u2005gpa, \u03c3(uts)\u2248270\\u2005mpa). stable crack propagation and multiple toughening mechanisms occur in situations of balanced dynamics, enabling synergistic combinations of stiffness and toughness. excellent gas barrier properties complement the multifunctional property profile.",
            "contribution_ids": [
                "R189571"
            ]
        },
        {
            "instance_id": "R199196xR189587",
            "comparison_id": "R199196",
            "paper_id": "R189587",
            "text": "Effects on the Mechanical Properties of Nacre-Like Bio-Hybrid Membranes with Inter-Penetrating Petal Structure Based on Magadiite rigid biological systems are increasingly becoming a source of inspiration for the fabrication of the advanced functional materials due to their diverse hierarchical structures and remarkable engineering properties. as a bionic biomaterial with a clear layered structure, excellent mechanical properties, and interesting rainbow colors, nacre has become one of the most attractive models for novel artificial materials design. in this research paper, the tough and strong nacre-like bio-hybrid membranes with an interpenetrating petals structure were fabricated from chitosan (cs) and magadiite (mag) clay nanosheets through the gel-casting self-assembling method. the analyses from x-ray diffraction (xrd), scanning electron microscope (sem), and observations of water droplets on membranes indicated that the nacre-like hybrid membranes had a layered compact structure. fourier transforms infrared spectroscopy (ftir) analyses suggested that the cs molecular chains formed chemical bonds and hydrogen bonds with mag layers. the inter-penetrating petal layered structure had a good effect on the mechanical properties of a nacre-like bio-hybrid membranes and the tensile strength of the hybrid membranes could reach at 78.6 mpa. however, the transmission analyses of the results showed that the hybrid membranes still had a certain visible light transmittance. finally, the hybrid membranes possessed an intriguing efficient fire-shielding property during exposure to the flame of alcohol burner. consequently, the great biocompatibility and excellent mechanical properties of the bio-hybrid membranes with the special interpenetrating petals structure provides a great opportunity for these composites to be widely applied in biomaterial research.",
            "contribution_ids": [
                "R189590"
            ]
        },
        {
            "instance_id": "R199196xR189679",
            "comparison_id": "R199196",
            "paper_id": "R189679",
            "text": "Thermochromic Artificial Nacre Based on Montmorillonite nacre-inspired nanocomposites have attracted a great deal of attention in recent years because of their special mechanical properties and universality of the underlying principles of materials engineering. the ability to respond to external stimuli will augment the high toughness and high strength of artificial nacre-like composites and open new technological horizons for these materials. herein, we fabricated robust artificial nacre based on montmorillonite (mmt) that combines robustness with reversible thermochromism. our artificial nacre shows great potential in various fields such as aerospace and sensors and opens an avenue to fabricate artificial nacre responsive to other external stimuli in the future.",
            "contribution_ids": [
                "R189681"
            ]
        },
        {
            "instance_id": "R199196xR189661",
            "comparison_id": "R199196",
            "paper_id": "R189661",
            "text": "Large-Area, Lightweight and Thick Biomimetic Composites with Superior Material Properties via Fast, Economic, and Green Pathways although remarkable success has been achieved to mimic the mechanically excellent structure of nacre in laboratory-scale models, it remains difficult to foresee mainstream applications due to time-consuming sequential depositions or energy-intensive processes. here, we introduce a surprisingly simple and rapid methodology for large-area, lightweight, and thick nacre-mimetic films and laminates with superior material properties. nanoclay sheets with soft polymer coatings are used as ideal building blocks with intrinsic hard/soft character. they are forced to rapidly self-assemble into aligned nacre-mimetic films via paper-making, doctor-blading or simple painting, giving rise to strong and thick films with tensile modulus of 45 gpa and strength of 250 mpa, that is, partly exceeding nacre. the concepts are environmentally friendly, energy-efficient, and economic and are ready for scale-up via continuous roll-to-roll processes. excellent gas barrier properties, optical translucency, and extraordinary shape-persistent fire-resistance are demonstrated. we foresee advanced large-scale biomimetic materials, relevant for lightweight sustainable construction and energy-efficient transportation.",
            "contribution_ids": [
                "R189663"
            ]
        },
        {
            "instance_id": "R200035xR200008",
            "comparison_id": "R200035",
            "paper_id": "R200008",
            "text": "Seroprevalence of Norovirus Genogroup IV Antibodies among Humans, Italy, 2010\u00e2\u0080\u00932011 antibodies specific to genogroup iv identified in human specimens suggest zoonotic exposure.",
            "contribution_ids": [
                "R200010"
            ]
        },
        {
            "instance_id": "R200035xR199203",
            "comparison_id": "R200035",
            "paper_id": "R199203",
            "text": "Detection of serum antibodies to bovine norovirus in veterinarians and the general population in the Netherlands \"the close genetic relationship of human and animal strains of norovirus has raised the possibility of transmission of noroviruses from animals to humans and may explain the emergence of certain norovirus strains. to assess if exposure to bovine noroviruses (nov) might result in infection in humans, an enzyme immunoassay (eia) was designed and validated in order to detect antibodies against bovine norovirus. this and two other eias were used to test sera from 210 veterinarians and 630 matched population controls for igg and iga antibodies to recombinant capsid protein of bovine nov (rbov), norwalk virus (rnv), and lordsdale virus (rldv). of 840 participants, igg reactivity to rbov was found in 185 (22%), to rnv in 638 (76%) and to rldv in 760 (90%). igg reactivity to rbov was more common in veterinarians (58/210: 28%) than in controls (127/630: 20% [p\\u2009=\\u20090.03]). iga reactivity to rbov was similar in both veterinarians and controls. cross\u2010reactivity of iga and igg antibodies to rbov and rnv was seen, but 26% of all specimens positive rbov antibodies showed high igg reactivity to rbov but low reactivity to rnv, suggesting a specific response to bovine antigen. no evidence of overall cross\u2010reactivity of antibodies to rbov and rldv was seen. among veterinarians, youth spent on farm (odds ratio [or]\\u2009=\\u20091.8) and membership of the bovine practitioners' society (or\\u2009=\\u20092.7) were significantly associated with igg seroreactivity to rbov. these data indicate that bovine strains of nov may infect humans though less frequently than human strains. j. med. virol. 76:119\u2013128, 2005. \u00a9 2005 wiley\u2010liss, inc.\"",
            "contribution_ids": [
                "R199205",
                "R199206",
                "R199208",
                "R199209"
            ]
        },
        {
            "instance_id": "R200035xR199199",
            "comparison_id": "R200035",
            "paper_id": "R199199",
            "text": "Human antibody responses to bovine (Newbury-2) norovirus (GIII.2) and association to histo-blood group antigens serum antibodies to bovine norovirus have been found recently in about 22% of humans. whether this prevalence reflects limited virulence properties of the virus or that inherited host factors provide protection against bovine norovirus infection in humans remains to be established. to investigate whether histo\u2010blood group antigens correlate with the presence of bovine norovirus (giii.2) antibody, plasma (n\\u2009=\\u2009105) from swedish blood donors, genotyped and phenotyped for secretor, lewis and abo, were tested and compared for the frequency of igg antibody and antibody titer to bo/newbury2/76/uk. in total, 26.7% (28/105) of swedish blood donors were antibody\u2010positive. two non\u2010secretors (2/21, 9.5%) were antibody\u2010positive compared with 26/84 (31%) secretors (p\\u2009=\\u20090.047). while no statistically significant correlation was found between the frequency of antibodies to bovine norovirus and different abo blood groups, individuals with blood type b presented the highest frequency of antibodies (37.5%) compared with 0\u201330% among other blood groups. individuals with le(a\u2212b+) had not only higher frequency of antibodies (31.3%) compared with le(a+b\u2212) (11%) (p\\u2009=\\u20090.068) but also higher antibody titer (p\\u2009=\\u20090.085) although this was not significant statistically. no detectable cross\u2010reaction between bovine giii.2 and human gii.3 nov vlp was found with human and animal sera. the results of this study suggest that bovine norovirus infections occur in sweden and that secretor status but not abo blood groups is a possible risk factor for infection. j. med. virol. 82: 1241\u20131246, 2010. \u00a9 2010 wiley\u2010liss, inc.",
            "contribution_ids": [
                "R199201"
            ]
        },
        {
            "instance_id": "R201263xR189415",
            "comparison_id": "R201263",
            "paper_id": "R189415",
            "text": "Byssal threads inspired ionic cross-linked narce-like graphene oxide paper with superior mechanical strength \"artificial nacre-like graphene oxide paper has sparked great excitement in the scientific community for its unique properties. the preparation of a bioinspired high-strength nanocomposite paper via a simple vacuum-assisted assembly technique from graphene oxide (go), tannic acid (ta) and fe3+ ions is reported in this article. the fabricated papers were characterized by x-ray diffraction (xrd), scanning electron microscopy (sem), thermogravimetric analysis (tga), fourier transformed infrared (ftir) spectroscopy, x-ray photoelectron spectroscopy (xps) and dynamic mechanical analysis (dma). we show that fe3+ ions only induce limited improvement in the mechanical properties of the graphene oxide paper, while the efficient cross-linking of neighboring sheets by fe3+\u2013ta complex network can significantly improve the fracture strength and young's modulus of graphene oxide paper by 150% and 521%, respectively, with an optimal content of 5.7 wt% fe3+. with general surface binding affinity, ta molecules can be adsorbed to go sheets and provide binding sites for fe3+. the fe3+\u2013ta coordinated compound serves as the \u201cmortar\u201d to stick the go \u201cbricks\u201d together. the mechanical properties of our paper can be simply varied by controlling the cross-linking condition. the obtained nacre-like ultrastrong go papers could find potential in energy and sustainability applications.\"",
            "contribution_ids": [
                "R189417"
            ]
        },
        {
            "instance_id": "R201263xR189429",
            "comparison_id": "R201263",
            "paper_id": "R189429",
            "text": "The Effect of Interlayer Adhesion on the Mechanical Behaviors of Macroscopic Graphene Oxide Papers \"high mechanical performances of macroscopic graphene oxide (go) papers are attracting great interest owing to their merits of lightweight and multiple functionalities. however, the loading role of individual nanosheets and its effect on the mechanical properties of the macroscopic go papers are not yet well understood. herein, we effectively tailored the interlayer adhesions of the go papers by introducing small molecules, that is, glutaraldehyde (ga) and water molecules, into the gallery regions. with the help of in situ raman spectroscopy, we compared the varied load-reinforcing roles of nanosheets, and further predicted the young's moduli of the go papers. systematic mechanical tests have proven that the enhancement of the tensile modulus and strength of the ga-treated go paper arose from the improved load-bearing capability of the nanosheets. on the basis of raman and macroscopic mechanical tests, the influences of interlayer adhesions on the fracture mechanisms of the strained go papers were inferred.\"",
            "contribution_ids": [
                "R189431"
            ]
        },
        {
            "instance_id": "R201263xR201158",
            "comparison_id": "R201263",
            "paper_id": "R201158",
            "text": "Realizing Ultrahigh Modulus and High Strength of Macroscopic Graphene Oxide Papers Through Crosslinking of Mussel-Inspired Polymers covalently crosslinked graphene oxide papers (gops) with enhanced mechanical properties are prepared by a strategy involving crosslinking by means of intercalated polymers. the strength and modulus of the crosslinked gops increase by 115% and 550%, respectively, compared to the pristine gops. these results broaden the potential applications of graphene, and the crosslinking strategy will open the door to the assembly of other nanometer-scale materials.",
            "contribution_ids": [
                "R201159"
            ]
        },
        {
            "instance_id": "R201263xR189421",
            "comparison_id": "R201263",
            "paper_id": "R189421",
            "text": "Bio-Inspired Borate Cross-Linking in Ultra-Stiff Graphene Oxide Thin Films adjacent graphene oxide nanosheets in a thin-film structure have been covalently cross-linked in a fashion similar to the cell walls of higher-order plants. the resulting ultra-stiff structure exhibits a maximum storage modulus of 127 gpa that can be tuned by varying borate concentration.",
            "contribution_ids": [
                "R189422"
            ]
        },
        {
            "instance_id": "R201263xR189426",
            "comparison_id": "R201263",
            "paper_id": "R189426",
            "text": "High-Nanofiller-Content Graphene Oxide-Polymer Nanocomposites via Vacuum-Assisted Self-Assembly highly ordered, homogeneous polymer nanocomposites of layered graphene oxide are prepared using a vacuum\u2010assisted self\u2010assembly (vasa) technique. in vasa, all components (nanofiller and polymer) are pre\u2010mixed prior to assembly under a flow, making it compatible with either hydrophilic poly(vinyl alcohol) (pva) or hydrophobic poly(methyl methacrylate) (pmma) for the preparation of composites with over 50 wt% filler. this process is complimentary to layer\u2010by\u2010layer assembly, where the assembling components are required to interact strongly (e.g., via coulombic attraction). the nanosheets within the vasa\u2010assembled composites exhibit a high degree of order with tunable intersheet spacing, depending on the polymer content. graphene oxide\u2013pva nanocomposites, prepared from water, exhibit greatly improved modulus values in comparison to films of either pure pva or pure graphene oxide. modulus values for graphene oxide\u2013pmma nanocomposites, prepared from dimethylformamide, are intermediate to those of the pure components. the differences in structure, modulus, and strength can be attributed to the gallery composition, specifically the hydrogen bonding ability of the intercalating species",
            "contribution_ids": [
                "R189428"
            ]
        },
        {
            "instance_id": "R201802xR189600",
            "comparison_id": "R201802",
            "paper_id": "R189600",
            "text": "Intrusion detection system based on the analysis of time intervals of CAN messages for in-vehicle network controller area network (can) bus in the vehicles is a de facto standard for serial communication to provide an efficient, reliable and economical link between electronic control units (ecu). however, can bus does not have enough security features to protect itself from inside or outside attacks. intrusion detection system (ids) is one of the best ways to enhance the vehicle security level. unlike the traditional ids for network security, ids for vehicle requires light-weight detection algorithm because of the limitations of the computing power of electronic devices reside in cars. in this paper, we propose a light-weight intrusion detection algorithm for in-vehicle network based on the analysis of time intervals of can messages. we captured can messages from the cars made by a famous manufacturer and performed three kinds of message injection attacks. as a result, we find the time interval is a meaningful feature to detect attacks in the can traffic. also, our intrusion detection system detects all of message injection attacks without making false positive errors.",
            "contribution_ids": [
                "R189602"
            ]
        },
        {
            "instance_id": "R201802xR189549",
            "comparison_id": "R201802",
            "paper_id": "R189549",
            "text": "Frequency-based anomaly detection for the automotive CAN bus the modern automobile is controlled by networked computers. the security of these networks was historically of little concern, but researchers have in recent years demonstrated their many vulnerabilities to attack. as part of a defence against these attacks, we evaluate an anomaly detector for the automotive controller area network (can) bus. the majority of attacks are based on inserting extra packets onto the network. but most normal packets arrive at a strict frequency. this motivates an anomaly detector that compares current and historical packet timing. we present an algorithm that measures inter-packet timing over a sliding window. the average times are compared to historical averages to yield an anomaly signal. we evaluate this approach over a range of insertion frequencies and demonstrate the limits of its effectiveness. we also show how a similar measure of the data contents of packets is not effective for identifying anomalies. finally we show how a one-class support vector machine can use the same information to detect anomalies with high confidence.",
            "contribution_ids": [
                "R189551"
            ]
        },
        {
            "instance_id": "R201802xR189537",
            "comparison_id": "R201802",
            "paper_id": "R189537",
            "text": "Fingerprinting Electronic Control Units for Vehicle Intrusion Detection \"as more software modules and external interfaces are getting added on vehicles, new attacks and vulnerabilities are emerging. researchers have demonstrated how to compromise in-vehicle electronic control units (ecus) and control the vehicle maneuver. to counter these vulnerabilities, various types of defense mechanisms have been proposed, but they have not been able to meet the need of strong protection for safety-critical ecus against in-vehicle network attacks. to mitigate this deficiency, we propose an anomaly-based intrusion detection system (ids), called clock-based ids (cids). it measures and then exploits the intervals of periodic in-vehicle messages for fingerprinting ecus. the thus-derived fingerprints are then used for constructing a baseline of ecus' clock behaviors with the recursive least squares (rls) algorithm. based on this baseline, cids uses cumulative sum (cusum) to detect any abnormal shifts in the identification errors - a clear sign of intrusion. this allows quick identification of in-vehicle network intrusions with a low false-positive rate of 0.055%. unlike state-of-the-art idss, if an attack is detected, cids's fingerprinting of ecus also facilitates a rootcause analysis; identifying which ecu mounted the attack. our experiments on a can bus prototype and on real vehicles have shown cids to be able to detect a wide range of in-vehicle network attacks.\"",
            "contribution_ids": [
                "R189539"
            ]
        },
        {
            "instance_id": "R201802xR189543",
            "comparison_id": "R201802",
            "paper_id": "R189543",
            "text": "Viden: Attacker Identification on In-Vehicle Networks \"various defense schemes --- which determine the presence of an attack on the in-vehicle network --- have recently been proposed. however, they fail to identify which electronic control unit (ecu) actually mounted the attack. clearly, pinpointing the attacker ecu is essential for fast/efficient forensic, isolation, security patch, etc. to meet this need, we propose a novel scheme, called viden (voltage-based attacker identification), which can identify the attacker ecu by measuring and utilizing voltages on the in-vehicle network. the first phase of viden, called ack learning, determines whether or not the measured voltage signals really originate from the genuine message transmitter. viden then exploits the voltage measurements to construct and update the transmitter ecus' voltage profiles as their fingerprints. it finally uses the voltage profiles to identify the attacker ecu. since viden adapts its profiles to changes inside/outside of the vehicle, it can pinpoint the attacker ecu under various conditions. moreover, its efficiency and design-compliance with modern in-vehicle network implementations make viden practical and easily deployable. our extensive experimental evaluations on both a can bus prototype and two real vehicles have shown that viden can accurately fingerprint ecus based solely on voltage measurements and thus identify the attacker ecu with a low false identification rate of 0.2%.\"",
            "contribution_ids": [
                "R189545"
            ]
        },
        {
            "instance_id": "R201802xR178407",
            "comparison_id": "R201802",
            "paper_id": "R178407",
            "text": "WINDS: A Wavelet-Based Intrusion Detection System for Controller Area Network (CAN) vehicles are equipped with electronic control units (ecus) to increase their overall system functionality and connectivity. however, the rising connectivity exposes a defenseless internal controller area network (can) to cyberattacks. an intrusion detection system (ids) is a supervisory module, proposed for identifying can network malicious messages, without modifying legacy ecus and causing high traffic overhead. the traditional ids approaches rely on time and frequency thresholding, leading to high false alarm rates, whereas state-of-the-art solutions may suffer from vehicle dependency. this paper presents a wavelet-based approach to locating the behavior change in the can traffic by analyzing the can network\u2019s transmission pattern. the proposed wavelet-based intrusion detection system (winds) is tested on various attack scenarios, using real vehicle traffic from two independent research centers, while being expanded toward more comprehensive attack scenarios using synthetic attacks. the technique is evaluated and compared against the state-of-the-art solutions and the baseline frequency method. experimental results show that winds offers a vehicle-independent solution applicable for various vehicles through a unique approach while generating low false alarms.",
            "contribution_ids": [
                "R178411",
                "R190003"
            ]
        },
        {
            "instance_id": "R201802xR189613",
            "comparison_id": "R201802",
            "paper_id": "R189613",
            "text": "Behavior Analysis for Safety and Security in Automotive Systems the connection of automotive systems with other systems such as road-side units, other vehicles, and various servers in the internet opens up new ways for attackers to remotely access safety relevant subsystems within connected cars. the security of connected cars and the whole vehicular ecosystem is thus of utmost importance for consumer trust and acceptance of this emerging technology. this paper describes an approach for on-board detection of unanticipated sequences of events in order to identify suspicious activities. the results show that this approach is fast enough for in-vehicle application at runtime. several behavior models and synchronization strategies are analyzed in order to narrow down suspicious sequences of events to be sent in a privacy respecting way to a global security operations center for further in-depth analysis.",
            "contribution_ids": [
                "R189615"
            ]
        },
        {
            "instance_id": "R201802xR189607",
            "comparison_id": "R201802",
            "paper_id": "R189607",
            "text": "Sliding Window Optimized Information Entropy Analysis Method for Intrusion Detection on In-Vehicle Networks with the considerable growth of cybersecurity risks in modern automobiles, cybersecurity issues in the in-vehicle network environment have attracted significant attention from security researchers in recent years. enhancing the cybersecurity ability of in-vehicle networks while considering the computing resource and cost constraints become an urgent issue. to address this problem, a novel information entropy-based method is proposed in this paper, which uses a fixed number of messages as sliding windows. by improving the sliding window strategy and optimizing the decision conditions, the detection accuracy is increased and the false positive rate is reduced. experimental results demonstrate that the proposed method can provide real-time response to attacks with a considerably improved detection precision for intrusion detection in the in-vehicle network environment.",
            "contribution_ids": [
                "R189611"
            ]
        },
        {
            "instance_id": "R201972xR201903",
            "comparison_id": "R201972",
            "paper_id": "R201903",
            "text": "A novel 7 degrees of freedom model for upper limb kinematic reconstruction based on wearable sensors wearable motion tracking systems have gained large popularity in the last decades because of their effectiveness in many fields, from performance assessment to human-robot interaction. among all the approaches, those based on inertial sensors have been widely explored. since inertial sensors are affected by measurements drift, they need to be aided by other sensors, thus requiring sensor measurements to be fused. the most used sensor fusion techniques are based on kalman filter. in particular, the extended kalman filter (ekf) and the unscented kalman filter (ukf) are used because of the non linearity characterizing most of the models. they often aim at reconstructing human motion by estimating limbs orientation, involving human's kinematics to constrain relative motion of the limbs. these models often neglect part of the degrees of freedom (dofs) that characterize human upper limbs, especially when modeling humerus motion with respect to the chest. in this paper we present a novel 7 dofs model which represents a trade-off between modeling accuracy and complexity for the human upper limb. in particular, we model the human shoulder girdle taking into account also the humerus head's elevation and the retraction due to the scapula's and the clavicle's motions. the model exploits inertial sensors measurements by means of an unscented kalman filter to reconstruct human movements. the system performance is validated firstly against a reconstruction based on an optical tracking system. secondly, the 5 dofs model extracted form the 7 dofs one was checked to have state of the art performance and used to estimate the improvement of position estimation that are obtained by extending the model to 7 dofs.",
            "contribution_ids": [
                "R201905"
            ]
        },
        {
            "instance_id": "R201972xR201894",
            "comparison_id": "R201972",
            "paper_id": "R201894",
            "text": "A novel approach to motion tracking with wearable sensors based on Probabilistic Graphical Models wearable motion tracking systems represent a breakthrough in ecological motion tracking. their effectiveness has been proved in many fields, from performance assessment to human-robot interaction. most of the approaches are based on the exploitation of optimal probabilistic filtering of inertial motion units (imus) signals, ranging from linear kalman filters (kf) to particle filters (pf). since most of the models are highly nonlinear, filters such as extended kalman filter (ekf) and unscented kalman filter (ukf) are typically used. these approaches cause all the variables of the models to be correlated each other. probabilistic graphical models (pgm) are a framework for probabilistic reasoning that allows to explicitly declare the actual dependencies among variables. in this paper we propose a novel algorithm for motion tracking with imus based on pgm. the model is compared to the state of the art ukf algorithm in tracking the human upper limb. the results show that the proposed approach perform a slightly better compared to the ukf.",
            "contribution_ids": [
                "R201896"
            ]
        },
        {
            "instance_id": "R201972xR201918",
            "comparison_id": "R201972",
            "paper_id": "R201918",
            "text": "Adaptive Information Fusion for Human Upper Limb Movement Estimation accurate human movement estimation techniques are widely used in various applications, such as robotics, human-machine interaction, sports, and rehabilitation. with rapid advances in microsensors, human movement estimation using wearable micro inertial sensors has become an active research topic. the main challenges for the wearable sensor motion estimation are the inertial sensor drift problem and the linear acceleration interference problem. because of the agility in movement, upper limb motion estimation has been regarded as the most difficult problem in human motion estimation. in this paper, we take the upper limb as our research subject and present a novel upper limb movement estimation algorithm to cope with these two challenges by adaptive fusion of sensor data and human skeleton constraint. in the sensor fusion part, a quaternion-based unscented kalman filter is invoked to fuse the gyroscope, accelerometer, and magnetometer measurement information. in the kalman filter framework, an acceleration interference detection scheme is implemented based on the exponentially discounted average of the normalized innovation squared (nis). according to the detection results, the process and measurement noise levels are scaled up or down automatically. to further compensate for the drift, we present a novel solution by modeling geometrical constraint in the elbow joint and fuse the constraint to revise the sensor fusion results and improve the estimation accuracy. the experimental results have shown that the proposed algorithm can provide accurate results in comparison to the bts smart-d optical motion tracker.",
            "contribution_ids": [
                "R201920"
            ]
        },
        {
            "instance_id": "R201972xR201927",
            "comparison_id": "R201972",
            "paper_id": "R201927",
            "text": "ETHOS: Miniature orientation sensor for wearable human motion analysis inertial and magnetic sensors offers a sourceless and mobile option to obtain body posture and motion for personal sports or healthcare assistants, if sensors could be unobtrusively integrated in casual garments and accessories. we present in this paper design, implementation, and evaluation results for a novel miniature attitude and heading reference system (ahrs) named ethos using current off-the-shelf technologies. ethos has a unit size of 2.5cm3, which is substantially below most currently marketed attitude heading reference systems, while the unit contains processing resources to estimate its orientation online. results on power consumption in relation to sampling frequency and sensor use are presented. moreover two sensor fusion algorithms to estimate orientation: a quaternion-based kalman-, and a complementary filter. evaluations of orientation estimation accuracy in static and dynamic conditions revealed that complementary filtering reached sufficient accuracy while consuming 46% of a kalman's power. the system runtime of ethos was found to be 10 hours at a complementary filter update rate of 128hz. furthermore, we found that a ethos prototype functioned with a sufficient accuracy in estimating human movement in real-life conditions using an arm rehabilitation robot.",
            "contribution_ids": [
                "R201929"
            ]
        },
        {
            "instance_id": "R201972xR201915",
            "comparison_id": "R201972",
            "paper_id": "R201915",
            "text": "Shoulder and Elbow Joint Angle Tracking With Inertial Sensors wearable inertial systems have recently been used to track human movement in and outside of the laboratory. continuous monitoring of human movement can provide valuable information relevant to individuals\u2019 level of physical activity and functional ability. traditionally, orientation has been calculated by integrating the angular velocity from gyroscopes. however, a small drift in the measured velocity leads to increasing integration error over time. to compensate that drift, complementary data from accelerometers are normally fused into tracking systems using the kalman or extended kalman filter. in this study, we combine kinematic models designed for control of robotic arms with state-space methods to continuously estimate the angles of human shoulder and elbow using two wearable inertial measurement units. we use the unscented kalman filter to implement the nonlinear state-space inertial tracker. shoulder and elbow joint angles obtained from 8 subjects using our inertial tracker were compared to the angles obtained from an optical-tracking reference system. on average, there was an rms angle error of less than 8 $^\\circ$ for all shoulder and elbow angles. the average correlation coefficient for all movement tasks among all subjects was $r\\ge \\hbox{0.95}$ . this agreement between our inertial tracker and the optical reference system was obtained for both regular and fast-speed movement of the arm. the same method can be used to track movement of other joints.",
            "contribution_ids": [
                "R201917"
            ]
        },
        {
            "instance_id": "R201972xR201930",
            "comparison_id": "R201972",
            "paper_id": "R201930",
            "text": "Unrestrained Measurement of Arm Motion Based on a Wearable Wireless Sensor Network techniques that could precisely monitor human motion are useful in applications such as rehabilitation, virtual reality, sports science, and surveillance. most of the existing systems require wiring that restrains the natural movement. to overcome this limitation, a wearable wireless sensor network using accelerometers has been developed in this paper to determine the arm motion in the sagittal plane. the system provides unrestrained movements and improves its usability. the lightweight and compact size of the developed sensor node makes its attachment to the limb easy. experimental results have shown that the system has good accuracy and response rate when compared with a goniometer.",
            "contribution_ids": [
                "R201932"
            ]
        },
        {
            "instance_id": "R201972xR201924",
            "comparison_id": "R201972",
            "paper_id": "R201924",
            "text": "A calibration process for tracking upper limb motion with inertial sensors real-time inertial tracking of human motion requires to attach inertial sensors to the major segments of a human body. due to the intrinsic noises and drifts of the sensor data, as well as the non-rigidity of the human muscles and skins, the tracking could be unprecise, especially as time elapses. therefore, an elaborate calibration process and a noise-insensitive tracking algorithm are needed. this paper presents an extended kalman filter-based method for calibrating the relative orientation between human upper limb bones and the sensors attached to them. the calibration result, represented as a rotation matrix, is then used in the tracking of the arm motion with the knowledge of the physical segment kinematic model. several experiments have been performed to validate the effectiveness of our method.",
            "contribution_ids": [
                "R201926"
            ]
        },
        {
            "instance_id": "R201972xR201897",
            "comparison_id": "R201972",
            "paper_id": "R201897",
            "text": "Miniature Low-Power Inertial Sensors: Promising Technology for Implantable Motion Capture Systems inertial and magnetic sensors are valuable for untethered, self-contained human movement analysis. very recently, complete integration of inertial sensors, magnetic sensors, and processing into single packages, has resulted in miniature, low power devices that could feasibly be employed in an implantable motion capture system. we developed a wearable sensor system based on a commercially available system-in-package inertial and magnetic sensor. we characterized the accuracy of the system in measuring 3-d orientation-with and without magnetometer-based heading compensation-relative to a research grade optical motion capture system. the root mean square error was less than 4 \u00b0 in dynamic and static conditions about all axes. using four sensors, recording from seven degrees-of-freedom of the upper limb (shoulder, elbow, wrist) was demonstrated in one subject during reaching motions. very high correlation and low error was found across all joints relative to the optical motion capture system. findings were similar to previous publications using inertial sensors, but at a fraction of the power consumption and size of the sensors. such ultra-small, low power sensors provide exciting new avenues for movement monitoring for various movement disorders, movement-based command interfaces for assistive devices, and implementation of kinematic feedback systems for assistive interventions like functional electrical stimulation.",
            "contribution_ids": [
                "R201899"
            ]
        },
        {
            "instance_id": "R201972xR201891",
            "comparison_id": "R201972",
            "paper_id": "R201891",
            "text": "Estimating Orientation Using Magnetic and Inertial Sensors and Different Sensor Fusion Approaches: Accuracy Assessment in Manual and Locomotion Tasks magnetic and inertial measurement units are an emerging technology to obtain 3d orientation of body segments in human movement analysis. in this respect, sensor fusion is used to limit the drift errors resulting from the gyroscope data integration by exploiting accelerometer and magnetic aiding sensors. the present study aims at investigating the effectiveness of sensor fusion methods under different experimental conditions. manual and locomotion tasks, differing in time duration, measurement volume, presence/absence of static phases, and out-of-plane movements, were performed by six subjects, and recorded by one unit located on the forearm or the lower trunk, respectively. two sensor fusion methods, representative of the stochastic (extended kalman filter) and complementary (non-linear observer) filtering, were selected, and their accuracy was assessed in terms of attitude (pitch and roll angles) and heading (yaw angle) errors using stereophotogrammetric data as a reference. the sensor fusion approaches provided significantly more accurate results than gyroscope data integration. accuracy improved mostly for heading and when the movement exhibited stationary phases, evenly distributed 3d rotations, it occurred in a small volume, and its duration was greater than approximately 20 s. these results were independent from the specific sensor fusion method used. practice guidelines for improving the outcome accuracy are provided.",
            "contribution_ids": [
                "R201893"
            ]
        },
        {
            "instance_id": "R201972xR201912",
            "comparison_id": "R201972",
            "paper_id": "R201912",
            "text": "Evaluation of Inertial Sensor Fusion Algorithms in Grasping Tasks Using Real Input Data: Comparison of Computational Costs and Root Mean Square Error sensor fusion is an important computation step for acquiring reliable orientation information from inertial sensors. these sensors are very attractive in order to achieve a mobile capturing of human movements, which is desired for application in sports or rehabilitation. commercial inertial sensors with small form factors and low power consumption can be used for capturing without any interference. there are several common techniques for calculating orientation data based on raw sensor data. this paper gives an overview of the computational effort and achievable accuracy of integration algorithms, vector observation algorithms and kalman filter algorithms for inertial sensor fusion. the sensor data were compared against an optical motion capturing system. the considered application is the capturing of arm movements during grasping tasks in stroke rehabilitation. therefore, the algorithms are evaluated based on corresponding real world input data. the provided benchmark compares the sensor fusion algorithms in terms of computational cost and orientation estimation error.",
            "contribution_ids": [
                "R201914"
            ]
        },
        {
            "instance_id": "R201972xR201906",
            "comparison_id": "R201972",
            "paper_id": "R201906",
            "text": "Improved extended Kalman fusion method for upper limb motion estimation with inertial sensors with the rapid development of microsensors, the real-time, low-cost human motion tracking system using inertial sensors has become more and more popular. because of the complicated indoor electromagnetic environment, magnetic disturbance has become one of the most challenging issues. this paper presents a portable real-time limb motion capture system based on extended kalman filter. in this system, a non-linear two step algorithm is used to calibrate the magnetometer. and an adaptive mechanism for weighting the measurements is introduced in the ekf to reduce the impact of the body motion and temporary magnetic disturbances. simulation and experimental results have shown that the proposed algorithm obtains good performance in magnetically disturbed environment.",
            "contribution_ids": [
                "R201908"
            ]
        },
        {
            "instance_id": "R202077xR202043",
            "comparison_id": "R202077",
            "paper_id": "R202043",
            "text": "A Comparative Assessment of Geostatistical, Machine Learning, and Hybrid Approaches for Mapping Topsoil Organic Carbon Content accurate digital soil mapping (dsm) of soil organic carbon (soc) is still a challenging subject because of its spatial variability and dependency. this study is aimed at comparing six typical methods in three types of dsm techniques for soc mapping in an area surrounding changchun in northeast china. the methods include ordinary kriging (ok) and geographically weighted regression (gwr) from geostatistics, support vector machines for regression (svr) and artificial neural networks (ann) from machine learning, and geographically weighted regression kriging (gwrk) and artificial neural networks kriging (annk) from hybrid approaches. the hybrid approaches, in particular, integrated the gwr from geostatistics and ann from machine learning with the estimation of residuals by ordinary kriging, respectively. environmental variables, including soil properties, climatic, topographic, and remote sensing data, were used for modeling. the mapping results of soc content from different models were validated by independent testing data based on values of the mean error, root mean squared error and coefficient of determination. the prediction maps depicted spatial variation and patterns of soc content of the study area. the results showed the accuracy ranking of the compared methods in decreasing order was annk, svr, ann, gwrk, ok, and gwr. two-step hybrid approaches performed better than the corresponding individual models, and non-linear models performed better than the linear models. when considering the uncertainty and efficiency, ml and two-step approach are more suitable than geostatistics in regional landscapes with the high heterogeneity. the study concludes that annk is a promising approach for mapping soc content at a local scale.",
            "contribution_ids": [
                "R202046"
            ]
        },
        {
            "instance_id": "R202077xR201848",
            "comparison_id": "R202077",
            "paper_id": "R201848",
            "text": "Geospatial modeling approaches for mapping topsoil organic  carbon stock in northern part of Mongolia soil organic carbon (soc) is one of the most important indicators of soil quality and agricultural productivity. this paper presents the application of regression kriging (rk), geographically weighted regression (gwr) and geographically weighted regression kriging (gwrk) for prediction of topsoil organic carbon stock in tarialan. a total of 25 topsoil (0-30 cm) samples were collected from tarialan soum of khuvsgul aimag in mongolia. in this study, seven independent variables were used including normalised difference vegetation index (ndvi), soil adjusted vegetation index (savi), normalised difference moisture index (ndmi), land surface temperature (lst) and terrain factors (dem, slope, aspect). we used root-mean-square error (rmse), mean error (me) and determination coefficient (r2) to evaluate the performance of these methods. validation results showed that performance of the gwrk, gwr, and rk approaches were good with not only low values of root-mean-square error (1.38 kg/m2, 1.48 kg/m2, 0.69 kg/m2), mean error (0.28 kg/m2, -0.22 kg/m2, 0.17 kg/m2) but also high values of r2 (0.76, 0.72, 0.94). the estimated soc stock values ranged from 0.28-16.26 kg/m2, 0.72\u201315.24 kg/m2, 0.16\u201315.83 kg/m2 using gwrk, gwr, rk approaches in the study area. the highest average soc stock value was in the wetland (6.47 kg/m2, 6.08 kg/m2, 6.44 kg/m2) and the lowest was in cropland (1.63 kg/m2, 1.48 kg/m2, 1.80 kg/m2) using these approaches. according to the validation, gwrk, gwr, and rk approaches produced satisfactory results for estimating and mapping soc stock. however, regression kriging was the best model, followed by gwrk and gwr to predict topsoil organic carbon stock in tarialan.",
            "contribution_ids": [
                "R201852"
            ]
        },
        {
            "instance_id": "R202077xR201980",
            "comparison_id": "R202077",
            "paper_id": "R201980",
            "text": "Ancillary information improves kriging on soil organic carbon data for a typical karst peak cluster depression landscape: Ancillary information improves kriging on soil organic carbon data background soil carbon management at landscape scale requires reliable information on the spatial distribution of soil organic carbon (soc). however, how to improve the accuracy of spatial prediction is not well addressed in the karst region of southwestern china. this study evaluates the performance of univariate kriging (ordinary kriging (ok)) and hybrid kriging (co-kriging (ck), regression kriging (rk) and residual maximum likelihood (reml)) in mapping the spatial distribution of soc at a depth of 0-15 cm. terrain attributes and the normalised difference vegetation index (ndvi) were used as ancillary variables. results the distribution of soc was significantly related to ndvi and terrain attributes. furthermore, geostatistical analyses reflected a moderately structured spatial correlation of soc. regression analyses identified the ndvi and slope as the best predictors for describing the spatial pattern of soc. combined with ndvi and slope gradient, reml and rk performed better in increasing map prediction accuracy and decreasing the soothing effect of kriging. conclusion the spatial pattern of soc was controlled by topography and cultivation activity. the predictive abilities of ok and ck were limited. combined with the auxiliary variables, reml and rk can improve the prediction accuracy. this study is beneficial for the further research of precise soc management in the typical karst landscape.",
            "contribution_ids": [
                "R201982"
            ]
        },
        {
            "instance_id": "R202360xR202278",
            "comparison_id": "R202360",
            "paper_id": "R202278",
            "text": "A Study on CP-ABE-Based Medical Data Sharing System with Key Abuse Prevention and Verifiable Outsourcing in the IoMT Environment recent developments in cloud computing allow data to be securely shared between users. this can be used to improve the quality of life of patients and medical staff in the internet of medical things (iomt) environment. however, in the iomt cloud environment, there are various security threats to the patient\u2019s medical data. as a result, security features such as encryption of collected data and access control by legitimate users are essential. many studies have been conducted on access control techniques using ciphertext-policy attribute-based encryption (cp-abe), a form of attribute-based encryption, among various security technologies and studies are underway to apply them to the medical field. however, several problems persist. first, as the secret key does not identify the user, the user may maliciously distribute the secret key and such users cannot be tracked. second, attribute-based encryption (abe) increases the size of the ciphertext depending on the number of attributes specified. this wastes cloud storage, and computational times are high when users decrypt. such users must employ outsourcing servers. third, a verification process is needed to prove that the results computed on the outsourcing server are properly computed. this paper focuses on the iomt environment for a study of a cp-abe-based medical data sharing system with key abuse prevention and verifiable outsourcing in a cloud environment. the proposed scheme can protect the privacy of user data stored in a cloud environment in the iomt field, and if there is a problem with the secret key delegated by the user, it can trace a user who first delegated the key. this can prevent the key abuse problem. in addition, this scheme reduces the user\u2019s burden when decoding ciphertext and calculates accurate results through a server that supports constant-sized ciphertext output and verifiable outsourcing technology. the goal of this paper is to propose a system that enables patients and medical staff to share medical data safely and efficiently in an iomt environment.",
            "contribution_ids": [
                "R202279"
            ]
        },
        {
            "instance_id": "R202360xR202302",
            "comparison_id": "R202360",
            "paper_id": "R202302",
            "text": "A Secure Three-Factor User Authentication Protocol With Forward Secrecy for Wireless Medical Sensor Network Systems the internet of things (iot) enables all objects to connect to the internet and exchange data via different emerging technologies, which makes the intelligent identification and management a reality. wireless sensor networks (wsns), as a crucial basis of iot, have been applied in many fields like smart health care and smart transportation. with the development of wsns, data security has attracted more and more attention, and user authentication is a popular mechanism to ensure the information security of wsns. recently, many authentication mechanisms for wireless medical sensor networks (wmsns) have been proposed, but most of the protocols cannot achieve the features of local password change and forward secrecy while resisting stolen smart card attack. to enhance the security based on previous work, an ecc-based secure three-factor authentication protocol with forward secrecy for wmsn is proposed in this paper. it utilizes a fuzzy commitment scheme to handle the biometric information. meanwhile, fuzzy verifier and honey_list techniques are used to solve the contradiction of local password verification and mobile device lost attack. the security of our protocol is evaluated by provable security, proverif tool, and information analysis. besides, the comparisons with the relevant protocols are given, and the results indicate that our protocol is robust and secure for wmsn systems.",
            "contribution_ids": [
                "R202309"
            ]
        },
        {
            "instance_id": "R202360xR202286",
            "comparison_id": "R202360",
            "paper_id": "R202286",
            "text": "Achieving Searchable and Privacy-Preserving Data Sharing for Cloud-Assisted E-Healthcare System the integration of wearable wireless devices and cloud computing in e-health systems has significantly improved their effectiveness and availability. patients can upload their personal health information (phi) files to the cloud, from where the health service providers (hsps) can obtain appropriate information to determine the health state. this system not only reduces the costs associated to healthcare but also provides timely diagnosis to save lives. however, a number of privacy concerns arise while sharing sensitive information. in this paper, we propose a novel privacy-preserving patient health information sharing scheme, which allows hsps to access and search phi files in a secure yet efficient manner. we make use of the searchable encryption technique with keyword range search and multikeyword search. the proposed privacy-preserving equality test protocol allows different types of numeric comparison searches on encrypted data. we also use a variant of bloom filter and message authentication code to classify phi files, filter false data, and check integrity of search results. the simulations on real-world and synthetic data show the feasibility and efficiency of the system, and security analysis proves the privacy-preservation properties.",
            "contribution_ids": [
                "R202292"
            ]
        },
        {
            "instance_id": "R202360xR202334",
            "comparison_id": "R202360",
            "paper_id": "R202334",
            "text": "DeepEDN: A Deep-Learning-Based Image Encryption and Decryption Network for Internet of Medical Things internet of medical things (iomt) can connect many medical imaging equipment to the medical information network to facilitate the process of diagnosing and treating doctors. as medical image contains sensitive information, it is of importance yet very challenging to safeguard the privacy or security of the patient. in this work, a deep-learning-based image encryption and decryption network (deepedn) is proposed to fulfill the process of encrypting and decrypting the medical image. specifically, in deepedn, the cycle-generative adversarial network (cycle-gan) is employed as the main learning network to transfer the medical image from its original domain into the target domain. the target domain is regarded as \u201chidden factors\u201d to guide the learning model for realizing the encryption. the encrypted image is restored to the original (plaintext) image through a reconstruction network to achieve image decryption. in order to facilitate the data mining directly from the privacy-protected environment, a region of interest (roi)-mining network is proposed to extract the interesting object from the encrypted image. the proposed deepedn is evaluated on the chest x-ray data set. extensive experimental results and security analysis show that the proposed method can achieve a high level of security with a good performance in efficiency.",
            "contribution_ids": [
                "R202340"
            ]
        },
        {
            "instance_id": "R202360xR202272",
            "comparison_id": "R202360",
            "paper_id": "R202272",
            "text": "Cooperative Privacy Preservation for Wearable Devices in Hybrid Computing-Based Smart Health along with an integration of wearable devices, wireless communications and big data in the smart health, biomedical data is collected referring to multiple associated patients during interactions. due to communication channel openness and data sensibility, privacy preservation become increasingly noteworthy in the edge and cloud hybrid computing-based healthcare applications. in this paper, a cooperative privacy preservation scheme is designed for wearable devices with identity authentication and data access control considerations in the space-aware and time-aware contexts. in the space-aware edge computing mode, secret sharing and minhash-based authentication is designed to enhance privacy preservation along with similarity computing without revealing sensitive data. in the time-aware cloud computing mode, ciphertext policy attribute-based encryption is applied for fine-grained access control, and bloom filter is used to achieve efficient data structure without privacy exposure. the gny logic-based security formal analysis is performed to prove theoretical correctness, and the proposed scheme achieves cooperative privacy preservation for wearable devices in smart health with communication overhead and computation cost.",
            "contribution_ids": [
                "R202276"
            ]
        },
        {
            "instance_id": "R202360xR202252",
            "comparison_id": "R202360",
            "paper_id": "R202252",
            "text": "Anonymous Group-Oriented Time-Bound Key Agreement for Internet of Medical Things in Telemonitoring Using Chaotic Maps telemonitoring using the internet of medical things (iomt) enables the seamless communication of physical signs from patients who do not visit healthcare providers. it, therefore, improves the efficiency of healthcare services and patient comfort the quality of life of patients. while providing many benefits, it is associated with challenges concerning energy consumption, privacy, and security. this work addresses those challenges by presenting a new group-oriented time-bound-authenticated key agreement scheme using extended chaotic maps. it provides details on the importance and contribution of this work, investigates the scheme of chien, and elucidates its weaknesses. the security of the proposed scheme is analyzed formally using the burrows\u2013abadi\u2013needham logic and informally through informal discussions about security features, possible attacks, and countermeasures. results of a simulation demonstrate that the proposed scheme has more security functions and is more computationally efficient than other related schemes.",
            "contribution_ids": [
                "R202256"
            ]
        },
        {
            "instance_id": "R202360xR202294",
            "comparison_id": "R202360",
            "paper_id": "R202294",
            "text": "IMDfence: Architecting a Secure Protocol for Implantable Medical Devices over the past decade, focus on the security and privacy aspects of implantable medical devices (imds) has intensified, driven by the multitude of cybersecurity vulnerabilities found in various existing devices. however, due to their strict computational, energy and physical constraints, conventional security protocols are not directly applicable to imds. custom-tailored schemes have been proposed instead which, however, fail to cover the full spectrum of security features that modern imds and their ecosystems so critically require. in this paper we propose imdfence, a security protocol for imd ecosystems that provides a comprehensive yet practical security portfolio, which includes availability, non-repudiation, access control, entity authentication, remote monitoring and system scalability. the protocol also allows emergency access that results in the graceful degradation of offered services without compromising security and patient safety. the performance of the security protocol as well as its feasibility and impact on modern imds are extensively analyzed and evaluated. we find that imdfence achieves the above security requirements at a mere less than 7% increase in total imd energy consumption, and less than 14 ms and 9 kb increase in system delay and memory footprint, respectively.",
            "contribution_ids": [
                "R202297"
            ]
        },
        {
            "instance_id": "R202360xR202280",
            "comparison_id": "R202360",
            "paper_id": "R202280",
            "text": "Practical Privacy-Preserving ECG-Based Authentication for IoT-Based Healthcare in current healthcare systems, patients use various types of medical internet of things devices for monitoring their health conditions. the collected information (personal health records) will be sent back to hospitals for diagnosis and quick responses. however, severe security and privacy leakages with regard to data privacy and identity authentication are incurred because the monitored health data contains sensitive information. therefore, the data should be well protected from unauthorized entities. unfortunately, traditional cryptographic approaches or password-based mechanisms cannot fulfill the privacy and security demands in health monitoring due to their low efficiency and knowledge-based property. biometric authentication overcomes these deficiencies and successfully verifies the inherent characteristics of humans. among all biometrics, the electrocardiogram (ecg) signal is the most suitable one due to its medical properties. however, the security and privacy objectives of ecg-based authentication usually fail in practice due to the noise interferences in the collected ecg data and the privacy breach of the ecg database. in this paper, we propose a practical scheme that can reliably authenticate patients with noisy ecg signals and provide differentially private protection simultaneously. the effectiveness and efficiency of our scheme are thoroughly analyzed and evaluated over online datasets. we also conduct a pilot study on human subjects experiencing different exercise levels to validate our scheme.",
            "contribution_ids": [
                "R202284"
            ]
        },
        {
            "instance_id": "R202360xR202214",
            "comparison_id": "R202360",
            "paper_id": "R202214",
            "text": "Smart Mutual Authentication Protocol for Cloud Based Medical Healthcare Systems Using Internet of Medical Things technological development expands the computation process of smart devices that adopt the telecare medical information system (tmis) to fulfill the demands of the healthcare organization. it provides better medical identification to claim the features namely trustworthy, efficient, and resourceful. moreover, the telecare services automate the remote healthcare monitoring process to ease professional workloads. importantly, it is conceived to be more timesaving, economical, and easy healthcare access. cloud-based medical healthcare (cbmh) system is a standard platform that gives its support to the patients for emergency treatment from the medical experts over internet communication. since the medical records are very sensitive, security protection is much necessitated. in addition, patient anonymity should be well preserved. in 2016, chiou et al. proposed a mutual authentication protocol for the telecare medical information system (tmis) using cloud environment (ce). they claim that their protocol satisfies patient anonymity. however, this paper proves that the chiou et al. scheme is not only completely insecure against the patient anonymity, health-report revelation, health-report forgery, report confidentiality, and non-repudiation but also fails to validate the service access against verifiability, undeniability and unforgeability. in order to provide better mutual authenticity, this paper suggests the framework of smart service authentication to cross-examine the common secret session key among the communication entities. in order to examine the security properties, formal and informal verification was carried out. lastly, to prove the security and performance efficiency of a system, the proposed ssa framework was implemented using fpga and moteiv tmote sky-mote. a proposed smart service authentication (ssa) framework is presented to ensure better data security between the patients and the physicians. the formal and informal security analysis proves the significance of the ssa framework model to withstand the security attacks such as health-report forgery, health-report revelation, server-spoofing etc. as a result, it is claimed that it can be well suited for tmis.",
            "contribution_ids": [
                "R202217"
            ]
        },
        {
            "instance_id": "R202360xR202310",
            "comparison_id": "R202360",
            "paper_id": "R202310",
            "text": "FTM-IoMT: Fuzzy-Based Trust Management for Preventing Sybil Attacks in Internet of Medical Things trustworthy transmission is a beneficial step toward the success of the new era of telecommunication technologies and online social networks (osns). many sensitive applications can benefit from osns, e.g., ehealth and medical services. however, osns have always been prey to sybil attacks where numerous fake nodes are being generated and propagated in social networks to mimic like real nodes for the purpose of achieving malicious goals. thus, for security reasons and for the sensitivity of data used in ehealth applications, such fake nodes have to be detected and deactivated immediately. the emerging field of the internet of medical things (iomt) promotes trust management (tm) among various iomt devices to provide accurate and reliable communications, which is quite essential in critical diseases such as covid-19. tm provides a secure platform to iomt devices using different security protocols in the iomt network. generically, if a device is not comfortable to connect with additional devices in a network, the motive of the communication process is not succeeded and leads to disappointment for one device toward others. to handle these types of situations, a tm mechanism, named fuzzy-based tm mechanism for preventing sybil attacks in the internet of medical things (ftm-iomt), is proposed. the ftm-iomt provides tm for the users of ehealth systems using iomt infrastructures. it is an intelligent mechanism to recognize sybil or untrustworthy nodes in the system. the proposed mechanism helps iomt nodes to collect authentic and credible information from their neighboring nodes as well as to neglect sybil nodes. the trust value of a node is evaluated using fuzzy logic processing followed by the trust attributes, such as integrity, receptivity, and compatibility of a node. the ftm-iomt provides a double evaluation check based on fuzzy logic processing and fuzzy filter. the proposed scheme shows superior results when compared to the state-of-the-art approaches.",
            "contribution_ids": [
                "R202315"
            ]
        },
        {
            "instance_id": "R202360xR202265",
            "comparison_id": "R202360",
            "paper_id": "R202265",
            "text": "Multiauthority Access Control With Anonymous Authentication for Personal Health Record a personal health record (phr) system is a smart health system that serves patients and doctors. a phr is usually stored in a cloud and managed by a semitrusted cloud provider. however, there is still a possibility of the exposure of personal health information to semitrusted parties and unauthorized users. to protect the privacy of patients and ensure that patients can control their phrs, a patient-centric phr sharing framework is proposed in this article. in this framework, all phrs are protected with multiauthority attribute-based encryption before outsourcing, which solves the key hosting problem and achieves fine-grained access control to phrs. furthermore, an anonymous authentication between the cloud and the user is proposed to ensure data integrity on the cloud while not exposing the user\u2019s identity during authentication. the proposed authentication is issued from a new online\u2013offline attribute-based signature. it can make the encrypted phrs resist collusion attacks and not be forged during the period of sharing, which enhances patients\u2019 control of their phrs. online\u2013offline and outsourcing decryption also reduces calculation costs and improves operational efficiency. finally, comparisons are given based on numerical experiments.",
            "contribution_ids": [
                "R202270"
            ]
        },
        {
            "instance_id": "R202360xR202318",
            "comparison_id": "R202360",
            "paper_id": "R202318",
            "text": "Efficient Authentication Protocol for Continuous Monitoring in Medical Sensor Networks currently, continuous monitoring on patients with the help of small devices (or sensors), is easy for doctors/nurses to check patients. due to privacy issues, data collected from devices should be protected. thus, a lightweight mutual authentication and key agreement protocol is required among doctors/nurses, trusted servers, sensors and patients. in this paper, we provide a secure protocol which could support continuous monitoring on patients. firstly, user's biometrics will be used to verify users by means of continuous monitoring of physiological data (e.g., ecg signals) in which verification of the patient identity. this could prevent device theft attacks. in addition, dynamic identity is taken to provide user anonymity and mitigate against user traceability. later, we provide informal and formal security analysis to prove that our protocol can establish a session key between the user and sensor after successfully mutually authentication. performance analysis proved our scheme to be competitive in comparison to existing schemes relative to the added security benefits it provides.",
            "contribution_ids": [
                "R202322"
            ]
        },
        {
            "instance_id": "R202360xR202226",
            "comparison_id": "R202360",
            "paper_id": "R202226",
            "text": "A Secure and Efficient Cloud-Centric Internet-of-Medical-Things-Enabled Smart Healthcare System With Public Verifiability the potential of the internet-of-medical-things (iomt) technology for interconnecting the biomedical sensors in e-health has ameliorated the people\u2019s living standards. another technology recognized in the recent e-healthcare is outsourcing the medical data to the cloud. there are, however, several stipulations for adopting these two technologies. the most difficult is the privacy of medical data and the challenge resulting from the resource constraint environment of sensor devices. in this article, we present the state-of-the-art secure and efficient cloud-centric iomt-enabled smart healthcare system with public verifiability. the system novelty implements an escrow-free identity-based aggregate signcryption (ef-idasc) scheme to secure data transmission, which is also proposed in this article. the proposed smart healthcare system fetches the medical data from multiple sensors implanted on the patient\u2019s body, signcrypts and aggregates them under the proposed ef-idasc scheme, and outsources the data on the medical cloud server via smartphone. the system does not reveal any information about the identity and medical data of the patient. we further analyze the performance of the proposed smart healthcare system in terms of energy consumption. moreover, we compare the performance of the proposed ef-idasc scheme with other related schemes.",
            "contribution_ids": [
                "R202230"
            ]
        },
        {
            "instance_id": "R202360xR202348",
            "comparison_id": "R202360",
            "paper_id": "R202348",
            "text": "A Secure IoT-Based Modern Healthcare System With Fault-Tolerant Decision Making Process the advent of internet of things (iot) has escalated the information sharing among various smart devices by many folds, irrespective of their geographical locations. recently, applications like e-healthcare monitoring has attracted wide attention from the research community, where both the security and the effectiveness of the system are greatly imperative. however, to the best of our knowledge none of the existing literature can accomplish both these objectives (e.g., existing systems are not secure against physical attacks). this paper addresses the shortcomings in existing iot-based healthcare system. we propose an enhanced system by introducing a physical unclonable function (puf)-based authentication scheme and a data driven fault-tolerant decision-making scheme for designing an iot-based modern healthcare system. analyses show that our proposed scheme is more secure and efficient than existing systems. hence, it will be useful in designing an advanced iot-based healthcare system.",
            "contribution_ids": [
                "R202353"
            ]
        },
        {
            "instance_id": "R202360xR202341",
            "comparison_id": "R202360",
            "paper_id": "R202341",
            "text": "PMsec: Physical Unclonable Function-Based Robust and Lightweight Authentication in the Internet of Medical Things various commercial off-the-shelf components are available for the development of communication-enabled consumer electronics devices. this opens new doors to attackers who can take advantage of various vulnerabilities to attack the entire network and compromise the integrity of the system and the environment. if a malicious device enters the environment and the attacker gains access to the server or transmits malicious data to the server or cloud, the entire network can be jeopardized. to avoid such cases, this paper presents a device authentication scheme which uses physical unclonable functions (pufs) and is suitable for the internet-of-medical-things (iomt). the main advantage of this authentication scheme is that no data related to the iomt devices are stored in server memory. the time taken to authenticate the devices completely was 1.2 s to 1.5 s. a hybrid oscillator arbiter physical unclonable function was used for validation of the proposed authentication scheme. from the puf module used during experimental validation, the number of keys that could be potentially used for the authentication protocol from each design is approximately 240. the proposed authentication scheme increases the robustness of the design while being lightweight to be deployed in various designs and supports scalability.",
            "contribution_ids": [
                "R202346"
            ]
        },
        {
            "instance_id": "R202361xR202123",
            "comparison_id": "R202361",
            "paper_id": "R202123",
            "text": "An Instance-Based Algorithm With Auxiliary Similarity Information for the Estimation of Gait Kinematics From Wearable Sensors wearable human movement measurement systems are increasingly popular as a means of capturing human movement data in real-world situations. previous work has attempted to estimate segment kinematics during walking from foot acceleration and angular velocity data. in this paper, we propose a novel neural network [grnn with auxiliary similarity information (gasi)] that estimates joint kinematics by taking account of proximity and gait trajectory slope information through adaptive weighting. furthermore, multiple kernel bandwidth parameters are used that can adapt to the local data density. to demonstrate the value of the gasi algorithm, hip, knee, and ankle joint motions are estimated from acceleration and angular velocity data for the foot and shank, collected using commercially available wearable sensors. reference hip, knee, and ankle kinematic data were obtained using externally mounted reflective markers and infrared cameras for subjects while they walked at different speeds. the results provide further evidence that a neural net approach to the estimation of joint kinematics is feasible and shows promise, but other practical issues must be addressed before this approach is mature enough for clinical implementation. furthermore, they demonstrate the utility of the new gasi algorithm for making estimates from continuous periodic data that include noise and a significant level of variability.",
            "contribution_ids": [
                "R202125"
            ]
        },
        {
            "instance_id": "R202361xR202118",
            "comparison_id": "R202361",
            "paper_id": "R202118",
            "text": "A study on band-pass filtering for calculating foot displacements from accelerometer and gyroscope sensors. as a promising alternative to laboratory-constrained video capture systems in studies of human movement, inertial sensors (accelerometers and gyroscopes) are recently gaining popularity. secondary quantities such as velocity, displacement and joint angles can be calculated through integration of acceleration and angular velocities. it is broadly accepted that this procedure is significantly influenced by accumulative errors due to integration, arising from sensor noise, non-linearities, asymmetries, sensitivity variations and bias drifts. in this paper, we assess the effectiveness of applying band-pass filtering to raw inertial sensor data under the assumption that sensor drift errors occur in the low frequency spectrum. the normalized correlation coefficient rho of the fast fourier transform (fft) spectra corresponding to vertical toe acceleration from inertial sensors and from a video capture system as a function of digital band-pass filter parameters is compared. the root mean square error (rmse) of the vertical toe displacement for 30 second walking windows is calculated for 2 healthy subjects over a range of 4 walking speeds. the lowest rmse and highest cross correlation achieved for the slowest walking speed of 2.5km/h was 3.06cm and 0.871 respectively, and 2.96cm and 0.952 for the fastest speed of 5.5km/h.",
            "contribution_ids": [
                "R202120"
            ]
        },
        {
            "instance_id": "R202361xR202129",
            "comparison_id": "R202361",
            "paper_id": "R202129",
            "text": "Human pose recovery using wireless inertial measurement units many applications in rehabilitation and sports training require the assessment of the patient\u2019s status based on observation of their movement. small wireless sensors, such as accelerometers and gyroscopes, can be utilized to provide a quantitative measure of the human movement for assessment. in this paper, a kinematics-based approach is developed to estimate human leg posture and velocity from wearable sensors during the performance of typical physiotherapy and training exercises. the proposed approach uses an extended kalman filter to estimate joint angles from accelerometer and gyroscopic data and is capable of recovering joint angles from arbitrary 3d motion. additional joint limit constraints are implemented to reduce drift, and an automated approach is developed for estimating and adapting the process noise during online estimation. the approach is validated through a user study consisting of 20 subjects performing knee and hip rehabilitation exercises. when compared to motion capture, the approach achieves an average root-mean-square error of 4.27 cm for unconstrained motion, with an average joint error of 6.5\u00b0. the average root-mean-square error is 3.31 cm for sagittal planar motion, with an average joint error of 4.3\u00b0.",
            "contribution_ids": [
                "R202131"
            ]
        },
        {
            "instance_id": "R202361xR202103",
            "comparison_id": "R202361",
            "paper_id": "R202103",
            "text": "Modular wireless inertial trackers for biomedical applications in the past few years, semiconductor based wireless positing and tracking devices have successfully integrated into consumer electronics devices. the sensors track the movement and the orientation of the device to provide a positioning feedback to the program. however, the accuracy of these trackers is typically not acceptable for biomedical application which demands high accuracy. previous study was performed to access the feasibility of using semiconductor based inertial measurement units (imu) for human motion tracking. after evaluating the strength and weakness in the previous imu modules, several modifications and improvement were made. a modular imu was designed with high resolution adc. a statistical based approach for orientation tracking is currently being developed and preliminary data were presented and compared with other tracking algorithms.",
            "contribution_ids": [
                "R202105"
            ]
        },
        {
            "instance_id": "R202361xR202094",
            "comparison_id": "R202361",
            "paper_id": "R202094",
            "text": "A Novel Complimentary Filter for Tracking Hip Angles During Cycling Using Wireless Inertial Sensors and Dynamic Acceleration Estimation as wireless motion sensors become more compact and robust, new opportunities emerge to develop wearable measurement technologies for in-field sports analysis. this paper presents a nonlinear complimentary filter for tracking 3-d hip joint angles during cycling using inertial and magnetic measurement systems (immss). the filter utilizes a novel method of dynamic acceleration compensation in the sensor frame based on the assumption of pendulum motion of the thigh around the hip joint center. a dynamic calibration is proposed in which the center of rotation of the thigh imms can be estimated during a functional hip movement in standing. validation results from a gold-standard optical system showed that the filter imms tracking is drift-free with mean absolute errors of less than 3\u00b0 for all imms axes combined at low, medium, and high pedaling speeds. hip angles were also validated using the vicon biomechanical model for standing and sitting calibration poses as well as true and normalized soft-tissue-artefact (sta). the best mean absolute errors for the sagittal, frontal, and coronal planes were 0.8\u00b0, 6.7\u00b0, and 2.2\u00b0, respectively. variability due to calibrations and sta ranged from 1.4\u00b0 to 8.1\u00b0. this demonstrates the high accuracies possible for imms tracking using algorithms designed for specific sports despite larger errors due to modeling.",
            "contribution_ids": [
                "R202096"
            ]
        },
        {
            "instance_id": "R202362xR202118",
            "comparison_id": "R202362",
            "paper_id": "R202118",
            "text": "A study on band-pass filtering for calculating foot displacements from accelerometer and gyroscope sensors. as a promising alternative to laboratory-constrained video capture systems in studies of human movement, inertial sensors (accelerometers and gyroscopes) are recently gaining popularity. secondary quantities such as velocity, displacement and joint angles can be calculated through integration of acceleration and angular velocities. it is broadly accepted that this procedure is significantly influenced by accumulative errors due to integration, arising from sensor noise, non-linearities, asymmetries, sensitivity variations and bias drifts. in this paper, we assess the effectiveness of applying band-pass filtering to raw inertial sensor data under the assumption that sensor drift errors occur in the low frequency spectrum. the normalized correlation coefficient rho of the fast fourier transform (fft) spectra corresponding to vertical toe acceleration from inertial sensors and from a video capture system as a function of digital band-pass filter parameters is compared. the root mean square error (rmse) of the vertical toe displacement for 30 second walking windows is calculated for 2 healthy subjects over a range of 4 walking speeds. the lowest rmse and highest cross correlation achieved for the slowest walking speed of 2.5km/h was 3.06cm and 0.871 respectively, and 2.96cm and 0.952 for the fastest speed of 5.5km/h.",
            "contribution_ids": [
                "R202120"
            ]
        },
        {
            "instance_id": "R202362xR202109",
            "comparison_id": "R202362",
            "paper_id": "R202109",
            "text": "Physical sensor difference-based method and virtual sensor difference-based method for visual and quantitative estimation of lower limb 3D gait posture using accelerometers and magnetometers an approach using a physical sensor difference-based algorithm and a virtual sensor difference-based algorithm to visually and quantitatively confirm lower limb posture was proposed. three accelerometers and two mag3s (inertial sensor module) were used to measure the accelerations and magnetic field data for the calculation of flexion/extension (fe) and abduction/adduction (aa) angles of hip joint and fe, aa and internal/external rotation (ie) angles of knee joint; then, the trajectories of knee and ankle joints were obtained with the joint angles and segment lengths. there was no integration of acceleration or angular velocity for the joint rotations and positions, which is an improvement on the previous method in recent literature. compared with the camera motion capture system, the correlation coefficients in five trials were above 0.91 and 0.92 for the hip fe and aa, respectively, and higher than 0.94, 0.93 and 0.93 for the knee joint fe, aa and ie, respectively.",
            "contribution_ids": [
                "R202111"
            ]
        },
        {
            "instance_id": "R202362xR202123",
            "comparison_id": "R202362",
            "paper_id": "R202123",
            "text": "An Instance-Based Algorithm With Auxiliary Similarity Information for the Estimation of Gait Kinematics From Wearable Sensors wearable human movement measurement systems are increasingly popular as a means of capturing human movement data in real-world situations. previous work has attempted to estimate segment kinematics during walking from foot acceleration and angular velocity data. in this paper, we propose a novel neural network [grnn with auxiliary similarity information (gasi)] that estimates joint kinematics by taking account of proximity and gait trajectory slope information through adaptive weighting. furthermore, multiple kernel bandwidth parameters are used that can adapt to the local data density. to demonstrate the value of the gasi algorithm, hip, knee, and ankle joint motions are estimated from acceleration and angular velocity data for the foot and shank, collected using commercially available wearable sensors. reference hip, knee, and ankle kinematic data were obtained using externally mounted reflective markers and infrared cameras for subjects while they walked at different speeds. the results provide further evidence that a neural net approach to the estimation of joint kinematics is feasible and shows promise, but other practical issues must be addressed before this approach is mature enough for clinical implementation. furthermore, they demonstrate the utility of the new gasi algorithm for making estimates from continuous periodic data that include noise and a significant level of variability.",
            "contribution_ids": [
                "R202125"
            ]
        },
        {
            "instance_id": "R202362xR202126",
            "comparison_id": "R202362",
            "paper_id": "R202126",
            "text": "Displacement estimation for different gait patterns in micro-sensor motion capture the human body displacement estimation in different gait patterns using wearable sensors is extremely challenging due to lack of external references. in this paper, we present a novel algorithm to estimate the center of mass (com) displacement of human body during walking, running and hopping using 7 body-worn sensor measurement units (smus). the lower body posture and feet displacements are firstly estimated by a complementary kalman filter (ckf) which compensates the orientation, velocity and position errors of the inertial navigation system (ins) solutions through its error state vector. the com displacement can then be acquired by further fusion of the lower body posture and feet locations based on the linked biomechanical model. the experimental results have shown that our method can accurately capture human motion including orientation and locomotion for these three different gait patterns with regard to the optical motion tracker.",
            "contribution_ids": [
                "R202128"
            ]
        },
        {
            "instance_id": "R202362xR202097",
            "comparison_id": "R202362",
            "paper_id": "R202097",
            "text": "An inertial sensor system for measurements of tibia angle with applications to knee valgus/varus detection accurate measurement of knee motion during dynamic movements is the key to detect and highlight deficiencies in peripheral muscles and ligaments of the knee and hence to predict the risk of injury. miniature inertial sensors are increasingly becoming a viable option for human movement measurement, given their small size, low cost and relatively good accuracy compared with traditional optical measurements. a system capable of measuring tibia angle using a shank mounted wireless inertial sensor is proposed. the system employs a simple setup with only one skin-mounted triaxial accelerometer and gyroscope module attached to the tibia segment, and an algorithm to estimate the tibia angle. the accuracy of the system was assessed by an optical tracking system (optotrak certus) during dynamic movements performed by three subjects by evaluating root-mean-square error (rmse) of tibia-flexion and tibia-adduction angles over the period of motion. we achieve an rmse of 1.6\u00b11.1 and2.5\u00b11.6 degrees in tibia-flexion and tibia-adduction angles, respectively. it is argued that tibia angle can be reliably used to detect valgus or varus movement of the knee and hence the proposed system provides a simple and useful assessment tool for performance enhancement and rehabilitation.",
            "contribution_ids": [
                "R202099"
            ]
        },
        {
            "instance_id": "R203903xR203607",
            "comparison_id": "R203903",
            "paper_id": "R203607",
            "text": "Design of sinkhole node detection mechanism for hierarchical wireless sensor networks: Design of sinkhole node detection mechanism for hierarchical wireless sensor networks wireless sensor networks wsns have several applications ranging from the civilian to military applications. wsns are prone to various hole attacks, such as sinkhole, wormhole, blackhole, and greyhole. among these hole attacks, the sinkhole attack is the malignant one. a sinkhole attack allows a malicious node, called the sinkhole node, advertises a best possible path to the base station bs. this misguides its neighbors to utilize that path more frequently. the sinkhole node has the opportunity to tamper with the data, and it also performs the modifications in messages or it drops messages or it produces unnecessary delay before forwarding them to the bs. on the basis of these malicious acts that are performed by a sinkhole attacker node, we consider three types of malicious nodes in a wsn: sinkhole message modification node smd, sinkhole message dropping node sdp, and sinkhole message delay node sdl. none of the existing techniques in the literature is capable to handle all three types of nodes at a time. this paper presents a new detection scheme for the detection of different types of sinkhole nodes for a hierarchical wireless sensor network hwsn. to the best of our knowledge, this is the first attempt to design such a detection scheme in hwsns which can detect smd, sdp, and sdl nodes. in our approach, the entire hwsn is divided into several disjoint clusters, and each cluster has a powerful high-end sensor node called a cluster head, which is responsible for the detection of different sinkhole attacker nodes if present in that cluster. we simulate our scheme using the widely-accepted ns2 simulator for measurement of various network parameters. the proposed scheme achieves around 95% detection rate and 1.25% false positive rate. these factors are significantly better than the previous related schemes. furthermore, the computation and communication efficiency is achieved in our scheme. as a result, our scheme seems suitable for the sensitive critical applications, such as military applications. copyright \u00a9 2016 john wiley & sons, ltd.",
            "contribution_ids": [
                "R203610"
            ]
        },
        {
            "instance_id": "R203903xR203892",
            "comparison_id": "R203903",
            "paper_id": "R203892",
            "text": "E-Spion: A System-Level Intrusion Detection System for IoT Devices as the internet of things (iot) grows at a rapid pace, there is a need for an effective and efficient form of security tailored for iot devices. in this paper, we introduce e-spion, an anomaly-based system level intrusion detection system (ids) for iot devices. e-spion profiles iot devices according to their 'behavior' using system level information, like running process parameters and their system calls, in an autonomous, efficient, and scalable manner. these profiles are then used to detect anomalous behaviors indicative of intrusions. e-spion provides three layers of detection with increasing detection efficiency but at the same time higher overhead costs on the devices. we have extensively evaluated e-spion using a comprehensive dataset of 3973 iot malware samples in our testbed. we observe a detection efficiency ranging from 78% to 100% depending on the layers of detection employed. we provide an analysis and comparison of the different layers of e-spion in terms of detection accuracy and overhead costs. we also analyze the behavior of the malware samples in terms of our device logs at each layer.",
            "contribution_ids": [
                "R203894"
            ]
        },
        {
            "instance_id": "R203903xR202381",
            "comparison_id": "R203903",
            "paper_id": "R202381",
            "text": "Intrusion Detection in Homogeneous and Heterogeneous Wireless Sensor Networks intrusion detection in wireless sensor network (wsn) is of practical interest in many applications such as detecting an intruder in a battlefield. the intrusion detection is defined as a mechanism for a wsn to detect the existence of inappropriate, incorrect, or anomalous moving attackers. for this purpose, it is a fundamental issue to characterize the wsn parameters such as node density and sensing range in terms of a desirable detection probability. in this paper, we consider this issue according to two wsn models: homogeneous and heterogeneous wsn. furthermore, we derive the detection probability by considering two sensing models: single-sensing detection and multiple-sensing detection. in addition, we discuss the network connectivity and broadcast reachability, which are necessary conditions to ensure the corresponding detection probability in a wsn. our simulation results validate the analytical values for both homogeneous and heterogeneous wsns.",
            "contribution_ids": [
                "R202383"
            ]
        },
        {
            "instance_id": "R203903xR203852",
            "comparison_id": "R203903",
            "paper_id": "R203852",
            "text": "BRIoT: Behavior Rule Specification-Based Misbehavior Detection for IoT-Embedded Cyber-Physical Systems the identification of vulnerabilities in a mission-critical system is one of the challenges faced by a cyber-physical system (cps). the incorporation of embedded internet of things (iot) devices makes it tedious to identify vulnerability and difficult to control the service-interruptions and manage the operations losses. rule-based mechanisms have been considered as a solution in the past. however, rule-based solutions operate on the goodwill of the generated rules and perform assumption-based detection. such a solution often is far from the actual realization of the iot runtime performance and can be fooled by zero-day attacks. thus, this paper takes this issue as motivation and proposes better lightweight behavior rule specification-based misbehavior detection for the iot-embedded cyber-physical systems (briot). the key concept of our approach is to model a system with which misbehavior of an iot device manifested as a result of attacks exploiting the vulnerability exposed may be detected through automatic model checking and formal verification, regardless of whether the attack is known or unknown. automatic model checking and formal verification are achieved through a 2-layer fuzzy-based hierarchical context-aware aspect-oriented petri net (hcapn) model, while effective misbehavior detection to avoid false alarms is achieved through a barycentric-coordinated-based center of mass calculation method. the proposed approach is verified by an unmanned aerial vehicle (uav) embedded in a uav system. the feasibility of the proposed model is demonstrated with high reliability, low operational cost, low false-positives, low false-negatives, and high true positives in comparison with existing rule-based solutions.",
            "contribution_ids": [
                "R203855"
            ]
        },
        {
            "instance_id": "R203903xR203845",
            "comparison_id": "R203903",
            "paper_id": "R203845",
            "text": "Toward a Lightweight Intrusion Detection System for the Internet of Things integration of the internet into the entities of the different domains of human society (such as smart homes, health care, smart grids, manufacturing processes, product supply chains, and environmental monitoring) is emerging as a new paradigm called the internet of things (iot). however, the ubiquitous and wide-range iot networks make them prone to cyberattacks. one of the main types of attack is a denial of service (dos), where the attacker floods the network with a large volume of data to prevent nodes from using the services. an intrusion detection mechanism is considered a chief source of protection for information and communications technology. however, conventional intrusion detection methods need to be modified and improved for application to the iot owing to certain limitations, such as resource-constrained devices, the limited memory and battery capacity of nodes, and specific protocol stacks. in this paper, we develop a lightweight attack detection strategy utilizing a supervised machine learning-based support vector machine (svm) to detect an adversary attempting to inject unnecessary data into the iot network. the simulation results show that the proposed svm-based classifier, aided by a combination of two or three incomplex features, can perform satisfactorily in terms of classification accuracy and detection time.",
            "contribution_ids": [
                "R203850"
            ]
        },
        {
            "instance_id": "R203903xR203828",
            "comparison_id": "R203903",
            "paper_id": "R203828",
            "text": "An Intrusion Detection Model for Wireless Sensor Networks With an Improved V-Detector Algorithm due to the advantage of negative selection algorithm (nsa) in classification domain, this paper proposes an intrusion detection model named as wireless sensor networks (wsn-nsa) based on an improved v-detector algorithm for wsn. to overcome the problem of resource constraints of storage space, computing capacity and energy in wsn, the main strategy of the wsn-nsa is to establish a three level detection mechanism by taking the advantage of the cooperation of the base station, detection nodes, and ordinary nodes considering their different capabilities, and to modify the v-detector algorithm by modifying the detector generation rule and optimizing the detectors, and to use the principal component analysis to reduce the detection features. two kinds of detectors sets which are memory detector set and mature detector set are used to detect the intrusion. the simulation results show that the proposed model outperforms the intrusion detection systems using the v-detector in the reduction of data storage space and computation, the increased detection rate, and the quick response to the secondary attack.",
            "contribution_ids": [
                "R203830",
                "R203833"
            ]
        },
        {
            "instance_id": "R203903xR203623",
            "comparison_id": "R203903",
            "paper_id": "R203623",
            "text": "Intelligent Intrusion Detection in Low-Power IoTs security and privacy of data are one of the prime concerns in today\u2019s internet of things (iot). conventional security techniques like signature-based detection of malware and regular updates of a signature database are not feasible solutions as they cannot secure such systems effectively, having limited resources. programming languages permitting immediate memory accesses through pointers often result in applications having memory-related errors, which may lead to unpredictable failures and security vulnerabilities. furthermore, energy efficient iot devices running on batteries cannot afford the implementation of cryptography algorithms as such techniques have significant impact on the system power consumption. therefore, in order to operate iot in a secure manner, the system must be able to detect and prevent any kind of intrusions before the network (i.e., sensor nodes and base station) is destabilised by the attackers. in this article, we have presented an intrusion detection and prevention mechanism by implementing an intelligent security architecture using random neural networks (rnns). the application\u2019s source code is also instrumented at compile time in order to detect out-of-bound memory accesses. it is based on creating tags, to be coupled with each memory allocation and then placing additional tag checking instructions for each access made to the memory. to validate the feasibility of the proposed security solution, it is implemented for an existing iot system and its functionality is practically demonstrated by successfully detecting the presence of any suspicious sensor node within the system operating range and anomalous activity in the base station with an accuracy of 97.23%. overall, the proposed security solution has presented a minimal performance overhead.",
            "contribution_ids": [
                "R203625"
            ]
        },
        {
            "instance_id": "R204005xR203973",
            "comparison_id": "R204005",
            "paper_id": "R203973",
            "text": "Detection and Molecular Characterization of a Canine Norovirus we identified a novel calicivirus in a pup with enteritis. the isolate was related genetically (90.1% aa identity in the capsid protein) to a lion norovirus strain.",
            "contribution_ids": [
                "R203975"
            ]
        },
        {
            "instance_id": "R204005xR201727",
            "comparison_id": "R204005",
            "paper_id": "R201727",
            "text": "Detection of Multiple Genotypes of Calicivirus Infection in Asymptomatic Swine in Taiwan: Multiple Genotypes of Noroviruses Co-Circulate in Swine noroviruses (novs) and sapoviruses (savs) of the family caliciviridae are emerging enteric pathogens in humans and animals. recent detection of genogroup ii norovirus (gii nov) rna from swine raises public health concerns about zoonotic transmission of porcine novs to humans. however, few papers reported genotype distributions and epidemiological features in swine farms and their genetic relationship to human strains, which was the objective of our study. this study investigated the epidemiological features and genotypes of caliciviruses in swine farms using 533 pig faecal samples from six farms in central and southern taiwan, tested for viral rna using rt\u2010pcr targeting the conserved polymerase gene. novs and savs were detected with a positive rate of 7.1% and 0.6%, respectively. to confirm the positive rate of novs, 255 pig faecal samples from two farms in central taiwan were tested with primer pairs targeting the partial capsid gene of gii, and 32.3% of the positive rate was found. furthermore, the results from the capsid region suggested a higher positive rate of 41.7% in winter than 26.4% in summer with statistical significance (p < 0.05). sequence analysis showed 29 strains belonging to gii.4 (human) and nine strains belonging to gii.11 (swine) identified based on the partial polymerase gene. additional genotypes clustered with gii.2 (human) and gii.18 (swine) were also characterized based on the partial capsid gene. savs detected in porcine faecal samples belonged to genogroup iii (giii), which clustered with the pec\u2010cowden strain. our study demonstrated the presence of multiple genotypes of both human and porcine novs infecting swine of various ages asymptomatically. although the zoonotic potential of detected human novs in swine was not conclusive owing to the lack of local human faecal samples, our study revealed the importance of monitoring emerging strains in swine to mitigate the potential impact of recombinant novs infecting the human population.",
            "contribution_ids": [
                "R201729"
            ]
        },
        {
            "instance_id": "R204005xR203994",
            "comparison_id": "R204005",
            "paper_id": "R203994",
            "text": "Prevalence of rotavirus and norovirus antibodies in non-human primates abstract: rotavirus and norovirus are associated with a substantial burden of diarrheal disease in humans and some animals, but their role in acute viral gastroenteritis in non\u2010human primates has not been established. we examined sera from five species of old and new world monkeys and chimpanzees for antibodies to rotavirus and norovirus by enzyme immunoassays using rrv and three recombinant human norovirus capsid proteins, respectively. most (88%) of the 3 old world monkey species (mangabey, pigtail, and rhesus) and apes were seropositive for rotavirus. norovirus antibody was prevalent in the three monkey species, with 53% (44/83) and 58% (48/83) seropositive for gi and gii strains, respectively. eleven (92%) of the 12 chimpanzees tested were seropositive for gi norovirus. given the high rate of infection with both viruses, the role of these agents in causing acute gastroenteritis in non\u2010human primates and the value of these animals as models of infection and disease need to be assessed.",
            "contribution_ids": [
                "R203996",
                "R203997",
                "R203998",
                "R203999"
            ]
        },
        {
            "instance_id": "R204005xR201765",
            "comparison_id": "R204005",
            "paper_id": "R201765",
            "text": "Faecal Virome Analysis of Wild Animals from Brazil the brazilian cerrado fauna shows very wide diversity and can be a potential viral reservoir. therefore, the animal\u2019s susceptibility to some virus can serve as early warning signs of potential human virus diseases. moreover, the wild animal virome of this biome is unknown. based on this scenario, high-throughput sequencing contributes a robust tool for the identification of known and unknown virus species in this environment. in the present study, faeces samples from cerrado birds (psittacara leucophthalmus, amazona aestiva, and sicalis flaveola) and mammals (didelphis albiventris, sapajus libidinosus, and galictis cuja) were collected at the veterinary hospital, university of bras\u00edlia. viral nucleic acid was extracted, submitted to random amplification, and sequenced by illumina hiseq platform. the reads were de novo assembled, and the identities of the contigs were evaluated by blastn and tblastx searches. most viral contigs analyzed were closely related to bacteriophages. novel archaeal viruses of the smacoviridae family were detected. moreover, sequences of members of adenoviridae, anelloviridae, circoviridae, caliciviridae, and parvoviridae families were identified. complete and nearly complete genomes of known anelloviruses, circoviruses, and parvoviruses were obtained, as well as putative novel species. we demonstrate that the metagenomics approach applied in this work was effective for identification of known and putative new viruses in faeces samples from brazilian cerrado fauna.",
            "contribution_ids": [
                "R201771"
            ]
        },
        {
            "instance_id": "R204005xR203909",
            "comparison_id": "R204005",
            "paper_id": "R203909",
            "text": "Seroprevalence of Noroviruses in Swine abstract noroviruses (nvs) are important human pathogens that cause acute gastroenteritis. genetically related animal enteric nvs have also been described, but there is no evidence of interspecies transmission of nvs. in this study we characterized antibody prevalence among domestic pigs by using recombinant capsid antigens of two human nvs (norwalk and hawaii) and one swine nv (sw918) that is genetically related to gii human nvs. recombinant sw918 capsid protein expressed in baculovirus self-assembled into virus-like particles (vlps) that were detected by antibodies against gii (hawaii and mexico), but not gi (norwalk and va115), human nvs. nvs recognize human histo-blood group antigens as receptors, but sw918 vlps did not bind to human saliva samples with major histo-blood group types. seventy-eight of 110 (71%) pig serum samples from the united states and 95 of 266 (36%) pig serum samples from japan possessed antibodies against sw918. serum samples from pigs in the united states were also tested for antibodies against human nvs; 63% were positive for norwalk virus (gi) and 52% for hawaii virus (gii). these results indicate that nv infections are common among domestic pigs; the finding of antigenic relationships between sw918 and human nvs and the detection of antibodies against both gi and gii human nvs in domestic animals highlights the importance of further studies on nv gastroenteritis as a possible zoonotic disease.",
            "contribution_ids": [
                "R203912"
            ]
        },
        {
            "instance_id": "R204005xR201751",
            "comparison_id": "R204005",
            "paper_id": "R201751",
            "text": "Human Norovirus Infection in Dogs, Thailand in july 2018, recombinant norovirus gii.pe-gii.4 sydney was detected in dogs who had diarrhea in a kennel and in children living on the same premises in thailand. whole-genome sequencing and phylogenetic analysis of 4 noroviruses from thailand showed that the canine norovirus was closely related to human norovirus gii.pe-gii.4 sydney, suggesting human-to-canine transmission.",
            "contribution_ids": [
                "R201753"
            ]
        },
        {
            "instance_id": "R204005xR203949",
            "comparison_id": "R204005",
            "paper_id": "R203949",
            "text": "Seroprevalence in Household Raised Pigs Indicate High Exposure to GII Noroviruses in Rural Nicaragua information about porcine norovirus (ponov), genetically similar to human nov (hunov), is limited from rural areas where household\u2010raised pigs are heavily exposed to faecal material which could facilitate transmission. histo\u2010blood group antigens (hbgas) are known susceptibility factors to nov in humans and in a germfree piglet model but their role in susceptibility in the porcine population remains unknown. this study reports: (i) the seroprevalence and antibody titres to human norovirus (nov) vlps in household raised pigs; (ii) the distribution of hbgas in relation to nov igg antibody titres and further characterization by blocking of gii.4 vlp binding to pig gastric mucins (pgm). the majority of pigs were seropositive to all three vlps tested (58\u201370%) with seropositivity and cross\u2010reactivity increasing significantly with age. however, pig sera could not block the binding of nov gii.4 vlps (dijon) to pgm suggesting no previous infection with this genotype. the majority of the pigs were h\u2010positive (84%), a susceptibility factor for human infections. igg antibody titres were however higher in h\u2010negative (gmt = 247) as compared with h\u2010positive (gmt = 57) pigs, but after age stratification, this difference in antibody titres was only observed in pigs \u22641 month of age. in conclusion, serological data show that the porcine population of nicaragua is highly exposed to nov infections, and the association to hbgas warrants further investigation.",
            "contribution_ids": [
                "R203951"
            ]
        },
        {
            "instance_id": "R204005xR201707",
            "comparison_id": "R204005",
            "paper_id": "R201707",
            "text": "Human noroviruses in the faeces of wild birds and rodents-new potential transmission routes human noroviruses (hunovs) are one of the leading global causes of diarrhoeal diseases and are transmitted mainly from person to person but also through contaminated food, water and fomites. the possible zoonotic nature of novs has occasionally been discussed, although the viruses are generally considered to be host\u2010species\u2010specific. we investigated whether wild birds and rodents could serve as carriers of hunovs, thereby transmitting the virus to humans directly or indirectly by contaminating foods. all samples, 115 avian and 100 rat faeces collected in springs 2009\u20132013 from dump sites, and 85 faeces from yellow\u2010necked mice trapped in late autumn 2008 and 2009 after the rodents entered human settlements due to the first night frosts, were screened for hunov using real\u2010time reverse transcription pcr. hunovs were detected in 31 (27%) faecal samples of wild birds, in two (2%) faecal samples of rats and in no samples of mice. most (25) of the positive bird samples and both rat samples contained genogroup ii, and six positive bird samples contained genogroup i hunov. the avian species shedding faeces containing hunovs were identified as gulls and crows using dna barcoding. our results show that wildlife, birds and rats in particular, is capable of spreading hunovs in the environment.",
            "contribution_ids": [
                "R201710",
                "R201718",
                "R201720"
            ]
        },
        {
            "instance_id": "R204005xR203989",
            "comparison_id": "R204005",
            "paper_id": "R203989",
            "text": "Detection of norovirus-, sapovirus- and rhesus enteric calicivirus-specific antibodies in captive juvenile macaques the objective of this study was to determine the prevalence of anti-norovirus (nov), -sapovirus (sav) and -tulane virus (tv) antibodies in rhesus macaques of the tulane national primate research center and to evaluate the antigenic relationship between these viruses. a high prevalence of nov-binding (51-61 %) and sav-binding (50-56 %) antibodies and tv-neutralizing (69 %) antibodies were detected. serum samples obtained during a human nov outbreak and a multivalent anti-nov hyperimmune serum were not able to neutralize tv infectivity. conversely, low levels of cross-reactivity between the prototype tv and novs, but not between the tv and savs were detected by elisa. these data indicate the preservation of some cross-reactive b-cell epitopes between the rhesus and human caliciviruses (cvs). the high prevalence of human and rhesus cv-specific serum antibodies suggests the frequent exposure of colony macaques to enteric cvs including the possibility of cv transmission between human and non-human primate hosts.",
            "contribution_ids": [
                "R203991",
                "R203992"
            ]
        },
        {
            "instance_id": "R204080xR204051",
            "comparison_id": "R204080",
            "paper_id": "R204051",
            "text": "ABY3: A mixed protocol framework for machine learning machine learning is widely used to produce models for a range of applications and is increasingly offered as a service by major technology companies. however, the required massive data collection raises privacy concerns during both training and prediction stages. in this paper, we design and implement a general framework for privacy-preserving machine learning and use it to obtain new solutions for training linear regression, logistic regression and neural network models. our protocols are in a three-server model wherein data owners secret share their data among three servers who train and evaluate models on the joint data using three-party computation (3pc). our main contribution is a new and complete framework ($\\textaby ^3$) for efficiently switching back and forth between arithmetic, binary, and yao 3pc which is of independent interest. many of the conversions are based on new techniques that are designed and optimized for the first time in this paper. we also propose new techniques for fixed-point multiplication of shared decimal values that extends beyond the three-party case, and customized protocols for evaluating piecewise polynomial functions. we design variants of each building block that is secure against \\em malicious adversaries who deviate arbitrarily. we implement our system in c++. our protocols are up to \\em four orders of magnitude faster than the best prior work, hence significantly reducing the gap between privacy-preserving and plaintext training.",
            "contribution_ids": [
                "R204053"
            ]
        },
        {
            "instance_id": "R204080xR204013",
            "comparison_id": "R204080",
            "paper_id": "R204013",
            "text": "Privacy-preserving deep learning via additively homomorphic encryption we present a privacy-preserving deep learning system in which many learning participants perform neural network-based deep learning over a combined dataset of all, without revealing the participants\u2019 local data to a central server. to that end, we revisit the previous work by shokri and shmatikov (acm ccs 2015) and show that, with their method, local data information may be leaked to an honest-but-curious server. we then fix that problem by building an enhanced system with the following properties: 1) no information is leaked to the server and 2) accuracy is kept intact, compared with that of the ordinary deep learning system also over the combined dataset. our system bridges deep learning and cryptography: we utilize asynchronous stochastic gradient descent as applied to neural networks, in combination with additively homomorphic encryption. we show that our usage of encryption adds tolerable overhead to the ordinary deep learning system.",
            "contribution_ids": [
                "R204015"
            ]
        },
        {
            "instance_id": "R204080xR204047",
            "comparison_id": "R204080",
            "paper_id": "R204047",
            "text": "Oblivious neural network predictions via minionn transformations machine learning models hosted in a cloud service are increasingly popular but risk privacy: clients sending prediction requests to the service need to disclose potentially sensitive information. in this paper, we explore the problem of privacy-preserving predictions: after each prediction, the server learns nothing about clients' input and clients learn nothing about the model. we present minionn, the first approach for transforming an existing neural network to an oblivious neural network supporting privacy-preserving predictions with reasonable efficiency. unlike prior work, minionn requires no change to how models are trained. to this end, we design oblivious protocols for commonly used operations in neural network prediction models. we show that minionn outperforms existing work in terms of response latency and message sizes. we demonstrate the wide applicability of minionn by transforming several typical neural network models trained from standard datasets.",
            "contribution_ids": [
                "R204049"
            ]
        },
        {
            "instance_id": "R204080xR204067",
            "comparison_id": "R204080",
            "paper_id": "R204067",
            "text": "CodedPrivateML: A fast and privacy-preserving framework for distributed machine learning how to train a machine learning model while keeping the data private and secure? we present codedprivateml, a fast and scalable approach to this critical problem. codedprivateml keeps both the data and the model information-theoretically private, while allowing efficient parallelization of training across distributed workers. we characterize codedprivateml\u2019s privacy threshold and prove its convergence for logistic (and linear) regression. furthermore, via extensive experiments on amazon ec2, we demonstrate that codedprivateml provides significant speedup over cryptographic approaches based on multi-party computing (mpc).",
            "contribution_ids": [
                "R204069"
            ]
        },
        {
            "instance_id": "R204080xR204059",
            "comparison_id": "R204080",
            "paper_id": "R204059",
            "text": "Chameleon: A hybrid secure computation framework for machine learning applications we present chameleon, a novel hybrid (mixed-protocol) framework for secure function evaluation (sfe) which enables two parties to jointly compute a function without disclosing their private inputs. chameleon combines the best aspects of generic sfe protocols with the ones that are based upon additive secret sharing. in particular, the framework performs linear operations in the ring $\\mathbbz _2^l $ using additively secret shared values and nonlinear operations using yao's garbled circuits or the goldreich-micali-wigderson protocol. chameleon departs from the common assumption of additive or linear secret sharing models where three or more parties need to communicate in the online phase: the framework allows two parties with private inputs to communicate in the online phase under the assumption of a third node generating correlated randomness in an offline phase. almost all of the heavy cryptographic operations are precomputed in an offline phase which substantially reduces the communication overhead. chameleon is both scalable and significantly more efficient than the aby framework (ndss'15) it is based on. our framework supports signed fixed-point numbers. in particular, chameleon's vector dot product of signed fixed-point numbers improves the efficiency of mining and classification of encrypted data for algorithms based upon heavy matrix multiplications. our evaluation of chameleon on a 5 layer convolutional deep neural network shows 133x and 4.2x faster executions than microsoft cryptonets (icml'16) and minionn (ccs'17), respectively.",
            "contribution_ids": [
                "R204061"
            ]
        },
        {
            "instance_id": "R204080xR204055",
            "comparison_id": "R204080",
            "paper_id": "R204055",
            "text": "Deepsecure: Scalable provably-secure deep learning this paper presents deepsecure, the an scalable and provably secure deep learning (dl) framework that is built upon automated design, efficient logic synthesis, and optimization methodologies. deepsecure targets scenarios in which neither of the involved parties including the cloud servers that hold the dl model parameters or the delegating clients who own the data is willing to reveal their information. our framework is the first to empower accurate and scalable dl analysis of data generated by distributed clients without sacrificing the security to maintain efficiency. the secure dl computation in deepsecure is performed using yao's garbled circuit (gc) protocol. we devise gc-optimized realization of various components used in dl. our optimized implementation achieves up to 58-fold higher throughput per sample compared with the best prior solution. in addition to the optimized gc realization, we introduce a set of novel low-overhead pre-processing techniques which further reduce the gc overall runtime in the context of dl. our extensive evaluations demonstrate up to two orders-of-magnitude additional runtime improvement achieved as a result of our pre-processing methodology.",
            "contribution_ids": [
                "R204057"
            ]
        },
        {
            "instance_id": "R204080xR204008",
            "comparison_id": "R204080",
            "paper_id": "R204008",
            "text": "Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy applying machine learning to a problem which involves medical, financial, or other types of sensitive data, not only requires accurate predictions but also careful attention to maintaining data privacy and security. legal and ethical requirements may prevent the use of cloud-based machine learning solutions for such tasks. in this work, we will present a method to convert learned neural networks to cryptonets, neural networks that can be applied to encrypted data. this allows a data owner to send their data in an encrypted form to a cloud service that hosts the network. the encryption ensures that the data remains confidential since the cloud does not have access to the keys needed to decrypt it. nevertheless, we will show that the cloud service is capable of applying the neural network to the encrypted data to make encrypted predictions, and also return them in encrypted form. these encrypted predictions can be sent back to the owner of the secret key who can decrypt them. therefore, the cloud service does not gain any information about the raw data nor about the prediction it made. we demonstrate cryptonets on the mnist optical character recognition tasks. cryptonets achieve 99% accuracy and can make around 59000 predictions per hour on a single pc. therefore, they allow high throughput, accurate, and private predictions.",
            "contribution_ids": [
                "R204010"
            ]
        },
        {
            "instance_id": "R204130xR204098",
            "comparison_id": "R204130",
            "paper_id": "R204098",
            "text": "Towards secure and dependable software-defined networks software-defined networking empowers network operators with more flexibility to program their networks. with sdn, network management moves from codifying functionality in terms of low-level device configurations to building software that facilitates network management and debugging. by separating the complexity of state distribution from network specification, sdn provides new ways to solve long-standing problems in networking --- routing, for instance --- while simultaneously allowing the use of security and dependability techniques, such as access control or multi-path. however, the security and dependability of the sdn itself is still an open issue. in this position paper we argue for the need to build secure and dependable sdns by design. as a first step in this direction we describe several threat vectors that may enable the exploit of sdn vulnerabilities. we then sketch the design of a secure and dependable sdn control platform as a materialization of the concept here advocated. we hope that this paper will trigger discussions in the sdn community around these issues and serve as a catalyser to join efforts from the networking and security & dependability communities in the ultimate goal of building resilient control planes.",
            "contribution_ids": [
                "R204100"
            ]
        },
        {
            "instance_id": "R204130xR204104",
            "comparison_id": "R204130",
            "paper_id": "R204104",
            "text": "A comprehensive security architecture for SDN sdn enables the administrators to configure network resources very quickly and to adjust network-wide traffic flow to meet changing needs dynamically. however, there are some challenges for implementing a full-scale carrier sdn. one of the most important challenges is sdn security, which is beginning to receive attention. with new sdn architecture, some security threats are common to traditional networking, but the profile of these threats (including their likelihood and impact and hence their overall risk level) changes. moreover, there are some new security challenges such as bypassing predefined mandatory policies by overwriting flow entries and data eavesdropping by inserting fraudulent flow entries. this paper is to design open-flow specific security solutions and propose a comprehensive security architecture to provide security services such as enforcing mandatory network policy correctly and receiving network policy securely for sdn in order to solve these common security issues and new security challenges. it can also help the developers to implement security functions to provide security services when developing the sdn controller.",
            "contribution_ids": [
                "R204106"
            ]
        },
        {
            "instance_id": "R204130xR204111",
            "comparison_id": "R204130",
            "paper_id": "R204111",
            "text": "OpenSec: A framework for implementing security policies using OpenFlow as the popularity of software defined networks (sdn) and openflow increases, policy-driven network management has received more attention. manual configuration of multiple devices is being replaced by an automated approach where a software-based, network-aware controller handles the configuration of all network devices. software applications running on top of the network controller provide an abstraction of the topology and facilitate the task of operating the network. we propose opensec, an openflow-based security framework that allows a network security operator to create and implement security policies written in human-readable language. using opensec, the user can describe a flow in terms of openflow matching fields, define which security services must be applied to that flow (deep packet inspection, intrusion detection, spam detection, etc) and specify security levels that define how opensec reacts if malicious traffic is detected. we implement opensec in the geni testbed to evaluate the flexibility, accuracy and scalability of the framework. the experimental setup includes deep packet inspection, intrusion detection and network quarantining to secure a web server from network scanners. we achieve a constant delay when reacting to security alerts and a detection rate of 98%.",
            "contribution_ids": [
                "R204113"
            ]
        },
        {
            "instance_id": "R204130xR204114",
            "comparison_id": "R204130",
            "paper_id": "R204114",
            "text": "SDN-based trusted path control security of sensitive data in the network is a key issue in a world where such sensitive data can easily be transferred between different servers and locations (e.g., in networked clouds). in this context, there is a particular need to control the path followed by the data when they move across the cloud (e.g., to avoid crossing -even encrypted- un-trusted nodes or areas). in this paper we proposed therefore a new approach which aims to leverage the programmability offered by the sdn technology in order to enforce a trusted path for the transfer of sensitive data in the network. given a policy related to the sensitive data (e.g., the data should not cross a given area), our approach allows sending this policy to an extended sdn controller (called trusted path controller) which automatically enforces this policy in the sdn network. two architectures have been investigated: the out-of-band architecture (the policy being sent to the trusted path controller via a web service interface) and the in-band architecture (the policy being sent to the trusted path controller via a dedicated \u201csignaling packet\u201d). these two architectures have been implemented in a sdn controller. experimentations and evaluations have also been performed on a test-bed of sdn switches which allow showing the feasibility of this approach as well as its performances.",
            "contribution_ids": [
                "R204116"
            ]
        },
        {
            "instance_id": "R204130xR204108",
            "comparison_id": "R204130",
            "paper_id": "R204108",
            "text": "SIMPLE-fying middlebox policy enforcement using SDN networks today rely on middleboxes to provide critical performance, security, and policy compliance capabilities. achieving these benefits and ensuring that the traffic is directed through the desired sequence of middleboxes requires significant manual effort and operator expertise. in this respect, software-defined networking (sdn) offers a promising alternative. middleboxes, however, introduce new aspects (e.g., policy composition, resource management, packet modifications) that fall outside the purvey of traditional l2/l3 functions that sdn supports (e.g., access control or routing). this paper presents simple, a sdn-based policy enforcement layer for efficient middlebox-specific \"traffic steering''. in designing simple, we take an explicit stance to work within the constraints of legacy middleboxes and existing sdn interfaces. to this end, we address algorithmic and system design challenges to demonstrate the feasibility of using sdn to simplify middlebox traffic steering. in doing so, we also take a significant step toward addressing industry concerns surrounding the ability of sdn to integrate with existing infrastructure and support l4-l7 capabilities.",
            "contribution_ids": [
                "R204110"
            ]
        },
        {
            "instance_id": "R204130xR204083",
            "comparison_id": "R204130",
            "paper_id": "R204083",
            "text": "Lightweight DDoS flooding attack detection using NOX/OpenFlow distributed denial-of-service (ddos) attacks became one of the main internet security problems over the last decade, threatening public web servers in particular. although the ddos mechanism is widely understood, its detection is a very hard task because of the similarities between normal traffic and useless packets, sent by compromised hosts to their victims. this work presents a lightweight method for ddos attack detection based on traffic flow features, in which the extraction of such information is made with a very low overhead compared to traditional approaches. this is possible due to the use of the nox platform which provides a programmatic interface to facilitate the handling of switch information. other major contributions include the high rate of detection and very low rate of false alarms obtained by flow analysis using self organizing maps.",
            "contribution_ids": [
                "R204085"
            ]
        },
        {
            "instance_id": "R204130xR204117",
            "comparison_id": "R204130",
            "paper_id": "R204117",
            "text": "EnforSDN: Network policies enforcement with SDN network services, such as security, load-balancing, and monitoring, are an indisputable part of modern networking infrastructure and are traditionally realized as specialized appliances or middleboxes. middleboxes complicate the management, the deployment, and the operations of the entire network. moreover, they induce network performance issues and scalability limitations by requiring huge amounts of traffic to be, often sub-optimally redirected, and sometimes redundantly processed. recent trends of server virtualization and network function virtualization (nfv) exacerbate these scalability and performance issues. in this paper, we present enforsdn - a new management approach that exploits sdn principles to decouple the policy resolution layer from the policy enforcement layer in network service appliances. our approach improves the enforcement management, network utilization and communication latency, without compromising the policy and the functionality of the network. using emulated sdn-based data center environment, we demonstrate higher throughput and lower latency achieved with enforsdn, as compared to a baseline sdn network. in addition, we show that enforsdn reduces the overall network appliances load, as well as the forwarding tables size.",
            "contribution_ids": [
                "R204119"
            ]
        },
        {
            "instance_id": "R204130xR204127",
            "comparison_id": "R204130",
            "paper_id": "R204127",
            "text": "FLOWGUARD: building robust firewalls for software-defined networks software-defined networking (sdn) introduces significant granularity, visibility and flexibility to networking, but at the same time brings forth new security challenges. one of the fundamental challenges is to build robust firewalls for protecting openflow-based networks where network states and traffic are frequently changed. to address this challenge, we introduce flowguard, a comprehensive framework, to facilitate not only accurate detection but also effective resolution of firewall policy violations in dynamic openflow-based networks. flowguard checks network flow path spaces to detect firewall policy violations when network states are updated. in addition, flowguard conducts automatic and real-time violation resolutions with the help of several innovative resolution strategies designed for diverse network update situations. we also implement our framework and demonstrate the efficacy and efficiency of the proposed detection and resolution approaches in flowguard through experiments with a real-world network topology.",
            "contribution_ids": [
                "R204129"
            ]
        },
        {
            "instance_id": "R204164xR203579",
            "comparison_id": "R204164",
            "paper_id": "R203579",
            "text": "Detection of sinkhole attack in wireless sensor networks generally wireless sensor networks rely of many-to-one communication approach for data gathering. this approach is extremely susceptible to sinkhole attack, where an intruder attracts surrounding nodes with unfaithful routing information, and subsequently presents selective forwarding or change the data that carry through it. a sinkhole attack causes an important threat to sensor networks and it should be considered that the sensor nodes are mostly spread out in open areas and of weak computation and battery power. in order to detect the intruder in a sinkhole attack this paper suggests an algorithm which firstly finds a group of suspected nodes by analyzing the consistency of data. then, the intruder is recognized efficiently in the group by checking the network flow information. the proposed algorithm's performance has been evaluated by using numerical analysis and simulations. therefore, accuracy and efficiency of algorithm would be verified.",
            "contribution_ids": [
                "R203581"
            ]
        },
        {
            "instance_id": "R204164xR203845",
            "comparison_id": "R204164",
            "paper_id": "R203845",
            "text": "Toward a Lightweight Intrusion Detection System for the Internet of Things integration of the internet into the entities of the different domains of human society (such as smart homes, health care, smart grids, manufacturing processes, product supply chains, and environmental monitoring) is emerging as a new paradigm called the internet of things (iot). however, the ubiquitous and wide-range iot networks make them prone to cyberattacks. one of the main types of attack is a denial of service (dos), where the attacker floods the network with a large volume of data to prevent nodes from using the services. an intrusion detection mechanism is considered a chief source of protection for information and communications technology. however, conventional intrusion detection methods need to be modified and improved for application to the iot owing to certain limitations, such as resource-constrained devices, the limited memory and battery capacity of nodes, and specific protocol stacks. in this paper, we develop a lightweight attack detection strategy utilizing a supervised machine learning-based support vector machine (svm) to detect an adversary attempting to inject unnecessary data into the iot network. the simulation results show that the proposed svm-based classifier, aided by a combination of two or three incomplex features, can perform satisfactorily in terms of classification accuracy and detection time.",
            "contribution_ids": [
                "R203850"
            ]
        },
        {
            "instance_id": "R204164xR203623",
            "comparison_id": "R204164",
            "paper_id": "R203623",
            "text": "Intelligent Intrusion Detection in Low-Power IoTs security and privacy of data are one of the prime concerns in today\u2019s internet of things (iot). conventional security techniques like signature-based detection of malware and regular updates of a signature database are not feasible solutions as they cannot secure such systems effectively, having limited resources. programming languages permitting immediate memory accesses through pointers often result in applications having memory-related errors, which may lead to unpredictable failures and security vulnerabilities. furthermore, energy efficient iot devices running on batteries cannot afford the implementation of cryptography algorithms as such techniques have significant impact on the system power consumption. therefore, in order to operate iot in a secure manner, the system must be able to detect and prevent any kind of intrusions before the network (i.e., sensor nodes and base station) is destabilised by the attackers. in this article, we have presented an intrusion detection and prevention mechanism by implementing an intelligent security architecture using random neural networks (rnns). the application\u2019s source code is also instrumented at compile time in order to detect out-of-bound memory accesses. it is based on creating tags, to be coupled with each memory allocation and then placing additional tag checking instructions for each access made to the memory. to validate the feasibility of the proposed security solution, it is implemented for an existing iot system and its functionality is practically demonstrated by successfully detecting the presence of any suspicious sensor node within the system operating range and anomalous activity in the base station with an accuracy of 97.23%. overall, the proposed security solution has presented a minimal performance overhead.",
            "contribution_ids": [
                "R203625"
            ]
        },
        {
            "instance_id": "R204164xR203852",
            "comparison_id": "R204164",
            "paper_id": "R203852",
            "text": "BRIoT: Behavior Rule Specification-Based Misbehavior Detection for IoT-Embedded Cyber-Physical Systems the identification of vulnerabilities in a mission-critical system is one of the challenges faced by a cyber-physical system (cps). the incorporation of embedded internet of things (iot) devices makes it tedious to identify vulnerability and difficult to control the service-interruptions and manage the operations losses. rule-based mechanisms have been considered as a solution in the past. however, rule-based solutions operate on the goodwill of the generated rules and perform assumption-based detection. such a solution often is far from the actual realization of the iot runtime performance and can be fooled by zero-day attacks. thus, this paper takes this issue as motivation and proposes better lightweight behavior rule specification-based misbehavior detection for the iot-embedded cyber-physical systems (briot). the key concept of our approach is to model a system with which misbehavior of an iot device manifested as a result of attacks exploiting the vulnerability exposed may be detected through automatic model checking and formal verification, regardless of whether the attack is known or unknown. automatic model checking and formal verification are achieved through a 2-layer fuzzy-based hierarchical context-aware aspect-oriented petri net (hcapn) model, while effective misbehavior detection to avoid false alarms is achieved through a barycentric-coordinated-based center of mass calculation method. the proposed approach is verified by an unmanned aerial vehicle (uav) embedded in a uav system. the feasibility of the proposed model is demonstrated with high reliability, low operational cost, low false-positives, low false-negatives, and high true positives in comparison with existing rule-based solutions.",
            "contribution_ids": [
                "R203855"
            ]
        },
        {
            "instance_id": "R204164xR203607",
            "comparison_id": "R204164",
            "paper_id": "R203607",
            "text": "Design of sinkhole node detection mechanism for hierarchical wireless sensor networks: Design of sinkhole node detection mechanism for hierarchical wireless sensor networks wireless sensor networks wsns have several applications ranging from the civilian to military applications. wsns are prone to various hole attacks, such as sinkhole, wormhole, blackhole, and greyhole. among these hole attacks, the sinkhole attack is the malignant one. a sinkhole attack allows a malicious node, called the sinkhole node, advertises a best possible path to the base station bs. this misguides its neighbors to utilize that path more frequently. the sinkhole node has the opportunity to tamper with the data, and it also performs the modifications in messages or it drops messages or it produces unnecessary delay before forwarding them to the bs. on the basis of these malicious acts that are performed by a sinkhole attacker node, we consider three types of malicious nodes in a wsn: sinkhole message modification node smd, sinkhole message dropping node sdp, and sinkhole message delay node sdl. none of the existing techniques in the literature is capable to handle all three types of nodes at a time. this paper presents a new detection scheme for the detection of different types of sinkhole nodes for a hierarchical wireless sensor network hwsn. to the best of our knowledge, this is the first attempt to design such a detection scheme in hwsns which can detect smd, sdp, and sdl nodes. in our approach, the entire hwsn is divided into several disjoint clusters, and each cluster has a powerful high-end sensor node called a cluster head, which is responsible for the detection of different sinkhole attacker nodes if present in that cluster. we simulate our scheme using the widely-accepted ns2 simulator for measurement of various network parameters. the proposed scheme achieves around 95% detection rate and 1.25% false positive rate. these factors are significantly better than the previous related schemes. furthermore, the computation and communication efficiency is achieved in our scheme. as a result, our scheme seems suitable for the sensitive critical applications, such as military applications. copyright \u00a9 2016 john wiley & sons, ltd.",
            "contribution_ids": [
                "R203610"
            ]
        },
        {
            "instance_id": "R204164xR203630",
            "comparison_id": "R204164",
            "paper_id": "R203630",
            "text": "A Multi-Level Intrusion Detection System for Wireless Sensor Networks Based on Immune Theory the human body has been, and will continue to be, a source of inspiration for researchers across various disciplines owing to its robustness and myriad of functions. while some of these advancements include the attempt to replicate the entire body to create an artificial self, some tend to use a few characteristics and theories and build upon an artificial subsystem. in this paper, an effort is made to secure a wireless sensor network (wsn) using an immune theory technique called danger theory. in other words, a multi-level intrusion detection system (ids) is designed based on the functions of various immune cells. this is realized by monitoring wsn parameters, such as energy, volume of data and frequency of data transfer and developing an output based on their weights and concentrations which is a suitable basis for ids design in wsns.",
            "contribution_ids": [
                "R203632"
            ]
        },
        {
            "instance_id": "R204164xR202381",
            "comparison_id": "R204164",
            "paper_id": "R202381",
            "text": "Intrusion Detection in Homogeneous and Heterogeneous Wireless Sensor Networks intrusion detection in wireless sensor network (wsn) is of practical interest in many applications such as detecting an intruder in a battlefield. the intrusion detection is defined as a mechanism for a wsn to detect the existence of inappropriate, incorrect, or anomalous moving attackers. for this purpose, it is a fundamental issue to characterize the wsn parameters such as node density and sensing range in terms of a desirable detection probability. in this paper, we consider this issue according to two wsn models: homogeneous and heterogeneous wsn. furthermore, we derive the detection probability by considering two sensing models: single-sensing detection and multiple-sensing detection. in addition, we discuss the network connectivity and broadcast reachability, which are necessary conditions to ensure the corresponding detection probability in a wsn. our simulation results validate the analytical values for both homogeneous and heterogeneous wsns.",
            "contribution_ids": [
                "R202383"
            ]
        },
        {
            "instance_id": "R204209xR204204",
            "comparison_id": "R204209",
            "paper_id": "R204204",
            "text": "A distributed access control system for cloud federations cloud federations are a new collaboration paradigm where organizations share data across their private cloud infrastructures. however, the adoption of cloud federations is hindered by federated organizations' concerns on potential risks of data leakage and data misuse. for cloud federations to be viable, federated organizations' privacy concerns should be alleviated by providing mechanisms that allow organizations to control which users from other federated organizations can access which data. we propose a novel identity and access management system for cloud federations. the system allows federated organizations to enforce attribute-based access control policies on their data in a privacy-preserving fashion. users are granted access to federated data when their identity attributes match the policies, but without revealing their attributes to the federated organization owning data. the system also guarantees the integrity of the policy evaluation process by using block chain technology and intel sgx trusted hardware. it uses block chain to ensure that users identity attributes and access control policies cannot be modified by a malicious user, while intel sgx protects the integrity and confidentiality of the policy enforcement process. we present the access control protocol, the system architecture and discuss future extensions.",
            "contribution_ids": [
                "R204206"
            ]
        },
        {
            "instance_id": "R204209xR204196",
            "comparison_id": "R204209",
            "paper_id": "R204196",
            "text": "Blockchain meets IoT: An architecture for scalable access management in IoT the internet of things (iot) is stepping out of its infancy into full maturity and establishing itself as a part of the future internet. one of the technical challenges of having billions of devices deployed worldwide is the ability to manage them. although access management technologies exist in iot, they are based on centralized models which introduce a new variety of technical limitations to manage them globally. in this paper, we propose a new architecture for arbitrating roles and permissions in iot. the new architecture is a fully distributed access control system for iot based on blockchain technology. the architecture is backed by a proof of concept implementation and evaluated in realistic iot scenarios. the results show that the blockchain technology could be used as access management technology in specific scalable iot scenarios.",
            "contribution_ids": [
                "R204197"
            ]
        },
        {
            "instance_id": "R204209xR204191",
            "comparison_id": "R204209",
            "paper_id": "R204191",
            "text": "FairAccess: a new Blockchain-based access control framework for the Internet of Things security and privacy are huge challenges in internet of things (iot) environments, but unfortunately, the harmonization of the iot-related standards and protocols is hardly and slowly widespread. in this paper, we propose a new framework for access control in iot based on the blockchain technology. our first contribution consists in providing a reference model for our proposed framework within the objectives, models, architecture and mechanism specification in iot. in addition, we introduce fairaccess as a fully decentralized pseudonymous and privacy preserving authorization management framework that enables users to own and control their data. to implement our model, we use and adapt the blockchain into a decentralized access control manager. unlike financial bitcoin transactions, fairaccess introduces new types of transactions that are used to grant, get, delegate, and revoke access. as a proof of concept, we establish an initial implementation with a raspberry pi device and local blockchain. finally, we discuss some limitations and propose further opportunities. copyright \u00a9 2017 john wiley & sons, ltd.",
            "contribution_ids": [
                "R204193"
            ]
        },
        {
            "instance_id": "R204209xR204178",
            "comparison_id": "R204209",
            "paper_id": "R204178",
            "text": "BBDS: Blockchain-based data sharing for electronic medical records in cloud environments disseminating medical data beyond the protected cloud of institutions poses severe risks to patients\u2019 privacy, as breaches push them to the point where they abstain from full disclosure of their condition. this situation negatively impacts the patient, scientific research, and all stakeholders. to address this challenge, we propose a blockchain-based data sharing framework that sufficiently addresses the access control challenges associated with sensitive data stored in the cloud using immutability and built-in autonomy properties of the blockchain. our system is based on a permissioned blockchain which allows access to only invited, and hence verified users. as a result of this design, further accountability is guaranteed as all users are already known and a log of their actions is kept by the blockchain. the system permits users to request data from the shared pool after their identities and cryptographic keys are verified. the evidence from the system evaluation shows that our scheme is lightweight, scalable, and efficient.",
            "contribution_ids": [
                "R204180"
            ]
        },
        {
            "instance_id": "R204209xR204167",
            "comparison_id": "R204209",
            "paper_id": "R204167",
            "text": "Decentralizing privacy: Using blockchain to protect personal data the recent increase in reported incidents of surveillance and security breaches compromising users' privacy call into question the current model, in which third-parties collect and control massive amounts of personal data. bit coin has demonstrated in the financial space that trusted, auditable computing is possible using a decentralized network of peers accompanied by a public ledger. in this paper, we describe a decentralized personal data management system that ensures users own and control their data. we implement a protocol that turns a block chain into an automated access-control manager that does not require trust in a third party. unlike bit coin, transactions in our system are not strictly financial -- they are used to carry instructions, such as storing, querying and sharing data. finally, we discuss possible future extensions to block chains that could harness them into a well-rounded solution for trusted computing problems in society.",
            "contribution_ids": [
                "R204169"
            ]
        },
        {
            "instance_id": "R204209xR204200",
            "comparison_id": "R204209",
            "paper_id": "R204200",
            "text": "Decentralised runtime monitoring for access control systems in cloud federations cloud federation is an emergent cloud-computing paradigm where partner organisations share data and services hosted on their own cloud platforms. in this context, it is crucial to enforce access control policies that satisfy data protection and privacy requirements of partner organisations. however, due to the distributed nature of cloud federations, the access control system alone does not guarantee that its deployed components cannot be circumvented while processing access requests. in order to promote accountability and reliability of a distributed access control system, we present a decentralised runtime monitoring architecture based on blockchain technology.",
            "contribution_ids": [
                "R204202"
            ]
        },
        {
            "instance_id": "R204209xR204188",
            "comparison_id": "R204209",
            "paper_id": "R204188",
            "text": "MeDShare: Trust-less medical data sharing among cloud service providers via blockchain the dissemination of patients\u2019 medical records results in diverse risks to patients\u2019 privacy as malicious activities on these records cause severe damage to the reputation, finances, and so on of all parties related directly or indirectly to the data. current methods to effectively manage and protect medical records have been proved to be insufficient. in this paper, we propose medshare, a system that addresses the issue of medical data sharing among medical big data custodians in a trust-less environment. the system is blockchain-based and provides data provenance, auditing, and control for shared medical data in cloud repositories among big data entities. medshare monitors entities that access data for malicious use from a data custodian system. in medshare, data transitions and sharing from one entity to the other, along with all actions performed on the medshare system, are recorded in a tamper-proof manner. the design employs smart contracts and an access control mechanism to effectively track the behavior of the data and revoke access to offending entities on detection of violation of permissions on data. the performance of medshare is comparable to current cutting edge solutions to data sharing among cloud service providers. by implementing medshare, cloud service providers and other data guardians will be able to achieve data provenance and auditing while sharing medical data with entities such as research and medical institutions with minimal risk to data privacy.",
            "contribution_ids": [
                "R204189"
            ]
        },
        {
            "instance_id": "R204284xR202252",
            "comparison_id": "R204284",
            "paper_id": "R202252",
            "text": "Anonymous Group-Oriented Time-Bound Key Agreement for Internet of Medical Things in Telemonitoring Using Chaotic Maps telemonitoring using the internet of medical things (iomt) enables the seamless communication of physical signs from patients who do not visit healthcare providers. it, therefore, improves the efficiency of healthcare services and patient comfort the quality of life of patients. while providing many benefits, it is associated with challenges concerning energy consumption, privacy, and security. this work addresses those challenges by presenting a new group-oriented time-bound-authenticated key agreement scheme using extended chaotic maps. it provides details on the importance and contribution of this work, investigates the scheme of chien, and elucidates its weaknesses. the security of the proposed scheme is analyzed formally using the burrows\u2013abadi\u2013needham logic and informally through informal discussions about security features, possible attacks, and countermeasures. results of a simulation demonstrate that the proposed scheme has more security functions and is more computationally efficient than other related schemes.",
            "contribution_ids": [
                "R202256"
            ]
        },
        {
            "instance_id": "R204284xR202220",
            "comparison_id": "R204284",
            "paper_id": "R202220",
            "text": "LAKS-NVT: Provably Secure and Lightweight Authentication and Key Agreement Scheme Without Verification Table in Medical Internet of Things wireless body area networks (wbans) and wireless sensor networks (wsns) are important concepts for the internet of things (iot). they have been applied to various healthcare services to ensure that users can access convenient medical services by exchanging physiological data between user and medical server. user physiological data is collected by sensor nodes and sent to medical service providers, doctors, etc. using public channels. however, these channels are vulnerable to various potential attacks, and hence, it is essential to design provably secure and lightweight mutual authentication (ma) schemes for medical iot to protect user privacy and achieve secure communication. a lightweight mutual authentication and key agreement (maka) scheme was designed in 2019 to guarantee user privacy, but we found that the scheme does not withstand impersonation, stolen senor node and leaking verification table attacks, and it does not also ensure anonymity, untraceability and secure mutual authentication. this paper proposes a provably secure and lightweight maka scheme for medical iot, called laks non-verification table (nvt), that does not require a server verification table. we assess laks-nvt\u2019s security against various potential attacks and demonstrate that it achieves secure ma between sensor node and server using burrows-abadi-needham logic. we employ the well-known real-or-random which is random oracle model to prove that laks-nvt provides a session key security. in addition, the formal security verification using the widely-accepted automated validation of internet security protocols and applications (avispa) software tool has been performed and the results show that laks-nvt is also secure. we compare laks-nvt\u2019s performance against contemporary authentication schemes, and verify that it achieves better security and comparable efficiency. the practical perspective of laks-nvt is also carried out via the network simulator 2 (ns2) simulation study.",
            "contribution_ids": [
                "R202225"
            ]
        },
        {
            "instance_id": "R204284xR202265",
            "comparison_id": "R204284",
            "paper_id": "R202265",
            "text": "Multiauthority Access Control With Anonymous Authentication for Personal Health Record a personal health record (phr) system is a smart health system that serves patients and doctors. a phr is usually stored in a cloud and managed by a semitrusted cloud provider. however, there is still a possibility of the exposure of personal health information to semitrusted parties and unauthorized users. to protect the privacy of patients and ensure that patients can control their phrs, a patient-centric phr sharing framework is proposed in this article. in this framework, all phrs are protected with multiauthority attribute-based encryption before outsourcing, which solves the key hosting problem and achieves fine-grained access control to phrs. furthermore, an anonymous authentication between the cloud and the user is proposed to ensure data integrity on the cloud while not exposing the user\u2019s identity during authentication. the proposed authentication is issued from a new online\u2013offline attribute-based signature. it can make the encrypted phrs resist collusion attacks and not be forged during the period of sharing, which enhances patients\u2019 control of their phrs. online\u2013offline and outsourcing decryption also reduces calculation costs and improves operational efficiency. finally, comparisons are given based on numerical experiments.",
            "contribution_ids": [
                "R202270"
            ]
        },
        {
            "instance_id": "R204284xR202278",
            "comparison_id": "R204284",
            "paper_id": "R202278",
            "text": "A Study on CP-ABE-Based Medical Data Sharing System with Key Abuse Prevention and Verifiable Outsourcing in the IoMT Environment recent developments in cloud computing allow data to be securely shared between users. this can be used to improve the quality of life of patients and medical staff in the internet of medical things (iomt) environment. however, in the iomt cloud environment, there are various security threats to the patient\u2019s medical data. as a result, security features such as encryption of collected data and access control by legitimate users are essential. many studies have been conducted on access control techniques using ciphertext-policy attribute-based encryption (cp-abe), a form of attribute-based encryption, among various security technologies and studies are underway to apply them to the medical field. however, several problems persist. first, as the secret key does not identify the user, the user may maliciously distribute the secret key and such users cannot be tracked. second, attribute-based encryption (abe) increases the size of the ciphertext depending on the number of attributes specified. this wastes cloud storage, and computational times are high when users decrypt. such users must employ outsourcing servers. third, a verification process is needed to prove that the results computed on the outsourcing server are properly computed. this paper focuses on the iomt environment for a study of a cp-abe-based medical data sharing system with key abuse prevention and verifiable outsourcing in a cloud environment. the proposed scheme can protect the privacy of user data stored in a cloud environment in the iomt field, and if there is a problem with the secret key delegated by the user, it can trace a user who first delegated the key. this can prevent the key abuse problem. in addition, this scheme reduces the user\u2019s burden when decoding ciphertext and calculates accurate results through a server that supports constant-sized ciphertext output and verifiable outsourcing technology. the goal of this paper is to propose a system that enables patients and medical staff to share medical data safely and efficiently in an iomt environment.",
            "contribution_ids": [
                "R202279"
            ]
        },
        {
            "instance_id": "R204284xR202341",
            "comparison_id": "R204284",
            "paper_id": "R202341",
            "text": "PMsec: Physical Unclonable Function-Based Robust and Lightweight Authentication in the Internet of Medical Things various commercial off-the-shelf components are available for the development of communication-enabled consumer electronics devices. this opens new doors to attackers who can take advantage of various vulnerabilities to attack the entire network and compromise the integrity of the system and the environment. if a malicious device enters the environment and the attacker gains access to the server or transmits malicious data to the server or cloud, the entire network can be jeopardized. to avoid such cases, this paper presents a device authentication scheme which uses physical unclonable functions (pufs) and is suitable for the internet-of-medical-things (iomt). the main advantage of this authentication scheme is that no data related to the iomt devices are stored in server memory. the time taken to authenticate the devices completely was 1.2 s to 1.5 s. a hybrid oscillator arbiter physical unclonable function was used for validation of the proposed authentication scheme. from the puf module used during experimental validation, the number of keys that could be potentially used for the authentication protocol from each design is approximately 240. the proposed authentication scheme increases the robustness of the design while being lightweight to be deployed in various designs and supports scalability.",
            "contribution_ids": [
                "R202346"
            ]
        },
        {
            "instance_id": "R204284xR202226",
            "comparison_id": "R204284",
            "paper_id": "R202226",
            "text": "A Secure and Efficient Cloud-Centric Internet-of-Medical-Things-Enabled Smart Healthcare System With Public Verifiability the potential of the internet-of-medical-things (iomt) technology for interconnecting the biomedical sensors in e-health has ameliorated the people\u2019s living standards. another technology recognized in the recent e-healthcare is outsourcing the medical data to the cloud. there are, however, several stipulations for adopting these two technologies. the most difficult is the privacy of medical data and the challenge resulting from the resource constraint environment of sensor devices. in this article, we present the state-of-the-art secure and efficient cloud-centric iomt-enabled smart healthcare system with public verifiability. the system novelty implements an escrow-free identity-based aggregate signcryption (ef-idasc) scheme to secure data transmission, which is also proposed in this article. the proposed smart healthcare system fetches the medical data from multiple sensors implanted on the patient\u2019s body, signcrypts and aggregates them under the proposed ef-idasc scheme, and outsources the data on the medical cloud server via smartphone. the system does not reveal any information about the identity and medical data of the patient. we further analyze the performance of the proposed smart healthcare system in terms of energy consumption. moreover, we compare the performance of the proposed ef-idasc scheme with other related schemes.",
            "contribution_ids": [
                "R202230"
            ]
        },
        {
            "instance_id": "R204284xR202286",
            "comparison_id": "R204284",
            "paper_id": "R202286",
            "text": "Achieving Searchable and Privacy-Preserving Data Sharing for Cloud-Assisted E-Healthcare System the integration of wearable wireless devices and cloud computing in e-health systems has significantly improved their effectiveness and availability. patients can upload their personal health information (phi) files to the cloud, from where the health service providers (hsps) can obtain appropriate information to determine the health state. this system not only reduces the costs associated to healthcare but also provides timely diagnosis to save lives. however, a number of privacy concerns arise while sharing sensitive information. in this paper, we propose a novel privacy-preserving patient health information sharing scheme, which allows hsps to access and search phi files in a secure yet efficient manner. we make use of the searchable encryption technique with keyword range search and multikeyword search. the proposed privacy-preserving equality test protocol allows different types of numeric comparison searches on encrypted data. we also use a variant of bloom filter and message authentication code to classify phi files, filter false data, and check integrity of search results. the simulations on real-world and synthetic data show the feasibility and efficiency of the system, and security analysis proves the privacy-preservation properties.",
            "contribution_ids": [
                "R202292"
            ]
        },
        {
            "instance_id": "R204284xR202310",
            "comparison_id": "R204284",
            "paper_id": "R202310",
            "text": "FTM-IoMT: Fuzzy-Based Trust Management for Preventing Sybil Attacks in Internet of Medical Things trustworthy transmission is a beneficial step toward the success of the new era of telecommunication technologies and online social networks (osns). many sensitive applications can benefit from osns, e.g., ehealth and medical services. however, osns have always been prey to sybil attacks where numerous fake nodes are being generated and propagated in social networks to mimic like real nodes for the purpose of achieving malicious goals. thus, for security reasons and for the sensitivity of data used in ehealth applications, such fake nodes have to be detected and deactivated immediately. the emerging field of the internet of medical things (iomt) promotes trust management (tm) among various iomt devices to provide accurate and reliable communications, which is quite essential in critical diseases such as covid-19. tm provides a secure platform to iomt devices using different security protocols in the iomt network. generically, if a device is not comfortable to connect with additional devices in a network, the motive of the communication process is not succeeded and leads to disappointment for one device toward others. to handle these types of situations, a tm mechanism, named fuzzy-based tm mechanism for preventing sybil attacks in the internet of medical things (ftm-iomt), is proposed. the ftm-iomt provides tm for the users of ehealth systems using iomt infrastructures. it is an intelligent mechanism to recognize sybil or untrustworthy nodes in the system. the proposed mechanism helps iomt nodes to collect authentic and credible information from their neighboring nodes as well as to neglect sybil nodes. the trust value of a node is evaluated using fuzzy logic processing followed by the trust attributes, such as integrity, receptivity, and compatibility of a node. the ftm-iomt provides a double evaluation check based on fuzzy logic processing and fuzzy filter. the proposed scheme shows superior results when compared to the state-of-the-art approaches.",
            "contribution_ids": [
                "R202315"
            ]
        },
        {
            "instance_id": "R204284xR202354",
            "comparison_id": "R204284",
            "paper_id": "R202354",
            "text": "HARCI: A Two-Way Authentication Protocol for Three Entity Healthcare IoT Networks with the recent use of iot in the field of healthcare, a lot of patient data is being transmitted and made available online. this necessitates sufficient security measures to be put in place to prevent the possibilities of cyberattacks. in this regard, several authentication techniques have been designed in recent times to mitigate these challenges, but the physical security of the healthcare iot devices against node tampering and node replacement attacks, in particular, is not addressed sufficiently in the literature. to address these challenges, a two-way two-stage authentication protocol using hardware security primitives called physical unclonable functions (pufs) is presented in this paper. considering the memory and energy constraints of healthcare iot devices, this protocol is made very lightweight. a formal security evaluation of this protocol is done to prove its validity. we also compare it with relevant protocols in the healthcare iot scenario in terms of computation time and security to show its suitability and robustness.",
            "contribution_ids": [
                "R202359"
            ]
        },
        {
            "instance_id": "R204284xR202334",
            "comparison_id": "R204284",
            "paper_id": "R202334",
            "text": "DeepEDN: A Deep-Learning-Based Image Encryption and Decryption Network for Internet of Medical Things internet of medical things (iomt) can connect many medical imaging equipment to the medical information network to facilitate the process of diagnosing and treating doctors. as medical image contains sensitive information, it is of importance yet very challenging to safeguard the privacy or security of the patient. in this work, a deep-learning-based image encryption and decryption network (deepedn) is proposed to fulfill the process of encrypting and decrypting the medical image. specifically, in deepedn, the cycle-generative adversarial network (cycle-gan) is employed as the main learning network to transfer the medical image from its original domain into the target domain. the target domain is regarded as \u201chidden factors\u201d to guide the learning model for realizing the encryption. the encrypted image is restored to the original (plaintext) image through a reconstruction network to achieve image decryption. in order to facilitate the data mining directly from the privacy-protected environment, a region of interest (roi)-mining network is proposed to extract the interesting object from the encrypted image. the proposed deepedn is evaluated on the chest x-ray data set. extensive experimental results and security analysis show that the proposed method can achieve a high level of security with a good performance in efficiency.",
            "contribution_ids": [
                "R202340"
            ]
        },
        {
            "instance_id": "R204284xR202302",
            "comparison_id": "R204284",
            "paper_id": "R202302",
            "text": "A Secure Three-Factor User Authentication Protocol With Forward Secrecy for Wireless Medical Sensor Network Systems the internet of things (iot) enables all objects to connect to the internet and exchange data via different emerging technologies, which makes the intelligent identification and management a reality. wireless sensor networks (wsns), as a crucial basis of iot, have been applied in many fields like smart health care and smart transportation. with the development of wsns, data security has attracted more and more attention, and user authentication is a popular mechanism to ensure the information security of wsns. recently, many authentication mechanisms for wireless medical sensor networks (wmsns) have been proposed, but most of the protocols cannot achieve the features of local password change and forward secrecy while resisting stolen smart card attack. to enhance the security based on previous work, an ecc-based secure three-factor authentication protocol with forward secrecy for wmsn is proposed in this paper. it utilizes a fuzzy commitment scheme to handle the biometric information. meanwhile, fuzzy verifier and honey_list techniques are used to solve the contradiction of local password verification and mobile device lost attack. the security of our protocol is evaluated by provable security, proverif tool, and information analysis. besides, the comparisons with the relevant protocols are given, and the results indicate that our protocol is robust and secure for wmsn systems.",
            "contribution_ids": [
                "R202309"
            ]
        },
        {
            "instance_id": "R204284xR202298",
            "comparison_id": "R204284",
            "paper_id": "R202298",
            "text": "Trustworthy Delegation Toward Securing Mobile Healthcare Cyber-Physical Systems attribute-based encryption (abe) offers a promising solution for flexible access control over sensitive personal health records in a mobile healthcare system on top of a public cloud infrastructure. however, abe cannot be simply applied to lightweight devices due to its substantial computation cost during decryption. this problem could be alleviated by delegating significant parts of the decryption operations to computationally powerful parties, such as cloud servers, but the correctness of the delegated computation would be at stake. thus, previous works enabled users to validate the partial decryption by employing a cryptographic commitment or message authentication code (mac). this paper demonstrates that the previous commitment or mac-based schemes cannot support verifiability in the presence of potentially malevolent cloud servers. we propose two concrete attacks on previous commitment or mac-based schemes. we propose an effective countermeasure scheme for securing resource-limited mobile healthcare systems and provide a rigorous security proof in the standard model, demonstrating that the proposed scheme is secure against our attacks. the experimental analysis shows that the proposed scheme provides the similar performance compared with the previous commitment-based schemes and outperforms the mac-based scheme.",
            "contribution_ids": [
                "R202301"
            ]
        },
        {
            "instance_id": "R204284xR202244",
            "comparison_id": "R204284",
            "paper_id": "R202244",
            "text": "Three-Factor UCSSO Scheme With Fast Authentication and Privacy Protection for Telecare Medicine Information Systems electronic healthcare (e-health) has gained more and more research attention in recent years, due to its flexibility and convenience. e-health is efficiently enabled by telecare medicine information system (tmis). tmis provides seamless transfer and timely sharing of medical information for specific healthcare services. since communications in tmis are carried out through unreliable channels, data security and user privacy concerns become prominent. with traditional single-server architecture, users must store massive credentials, which causes inefficient communication and significant overhead. moreover, user credentials in previously proposed schemes are stored at server side, suffering potential risks. our work proposes a three-factor user-controlled single sign-on (ucsso) with fast authentication and privacy protection for tmis. the contributions of this paper are as follows. our work integrates three factors including password, smart card and biometrics in authentication procedure, for providing a high-security and privacy-preserved communication. we introduce single sign-on solution that allows users to log in to multiple servers using a single password. user-controlled mechanism is proposed to address insider attacks and the risk that registration center may be compromised. the proposed scheme is designed with fast authentication mechanism that helps to efficiently establishes new session key. our work is proved secure using ban logic, ror model, and avispa toolset. the results of performance comparison show that our scheme provides more security properties and bears the least overhead, compared with competitive schemes.",
            "contribution_ids": [
                "R202251"
            ]
        },
        {
            "instance_id": "R204284xR202232",
            "comparison_id": "R204284",
            "paper_id": "R202232",
            "text": "HERMIT: A Benchmark Suite for the Internet of Medical Things the growth of the internet of things (iot) will transform the healthcare industry, and enable the emergence of the internet of medical things (iomt). in this paper, we present and analyze hermit, a benchmark suite for the iomt. the goal of hermit is to facilitate research into new microarchitectures and optimizations that will enable efficient execution of emerging iomt applications. hermit comprises of applications spanning various domains in the healthcare industry, including computerized tomography scan, ultrasound, magnetic resonance imaging, implantable heart monitors, wearable devices. hermit also includes supplementary applications for security and data compression. we analyze hermit on an iot prototyping platform to derive insights into iomt applications\u2019 compute and memory characteristics. we also compare hermit to three commonly used benchmark suites: 1) mibench; 2) spec cpu2006; and 3) parsec, and show that iomt applications\u2019 characteristics differ from existing benchmarks. our results motivate the need for a new benchmark suite to enable iomt-targeted microarchitecture research.",
            "contribution_ids": [
                "R202235"
            ]
        },
        {
            "instance_id": "R204284xR202318",
            "comparison_id": "R204284",
            "paper_id": "R202318",
            "text": "Efficient Authentication Protocol for Continuous Monitoring in Medical Sensor Networks currently, continuous monitoring on patients with the help of small devices (or sensors), is easy for doctors/nurses to check patients. due to privacy issues, data collected from devices should be protected. thus, a lightweight mutual authentication and key agreement protocol is required among doctors/nurses, trusted servers, sensors and patients. in this paper, we provide a secure protocol which could support continuous monitoring on patients. firstly, user's biometrics will be used to verify users by means of continuous monitoring of physiological data (e.g., ecg signals) in which verification of the patient identity. this could prevent device theft attacks. in addition, dynamic identity is taken to provide user anonymity and mitigate against user traceability. later, we provide informal and formal security analysis to prove that our protocol can establish a session key between the user and sensor after successfully mutually authentication. performance analysis proved our scheme to be competitive in comparison to existing schemes relative to the added security benefits it provides.",
            "contribution_ids": [
                "R202322"
            ]
        },
        {
            "instance_id": "R206187xR206104",
            "comparison_id": "R206187",
            "paper_id": "R206104",
            "text": "Classical abstract nowadays, the world faces the issue of sustainable integrated business network. sustainable development attracts both researchers and industrial practitioners who are focused on the supply chain network design (scnd). in this regard, all economic, environment, and social factors should be considered. contrary to previous works, this paper addresses a sustainable closed-loop supply chain network problem considering by proposing three new heuristics. to the best of our knowledge, a few related studies have developed heuristics to find best solutions via metaheuristic. in this regard, three heuristics are utilized as procedures to generate initial population to start the recent and old employed metaheuristics. red deer algorithm (rda) and genetic algorithm (ga) are utilized. in addition, the parameters of algorithm are tuned by response surface method (rsm) with an modm approach in order to improve the performance of algorithms. the results show the capability of proposed heuristics\u2019 solution for rda.",
            "contribution_ids": [
                "R206107"
            ]
        },
        {
            "instance_id": "R206242xR196754",
            "comparison_id": "R206242",
            "paper_id": "R196754",
            "text": "Quantification of Non-Exhaust Particulate Matter Traffic Emissions and the Impact of COVID-19 Lockdown at London Marylebone Road this research quantifies current sources of non-exhaust particulate matter traffic emissions in london using simultaneous, highly time-resolved, atmospheric particulate matter mass and chemical composition measurements. the measurement campaign ran at marylebone road (roadside) and honor oak park (background) urban monitoring sites over a 12-month period between 1 september 2019 and 31 august 2020. the measurement data were used to determine the traffic increment (roadside\u2013background) and covered a range of meteorological conditions, seasons, and driving styles, as well as the influence of the covid-19 \u201clockdown\u201d on non-exhaust concentrations. non-exhaust particulate matter (pm)10 concentrations were calculated using chemical tracer scaling factors for brake wear (barium), tyre wear (zinc), and resuspension (silicon) and as average vehicle fleet non-exhaust emission factors, using a co2 \u201cdilution approach\u201d. the effect of lockdown, which saw a 32% reduction in traffic volume and a 15% increase in average speed on marylebone road, resulted in lower pm10 and pm2.5 traffic increments and brake wear concentrations but similar tyre and resuspension concentrations, confirming that factors that determine non-exhaust emissions are complex. brake wear was found to be the highest average non-exhaust emission source. in addition, results indicate that non-exhaust emission factors were dependent upon speed and road surface wetness conditions. further statistical analysis incorporating a wider variability in vehicle mix, speeds, and meteorological conditions, as well as advanced source apportionment of the pm measurement data, were undertaken to enhance our understanding of these important vehicle sources.",
            "contribution_ids": [
                "R196759",
                "R200075",
                "R200131"
            ]
        },
        {
            "instance_id": "R206242xR197510",
            "comparison_id": "R206242",
            "paper_id": "R197510",
            "text": "Has COVID-19 Lockdown Affected on Air Quality?\u00e2\u0080\u0094Different Time Scale Case Study in Wroc\u00c5\u0082aw, Poland due to the covid-19 pandemic, there are series of negative economic consequences, however, in limiting mobility and reducing the number of vehicles, positive effects can also be observed, i.e., improvement of air quality. the paper presents an analysis of air quality measured by concentrations of no2, nox and pm2.5 during the most restrictive lockdown from 10 march to 31 may 2020 on the case of wroc\u0142aw. the results were compared with the reference period\u20142016\u20132019. a significant reduction in traffic volume was identified, on average by 26.3%. the greatest reduction in the concentration of no2 and nox was recorded at the station farthest from the city center, characterized by the lowest concentrations: 20.1% and 22.4%. lower reduction in the average concentrations of no2 and nox was recorded at the municipal station (7.9% and 7.7%) and the communication station (6.7% and 10.2%). concentrations of pms in 2020 were on average 15% and 13.4% lower than in the reference period for the traffic station and the background station. the long-term impact of the lockdown on air quality was also examined. the analysis of the concentrations of the pollutants throughout 2020, and in the analyzed period of 2021, indicated that the reduction of concentrations and the improvement in air quality caused by the restrictions should be considered as a temporary anomaly, without affecting long-term changes and trends.",
            "contribution_ids": [
                "R197514",
                "R201083",
                "R201090"
            ]
        },
        {
            "instance_id": "R206242xR204403",
            "comparison_id": "R206242",
            "paper_id": "R204403",
            "text": "Air Quality in the Italian Northwestern Alps during Year 2020: Assessment of the COVID-19 \u00c2\u00abLockdown Effect\u00c2\u00bb from Multi-Technique Observations and Models the effect of covid-19 confinement regulations on air quality in the northwestern alps is assessed here based on measurements at five valley sites in different environmental contexts. surface concentrations of nitrogen oxides (no and no2), ozone (o3), particulate matter (pm2.5 and pm10), together with a thorough microphysical (size), chemical, and optical (light absorption) aerosol characterisation, complemented by observations along the vertical column are considered. even in the relatively pristine environment of the alps, the \u00ablockdown effect\u00bb is well discernible, both in the early confinement phase and in late 2020. the variations observed during the first confinement period in the city of aosta (\u221261% no, \u221243% no2, +5% o3, +9% pm2.5, \u221212% pm10, relative to average 2015\u20132019 conditions) are attributed to the competing effects of air pollution lockdown-induced changes (\u221274%, \u221252%, +18%, \u221213%, \u221227%, relative to the counterfactual scenario for 2020 provided by a predictive statistical model trained on past measurements) and meteorology (+52%, +18%, \u221211%, +25%, +20%, relative to average conditions). these changes agree well with the ones obtained from a chemical transport model with modified emissions according to the restrictions. with regard to column-integrated quantities and vertical profiles, the no2 column density decreases by &gt;20% due to the lockdown, whereas tropospheric aerosols are mainly influenced by large-scale dynamics (transport of secondary particles from the po basin and mineral dust from the sahara desert and the caspian sea), except a shallow layer about 500 m thick close to the surface, possibly sensitive to curtailed emissions (especially exhaust and non-exhaust particles from road traffic and fugitive emissions from the industry).",
            "contribution_ids": [
                "R204408",
                "R204462",
                "R204466",
                "R204469",
                "R204473"
            ]
        },
        {
            "instance_id": "R206242xR201108",
            "comparison_id": "R206242",
            "paper_id": "R201108",
            "text": "Effect of Road Traffic on Air Pollution. Experimental Evidence from COVID-19 Lockdown the increasing concentration of human activities in cities has been leading to a worsening in air quality, thus negatively affecting the lives and health of humans living in urban contexts. transport is one of the main sources of pollution in such environments. several local authorities have therefore implemented strict traffic-restriction measures. the aim of this paper is to evaluate the effectiveness and limitations of these interventions, by analyzing the relationship between traffic flows and air quality. the used dataset contains concentrations of no, no2, nox and pm10, vehicle counts and meteorology, all collected during the covid-19 lockdown in the city of padova (italy), in which severe limitations to contain the spread of the virus simulated long and large-scale traffic restrictions in normal conditions. in particular, statistical tests, correlation analyses and multivariate linear regression models were applied to non-rainy days in 2020, 2018 and 2017, in order to isolate the effect of traffic. analysis indicated that vehicle flows significantly affect no, no2, and nox concentrations, although no evidence of a relationship between traffic and pm10 was highlighted. according to this perspective, measures to limit traffic flows seem to be effective in improving air quality only in terms of reducing nitrogen oxide.",
            "contribution_ids": [
                "R201111",
                "R201118",
                "R201120"
            ]
        },
        {
            "instance_id": "R206258xR196764",
            "comparison_id": "R206258",
            "paper_id": "R196764",
            "text": "Unexpected Impact of COVID-19 Lockdown on the Air Quality in the Metro Atlanta, USA Using Ground-based and Satellite Observations we studied the impact of covid-19 (coronavirus disease 2019) lockdown on the air quality over the atlanta area using satellite and ground-based observations, meteorological reanalysis data and traffic information. unlike other cities, we found the air quality has improved slightly over the atlanta area during the 2020 covid-19 lockdown period (march 14\u2013april 30, 2020), compared to the analogous period of 2019 (march 14\u2013april 30, 2019). ground no2 concentrations have decreased slightly 10.8% and 8.2% over the near-road (nr) and urban ambient (ua) stations, respectively. tropospheric no2 columns have reduced 13%\u201349% over the atlanta area from space-borne observations of tropospheric monitoring instrument (tropomi). ground ozone and pm2.5 have decreased 15.7% and ~5%, respectively. this slight air quality improvement is primarily caused by the reduced human activities, as covid-19 lockdowns have reduced ~50% human activities, measured by traffic volume. higher wind speed and precipitations also make the meteorological conditions favorable to this slight air quality improvement. we have not found a significant improvement in air quality over atlanta amid the lockdown when human activities have reduced ~50%. further studies are needed to understand the impacts of reduced human activities on atmospheric chemistry. we also found tropomi and ground measurements have disagreements on no2 reductions, as collocated tropomi observations revealed ~23% and ~21% reductions of tropospheric no2 columns over nr and ua stations, respectively. several factors may explain this disagreement: first, tropospheric no2 columns and ground no2 concentrations are not necessarily the same, although they are highly correlated in the afternoon;second, meteorological conditions may have different impacts on tropmi and ground measurements. third, tropomi may underestimate tropospheric no2 due to uncertainties from air mass factors. fourth, the uncertainties of chemiluminescence no2 measurements used by ground stations. consequently, studies using space-borne tropospheric no2 column and ground no2 measurements should take these factors into account. \u00a9 the author(s).",
            "contribution_ids": [
                "R196766",
                "R201018",
                "R201025",
                "R201028",
                "R201030"
            ]
        },
        {
            "instance_id": "R206258xR206023",
            "comparison_id": "R206258",
            "paper_id": "R206023",
            "text": "Impact of the COVID-19 Lockdown in a European Regional Monitoring Network (Spain): Are We Free from Pollution Episodes? the impact of the lockdown, during the period from march to june in 2020, upon the air quality of the basque country in northern spain is analyzed. the evaluation accounts for the meteorology of the period. daily and sub-daily analysis of aerosol and ozone records show that the territory was repeatedly affected by episodes of pollutants from outer regions. three episodes of pm10 and ten of pm2.5 were caused by transported anthropogenic european sulfates, african dust, and wildland fires. the region, with a varied orographic climatology, shows high and diverse industrial activity. urban and interurban road traffic of the region decreased by 49% and 53%, respectively, whereas industrial activity showed a lower reduction of 20%. consequently, the average concentrations of no2 in the cities during the period fell to 12.4 \u00b5g\u00b7m\u22123 (\u221245%). ozone showed up to five exceedances of the whoaqg for the daily maximum 8-h average in both rural and urban sites, associated with transport through france and the bay of biscay, under periods of european blocking anticyclones. however, averages showed a moderate decrease (\u221211%) in rural environments, in line with the precursor reductions, and disparate changes in the cities, which reproduced the weekend effect of their historical records. the pm10 decreased less than expected (\u221210% and \u221221%, in the urban and rural environments, respectively), probably caused by the modest decrease of industrial activity around urban sites and favorable meteorology for secondary aerosol formation, which could also influence the lower changes observed in the pm2.5 (\u22121% and +3% at the urban and rural sites, respectively). consequently, in a future low nox traffic emission scenario, the inter-regional pm and ozone control will require actions across various sectors, including the industry and common pollution control strategies.",
            "contribution_ids": [
                "R206033",
                "R206043",
                "R206061",
                "R206063",
                "R206064",
                "R206065",
                "R206066",
                "R206067",
                "R206068",
                "R206069"
            ]
        },
        {
            "instance_id": "R206258xR204403",
            "comparison_id": "R206258",
            "paper_id": "R204403",
            "text": "Air Quality in the Italian Northwestern Alps during Year 2020: Assessment of the COVID-19 \u00c2\u00abLockdown Effect\u00c2\u00bb from Multi-Technique Observations and Models the effect of covid-19 confinement regulations on air quality in the northwestern alps is assessed here based on measurements at five valley sites in different environmental contexts. surface concentrations of nitrogen oxides (no and no2), ozone (o3), particulate matter (pm2.5 and pm10), together with a thorough microphysical (size), chemical, and optical (light absorption) aerosol characterisation, complemented by observations along the vertical column are considered. even in the relatively pristine environment of the alps, the \u00ablockdown effect\u00bb is well discernible, both in the early confinement phase and in late 2020. the variations observed during the first confinement period in the city of aosta (\u221261% no, \u221243% no2, +5% o3, +9% pm2.5, \u221212% pm10, relative to average 2015\u20132019 conditions) are attributed to the competing effects of air pollution lockdown-induced changes (\u221274%, \u221252%, +18%, \u221213%, \u221227%, relative to the counterfactual scenario for 2020 provided by a predictive statistical model trained on past measurements) and meteorology (+52%, +18%, \u221211%, +25%, +20%, relative to average conditions). these changes agree well with the ones obtained from a chemical transport model with modified emissions according to the restrictions. with regard to column-integrated quantities and vertical profiles, the no2 column density decreases by &gt;20% due to the lockdown, whereas tropospheric aerosols are mainly influenced by large-scale dynamics (transport of secondary particles from the po basin and mineral dust from the sahara desert and the caspian sea), except a shallow layer about 500 m thick close to the surface, possibly sensitive to curtailed emissions (especially exhaust and non-exhaust particles from road traffic and fugitive emissions from the industry).",
            "contribution_ids": [
                "R204408",
                "R204462",
                "R204466",
                "R204469",
                "R204473"
            ]
        },
        {
            "instance_id": "R206258xR197510",
            "comparison_id": "R206258",
            "paper_id": "R197510",
            "text": "Has COVID-19 Lockdown Affected on Air Quality?\u00e2\u0080\u0094Different Time Scale Case Study in Wroc\u00c5\u0082aw, Poland due to the covid-19 pandemic, there are series of negative economic consequences, however, in limiting mobility and reducing the number of vehicles, positive effects can also be observed, i.e., improvement of air quality. the paper presents an analysis of air quality measured by concentrations of no2, nox and pm2.5 during the most restrictive lockdown from 10 march to 31 may 2020 on the case of wroc\u0142aw. the results were compared with the reference period\u20142016\u20132019. a significant reduction in traffic volume was identified, on average by 26.3%. the greatest reduction in the concentration of no2 and nox was recorded at the station farthest from the city center, characterized by the lowest concentrations: 20.1% and 22.4%. lower reduction in the average concentrations of no2 and nox was recorded at the municipal station (7.9% and 7.7%) and the communication station (6.7% and 10.2%). concentrations of pms in 2020 were on average 15% and 13.4% lower than in the reference period for the traffic station and the background station. the long-term impact of the lockdown on air quality was also examined. the analysis of the concentrations of the pollutants throughout 2020, and in the analyzed period of 2021, indicated that the reduction of concentrations and the improvement in air quality caused by the restrictions should be considered as a temporary anomaly, without affecting long-term changes and trends.",
            "contribution_ids": [
                "R197514",
                "R201083",
                "R201090"
            ]
        },
        {
            "instance_id": "R206309xR206225",
            "comparison_id": "R206309",
            "paper_id": "R206225",
            "text": "Measurement of movements of the lumbar spine this review is an appraisal of the current methods of measurement of lumbar spine movements. three-dimensional measurement of the movements is technically difficult, and most clinical methods, such as the fingertips-to-floor method, the schober (skin distraction) method and the inclinometers, are able to provide one-dimensional information only. radiographic techniques are able to give accurate measurements of the intervertebral movements in three dimensions, but it has the inherent health risk of repeated x-ray exposure. optoelectronic systems are increasingly popular due to the improvement in camera quality and computer capabilities, but they are rather complex and time-consuming to be suitable for routine clinical use. it appears that electromagnetic tracking system is suitable for measuring three-dimensional spinal movements in a clinical environment. it provides real-time information, and is highly accurate and reliable if adequate precautions are taken to ensure that it is not adversely affected by the presence of metals. finally, this review describes the problems involved in the mathematical computation of anatomical angles. it is concluded that there is a need to further develop the current measurement methods and to employ new technologies to solve some of the methodological problems.",
            "contribution_ids": [
                "R206226"
            ]
        },
        {
            "instance_id": "R206309xR206211",
            "comparison_id": "R206309",
            "paper_id": "R206211",
            "text": "Inertial sensors for motion detection of human upper limbs purpose this paper seeks to present an inertial motion tracking system for monitoring movements of human upper limbs in order to support a home\u2010based rehabilitation scheme in which the recovery of stroke patients' motor function through repetitive exercises needs to be continuously monitored and appropriately evaluated. design/methodology/approach two inertial sensors are placed on the upper and lower arms in order to obtain acceleration and turning rates. then the position of the upper limbs can be deduced by using the kinematical model of the upper limbs that was designed in the previous paper. the tracking system starts from inertial data acquisition and pre\u2010filtering, followed by a number of processes such as transformation of coordinate systems of sensor data, and kinematical modelling and optimization of position estimation. findings the motion detector using the proposed kinematic model only has drifts in the measurements. fusion of acceleration and orientation data can effectively solve the drift problem without the involvement of a kalman filter. research limitations/implications the image rendering is not undertaken when the data sampling is performed. this non\u2010synchronization is applied in order to avoid the breaks in the continuous sampling. originality/value this new motion detector can work in different environments without significant drifts. also, this system only deploys two inertial sensors but is able to estimate the position of the wrist, elbow and shoulder joints.",
            "contribution_ids": [
                "R206212"
            ]
        },
        {
            "instance_id": "R207120xR207093",
            "comparison_id": "R207120",
            "paper_id": "R207093",
            "text": "DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep Learning misinformation such as fake news is one of the big challenges of our society. research on automated fact-checking has proposed methods based on supervised learning, but these approaches do not consider external evidence apart from labeled training instances. recent approaches counter this deficit by considering external sources related to a claim. however, these methods require substantial feature modeling and rich lexicons. this paper overcomes these limitations of prior work with an end-to-end model for evidence-aware credibility assessment of arbitrary textual claims, without any human intervention. it presents a neural network model that judiciously aggregates signals from external evidence articles, the language of these articles and the trustworthiness of their sources. it also derives informative features for generating user-comprehensible explanations that makes the neural network predictions transparent to the end-user. experiments with four datasets and ablation studies show the strength of our method.",
            "contribution_ids": [
                "R207095"
            ]
        },
        {
            "instance_id": "R207120xR207073",
            "comparison_id": "R207120",
            "paper_id": "R207073",
            "text": "FNED: A Deep Network for Fake News Early Detection on Social Media the fast spreading of fake news stories on social media can cause inestimable social harm. developing effective methods to detect them early is of paramount importance. a major challenge of fake news early detection is fully utilizing the limited data observed at the early stage of news propagation and then learning useful patterns from it for identifying fake news. in this article, we propose a novel deep neural network to detect fake news early. it has three novel components: (1) a status-sensitive crowd response feature extractor that extracts both text features and user features from combinations of users\u2019 text response and their corresponding user profiles, (2) a position-aware attention mechanism that highlights important user responses at specific ranking positions, and (3) a multi-region mean-pooling mechanism to perform feature aggregation based on multiple window sizes. experimental results on two real-world datasets demonstrate that our proposed model can detect fake news with greater than 90% accuracy within 5 minutes after it starts to spread and before it is retweeted 50 times, which is significantly faster than state-of-the-art baselines. most importantly, our approach requires only 10% labeled fake news samples to achieve this effectiveness under pu-learning settings.",
            "contribution_ids": [
                "R207075"
            ]
        },
        {
            "instance_id": "R207120xR201542",
            "comparison_id": "R207120",
            "paper_id": "R201542",
            "text": "Cross-modal Ambiguity Learning for Multimodal Fake News Detection cross-modal learning is essential to enable accurate fake news detection due to the fast-growing multimodal contents in online social communities. a fundamental challenge of multimodal fake news detection lies in the inherent ambiguity across different content modalities, i.e., decisions made from unimodalities may disagree with each other, which may lead to inferior multimodal fake news detection. to address this issue, we formulate the cross-modal ambiguity learning problem from an information-theoretic perspective and propose cafe \u2014 an ambiguity-aware multimodal fake news detection method. cafe consists of 1) a cross-modal alignment module to transform the heterogeneous unimodality features into a shared semantic space, 2) a cross-modal ambiguity learning module to estimate the ambiguity between different modalities, and 3) a cross-modal fusion module to capture the cross-modal correlations. cafe improves fake news detection accuracy by judiciously and adaptively aggregating unimodal features and cross-modal correlations, i.e., relying on unimodal features when cross-modal ambiguity is weak and referring to cross-modal correlations when cross-modal ambiguity is strong. experimental studies on two widely used datasets (twitter and weibo) demonstrate that cafe outperforms state-of-the-art fake news detection methods by 2.2-18.9% and 1.7-11.4% on accuracy, respectively.",
            "contribution_ids": [
                "R201544"
            ]
        },
        {
            "instance_id": "R207120xR207111",
            "comparison_id": "R207120",
            "paper_id": "R207111",
            "text": "Weak Supervision for Fake News Detection via Reinforcement Learning today social media has become the primary source for news. via social media platforms, fake news travel at unprecedented speeds, reach global audiences and put users and communities at great risk. therefore, it is extremely important to detect fake news as early as possible. recently, deep learning based approaches have shown improved performance in fake news detection. however, the training of such models requires a large amount of labeled data, but manual annotation is time-consuming and expensive. moreover, due to the dynamic nature of news, annotated samples may become outdated quickly and cannot represent the news articles on newly emerged events. therefore, how to obtain fresh and high-quality labeled samples is the major challenge in employing deep learning models for fake news detection. in order to tackle this challenge, we propose a reinforced weakly-supervised fake news detection framework, i.e., wefend, which can leverage users' reports as weak supervision to enlarge the amount of training data for fake news detection. the proposed framework consists of three main components: the annotator, the reinforced selector and the fake news detector. the annotator can automatically assign weak labels for unlabeled news based on users' reports. the reinforced selector using reinforcement learning techniques chooses high-quality samples from the weakly labeled data and filters out those low-quality ones that may degrade the detector's prediction performance. the fake news detector aims to identify fake news based on the news content. we tested the proposed framework on a large collection of news articles published via wechat official accounts and associated user reports. extensive experiments on this dataset show that the proposed wefend model achieves the best performance compared with the state-of-the-art methods.",
            "contribution_ids": [
                "R207113"
            ]
        },
        {
            "instance_id": "R209290xR209027",
            "comparison_id": "R209290",
            "paper_id": "R209027",
            "text": "Are we ready for autonomous driving? The KITTI vision benchmark suite today, visual recognition systems are still rarely employed in robotics applications. perhaps one of the main reasons for this is the lack of demanding benchmarks that mimic such scenarios. in this paper, we take advantage of our autonomous driving platform to develop novel challenging benchmarks for the tasks of stereo, optical flow, visual odometry/slam and 3d object detection. our recording platform is equipped with four high resolution video cameras, a velodyne laser scanner and a state-of-the-art localization system. our benchmarks comprise 389 stereo and optical flow image pairs, stereo visual odometry sequences of 39.2 km length, and more than 200k 3d object annotations captured in cluttered scenarios (up to 15 cars and 30 pedestrians are visible per image). results from state-of-the-art algorithms reveal that methods ranking high on established datasets such as middlebury perform below average when being moved outside the laboratory to the real world. our goal is to reduce this bias by providing challenging benchmarks with novel difficulties to the computer vision community. our benchmarks are available online at: www.cvlibs.net/datasets/kitti.",
            "contribution_ids": [
                "R209029"
            ]
        },
        {
            "instance_id": "R209290xR209030",
            "comparison_id": "R209290",
            "paper_id": "R209030",
            "text": "Stable multi-target tracking in real-time surveillance video the majority of existing pedestrian trackers concentrate on maintaining the identities of targets, however systems for remote biometric analysis or activity recognition in surveillance video often require stable bounding-boxes around pedestrians rather than approximate locations. we present a multi-target tracking system that is designed specifically for the provision of stable and accurate head location estimates. by performing data association over a sliding window of frames, we are able to correct many data association errors and fill in gaps where observations are missed. the approach is multi-threaded and combines asynchronous hog detections with simultaneous klt tracking and markov-chain monte-carlo data association (mcm-cda) to provide guaranteed real-time tracking in high definition video. where previous approaches have used ad-hoc models for data association, we use a more principled approach based on a minimal description length (mdl) objective which accurately models the affinity between observations. we demonstrate by qualitative and quantitative evaluation that the system is capable of providing precise location estimates for large crowds of pedestrians in real-time. to facilitate future performance comparisons, we make a new dataset with hand annotated ground truth head locations publicly available.",
            "contribution_ids": [
                "R209032"
            ]
        },
        {
            "instance_id": "R209290xR209005",
            "comparison_id": "R209290",
            "paper_id": "R209005",
            "text": "You'll never walk alone: Modeling social behavior for multi-target tracking object tracking typically relies on a dynamic model to predict the object's location from its past trajectory. in crowded scenarios a strong dynamic model is particularly important, because more accurate predictions allow for smaller search regions, which greatly simplifies data association. traditional dynamic models predict the location for each target solely based on its own history, without taking into account the remaining scene objects. collisions are resolved only when they happen. such an approach ignores important aspects of human behavior: people are driven by their future destination, take into account their environment, anticipate collisions, and adjust their trajectories at an early stage in order to avoid them. in this work, we introduce a model of dynamic social behavior, inspired by models developed for crowd simulation. the model is trained with videos recorded from birds-eye view at busy locations, and applied as a motion model for multi-people tracking from a vehicle-mounted camera. experiments on real sequences show that accounting for social interactions and scene knowledge improves tracking performance, especially during occlusions.",
            "contribution_ids": [
                "R209007"
            ]
        },
        {
            "instance_id": "R209290xR209036",
            "comparison_id": "R209290",
            "paper_id": "R209036",
            "text": "Online learning for human classification in 3D LiDAR-based tracking human detection and tracking are essential aspects to be considered in service robotics, as the robot often shares its workspace and interacts closely with humans. this paper presents an online learning framework for human classification in 3d lidar scans, taking advantage of robust multi-target tracking to avoid the need for data annotation by a human expert. the system learns iteratively by retraining a classifier online with the samples collected by the robot over time. a novel aspect of our approach is that errors in training data can be corrected using the information provided by the 3d lidar-based tracking. in order to do this, an efficient 3d cluster detector of potential human targets has been implemented. we evaluate the framework using a new 3d lidar dataset of people moving in a large indoor public space, which is made available to the research community. the experiments analyse the real-time performance of the cluster detector and show that our online learned human classifier matches and in some cases outperforms its offline version.",
            "contribution_ids": [
                "R209038"
            ]
        },
        {
            "instance_id": "R209290xR209048",
            "comparison_id": "R209290",
            "paper_id": "R209048",
            "text": "TH\u00c3\u0096R: Human-Robot Navigation Data Collection and Accurate Motion Trajectories Dataset understanding human behavior is key for robots and intelligent systems that share a space with people. accordingly, research that enables such systems to perceive, track, learn and predict human behavior as well as to plan and interact with humans has received increasing attention over the last years. the availability of large human motion datasets that contain relevant levels of difficulty is fundamental to this research. existing datasets are often limited in terms of information content, annotation quality or variability of human behavior. in this article, we present th\u00f6r, a new dataset with human motion trajectory and eye gaze data collected in an indoor environment with accurate ground truth for position, head orientation, gaze direction, social grouping, obstacles map and goal coordinates. th\u00f6r also contains sensor data collected by a 3d lidar and involves a mobile robot navigating the space. we propose a set of metrics to quantitatively analyze motion trajectory datasets such as the average tracking duration, ground truth noise, curvature and speed variation of the trajectories. in comparison to prior art, our dataset has a larger variety in human motion behavior, is less noisy, and contains annotations at higher frequencies.",
            "contribution_ids": [
                "R209050"
            ]
        },
        {
            "instance_id": "R209290xR209039",
            "comparison_id": "R209290",
            "paper_id": "R209039",
            "text": "Using road topology to improve cyclist path prediction we learn motion models for cyclist path prediction on real-world tracks obtained from a moving vehicle, and propose to exploit the local road topology to obtain better predictive distributions. the tracks are extracted from the tsinghua-daimler cyclist benchmark for cyclist detection, and corrected for vehicle egomotion. tracks are then spatially aligned to local curves and crossings in the road. we study a standard approach for path prediction in the literature based on kalman filters, as well as a mixture of specialized filters related to specific road orientations at junctions. our experiments demonstrate an improved prediction accuracy (up to 20% on sharp turns) of mixing specialized motion models for canonical directions, and prior knowledge on the road topology. the new track data complements the existing video, disparity and annotation data of the original benchmark, and will be made publicly available.",
            "contribution_ids": [
                "R209041"
            ]
        },
        {
            "instance_id": "R209290xR209008",
            "comparison_id": "R209290",
            "paper_id": "R209008",
            "text": "Crowds by Example we present an example\u2010based crowd simulation technique. most crowd simulation techniques assume that the behavior exhibited by each person in the crowd can be defined by a restricted set of rules. this assumption limits the behavioral complexity of the simulated agents. by learning from real\u2010world examples, our autonomous agents display complex natural behaviors that are often missing in crowd simulations. examples are created from tracked video segments of real pedestrian crowds. during a simulation, autonomous agents search for examples that closely match the situation that they are facing. trajectories taken by real people in similar situations, are copied to the simulated agents, resulting in seemingly natural behaviors.",
            "contribution_ids": [
                "R209010"
            ]
        },
        {
            "instance_id": "R209290xR209018",
            "comparison_id": "R209290",
            "paper_id": "R209018",
            "text": "Understanding collective crowd behaviors: Learning a Mixture model of Dynamic pedestrian-Agents in this paper, a new mixture model of dynamic pedestrian-agents (mda) is proposed to learn the collective behavior patterns of pedestrians in crowded scenes. collective behaviors characterize the intrinsic dynamics of the crowd. from the agent-based modeling, each pedestrian in the crowd is driven by a dynamic pedestrian-agent, which is a linear dynamic system with its initial and termination states reflecting a pedestrian's belief of the starting point and the destination. then the whole crowd is modeled as a mixture of dynamic pedestrian-agents. once the model is unsupervisedly learned from real data, mda can simulate the crowd behaviors. furthermore, mda can well infer the past behaviors and predict the future behaviors of pedestrians given their trajectories only partially observed, and classify different pedestrian behaviors in the scene. the effectiveness of mda and its applications are demonstrated by qualitative and quantitative experiments on the video surveillance dataset collected from the new york grand central station.",
            "contribution_ids": [
                "R209020"
            ]
        },
        {
            "instance_id": "R210471xR201427",
            "comparison_id": "R210471",
            "paper_id": "R201427",
            "text": "Written-in Conductive Patterns on Robust Graphene Oxide Biopaper by Electrochemical Microstamping the silk road: by employing silk fibroin as a binder between graphene oxide films and aluminum foil for a facile, highly localized reduction process, conductive paper is reinvented. the flexible, robust biographene papers have high toughness and electrical conductivity. this electrochemical written-in approach is readily applicable for the fabrication of conductive patterned papers with complex circuitries.",
            "contribution_ids": [
                "R201429"
            ]
        },
        {
            "instance_id": "R210471xR203125",
            "comparison_id": "R210471",
            "paper_id": "R203125",
            "text": "Fatigue Resistant Bioinspired Composite from Synergistic Two-Dimensional Nanocomponents portable and wearable electronics require much more flexible graphene-based electrode with high fatigue life, which could repeatedly bend, fold, or stretch without sacrificing its mechanical properties and electrical conductivity. herein, a kind of ultrahigh fatigue resistant graphene-based nanocomposite via tungsten disulfide (ws2) nanosheets is synthesized by introducing a synergistic effect with covalently cross-linking inspired by the orderly layered structure and abundant interfacial interactions of nacre. the fatigue life of resultant graphene-based nanocomposites is more than one million times at the stress level of 270 mpa, and the electrical conductivity can be kept as high as 197.1 s/cm after 1.0 \u00d7 105 tensile testing cycles. these outstanding properties are attributed to the synergistic effect from lubrication of ws2 nanosheets for deflecting crack propagation, and covalent bonding between adjacent go nanosheets for bridging crack, which is verified by the molecular dynamics (md) simulations. the ws2 induced synergistic effect with covalent bonding offers a guidance for constructing graphene-based nanocomposites with high fatigue life, which have great potential for applications in flexible and wearable electronic devices, etc.",
            "contribution_ids": [
                "R203388"
            ]
        },
        {
            "instance_id": "R210471xR203394",
            "comparison_id": "R210471",
            "paper_id": "R203394",
            "text": "Robust Bioinspired Graphene Film via \u00cf\u0080\u00e2\u0080\u0093\u00cf\u0080 Cross-linking graphene composite films inspired by nacre are the subject of ongoing research efforts to optimize their properties for applications in flexible energy devices. noncovalent interactions do not cause interruption of the delocalized conjugated \u03c0-electron system, thus preserving graphene's excellent properties. herein, we synthesized a conjugated molecule with pyrene groups on both ends of a long linear chain (ap-dss) from 1-aminopyrene (ap) and disuccinimidyl suberate (dss). the ap-dss molecules are used to cross-link adjacent graphene nanosheets via \u03c0-\u03c0 interfacial interactions to improve properties of graphene films. the tensile strength and toughness of resultant graphene films were 4.1 and 6.4 times higher, respectively, than that of pure rgo film. more remarkably, the electrical conductivity showed a simultaneous improvement, which is rare to be achieved in other kinds of covalent or noncovalent functionalization. such integration demonstrates the advantage of this work to previously reported noncovalent functionalization of graphene.",
            "contribution_ids": [
                "R203404"
            ]
        },
        {
            "instance_id": "R210471xR203400",
            "comparison_id": "R210471",
            "paper_id": "R203400",
            "text": "Strong, Conductive, Foldable Graphene Sheets by Sequential Ionic and \u00cf\u0080 Bridging the goal of this work is to develop an inexpensive low\u2010temperature process that provides polymer\u2010free, high\u2010strength, high\u2010toughness, electrically conducting sheets of reduced graphene oxide (rgo). to develop this process, we have evaluated the mechanical and electrical properties resulting from the application of an ionic bonding agent (cr3+), a \u03c0\u2013\u03c0 bonding agent comprising pyrene end groups, and their combinations for enhancing the performance of rgo sheets. when only one bonding agent was used, the \u03c0\u2013\u03c0 bonding agent is much more effective than the ionic bonding agent for improving both the mechanical and electrical properties of rgo sheets. however, the successive application of ionic bonding and \u03c0\u2013\u03c0 bonding agents maximizes tensile strength, toughness, long\u2010term electrical stability in various corrosive solutions, and resistance to mechanical abuse and ultrasonic dissolution. using a combination of ionic bonding and \u03c0\u2013\u03c0 bonding agents, high tensile strength (821 mpa), high toughness (20 mj m\u22123), and electrical conductivity (416 s cm\u22121) were obtained, as well as remarkable retention of mechanical and electrical properties during ultrasonication and mechanical cycling by both sheet stretch and sheet folding, suggesting high potential for applications in aerospace and flexible electronics.",
            "contribution_ids": [
                "R203410"
            ]
        },
        {
            "instance_id": "R211056xR209264",
            "comparison_id": "R211056",
            "paper_id": "R209264",
            "text": "SARS\u00e2\u0080\u0090CoV\u00e2\u0080\u00902 endothelial infection causes COVID\u00e2\u0080\u009019 chilblains: histopathological, immunohistochemical and ultrastructural study of seven paediatric cases chilblains (\u2018covid toes\u2019) are being seen with increasing frequency in children and young adults during the covid\u201019 pandemic. detailed histopathological descriptions of covid\u201019 chilblains have not been reported, and causality of sars\u2010cov\u20102 has not yet been established.",
            "contribution_ids": [
                "R209273",
                "R209274"
            ]
        },
        {
            "instance_id": "R211056xR209190",
            "comparison_id": "R211056",
            "paper_id": "R209190",
            "text": "Detection of SARS-CoV-2 genomic and subgenomic RNA in retina and optic nerve of patients with COVID-19 purpose presence of sars-cov-2 rna in human retinal biopsies (rbs) was previously reported by us. in this consecutive study, we analysed rb and optic nerve biopsies (onbs) in deceased patients with confirmed covid-19 assessing viral rna load, possible virus replication and infectivity. patients and methods in this case series, 14 eyes of 14 deceased patients with covid-19 were enucleated during autopsy. rb and onb were subjected to molecular detection of viral rna, virus cultivation and immunohistochemistry. sars-cov-2 rna loads were compared with rna loads in the respective throat swabs, vitreous humour and blood samples. results sars-cov-2 rna was detected in 7/14 rbs and in 10/13 onbs. while virus isolation failed and immunohistochemistry of sars-cov-2 spike protein was negative, subgenomic rna (sgrna) was detectable (40% rb; 60% onb). conclusion sars-cov-2 rna is detectable in rb and onb of patients with covid-19. presence of sgrna could point to a sars-cov-2 infection of neuronal tissue, but as virus isolation failed and immunohistochemistry of sars-cov-2 spike protein was negative, an active infection seems unlikely.",
            "contribution_ids": [
                "R209194",
                "R209208"
            ]
        },
        {
            "instance_id": "R211056xR209211",
            "comparison_id": "R211056",
            "paper_id": "R209211",
            "text": "SARS-CoV-2 Infects Hamster Testes the covid-19 pandemic continues to affect millions of people worldwide. although sars-cov-2 is a respiratory virus, there is growing concern that the disease could cause damage and pathology outside the lungs, including in the genital tract. studies suggest that sars-cov-2 infection can damage the testes and reduce testosterone levels, but the underlying mechanisms are unknown and evidence of virus replication in testicular cells is lacking. we infected golden syrian hamsters intranasally, a model for mild human covid-19, and detected viral rna in testes samples without histopathological changes up to one month post-infection. using an ex vivo infection model, we detected sars-cov-2 replication in hamster testicular cells. taken together, our data raise the possibility that testes damage observed in severe cases of covid-19 could be partly explained by direct sars-cov-2 infection of the testicular cells.",
            "contribution_ids": [
                "R209217",
                "R209221"
            ]
        },
        {
            "instance_id": "R211056xR209162",
            "comparison_id": "R211056",
            "paper_id": "R209162",
            "text": "Evidence of Severe Acute Respiratory Syndrome Coronavirus 2 Replication and Tropism in the Lungs, Airways, and Vascular Endothelium of Patients With Fatal Coronavirus Disease 2019: An Autopsy Case Series abstract background the coronavirus disease 2019 (covid-19) pandemic continues to produce substantial morbidity and mortality. to understand the reasons for the wide-spectrum complications and severe outcomes of covid-19, we aimed to identify cellular targets of severe acute respiratory syndrome coronavirus 2 (sars-cov-2) tropism and replication in various tissues. methods we evaluated rna extracted from formalin-fixed, paraffin-embedded autopsy tissues from 64 case patients (age range, 1 month to 84 years; 21 covid-19 confirmed, 43 suspected covid-19) by sars-cov-2 reverse-transcription polymerase chain reaction (rt-pcr). for cellular localization of sars-cov-2 rna and viral characterization, we performed in situ hybridization (ish), subgenomic rna rt-pcr, and whole-genome sequencing. results sars-cov-2 was identified by rt-pcr in 32 case patients (21 covid-19 confirmed, 11 suspected). ish was positive in 20 and subgenomic rna rt-pcr was positive in 17 of 32 rt-pcr\u2013positive case patients. sars-cov-2 rna was localized by ish in hyaline membranes, pneumocytes, and macrophages of lungs; epithelial cells of airways; and endothelial cells and vessel walls of brain stem, leptomeninges, lung, heart, liver, kidney, and pancreas. the d614g variant was detected in 9 rt-pcr\u2013positive case patients. conclusions we identified cellular targets of sars-cov-2 tropism and replication in the lungs and airways and demonstrated its direct infection in vascular endothelium. this work provides important insights into covid-19 pathogenesis and mechanisms of severe outcomes.",
            "contribution_ids": [
                "R209164",
                "R209185",
                "R209186",
                "R209187"
            ]
        },
        {
            "instance_id": "R211056xR208002",
            "comparison_id": "R211056",
            "paper_id": "R208002",
            "text": "Multiorgan and Vascular Tropism of SARS-CoV-2 although the respiratory tract is the main target of sars-cov-2, other tissues and organs are permissive to the infection. in this report, we investigated this wide-spectrum tropism by studying the sars-cov-2 genetic intra-host variability in multiple tissues. the virological and histological investigation of multiple specimens from a post-mortem covid-19 patient was performed. sars-cov-2 genome was detected in several tissues, including the lower respiratory system, cardio-vascular biopsies, stomach, pancreas, adrenal gland, mediastinal ganglion and testicles. subgenomic rna transcripts were also detected, in favor of an active viral replication, especially in testicles. ultra-deep sequencing allowed us to highlight several sars-cov-2 mutations according to tissue distribution. more specifically, mutations of the spike protein, i.e., v341a (18.3%), e654 (44%) and h655r (30.8%), were detected in the inferior vena cava. sars-cov-2 variability can contribute to heterogeneous distributions of viral quasispecies, which may affect the covid-19 pathogeny.",
            "contribution_ids": [
                "R208010",
                "R208011",
                "R208012",
                "R208013",
                "R208015"
            ]
        },
        {
            "instance_id": "R211935xR193330",
            "comparison_id": "R211935",
            "paper_id": "R193330",
            "text": "Towards Achieving Trust Through Transparency and Ethics the ubiquitous presence of software in the products we use, together with artificial intelligence in these products, has led to an increasing need for consumer trust. consumers often lose faith in products, and the lack of trust propagates to the companies behind them. this is even more so in mission-critical systems such as autonomous vehicles and clinical support systems. this paper follows grounded theory principles to elicit knowledge related to trust, ethics, and transparency. we approach these qualities as non-functional requirements (nfrs), aiming to build catalogs to subsidize the construction of socially responsible software. the corpus we have used was built on a selected collection of literature on corporate social responsibility, with an emphasis on business ethics. our challenge is how to encode the social perspective knowledge, mainly through the view of corporate social responsibility, on how organizations or institutions achieve trustworthiness. since our ground perspective is that of nfrs, results are presented by a catalogue of trust as a non-functional requirement, represented as a softgoal interdependency graph (sig). the sig language helps software engineers in understanding alternatives they have to improve trust in software products.",
            "contribution_ids": [
                "R193331"
            ]
        },
        {
            "instance_id": "R211935xR193295",
            "comparison_id": "R211935",
            "paper_id": "R193295",
            "text": "The practical role of context modeling in the elicitation of context-aware functionalities: a survey context-aware functionalities are functionalities that consider the context to produce a certain system behavior, typically an adaptation or recommendation. as contextual elements such as time, location, weather, user activity, device characteristics, network status, and countless others are becoming increasingly more accessible, the potential for adding context awareness to applications is enormous. identifying novel, unexpected, and even delightful context-aware functionalities in practice can be challenging, though: what context information is relevant for a given user task? how can contextual elements be combined? what if there is a large number of contextual elements? context modeling has been described in the literature as an essential aspect in the elicitation of context-aware functionalities; however, reports on the state of the practice are rare. in this study, we conducted a survey with industrial practitioners, mostly experienced professionals from large enterprises, to investigate how context models and context-modeling activities have been used to support the elicitation of context-aware functionalities. the results indicate a gap between research and industry: context models are rarely used in practice, and context-modeling activities such as analysis of relevance and especially analysis of combinations of contextual elements have been overlooked due to their high complexity, despite practitioners recognizing their importance.",
            "contribution_ids": [
                "R193296"
            ]
        },
        {
            "instance_id": "R211935xR193035",
            "comparison_id": "R211935",
            "paper_id": "R193035",
            "text": "Exploring explainability: a definition, a model, and a knowledge catalogue the growing complexity of software systems and the influence of software-supported decisions in our society awoke the need for software that is transparent, accountable, and trust-worthy. explainability has been identified as a means to achieve these qualities. it is recognized as an emerging non-functional requirement (nfr) that has a significant impact on system quality. however, in order to incorporate this nfr into systems, we need to understand what explainability means from a software engineering perspective and how it impacts other quality aspects in a system. this allows for an early analysis of the benefits and possible design issues that arise from interrelationships between different quality aspects. nevertheless, explainability is currently under-researched in the domain of requirements engineering and there is a lack of conceptual models and knowledge catalogues that support the requirements engineering process and system design. in this work, we bridge this gap by proposing a definition, a model, and a catalogue for explainability. they illustrate how explainability interacts with other quality aspects and how it may impact various quality dimensions of a system. to this end, we conducted an interdisciplinary systematic literature review and validated our findings with experts in workshops.",
            "contribution_ids": [
                "R193037"
            ]
        },
        {
            "instance_id": "R211935xR193070",
            "comparison_id": "R211935",
            "paper_id": "R193070",
            "text": "Non-functional requirements for machine learning: understanding current use and challenges in industry machine learning (ml) is an application of artificial intelligence (ai) that uses big data to produce complex predictions and decision-making systems, which would be challenging to obtain otherwise. to ensure the success of ml-enabled systems, it is essential to be aware of certain qualities of ml solutions (performance, transparency, fairness), known from a requirement engineering (re) perspective as non-functional requirements (nfrs). however, when systems involve ml, nfrs for traditional software may not apply in the same ways; some nfrs may become more prominent or less important; nfrs may be defined over the ml model, data, or the entire system; and nfrs for ml may be measured differently. in this work, we aim to understand the state-of-the-art and challenges of dealing with nfrs for ml in industry. we interviewed ten engineering practitioners working with nfrs and ml. we find examples of (1) the identification and measurement of nfrs for ml, (2) identification of more and less important nfrs for ml, and (3) the challenges associated with nfrs and ml in the industry. this knowledge paints a picture of how ml-related nfrs are treated in practice and helps to guide future re for ml efforts.",
            "contribution_ids": [
                "R193072"
            ]
        },
        {
            "instance_id": "R211935xR193336",
            "comparison_id": "R211935",
            "paper_id": "R193336",
            "text": "Unsupervised Topic Discovery in User Comments on social media platforms like twitter, users regularly share their opinions and comments with software vendors and service providers. popular software products might get thousands of user comments per day. research has shown that such comments contain valuable information for stakeholders, such as feature ideas, problem reports, or support inquiries. however, it is hard to manually manage and grasp a large amount of user comments, which can be redundant and of a different quality. consequently, researchers suggested automated approaches to extract valuable comments, e.g., through problem report classifiers. however, these approaches do not aggregate semantically similar comments into specific aspects to provide insights like how often users reported a certain problem.we introduce an approach for automatically discovering topics composed of semantically similar user comments based on deep bidirectional natural language processing algorithms. stakeholders can use our approach without the need to configure critical parameters like the number of clusters. we present our approach and report on a rigorous multiple-step empirical evaluation to assess how cohesive and meaningful the resulting clusters are. each evaluation step was peer-coded and resulted in inter-coder agreements of up to 98%, giving us high confidence in the approach. we also report a thematic analysis on the topics discovered from tweets in the telecommunication domain.",
            "contribution_ids": [
                "R193337"
            ]
        },
        {
            "instance_id": "R211935xR192445",
            "comparison_id": "R211935",
            "paper_id": "R192445",
            "text": "Automated Traceability for Domain Modelling Decisions Empowered by Artificial Intelligence domain modelling abstracts real-world entities and their relationships in the form of class diagrams for a given domain problem space. modellers often perform domain modelling to reduce the gap between understanding the problem description which expresses requirements in natural language and the concise interpretation of these requirements. however, the manual practice of domain modelling is both time-consuming and error-prone. these issues are further aggravated when problem descriptions are long, which makes it hard to trace modelling decisions from domain models to problem descriptions or vice-versa leading to completeness and conciseness issues. automated support for tracing domain modelling decisions in both directions is thus advantageous. in this paper, we propose an automated approach that uses artificial intelligence techniques to extract domain models along with their trace links. we present a traceability information model to enable traceability of modelling decisions in both directions and provide its proof-of-concept in the form of a tool. the evaluation on a set of unseen problem descriptions shows that our approach is promising with an overall median f2 score of 82.04%. we conduct an exploratory user study to assess the benefits and limitations of our approach and present the lessons learned from this study.",
            "contribution_ids": [
                "R192447"
            ]
        },
        {
            "instance_id": "R211935xR193341",
            "comparison_id": "R211935",
            "paper_id": "R193341",
            "text": "What can Open Domain Model Tell Us about the Missing Software Requirements: A Preliminary Study completeness is one of the most important attributes of software requirement specification. unfortunately, incompleteness is one of the most difficult violations to detect. some approaches have been proposed to detect missing requirements based on the requirement-oriented domain model. however, these kinds of models are actually lack for lots of domains. fortunately, the domain models constructed for different purposes can usually be found online. this raises a question: whether or not these domain models are useful for finding the missing functional information in requirement specification? to explore this question, we design and conduct a preliminary study by computing the overlapping rate between the entities in domain models and the concepts of natural language software requirements, and then digging into four regularities of the occurrence of these entities(concepts) based on two example domains. the usefulness of these regularities, especially the one based our proposed metric ahme (with 54% and 70% of f2 on the two domains), has been initially evaluated with an additional experiment.",
            "contribution_ids": [
                "R193342"
            ]
        },
        {
            "instance_id": "R211935xR193108",
            "comparison_id": "R211935",
            "paper_id": "R193108",
            "text": "Perspectives on Regulatory Compliance in Software Engineering \"compliance reviews within a software organization are internal attempts to verify regulatory and security requirements during product development before its release. however, these reviews are not enough to adequately assess and address regulatory and security requirements throughout a software's development lifecycle. we believe requirements engineers can benefit from an improved understanding of how software practitioners treat and perceive compliance requirements. this paper describes an interview study seeking to understand how regulatory and security standard requirements are addressed, how burdensome they may be for businesses, and how our participants perceived them in the software development lifecycle. we interviewed 15 software practitioners from 13 organizations with different roles in the software development process and working in various industry domains, including big tech, healthcare, data analysis, finance, and small businesses. our findings suggest that, for our participants, the software release process is the ultimate focus for regulatory and security compliance reviews. also, most participants suggested that having a defined process for addressing compliance requirements was freeing rather than burdensome. finally, participants generally saw compliance requirements as an investment for both employees and customers. these findings may be unintuitive, and we discuss seven lessons this work may hold for requirements engineering.\"",
            "contribution_ids": [
                "R193109"
            ]
        },
        {
            "instance_id": "R211935xR192345",
            "comparison_id": "R211935",
            "paper_id": "R192345",
            "text": "On the impact of using different templates on creating and understanding user stories context: user stories are often used for elicitation and prioritisation of requirements. however, the lack of a widely adopted user story template, covering benefit and the usage (or not) of a persona, can affect user stories\u2019 quality, leading to ambiguity, lack of completeness, or accidental complexity. objectives: our goal was to analyse the differences between 4 alternative user story templates when creating and understanding user stories. methods: we conducted a quasi-experiment. we asked 41 participants to perform creation and understanding tasks with the user story templates. we measured their accuracy, using metrics of task success; their speed, with task duration; visual effort, collected with an eye-tracker; and participants\u2019 perceived effort, evaluated with nasa-tlx. results: regarding the impact of the different templates in creating user stories, we observed statistically significant differences in some of the metrics for accuracy, speed and visual effort. for understanding user stories, we observed small differences in terms of visual effort. conclusions: although some templates outperformed others in a few metrics, no template obtained the best overall result. as such, we found no compelling evidence that one template is \"better\" than the others.",
            "contribution_ids": [
                "R192347"
            ]
        },
        {
            "instance_id": "R211935xR193798",
            "comparison_id": "R211935",
            "paper_id": "R193798",
            "text": "Classifying user requirements from online feedback in small dataset environments using deep learning an overwhelming number of users access app repositories like app store/google play and social media platforms like twitter, where they provide feedback on digital experiences. this vast textual corpus comprising user feedback has the potential to unearth detailed insights regarding the users\u2019 opinions on products and services. various tools have been proposed that employ natural language processing (nlp) and traditional machine learning (ml) based models as an inexpensive mechanism to identify requirements in user feedback. however, they fall short on their classification accuracy over unseen data due to factors like the cost of generating voluminous de-biased labeled datasets and general inefficiency. recently, van vliet et al. [1] achieved state-of-the-art results extracting and classifying requirements from user reviews through traditional crowdsourcing. based on their reference classification tasks and outcomes, we successfully developed and validated a deep-learning-backed artificial intelligence pipeline to achieve a state-of-the-art averaged classification accuracy of \u223c87% on standard tasks for user feedback analysis. this approach, which comprises a bert-based sequence classifier, proved effective even in extremely low-volume dataset environments. additionally, our approach drastically reduces the time and costs of evaluation, and improves on the accuracy measures achieved using traditional ml-/nlp-based techniques.",
            "contribution_ids": [
                "R193799"
            ]
        },
        {
            "instance_id": "R211935xR192398",
            "comparison_id": "R211935",
            "paper_id": "R192398",
            "text": "Agile Teams\u00e2\u0080\u0099 Perception in Privacy Requirements Elicitation: LGPD\u00e2\u0080\u0099s compliance in Brazil context: the implementation of the brazilian general data protection law (lgpd) may impact activities carried out by the software development teams. it is necessary for developers to know the existing techniques and tools to carry out privacy requirements elicitation. objectives: in this research, we investigated the perception of agile software development team members from different organizations, regarding the impact that lgpd will have on the activities of the software development process. methods: we conducted an online survey and a systematic literature review to identify the techniques, methodologies and tools used in the literature to perform privacy requirements elicitation in the context of agile software development (asd). in addition, we also investigated the perception of an agile team from a federal public administration organization regarding the impacts of the obligation to develop software in accordance with the lgpd. results: our findings reveal that agile teams know the concepts related to data privacy legislation, but they do not use the techniques proposed in the literature to perform privacy requirements elicitation. in addition, agile teams face problems with outdated software requirements specifications and stakeholders\u2019 lack of knowledge regarding data privacy. conclusions: agile teams need to improve their knowledge on privacy requirements.",
            "contribution_ids": [
                "R192400"
            ]
        },
        {
            "instance_id": "R211935xR193022",
            "comparison_id": "R211935",
            "paper_id": "R193022",
            "text": "Design Decisions in the Construction of Traceability Information Models for Safe Automotive Systems traceability management relies on a supporting model, the traceability information model (tim), that defines which types of relationships exist between which artifacts and contains additional constraints such as multiplicities. constructing a tim that is fit for purpose is crucial to ensure that a traceability strategy yields the desired benefits. however, which design decisions are critical in the construction of tims and which impact they have on the usefulness and applicability of traceability is still an open question. in this paper, we use two cases of tims constructed for safety-critical, automotive systems with industrial safety experts, to identify key design decisions. we also propose a comparison scheme for tims based on a systematic literature review and evaluate the two cases as well as tims from the literature according to the scheme. based on our analyses, we thus derive key insights into tim construction and the design decisions that ensure that a tim is fit for purpose.",
            "contribution_ids": [
                "R193024"
            ]
        },
        {
            "instance_id": "R211935xR192428",
            "comparison_id": "R211935",
            "paper_id": "R192428",
            "text": "Ambiguity and Generality in Natural Language Privacy Policies privacy policies are legal documents containing application data practices. these documents are well-established sources of requirements in software engineering. however, privacy policies are written in natural language, thus subject to ambiguity and abstraction. eliciting requirements from privacy policies is a challenging task as these ambiguities can result in more than one interpretation of a given information type (e.g., ambiguous information type \"device information\" in the statement \"we collect your device information\"). to address this challenge, we propose an automated approach to infer semantic relations among information types and construct an ontology to guide requirements authors in the selection of the most appropriate information type terms. our solution utilizes word embeddings and convolutional neural networks (cnn) to classify information type pairs as either hypernymy, synonymy, or unknown. we evaluate our model on a manually-built ontology, yielding predictions that identify hypernymy relations in information type pairs with 0.904 f-1 score, suggesting a large reduction in effort required for ontology construction.",
            "contribution_ids": [
                "R192430"
            ]
        },
        {
            "instance_id": "R211935xR192386",
            "comparison_id": "R211935",
            "paper_id": "R192386",
            "text": "A Survey of Instructional Approaches in the Requirements Engineering Education Literature requirements engineering (re) has established itself as a core software engineering discipline. it is well acknowledged that good re leads to higher quality software and considerably reduces the risk of failure or exceeding budgets of software development projects. therefore, it is of vital importance to train future software engineers in re and educate future requirements engineers to adequately manage requirements in various projects. however, to date there exists no central concept of what the most useful educational approaches are in re education in order to best interweave theory with practice. to lay the foundation for this important mission, we conducted a systematic literature review. in this paper, we report on the results and provide a synthesis of instructional approaches in re education. findings show that experiential learning through projects, collaboration, and realistic stakeholder involvement are among the most promising trends to teach both re theory and develop student soft skills.",
            "contribution_ids": [
                "R192388"
            ]
        },
        {
            "instance_id": "R212902xR209400",
            "comparison_id": "R212902",
            "paper_id": "R209400",
            "text": "Extending the SAREF ontology for building devices and topology ? in recent years, approaches to model different domains that interact in the iot landscape are constantly emerging, such as the building information one, which includes related sensors, devices and appliances. the saref ontology represents a reference model for smart appliances, originally focused on the smart home domain. this work presents a saref extension for building devices as well as their location.",
            "contribution_ids": [
                "R209402"
            ]
        },
        {
            "instance_id": "R212902xR209379",
            "comparison_id": "R212902",
            "paper_id": "R209379",
            "text": "BOnSAI: a smart building ontology for ambient intelligence this work introduces an ontology for incorporating ambient intelligence in smart buildings. the ontology extends and benefits from existing ontologies in the field, but also adds classes needed to sufficiently model every aspect of a service-oriented smart building system. namely, it includes concepts modeling all functionality (i.e. services, operations, inputs, outputs, logic, parameters and environmental conditions), qos (resources, qos parameters), hardware (smart devices, sensors and actuators, appliances, servers) users and context (user profiles, moods, location, rooms etc.). the ontology is instantiated and put to use at the smart building setting of the international hellenic university, enabling knowledge representation in machine-interpretable form and hence is expected to enhance service-based intelligent applications.",
            "contribution_ids": [
                "R209381"
            ]
        },
        {
            "instance_id": "R212902xR142721",
            "comparison_id": "R212902",
            "paper_id": "R142721",
            "text": "The SEAS Knowledge Model this deliverable concentrates on the results of task 2.2 of work package 2. it describes the seas knowledge model as a basis for semantic interoperability in the seas ecosystem. the seas knowledge model consists of an innovative web ontology that is designed to: (i) meet the current best practices in terms of quality, metadata, and publication, (ii) reuse or align to existing standards, and (iii) cover the required expressivity for the seas use cases, while being extensible to other use cases and domains (gas, water, air, waste management). this document is a snapshot of the situation at the end of the seas project. up-to-date information can be found at the following websites: https://w3id.org/seas/ for the seas knowledge model, and contributing to it; https://w3id.org/pep/ for the process executor platform ontology. deliverable d2.2 seas knowledge model 2 19 december 2016 version 1.0 smart energy aware systems itea2 \u2013 12004",
            "contribution_ids": [
                "R142723",
                "R142755",
                "R143941",
                "R143943",
                "R144802",
                "R144803"
            ]
        },
        {
            "instance_id": "R212902xR209403",
            "comparison_id": "R212902",
            "paper_id": "R209403",
            "text": "BOT: The building topology ontology of the W3C linked building data group actors in the architecture, engineering, construction, owner and operation (aecoo) industry traditionally exchange building models as files. the building information modelling (bim) methodology advocates the seamless exchange of all information between related stakeholders using digital technologies. the ultimate evolution of the methodology, bim maturity level 3, envisions interoperable, distributed, web-based, interdisciplinary information exchange among stakeholders across the life-cycle of buildings. the world wide web consortium linked building data community group (w3c lbd-cg) hypothesises that the linked data models and best practices can be leveraged to achieve this vision in modern web-based applications. in this paper, we introduce the building topology ontology (bot) as a core vocabulary to this approach. it provides a high-level description of the topology of buildings including storeys and spaces, the building elements they contain, and their web-friendly 3d models. we describe how existing applications produce and consume datasets combining bot with other ontologies that describe product catalogues, sensor observations, or internet of things (iot) devices effectively implementing bim maturity level 3. we evaluate our approach by exporting and querying three real-life large building models.",
            "contribution_ids": [
                "R209405"
            ]
        },
        {
            "instance_id": "R25093xR25075",
            "comparison_id": "R25093",
            "paper_id": "R25075",
            "text": "Predicting Personality with Social Behavior \"in this paper, we examine to which degree behavioral measures can be used to predict personality. personality is one factor that dictates people's propensity to trust and their relationships with others. in previous work, we have shown that personality can be predicted relatively accurately by analyzing social media profiles. we demonstrated this using public data from facebook profiles and text from twitter streams. as social situations are crucial in the formation of one's personality, one's social behavior could be a strong indicator of her personality. given most users of social media sites typically have a large number of friends and followers, considering only these aspects may not provide an accurate picture of personality. to overcome this problem, we develop a set of measures based on one's behavior towards her friends and followers. we introduce a number of measures that are based on the intensity and number of social interactions one has with friends along a number of dimensions such as reciprocity and priority. we analyze these features along with a set of features based on the textual analysis of the messages sent by the users. we show that behavioral features are very useful in determining personality and perform as well as textual features.\"",
            "contribution_ids": [
                "R25076"
            ]
        },
        {
            "instance_id": "R25093xR25087",
            "comparison_id": "R25093",
            "paper_id": "R25087",
            "text": "Mining facebook data for predictive personality modeling beyond being facilitators of human interactions, social networks have become an interesting target of research, providing rich information for studying and modeling user\u2019s behavior. identification of personality-related indicators encrypted in facebook profiles and activities are of special concern in our current research efforts. this paper explores the feasibility of modeling user personality based on a proposed set of features extracted from the facebook data. the encouraging results of our study, exploring the suitability and performance of several classification techniques, will also be presented.",
            "contribution_ids": [
                "R25088"
            ]
        },
        {
            "instance_id": "R25093xR25070",
            "comparison_id": "R25093",
            "paper_id": "R25070",
            "text": "Leveraging online social networks and external data sources to predict personality over the past decade, people have been expressing more and more of their personalities online. online social networks such as facebook.com capture much of individuals\\' personalities through their published interests, attributes and social interactions. knowledge of an individual\\'s personality can be of wide utility, either for social research, targeted marketing or a variety of other fields a key problem to predicting and utilizing personality information is the myriad of ways it is expressed across various people, locations and cultures. similarly, a model predicting personality based on online data which cannot be extrapolated to \"real world\" situations is of limited utility for researchers. this paper presents initial work done on generating a probabilistic model of personality which uses representations of people\\'s connections to other people, places, cultures, and ideas, as expressed through face book. to this end, personality was predicted using a machine learning method known as a bayesian network. the model was trained using face book data combined with external data sources to allow further inference. the results of this paper present one predictive model of personality that this project has produced. this model demonstrates the potential of this methodology in two ways: first, it is able to explain up to 56% of all variation in a personality trait from a sample of 615 individuals. second it is able to clearly present how this variability is explained through findings such as how to determine how agreeable a man is based on his age, number of face book wall posts, and his willingness to disclose his preference for music made by lady gaga.",
            "contribution_ids": [
                "R25071"
            ]
        },
        {
            "instance_id": "R25093xR25079",
            "comparison_id": "R25093",
            "paper_id": "R25079",
            "text": "Machine prediction of personality from Facebook profiles \"an increasing number of americans use social networking sites such as facebook, but few fully appreciate the amount of information they share with the world as a result. although studies exist on the sharing of specific types of information (photos, posts, etc.), one area that has been less explored is how facebook profiles can share personality information in a broad, machine-readable fashion. in this study, we apply data-mining and machine learning techniques to predict users' personality traits (specifically, the traits of the big five personality model) using only demographic and text-based attributes extracted from their profiles. we then use these predictions to rank individuals in terms of the five traits, predicting which users will appear in the top or bottom 5% or 10% of these traits. our results show that when using certain models, we can find the top 10% most open individuals with nearly 75% accuracy, and across all traits and directions, we can predict the top 10% with at least 34.5% accuracy (exceeding 21.8%, which is the best accuracy when using just the best-performing profile attribute). these results have privacy implications in terms of allowing advertisers and other groups to focus on a specific subset of individuals based on their personality traits.\"",
            "contribution_ids": [
                "R25080"
            ]
        },
        {
            "instance_id": "R25093xR25091",
            "comparison_id": "R25093",
            "paper_id": "R25091",
            "text": "Towards automated personality identification using speech acts the way people communicate \u2014 be it verbally, visually, or via text\u2013 is indicative of personality traits. in social media the concept of the status update is used for individuals to communicate to their social networks in an always-on fashion. in doing so individuals utilize various kinds of speech acts that, while primarily communicating their content, also leave traces of their personality dimensions behind. we human-coded a set of facebook status updates from the mypersonality dataset in terms of speech acts label and then experimented with surface level linguistic features including lexical, syntactic, and simple sentiment detection to automatically label status updates as their appropriate speech act. we apply supervised learning to the dataset and using our features are able to classify with high accuracy two dominant kinds of acts that have been found to occur in social media. at the same time we used the coded data to perform a regression analysis to determine which speech acts are significant of certain personality dimensions. the implications of our work allow for automatic large-scale personality identification through social media status updates.",
            "contribution_ids": [
                "R25092"
            ]
        },
        {
            "instance_id": "R25093xR25068",
            "comparison_id": "R25093",
            "paper_id": "R25068",
            "text": "Our Twitter Profiles, Our Selves: Predicting Personality with Twitter \"psychological personality has been shown to affect a variety of aspects: preferences for interaction styles in the digital world and for music genres, for example. consequently, the design of personalized user interfaces and music recommender systems might benefit from understanding the relationship between personality and use of social media. since there has not been a study between personality and use of twitter at large, we set out to analyze the relationship between personality and different types of twitter users, including popular users and influentials. for 335 users, we gather personality data, analyze it, and find that both popular users and influentials are extroverts and emotionally stable (low in the trait of neuroticism). interestingly, we also find that popular users are `imaginative' (high in openness), while influentials tend to be `organized' (high in conscientiousness). we then show a way of accurately predicting a user's personality simply based on three counts publicly available on profiles: following, followers, and listed counts. knowing these three quantities about an active user, one can predict the user's five personality traits with a root-mean-squared error below 0.88 on a $[1,5]$ scale. based on these promising results, we argue that being able to predict user personality goes well beyond our initial goal of informing the design of new personalized applications as it, for example, expands current studies on privacy in social media.\"",
            "contribution_ids": [
                "R25069"
            ]
        },
        {
            "instance_id": "R25093xR25085",
            "comparison_id": "R25093",
            "paper_id": "R25085",
            "text": "Recognising personality traits using facebook status updates \"gaining insight in a web user's personality is very valuable for applications that rely on personalisation, such as recommender systems and personalised advertising. in this paper we explore the use of machine learning techniques for inferring a user's personality traits from their facebook status updates. even with a small set of training examples we can outperform the majority class baseline algorithm. furthermore, the results are improved by adding training examples from another source. this is an interesting result because it indicates that personality trait recognition generalises across social media platforms.\"",
            "contribution_ids": [
                "R25086"
            ]
        },
        {
            "instance_id": "R25093xR25081",
            "comparison_id": "R25093",
            "paper_id": "R25081",
            "text": "Private traits and attributes are predictable from digital records of human behavior we show that easily accessible digital records of behavior, facebook likes, can be used to automatically and accurately predict a range of highly sensitive personal attributes including: sexual orientation, ethnicity, religious and political views, personality traits, intelligence, happiness, use of addictive substances, parental separation, age, and gender. the analysis presented is based on a dataset of over 58,000 volunteers who provided their facebook likes, detailed demographic profiles, and the results of several psychometric tests. the proposed model uses dimensionality reduction for preprocessing the likes data, which are then entered into logistic/linear regression to predict individual psychodemographic profiles from likes. the model correctly discriminates between homosexual and heterosexual men in 88% of cases, african americans and caucasian americans in 95% of cases, and between democrat and republican in 85% of cases. for the personality trait \u201copenness,\u201d prediction accuracy is close to the test\u2013retest accuracy of a standard personality test. we give examples of associations between attributes and likes and discuss implications for online personalization and privacy.",
            "contribution_ids": [
                "R25082"
            ]
        },
        {
            "instance_id": "R25115xR25111",
            "comparison_id": "R25115",
            "paper_id": "R25111",
            "text": "How much participation is enough? \"this paper considers the relationship between depth of participation (i.e., the effort and resources invested in participation) versus (tangible) outcomes. the discussion is based on experiences from six participatory research projects of different sizes and durations all taking place within a two year period and all aiming to develop new digital technologies to address an identified social need. the paper asks the fundamental question: how much participation is enough? that is, it challenges the notion that more participation is necessarily better, and, by using the experience of these six projects, it asks whether a more light touch or 'lean' participatory process can still achieve good outcomes, but at reduced cost. the paper concludes that participatory design researchers could consider 'agile' principles from the software development field as one way to streamline participatory processes.\"",
            "contribution_ids": [
                "R25112"
            ]
        },
        {
            "instance_id": "R25115xR25109",
            "comparison_id": "R25115",
            "paper_id": "R25109",
            "text": "Examining participation participatory design (pd) seeks to promote and regulate the negotiation of social change. although many methods claim to be participatory, empirical evidence to support them is lacking. few comprehensive criteria exist to describe and evaluate participation as experienced by stakeholders. there is a need for rigorous research tools to study, validate and improve pd practice. this paper presents the development and initial testing of parte (participation evaluation), an interdisciplinary and intercommunity approach to studying and supporting participation in pd. semi-structured interviews based on the framework showed it to be useful in: a) revealing differences in how stakeholders view participation and design, b) developing a personal frame of participation c) exploration of the future of participatory practices; and d) suggesting actions to resolve specific challenges or contradictions in participation at a broader level. the paper discusses the need to move away from considering pd as a practice claimed by designers towards a more open dialogue between all stakeholders to collective redefine \"participation and design\" for social change.",
            "contribution_ids": [
                "R25110"
            ]
        },
        {
            "instance_id": "R25115xR25105",
            "comparison_id": "R25115",
            "paper_id": "R25105",
            "text": "User gains and PD aims \"we present a study of user gains from their participation in a participatory design (pd) project at danish primary schools. we explore user experiences and reported gains from the project in relation to the multiple aims of pd, based on a series of interviews with pupils, teachers, administrators, and consultants, conducted approximately three years after the end of the project. in particular, we reflect on how the pd initiatives were sustained after the project had ended. we propose that not only are ideas and initiatives disseminated directly within the organization, but also through networked relationships among people, stretching across organizations and project groups. moreover, we demonstrate how users' gains related to their acting within these networks. these results suggest a heightened focus on the indirect and distributed channels through which the long-term impact of pd emerges.\"",
            "contribution_ids": [
                "R25106"
            ]
        },
        {
            "instance_id": "R25115xR25097",
            "comparison_id": "R25115",
            "paper_id": "R25097",
            "text": "A retrospective look at PD projects w h i l e m o d e r n m e t h o d s f o r i n f o r m a t i o n s y s t e m d e v e l o p m e n t g e n e r a l l y a c c e p t t h a t u s e r s s h o u l d b e i n v o l v e d in s o m e w a y [15], t h e f o r m o f t h e i n v o l v e m e n t d i f f e r s c o n s i d e r a b l y . m o s t l y , u s e r s a r e v i e w e d a s r e l a t i v e l y p a s s i v e s o u r c e s o f i n f o r m a t i o n , a n d t h e i n v o l v e m e n t is r e g a r d e d a s \" f u n c t i o n a l , \" in t h e s e n s e t h a t i t s h o u l d y i e l d b e t t e r s y s t e m r e q u i r e m e n t s a n d i n c r e a s e d a c c e p t a n c e b y u s e r s .",
            "contribution_ids": [
                "R25098"
            ]
        },
        {
            "instance_id": "R25160xR25118",
            "comparison_id": "R25160",
            "paper_id": "R25118",
            "text": "VisionSense: an advanced lateral collision warning system visionsense is an advanced driver assistance system which combines a lateral collision warning system with vehicle-to-vehicle communication. this paper shows the results of user needs assessment and traffic safety modelling of visionsense. user needs were determined by means of a web-based survey. the results show, that visionsense is most appreciated when it uses a light signal to warn the driver in a possibly hazardous situation on a highway. the willingness to pay is estimated at 300 euros. another conclusion based on the survey is that frequent car users want less assistance than less frequent drivers. besides the user needs the impact on traffic safety is modelled. the results are indicative and more research has to be done. traffic safety effects of visionsense on a highway were modelled by means of a microscopic car following and lane change algorithm. twelve different traffic scenarios were modelled with and without visionsense. with visionsense no traffic conflicts occur due to lane changing and less lane changes are performed. visionsense is a system that can improve traffic safety in the future.",
            "contribution_ids": [
                "R25119"
            ]
        },
        {
            "instance_id": "R25160xR25139",
            "comparison_id": "R25160",
            "paper_id": "R25139",
            "text": "LED-A-pillars as the chassis of cars become more robust, the pillars of a car become broader in order to increase driver safety. as a-pillars grow wider, so too does their negative affect on the panoramic view of the driver and with a smaller field of vision, the risk of overlooking a pedestrian or an object outside the car increases. in order to deal with a-pillar blind spots, this project examined how distances and directions of possible obstacles can be displayed and how different visualization types with led strips on the a-pillars can affect drivers perception. the result of this study shows that such a prototype improves the panoramic view for car drivers resulting in higher security for road users.",
            "contribution_ids": [
                "R25140"
            ]
        },
        {
            "instance_id": "R25160xR25144",
            "comparison_id": "R25160",
            "paper_id": "R25144",
            "text": "GPS enabled speed control embedded system speed limiting device with display and engine control interface \"in the past decade, there have been close to 350,000 fatal crashes in the united states [1]. with various improvements in traffic and vehicle safety, the number of such crashes is decreasing every year. one of the ways to reduce vehicle crashes is to prevent excessive speeding in the roads and highways. the paper aims to outline the design of an embedded system that will automatically control the speed of a motor vehicle based on its location determined by a gps device. the embedded system will make use of an avr atmega128 microcontroller connected to an em-406a gps receiver. the large amount of location input data justifies the use of an atmega128 microcontroller which has 128kb of programmable flash memory as well as 4kb sram, and a 4kb eeprom memory [2]. the output of the atmega128 will be a dogmi63w-a lcd module which will display information of the current and the set-point speed of the vehicle at the current position. a discrete indicator led will flash at a pre-determined frequency when the speed of the vehicle has exceeded the recommended speed limit. finally, the system will have outputs that will communicate with the engine control unit (ecu) of the vehicle. for the limited scope of this project, the ecu is simulated as an external device with two inputs that will acknowledge pulse-trains of particular frequencies to limit the speed of a vehicle. the speed control system will be programmed using mixed language c and assembly with the latter in use for some pre-written subroutines to drive the lcd module. the gps module will transmit national marine electronics association (nmea) data strings to the microcontroller (mcu) using serial peripheral interface (spi). the mcu will use the location coordinates (latitude and longitude) and the speed from the nmea rmc output string. the current speed is then compared against the recommended speed for the vehicle's location. the memory locations in the atmega128 can be used to store set-point speed values against a particular set of location co-ordinates. apart from its implementation in human operated vehicles, the project can be used to control speed of autonomous cars and to implement the idea of a variable speed limit on roads introduced by the department of transportation [3].\"",
            "contribution_ids": [
                "R25145"
            ]
        },
        {
            "instance_id": "R25160xR25156",
            "comparison_id": "R25160",
            "paper_id": "R25156",
            "text": "heart rate electric vehicles (evs) are an emerging technology and open up an exciting new space for designing in-car interfaces. this technology enhances driving experience by a strong acceleration, regenerative breaking and especially a reduced noise level. however, engine vibrations and sound transmit valuable feedback to drivers of conventional cars, e.g. signaling that the engine is running and ready to go. we address this lack of feedback with heartbeat, a multimodal electric vehicle information system. heartbeat communicates (1) the state of the electric drive including energy flow and (2) the energy level of the batteries in a natural and experienceable way. we enhance the underlying experience design process by formulating working principles derived from an experience story in order to transport its essence throughout the following design phases. this way, we support the design of a consistent experience and resolve the tension between implementation constraints (e.g., space) and the persistence of the underlying story while building prototypes and integrating them into a technical environment (e.g., a dashboard).",
            "contribution_ids": [
                "R25157"
            ]
        },
        {
            "instance_id": "R25160xR25158",
            "comparison_id": "R25160",
            "paper_id": "R25158",
            "text": "TactiCar while deciding if it is possible to overtake a slower car, drivers have to take several factors into account. accident statistics show that many drivers make mistakes in this sit-uation. we want to assist drivers during lane change deci-sion without raising his or her mental workload. since vision is already highly loaded to assess the situation, we address vibration in this work and investigated if it is possible to con-tinuously inform drivers about a closing car using a vibro-tactile belt. we developed two different tactile patterns and tested them in a driving simulator. both patterns achieved promising results regarding usability. in the future, we plan to refine the patterns and evaluate the impact on workload and safety.",
            "contribution_ids": [
                "R25159"
            ]
        },
        {
            "instance_id": "R25160xR25142",
            "comparison_id": "R25160",
            "paper_id": "R25142",
            "text": "A large-scale LED array to support anticipatory driving we present a novel assistance system which supports anticipatory driving by means of fostering early deceleration. upcoming technologies like car2x communication provide information about a time interval which is currently uncovered. this information shall be used in the proposed system to inform drivers about future situations which require reduced speed. such situations include traffic jams, construction sites or speed limits. the hmi is an optical output system based on line arrays of rgb-leds. our contribution presents construction details as well as user evaluations. the results show an earlier deceleration of 3.9 \u2013 11.5 s and a shorter deceleration distance of 2 \u2013 166 m.",
            "contribution_ids": [
                "R25143"
            ]
        },
        {
            "instance_id": "R25160xR25149",
            "comparison_id": "R25160",
            "paper_id": "R25149",
            "text": "Simple gaze-contingent cues guide eye movements in a realistic driving simulator looking at the right place at the right time is a critical component of driving skill. therefore, gaze guidance has the potential to become a valuable driving assistance system. in previous work, we have already shown that complex gaze-contingent stimuli can guide attention and reduce the number of accidents in a simple driving simulator. we here set out to investigate whether cues that are simple enough to be implemented in a real car can also capture gaze during a more realistic driving task in a high-fidelity driving simulator. we used a state-of-the-art, wide-field-of-view driving simulator with an integrated eye tracker. gaze-contingent warnings were implemented using two arrays of light-emitting diodes horizontally fitted below and above the simulated windshield. thirteen volunteering subjects drove along predetermined routes in a simulated environment popu lated with autonomous traffic. warnings were triggered during the approach to half of the intersections, cueing either towards the right or to the left. the remaining intersections were not cued, and served as controls. the analysis of the recorded gaze data revealed that the gaze-contingent cues did indeed have a gaze guiding effect, triggering a significant shift in gaze position towards the highlighted direction. this gaze shift was not accompanied by changes in driving behaviour, suggesting that the cues do not interfere with the driving task itself.",
            "contribution_ids": [
                "R25150"
            ]
        },
        {
            "instance_id": "R25160xR25151",
            "comparison_id": "R25160",
            "paper_id": "R25151",
            "text": "Light my way \"in demanding driving situations, the front-seat passenger can become a supporter of the driver by, e.g., monitoring the scene or providing hints about upcoming hazards or turning points. a fast and efficient communication of such spatial information can help the driver to react properly, with more foresight. as shown in previous research, this spatial referencing can be facilitated by providing the driver a visualization of the front-seat passenger's gaze. in this paper, we focus on the question how the gaze should be visualized for the driver, taking into account the feasibility of implementation in a real car. we present the results from a driving simulator study, where we compared an led visualization (glowing leds on an led stripe mounted at the bottom of the windshield, indicating the horizontal position of the gaze) with a visualization of the gaze as a dot in the simulated environment. our results show that led visualization comes with benefits with regard to driver distraction but also bears disadvantages with regard to accuracy and control for the front-seat passenger.\"",
            "contribution_ids": [
                "R25152"
            ]
        },
        {
            "instance_id": "R25160xR25146",
            "comparison_id": "R25160",
            "paper_id": "R25146",
            "text": "ChaseLight in order to support drivers to maintain a predefined driving speed, we introduce chaselight, an in-car system that uses a programmable led stripe mounted along the a-pillar of a car. the chase light (i.e., stripes of adjacent leds that are turned on and off frequently to give the illusion of lights moving along the stripe) provides ambient feedback to the driver about speed. we present a simulator based user study that uses three different types of feedback: (1) chase light with constant speed, (2) with proportional speed (i.e., chase light speed correlates with vehicle speed), and (3) with adaptive speed (i.e., chase light speed adapts to a target speed of the vehicle). our results show that the adaptive condition is suited best to help a driver to control driving speed. the proportional speed condition resulted in a significantly slower mean speed than the baseline condition (no chase light).",
            "contribution_ids": [
                "R25147"
            ]
        },
        {
            "instance_id": "R25160xR25135",
            "comparison_id": "R25160",
            "paper_id": "R25135",
            "text": "Integrating Off-Board Cameras and Vehicle On-Board Localization for Pedestrian Safety \"situational awareness for industrial vehicles is crucial to ensure safety of personnel and equipment. while human drivers and onboard sensors are able to detect obstacles and pedestrians within line-of-sight, in complex environments, initially occluded or obscured dynamic objects can unpredictably enter the path of a vehicle. we propose a system that integrates a vision-based offboard pedestrian tracking subsystem with an onboard localization and navigation subsystem. this combination enables warnings to be communicated and effectively extends the vehicle controller's field of view to include areas that would otherwise be blind spots. a simple flashing light interface in the vehicle cabin provides a clear and intuitive interface to alert drivers of potential collisions. alternatively, the system can be also applied to vehicles that have autonomous navigation capabilities, in which case, instead of alert lights, the vehicle is halted or redirected. we implemented and tested the proposed solution on an automated industrial vehicle under autonomous operation and on a human-driven vehicle in a full-scale production facility, over a period of four months.\"",
            "contribution_ids": [
                "R25136"
            ]
        },
        {
            "instance_id": "R25160xR25154",
            "comparison_id": "R25160",
            "paper_id": "R25154",
            "text": "A color scenario of Eco & Healthy Driving for the RGB LED based interface display of a climate control device the study demonstrates a process of synergizing both exploratory and confirmatory research approaches to design the color for a luminescent surface facilitated by rgb leds. focusing on the relationship between color and in-door climate of automobiles, the study consists of three parts: in part i, a workshop of ten designers was executed in which ideas were exploited to find in-car scenarios. the scenarios were evaluated based on the criteria of interesting, informative, and inspiring aspects to conclusively derive the scenario labeled \u201ceco & healthy driving\u201d in part ii, a user test was carried out to investigate the relationship between the attributes of luminescent color-hue, brightness, and purity- and an indoor climate condition. in the user test (n= 36), subjects were instructed to match a luminescent color to a given in-car climate condition. the user test results revealed that hue category of luminescent surface is related to temperature while brightness of luminescent color is correlated with blow level; lastly, in part iii, by employing the results of user test, a guideline for implementing the new design scenario, \u201ceco & healthy driving\u201d was projected for further development and application.",
            "contribution_ids": [
                "R25155"
            ]
        },
        {
            "instance_id": "R25201xR25180",
            "comparison_id": "R25201",
            "paper_id": "R25180",
            "text": "Off-line English and Chinese Signature Identification Using Foreground and Background Features in the field of information security, the usage of biometrics is growing for user authentication. automatic signature recognition and verification is one of the biometric techniques, which is only one of several used to verify the identity of individuals. in this paper, a foreground and background based technique is proposed for identification of scripts from bi-lingual (english/roman and chinese) off-line signatures. this system will identify whether a claimed signature belongs to the group of english signatures or chinese signatures. the identification of signatures based on its script is a major contribution for multi-script signature verification. two background information extraction techniques are used to produce the background components of the signature images. gradient-based method was used to extract the features of the foreground as well as background components. zernike moment feature was also employed on signature samples. support vector machine (svm) is used as the classifier for signature identification in the proposed system. a database of 1120 (640 english+480 chinese) signature samples were used for training and 560 (320 english+240 chinese) signature samples were used for testing the proposed system. an encouraging identification accuracy of 97.70% was obtained using gradient feature from the experiment.",
            "contribution_ids": [
                "R25181"
            ]
        },
        {
            "instance_id": "R25201xR25193",
            "comparison_id": "R25201",
            "paper_id": "R25193",
            "text": "Discriminative DCT: An Efficient and Accurate Approach for Off-line Signature Verification in this paper, we proposed to combine the transform based approach with dimensionality reduction technique for off-line signature verification. the proposed approach has four major phases: preprocessing, feature extraction, feature reduction and classification. in the feature extraction phase, discrete cosine transform (dct) is employed on the signature image to obtain the upper-left corner block of size mx n as a representative feature vector. these features are subjected to linear discriminant analysis (lda) for further reduction and representing the signature with optimal set of features. thus obtained features from all the samples in the dataset form the knowledge base. the support vector machine (svm), a bilinear classifier is used for classification and the performance is measured through far/frr metric. experiments have been conducted on standard signature datasets namely cedar and gpds-160, and mukos, a regional language (kannada) dataset. the comparative study is also provided with the well known approaches to exhibit the performance of the proposed approach.",
            "contribution_ids": [
                "R25194"
            ]
        },
        {
            "instance_id": "R25201xR25191",
            "comparison_id": "R25201",
            "paper_id": "R25191",
            "text": "GMM For Offline Signature Forgery Detection as signature continues to play a crucial part in personal identification for number of applications including financial transaction, an efficient signature authentication system becomes more and more important. various researches in the field of signature authentication has been dynamically pursued for many years and its extent is still being explored. signature verification is the process which is carried out to determine whether a given signature is genuine or forged. it can be distinguished into two types such as the online and the offline. in this paper we presented the offline signature verification system and extracted some new local and geometric features like quadsurface feature, area ratio, distance ratio etc. for this we have taken some genuine signatures from 5 different persons and extracted the features from all of the samples after proper preprocessing steps. the training phase uses gaussian mixture model (gmm) technique to obtain a reference model for each signature sample of a particular user. by computing euclidian distance between reference signature and all the training sets of signatures, acceptance range is defined. if the euclidian distance of a query signature is within the acceptance range then it is detected as an authenticated signature else, a forged signature.",
            "contribution_ids": [
                "R25192"
            ]
        },
        {
            "instance_id": "R25201xR25163",
            "comparison_id": "R25201",
            "paper_id": "R25163",
            "text": "Applying Dissimilarity Representation to Off-line Signature Verification in this paper, a two-stage off-line signature verification system based on dissimilarity representation is proposed. in the first stage, a set of discrete left-to-right hmms trained with different number of states and codebook sizes is used to measure similarity values that populate new feature vectors. then, these vectors are input to the second stage, which provides the final classification. experiments were performed using two different classification techniques -- adaboost, and random subspaces with svms -- and a real-world signature verification database. results indicate that the performance is significantly better with the proposed system over other reference signature verification systems from literature.",
            "contribution_ids": [
                "R25164"
            ]
        },
        {
            "instance_id": "R25201xR25182",
            "comparison_id": "R25201",
            "paper_id": "R25182",
            "text": "Off-line Signature Verification Based on Chain Code Histogram and Support Vector Machine \"in this paper, we present an approach based on chain code histogram features enhanced through laplacian of gaussian filter for off-line signature verification. in the proposed approach, the four-directional chain code histogram of each grid on the contour of the signature image is extracted. the laplacian of gaussian filter is used to enhance the extracted features of each signature sample. thus, the extracted and enhanced features of all signature samples of the off-line signature dataset constitute the knowledge base. subsequently, the support vector machine (svm) classifier is used as the verification tool. the svm is trained with the randomly selected training sample's features including genuine and random forgeries and tested with the remaining untrained genuine along with the skilled forge sample features to classify the tested/questioned sample as genuine or forge. similar to the real time scenario, in the proposed approach we have not considered the skilled fore sample to train the classifier. extensive experimentations have been conducted to exhibit the performance of the proposed approach on the publicly available datasets namely, cedar, gpds-100 and mukos, a regional language dataset. the state-of-art off-line signature verification methods are considered for comparative study to justify the feasibility of the proposed approach for off-line signature verification and to reveal its accuracy over the existing approaches.\"",
            "contribution_ids": [
                "R25183"
            ]
        },
        {
            "instance_id": "R25201xR25188",
            "comparison_id": "R25201",
            "paper_id": "R25188",
            "text": "Offline Signature Verification Using Shape Dissimilarities \"offline signature verification is a challenging and important form of biometric identification. other biometric measures don't have variability as that of signatures which poses difficult problem in verification of signatures. in this paper, we explore a novel approach for verification of signatures based on curve matching using shape descriptor and euclidian distance. in our approach, the measurement of similarities are proceeded by 1)finding correspondences between signatures, we attach shape descriptor (shape context) with euclidian distance between the sample points of one signature and the sample point of other signature for better results, 2)we estimate aligning transforms by using this correspondences between signatures, 3) classify the signatures using linear discriminant analysis and measures of shape dissimilarity between signatures based on shape context distance, bending energy, registration residual, anisotropic scaling.\"",
            "contribution_ids": [
                "R25189"
            ]
        },
        {
            "instance_id": "R25201xR25172",
            "comparison_id": "R25201",
            "paper_id": "R25172",
            "text": "Off-line Signature Verification Using Flexible Grid Features and Classifier Fusion in this paper we present two novel off-line signature verification systems, constructed by combining an ensemble of eight base classifiers. both score-based and decision-based fusion strategies are investigated. each base classifier utilises the novel flexible grid-based feature extraction technique proposed in this paper. we show that the flexible grid-based approach consistently outperforms the existing rigid grid-based approach. we also show that the combined classifiers outperform the most proficient base classifier. when evaluated on dolfing\u2019s data set, a signature database containing 1530 genuine signatures and 3000 amateur skilled forgeries, we show that the combined classifiers presented in this paper outperform existing systems that were also evaluated on this data set.",
            "contribution_ids": [
                "R25173"
            ]
        },
        {
            "instance_id": "R25223xR25209",
            "comparison_id": "R25223",
            "paper_id": "R25209",
            "text": "Distributed Selfish Replication a commonly employed abstraction for studying the object placement problem for the purpose of internet content distribution is that of a distributed replication group. in this work, the initial model of the distributed replication group of leff et al. [check end of sentence] is extended to the case that individual nodes act selfishly, i.e., cater to the optimization of their individual local utilities. our main contribution is the derivation of equilibrium object placement strategies that 1) can guarantee improved local utilities for all nodes concurrently as compared to the corresponding local utilities under greedy local object placement, 2) do not suffer from potential mistreatment problems, inherent to centralized strategies that aim at optimizing the social utility, and 3) do not require the existence of complete information at all nodes. we develop a baseline computationally efficient algorithm for obtaining the aforementioned equilibrium strategies and then extend it to improve its performance with respect to fairness. both algorithms are realizable, in practice, through a distributed protocol that requires only a limited exchange of information.",
            "contribution_ids": [
                "R25210"
            ]
        },
        {
            "instance_id": "R25223xR25217",
            "comparison_id": "R25223",
            "paper_id": "R25217",
            "text": "A Distributed Algorithm for the Replica Placement Problem caching and replication of popular data objects contribute significantly to the reduction of the network bandwidth usage and the overall access time to data. our focus is to improve the efficiency of object replication within a given distributed replication group. such a group consists of servers that dedicate certain amount of memory for replicating objects requested by their clients. the content replication problem we are solving is defined as follows: given the request rates for the objects and the server capacities, find the replica allocation that minimizes the access time over all servers and objects. we design a distributed approximation algorithm that solves this problem and prove that it provides a 2-approximation solution. we also show that the communication and computational complexity of the algorithm is polynomial with respect to the number of servers, the number of objects, and the sum of the capacities of all servers. finally, we perform simulation experiments to investigate the performance of our algorithm. the experiments show that our algorithm outperforms the best existing distributed algorithm that solves the replica placement problem.",
            "contribution_ids": [
                "R25218"
            ]
        },
        {
            "instance_id": "R25223xR25219",
            "comparison_id": "R25223",
            "paper_id": "R25219",
            "text": "On Replica Placement for QOSAware Content Distribution the rapid growth of time-critical information services and business-oriented applications is making quality of service (qos) support increasingly important in content distribution. this paper investigates the problem of placing object replicas (e.g., web pages and images) to meet the qos requirements of clients with the objective of minimizing the replication cost. we consider two classes of service models: replica-aware service and replica-blind service. in the replica-aware model, the servers are aware of the locations of replicas and can therefore direct requests to the nearest replica. we show that the qos-aware placement problem for replica-aware services is np-complete. several heuristic algorithms for efficient computation of suboptimal solutions are proposed and experimentally evaluated. in the replica-blind model, the servers are not aware of the locations of replicas or even their existence. as a result, each replica only serves the requests flowing through it under some given routing strategy. we show that there exist polynomial optimal solutions to the qos-aware placement problem for replica-blind services. efficient algorithms are proposed to compute the optimal locations of replicas under different cost models.",
            "contribution_ids": [
                "R25220"
            ]
        },
        {
            "instance_id": "R25223xR25203",
            "comparison_id": "R25223",
            "paper_id": "R25203",
            "text": "Replication Algorithms in a Remote Caching Architectures studies the cache performance in a remote caching architecture. the authors develop a set of distributed object replication policies that are designed to implement different optimization goals. each site is responsible for local cache decisions, and modifies cache contents in response to decisions made by other sites. the authors use the optimal and greedy policies as upper and lower bounds, respectively, for performance in this environment. critical system parameters are identified, and their effect on system performance studied. performance of the distributed algorithms is found to be close to optimal, while that of the greedy algorithms is far from optimal. >",
            "contribution_ids": [
                "R25204"
            ]
        },
        {
            "instance_id": "R25223xR25215",
            "comparison_id": "R25223",
            "paper_id": "R25215",
            "text": "A Distributed Algorithm for Web content Replication web caching and replication techniques increase accessibility of web contents and reduce internet bandwidth requirements. in this paper, we are considering the replica placement problem in a distributed replication group. the replication group consists of servers dedicating certain amount of memory for replicating objects. the replica placement problem is to place the replica at the servers within the replication group such that the access time over all objects and servers is minimized. we design a distributed 2-approximation algorithm that solves this optimization problem. we show that the communication and computational complexity of the algorithm is polynomial in the number of servers and objects. we perform simulation experiments to investigate the performance of our algorithm.",
            "contribution_ids": [
                "R25216"
            ]
        },
        {
            "instance_id": "R25255xR25249",
            "comparison_id": "R25255",
            "paper_id": "R25249",
            "text": "NileULex: A phrase and word level sentiment lexicon for egyptian and modern standard Arabic this paper presents nileulex, which is an arabic sentiment lexicon containing close to six thousands arabic words and compound phrases. forty five percent of the terms and expressions in the lexicon are egyptian or colloquial while fifty five percent are modern standard arabic. while the collection of many of the terms included in the lexicon was done automatically, the actual addition of any term was done manually. one of the important criterions for adding terms to the lexicon, was that they be as unambiguous as possible. the result is a lexicon with a much higher quality than any translated variant or automatically constructed one. to demonstrate that a lexicon such as this can directly impact the task of sentiment analysis, a very basic machine learning based sentiment analyser that uses unigrams, bigrams, and lexicon based features was applied on two different twitter datasets. the obtained results were compared to a baseline system that only uses unigrams and bigrams. the same lexicon based features were also generated using a publicly available translation of a popular sentiment lexicon. the experiments show that usage of the developed lexicon improves the results over both the baseline and the publicly available lexicon.",
            "contribution_ids": [
                "R25250"
            ]
        },
        {
            "instance_id": "R25255xR25245",
            "comparison_id": "R25255",
            "paper_id": "R25245",
            "text": "Automatic expandable large-scale sentiment lexicon of modern standard Arabic and colloquial in subjectivity and sentiment analysis (ssa), there are two main requirements are necessary to improve sentiment analysis effectively in any language and genres, first, high coverage sentiment lexicon - where entries are tagged with semantic orientation (positive, negative and neutral) - second, tagged corpora to train the sentiment classifier. much of research has been conducted in this area during the last decade, but the need of building these resources is still ongoing, especially for morphologically-rich language (mrl) such as arabic. in this paper, we present an automatic expandable wide coverage polarity lexicon of arabic sentiment words, this lexical resource explicitly devised for supporting arabic sentiment classification and opinion mining applications. the lexicon is built using a seed of gold-standard arabic sentiment words which are manually collected and annotated with semantic orientation (positive or negative), and automatically expanded with sentiment orientation detection of the new sentiment words by exploiting some lexical information such as part-of-speech (pos) tags and using synset aggregation techniques from free online arabic lexicons, thesauruses. we report efforts to expand a manually-built our polarity lexicon using different types of data. finally, we used various tagged data to evaluate the coverage and quality of our polarity lexicon, moreover, to evaluate the lexicon expansion and its effects on the sentiment analysis accuracy. our data focus on modern standard arabic (msa) and egyptian dialectal arabic tweets and arabic microblogs (hotel reservation, product reviews, and tv program comments).",
            "contribution_ids": [
                "R25246"
            ]
        },
        {
            "instance_id": "R25255xR25229",
            "comparison_id": "R25255",
            "paper_id": "R25229",
            "text": "Arabic sentiment analysis: Lexicon-based and corpus-based \"the emergence of the web 2.0 technology generated a massive amount of raw data by enabling internet users to post their opinions, reviews, comments on the web. processing this raw data to extract useful information can be a very challenging task. an example of important information that can be automatically extracted from the users' posts and comments is their opinions on different issues, events, services, products, etc. this problem of sentiment analysis (sa) has been studied well on the english language and two main approaches have been devised: corpus-based and lexicon-based. this paper addresses both approaches to sa for the arabic language. since there is a limited number of publically available arabic dataset and arabic lexicons for sa, this paper starts by building a manually annotated dataset and then takes the reader through the detailed steps of building the lexicon. experiments are conducted throughout the different stages of this process to observe the improvements gained on the accuracy of the system and compare them to corpus-based approach.\"",
            "contribution_ids": [
                "R25230"
            ]
        },
        {
            "instance_id": "R25255xR25237",
            "comparison_id": "R25255",
            "paper_id": "R25237",
            "text": "A Large Scale Arabic Sentiment Lexicon for Arabic Opinion Mining most opinion mining methods in english rely successfully on sentiment lexicons, such as english sentiwordnet (eswn). while there have been efforts towards building arabic sentiment lexicons, they suffer from many deficiencies: limited size, unclear usability plan given arabic\u2019s rich morphology, or nonavailability publicly. in this paper, we address all of these issues and produce the first publicly available large scale standard arabic sentiment lexicon (arsenl) using a combination of existing resources: eswn, arabic wordnet, and the standard arabic morphological analyzer (sama). we compare and combine two methods of constructing this lexicon with an eye on insights for arabic dialects and other low resource languages. we also present an extrinsic evaluation in terms of subjectivity and sentiment analysis.",
            "contribution_ids": [
                "R25238"
            ]
        },
        {
            "instance_id": "R25255xR25247",
            "comparison_id": "R25255",
            "paper_id": "R25247",
            "text": "SLSA: A Sentiment Lexicon for Standard Arabic sentiment analysis has been a major area of interest, for which the existence of highquality resources is crucial. in arabic, there is a reasonable number of sentiment lexicons but with major deficiencies. the paper presents a large-scale standard arabic sentiment lexicon (slsa) that is publicly available for free and avoids the deficiencies in the current resources. slsa has the highest up-to-date reported coverage. the construction of slsa is based on linking the lexicon of aramorph with sentiwordnet along with a few heuristics and powerful back-off. slsa shows a relative improvement of 37.8% over a state-of-theart lexicon when tested for accuracy. it also outperforms it by an absolute 3.5% of f1-score when tested for sentiment analysis.",
            "contribution_ids": [
                "R25248"
            ]
        },
        {
            "instance_id": "R25255xR25251",
            "comparison_id": "R25255",
            "paper_id": "R25251",
            "text": "Arabic senti-lexicon: Constructing publicly available language resources for Arabic sentiment analysis sentiment analysis is held to be one of the highly dynamic recent research fields in natural language processing, facilitated by the quickly growing volume of web opinion data. most of the approaches in this field are focused on english due to the lack of sentiment resources in other languages such as the arabic language and its large variety of dialects. in most sentiment analysis applications, good sentiment resources play a critical role. based on that, in this article, several publicly available sentiment analysis resources for arabic are introduced. this article introduces the arabic senti-lexicon, a list of 3880 positive and negative synsets annotated with their part of speech, polarity scores, dialects synsets and inflected forms. this article also presents a multi-domain arabic sentiment corpus (masc) with a size of 8860 positive and negative reviews from different domains. in this article, an in-depth study has been conducted on five types of feature sets for exploiting effective features and investigating their effect on performance of arabic sentiment analysis. the aim is to assess the quality of the developed language resources and to integrate different feature sets and classification algorithms to synthesise a more accurate sentiment analysis method. the arabic senti-lexicon is used for generating feature vectors. five well-known machine learning algorithms: na\u00efve bayes, k-nearest neighbours, support vector machines (svms), logistic linear regression and neural network are employed as base-classifiers for each of the feature sets. a wide range of comparative experiments on standard arabic data sets were conducted, discussion is presented and conclusions are drawn. the experimental results show that the arabic senti-lexicon is a very useful resource for arabic sentiment analysis. moreover, results show that classifiers which are trained on feature vectors derived from the corpus using the arabic sentiment lexicon are more accurate than classifiers trained using the raw corpus.",
            "contribution_ids": [
                "R25252"
            ]
        },
        {
            "instance_id": "R25358xR25344",
            "comparison_id": "R25358",
            "paper_id": "R25344",
            "text": "A new service matching definition and algorithm with SAWSDL semantic web service (or briefly \u201csws\u201d) matching is a potential solution for automatic service discovery in various applications such as dynamic and automatic web service composition. a number of approaches for sws matching have been proposed. most of them solely relied on concept subsumption relationship to improve the precision of web service matching result from lexical-based methods. however such approaches suffer from several limitations such as not providing a fine-grained service matching degree, not supporting many-to-many matching between operation parameters, and not deriving data mappings between them. in this paper, we introduce a novel method for sws matching based on sawsdl, a semantic annotation specification for wsdl. we first define a fine-grained service matching result and then develop a corresponding service matching algorithm which can facilitate many-to-many matching of operation parameters as well as deriving concrete data mappings between them. semantic techniques are used to infer and match data elements of operation parameters between a request and a service. the proposed algorithm was implemented and applied in the setef \u2014 an automatic task-oriented business process execution system.",
            "contribution_ids": [
                "R25345"
            ]
        },
        {
            "instance_id": "R25358xR25317",
            "comparison_id": "R25358",
            "paper_id": "R25317",
            "text": "A Fuzzy-set based Semantic Similarity Matching Algorithm for Web Service a critical step in the process of reusing existing wsdl-specified services for building web-based applications is the discovery of potentially relevant services. however, the category-based service discovery, such as uddi, is clearly insufficient. semantic web services, augmenting web service descriptions using semantic web technology, were introduced to facilitate the publication, discovery, and execution of web services at the semantic level. semantic matchmaker enhances the capability of uddi service registries in the semantic web services architecture by applying some matching algorithms between advertisements and requests described in owl-s to recognize various degrees of matching for web services. based on semantic web service framework, semantic matchmaker, specification matching and probabilistic matching approach, this paper proposes a fuzzy-set based semantic similarity matching algorithm for web service to support a more automated and veracity service discovery process in the semantic web service framework.",
            "contribution_ids": [
                "R25318"
            ]
        },
        {
            "instance_id": "R25358xR25290",
            "comparison_id": "R25358",
            "paper_id": "R25290",
            "text": "An abstract model of service discovery and binding abstract \\n we propose a formal operational semantics for service discovery and binding. this semantics is based on a graph-based representation of the configuration of global computers typed by business activities. business activities execute distributed workflows that can trigger, at run time, the discovery, ranking and selection of services to which they bind, thus reconfiguring the workflows that they execute. discovery, ranking and selection are based on compliance with required business and interaction protocols and optimisation of quality-of-service constraints. binding and reconfiguration are captured as algebraic operations on configuration graphs. we also discuss the methodological implications that this model framework has on software engineering using a typical travel-booking scenario. to the best of our knowledge, our approach is the first to provide a clear separation between service computation and discovery/instantiation/binding, and to offer a formal framework that is independent of the soa middleware components that act as service registries or brokers, and the protocols through which bindings and invocations are performed.",
            "contribution_ids": [
                "R25291"
            ]
        },
        {
            "instance_id": "R25358xR25356",
            "comparison_id": "R25358",
            "paper_id": "R25356",
            "text": "WSExpress: A QoS-aware Search Engine for Web Services web services are becoming prevalent nowadays. finding desired web services is becoming an emergent and challenging research problem. in this paper, we present wsexpress (web service express), a novel web service search engine to expressively find expected web services. wsexpress ranks the publicly available web services not only by functional similarities to users\u2019 queries, but also by nonfunctional qos characteristics of web services. wsexpress provides three searching styles, which can adapt to the scenario of finding an appropriate web service and the scenario of automatically replacing a failed web service with a suitable one. wsexpress is implemented by java language and large-scale experiments employing real-world web services are conducted. totally 3,738 web services (15,811 operations) from 69 countries are involved in our experiments. the experimental results show that our search engine can find web services with the desired functional and non-functional requirements. extensive experimental studies are also conducted on a well known benchmark dataset consisting of 1,000 web service operations to show the recall and precision performance of our search engine.",
            "contribution_ids": [
                "R25357"
            ]
        },
        {
            "instance_id": "R25358xR25331",
            "comparison_id": "R25358",
            "paper_id": "R25331",
            "text": "Research on Fuzzy Matching Model for Semantic Web Services semantic descriptions of web services are necessary in order to enable their automatic discovery, composition and execution across heterogeneous users and domains on the basis of ontology. matching approach is considered as one of the crucial factors to ensure dynamic discovery and composition of web services. current matching methods such as uddi or larks are inadequate given their inability to abstract and classify web services. therefore proposes a novel matching model which exploits fuzzy logic in order to abstract and classify the underlying data of web services by fuzzy terms and rules. the aim is to make the match between service advertisement with service request more effective and allow vague terms in the search query and to provide more suited services for requesters.",
            "contribution_ids": [
                "R25332"
            ]
        },
        {
            "instance_id": "R25358xR25341",
            "comparison_id": "R25358",
            "paper_id": "R25341",
            "text": "Discovering Services during Service-Based System Design Using UML recently, there has been a proliferation of service-based systems, i.e., software systems that are composed of autonomous services but can also use software code. in order to support the development of these systems, it is necessary to have new methods, processes, and tools. in this paper, we describe a uml-based framework to assist with the development of service-based systems. the framework adopts an iterative process in which software services that can provide functional and nonfunctional characteristics of a system being developed are discovered, and the identified services are used to reformulate the design models of the system. the framework uses a query language to represent structural, behavioral, and quality characteristics of services to be identified, and a query processor to match the queries against service registries. the matching process is based on distance measurements between the queries and service specifications. a prototype tool has been implemented. the work has been evaluated in terms of recall, precision, and performance measurements.",
            "contribution_ids": [
                "R25342"
            ]
        },
        {
            "instance_id": "R25358xR25320",
            "comparison_id": "R25358",
            "paper_id": "R25320",
            "text": "Measuring Similarity of Web Services Based on WSDL web service has already been an important paradigm for web applications. growing number of services need efficiently locating the desired web services. the similarity metric of web services plays important role in service search and classification. the very small text fragments in wsdl of web services are unsuitable for applying the traditional ir techniques. we describe our approach which supports the similarity search and classification of service operations. the approach firstly employs the external knowledge to compute the semantic distance of terms from two compared services. the similarity of services is measured upon these distances. previous researches treat terms within the same wsdl documents as the isolated words and neglect the semantic association among them, hence lower down the accuracy of the similarity metric. we provide our method which tries to reflect the underlying semantics of web services by utilizing the terms within wsdl fully. the experiments show that our method works well on both service classification and query.",
            "contribution_ids": [
                "R25321"
            ]
        },
        {
            "instance_id": "R25358xR25350",
            "comparison_id": "R25358",
            "paper_id": "R25350",
            "text": "A New Framework for Web Service Discovery Based on Behavior \"with the rapid expanse of the web service over the internet, discovering related web service is becoming the most urgent problem. traditional methods focus on the interfaces of service through using ontology without considering service behavior. in this paper, the calculus of communicating systems(ccs) is exploited to specify web service's behavior, weak equivalence on behavior is used for matchmaking between the advertised service and the requested service. then, the paper combines behavior matching with fuzzy similarity of ontological concept to propose a new matching algorithm for web service. therefore, a promising framework for web service discovery is proposed.\"",
            "contribution_ids": [
                "R25351"
            ]
        },
        {
            "instance_id": "R25358xR25260",
            "comparison_id": "R25358",
            "paper_id": "R25260",
            "text": "Adaptive fuzzy-valued service selection \"service composition concerns both integration of heterogeneous distributed applications and dynamic selection of services. qos-aware selection enables a service requester with certain qos requirements to classify services according to their qos guarantees. in this paper we present a method that allows for a fuzzy-valued description of qos parameters. fuzzy sets are suited to specify both the qos preferences raised by a service requester such as 'response time must be as lower as possible and cannot be more that 1000ms' and approximate estimates a provider can make on the qos capabilities of its services like 'availability is roughly between 95% and 99%'. we propose a matchmaking procedure based on a fuzzy-valued similarity measure that, given the specifications of qos parameters of the requester and the providers, selects the most appropriate service among several functionally-equivalent ones. we also devise a method for dynamical update of service offers by means of runtime monitoring of the actual qos performance.\"",
            "contribution_ids": [
                "R25261"
            ]
        },
        {
            "instance_id": "R25358xR25348",
            "comparison_id": "R25358",
            "paper_id": "R25348",
            "text": "Study on Web Service Matching and Composition Based on Ontology because web service function is continually strengthened, and web service quantity increases rapidly, it is urgent to solve the problem on automatic service matching and composition to meet service request. the service matching algorithm for bionic manufacturing domain-specific ontology is proposed in the paper. for this algorithm, the semantic similarity between two concepts is calculated according to the distance of two nodes corresponding to two words of service request and description. the revised index for matching the key word is considered to emphasize the key parameter among service description, and the matching accuracy is highly improved. the total matching degree of service is equal to the average of all semantic similarities between the service request and the service description. it can be accurately judged if the service matching is successful by the total matching degree. according to the dynamic hierarchical structure of domain-specific ontology model of bionic manufacturing, the service auto-link composition algorithm is proposed based on the recursive principle in the paper. the service is automatically and intelligently matched and reasoned by using the heuristic knowledge of knowledge base and the semantic information of ontology base of bionic manufacturing. the structure-well user objective iopes (input, output, precondition, and effect) is linked to get the abstract or concrete service-flow framework. the automatic service composition is implemented from single service to higher concept hierarchical service. lastly, the system structure of semantic web service matching and composition is designed based on two described algorithms",
            "contribution_ids": [
                "R25349"
            ]
        },
        {
            "instance_id": "R25358xR25276",
            "comparison_id": "R25358",
            "paper_id": "R25276",
            "text": "Semantics-based composition-oriented discovery of Web services service discovery and service aggregation are two crucial issues in the emerging area of service-oriented computing (soc). we propose a new technique for the discovery of (web) services that accounts for the need of composing several services to satisfy a client query. the proposed algorithm makes use of owl-s ontologies, and explicitly returns the sequence of atomic process invocations that the client must perform in order to achieve the desired result. when no full match is possible, the algorithm features a flexible matching by returning partial matches and by suggesting additional inputs that would produce a full match.",
            "contribution_ids": [
                "R25277"
            ]
        },
        {
            "instance_id": "R25358xR25283",
            "comparison_id": "R25358",
            "paper_id": "R25283",
            "text": "BeMatch the capability to easily find useful services (software applications, software components, scientific computations) becomes increasingly critical in several fields. current approaches for services retrieval are mostly limited to the matching of their inputs/outputs possibly enhanced with some ontological knowledge. recent works have demonstrated that this approach is not sufficient to discover relevant components. motivated by these concerns, we have developed bematch platform for ranking web services based on behavior matchmaking. we developed matching techniques that operate on behavior models and allow delivery of partial matches and evaluation of semantic distance between these matches and user requirements. consequently, even if a service satisfying exactly the user requirements does not exist, the most similar ones will be retrieved and proposed for reuse by extension or modification. we exemplify our approach for behavioral services matchmaking by describing two demonstration scenarios for matchmaking bpel and wscl protocols, respectively. a demo scenario is also described concerning the tool for evaluating the effectiveness of the behavioral matchmaking method.",
            "contribution_ids": [
                "R25284"
            ]
        },
        {
            "instance_id": "R25358xR25309",
            "comparison_id": "R25358",
            "paper_id": "R25309",
            "text": "iSeM: Approximated Reasoning for Adaptive Hybrid Selection of Semantic Services we present an intelligent service matchmaker, called isem, for adaptive and hybrid semantic service selection that exploits the full semantic profile in terms of signature annotations in description logic sh and functional specifications in swrl. in particular, isem complements its strict logical signature matching with approximated reasoning based on logical concept abduction and contraction together with information-theoretic similarity and evidential coherence-based valuation of the result, and nonlogic-based approximated matching. besides, it may avoid failures of signature matching only through logical specification plug in matching of service preconditions and effects. eventually, it learns the optimal aggregation of its logical and non-logic-based matching filters off-line by means of binary svm-based service relevance classifier with ranking. we demonstrate the usefulness of isem by example and preliminary results of experimental performance evaluation.",
            "contribution_ids": [
                "R25310"
            ]
        },
        {
            "instance_id": "R25358xR25269",
            "comparison_id": "R25358",
            "paper_id": "R25269",
            "text": "On Extending Semantic Matchmaking to Include Preconditions and Effects central to the notion of dynamic binding and loose coupling that underlie service-oriented architectures is dynamic service discovery. at the heart of most service discovery mechanisms is a matchmaking algorithm that matches a semantic query to a set of compatible web service advertisements. these advertisements also describe service semantics as a set of owl-s terms. most current matchmaking algorithms are based on semantic matching of input and output terms alone. however, a complete description of the service profile also includes preconditions and effects and in order to find a true match the matchmaker needs to match on these aspects of the advertisement as well. in this paper, we make the case for augmenting existing matchmaking algorithms with preconditions and effects in the context of web services. further, we propose an algorithm for condition matching that is layered on the top of input-output term matching that overcomes the limitations of existing work. although the problem of condition matching is np-complete, we can overcome this limitation by using a set of heuristics that gives us results in polynomial time. we also analyze complexity of the algorithm by comparing it with brute force approach of matching. we show that our algorithm yields results more efficiently than brute force matching but with the same accuracy.",
            "contribution_ids": [
                "R25270"
            ]
        },
        {
            "instance_id": "R25400xR25391",
            "comparison_id": "R25400",
            "paper_id": "R25391",
            "text": "The molhado hypertext versioning system \"this paper describes molhado, a hypertext versioning and software configuration management system that is distinguished from previous systems by its flexible product versioning and structural configuration management model. the model enables a unified versioning framework for atomic and composite software artifacts, and hypermedia structures among them in a fine-grained manner at the logical level. hypermedia structures are managed separately from documents' contents. molhado explicitly represents hyperlinks, allowing them to be browsed, visualized, and systematically analyzed. molhado not only versions complex hypermedia structures (e.g., multi links), but also supports versioning of individual hyperlinks. this paper focuses on molhado's hypertext versioning and its use in the software concordance environment to manage the evolution of a software project and hypermedia structures.\"",
            "contribution_ids": [
                "R25392"
            ]
        },
        {
            "instance_id": "R25400xR25398",
            "comparison_id": "R25400",
            "paper_id": "R25398",
            "text": "Architectural point mapping for design traceability aop can be applied to not only modularization of crosscutting concerns but also other kinds of software development processes. as one of the applications, this paper proposes a design traceability mechanism originating in join points and pointcuts. it is not easy to design software architecture reflecting the intention of developers and implement the result of design as a program while preserving the architectural correctness. to deal with this problem, we propose two novel ideas: archpoint (architectural point) and archmapping (archpoint mapping). archpoints are points for representing the essence of architectural design in terms of behavioral and structural aspects. by defining a set of archpoints, we can describe the inter-component structure and the message interaction among components. archmapping is a mechanism for checking the bidirectional traceability between design and code. the traceability can be verified by checking whether archpoints in design are consistently mapped to program points in code. for this checking, we use an smt (satisfiability modulo theories) solver, a tool for deciding the satisfiability of logical formulas. the idea of archpoints, program points, and their selection originates in aop.",
            "contribution_ids": [
                "R25399"
            ]
        },
        {
            "instance_id": "R25400xR25371",
            "comparison_id": "R25400",
            "paper_id": "R25371",
            "text": "Automatic Tracing of Decisions to Architecture and Implementation traceability requires capturing the relations between software artifacts like requirements, architecture and implementation explicitly. manual discovery and recovery of tracing information by studying documents, architecture documentation and implementation is time-intensive, costly, and may miss important information not found in the analyzed artifacts. approaches for explicitly capturing traces exist, but either require manual capturing or lack comprehensive tracing to both architecture and implementation. in this paper we present an approach for (semi)automatically capturing traceability relationships from requirements and design decisions to architecture and implementation. traces are captured in a non-intrusive way during architecture design and implementation. the captured traces are integrated with a semi-formally defined architecture description model and serve as the basis for different kinds of architecture-related activities.",
            "contribution_ids": [
                "R25372"
            ]
        },
        {
            "instance_id": "R25400xR25363",
            "comparison_id": "R25400",
            "paper_id": "R25363",
            "text": "Experiments in the use of XML to enhance traceability between object-oriented design specifications and source code in this paper we explain how we implemented traceability between a uml design specification and its implementing source code using xml technologies. in our linking framework an xmi file represents a detailed-design specification and a javaml file represents its source code. these xml-derivative representations were linked using another xml file, an xlink link-base, containing our linking information. this link-base states which portions of the source code implement which portions of a design specification and vice-versa. we also rendered those links to an html file using xsl and traversed from our design specification to its implementing source code. this is the first step in our traceability endeavors where we aim to achieve total traceability among software life-cycle deliverables form requirements to source code.",
            "contribution_ids": [
                "R25364"
            ]
        },
        {
            "instance_id": "R25447xR25416",
            "comparison_id": "R25447",
            "paper_id": "R25416",
            "text": "Dependability and Rollback Recovery For Composite Web Services in this paper, we propose a service-oriented reliability model that dynamically calculates the reliability of composite web services with rollback recovery based on the real-time reliabilities of the atomic web services of the composition. our model is a hybrid reliability model based on both path-based and state-based models. many reliability models assume that failure or error arrival times are exponentially distributed. this is inappropriate for web services as error arrival times are dependent on the operating state including workload of servers where the web service resides. in this manuscript, we modify our previous model (for software based on the doubly stochastic model and renewal processes) to evaluate the reliability of atomic web services. in order to fix our idea, we developed the case of one simple web service which contains two states, i.e., idle and active states. in real-world applications, where web services could contain quite a large number of atomic services, the calculus as well as the computing complexity increases greatly. to limit our computing efforts and calculus, we chose the bounded set techniques that we apply using the previously developed stochastic model. as a first type of system combination, we proposed to study a scheme based on combining web services into parallel and serial configurations with centralized coordination. in this case, the broker has an acceptance testing mechanism that examines the results returned from a particular web service. if it was acceptable, then the computation continues to the next web service. otherwise, it involves rollback and invokes another web service already specified by a checkpoint algorithm. finally, the acceptance test is conducted using the broker. the broker can be considered as a single point of failure. to increase the reliability of the broker introduced in our systems and mask out errors at the broker level, we suggest a modified general scheme based on triple modular redundancy and n-version programming. to imitate a real scenario where errors could happen at any stage of our application and improve the quality of service qos of the proposed model, we introduce fault-tolerance techniques using an adaption of the recovery block technique.",
            "contribution_ids": [
                "R25417"
            ]
        },
        {
            "instance_id": "R25447xR25431",
            "comparison_id": "R25447",
            "paper_id": "R25431",
            "text": "Automatic Reliability Management in SOA-based critical systems a well-known concept for the design and development of distributed software systems is service-orientation. in soa, an interacting group of autonomous services realize a dynamic adaptive heterogenous distributed system. because of its flexibility, soa allows an easy adaptation of new business requirements. this also makes the serviceorientation idea a suitable concept for development of critical software systems. reliability is a central parameter for developing critical software systems. soa brings some additional requirements to the usual reliability models currently being used for standard software solutions. in order to fullfil all requirements and guarantee a certain degree of reliability, a generic reliability management model is needed for soa based software systems. this article defines research challenges in this area and gives an approach to solve this problem.",
            "contribution_ids": [
                "R25432"
            ]
        },
        {
            "instance_id": "R25447xR25420",
            "comparison_id": "R25447",
            "paper_id": "R25420",
            "text": "Hybrid Reliability Model to Enhance the Efficiency of Composite Web Services in this paper, a service-oriented reliability model that calculates the reliability of composite web services is designed. this model is based on the real-time reliabilities of the atomic web services of the composition. this manuscript contradicts the fact that the reliability of system is based on the exponential function of error arrival rate. the reliability rate of composite web services is inversely proportional to the workload of the servers. after obtaining the server workload, we dispatch the services into idle and active state using doubly stochastic model. this model assumes a single composite service and the atomicity of the services are dispatched in both serial and parallel configurations. a broker architecture based on bounded set technique is designed to deduce the error in the active state by calculating accessibility, availability and error rate. these factors are represented in terms of mtte, mtbf, mear which in turn used to dispatch the services into the server which provides high reliability.",
            "contribution_ids": [
                "R25421"
            ]
        },
        {
            "instance_id": "R25447xR25404",
            "comparison_id": "R25447",
            "paper_id": "R25404",
            "text": "A Reliability Evaluation Framework on Composite Web Service the composition of web-based services is a process that usually requires advanced programming skills and vast knowledge about specific technologies. how to carry out web service composition according to functional sufficiency and performance is widely studied. non-functional characteristics like reliability and security play an important role in the selection of web services composition process. this paper provides a web service reliability model for atomic web service without structural information and the composite web service consist of atomic web service and its redundant services. it outlines a framework based on client feedback to gather trustworthiness attributes to service registry for reliability evaluation.",
            "contribution_ids": [
                "R25405"
            ]
        },
        {
            "instance_id": "R25447xR25439",
            "comparison_id": "R25447",
            "paper_id": "R25439",
            "text": "Reliability of Component Based systems- a Critical Survey software reliability is defined as the probability of the failure free operation of a software system for a specified period of time in a specified environment. day by day software applications are growing more complex and with more emphasis on reuse. component based software (cbs) applications have emerged. the focus of this paper is to provide an overview for the state of the art of component based systems reliability estimation. in this paper, we discussed various approaches in terms of their scope, model, methods, technique and validation scheme. this comparison provides insight into determining the direction of future cbs reliability research.",
            "contribution_ids": [
                "R25440"
            ]
        },
        {
            "instance_id": "R25447xR25433",
            "comparison_id": "R25447",
            "paper_id": "R25433",
            "text": "Component-Based Software Engineering: Technologies, Development Frameworks, and Quality Assurance Schemes\u00e2\u0080\u009d, Asia-Pacific Software Engineering Conference component-based software development approach is based on the idea to develop software systems by selecting appropriate off-the-shelf components and then to assemble them with a well-defined software architecture. because the new software development paradigm is very different from the traditional approach, quality assurance (qa) for component-based software development is a new topic in the software engineering community. in this paper, we survey current component-based software technologies, describe their advantages and disadvantages, and discuss the features they inherit. we also address qa issues for component-based software. as a major contribution, we propose a qa model for component-based software which covers component requirement analysis, component development, component certification, component customization, and system architecture design, integration, testing and maintenance.",
            "contribution_ids": [
                "R25434"
            ]
        },
        {
            "instance_id": "R25495xR25475",
            "comparison_id": "R25495",
            "paper_id": "R25475",
            "text": "Modeling Day-to-Day Variability of Glucose\u00e2\u0080\u0093Insulin Regulation Over 12-Week Home Use of Closed-Loop Insulin Delivery parameters of physiological models of glucose\u2013insulin regulation in type 1 diabetes have previously been estimated using data collected over short periods of time and lack the quantification of day-to-day variability. we developed a new hierarchical model to relate subcutaneous insulin delivery and carbohydrate intake to continuous glucose monitoring over 12 weeks while describing day-to-day variability. sensor glucose data sampled every 10-min, insulin aspart delivery and meal intake were analyzed from eight adults with type 1 diabetes (male/female 5/3, age ${\\\\text{39.9}\\\\,\\\\pm \\\\,\\\\text{9.5}}$ years, bmi $\\\\text{25.4}\\\\,\\\\pm \\\\,\\\\text{4.4 kg/ m}^{2}$ , hba1c ${\\\\text{8.4}\\\\,\\\\pm \\\\,\\\\text{0.6}}$ %) who underwent a 12-week home study of closed-loop insulin delivery. a compartment model comprised of five linear differential equations; model parameters were estimated using the markov chain monte carlo approach within a hierarchical bayesian model framework. physiologically, plausible a posteriori distributions of model parameters including insulin sensitivity, time-to-peak insulin action, time-to-peak gut absorption, and carbohydrate bioavailability, and good model fit were observed. day-to-day variability of model parameters was estimated in the range of 38\u201379% for insulin sensitivity and 27\u201348% for time-to-peak of insulin action. in conclusion, a linear bayesian hierarchical approach is feasible to describe a 12-week glucose\u2013insulin relationship using conventional clinical data. the model may facilitate in silico testing to aid the development of closed-loop insulin delivery systems.",
            "contribution_ids": [
                "R25476"
            ]
        },
        {
            "instance_id": "R25495xR25451",
            "comparison_id": "R25495",
            "paper_id": "R25451",
            "text": "One-Day Bayesian Cloning of Type 1 Diabetes Subjects: Toward a Single-Day UVA/Padova Type 1 Diabetes Simulator objective: the uva/padova type 1 diabetes (t1dm) simulator has been shown to be representative of a t1dm population observed in a clinical trial, but has not yet been identified on t1dm data. moreover, the current version of the simulator is \u201csingle meal\u201d while making it \u201csingle-day centric,\u201d i.e., by describing intraday variability, would be a step forward to create more realistic in silico scenarios. here, we propose a bayesian method for the identification of the model from plasma glucose and insulin concentrations only, by exploiting the prior model parameter distribution. methods: the database consists of 47 t1dm subjects, who received dinner, breakfast, and lunch (respectively, 80, 50, and 60 cho grams) in three 23-h occasions (one openand one closed-loop). the model is identified using the bayesian maximum a posteriori technique, where the prior parameter distribution is that of the simulator. diurnal variability of glucose absorption and insulin sensitivity is allowed. results: the model well describes glucose traces (coefficient of determination r2 = 0.962 \u00b1 0.027) and the posterior parameter distribution is similar to that included in the simulator. absorption parameters at breakfast are significantly different from those at lunch and dinner, reflecting more rapid dynamics of glucose absorption. insulin sensitivity varies in each individual but without a specific pattern. conclusion: the incorporation of glucose absorption and insulin sensitivity diurnal variability into the simulator makes it more realistic. significance: the proposed method, applied to the increasing number of longterm artificial pancreas studies, will allow to describe week/month variability, thus further refining the simulator.",
            "contribution_ids": [
                "R25452"
            ]
        },
        {
            "instance_id": "R25495xR25449",
            "comparison_id": "R25495",
            "paper_id": "R25449",
            "text": "Robust PBPK/PD-Based Model Predictive Control of Blood Glucose goal: automated glucose control (agc) has not yet reached the point where it can be applied clinically [3]. challenges are accuracy of subcutaneous (sc) glucose sensors, physiological lag times, and both inter- and intraindividual variability. to address above issues, we developed a novel scheme for mpc that can be applied to agc. results: an individualizable generic whole-body physiology-based pharmacokinetic and dynamics (pbpk/pd) model of the glucose, insulin, and glucagon metabolism has been used as the predictive kernel. the high level of mechanistic detail represented by the model takes full advantage of the potential of mpc and may make long-term prediction possible as it captures at least some relevant sources of variability [4]. robustness against uncertainties was increased by a control cascade relying on proportional-integrative derivative-based offset control. the performance of this agc scheme was evaluated in silico and retrospectively using data from clinical trials. this analysis revealed that our approach handles sensor noise with a mard of 10%-14%, and model uncertainties and disturbances. conclusion: the results suggest that pbpk/pd models are well suited for mpc in a glucose control setting, and that their predictive power in combination with the integrated database-driven (a priori individualizable) model framework will help overcome current challenges in the development of agc systems. significance: this study provides a new, generic, and robust mechanistic approach to agc using a pbpk platform with extensive a priori (database) knowledge for individualization.",
            "contribution_ids": [
                "R25450"
            ]
        },
        {
            "instance_id": "R25495xR25477",
            "comparison_id": "R25495",
            "paper_id": "R25477",
            "text": "Model Free iPID Control for Glycemia Regulation of Type-1 Diabetes objective: the objective is to design a fully automated glycemia controller of type-1 diabetes (t1d) in both fasting and postprandial phases on a large number of virtual patients. methods: a model-free intelligent proportional-integral-derivative (ipid) is used to infuse insulin. the feasibility of ipid is tested in silico on two simulators with and without measurement noise. the first simulator is derived from a long-term linear time-invariant model. the controller is also validated on the uva/padova metabolic simulator on 10 adults under 25 runs/subject for noise robustness test. results: it was shown that without measurement noise, ipid mimicked the normal pancreatic secretion with a relatively fast reaction to meals as compared to a standard pid. with the uva/padova simulator, the robustness against cgm noise was tested. a higher percentage of time in target was obtained with ipid as compared to standard pid with reduced time spent in hyperglycemia. conclusion: two different t1d simulators tests showed that ipid detects meals and reacts faster to meal perturbations as compared to a classic pid. the intelligent part turns the controller to be more aggressive immediately after meals without neglecting safety. further research is suggested to improve the computation of the intelligent part of ipid for such systems under actuator constraints. any improvement can impact the overall performance of the model-free controller. significance: the simple structure ipid is a step for pid-like controllers since it combines the classic pid nice properties with new adaptive features.",
            "contribution_ids": [
                "R25478"
            ]
        },
        {
            "instance_id": "R25495xR25453",
            "comparison_id": "R25495",
            "paper_id": "R25453",
            "text": "Individualized model predictive control for the artificial pancreas: In silico evaluation of closed-loop glucose control \"despite the continuous efforts devoted to ap development in the last decades, an artificial pancreas (ap) system is not yet available on the market. one of the major issues involves the inter-subject variability affecting type 1 diabetes (t1d) patients, which makes the definition of a single controller suitable for any patient practically impossible. moreover, a state-of-the-art, noninvasive, and portable ap system is composed of subcutaneous hardware components, and the control algorithm must be properly designed to reside on a standalone device with limited battery life and computational power. these characteristics make the design of a safe and effective ap system even more challenging, due to the inherent delays affecting the subcutaneous insulin delivery route and the tradeoff between control performance and computational power expenditure. as a result of the model predictive control's (mpc's) ability to address inherent delays of the process under control, it is one of the most promising control approaches in the context of an ap. however, the achievable control performance is strictly related to the prediction capabilities of the model included in the controller, which, in general, can be highly nonlinear. the currently used mpc in clinical experiments relies on a linear average glucose-insulin model designed to represent the average dynamics of a subject with diabetes. this non-individualized mpc is not designed to cope with patient-specific dynamics but is designed to be non-computationally demanding and robust enough to result in a safe and effective control law.\"",
            "contribution_ids": [
                "R25454"
            ]
        },
        {
            "instance_id": "R25495xR25481",
            "comparison_id": "R25495",
            "paper_id": "R25481",
            "text": "An Ontology-Based Interpretable Fuzzy Decision Support System for Diabetes Diagnosis diabetes is a serious chronic disease. the importance of clinical decision support systems (cdsss) to diagnose diabetes has led to extensive research efforts to improve the accuracy, applicability, interpretability, and interoperability of these systems. however, this problem continues to require optimization. fuzzy rule-based systems are suitable for the medical domain, where interpretability is a main concern. the medical domain is data-intensive, and using electronic health record data to build the frbs knowledge base and fuzzy sets is critical. multiple variables are frequently required to determine a correct and personalized diagnosis, which usually makes it difficult to arrive at accurate and timely decisions. in this paper, we propose and implement a new semantically interpretable frbs framework for diabetes diagnosis. the framework uses multiple aspects of knowledge-fuzzy inference, ontology reasoning, and a fuzzy analytical hierarchy process (fahp) to provide a more intuitive and accurate design. first, we build a two-layered hierarchical and interpretable frbs; then, we improve this by integrating an ontology reasoning process based on snomed ct standard ontology. we incorporate fahp to determine the relative medical importance of each sub-frbs. the proposed system offers numerous unique and critical improvements regarding the implementation of an accurate, dynamic, semantically intelligent, and interpretable cdss. the designed system considers the ontology semantic similarity of diabetes complications and symptoms concepts in the fuzzy rules\u2019 evaluation process. the framework was tested using a real data set, and the results indicate how the proposed system helps physicians and patients to accurately diagnose diabetes mellitus.",
            "contribution_ids": [
                "R25482"
            ]
        },
        {
            "instance_id": "R25495xR25455",
            "comparison_id": "R25495",
            "paper_id": "R25455",
            "text": "Rapid Model Identification for Online Subcutaneous Glucose Concentration Prediction for New Subjects With Type I Diabetes goal: for conventional modeling methods, the work of model identification has to be repeated with sufficient data for each subject because different subjects may have different response to exogenous inputs. this may cause repetitive cost and burden for patients and clinicians and require a lot of modeling efforts. here, to overcome the aforementioned problems, a rapid model development strategy for new subjects is proposed using the idea of model migration for online glucose prediction. methods: first, a base model is obtained that can be empirically identified from any subject or constructed by a priori knowledge. then, parameters of inputs in the base model are properly revised based on a small amount of new data from new subjects so that the updated models can reflect the specific glucose dynamics excited by inputs for new subjects. these problems are investigated by developing autoregressive models with exogenous inputs (arx) based on 30 in silico subjects using uva/padova metabolic simulator. results: the prediction accuracy of the rapid modeling method is comparable to that for subject-dependent modeling method for some cases. also, it can present better generalization ability. conclusion: the proposed method can be regarded as an effective and economic modeling method instead of repetitive subject-dependent modeling method especially for lack of modeling data.",
            "contribution_ids": [
                "R25456"
            ]
        },
        {
            "instance_id": "R25529xR25509",
            "comparison_id": "R25529",
            "paper_id": "R25509",
            "text": "Entrepreneurial implications of crowdfunding as alternative funding source for innovations crowdfunding (cf) is a form of early-stage financing for innovative ventures, which has seen tremendous growth in the past few years \u2013 partly because it provides a desperately needed alternative to the scarcity of traditional sources of finance during the so called \u2018credit crunch\u2019. cf ranges from a simple form of pre-financing to full grown debt or equity investments, but they are typically small pledges that can add up to incredible amounts. scholarly literature has only started to examine cf and is still in an early stage when it comes to identifying implications for entrepreneurs apart from often over-simplified anecdotal evidence of success. the authors argue that cf can by no means be seen from a financial perspective only, rather it needs to be addressed as a bundle of processes leading to innovative entrepreneurial business-models. this qualitative study explores four extreme cases from the information and communications technology sphere to find out non-financial implications of cf as alternative funding source for innovative entrepreneurs and their business models.",
            "contribution_ids": [
                "R25510"
            ]
        },
        {
            "instance_id": "R25529xR25503",
            "comparison_id": "R25529",
            "paper_id": "R25503",
            "text": "Product and Pricing Decisions in Crowdfunding this paper studies the optimal product and pricing decisions in a crowdfunding mechanism by which a project between a creator and many buyers will be realized only if the total funds committed by the buyers reach a specified goal. when the buyers are sufficiently heterogeneous in their product valuations, the creator should offer a line of products with different levels of product quality. compared to the traditional situation where orders are placed and fulfilled individually, with the crowdfunding mechanism, a product line is more likely than a single product to be optimal and the quality gap between products is smaller. this paper also shows the effect of the crowdfunding mechanism on pricing dynamics over time. together, these results underscore the substantial influence of the emerging crowdfunding mechanisms on common marketing decisions.",
            "contribution_ids": [
                "R25504"
            ]
        },
        {
            "instance_id": "R25529xR25519",
            "comparison_id": "R25529",
            "paper_id": "R25519",
            "text": "The role of balanced centricity in the Spanish creative industries adopting a crowdfunding organisational model purpose \u2013 the purpose of this paper is to analyse the structures of the relationships between actors in the creative industries sector using crowd-funding, and how co-creation is the basis for reaching balanced centricity in the creative industries. design/methodology/approach \u2013 the many-to-many marketing theory, service-dominant logic and service logic are the theoretical bases for explaining how the changing roles of the actors in the creative industries sector have given the crowd a great capacity for deciding in the value-creation process. a qualitative, case-based approach is used, given the complexity of the phenomenon to be analysed. findings \u2013 the findings of the empirical approach have important theoretical and practical implications. on the theoretical side, it analyses the importance of balanced centricity instead of customer centricity as the basis for system stability. findings also have implications for service managers, as this can be considered an alternative for certain business projects,...",
            "contribution_ids": [
                "R25520"
            ]
        },
        {
            "instance_id": "R25529xR25497",
            "comparison_id": "R25529",
            "paper_id": "R25497",
            "text": "Crowdfunding to generate crowdsourced R&D: The alternative paradigm of societal problem solving offered by second generation innovation and R&D in a global context of resource scarcity few incentives exist for firms to pursue innovations that provide social externalities if these are not inherently profitable. the purpose of this article is to present an alternative paradigm of societal problem solving entirely premised on second generation innovation processes. further, a theoretical model of multidimensional, or three dimensional, knowledge creation is offered, together with the notion of a multiplier effect that relates to how knowledge creation can increase exponentially when knowledge is not constrained by proprietary requirements. second generation innovation is based on probabilistic processes that utilize and maximize economies of scale in pursuit of problem solving. two processes that contribute to the potential of second generation innovation to solve societal problems are crowdfunding and crowdsourcing. it is argued that the processes required to enable a new paradigm in societal problem solving already exist. a further model is developed based on potential synergies between crowdfunding and crowdsourced research and development. this theoretical model predicts that r&amp;d productivity can be accelerated significantly, and if applied in fields such as proteomics or medical research in general can accelerated increases in research output and therefore benefits to society.",
            "contribution_ids": [
                "R25498"
            ]
        },
        {
            "instance_id": "R25529xR25507",
            "comparison_id": "R25529",
            "paper_id": "R25507",
            "text": "The formation and interplay of social capital in crowdfunded social ventures \"the multi-levelled processes taking place in crowdfunding (cf), when tapping a large heterogeneous crowd for resources, and the often fundamentally different intentions of individual crowd members in the case of highly desirable social ventures with little prospect for economic gains, may lead to a different logic and approach to how entrepreneurship develops. using this under-institutionalized sphere as both, context and subject, the author seeks evidence and a new understanding of entrepreneurial routes by using the sociological perspectives of bourdieus' four forms of capital as a lens on 36 cases of social ventures. in the cases, opportunity recognition, formation and exploitation could not be distinguished as separate processes. cf and sourcing help form the actual opportunity and disperse information at the same time. in addition, the \u2018nexus\u2019 of opportunity and entrepreneur is breached in cf of social causes through the constant exchange of ideas with the crowd, leading to norm-value pairs between the funders and the entrepreneurs. issues of identification and control are thus not based upon any formal relationship but based on perceived legitimization and offered democratic participation leading to the transformation of social capital (sc) into economic capital (ec). success is based upon the sc of the entrepreneurial teams, yet the actual resource exchange and transformation into ec is highly moderated by cultural and symbolic capital that is being built up through the process.\"",
            "contribution_ids": [
                "R25508"
            ]
        },
        {
            "instance_id": "R25529xR25501",
            "comparison_id": "R25529",
            "paper_id": "R25501",
            "text": "Platform Strategy and Market Response Impact on the Success of Crowdfunding: A Chinese Case nowadays, crowdfunding presents a promising development. this research focuses on the influence of platform strategy and market response on the success of crowdfunding from the perspective of the elaboration likelihood model (elm) theory. detailed product specifications, crowdfunding difficulty coefficient, vivid advertising video such as introduction and music, and recommendations from relevant figures are all used to depict platform strategy. meanwhile, we use the number of lovers, followers, comments and 1 rmb backers to measure the level of market response. and thus, we model the impact of platform strategy and market response on crowdfunding success with empirical studies based on 400 samples of observed value. we found firstly that there exist significant positive relations between the total amount of funds pledged and detailed product specification, vivid advertising video, recommendations from relevant figures and the number of 1 rmb backers. secondly, the crowdfunding difficulty of projects affects negatively, and significantly, the total amount of funds pledged. thirdly, the influence of the number of lovers and followers on funds pledged is not significant.",
            "contribution_ids": [
                "R25502"
            ]
        },
        {
            "instance_id": "R25529xR25521",
            "comparison_id": "R25529",
            "paper_id": "R25521",
            "text": "The backer\u00e2\u0080\u0093developer connection: Exploring crowdfunding\u00e2\u0080\u0099s influence on video game production as video game development studios increasingly turn to digital crowdfunding platforms such as kickstarter for financing, this article explores the ways in which these processes shape production. it examines in particular the interactions that typically occur between studios and players as part of crowdfunded development, analysing the ways in which these activities inform aspects of video game design. by charting the implications of this burgeoning economic model, the article contributes to scholarship concerning video game production and intervenes within more specific discussions concerning the role of the player within development. the article\u2019s case study, which draws from evidence of production concerning multiple kickstarter projects, is organised into two sections. the first ascertains the degrees to which kickstarter users can influence the details of a proposed project during a crowdfunding campaign; the second looks at how developers involve crowdfunding communities within production once funding is secured.",
            "contribution_ids": [
                "R25522"
            ]
        },
        {
            "instance_id": "R25583xR25549",
            "comparison_id": "R25583",
            "paper_id": "R25549",
            "text": "Model-Driven Serious Game Development Integration of the Gamification Modeling Language GaML with Unity the development of gamification within non-game information systems as well as serious games has recently gained an important role in a variety of business fields due to promising behavioral or psychological improvements. however, industries still struggle with the high efforts of implementing gameful affordances in non-game systems. in order to decrease factors such as project costs, development cycles, and resource consumption as well as to improve the quality of products, the gamification modeling language has been proposed in prior research. however, the language is on a descriptive level only, i.e., cannot be used to automatically generate executable software artifacts. in this paper and based on this language, we introduce a model-driven architecture for designing as well as generating building blocks for serious games. furthermore, we give a validation of our approach by going through the different steps of designing an achievement system in the context of an existing serious game.",
            "contribution_ids": [
                "R25550"
            ]
        },
        {
            "instance_id": "R25583xR25581",
            "comparison_id": "R25583",
            "paper_id": "R25581",
            "text": "RealCoins A Case Study of Enhanced Model Driven Development for Pervasive Games model driven development (mdd) and domain specific modeling (dsm) have been widely used in information system domains and achieved success in many open or inhouse scenarios. but its application in the game domain is seldom and immature. in our research, we identified three issues that should be considered carefully in order to play the strength of mdd in the game development environment to a larger extend: 1) structured domain analysis should be done to assure the size and familiarity of the domain; 2) adapted process should be designed to save cost and support evolution; and 3) proper tools (especially language workbenches) should be evaluated and utilized to ease dsm tasks and accelerate iterations. in this paper, we explain these three issues and illustrate our solutions to them by presenting the development details (both technical and procedural) of one pervasive game case. we evaluate the gains and costs by involving mdd into the game development process. we reflect on the issues we have met, and discuss possible future works as well.",
            "contribution_ids": [
                "R25582"
            ]
        },
        {
            "instance_id": "R25583xR25567",
            "comparison_id": "R25583",
            "paper_id": "R25567",
            "text": "Eberos GML2D the complexity of game development has increased in the past 30 years, from a task that could almost be entirely handled by a single programmer to an endeavor requiring a large team. to reduce this complexity, we have developed a domain-specific language (dsl) targeting the modeling of two-dimensional (2d) games. we call this language eberos game modeling language 2d (eberos gml2d). by raising the level of abstraction through modeling, we allowed a simpler specification of the game, and reduced the time and programming efforts. in order to evaluate our approach, we modeled two games and compared the difference between the amount of work required to write the game from scratch and the amount required using our proposed language. these evaluations yielded promising results of 86.4% savings on programming effort, and 82.3% savings on programming time.",
            "contribution_ids": [
                "R25568"
            ]
        },
        {
            "instance_id": "R25583xR25547",
            "comparison_id": "R25583",
            "paper_id": "R25547",
            "text": "Model-driven development of user interfaces for educational games the main topic of this paper is the problem of developing user interfaces for educational games. focus of educational games is usually on the knowledge while it should be evenly distributed to the user interface as well. our proposed solution is based on the model-driven approach, thus we created a framework that incorporates meta-models, models, transformations and software tools. we demonstrated practical application of the mentioned framework by developing user interface for educational adventure game.",
            "contribution_ids": [
                "R25548"
            ]
        },
        {
            "instance_id": "R25583xR25553",
            "comparison_id": "R25583",
            "paper_id": "R25553",
            "text": "The RPG DSL: A case study of language engineering using MDD for generating RPG games for mobile phones \"it is typical in the domain of digital games to have many development problems due to its increasing complexity. those difficulties include: i)little code reuse in order to develop a cross-platform game; and ii)performing game's verification through extensive and expensive tests. this of course results in low productivity in the development (evolution and maintenance) of game solutions.\\n in this paper, we present a domain-specific language (dsl) for a role-playing game (rpg) product lines, which was completely built using a software development technique driven by high level abstractions---called model-driven development (mdd). also, we discuss and demonstrate the several benefits of applying mdd in terms of rapid prototyping of cross-platform games, and their evaluation by means of static and dynamic verification of the game's logic properties.\"",
            "contribution_ids": [
                "R25554"
            ]
        },
        {
            "instance_id": "R25583xR25571",
            "comparison_id": "R25583",
            "paper_id": "R25571",
            "text": "A Model-Based Approach for Designing Location-Based Games \"location-based games (lbgs) are a subclass of pervasive games that make use of location technologies to consider the players' geographic position in the game rules and mechanics. this research presents a model to describe and represent lbgs. the proposed model decouples location, mechanics, and game content from their implementation. we aim at allowing lbgs to be edited quickly and deployed on many platforms. the core model component is legal, a language derived from ncl (nested context language) to model and represented the game structure and its multimedia contents (e.g., video, audio, 3d objects, etc.). it allows the modelling of mission-based games by supporting spatial and temporal relationships between game elements and multimedia documents. we validated our approach by implementing a legal interpreter, which was coupled to an lbg authoring tool and a game server. these tools enabled us to reimplement a real lbg using the proposed model to attest its utility. we also edited the original game by using an external tool to showcase how simple is to transpose an lbg using the concepts introduced in this work. results indicate both the model and legal can be used to foster the design of lbgs.\"",
            "contribution_ids": [
                "R25572"
            ]
        },
        {
            "instance_id": "R25583xR25559",
            "comparison_id": "R25583",
            "paper_id": "R25559",
            "text": "Gade4all: Developing multi-platform videogames based on domain specific languages and model-driven engineering the development of applications for mobile devices is a constantly growing market which and more and more enterprises support the development of applications for this kind of devices. in that sense, videogames for mobile devices have become very popular worldwide and are now part of highly profitable and competitive industry. due to the diversity of platforms and mobile devices and the complexity of this kind of applications, the development time and the number of errors within that development process have increased. the productivity of the developers has also decreased due to the necessity of using many programming languages in the development process. one of the most popular strategies is to employ specialized people to perform the development tasks more efficiently, but this involves an increase of the costs, which makes some applications economically unviable. in this article we present the gade4all project, consisting in a new platform that aims to facilitate the development of videogames and entertainment software through the use of domain specific languages and model driven engineering. this tool makes possible for users without previous knowledge in the field of software development to create 2d videogames for multiplatform mobile devices in a simple and innovative way.",
            "contribution_ids": [
                "R25560"
            ]
        },
        {
            "instance_id": "R25583xR25579",
            "comparison_id": "R25583",
            "paper_id": "R25579",
            "text": "Improving digital game development with software product lines \"introducing reuse and software product line (spl) concepts into digital game-development processes isn't a straightforward task. this work presents a systematic process for bridging spls to game development, culminating with domain-specific languages and generators streamlined for game subdomains. the authors present a game spl for arcade games as a case study to illustrate and evaluate their proposed guidelines. this article is part of a special issue on games.\"",
            "contribution_ids": [
                "R25580"
            ]
        },
        {
            "instance_id": "R25583xR25563",
            "comparison_id": "R25583",
            "paper_id": "R25563",
            "text": "PULP scription: A DSL for mobile HTML5 game applications . as applications and especially games are moving to the web and mobile environments, di\ufb00erent tools are needed to design these applications and their behavior. html5 in combination with javascript is a promising basis for such applications on a wide range of platforms. content producers and designers often lack the tools for such develop-ments, or the expertise to operate existing, but too complex tools. this paper presents work in progress about a novel domain-speci\ufb01c language (dsl) pulp that aims at closing this gap. the language allows tying content such as images and media \ufb01les together by modeling the dynamic behavior, movements, and control \ufb02ow. the dsl helps abstracting from asynchronous javascript, state machines, and access to cross-platform media playback, which is generated in a \ufb01nal model-to-text transforma-tion. the dsl and tooling were created and evaluated in close coopera-tion with content authors.",
            "contribution_ids": [
                "R25564"
            ]
        },
        {
            "instance_id": "R25583xR25535",
            "comparison_id": "R25583",
            "paper_id": "R25535",
            "text": "Automatic prototyping in model-driven game development model-driven game development (mdgd) is an emerging paradigm where models become first-order elements in game development, maintenance, and evolution. in this article, we present a first approach to 2d platform game prototyping automatization through the use of model-driven engineering (mde). platform-independent models (pim) define the structure and the behavior of the games and a platform-specific model (psm) describes the game control mapping. automatic mofscript transformations from these models generate the software prototype code in c++. as an example, bubble bobble has been prototyped in a few hours following the mdgd approach. the resulting code generation represents 93% of the game prototype.",
            "contribution_ids": [
                "R25536"
            ]
        },
        {
            "instance_id": "R25583xR25555",
            "comparison_id": "R25583",
            "paper_id": "R25555",
            "text": "Virtual worlds on demand? Model-driven development of javascript-based virtual world UI components for mobile apps virtual worlds and avatar-based interactive computer games are a hype among consumers and researchers for many years now. in recent years, such games on mobile devices also became increasingly important. however, most virtual worlds require the use of proprietary clients and authoring environments and lack portability, which limits their usefulness for targeting wider audiences like e.g. in consumer marketing or sales. using mobile devices and client-side web technologies like i.e. javascript in combination with a more automatic generation of customer-specific virtual worlds could help to overcome these limitations. here, model-driven software development (mdd) provides a promising approach for automating the creation of user interface (ui) components for games on mobile devices. therefore, in this paper an approach is proposed for the model-driven generation of ui components for virtual worlds using javascript and the upcoming famo.us framework. the feasibilty of the approach is evaluated by implementing a proof-of-concept scenario.",
            "contribution_ids": [
                "R25556"
            ]
        },
        {
            "instance_id": "R25583xR25545",
            "comparison_id": "R25583",
            "paper_id": "R25545",
            "text": "MDA game design for video game development by genre game \u0301s development process remains a difficult task due to game platform\u2019s increasing technological complexity and lack of game \u0301s development methodologies for unified processes. in this work we show a way to develop different types of arcade games genre using model driven architecture (mda). we present a metamodel for game design that allows the specification for a high level abstraction independently of platform. this proposal shows that it is possible to generate a 2d game from the essential characteristics that make up such type of video game. also, some model transformation rules to generate executable java code from a specific model are shown.",
            "contribution_ids": [
                "R25546"
            ]
        },
        {
            "instance_id": "R25583xR25575",
            "comparison_id": "R25583",
            "paper_id": "R25575",
            "text": "Facilitating language-oriented game development by the help of language workbenches in recent years, a strong tendency towards language-oriented engineering became visible within game development projects. this approach is typically based on data-driven game engines and scripting languages resp. editing tools alike and already provided a great deal of overall productivity improvements. however, in its current form, potential benefits are not able to fully unfold yet. this is due to a mostly manual tool development process, which provokes substantial costs and lacks flexibility -- especially during prototyping phases of development. language workbenches seem to be a viable solution to this problem as they promise the ability of (visual) language (re-)generation by introducing a meta-level of development. this paper picks up that idea and evaluates its application in the area of game development. in this particular case, we discuss first findings of an ongoing case study, covering the development of level editors for several classic games, which have been built by the help of a language workbench.",
            "contribution_ids": [
                "R25576"
            ]
        },
        {
            "instance_id": "R25583xR25573",
            "comparison_id": "R25583",
            "paper_id": "R25573",
            "text": "Models and mechanisms for implementing playful scenarios serious games are becoming an increasingly used alternative in technical/professional/academic fields. however, scenario development poses a challenging problem since it is an expensive task, only devoted to computer specialists (game developers, programmers\u2026). the ultimate goal of our work is to propose a new scenario-building approach capable of ensuring a high degree of deployment and reusability. thus, we will define in this paper a new generation mechanism. this mechanism is built upon a model driven architecture (mda). we have started up by enriching the existing standards, which resulted in defining a new generic meta-model (cim). the resulting meta-model is capable of describing and standardizing game scenarios. then, we have laid down a new transformational mechanism in order to integrate the indexed game components into operational platforms (psm). finally, the effectiveness of our strategy was assessed under two separate contexts (target platforms) : the claroline-connect platform and the unity 3d environment.",
            "contribution_ids": [
                "R25574"
            ]
        },
        {
            "instance_id": "R25629xR25591",
            "comparison_id": "R25629",
            "paper_id": "R25591",
            "text": "Usage and Perceptions of Agile Software Development in an Industrial Context: An Exploratory Study agile development methodologies have been gaining acceptance in the mainstream software development community. while there are numerous studies of agile development in academic and educational settings, there has been little detailed reporting of the usage, penetration and success of agile methodologies in traditional, professional software development organizations. we report on the results of an empirical study conducted at microsoft to learn about agile development and its perception by people in development, testing, and management. we found that one-third of the study respondents use agile methodologies to varying degrees, and most view it favorably due to improved communication between team members, quick releases and the increased flexibility of agile designs. the scrum variant of agile methodologies is by far the most popular at microsoft. our findings also indicate that developers are most worried about scaling agile to larger projects (greater than twenty members), attending too many meetings and the coordinating agile and non-agile teams.",
            "contribution_ids": [
                "R25592"
            ]
        },
        {
            "instance_id": "R25629xR25617",
            "comparison_id": "R25629",
            "paper_id": "R25617",
            "text": "Understanding post-adoptive agile usage: An exploratory cross- case analysis the widespread adoption of agile methodologies raises the question of their continued and effective usage in organizations. an agile usage model consisting of innovation, sociological, technological, team, and organizational factors is used to inform an analysis of post-adoptive usage of agile practices in two major organizations. analysis of the two case studies found that a methodology champion and top management support were the most important factors influencing continued usage, while innovation factors such as compatibility seemed less influential. both horizontal and vertical usage was found to have significant impact on the effectiveness of agile usage.",
            "contribution_ids": [
                "R25618"
            ]
        },
        {
            "instance_id": "R25629xR25627",
            "comparison_id": "R25629",
            "paper_id": "R25627",
            "text": "Experience Report: The Social Nature of Agile Teams agile software development is often, but not always, associated with the term dasiaproject chemistry,psila or the positive team climate that can contribute to high performance. a qualitative study involving 22 participants in agile teams sought to explore this connection, and answer the question: what aspects of agile software development are related to team cohesion? the following is a discussion of participant experiences as seen through a socio-psychological lens. it draws from social-identity theory and socio-psychological literature to explain, not only how, but why agile methodologies support teamwork and collective progress. agile practices are shown to produce a socio-psychological environment of high-performance, with many of the practical benefits of agile practices being supported and mediated by social and personal concerns.",
            "contribution_ids": [
                "R25628"
            ]
        },
        {
            "instance_id": "R25629xR25612",
            "comparison_id": "R25629",
            "paper_id": "R25612",
            "text": "Investigating the Long-Term Acceptance of Agile Methodologies: An Empirical Study of Developer Perceptions in Scrum Projects agile development methodologies have gained great interest in research and practice. as their introduction considerably changes traditional working habits of developers, the long-term acceptance of agile methodologies becomes a critical success factor. yet, current studies primarily examine the early adoption stage of agile methodologies. to investigate the long-term acceptance, we conducted a study at a leading insurance company that introduced scrum in 2007. using a qualitative research design and the diffusion of innovations theory as a lens for analysis, we gained in-depth insights into factors influencing the acceptance of scrum. particularly, developers felt scrum to be more compatible to their actual working practices. moreover, they perceived the use of scrum to deliver numerous relative advantages. however, we also identified possible barriers to acceptance since developers felt both the complexity of scrum and the required discipline to be higher in comparison with traditional development methodologies.",
            "contribution_ids": [
                "R25613"
            ]
        },
        {
            "instance_id": "R25629xR25619",
            "comparison_id": "R25629",
            "paper_id": "R25619",
            "text": "The Impact of Organizational Culture on Agile Method Use agile method proponents believe that organizational culture has an effect on the extent to which an agile method is used. research into the relationship between organizational culture and information systems development methodology deployment has been explored by others using the competing values framework (cvf). however this relationship has not been explored with respect to the agile development methodologies. based on a multi-case study of nine projects we show that specific organizational culture factors correlate with effective use of an agile method. our results contribute to the literature on organizational culture and system development methodology use.",
            "contribution_ids": [
                "R25620"
            ]
        },
        {
            "instance_id": "R25629xR25610",
            "comparison_id": "R25629",
            "paper_id": "R25610",
            "text": "A qualitative study of the determinants of self-managing team effectiveness in a scrum team there are many evidences in the literature that the use self-managing teams has positive impacts on several dimensions of team effectiveness. agile methods, supported by the agile manifesto, defend the use of self-managing teams in software development in substitution of hierarchically managed, traditional teams. the goal of this research was to study how a self-managing software team works in practice and how the behaviors of the software organization support or hinder the effectiveness of such teams. we performed a single case holistic case study, looking in depth into the actual behavior of a mature scrum team in industry. using interviews and participant observation, we collected qualitative data from five team members in several interactions. we extract the behavior of the team and of the software company in terms of the determinants of self-managing team effectiveness defined in a theoretical model from the literature. we found evidence that 17 out of 24 determinants of this model exist in the studied context. we concluded that certain determinants can support or facilitate the adoption of methodologies like scrum, while the use of scrum may affect other determinants.",
            "contribution_ids": [
                "R25611"
            ]
        },
        {
            "instance_id": "R25629xR25597",
            "comparison_id": "R25629",
            "paper_id": "R25597",
            "text": "An empirical study on the relationship between the use of agile practices and the success of Scrum projects \"in this article, factors considered critical for the success of projects managed using scrum are correlated to the results of software projects in industry. using a set of 25 factors compiled in by other researchers, a cross section survey was conducted to evaluate the presence or application of these factors in 11 software projects that used scrum in 9 different software companies located in recife-pe, brazil. the questionnaire was applied to 65 developers and scrum masters, representing 75% (65/86) of the professionals that have participated in the projects. the result was correlated with the level of success achieved by the projects, measured by the subjective perception of the project participant, using spearman's rank correlation coefficient. the main finding is that only 32% (8/25) of the factors correlated positively with project success, raising the question of whether the factors hypothesized in the literature as being critical to the success of agile software projects indeed have an effect on project success. given the limitations regarding the generalization of this result, other forms of empirical results, in particular case-studies, are needed to test this question.\"",
            "contribution_ids": [
                "R25598"
            ]
        },
        {
            "instance_id": "R25663xR25639",
            "comparison_id": "R25663",
            "paper_id": "R25639",
            "text": "Pick-by-Vision: A first stress test in this paper we report on our ongoing studies around the application of augmented reality methods to support the order picking process of logistics applications. order picking is the gathering of goods out of a prepared range of items following some customer orders. we named the visual support of this order picking process using head-mounted displays \u201cpick-by-vision\u201d. this work presents the case study of bringing our previously developed pickby-vision system from the lab to an experimental factory hall to evaluate it under more realistic conditions. this includes the execution of two user studies. in the first one we compared our pickby-vision system with and without tracking to picking using a paper list to check picking performance and quality in general. in a second test we had subjects using the pick-by-vision system continuously for two hours to gain in-depth insight into the longer use of our system, checking user strain besides the general performance. furthermore, we report on the general obstacles of trying to use hmd-based ar in an industrial setup and discuss our observations of user behaviour.",
            "contribution_ids": [
                "R25640"
            ]
        },
        {
            "instance_id": "R25663xR25631",
            "comparison_id": "R25663",
            "paper_id": "R25631",
            "text": "Reducing Warehouse Employee Errors Using Voice-Assisted Technology That Provided Immediate Feedback abstract a foodservice distributor in the southeastern united states implemented a voice assisted selecting tool to reduce selector errors by providing immediate feedback when errors occurred. an ab design with a nonequivalent comparison group was used to examine the effects of the voice technology on 132 selectors whose mispicks and shorts were collected over 6 weeks of baseline and 8 weeks of the intervention phase. selector errors were reduced from 2.44 errors per 1,000 cases picked to 0.94 errors per 1,000 cases when voice technology was implemented. further analysis indicated that the immediate feedback provided by voice had a greater impact on employees who were making the most errors during baseline.",
            "contribution_ids": [
                "R25632"
            ]
        },
        {
            "instance_id": "R25663xR25653",
            "comparison_id": "R25663",
            "paper_id": "R25653",
            "text": "A comparison of order picking assisted by head-up display (HUD), cart-mounted display (CMD), light, and paper pick list wearable and contextually aware technologies have great applicability in task guidance systems. order picking is the task of collecting items from inventory in a warehouse and sorting them for distribution; this process accounts for about 60% of the total operational costs of these warehouses. current practice in industry includes paper pick lists and pick-by-light systems. we evaluated order picking assisted by four approaches: head-up display (hud); cart-mounted display (cmd); pick-by-light; and paper pick list. we report accuracy, error types, task time, subjective task load and user preferences for all four approaches. the findings suggest that pick-by-hud and pick-by-cmd are superior on all metrics to the current practices of pick-by-paper and pick-by-light.",
            "contribution_ids": [
                "R25654"
            ]
        },
        {
            "instance_id": "R25663xR25661",
            "comparison_id": "R25663",
            "paper_id": "R25661",
            "text": "A Comparative Study of an Assistance System for Manual Order Picking -- Called Pick-by-Projection -- with the Guiding Systems Pick-by-Paper, Pick-by-Light and Pick-by-Display changes and innovations are needed in the area of instruction and control of employees to perform reliably and cost effective in order picking. the information must be easily accessible - communicated in a succinct way to overcome intellectual, socio-educational as well as language barriers. this case mainly focuses on conducting, research in the field of technical support by assistance systems for impaired people and people with altered performance, but also for people without restrictions. this paper aims at presenting the prototype of a new assistance system for manual order picking. in addition, the prototype was evaluated in a user study involving 24 people with three other methods (pick-by-paper, pick-by-light, pick-by-display), which represent the current state of the art. we report about the number of errors, the task completion time and the cognitive workload for all four approaches. the results show that this new kind of assistance system can have benefits, particularly in the area of error prevention and workload.",
            "contribution_ids": [
                "R25662"
            ]
        },
        {
            "instance_id": "R25663xR25655",
            "comparison_id": "R25663",
            "paper_id": "R25655",
            "text": "Comparing order picking assisted by head-up display versus pick-by-light with explicit pick confirmation manual order picking is an important part of distribution. many techniques have been proposed to improve pick efficiency and accuracy. previous studies compared pick-by-hud (head-up display) with pick-by-light but without the explicit pick confirmation that is typical in industrial environments. we compare a pick-by-light system designed to emulate deployed systems with a pick-by-hud system using google glass. the pick-by-light system tested 50% slower than pick-by-hud and required a higher workload. the number of errors committed and picker preference showed no statistically significant difference.",
            "contribution_ids": [
                "R25656"
            ]
        },
        {
            "instance_id": "R25694xR6515",
            "comparison_id": "R25694",
            "paper_id": "R6515",
            "text": "Formal Linked Data Visualization Model recently, the amount of semantic data available in the web has increased dramatically. the potential of this vast amount of data is enormous but in most cases it is difficult for users to explore and use this data, especially for those without experience with semantic web technologies. applying information visualization techniques to the semantic web helps users to easily explore large amounts of data and interact with them. in this article we devise a formal linked data visualization model (ldvm), which allows to dynamically connect data with visualizations. we report about our implementation of the ldvm comprising a library of generic visualizations that enable both users and data analysts to get an overview on, visualize and explore the data web and perform detailed analyzes on linked data.",
            "contribution_ids": [
                "R25679",
                "R6516"
            ]
        },
        {
            "instance_id": "R25694xR6511",
            "comparison_id": "R25694",
            "paper_id": "R6511",
            "text": "SemLens: visual analysis of semantic data with scatter plots and semantic lenses querying the semantic web and analyzing the query results are often complex tasks that can be greatly facilitated by visual interfaces. a major challenge in the design of these interfaces is to provide intuitive and efficient interaction support without limiting too much the analytical degrees of freedom. this paper introduces semlens, a visual tool that combines scatter plots and semantic lenses to overcome this challenge and to allow for a simple yet powerful analysis of rdf data. the scatter plots provide a global overview on an object collection and support the visual discovery of correlations and patterns in the data. the semantic lenses add dimensions for local analysis of subsets of the objects. a demo accessing dbpedia data is used for illustration.",
            "contribution_ids": [
                "R25676",
                "R6512"
            ]
        },
        {
            "instance_id": "R25694xR25683",
            "comparison_id": "R25694",
            "paper_id": "R25683",
            "text": "Information content based ranking metric for linked open vocabularies it is widely accepted that by controlling metadata, it is easier to publish high quality data on the web. metadata, in the context of linked data, refers to vocabularies and ontologies used for describing data. with more and more data published on the web, the need for reusing controlled taxonomies and vocabularies is becoming more and more a necessity. catalogues of vocabularies are generally a starting point to search for vocabularies based on search terms. some recent studies recommend that it is better to reuse terms from \"popular\" vocabularies [4]. however, there is not yet an agreement on what makes a popular vocabulary since it depends on diverse criteria such as the number of properties, the number of datasets using part or the whole vocabulary, etc. in this paper, we propose a method for ranking vocabularies based on an information content metric which combines three features: (i) the datasets using the vocabulary, (ii) the outlinks from the vocabulary and (iii) the inlinks to the vocabulary. we applied this method to 366 vocabularies described in the lov catalogue. the results are then compared with other catalogues which provide alternative rankings.",
            "contribution_ids": [
                "R25684"
            ]
        },
        {
            "instance_id": "R25726xR25722",
            "comparison_id": "R25726",
            "paper_id": "R25722",
            "text": "Visualizing ontologies with VOWL the visual notation for owl ontologies (vowl) is a well-specified visual language for the user-oriented representation of ontologies. it defines graphical depictions for most elements of the web ontology language (owl) that are combined to a force-directed graph layout visualizing the ontology. in contrast to related work, vowl aims for an intuitive and comprehensive representation that is also understandable to users less familiar with ontologies. this article presents vowl in detail and describes its implementation in two different tools: protegevowl and webvowl. the first is a plugin for the ontology editor protege, the second a standalone web application. both tools demonstrate the applicability of vowl by means of various ontologies. in addition, the results of three user studies that evaluate the comprehensibility and usability of vowl are summarized. they are complemented by findings from an interview with experienced ontology users and from testing the visual scope and completeness of vowl with a benchmark ontology. the evaluations helped to improve vowl and confirm that it produces comparatively intuitive and comprehensible ontology visualizations.",
            "contribution_ids": [
                "R25723"
            ]
        },
        {
            "instance_id": "R25726xR6429",
            "comparison_id": "R25726",
            "paper_id": "R6429",
            "text": "Using Clusters in RDF Visualization clustered graph visualization techniques are an easy to understand way of hiding complex parts of a visualized graph when they are not needed by the user. when visualizing rdf, there are several situations where such clusters are defined in a very natural way. using this techniques, we can give the user optional access to some detailed information without unnecessarily occupying space in the basic view of the data. this paper describes algorithms for clustered visualization used in the trisolda rdf visualizer. most notable is the newly added clustered navigation technique.",
            "contribution_ids": [
                "R25708",
                "R6430"
            ]
        },
        {
            "instance_id": "R25726xR6417",
            "comparison_id": "R25726",
            "paper_id": "R6417",
            "text": "RDF data exploration and visualization we present paged graph visualization (pgv), a new semi-autonomous tool for rdf data exploration and visualization. pgv consists of two main components: a) the \"pgv explorer\" and b) the \"rdf pager\" module utilizing brahms, our high per-formance main-memory rdf storage system. unlike existing graph visualization techniques which attempt to display the entire graph and then filter out irrelevant data, pgv begins with a small graph and provides the tools to incrementally explore and visualize relevant data of very large rdf ontologies. we implemented several techniques to visualize and explore hot spots in the graph, i.e. nodes with large numbers of immediate neighbors. in response to the user-controlled, semantics-driven direction of the exploration, the pgv explorer obtains the necessary sub-graphs from the rdf pager and enables their incremental visualization leaving the previously laid out sub-graphs intact. we outline the problem of visualizing large rdf data sets, discuss our interface and its implementation, and through a controlled experiment we show the benefits of pgv.",
            "contribution_ids": [
                "R25704",
                "R6418"
            ]
        },
        {
            "instance_id": "R25726xR25695",
            "comparison_id": "R25726",
            "paper_id": "R25695",
            "text": "GrouseFlocks: Steerable Exploration of Graph Hierarchy Space several previous systems allow users to interactively explore a large input graph through cuts of a superimposed hierarchy. this hierarchy is often created using clustering algorithms or topological features present in the graph. however, many graphs have domain-specific attributes associated with the nodes and edges, which could be used to create many possible hierarchies providing unique views of the input graph. grouseflocks is a system for the exploration of this graph hierarchy space. by allowing users to see several different possible hierarchies on the same graph, the system helps users investigate graph hierarchy space instead of a single fixed hierarchy. grouseflocks provides a simple set of operations so that users can create and modify their graph hierarchies based on selections. these selections can be made manually or based on patterns in the attribute data provided with the graph. it provides feedback to the user within seconds, allowing interactive exploration of this space.",
            "contribution_ids": [
                "R25696"
            ]
        },
        {
            "instance_id": "R25726xR6461",
            "comparison_id": "R25726",
            "paper_id": "R6461",
            "text": "LodLive, exploring the web of data lodlive project, http://en.lodlive.it/, provides a demonstration of the use of linked data standard (rdf, sparql) to browse rdf resources. the application aims to spread linked data principles with a simple and friendly interface and reusable techniques. in this report we present an overview of the potential of lodlive, mentioning tools and methodologies that were used to create it.",
            "contribution_ids": [
                "R25718",
                "R6462"
            ]
        },
        {
            "instance_id": "R25726xR6465",
            "comparison_id": "R25726",
            "paper_id": "R6465",
            "text": "Visualizing Populated Ontologies with OntoTrix research on visualizing semantic web data has yielded many tools that rely on information visualization techniques to better support the user in understanding and editing these data. most tools structure the visualization according to the concept definitions and interrelations that constitute the ontology\u2019s vocabulary. instances are often treated as somewhat peripheral information, when considered at all. these instances, that populate ontologies, represent an essential part of any knowledge base. understanding instance-level data might be easier for users because of their higher concreteness, but instances will often be orders of magnitude more numerous than the concept definitions that give them machine-processable meaning. as such, the visualization of instance-level data poses different but real challenges. the authors present a visualization technique designed to enable users to visualize large instance sets and the relations that connect them. this visualization uses both node-link and adjacency matrix representations of graphs to visualize different parts of the data depending on their semantic and local structural properties. the technique was originally devised for simple social network visualization. the authors extend it to handle the richer and more complex graph structures of populated ontologies, exploiting ontological knowledge to drive the layout of, and navigation in, the representation embedded in a smooth zoomable environment.",
            "contribution_ids": [
                "R25719",
                "R6466"
            ]
        },
        {
            "instance_id": "R25726xR6421",
            "comparison_id": "R25726",
            "paper_id": "R6421",
            "text": "Browsing Linked Data with Fenfire a wealth of information has recently become available as browsable rdf data on the web, but the selection of client applications to interact with this linked data remains limited. we show how to browse linked data with fenfire, a free and open source software rdf browser and editor that employs a graph view and focuses on an engaging and interactive browsing experience. this sets fenfire apart from previous table- and outline-based linked data browsers.",
            "contribution_ids": [
                "R25705",
                "R6422"
            ]
        },
        {
            "instance_id": "R25726xR6433",
            "comparison_id": "R25726",
            "paper_id": "R6433",
            "text": "Visualizing large-scale RDF data using Subsets, Summaries, and Sampling in Oracle the paper addresses the problem of visualizing large scale rdf data via a 3-s approach, namely, by using, 1) subsets: to present only relevant data for visualisation; both static and dynamic subsets can be specified, 2) summaries: to capture the essence of rdf data being viewed; summarized data can be expanded on demand thereby allowing users to create hybrid (summary-detail) fisheye views of rdf data, and 3) sampling: to further optimize visualization of large-scale data where a representative sample suffices. the visualization scheme works with both asserted and inferred triples (generated using rdf(s) and owl semantics). this scheme is implemented in oracle by developing a plug-in for the cytoscape graph visualization tool, which uses functions defined in a oracle pl/sql package, to provide fast and optimized access to oracle semantic store containing rdf data. interactive visualization of a synthesized rdf data set (lubm 1 million triples), two native rdf datasets (wikipedia 47 million triples and uniprot 700 million triples), and an owl ontology (eclassowl with a large class hierarchy including over 25,000 owl classes, 5,000 properties, and 400,000 class-properties) demonstrates the effectiveness of our visualization scheme.",
            "contribution_ids": [
                "R25709",
                "R6434"
            ]
        },
        {
            "instance_id": "R25726xR6413",
            "comparison_id": "R25726",
            "paper_id": "R6413",
            "text": "NodeTrix: a Hybrid Visualization of Social Networks the need to visualize large social networks is growing as hardware capabilities make analyzing large networks feasible and many new data sets become available. unfortunately, the visualizations in existing systems do not satisfactorily resolve the basic dilemma of being readable both for the global structure of the network and also for detailed analysis of local communities. to address this problem, we present nodetrix, a hybrid representation for networks that combines the advantages of two traditional representations: node-link diagrams are used to show the global structure of a network, while arbitrary portions of the network can be shown as adjacency matrices to better support the analysis of communities. a key contribution is a set of interaction techniques. these allow analysts to create a nodetrix visualization by dragging selections to and from node-link and matrix forms, and to flexibly manipulate the nodetrix representation to explore the dataset and create meaningful summary visualizations of their findings. finally, we present a case study applying nodetrix to the analysis of the infovis 2004 coauthorship dataset to illustrate the capabilities of nodetrix as both an exploration tool and an effective means of communicating results.",
            "contribution_ids": [
                "R25703",
                "R6414"
            ]
        },
        {
            "instance_id": "R25726xR25698",
            "comparison_id": "R25726",
            "paper_id": "R25698",
            "text": "Node-centric RDF Graph Visualization rdf, visualization, resource description framework, graph, browser, nodecentric this paper describes a node-centric technique for visualizing resource description framework (rdf) graphs. nodes of interest are discovered by searching over literals. subgraphs for display are constructed by using the area around selected nodes. wider views are created by sorting and displaying nodes based on the number of incoming and outgoing arcs.",
            "contribution_ids": [
                "R25699"
            ]
        },
        {
            "instance_id": "R25726xR6457",
            "comparison_id": "R25726",
            "paper_id": "R6457",
            "text": "Using Hierarchical Edge Bundles to visualize complex ontologies in GLOW \"in the past decade, much effort has been put into the visual representation of ontologies. however, present visualization strategies are not equipped to handle complex ontologies with many relations, leading to visual clutter and inefficient use of space. in this paper, we propose glow, a method for ontology visualization based on hierarchical edge bundles. hierarchical edge bundles is a new visually attractive technique for displaying relations in hierarchical data, such as concept structures formed by 'subclass-of' and 'type-of' relations. we have developed a visualization library based on owl api, as well as a plug-in for prot\u00e9g\u00e9, a well-known ontology editor. the displayed adjacency relations can be selected from an ontology using a set of common configurations, allowing for intuitive discovery of information. our evaluation demonstrates that the glow visualization provides better visual clarity, and displays relations and complex ontologies better than the existing prot\u00e9g\u00e9 visualization plug-in jambalaya.\"",
            "contribution_ids": [
                "R25717",
                "R6458"
            ]
        },
        {
            "instance_id": "R25762xR25738",
            "comparison_id": "R25762",
            "paper_id": "R25738",
            "text": "CTU-Mine: An Efficient High Utility Itemset Mining Algorithm Using the Pattern Growth Approach frequent pattern mining discovers patterns in transaction databases based only on the relative frequency of occurrence of items without considering their utility. for many real world applications, however, utility of itemsets based on cost, profit or revenue is of importance. the utility mining problem is to find itemsets that have higher utility than a user specified minimum. unlike itemset support in frequent pattern mining, itemset utility does not have the anti-monotone property and so efficient high utility mining poses a greater challenge. recent research on utility mining has been based on the candidate-generation-and-test approach which is suitable for sparse data sets with short patterns, but not feasible for dense data sets or long patterns. in this paper we propose a new algorithm called ctu-mine that mines high utility itemsets using the pattern growth approach. we have tested our algorithm on several dense data sets, compared it with the recent algorithms and the results show that our algorithm works efficiently.",
            "contribution_ids": [
                "R25739"
            ]
        },
        {
            "instance_id": "R25762xR25744",
            "comparison_id": "R25762",
            "paper_id": "R25744",
            "text": "A Parallel Apriori Algorithm for Frequent Itemsets Mining \"finding frequent itemsets is one of the most investigated fields of data mining. the apriori algorithm is the most established algorithm for frequent itemsets mining (fim). several implementations of the apriori algorithm have been reported and evaluated. one of the implementations optimizing the data structure with a trie by bodon catches our attention. the results of the bodon's implementation for finding frequent itemsets appear to be faster than the ones by borgelt and goethals. in this paper, we revised bodon's implementation into a parallel one where input transactions are read by a parallel computer. the effect a parallel computer on this modified implementation is presented\"",
            "contribution_ids": [
                "R25745"
            ]
        },
        {
            "instance_id": "R25762xR25756",
            "comparison_id": "R25762",
            "paper_id": "R25756",
            "text": "A trie-based APRIORI implementation for mining frequent item sequences \"in this paper we investigate a trie-based apriori algorithm for mining frequent item sequences in a transactional database. we examine the data structure, implementation and algorithmic features mainly focusing on those that also arise in frequent itemset mining. in our analysis we take into consideration modern processors' properties (memory hierarchies, prefetching, branch prediction, cache line size, etc.), in order to better understand the results of the experiments.\"",
            "contribution_ids": [
                "R25757"
            ]
        },
        {
            "instance_id": "R25762xR25732",
            "comparison_id": "R25762",
            "paper_id": "R25732",
            "text": "Fast Algorithms for Mining Association Rules we consider the problem of discovering association rules between items in a large database of sales transactions. we present two new algorithms for solving thii problem that are fundamentally different from the known algorithms. empirical evaluation shows that these algorithms outperform the known algorithms by factors ranging from three for small problems to more than an order of magnitude for large problems. we also show how the best features of the two proposed algorithms can be combined into a hybrid algorithm, called apriorihybrid. scale-up experiments show that apriorihybrid scales linearly with the number of transactions. apriorihybrid also has excellent scale-up properties with respect to the transaction size and the number of items in the database.",
            "contribution_ids": [
                "R25733"
            ]
        },
        {
            "instance_id": "R25762xR25748",
            "comparison_id": "R25762",
            "paper_id": "R25748",
            "text": "Efficient mining of weighted association rules (WAR) in this paper, we extend the tradition association rule problem by allowing a weight to be associated with each item in a transaction, to re ect interest/intensity of the item within the transaction. this provides us in turn with an opportunity to associate a weight parameter with each item in the resulting association rule. we call it weighted association rule (war). war not only improves the con dence of the rules, but also provides a mechanism to do more effective target marketing by identifying or segmenting customers based on their potential degree of loyalty or volume of purchases. our approach mines wars by rst ignoring the weight and nding the frequent itemsets (via a traditional frequent itemset discovery algorithm), and is followed by introducing the weight during the rule generation. it is shown by experimental results that our approach not only results in shorter average execution times, but also produces higher quality results than the generalization of previous known methods on quantitative association rules.",
            "contribution_ids": [
                "R25749"
            ]
        },
        {
            "instance_id": "R25857xR25828",
            "comparison_id": "R25857",
            "paper_id": "R25828",
            "text": "Selective Hydrogenation of 1,3-Butadiene in the Presence of an Excess of Alkenes over Supported Bimetallic Gold\u00e2\u0088\u0092Palladium Catalysts supported au catalysts modified by the addition of low amount of pd (au/pd atomic ratio \u226510), prepared by either codeposition\u2212precipitation (dp) or coimpregnation in excess of solution (ies), result in the formation of bimetallic au\u2212pd particles that promote the selective hydrogenation of butadiene in the presence of propene. the dp method appears more appropriate to obtain reproducible and homogeneous bimetallic catalysts with smaller nanoparticles than the ies method, although it does not allow one to perfectly control the au/pd ratio. playing with the au/pd ratio, it is possible to modulate the catalytic properties, especially in the case of the dp samples, and to reach a satisfying compromise between activity and selectivity, with a very low amount of alkanes formed at complete conversion of butadiene. co adsorption followed by drifts indicates that bimetallic au/pd alloy particles are formed, except for the catalyst prepared by ies with the lowest au/pd atomic ratio of 10. pd segregation to the surfa...",
            "contribution_ids": [
                "R25829"
            ]
        },
        {
            "instance_id": "R25857xR25803",
            "comparison_id": "R25857",
            "paper_id": "R25803",
            "text": "Intermetallic Compound Pd 2 Ga as a Selective Catalyst for the Semi-Hydrogenation of Acetylene: From Model to High Performance Systems selective catalytic hydrogenation has wide applications in both petrochemical and fine chemical industries, however, it remains challenging when two or multiple functional groups coexist in the substrate. to tackle this challenge, the \"active site isolation\" strategy has been proved effective, and various approaches to the site isolation have been developed. in this review, we have summarized these approaches, including adsorption/grafting of n/s-containing organic molecules on the metal surface, partial covering of active metal surface by metal oxides either via doping or through strong metal-support interaction, confinement of active metal nanoparticles in micro- or mesopores of the supports, formation of bimetallic alloys or intermetallics or core@shell structures with a relatively inert metal (ib and iib) or nonmetal element (b, c, s, etc.), and construction of single-atom catalysts on reducible oxides or inert metals. both advantages and disadvantages of each approach toward the site isolation have been discussed for three types of chemoselective hydrogenation reactions, including alkynes/dienes to monoenes, \u03b1,\u03b2-unsaturated aldehydes/ketones to the unsaturated alcohols, and substituted nitroarenes to the corresponding anilines. the key factors affecting the catalytic activity/selectivity, in particular, the geometric and electronic structure of the active sites, are discussed with the aim to extract fundamental principles for the development of efficient and selective catalysts in hydrogenation as well as other transformations.",
            "contribution_ids": [
                "R25804"
            ]
        },
        {
            "instance_id": "R25857xR25797",
            "comparison_id": "R25857",
            "paper_id": "R25797",
            "text": "TiO2 supported Pd@Ag as highly selective catalysts for hydrogenation of acetylene in excess ethylene a novel tio2 supported core-shell (pd@ag) bimetallic catalyst was fabricated via the sequential photodeposition method. the ag shell effectively blocks the high coordination sites on the pd core, and therefore pronouncedly enhances the ethylene selectivity for the catalytic hydrogenation of acetylene in excess ethylene.",
            "contribution_ids": [
                "R25798"
            ]
        },
        {
            "instance_id": "R25857xR25807",
            "comparison_id": "R25857",
            "paper_id": "R25807",
            "text": "Nanosizing Intermetallic Compounds Onto Carbon Nanotubes: Active and Selective Hydrogenation Catalysts therefore, nanosizing andsupporting the annealed metal products remain challenges.another difficulty is in directly preparing supportedcatalysts while simultaneously obtaining good crystallite sizecontrol. a good catalyst support should be capable ofinhibiting sintering and loss of the catalyst during reaction.fabrication of supported intermetallics catalysts in nanoscaledimensionsrequiresareliablemethodthatfacilitatesnotonlysize control but a thermally stable phase under reactionconditions. since the work of iijima in 1991,",
            "contribution_ids": [
                "R25808"
            ]
        },
        {
            "instance_id": "R25857xR25855",
            "comparison_id": "R25857",
            "paper_id": "R25855",
            "text": "Crystal-Facet Effect of \u00ce\u00b3-Al2O3 on Supporting CrOx for Catalytic Semihydrogenation of Acetylene with the successful preparation of \u03b3-alumina with high-energy external surfaces such as {111} facets, the crystal-facet effect of \u03b3-al2o3 on surface-loaded crox has been explored for semihydrogenation of acetylene. our results indeed demonstrate that the harmonious interaction of crox with traditional \u03b3-al2o3, the external surfaces of which are typically low-energy{110} facets, has caused a highly efficient performance for semihydrogenation of acetylene over crox/(110)\u03b3-al2o3 catalyst, whereas the activity of the crox/(111)\u03b3-al2o3 catalyst for acetylene hydrogenation is suppressed dramatically due to the limited formation of active cr species, restrained by the high-energy {111} facets of \u03b3-al2o3. furthermore, the use of inexpensive crox as the active component for semihydrogenation of acetylene is an economically friendly alternative relative to commercial precious pd catalysts. this work sheds light on a strategy for exploiting the crystal-facet effect of the supports to purposefully tailor the catalyti...",
            "contribution_ids": [
                "R25856"
            ]
        },
        {
            "instance_id": "R25857xR25809",
            "comparison_id": "R25857",
            "paper_id": "R25809",
            "text": "PdZn Intermetallic Nanostructure with Pd\u00e2\u0080\u0093Zn\u00e2\u0080\u0093Pd Ensembles for Highly Active and Chemoselective Semi-Hydrogenation of Acetylene intermetallic alloying of one active metal to another inert metal provides not only the improved dispersion of active centers but also a unique and homogeneous ensemble of active sites, thus offering new opportunities in a variety of reactions. herein, we report that pdzn intermetallic nanostructure with pd\u2013zn\u2013pd ensembles are both highly active and selective for the semihydrogenation of acetylene to ethylene, which is usually inaccessible due to the sequential hydrogenation to ethane. microcalorimetric measurements and density functional theory calculations demonstrate that the appropriate spatial arrangement of pd sites in the pd\u2013zn\u2013pd ensembles of the pdzn alloy leads to the moderate \u03c3-bonding mode for acetylene with two neighboring pd sites while the weak \u03c0-bonding pattern of ethylene adsorption on the single pd site, which facilitates the chemisorption toward acetylene and promotes the desorption of ethylene from the catalyst surface. as a result, it leads to the kinetic favor of the selective conver...",
            "contribution_ids": [
                "R25810",
                "R25811"
            ]
        },
        {
            "instance_id": "R25857xR25812",
            "comparison_id": "R25857",
            "paper_id": "R25812",
            "text": "MOF-Confined Sub-2 nm Atomically Ordered Intermetallic PdZn Nanoparticles as High-Performance Catalysts for Selective Hydrogenation of Acetylene controllable synthesis of ultrasmall atomically ordered intermetallic nanoparticles is a challenging task, owing to the high temperature commonly required for the formation of intermetallic phases. here, a metal\u2013organic framework (mof)\u2010confined co\u2010reduction strategy is developed for the preparation of sub\u20102 nm intermetallic pdzn nanoparticles, by employing the well\u2010defined porous structures of calcinated zif\u20108 (zif\u20108c) and an in situ co\u2010reduction therein. haadf\u2010stem, hrtem, and eds characterizations reveal the homogeneous dispersion of these sub\u20102 nm intermetallic pdzn nanoparticles within the zif\u20108c frameworks. xrd, xps, and exafs measurements further confirm the atomically ordered intermetallic phase nature of these sub\u20102 nm pdzn nanoparticles. selective hydrogenation of acetylene evaluation results show the excellent catalytic properties of the sub\u20102 nm intermetallic pdzn, which result from the energetically more favorable path for acetylene hydrogenation and ethylene desorption over the ultrasmall particles than over larger\u2010sized intermetallic pdzn as revealed by density functional theory (dft) calculations. moreover, this protocol is also extendable for the preparation of sub\u20102 nm intermetallic ptzn nanoparticles and is expected to provide a novel methodology in synthesizing ultrasmall atomically ordered intermetallic nanomaterials by rationally functionalizing mofs.",
            "contribution_ids": [
                "R25813"
            ]
        },
        {
            "instance_id": "R25857xR25772",
            "comparison_id": "R25857",
            "paper_id": "R25772",
            "text": "Detecting the Genesis of a High-Performance Carbon-Supported Pd Sulfide Nanophase and Its Evolution in the Hydrogenation of Butadiene a new procedure for preparation of palladium sulfide nanoparticles, which are deposited and anchored over highly graphitized carbon nanofibers, is presented. the preparation method is based on the use of pdso4 as metal precursor or alternatively in the previous functionalization of the carbon surfaces with sulfonic groups by treatment with fuming sulfuric acid. using an in situ high-energy x-ray diffraction technique, in both cases it is demonstrated that during the reduction treatment, the initially present palladium hydride is transformed into a palladium sulfide (pd4s). the catalytic properties of these materials have been tested in the gas-phase butadiene partial reduction to butenes. although metallic palladium nanoparticles supported in the same carbon fibers produce butane as the principal product, the supported pd4s nanocrystals mainly yield different isomers of butenes independently of the conversion level. furthermore, applying the same x-ray diffraction method reveals that this catalytic phase ...",
            "contribution_ids": [
                "R25773"
            ]
        },
        {
            "instance_id": "R25857xR25770",
            "comparison_id": "R25857",
            "paper_id": "R25770",
            "text": "A Highly Selective Catalyst for Partial Hydrogenation of 1,3-Butadiene: MgO-Supported Rhodium Clusters Selectively Poisoned with CO the research was supported by the european union seventh framework programme (fp7/2007-2013) under grant agreement n8 piof-ga-2009-253129 (p.s.) and by doe basic energy sciences (contract no. fg02-04er15513) (dy). we thank the doe division of materials sciences for its role in the operation and development of beam lines 4-1 at the stanford synchrotron radiation lightsource. we thank the beamline staff for valuable support.",
            "contribution_ids": [
                "R25771"
            ]
        },
        {
            "instance_id": "R25857xR25814",
            "comparison_id": "R25857",
            "paper_id": "R25814",
            "text": "Isolated Single-Atom Pd Sites in Intermetallic Nanostructures: High Catalytic Selectivity for Semihydrogenation of Alkynes improving the catalytic selectivity of pd catalysts is of key importance for various industrial processes and remains a challenge so far. given the unique properties of single-atom catalysts, isolating contiguous pd atoms into a single-pd site with another metal to form intermetallic structures is an effective way to endow pd with high catalytic selectivity and to stabilize the single site with the intermetallic structures. based on density functional theory modeling, we demonstrate that the (110) surface of pm3\u0305m pdin with single-atom pd sites shows high selectivity for semihydrogenation of acetylene, whereas the (111) surface of p4/mmm pd3in with pd trimer sites shows low selectivity. this idea has been further validated by experimental results that intermetallic pdin nanocrystals mainly exposing the (110) surface exhibit much higher selectivity for acetylene hydrogenation than pd3in nanocrystals mainly exposing the (111) surface (92% vs 21% ethylene selectivity at 90 \u00b0c). this work provides insight for rational design of bimetallic metal catalysts with specific catalytic properties.",
            "contribution_ids": [
                "R25815"
            ]
        },
        {
            "instance_id": "R25857xR25789",
            "comparison_id": "R25857",
            "paper_id": "R25789",
            "text": "Ag Alloyed Pd Single-Atom Catalysts for Efficient Selective Hydrogenation of Acetylene to Ethylene in Excess Ethylene semihydrogenation of acetylene in an ethylene-rich stream is an industrially important process. conventional supported monometallic pd catalysts offer high acetylene conversion, but they suffer from very low selectivity to ethylene due to overhydrogenation and the formation of carbonaceous deposits. herein, a series of ag alloyed pd single-atom catalysts, possessing only ppm levels of pd, supported on silica gel were prepared by a simple incipient wetness coimpregnation method and applied to the selective hydrogenation of acetylene in an ethylene-rich stream under conditions close to the front-end employed by industry. high acetylene conversion and simultaneous selectivity to ethylene was attained over a wide temperature window, surpassing an analogous au alloyed pd single-atom system we previously reported. restructuring of agpd nanoparticles and electron transfer from ag to pd were evidenced by in situ ftir and in situ xps as a function of increasing reduction temperature. microcalorimetry and xanes measurements support both geometric and electronic synergetic effects between the alloyed pd and ag. kinetic studies provide valuable insight into the nature of the active sites within these agpd/sio2 catalysts, and hence, they provide evidence for the key factors underpinning the excellent performance of these bimetallic catalysts toward the selective hydrogenation of acetylene under ethylene-rich conditions while minimizing precious metal usage.",
            "contribution_ids": [
                "R25790"
            ]
        },
        {
            "instance_id": "R25857xR25783",
            "comparison_id": "R25857",
            "paper_id": "R25783",
            "text": "Pd@C core\u00e2\u0080\u0093shell nanoparticles on carbon nanotubes as highly stable and selective catalysts for hydrogenation of acetylene to ethylene highly stable and selective pd-based catalyst was synthesized by covering supported pd nanoparticles with an n-doped carbon shell for acetylene hydrogenation.",
            "contribution_ids": [
                "R25784"
            ]
        },
        {
            "instance_id": "R25857xR25801",
            "comparison_id": "R25857",
            "paper_id": "R25801",
            "text": "Synthesis and Catalytic Properties of Nanoparticulate Intermetallic Ga\u00e2\u0080\u0093Pd Compounds a two-step synthesis for the preparation of single-phase and nanoparticulate gapd and gapd(2) by coreduction of ionic metal-precursors with lihbet(3) in thf without additional stabilizers is described. the coreduction leads initially to the formation of pd nanoparticles followed by a pd-mediated reduction of ga(3+) on their surfaces, requiring an additional annealing step. the majority of the intermetallic particles have diameters of 3 and 7 nm for gapd and gapd(2), respectively, and unexpected narrow size distributions as determined by disk centrifuge measurements. the nanoparticles have been characterized by xrd, tem, and chemical analysis to ensure the formation of the intermetallic compounds. unsupported nanoparticles possess high catalytic activity while maintaining the excellent selectivity of the ground bulk materials in the semihydrogenation of acetylene. the activity could be further increased by depositing the particles on \u03b1-al(2)o(3).",
            "contribution_ids": [
                "R25802"
            ]
        },
        {
            "instance_id": "R25900xR25888",
            "comparison_id": "R25900",
            "paper_id": "R25888",
            "text": "Formation and Characterization of PdZn Alloy: A Very Selective Catalyst for Alkyne Semihydrogenation the formation of a pdzn alloy from a 4.3% pd/zno catalyst was characterized by combined in situ high-resolution x-ray diffraction (hrxrd) and x-ray absorption spectroscopy (xas). alloy formation started already at around 100 \u00b0c, likely at the surface, and reached the bulk with increasing temperature. the structure of the catalyst was close to the bulk value of a 1:1 pdzn alloy with a l1o structure (rpd\u2212pd = 2.9 a, rpd\u2212zn = 2.6 a, cnpd\u2212zn = 8, cnpd\u2212pd = 4) after reduction at 300 \u00b0c and above. the activity of the gas-phase hydrogenation of 1-pentyne decreased with the formation of the pdzn alloy. in contrast to pd/sio2, no full hydrogenation occurred over pd/zno. over time, only slight decomposition of the alloy occurred under reaction conditions.",
            "contribution_ids": [
                "R25889"
            ]
        },
        {
            "instance_id": "R25900xR25868",
            "comparison_id": "R25900",
            "paper_id": "R25868",
            "text": "Selective Hydrogenation of Polyunsaturated Fatty Acids Using Alkanethiol Self-Assembled Monolayer-Coated Pd/Al2O3 Catalysts pd/al2o3 catalysts coated with various thiolate self-assembled monolayers (sams) were used to direct the partial hydrogenation of 18-carbon polyunsaturated fatty acids, yielding a product stream enriched in monounsaturated fatty acids (with low saturated fatty acid content), a favorable result for increasing the oxidative stability of biodiesel. the uncoated pd/al2o3 catalyst quickly saturated all fatty acid reactants under hydrogenation conditions, but the addition of alkanethiol sams markedly increased the reaction selectivity to the monounsaturated product oleic acid to a level of 80\u201390%, even at conversions >70%. this effect, which is attributed to steric effects between the sams and reactants, was consistent with the relative consumption rates of linoleic and oleic acid using alkanethiol-coated and uncoated pd/al2o3 catalysts. with an uncoated pd/al2o3 catalyst, each fatty acid, regardless of its degree of saturation had a reaction rate of \u223c0.2 mol reactant consumed per mole of surface palladium per ...",
            "contribution_ids": [
                "R25869"
            ]
        },
        {
            "instance_id": "R25900xR25894",
            "comparison_id": "R25900",
            "paper_id": "R25894",
            "text": "Single atom alloy surface analogs in Pd0.18Cu15 nanoparticles for selective hydrogenation reactions we report a novel synthesis of nanoparticle pd-cu catalysts, containing only trace amounts of pd, for selective hydrogenation reactions. pd-cu nanoparticles were designed based on model single atom alloy (saa) surfaces, in which individual, isolated pd atoms act as sites for hydrogen uptake, dissociation, and spillover onto the surrounding cu surface. pd-cu nanoparticles were prepared by addition of trace amounts of pd (0.18 atomic (at)%) to cu nanoparticles supported on al2o3 by galvanic replacement (gr). the catalytic performance of the resulting materials for the partial hydrogenation of phenylacetylene was investigated at ambient temperature in a batch reactor under a head pressure of hydrogen (6.9 bar). the bimetallic pd-cu nanoparticles have over an order of magnitude higher activity for phenylacetylene hydrogenation when compared to their monometallic cu counterpart, while maintaining a high selectivity to styrene over many hours at high conversion. greater than 94% selectivity to styrene is observed at all times, which is a marked improvement when compared to monometallic pd catalysts with the same pd loading, at the same total conversion. x-ray photoelectron spectroscopy and uv-visible spectroscopy measurements confirm the complete uptake and alloying of pd with cu by gr. scanning tunneling microscopy and thermal desorption spectroscopy of model saa surfaces confirmed the feasibility of hydrogen spillover onto an otherwise inert cu surface. these model studies addressed a wide range of pd concentrations related to the bimetallic nanoparticles.",
            "contribution_ids": [
                "R25895"
            ]
        },
        {
            "instance_id": "R25900xR25884",
            "comparison_id": "R25900",
            "paper_id": "R25884",
            "text": "Design of Core-Pd/Shell-Ag Nanocomposite Catalyst for Selective Semihydrogenation of Alkynes we designed core-pd/shell-ag nanocomposite catalyst (pd@ag) for highly selective semihydrogenation of alkynes. the construction of the core\u2013shell nanocomposite enables a significant improvement in the low activity of ag nps for the selective semihydrogenation of alkynes because hydrogen is supplied from the core-pd nps to the shell-ag nps in a synergistic manner. simultaneously, coating the core-pd nps with shell-ag nps results in efficient suppression of overhydrogenation of alkenes by the pd nps. this complementary action of core-pd and shell-ag provides high chemoselectivity toward a wide range of alkenes with high z-selectivity under mild reaction conditions (room temperature and 1 atm h2). moreover, pd@ag can be easily separated from the reaction mixture and is reusable without loss of catalytic activity or selectivity.",
            "contribution_ids": [
                "R25885"
            ]
        },
        {
            "instance_id": "R25900xR25858",
            "comparison_id": "R25900",
            "paper_id": "R25858",
            "text": "Beyond the use of modifiers in selective alkyne hydrogenation: silver and gold nanocatalysts in flow mode for sustainable alkene production supported silver and gold nanoparticles are highly stereo and chemoselective catalysts for the three-phase hydrogenation of alkynes in continuous mode.",
            "contribution_ids": [
                "R25859",
                "R25860"
            ]
        },
        {
            "instance_id": "R25900xR25896",
            "comparison_id": "R25900",
            "paper_id": "R25896",
            "text": "A stable single-site palladium catalyst for hydrogenations we report the preparation and hydrogenation performance of a single-site palladium catalyst that was obtained by the anchoring of pd\\u2005atoms into the cavities of mesoporous polymeric graphitic carbon nitride. the characterization of the material confirmed the atomic dispersion of the palladium phase throughout the sample. the catalyst was applied for three-phase hydrogenations of alkynes and nitroarenes in a continuous-flow reactor, showing its high activity and product selectivity in comparison with benchmark catalysts based on nanoparticles. density functional theory calculations provided fundamental insights into the material structure and attributed the high catalyst activity and selectivity to the facile hydrogen activation and hydrocarbon adsorption on atomically dispersed pd sites.",
            "contribution_ids": [
                "R25897"
            ]
        },
        {
            "instance_id": "R25900xR25863",
            "comparison_id": "R25900",
            "paper_id": "R25863",
            "text": "Green, Multi-Gram One-Step Synthesis of Core-Shell Nanocomposites in Water and Their Catalytic Application to Chemoselective Hydrogenations we devise a new and green route for the multi-gram synthesis of core-shell nanoparticles (nps) in one step under organic-free and ph-neutral conditions. simply mixing core and shell metal precursors in the presence of solid metal oxides in water allowed for the facile fabrication of small ceo2 -covered au and ag nanoparticles dispersed on metal oxides in one step. the ceo2 -covered au nanoparticles acted as a highly efficient and reusable catalyst for a series of chemoselective hydrogenations, while retaining c=c bonds in diverse substrates. consequently, higher environmental compatibility and more efficient energy savings were achieved across the entire process, including catalyst preparation, reaction, separation, and reuse.",
            "contribution_ids": [
                "R25864"
            ]
        },
        {
            "instance_id": "R25900xR25898",
            "comparison_id": "R25900",
            "paper_id": "R25898",
            "text": "Merging Single-Atom-Dispersed Silver and Carbon Nitride to a Joint Electronic System via Copolymerization with Silver Tricyanomethanide herein, we present an approach to create a hybrid between single-atom-dispersed silver and a carbon nitride polymer. silver tricyanomethanide (agtcm) is used as a reactive comonomer during templated carbon nitride synthesis to introduce both negative charges and silver atoms/ions to the system. the successful introduction of the extra electron density under the formation of a delocalized joint electronic system is proven by photoluminescence measurements, x-ray photoelectron spectroscopy investigations, and measurements of surface \u03b6-potential. at the same time, the principal structure of the carbon nitride network is not disturbed, as shown by solid-state nuclear magnetic resonance spectroscopy and electrochemical impedance spectroscopy analysis. the synthesis also results in an improvement of the visible light absorption and the development of higher surface area in the final products. the atom-dispersed agtcm-doped carbon nitride shows an enhanced performance in the selective hydrogenation of alkynes in comparison with the performance of other conventional ag-based materials prepared by spray deposition and impregnation-reduction methods, here exemplified with 1-hexyne.",
            "contribution_ids": [
                "R25899"
            ]
        },
        {
            "instance_id": "R25900xR25892",
            "comparison_id": "R25900",
            "paper_id": "R25892",
            "text": "Palladium\u00e2\u0080\u0093gold single atom alloy catalysts for liquid phase selective hydrogenation of 1-hexyne silica supported and unsupported pdau single atom alloys (saas) were investigated for the selective hydrogenation of 1-hexyne to hexenes under mild conditions.",
            "contribution_ids": [
                "R25893"
            ]
        },
        {
            "instance_id": "R25900xR25861",
            "comparison_id": "R25900",
            "paper_id": "R25861",
            "text": "One-step Synthesis of Core-Gold/Shell- Ceria Nanomaterial and Its Catalysis for Highly Selective Semi- hydrogenation of Alkynes we report a facile synthesis of new core-au/shell-ceo2 nanoparticles (au@ceo2) using a redox-coprecipitation method, where the au nanoparticles and the nanoporous shell of ceo2 are simultaneously formed in one step. the au@ceo2 catalyst enables the highly selective semihydrogenation of various alkynes at ambient temperature under additive-free conditions. the core-shell structure plays a crucial role in providing the excellent selectivity for alkenes through the selective dissociation of h2 in a heterolytic manner by maximizing interfacial sites between the core-au and the shell-ceo2.",
            "contribution_ids": [
                "R25862"
            ]
        },
        {
            "instance_id": "R25900xR25876",
            "comparison_id": "R25900",
            "paper_id": "R25876",
            "text": "A Pd- Cu2O nanocomposite as an effective synergistic catalyst for selective semi-hydrogenation of the terminal alkynes only a new type lead-free pd\u2013cu 2 o nanocomposite catalyst shows \u201cdouble\u201d selectivities for hydrogenation of alkynes: only terminal alkynes hydrogenated and only alkenes produced, i.e. no internal alkyne is hydrogenated.",
            "contribution_ids": [
                "R25877"
            ]
        },
        {
            "instance_id": "R25999xR25989",
            "comparison_id": "R25999",
            "paper_id": "R25989",
            "text": "Computer understanding of document structure we describe a system which is capable of learning the presentation of document logical structure, exemplary as shown for business letters. presenting a set of instances to the system, it clusters them into structural concepts and induces a concept hierarchy. this concept hierarchy is taken as a reference for classifying future input. the article introduces the sequence of learning steps and describes how the resulting concept hierarchy is applied to logical labeling, and reports the results. \u00a9 1996 john wiley & sons, inc.",
            "contribution_ids": [
                "R25990",
                "R26013"
            ]
        },
        {
            "instance_id": "R25999xR25985",
            "comparison_id": "R25999",
            "paper_id": "R25985",
            "text": "Knowledge-based derivation of document logical structure the analysis of a document image to derive a symbolic description of its structure and contents involves using spatial domain knowledge to classify the different printed blocks (e.g., text paragraphs), group them into logical units (e.g., newspaper stories), and determine the reading order of the text blocks within each unit. these steps describe the conversion of the physical structure of a document into its logical structure. we have developed a computational model for document logical structure derivation, in which a rule-based control strategy utilizes the data obtained from analyzing a digitized document image, and makes inferences using a multi-level knowledge base of document layout rules. the knowledge-based document logical structure derivation system (delos) based on this model consists of a hierarchical rule-based control system to guide the block classification, grouping and read-ordering operations; a global data structure to store the document image data and incremental inferences; and a domain knowledge base to encode the rules governing document layout.",
            "contribution_ids": [
                "R25986",
                "R26011"
            ]
        },
        {
            "instance_id": "R25999xR25981",
            "comparison_id": "R25999",
            "paper_id": "R25981",
            "text": "Document image segmentation and text area ordering a system for document image segmentation and ordering text areas is described and applied to both japanese and english complex printed page layouts. there is no need to make any assumption about the shape of blocks, hence the segmentation technique can handle not only skewed images without skew-correction but also documents where column are not rectangular. in this technique, on the bottom-up strategy, the connected components are extracted from the reduced image, and classified according to their local information. the connected components are merged into lines, and lines are merged into areas. extracted text areas are classified as body, caption, header, and footer. a tree graph of the layout of body texts is made, and we get the order of texts by preorder traversal on the graph. the authors introduce the influence range of each node, a procedure for the title part, and extraction of the white horizontal separator. making it possible to get good results on various documents. the total system is fast and compact. >",
            "contribution_ids": [
                "R25982",
                "R26009"
            ]
        },
        {
            "instance_id": "R25999xR25977",
            "comparison_id": "R25999",
            "paper_id": "R25977",
            "text": "Page grammars and page parsing. A syntactic approach to document layout recognition describes a syntactic approach to deducing the logical structure of printed documents from their physical layout. page layout is described by a two-dimensional grammar, similar to a context-free string grammar, and a chart parser is used to parse segmented page images according to the grammar. this process is part of a system which reads scanned document images and produces computer-readable text in a logical mark-up format such as sgml. the system is briefly outlined, the grammar formalism and the parsing algorithm are described in detail, and some experimental results are reported. >",
            "contribution_ids": [
                "R25978",
                "R26007"
            ]
        },
        {
            "instance_id": "R25999xR25993",
            "comparison_id": "R25999",
            "paper_id": "R25993",
            "text": "Logical structure analysis of document images based on emergent computation a new method for logical structure analysis of document images is proposed in this paper as the basis for a document reader which can extract logical information from various printed documents. the proposed system consists of five basic modules: typography analysis, object recognition, object segmentation, object grouping and object modification. emergent computation, which is a key concept of artificial life, is adopted for the cooperative interaction among the modules in the system in order to achieve an effective and flexible behavior of the whole system. it has two principal advantages over other methods: adaptive system configuration for various and complex logical structures, and robust document analysis that is tolerant of erroneous feature detection.",
            "contribution_ids": [
                "R25994",
                "R26015"
            ]
        },
        {
            "instance_id": "R25999xR25963",
            "comparison_id": "R25999",
            "paper_id": "R25963",
            "text": "Understanding multi-articled documents a document understanding method based on the tree representation of document structures is proposed. it is shown that documents have an obvious hierarchical structure in their geometry which is represented by a tree. a small number of rules are introduced to transform the geometric structure into the logical structure which represents the semantics. the virtual field separator technique is employed to utilize the information carried by special constituents of documents such as field separators and frames, keeping the number of transformation rules small. experimental results on a variety of document formats have shown that the proposed method is applicable to most of the documents commonly encountered in daily use, although there is still room for further refinement of the transformation rules. >",
            "contribution_ids": [
                "R25964",
                "R26000"
            ]
        },
        {
            "instance_id": "R25999xR25995",
            "comparison_id": "R25999",
            "paper_id": "R25995",
            "text": "Information theoretic analysis of postal address fields for automatic address interpretation \"this paper concerns a study of information content in postal address fields for automatic address interpretation. information provided by a combination of address components and information interaction among components is characterized in terms of shannon's entropy. the efficiency of assignment strategies for determining a delivery point code can be compared by the propagation of uncertainty in address components. the quantity of redundancy between components can be computed from the information provided by these components. this information is useful in developing a strategy for selecting a useful component for recovering the value of an uncertain component. the uncertainty of a component based on another known component can be measured by conditional entropy. by ranking the uncertainty quantity, the effective processing flow for determining the value of a candidate component can be constructed.\"",
            "contribution_ids": [
                "R25996"
            ]
        },
        {
            "instance_id": "R25999xR25991",
            "comparison_id": "R25999",
            "paper_id": "R25991",
            "text": "Logical structure analysis of book document images using contents information numerous studies have so far been carried out extensively for the analysis of document image structure, with particular emphasis placed on media conversion and layout analysis. for the conversion of a collection of books in a library into the form of hypertext documents, a logical structure extraction technology is indispensable, in addition to document layout analysis. the table of contents of a book generally involves very concise and faithful information to represent the logical structure of the entire book. that is to say, we can efficiently analyze the logical structure of a book by making full use of its contents pages. this paper proposes a new approach for document logical structure analysis to convert document images and contents information into an electronic document. first, the contents pages of a book are analyzed to acquire the overall document logical structure. thereafter, we are able to use this information to acquire the logical structure of all the pages of the book by analyzing consecutive pages of a portion of the book. test results demonstrate very high discrimination rates: up to 97.6% for the headline structure, 99.4% for the text structure, 97.8% for the page-number structure and almost 100% for the head-foot structure.",
            "contribution_ids": [
                "R25992",
                "R26014"
            ]
        },
        {
            "instance_id": "R25999xR25979",
            "comparison_id": "R25999",
            "paper_id": "R25979",
            "text": "Syntactic segmentation and labeling of digitized pages from technical journals a method for extracting alternating horizontal and vertical projection profiles are from nested sub-blocks of scanned page images of technical documents is discussed. the thresholded profile strings are parsed using the compiler utilities lex and yacc. the significant document components are demarcated and identified by the recursive application of block grammars. backtracking for error recovery and branch and bound for maximum-area labeling are implemented with unix shell programs. results of the segmentation and labeling process are stored in a labeled x-y tree. it is shown that families of technical documents that share the same layout conventions can be readily analyzed. results from experiments in which more than 20 types of document entities were identified in sample pages from two journals are presented. >",
            "contribution_ids": [
                "R25980",
                "R26008"
            ]
        },
        {
            "instance_id": "R26017xR25975",
            "comparison_id": "R26017",
            "paper_id": "R25975",
            "text": "Modeling documents for structure recognition using generalized N-grams we present and discuss a novel approach to modeling logical structures of documents, based on a statistical representation of patterns in a document class. an efficient and error tolerant recognition heuristics adapted to the model is proposed. the statistical approach permits easily automated and incremental learning of the model. the approach has been partially evaluated on a prototype. a discussion of the results achieved by the prototype is finally made.",
            "contribution_ids": [
                "R25976",
                "R26006"
            ]
        },
        {
            "instance_id": "R26017xR25991",
            "comparison_id": "R26017",
            "paper_id": "R25991",
            "text": "Logical structure analysis of book document images using contents information numerous studies have so far been carried out extensively for the analysis of document image structure, with particular emphasis placed on media conversion and layout analysis. for the conversion of a collection of books in a library into the form of hypertext documents, a logical structure extraction technology is indispensable, in addition to document layout analysis. the table of contents of a book generally involves very concise and faithful information to represent the logical structure of the entire book. that is to say, we can efficiently analyze the logical structure of a book by making full use of its contents pages. this paper proposes a new approach for document logical structure analysis to convert document images and contents information into an electronic document. first, the contents pages of a book are analyzed to acquire the overall document logical structure. thereafter, we are able to use this information to acquire the logical structure of all the pages of the book by analyzing consecutive pages of a portion of the book. test results demonstrate very high discrimination rates: up to 97.6% for the headline structure, 99.4% for the text structure, 97.8% for the page-number structure and almost 100% for the head-foot structure.",
            "contribution_ids": [
                "R25992",
                "R26014"
            ]
        },
        {
            "instance_id": "R26017xR25989",
            "comparison_id": "R26017",
            "paper_id": "R25989",
            "text": "Computer understanding of document structure we describe a system which is capable of learning the presentation of document logical structure, exemplary as shown for business letters. presenting a set of instances to the system, it clusters them into structural concepts and induces a concept hierarchy. this concept hierarchy is taken as a reference for classifying future input. the article introduces the sequence of learning steps and describes how the resulting concept hierarchy is applied to logical labeling, and reports the results. \u00a9 1996 john wiley & sons, inc.",
            "contribution_ids": [
                "R25990",
                "R26013"
            ]
        },
        {
            "instance_id": "R26017xR25997",
            "comparison_id": "R26017",
            "paper_id": "R25997",
            "text": "Automated labeling in document images the national library of medicine (nlm) is developing an automated system to produce bibliographic records for its medliner database. this system, named medical article record system (mars), employs document image analysis and understanding techniques and optical character recognition (ocr). this paper describes a key module in mars called the automated labeling (al) module, which labels all zones of interest (title, author, affiliation, and abstract) automatically. the al algorithm is based on 120 rules that are derived from an analysis of journal page layouts and features extracted from ocr output. experiments carried out on more than 11,000 articles in over 1,000 biomedical journals show the accuracy of this rule-based algorithm to exceed 96%.",
            "contribution_ids": [
                "R25998",
                "R26016"
            ]
        },
        {
            "instance_id": "R26017xR25963",
            "comparison_id": "R26017",
            "paper_id": "R25963",
            "text": "Understanding multi-articled documents a document understanding method based on the tree representation of document structures is proposed. it is shown that documents have an obvious hierarchical structure in their geometry which is represented by a tree. a small number of rules are introduced to transform the geometric structure into the logical structure which represents the semantics. the virtual field separator technique is employed to utilize the information carried by special constituents of documents such as field separators and frames, keeping the number of transformation rules small. experimental results on a variety of document formats have shown that the proposed method is applicable to most of the documents commonly encountered in daily use, although there is still room for further refinement of the transformation rules. >",
            "contribution_ids": [
                "R25964",
                "R26000"
            ]
        },
        {
            "instance_id": "R26017xR25987",
            "comparison_id": "R26017",
            "paper_id": "R25987",
            "text": "Near-wordless document structure classification automatic derivation of logical document structure from generic layout would enable the development of many highly flexible electronic document manipulation tools. this problem can be divided into the segmentation of text into pieces and the classification of these pieces as particular logical structures. this paper proposes an approach to the classification of logical document structures, according to their distance from predefined prototypes. the prototypes consider linguistic information minimally, thus relying minimally on the accuracy of ocr and decreasing language-dependence. different classes of logical structures and the differences in the requisite information for classifying them are discussed. a prototype format is proposed, existing prototypes and a distance measurement are described, and performance results are provided.",
            "contribution_ids": [
                "R25988",
                "R26012"
            ]
        },
        {
            "instance_id": "R26017xR25979",
            "comparison_id": "R26017",
            "paper_id": "R25979",
            "text": "Syntactic segmentation and labeling of digitized pages from technical journals a method for extracting alternating horizontal and vertical projection profiles are from nested sub-blocks of scanned page images of technical documents is discussed. the thresholded profile strings are parsed using the compiler utilities lex and yacc. the significant document components are demarcated and identified by the recursive application of block grammars. backtracking for error recovery and branch and bound for maximum-area labeling are implemented with unix shell programs. results of the segmentation and labeling process are stored in a labeled x-y tree. it is shown that families of technical documents that share the same layout conventions can be readily analyzed. results from experiments in which more than 20 types of document entities were identified in sample pages from two journals are presented. >",
            "contribution_ids": [
                "R25980",
                "R26008"
            ]
        },
        {
            "instance_id": "R26017xR25977",
            "comparison_id": "R26017",
            "paper_id": "R25977",
            "text": "Page grammars and page parsing. A syntactic approach to document layout recognition describes a syntactic approach to deducing the logical structure of printed documents from their physical layout. page layout is described by a two-dimensional grammar, similar to a context-free string grammar, and a chart parser is used to parse segmented page images according to the grammar. this process is part of a system which reads scanned document images and produces computer-readable text in a logical mark-up format such as sgml. the system is briefly outlined, the grammar formalism and the parsing algorithm are described in detail, and some experimental results are reported. >",
            "contribution_ids": [
                "R25978",
                "R26007"
            ]
        },
        {
            "instance_id": "R26063xR26041",
            "comparison_id": "R26063",
            "paper_id": "R26041",
            "text": "Analysis of Adhesive\u00e2\u0080\u0090Bonded Joints with Nonidentical Adherends in this paper the effect of the deflected configuration of the joint on the static equilibrium of the jointed portion is considered and the two end-binding moments of the joint are deduced from classical beam-plate theory in closed forms. this simplifies the calculation of the stress distribution, and makes feasible closed form solutions of stress-intensity factors. by this method, all boundary stress conditions of the joint can be strictly satisfied and the effects of the bonding material and the physical and dimensional properties of the nonidentical adherents are taken into account. the study results show that the intensities of the normal stress and the shearing stress are always much greater in a small zone at both ends of the joint. it was also found that the maximum shearing stress and the maximum normal stress always occur at different end zones of the joint.",
            "contribution_ids": [
                "R26042"
            ]
        },
        {
            "instance_id": "R26063xR26045",
            "comparison_id": "R26063",
            "paper_id": "R26045",
            "text": "A Method for the Stress Analysis of Lap Joints abstract a theory is presented for the adhesive stresses in single and double lap joints under tensile loading, while subjected to thermal stress. the formulation includes the effects of bending, shearing, stretching and hygrothermal deformation in both the adherend and adhesive. all boundary conditions, including shear stress free surfaces, are satisfied. the method is general and therefore applicable to a range of material properties and joint configurations including metal-to-metal, metal-to-cfrp or cfrp-to-cfrp. the solution is numerical and is based on an equilibrium finite element approach. through the use of an iterative procedure, the solution has been extended to cater for non-linear adhesive materials.",
            "contribution_ids": [
                "R26046"
            ]
        },
        {
            "instance_id": "R26063xR26033",
            "comparison_id": "R26063",
            "paper_id": "R26033",
            "text": "Bond Thickness Effects upon Stresses in Single-Lap Adhesive Joints results of an analytical investigation on the influence of bond thickness upon the stress distribution in singlelap adhesive joints are presented. the present work extends the basic approach for bonded joints, orginally introduced by goland and reissner, through use of a more complete shear-strain/displacement equation for the adhesive layer. this refinement was not found to be included in any of the numerous analytical investigations reviewed. as a result of the approach employed, the present work uncovers several interesting phenomena without adding any significant complication to the analysis. besides modifying some coefficients in the shear stress equations, completely new terms in the differential equation and boundary conditions for bond peel stress are obtained. sn addition, a variation of shear stress through the bond thickness, no matter how thin it may be, is analytically predicted only by the present theory. this through-the-bond-thickness variation of shear stress identifies two antisymmetrical adherend-bond interface points at which the shear stresses are highest. the growth of joint failures originating from these points agrees with results obtained from actual experiments.",
            "contribution_ids": [
                "R26034"
            ]
        },
        {
            "instance_id": "R26063xR26053",
            "comparison_id": "R26063",
            "paper_id": "R26053",
            "text": "A two-dimensional stress analysis of single-lap adhesive joints of dissimilar adherends subjected to tensile loads \"single-lap adhesive joints of dissimilar adherends subjected to tensile loads are analyzed as a three-body contact problem using the two-dimensional theory of elasticity. in the numerical calculations, the effects of young's modulus ratio between different adherends, the ratio of the adherend thicknesses, the ratio of the adherend lengths, and the adhesive thickness on the contact stress distributions at the interfaces are examined. as a result, it is found that (1) the stress singularity occurs near the edges of the interfaces and it increases at the edge of the interface of an adherend with smaller young's modulus; (2) the stress singularity increases at the edge of the interface of an adherend with thinner thickness; (3) the singular stresses increase at the edges of the two interfaces as the ratio of the upper adherend length to the lower one decreases; and (4) the singular stresses increase at the edges of the two interfaces as the adhesive thickness decreases when the adhesive is thin enough, and they also increase as the adhesive thickness increases when the adhesive is thick enough. in addition, the singular stresses obtained from the present analysis are compared with those obtained by bogy. fairly good agreement is seen between the present analysis and the results from bogy. strain measurement and finite element analysis (fea) were carried out. the analytical results are in fairly good agreement with the measured and the fea results.\"",
            "contribution_ids": [
                "R26054"
            ]
        },
        {
            "instance_id": "R26063xR26051",
            "comparison_id": "R26063",
            "paper_id": "R26051",
            "text": "Analysis of Adhesive-Bonded Joints, Square-End, and Spew-Fillet\u00e2\u0080\u0094High-Order Theory Approach the analysis of adhesive-bonded joints using a closed-form high-order theory (cfho theory) is presented, and its capabilities are demonstrated numerically for the case of single lap joints with and without a \u201cspew-fillet.\u201d the governing equations based on the cfho theory are presented along with the appropriate boundary/continuity conditions at the free edges. the joints consist of two metallic or composite laminated adherents that are interconnected through equilibrium and compatibility requirements by a 2d linear elastic adhesive layer. the cfho theory predicts that the distributions of the displacements through the thickness of the adhesive layer are nonlinear in general (high-order effects) and are a result of \\\\inot presumed\\\\n displacement patterns. the spew-fillet is modeled through an equivalent tensile bar, which enables quantification of the effects of the spew-fillet size on the stress fields. satisfactory comparisons with two-parameter elastic foundation solution (goland-reissner type) results and finite-element results are presented.",
            "contribution_ids": [
                "R26052"
            ]
        },
        {
            "instance_id": "R26063xR26059",
            "comparison_id": "R26063",
            "paper_id": "R26059",
            "text": "Strength of adhesive joints with adherend yielding: I. Analytical model a sandwich element can be isolated in all two-dimensional adhesive joints, thereby simplifying the analysis of strain and stress. an adhesive sandwich model has been developed that accommodates arbitrary loading, a bilinear adherend stress-strain response, and any form of nonlinear adhesive behavior. the model accounts for both the bending deformation and the shear deformation of the adherends. stress and strain distributions in the adhesive were obtained by solving a system of six differential equations using a finite-difference method. for a sample adhesive sandwich, the adhesive strains and stresses from the new model were compared with those of other models. finally, the model was coupled with an analytical solution for the detached section of an adhesive joint in peel. the stress and strain distributions in the adhesive and the root curvature of the peel adherend were then compared with finite element results. an accompanying article in this issue uses the model with experimental peel data to investigate the suitability of various adhesive failure criteria.",
            "contribution_ids": [
                "R26060"
            ]
        },
        {
            "instance_id": "R26063xR26043",
            "comparison_id": "R26063",
            "paper_id": "R26043",
            "text": "Development of a full elasto-plastic adhesive joint design analysis a previous adhesive joint analysis that accommodated non-linear adhesive behaviour is extended to model the elasto-plastic response of the adherends. the resulting analysis models the joint as an adherend-adhesive sandwich capable of sustaining any combination of end load conditions, thus enabling a wide variety of adhesive joints to be modelled. the adhesive is assumed to behave as a coupled set of non-linear shear and tension springs, and the adherends as cylindrically bent plates which yield under the action of combined tension and bending. the complete problem is reduced to a set of six non-linear first-order ordinary differential equations which are solved numerically using a finite-difference method. in this way a reasonable assessment of adhesive stresses and strains can be obtained easily, without resorting to the complexity of a two-dimensional finite element solution. a comparison between the results from these two methods has been made and is presented in this paper after the outline of the analysis derivations.",
            "contribution_ids": [
                "R26044"
            ]
        },
        {
            "instance_id": "R26107xR26095",
            "comparison_id": "R26107",
            "paper_id": "R26095",
            "text": "Field study on occupant comfort and the office thermal environment in rooms with displacement ventilation \"unlabelled\\na field survey of occupants' response to the indoor environment in 10 office buildings with displacement ventilation was performed. the response of 227 occupants was analyzed. about 24% of the occupants in the survey complained that they were daily bothered by draught, mainly at the lower leg. vertical air temperature difference measured between head and feet levels was less than 3 degrees c at all workplaces visited. combined local discomfort because of draught and vertical temperature difference does not seem to be a serious problem in rooms with displacement ventilation. almost one half (49%) of the occupants reported that they were daily bothered by an uncomfortable room temperature. forty-eight per cent of the occupants were not satisfied with the air quality.\\n\\n\\npractical implications\\nthe pmv and the draught rating indices as well as the specifications for local discomfort because of the separate impact of draught and vertical temperature difference, as defined in the present standards, are relevant for the design of a thermal environment in rooms with displacement ventilation and for its assessment in practice. increasing the supply air temperature in order to counteract draught discomfort is a measure that should be considered carefully; even if the desired stratification of pollution in the occupied zone is preserved, an increase of the inhaled air temperature may have a negative effect on perceived air quality.\"",
            "contribution_ids": [
                "R26096"
            ]
        },
        {
            "instance_id": "R26107xR26101",
            "comparison_id": "R26107",
            "paper_id": "R26101",
            "text": "Subjective indoor air quality in schools- the influence of high room temperature, carpeting, fleecy wall materials and volatile organic compounds (VOC) subjective indoor air quality in schools-the influence of high room temperature,carpeting, fleecy materials and volatile organic compounds (voc)",
            "contribution_ids": [
                "R26102"
            ]
        },
        {
            "instance_id": "R26107xR26099",
            "comparison_id": "R26107",
            "paper_id": "R26099",
            "text": "Linking indoor environment conditions to job satisfaction: a field study \"physical and questionnaire data were collected from 95 workstations at an open-plan office building in michigan, us. the physical measurements encompassed thermal, lighting, and acoustic variables, furniture dimensions, and an assessment of potential exterior view. occupants answered a detailed questionnaire concerning their environmental and job satisfaction, and aspects of well-being. these data were used to test, via mediated regression, a model linking the physical environment, through environmental satisfaction, to job satisfaction and other related measures. in particular, a significant link was demonstrated between overall environmental satisfaction and job satisfaction, mediated by satisfaction with management and with compensation. analysis of physical data was limited to the lighting domain. results confirmed the important role of window access at the desk in satisfaction with lighting, particularly through its effect on satisfaction with outside view. des donn\u00e9es physiques et des donn\u00e9es obtenues par questionnaire ont \u00e9t\u00e9 recueillies aupr\u00e8s de 95 postes de travail dans un immeuble de bureaux d\u00e9cloisonn\u00e9s du michigan, aux etats-unis. les mesures physiques comprenaient des variables thermiques, acoustiques et relatives \u00e0 l'\u00e9clairage, les dimensions des meubles, ainsi qu'une \u00e9valuation de la vue ext\u00e9rieure potentielle. les occupants ont r\u00e9pondu \u00e0 un questionnaire d\u00e9taill\u00e9 portant sur la satisfaction \u00e0 l'\u00e9gard de leur environnement et de leur travail, et sur des aspects relatifs au bien-\u00eatre. ces donn\u00e9es ont \u00e9t\u00e9 utilis\u00e9es pour tester, au moyen d'une r\u00e9gression m\u00e9diatis\u00e9e, un mod\u00e8le liant l'environnement physique, par la satisfaction \u00e0 l'\u00e9gard de l'environnement, \u00e0 la satisfaction dans le travail et aux autres mesures li\u00e9es. il a en particulier \u00e9t\u00e9 d\u00e9montr\u00e9 qu'il existe un lien important entre la satisfaction globale \u00e0 l'\u00e9gard de l'environnement et la satisfaction dans le travail, m\u00e9diatis\u00e9 par la satisfaction vis-\u00e0-vis de la direction et de la r\u00e9mun\u00e9ration. l'analyse des donn\u00e9es physiques a \u00e9t\u00e9 limit\u00e9e au domaine de l'\u00e9clairage. les r\u00e9sultats ont confirm\u00e9 que le fait de pouvoir acc\u00e9der \u00e0 une fen\u00eatre au bureau joue un r\u00f4le important dans la satisfaction \u00e0 l'\u00e9gard de l'\u00e9clairage, en particulier par son effet sur la satisfaction vis-\u00e0-vis de la vue ext\u00e9rieure. mots cl\u00e9s: satisfaction \u00e0 l'\u00e9gard de l'environnement, satisfaction dans le travail, \u00e9clairage, perception par les occupants, bureaux, productivit\u00e9 organisationnelle, vue, bien-\u00eatre\"",
            "contribution_ids": [
                "R26100"
            ]
        },
        {
            "instance_id": "R26107xR26087",
            "comparison_id": "R26107",
            "paper_id": "R26087",
            "text": "Second-Level Post-Occupancy Evaluation Analysis findings from a detailed analysis of post-occupancy evaluation data, sponsored by lri, which involved thirteen office buildings typical of current design practice, will be discussed. analysis of the data indicates that occupant satisfaction can be related to type of lighting system, presence of daylight, and patterns of luminance in the office. 15 refs., 9 figs., 3 tabs.",
            "contribution_ids": [
                "R26088"
            ]
        },
        {
            "instance_id": "R26127xR26111",
            "comparison_id": "R26127",
            "paper_id": "R26111",
            "text": "Underground activity and institutional change: Productive, protective and predatory behavior in transition economies this paper examines why some transitions are more successful than others by focusing attention on the role of productive, protective and predatory behaviors from the perspective of the new institutional economics. many transition economies are characterized by a fundamental inconsistency between formal and informal institutions. when formal and informal rules clash, noncompliant behaviors proliferate, among them, tax evasion, corruption, bribery, organized criminality, and theft of government property. these wealth redistributing protective and predatory behaviors activities absorb resources that could otherwise be used for wealth production resulting in huge transition costs. noncompliant behaviors--evasion, avoidance, circumvention, abuse, and/or corruption of institutional rules--comprise what we can be termed underground economies. a variety of underground economies can be differentiated according to the types of rules violated by the noncompliant behaviors. the focus of the new institutional economics is on the consequences of institutions--the rules that structure and constrain economic activity--for economic outcomes. underground economics is concerned with instances in which the rules are evaded, circumvented, and violated. it seeks to determine the conditions likely to foster rule violations, and to understand the various consequences of noncompliance with institutional rules. noncompliance with \u2018bad\u201d rules may actually foster development whereas non compliance with \u201cgood\u201d rules will hinder development. since rules differ, both the nature and consequences of rule violations will therefore depend on the particular rules violated. institutional economics and underground economics are therefore highly complementary. the former examines the rules of the game, the latter the strategic responses of individuals and organizations to those rules. economic performance depends on both the nature of the rules and the extent of compliance with them. institutions therefore do affect economic performance, but it is not always obvious which institutional rules dominate. where formal and informal institutions are coherent and consistent, the incentives produced by the formal rules will affect economic outcomes. under these circumstances, the rule of law typically secures property rights, reduces uncertainty, and lowers transaction costs. in regimes of discretionary authority where formal institutions conflict with informal norms, noncompliance with the formal rules becomes pervasive, and underground economic activity is consequential for economic outcomes.",
            "contribution_ids": [
                "R26112",
                "R26122"
            ]
        },
        {
            "instance_id": "R26146xR26140",
            "comparison_id": "R26146",
            "paper_id": "R26140",
            "text": "Integrating the unofficial economy into the dynamics of post-socialist economies: A framework of analysis and evidence over a third of economic activity in theformer soviet countries was estimated to occur in the unofficial economy by the mid-1990s; in central and eastern europe, the average is close to one-quarter. intraregional variations are great: in some countries 10 to 15 percent of economic activity is unofficial, and in some more than half of it. the growth of unofficial activity in most post-socialist countries, and its mitigating effect on the decline in official output during the early stages of the transition, have been marked. in this paper, the authors challenge the conventional view of how post-socialist economies function by incorporating the unofficial economy into an analysis of the full economy. then they advance a simple framework for understanding the evolution of the unofficial economy, and the links between both economies, highlighting the main characteristics of\"officialdom,\"contrasting conventional notions of\"informal\"or\"shadow\"economies, and focusing on what determines the decision to cross over from one segment to another. the initial empirical results seem to support hypothetical explanations of what determines the dynamics of the unofficial economy. the authors emphasize the speedy liberalization of markets, macro stability, and a stable and moderate tax regime. although widespread, most\"unofficialdom\"in the region is found to be relatively shallow--subject to reversal by appropriate economic policies. the framework and evidence presented here have implications for measurement, forecasting, and policymaking--calling for even faster liberalization and privatization than already advocated. and the lessons in social protection and taxation policy differ from conventional advice.",
            "contribution_ids": [
                "R26141"
            ]
        },
        {
            "instance_id": "R26146xR26144",
            "comparison_id": "R26146",
            "paper_id": "R26144",
            "text": "The size, origins, and character of Mongolia\u00e2\u0080\u0099s informal sector during the transition the explosion of informal entrepreneurial activity during mongolia\\'s transition to a market economy represents one of the most visible signs of change in this expansive but sparsely populated asian country. to deepen our understanding of mongolia\\'s informal sector during the transition, the author merges anecdotal experience from qualitative interviews with hard data from a survey of 770 informals in ulaanbaatar, from a national household survey, and from official employment statistics. using varied sources, the author generates rudimentary estimates of the magnitude of, and trends in, informal activity in mongolia, estimates that are surprisingly consistent with each other. he evaluates four types of reasons for the burst of informal activity in mongolia since 1990: 1) the crisis of the early and mid-1990s, during which large pools of labor were released from formal employment. 2) rural to urban migration. 3) the\"market\\'s\"reallocation of resources toward areas neglected under the old system: services such as distribution and transportation. 4) the institutional environments faced by the formal and informal sectors: hindering growth of the formal sector, facilitating entry for the informal sector. formal labor markets haven\\'t absorbed the labor made available by the crisis and by migration and haven\\'t fully responded to the demand for new services. the relative ease of entering the informal market explains that market\\'s great expansion. the relative difficulty of entering formal markets is not random but is driven by policy. improving policies in the formal sector could afford the same ease of entry there as is currently being experienced in the informal sector.",
            "contribution_ids": [
                "R26145"
            ]
        },
        {
            "instance_id": "R26194xR26192",
            "comparison_id": "R26194",
            "paper_id": "R26192",
            "text": "Deliveries in an inventory/routing problem using stochastic dynamic programming an industrial gases tanker vehicle visits n customers on a tour, with a possible (n + 1)st customer added at the end. the amount of needed product at each customer is a known random process, typically a wiener process. the objective is to adjust dynamically the amount of product provided on scene to each customer so as to minimize total expected costs, comprising costs of earliness, lateness, product shortfall, and returning to the depot nonempty. earliness costs are computed by invocation of an annualized incremental cost argument. amounts of product delivered to each customer are not known until the driver is on scene at the customer location, at which point the customer is either restocked to capacity or left with some residual empty capacity, the policy determined by stochastic dynamic programming. the methodology has applications beyond industrial gases.",
            "contribution_ids": [
                "R26193"
            ]
        },
        {
            "instance_id": "R26194xR26189",
            "comparison_id": "R26194",
            "paper_id": "R26189",
            "text": "A decomposition approach to the inventory routing problem with satellite facilities this paper presents a comprehensive decomposition scheme for solving the inventory routing problem in which a central supplier must restock a subset of customers on an intermittent basis. in this setting, the customer demand is not known with certainty and routing decisions taken over the short run might conflict with the long-run goal of minimizing annual operating costs. a unique aspect of the short-run subproblem is the presence of satellite facilities where vehicles can be reloaded and customer deliveries continued until the closing time is reached. three heuristics have been developed to solve the vehicle routing problem with satellite facilities (randomized clarke-wright, grasp, modified sweep). after the daily tours are derived, a parametric analysis is conducted to investigate the tradeoff between distance and annual costs. this leads to the development of the efficient frontier from which the decision maker is free to choose the most attractive alternative. the proposed procedures are tested on data sets generated from field experience with a national liquid propane distributor.",
            "contribution_ids": [
                "R26190"
            ]
        },
        {
            "instance_id": "R26194xR26181",
            "comparison_id": "R26194",
            "paper_id": "R26181",
            "text": "Dynamic allocations for multi-product distribution consider the problem of allocating multiple products by a distributor with limited capacity (truck size), who has a fixed sequence of customers (retailers) whose demands are unknown. each time the distributor visits a customer, he gets information about the realization of the demand for this customer, but he does not yet know the demands of the following customers. the decision faced by the distributor is how much to allocate to each customer given that the penalties for not satisfying demand are not identical. in addition, we optimally solve the problem of loading the truck with the multiple products, given the limited storage capacity. this framework can also be used for the general problem of seat allocation in the airline industry. as with the truck in the distribution problem, the airplane has limited capacity. a critical decision is how to allocate the available seats between early and late reservations (sequence of customers), for the different fare classes (multiple products), where the revenues from discount (early) and regular (late) passengers are different.",
            "contribution_ids": [
                "R26182"
            ]
        },
        {
            "instance_id": "R26194xR26161",
            "comparison_id": "R26194",
            "paper_id": "R26161",
            "text": "Analysis of a large scale vehicle routing problem with an inventory component \"description d'un systeme de distribution integre base sur l'optimisation, couramment developpe pour une grande entreprise commerciale. le probleme de distribution est tel qu'il est necessaire de prevoir les demandes des consommateurs, de choisir un sous ensemble de consommateurs, et de generer des itineraires journaliers pour les vehicules\"",
            "contribution_ids": [
                "R26162",
                "R26355"
            ]
        },
        {
            "instance_id": "R26194xR26167",
            "comparison_id": "R26194",
            "paper_id": "R26167",
            "text": "An Allocation and Distribution Model for Perishable Products this paper presents an allocation model for a perishable product, distributed from a regional center to a given set of locations with random demands. we consider the combined problem of allocating the available inventory at the center while deciding how these deliveries should be performed. two types of delivery patterns are analyzed: the first pattern assumes that all demand points receive individual deliveries; the second pattern subsumes the frequently occurring case in which deliveries are combined in multistop routes traveled by a fleet of vehicles. computational experience is reported.",
            "contribution_ids": [
                "R26168"
            ]
        },
        {
            "instance_id": "R26262xR26209",
            "comparison_id": "R26262",
            "paper_id": "R26209",
            "text": "Solving An Integrated Logistics Problem Arising In Grocery Distribution abstracta complex allocation-routing problem arising in grocery distribution is described. it is solved by means of a heuristic that alternates between these two components. tests on real and artificial data confirm the efficiency and the robustness of the proposed approach.",
            "contribution_ids": [
                "R26210"
            ]
        },
        {
            "instance_id": "R26262xR26235",
            "comparison_id": "R26262",
            "paper_id": "R26235",
            "text": "A genetic algorithm approach to the integrated inventory-distribution problem we introduce a new genetic algorithm (ga) approach for the integrated inventory distribution problem (iidp). we present the developed genetic representation and use a randomized version of a previously developed construction heuristic to generate the initial random population. we design suitable crossover and mutation operators for the ga improvement phase. the comparison of results shows the significance of the designed ga over the construction heuristic and demonstrates the capability of reaching solutions within 20% of the optimum on sets of randomly generated test problems.",
            "contribution_ids": [
                "R26236"
            ]
        },
        {
            "instance_id": "R26262xR26248",
            "comparison_id": "R26262",
            "paper_id": "R26248",
            "text": "Omya Hustadmarmor optimizes its supply chain for delivering calcium carbonate slurry to European paper manufacturers the norwegian company omya hustadmarmor supplies calcium carbonate slurry to european paper manufacturers from a single processing plant, using chemical tank ships of various sizes to transport its products. transportation costs are lower for large ships than for small ships, but their use increases planning complexity and creates problems in production. in 2001, the company faced overwhelming operational challenges and sought operations-research-based planning support. the ceo, sturla steinsvik, contacted m\u00f8re research molde, which conducted a project that led to the development of a decision-support system (dss) for maritime inventory routing. the core of the dss is an optimization model that is solved through a metaheuristic-based algorithm. the system helps planners to make stronger, faster decisions and has increased predictability and flexibility throughout the supply chain. it has saved production and transportation costs close to us$7 million a year. we project additional direct savings of nearly us$4 million a year as the company adds even larger ships to the fleet as a result of the project. in addition, the company has avoided investments of us$35 million by increasing capacity utilization. finally, the project has had a positive environmental effect by reducing overall oil consumption by more than 10 percent.",
            "contribution_ids": [
                "R26249",
                "R26374"
            ]
        },
        {
            "instance_id": "R26262xR26196",
            "comparison_id": "R26262",
            "paper_id": "R26196",
            "text": "Improving the distribution of industrial gases with an on-line computerized routing and scheduling optimizer for air products and chemicals, inc., inventory management of industrial gases at customer locations is integrated with vehicle scheduling and dispatching. their advanced decision support system includes on-line data entry functions, customer usage forecasting, a time/distance network with a shortest path algorithm to compute intercustomer travel times and distances, a mathematical optimization module to produce daily delivery schedules, and an interactive schedule change interface. the optimization module uses a sophisticated lagrangian relaxation algorithm to solve mixed integer programs with up to 800,000 variables and 200,000 constraints to near optimality. the system, first implemented in october, 1981, has been saving between 6% to 10% of operating costs.",
            "contribution_ids": [
                "R26197",
                "R26354"
            ]
        },
        {
            "instance_id": "R26262xR26224",
            "comparison_id": "R26262",
            "paper_id": "R26224",
            "text": "A Decomposition Approach for the Inventory-Routing Problem in this paper, we present a solution approach for the inventory-routing problem. the inventory-routing problem is a variation of the vehicle-routing problem that arises in situations where a vendor has the ability to make decisions about the timing and sizing of deliveries, as well as the routing, with the restriction that customers are not allowed to run out of product. we develop a two-phase approach based on decomposing the set of decisions: a delivery schedule is created first, followed by the construction of a set of delivery routes. the first phase utilizes integer programming, whereas the second phase employs routing and scheduling heuristics. our focus is on creating a solution methodology appropriate for large-scale real-life instances. computational experiments demonstrating the effectiveness of our approach are presented.",
            "contribution_ids": [
                "R26225",
                "R26365"
            ]
        },
        {
            "instance_id": "R26262xR26222",
            "comparison_id": "R26262",
            "paper_id": "R26222",
            "text": "Deterministic Order-Up-To Level Policies in an Inventory Routing Problem we consider a distribution problem in which a set of products has to be shipped from a supplier to several retailers in a given time horizon. shipments from the supplier to the retailers are performed by a vehicle of given capacity and cost. each retailer determines a minimum and a maximum level of the inventory of each product, and each must be visited before its inventory reaches the minimum level. every time a retailer is visited, the quantity of each product delivered by the supplier is such that the maximum level of the inventory is reached at the retailer. the problem is to determine for each discrete time instant the retailers to be visited and the route of the vehicle. various objective functions corresponding to different decision policies, and possibly to different decision makers, are considered. we present a heuristic algorithm and compare the solutions obtained with the different objective functions on a set of randomly generated problem instances.",
            "contribution_ids": [
                "R26223"
            ]
        },
        {
            "instance_id": "R26352xR26313",
            "comparison_id": "R26352",
            "paper_id": "R26313",
            "text": "The Stochastic Inventory Routing Problem with Direct Deliveries \" vendor managed inventory replenishment is a business practice in which vendors monitor their customers' inventories, and decide when and how much inventory should be replenished. the inventory routing problem addresses the coordination of inventory management and transportation. the ability to solve the inventory routing problem contributes to the realization of the potential savings in inventory and transportation costs brought about by vendor managed inventory replenishment. the inventory routing problem is hard, especially if a large number of customers is involved. we formulate the inventory routing problem as a markov decision process, and we propose approximation methods to find good solutions with reasonable computational effort. computational results are presented for the inventory routing problem with direct deliveries. \"",
            "contribution_ids": [
                "R26314"
            ]
        },
        {
            "instance_id": "R26352xR26269",
            "comparison_id": "R26352",
            "paper_id": "R26269",
            "text": "One Warehouse Multiple Retailer Systems with Vehicle Routing Costs we consider distribution systems with a depot and many geographically dispersed retailers each of which faces external demands occurring at constant, deterministic but retailer specific rates. all stock enters the system through the depot from where it is distributed to the retailers by a fleet of capacitated vehicles combining deliveries into efficient routes. inventories are kept at the retailers but not at the depot. we wish to determine feasible replenishment strategies (i.e., inventory rules and routing patterns) minimising (infinite horizon) long-run average transportation and inventory costs. we restrict ourselves to a class of strategies in which a collection of regions (sets of retailers) is specified which cover all outlets: if an outlet belongs to several regions, a specific fraction of its sales/operations is assigned to each of these regions. each time one of the retailers in a given region receives a delivery, this delivery is made by a vehicle who visits all other outlets in the region as well (in an efficient route). we describe a class of low complexity heuristics and show under mild probabilistic assumptions that the generated solutions are asymptotically optimal (within the above class of strategies). we also show that lower and upper bounds on the system-wide costs may be computed and that these bounds are asymptotically tight under the same assumptions. a numerical study exhibits the performance of these heuristics and bounds for problems of moderate size.",
            "contribution_ids": [
                "R26270"
            ]
        },
        {
            "instance_id": "R26352xR26300",
            "comparison_id": "R26352",
            "paper_id": "R26300",
            "text": "Integrating Routing and Inventory Decisions in One-Warehouse Multiretailer Multiproduct Distribution Systems we consider distribution systems with a central warehouse and many retailers that stock a number of different products. deterministic demand occurs at the retailers for each product. the warehouse acts as a break-bulk center and does not keep any inventory. the products are delivered from the warehouse to the retailers by vehicles that combine the deliveries to several retailers into efficient vehicle routes. the objective is to determine replenishment policies that specify the delivery quantities and the vehicle routes used for the delivery, so as to minimize the long-run average inventory and transportation costs. a new heuristic that develops a stationary nested joint replenishment policy for the problem is presented in this paper. unlike existing methods, the proposed heuristic is capable of solving problems involving distribution systems with multiple products. results of a computational study on randomly generated single-product problems are also presented.",
            "contribution_ids": [
                "R26301"
            ]
        },
        {
            "instance_id": "R26352xR26343",
            "comparison_id": "R26352",
            "paper_id": "R26343",
            "text": "Scenario Tree-Based Heuristics for Stochastic Inventory-Routing Problems in vendor-managed inventory replenishment, the vendor decides when to make deliveries to customers, how much to deliver, and how to combine shipments using the available vehicles. this gives rise to the inventory-routing problem in which the goal is to coordinate inventory replenishment and transportation to minimize costs. the problem tackled in this paper is the stochastic inventory-routing problem, where stochastic demands are specified through general discrete distributions. the problem is formulated as a discounted infinite-horizon markov decision problem. heuristics based on finite scenario trees are developed. computational results confirm the efficiency of these heuristics.",
            "contribution_ids": [
                "R26344"
            ]
        },
        {
            "instance_id": "R26352xR26330",
            "comparison_id": "R26352",
            "paper_id": "R26330",
            "text": "On the Interactions Between Routing and Inventory-Management Policies in a One-WarehouseN-Retailer Distribution System this paper examines the interactions between routing and inventory-management decisions in a two-level supply chain consisting of a cross-docking warehouse and n retailers. retailer demand is normally distributed and independent across retailers and over time. travel times are fixed between pairs of system sites. every m time periods, system inventory is replenished at the warehouse, whereupon an uncapacitated vehicle departs on a route that visits each retailer once and only once, allocating all of its inventory based on the status of inventory at the retailers who have not yet received allocations. the retailers experience newsvendor-type inventory-holding and backorder-penalty costs each period; the vehicle experiences in-transit inventory-holding costs each period. our goal is to determine a combined system inventory-replenishment, routing, and inventory-allocation policy that minimizes the total expected cost/period of the system over an infinite time horizon. our analysis begins by examining the determination of the optimal static route, i.e., the best route if the vehicle must travel the same route every replenishment-allocation cycle. here we demonstrate that the optimal static route is not the shortest-total-distance (tsp) route, but depends on the variance of customer demands, and, if in-transit inventory-holding costs are charged, also on mean customer demands. we then examine dynamic-routing policies, i.e., policies that can change the route from one system-replenishment-allocation cycle to another, based on the status of the retailers\u2019 inventories. here we argue that in the absence of transportation-related cost, the optimal dynamic-routing policy should be viewed as balancing management\u2019s ability to respond to system uncertainties (by changing routes) against system uncertainties that are induced by changing routes. we then examine the performance of a change-revert heuristic policy. although its routing decisions are not fully dynamic, but determined and fixed for a given cycle at the time of each system replenishment, simulation tests with n = 2 and n = 6 retailers indicate that its use can substantially reduce system inventory-related costs even if most of the time the chosen route is the optimal static route.",
            "contribution_ids": [
                "R26331"
            ]
        },
        {
            "instance_id": "R26352xR26333",
            "comparison_id": "R26352",
            "paper_id": "R26333",
            "text": "An Efficient Heuristic Algorithm for a Two-Echelon Joint Inventory and Routing Problem with an increasing emphasis on coordination in the supply chain, the inventory and distribution decisions, which in most part had been dealt with independently of each other, need to be considered jointly. this research considers a two-echelon distribution system consisting of one warehouse and n retailers that face external demand at a constant rate. inventories are kept at retailers as well as at the warehouse. the products are delivered to the retailers by a fleet of vehicles with limited capacity. we develop an efficient heuristic procedure that finds a reorder interval for the warehouse, the replenishment quantities (and associated reorder interval) for each retailer, and the delivery routes so as to minimize the long-run average inventory and transportation costs.",
            "contribution_ids": [
                "R26334"
            ]
        },
        {
            "instance_id": "R26352xR26284",
            "comparison_id": "R26352",
            "paper_id": "R26284",
            "text": "Minimizing Transportation and Inventory Costs for Several Products on a Single Link this paper deals with the problem of determining the frequencies at which several products have to be shipped on a common link to minimize the sum of transportation and inventory costs. a set of feasible shipping frequencies is given. transportation costs are supposed to be proportional to the number of journeys performed by vehicles of a given capacity. vehicles may or may not be supposed to carry out completely all materials available, and products assigned to different frequencies may or may not share the same truck. integer and mixed integer linear programming models are formulated for each of the resulting four situations, and their properties are investigated. in particular, we show that allowing products to be split among several shipping frequencies makes trucks traveling at high frequencies to be filled up completely. in this situation, trucks may always be loaded with products shipped at the same frequency.",
            "contribution_ids": [
                "R26285"
            ]
        },
        {
            "instance_id": "R26352xR26326",
            "comparison_id": "R26352",
            "paper_id": "R26326",
            "text": "Redesigning distribution operations: a case study on integrating inventory management and vehicle routes design this paper describes a real-world application concerning the distribution in portugal of frozen products of a world-wide food and beverage company. its focus is the development of a model to support negotiations between a logistics operator and retailers, establishing a common basis for a co-operative scheme in supply chain management. a periodic review policy is adopted and an optimisation procedure based on the heuristic proposed by viswanathan and mathur (mgmnt sci., 1997, 43, 294\u2013312) is used to devise guidelines for inventory replenishment frequencies and for the design of routes to be used in the distribution process. this provides an integrated approach of the two logistics functions\u2014inventory management and routing\u2014with the objective of minimising long-term average costs, considering an infinite time horizon. a framework to estimate inventory levels, namely safety stocks, is also presented. the model provides full information concerning the expected performance of the proposed solution, which can be compared against the present situation, allowing each party to assess its benefits and drawbacks.",
            "contribution_ids": [
                "R26327",
                "R26369"
            ]
        },
        {
            "instance_id": "R26352xR26311",
            "comparison_id": "R26352",
            "paper_id": "R26311",
            "text": "Heavy Traffic Analysis of the Dynamic Stochastic Inventory-Routing Problem we analyze three queueing control problems that model a dynamic stochastic distribution system, where a single capacitated vehicle serves a finite number of retailers in a make-to-stock fashion. the objective in each of these vehicle routing and inventory problems is to minimize the long run average inventory (holding and backordering) and transportation cost. in all three problems, the controller dynamically specifies whether a vehicle at the warehouse should idle or embark with a full load. in the first problem, the vehicle must travel along a prespecified (tsp) tour of all retailers, and the controller dynamically decides how many units to deliver to each retailer. in the second problem, the vehicle delivers an entire load to one retailer (direct shipping) and the controller decides which retailer to visit next. the third problem allows the additional dynamic choice between the tsp and direct shipping options. motivated by existing heavy traffic limit theorems, we make a time scale decomposition assumption that allows us to approximate these queueing control problems by diffusion control problems, which are explicitly solved in the fixed route problems, and numerically solved in the dynamic routing case. simulation experiments confirm that the heavy traffic approximations are quite accurate over a broad range of problem parameters. our results lead to some new observations about the behavior of this complex system.",
            "contribution_ids": [
                "R26312"
            ]
        },
        {
            "instance_id": "R26352xR26319",
            "comparison_id": "R26352",
            "paper_id": "R26319",
            "text": "A Price-Directed Approach to Stochastic Inventory/Routing we consider a new approach to stochastic inventory/routing that approximates the future costs of current actions using optimal dual prices of a linear program. we obtain two such linear programs by formulating the control problem as a markov decision process and then replacing the optimal value function with the sum of single-customer inventory value functions. the resulting approximation yields statewise lower bounds on optimal infinite-horizon discounted costs. we present a linear program that takes into account inventory dynamics and economics in allocating transportation costs for stochastic inventory routing. on test instances we find that these allocations do not introduce any error in the value function approximations relative to the best approximations that can be achieved without them. also, unlike other approaches, we do not restrict the set of allowable vehicle itineraries in any way. instead, we develop an efficient algorithm to both generate and eliminate itineraries during solution of the linear programs and control policy. in simulation experiments, the price-directed policy outperforms other policies from the literature.",
            "contribution_ids": [
                "R26320"
            ]
        },
        {
            "instance_id": "R26352xR26317",
            "comparison_id": "R26352",
            "paper_id": "R26317",
            "text": "Price-Directed Replenishment of Subsets: Methodology and Its Application to Inventory Routing the idea of price-directed control is to use an operating policy that exploits optimal dual prices from a mathematical programming relaxation of the underlying control problem. we apply it to the problem of replenishing inventory to subsets of products/locations, such as in the distribution of industrial gases, so as to minimize long-run time average replenishment costs. given a marginal value for each product/location, whenever there is a stockout the dispatcher compares the total value of each feasible replenishment with its cost, and chooses one that maximizes the surplus. we derive this operating policy using a linear functional approximation to the optimal value function of a semi-markov decision process on continuous spaces. this approximation also leads to a math program whose optimal dual prices yield values and whose optimal objective value gives a lower bound on system performance. we use duality theory to show that optimal prices satisfy several structural properties and can be interpreted as estimates of lowest achievable marginal costs. on real-world instances, the price-directed policy achieves superior, near optimal performance as compared with other approaches.",
            "contribution_ids": [
                "R26318"
            ]
        },
        {
            "instance_id": "R26352xR26297",
            "comparison_id": "R26352",
            "paper_id": "R26297",
            "text": "Fully Loaded Direct Shipping Strategy in One Warehouse/NRetailer Systems without Central Inventories in this paper, we consider one warehouse/multiple retailer systems with transportation costs. the planning horizon is infinite and the warehouse keeps no central inventory. it is shown that the fully loaded direct shipping strategy is optimal among all possible shipping/allocation strategies if the truck capacity is smaller than a certain quantity, and a bound is provided for the general case.",
            "contribution_ids": [
                "R26298"
            ]
        },
        {
            "instance_id": "R26352xR26272",
            "comparison_id": "R26352",
            "paper_id": "R26272",
            "text": "On the Effectiveness of Direct Shipping Strategy for the One-Warehouse Multi-Retailer R-Systems we consider the problem of integrating inventory control and vehicle routing into a cost-effective strategy for a distribution system consisting of one depot and many geographically dispersed retailers. all stock enters the system through the depot and is distributed to the retailers by vehicles of limited constant capacity. we assume that each one of the retailers faces a constant, retailer specific, demand rate and that inventory is charged only at the retailers but not at the depot. we provide a lower bound on the long run average cost over all inventory-routing strategies. we use this lower bound to show that the effectiveness of direct shipping over all inventory-routing strategies is at least 94% whenever the economic lot size of each of the retailers is at least 71% of vehicle capacity. the effectiveness deteriorates as the economic lot sizes become smaller. these results are important because they provide useful guidelines as to when to embark into the much more difficult task of finding cost-effective routes. additional advantages of direct shipping are lower in-transit inventory and ease of coordination.",
            "contribution_ids": [
                "R26273"
            ]
        },
        {
            "instance_id": "R26352xR26295",
            "comparison_id": "R26352",
            "paper_id": "R26295",
            "text": "Heuristics for a One-Warehouse Multiretailer Distribution Problem with Performance Bounds we investigate the one warehouse multiretailer distribution problem with traveling salesman tour vehicle routing costs. we model the system in the framework of the more general production/distribution system with arbitrary non-negative monotone joint order costs. we develop polynomial time heuristics whose policy costs are provably close to the cost of an optimal policy. in particular, we show that given a submodular function which is close to the true order cost then we can find a power-of-two policy whose cost is only moderately greater than the cost of an optimal policy. since such submodular approximations exist for traveling salesman tour vehicle routing costs we present a detailed description of heuristics for the one warehouse multiretailer distribution problem. we formulate a nonpolynomial dynamic program that computes optimal power-of-two policies for the one warehouse multiretailer system assuming only that the order costs are non-negative monotone. finally, we perform computational tests which compare our heuristics to optimal power of two policies for problems of up to sixteen retailers. we also perform computational tests on larger problems; these tests give us insight into what policies one should employ.",
            "contribution_ids": [
                "R26296"
            ]
        },
        {
            "instance_id": "R26377xR26326",
            "comparison_id": "R26377",
            "paper_id": "R26326",
            "text": "Redesigning distribution operations: a case study on integrating inventory management and vehicle routes design this paper describes a real-world application concerning the distribution in portugal of frozen products of a world-wide food and beverage company. its focus is the development of a model to support negotiations between a logistics operator and retailers, establishing a common basis for a co-operative scheme in supply chain management. a periodic review policy is adopted and an optimisation procedure based on the heuristic proposed by viswanathan and mathur (mgmnt sci., 1997, 43, 294\u2013312) is used to devise guidelines for inventory replenishment frequencies and for the design of routes to be used in the distribution process. this provides an integrated approach of the two logistics functions\u2014inventory management and routing\u2014with the objective of minimising long-term average costs, considering an infinite time horizon. a framework to estimate inventory levels, namely safety stocks, is also presented. the model provides full information concerning the expected performance of the proposed solution, which can be compared against the present situation, allowing each party to assess its benefits and drawbacks.",
            "contribution_ids": [
                "R26327",
                "R26369"
            ]
        },
        {
            "instance_id": "R26377xR26248",
            "comparison_id": "R26377",
            "paper_id": "R26248",
            "text": "Omya Hustadmarmor optimizes its supply chain for delivering calcium carbonate slurry to European paper manufacturers the norwegian company omya hustadmarmor supplies calcium carbonate slurry to european paper manufacturers from a single processing plant, using chemical tank ships of various sizes to transport its products. transportation costs are lower for large ships than for small ships, but their use increases planning complexity and creates problems in production. in 2001, the company faced overwhelming operational challenges and sought operations-research-based planning support. the ceo, sturla steinsvik, contacted m\u00f8re research molde, which conducted a project that led to the development of a decision-support system (dss) for maritime inventory routing. the core of the dss is an optimization model that is solved through a metaheuristic-based algorithm. the system helps planners to make stronger, faster decisions and has increased predictability and flexibility throughout the supply chain. it has saved production and transportation costs close to us$7 million a year. we project additional direct savings of nearly us$4 million a year as the company adds even larger ships to the fleet as a result of the project. in addition, the company has avoided investments of us$35 million by increasing capacity utilization. finally, the project has had a positive environmental effect by reducing overall oil consumption by more than 10 percent.",
            "contribution_ids": [
                "R26249",
                "R26374"
            ]
        },
        {
            "instance_id": "R26377xR26224",
            "comparison_id": "R26377",
            "paper_id": "R26224",
            "text": "A Decomposition Approach for the Inventory-Routing Problem in this paper, we present a solution approach for the inventory-routing problem. the inventory-routing problem is a variation of the vehicle-routing problem that arises in situations where a vendor has the ability to make decisions about the timing and sizing of deliveries, as well as the routing, with the restriction that customers are not allowed to run out of product. we develop a two-phase approach based on decomposing the set of decisions: a delivery schedule is created first, followed by the construction of a set of delivery routes. the first phase utilizes integer programming, whereas the second phase employs routing and scheduling heuristics. our focus is on creating a solution methodology appropriate for large-scale real-life instances. computational experiments demonstrating the effectiveness of our approach are presented.",
            "contribution_ids": [
                "R26225",
                "R26365"
            ]
        },
        {
            "instance_id": "R26377xR26228",
            "comparison_id": "R26377",
            "paper_id": "R26228",
            "text": "A Periodic Inventory Routing Problem at a Supermarket Chain albert heijn, bv, a supermarket chain in the netherlands, faces a vehicle routing and delivery scheduling problem once every three to six months. given hourly demand forecasts for each store, travel times and distances, cost parameters, and various transportation constraints, the firm seeks to determine a weekly delivery schedule specifying the times when each store should be replenished from a central distribution center, and to determine the vehicle routes that service these requirements at minimum cost. we describe the development and implementation of a system to solve this problem at albert heijn. the system resulted in savings of 4% of distribution costs in its first year of implementation and is expected to yield 12%\u201320% savings as the firm expands its usage. it also has tactical and strategic advantages for the firm, such as in assessing the cost impact of various logistics and marketing decisions, in performance measurement, and in competing effectively through reduced lead time and increased frequency of replenishment.",
            "contribution_ids": [
                "R26229",
                "R26364"
            ]
        },
        {
            "instance_id": "R26377xR26214",
            "comparison_id": "R26377",
            "paper_id": "R26214",
            "text": "Decomposition of a Combined Inventory and Time Constrained Ship Routing Problem in contrast to vehicle routing problems, little work has been done in ship routing and scheduling, although large benefits may be expected from improving this scheduling process. we will present a real ship planning problem, which is a combined inventory management problem and a routing problem with time windows. a fleet of ships transports a single product (ammonia) between production and consumption harbors. the quantities loaded and discharged are determined by the production rates of the harbors, possible stock levels, and the actual ship visiting the harbor. we describe the real problem and the underlying mathematical model. to decompose this model, we discuss some model adjustments. then, the problem can be solved by a dantzig\u2013wolfe decomposition approach including both ship routing subproblems and inventory management subproblems. the overall problem is solved by branch-and-bound. our computational results indicate that the proposed method works for the real planning problem.",
            "contribution_ids": [
                "R26215",
                "R26362"
            ]
        },
        {
            "instance_id": "R26421xR26395",
            "comparison_id": "R26421",
            "paper_id": "R26395",
            "text": "Novel Chitosanase fromStreptomyces griseusHUT 6037 with Transglycosylation Activity streptomyces griseus hut 6037 inducibly produced two chitosanases when grown on chitosan. to elucidate the mechanism of degradation of chitinous compound by this strain, chitosanases i and ii of s. griseus hut 6037 were purified and characterized. the purified enzymes had a molecular mass of 34 kda. their optimum ph was 5.7, and their optimum temperature was 60\u00b0c. they hydrolyzed not only partially deacetylated chitosan, but also carboxymethylcellulose. time-dependent 1h-nmr spectra showing hydrolysis of (glcn)6 by the chitosanases were obtained for identification of the anomeric form of the reaction products. both chitosanases produced the \u03b2-form specifically, indicating that they were retaining enzymes. these enzymes catalyzed a glycosyltransfer reaction in the hydrolysis of chitooligosaccharides. the n-terminal and internal amino acid sequences of chitosanase ii were identified. a pcr fragment corresponding to these amino acid sequences was used to screen a genomic library for the entire gene encoding chitosanase ii. sequencing of the choii gene showed an open reading frame encoding a protein with 359 amino acid residues. the deduced primary structure was similar to endoglucanase e-5 of thermomonospora fusca, which enzyme belongs to family 5 of the glycosyl hydrolases. this is the first report of a family 5 chitosanase with transglycosylation activity.",
            "contribution_ids": [
                "R26396"
            ]
        },
        {
            "instance_id": "R26421xR26391",
            "comparison_id": "R26421",
            "paper_id": "R26391",
            "text": "Biochemical and Genetic Properties ofPaenibacillusGlycosyl Hydrolase Having Chitosanase Activity and Discoidin Domain cells of \u201cpaenibacillus fukuinensis\u201d d2 produced chitosanase into surrounding medium, in the presence of colloidal chitosan or glucosamine. the gene of this enzyme was cloned, sequenced, and subjected to site-directed mutation and deletion analyses. the nucleotide sequence indicated that the chitosanase was composed of 797 amino acids and its molecular weight was 85,610. unlike conventional family 46 chitosanases, the enzyme has family 8 glycosyl hydrolase catalytic domain, at the amino-terminal side, and discoidin domain at the carboxyl-terminal region. expression of the cloned gene in escherichia coli revealed \u03b2-1,4-glucanase function, besides chitosanase activity. analyses by zymography and immunoblotting suggested that the active enzyme was, after removal of signal peptide, produced from inactive 81-kda form by proteolysis at the carboxyl-terminal region. replacements of glu115 and asp176, highly conserved residues in the family 8 glycosylase region, with gln and asn caused simultaneous loss of chitosanase and glucanase activities, suggesting that these residues formed part of the catalytic site. truncation experiments demonstrated indispensability of an amino-terminal region spanning 425 residues adjacent to the signal peptide.",
            "contribution_ids": [
                "R26392"
            ]
        },
        {
            "instance_id": "R26421xR26417",
            "comparison_id": "R26421",
            "paper_id": "R26417",
            "text": "Purification and Mode of Action of a Chitosanase from Penicillium islandicum penicillium islandicum produced an inducible extracellular chitosanase when grown on chitosan. large-scale production of the enzyme was obtained using rhizopus rhizopodiformis hyphae as substrate. chitosanase was purified 38-fold to homogeneity by ammonium sulphate fractionation and sequential chromatography on deae-biogel a, biogel p60 and hydroxyl-apatite. crude enzyme was unstable at 370c, but was stabilized by 1\u00b70 mm-ca2+. the ph optimum for activity was broad and dependent on the solubility of the chitosan substrate. various physical and chemical properties of the purified enzyme were determined.\\npenicillium islandicum chitosanase cleaved chitosan in an endo-splitting manner with maximal activity on polymers of 30 to 60% acetylation. no activity was found on chitin (100% acetylated chitosan) or trimers and tetramers of n-acetylglucosamine. the latter two oligomers and all small oligomers of glucosamine inhibited the activity of chitosanase on 30% acetylated chitosan. the pentamer of n-acetylglucosamine and glucosamine oligomers were slowly cleaved by the enzyme. analysis of the reaction products from 30% acetylated chitosan indicated that the major oligomeric product was a trimer; with 60% acetylated chitosan as substrate a dimer was also found. the new terminal reducing groups produced by chitosanase hydrolysis of 30% acetylated chitosan were reduced by sodium boro[3h]hydride. the new end residues were found to be n-acetylglucosamine. the analyses strongly indicated that p. islandicum chitosanase cleaved chitosan between n-acetylglucosamine and glucosamine. both residues were needed for cleavage, and polymers containing equal proportions of acetylated and non-acetylated sugars were optimal for chitosanase activity. the products of reaction depended on the degree of acetylation of the polymer.",
            "contribution_ids": [
                "R26418"
            ]
        },
        {
            "instance_id": "R26421xR26381",
            "comparison_id": "R26421",
            "paper_id": "R26381",
            "text": "Crystal Structure of Chitosanase fromBacillus circulansMH-K1 at 1.6-\u00c3\u0085 Resolution and Its Substrate Recognition Mechanism chitosanase from bacillus circulans mh-k1 is a 29-kda extracellular protein composed of 259 amino acids. the crystal structure of chitosanase from b. circulans mh-k1 has been determined by multiwavelength anomalous diffraction method and refined to crystallographic r = 19.2% (r free = 23.5%) for the diffraction data at 1.6-\u00e5 resolution collected by synchrotron radiation. the enzyme has two globular upper and lower domains, which generate the active site cleft for the substrate binding. the overall molecular folding is similar to chitosanase from streptomyces sp. n174, although there is only 20% identity at the amino acid sequence level between both chitosanases. however, there are three regions in which the topology is remarkably different. in addition, the disulfide bridge between cys50 and cys124 joins the \u03b21 strand and the \u03b17 helix, which is not conserved among other chitosanases. the orientation of two backbone helices, which connect the two domains, is also different and is responsible for the differences in size and shape of the active site cleft in these two chitosanases. this structural difference in the active site cleft is the reason why the enzymes specifically recognize different substrates and catalyze different types of chitosan degradation.",
            "contribution_ids": [
                "R26382"
            ]
        },
        {
            "instance_id": "R26421xR26393",
            "comparison_id": "R26421",
            "paper_id": "R26393",
            "text": "Reaction mechanism of chitosanase from Streptomyces sp. N174 chitosanase was produced by the strain of streptomyces lividans tk24 bearing the csn gene from streptomyces sp. n174, and purified by s-sepharose and bio-gel a column chromatography. partially (25-35%) n-acetylated chitosan was digested by the purified chitosanase, and structures of the products were analysed by nmr spectroscopy. the chitosanase produced heterooligosaccharides consisting of d-glcn and glcnac in addition to glucosamine oligosaccharides [(glcn)n, n = 1, 2 and 3]. the reducing- and non-reducing-end residues of the heterooligosaccharide products were glcnac and glcn respectively, indicating that the chitosanase can split the glcnac-glcn linkage in addition to that of glcn-glcn. time-dependent 1h-nmr spectra showing hydrolysis of (glcn)6 by the chitosanase were obtained in order to determine the anomeric form of the reaction products. the chitosanase was found to produce only the alpha-form; therefore it is an inverting enzyme. separation and quantification of (glcn)n was achieved by hplc, and the time course of the reaction catalysed by the chitosanase was studied using (glcn)n (n = 4, 5 and 6) as the substrate. the chitosanase hydrolysed (glcn)6 in an endo-splitting manner producing (glcn)2, (glcn)3 and (glcn)4, and did not catalyse transglycosylation. product distribution was (glcn)3 &amp;gt;&amp;gt; (glcn)2 &amp;gt; (glcn)4. cleavage to (glcn)3 + (glcn)3 predominated over that to (glcn)2 + (glcn)4. time courses showed a decrease in rate of substrate degradation from (glcn)6 to (glcn)5 to (glcn)4. it is most likely that the substrate-binding cleft of the chitosanase can accommodate at least six glcn residues, and that the cleavage point is located at the midpoint of the binding cleft.",
            "contribution_ids": [
                "R26394"
            ]
        },
        {
            "instance_id": "R26421xR26409",
            "comparison_id": "R26421",
            "paper_id": "R26409",
            "text": "Purification and Properties of a Chitosanase fromPseudomonassp. H-14 purification and properties of a chitosanase from pseudomonas sp. h-14 kazutoshi yoshihara, jun hosokawa, takamasa kubo, masashi nishiyama & yojiro koba to cite this article: kazutoshi yoshihara, jun hosokawa, takamasa kubo, masashi nishiyama & yojiro koba (1992) purification and properties of a chitosanase from pseudomonas sp. h-14, bioscience, biotechnology, and biochemistry, 56:6, 972-973, doi: 10.1271/bbb.56.972 to link to this article: http://dx.doi.org/10.1271/bbb.56.972",
            "contribution_ids": [
                "R26410"
            ]
        },
        {
            "instance_id": "R26421xR26419",
            "comparison_id": "R26421",
            "paper_id": "R26419",
            "text": "Characterization of Two Chitinase Genes and One Chitosanase Gene Encoded by Chlorella Virus PBCV-1 chlorella virus pbcv-1 encodes two putative chitinase genes, a181/182r and a260r, and one chitosanase gene, a292l. the three genes were cloned and expressed in escherichia coli. the recombinant a181/182r protein has endochitinase activity, recombinant a260r has both endochitinase and exochitinase activities, and recombinant a292l has chitosanase activity. transcription of a181/182r, a260r, and a292l genes begins at 30, 60, and 60 min p.i., respectively; transcription of all three genes continues until the cells lyse. a181/182r, a260r, and a292l proteins are first detected by western blots at 60, 90, and 120 min p.i., respectively. therefore, a181/182r is an early gene and a260r and a292l are late genes. all three genes are widespread in chlorella viruses. phylogenetic analyses indicate that the ancestral condition of the a181/182r gene arose from the most recent common ancestor of a gene found in tobacco, whereas the genealogical position of the a260r gene could not be unambiguously resolved.",
            "contribution_ids": [
                "R26420"
            ]
        },
        {
            "instance_id": "R26421xR26389",
            "comparison_id": "R26421",
            "paper_id": "R26389",
            "text": "A new chitosanase gene from a Nocardioides sp. is a third member of glycosyl hydrolase family 46 \"strain n106, a newly isolated soil actinomycete classified in the genus nocardioides on the basis of its chemotaxonomy, produced an extracellular chitosanase and was highly active in chitosan degradation. a gene library of nocardioides sp. n106 was constructed in the shuttle vector pfd666 and recombinant plasmids carrying the chitosanase gene (csnn106) were identified using the 5'-terminal portion of the chitosanase gene from streptomyces sp. n174 as a hybridization probe. one plasmid, pcsn106-2, was used to transform streptomyces lividans tk24. the chitosanase produced by s. lividans (pcsn106-2) is a protein of 29.5 kda, with a pi 8.1, and hydrolyses chitosan by an endo-mechanism giving a mixture of dimers and trimers as end-products. n-terminal sequencing revealed that the mature chitosanase is a mixture of two enzyme forms differing by one n-terminal amino acid. the csnn106 gene is 79.5% homologous to the csn gene from streptomyces sp. n174. at the amino acid level, both chitosanases are homologous at 74.4% and hydrophobic cluster analysis revealed a strict conservation of structural features. this chitosanase is the third known member of family 46 of glycosyl hydrolases.\"",
            "contribution_ids": [
                "R26390"
            ]
        },
        {
            "instance_id": "R26550xR26530",
            "comparison_id": "R26550",
            "paper_id": "R26530",
            "text": "Development and evaluation of an edible antimicrobial film based on yam starch and chitosan edible antimicrobial films are an innovation within the biodegradable active packaging concept. they have been developed in order to reduce and/or inhibit the growth of microorganisms on the surface of foods. this study developed an edible antimicrobial film based on yam starch (dioscorea alata) and chitosan and investigated its antimicrobial efficiency on salmonella enteritidis. a solution of yam starch (4%) and glycerol (2%) was gelatinized in a viscoamilograph and chitosan added at concentrations of 1%, 3% and 5%. films with and without chitosan were produced by the cast method. to evaluate the antimicrobial activity of the films, two suspensions of s. enteritidis were used in bhi medium, corresponding to counts of 2 \u00d7 108 and 1.1 \u00d7 106\\u2009cfu/ml. the suspensions (50\\u2009ml) were poured into flasks. the films were cut into 5 \u00d7 5 and 5 \u00d7 10\\u2009cm rectangles to be used at ratios of 1\\u2009:\\u20091 (1\\u2009cm2/ml microorganism suspension) and 2\\u2009:\\u20091 (2\\u2009cm2/ml). the film 30\\u2009\u00b5m thick on average. as a control, pure chitosan at an amount corresponding to that contained in the 3% and 5% films (5 \u00d7 10\\u2009cm) was added to flasks containing the microorganism suspension. also, flasks containing only a suspension of s. enteritidis were used as control. the suspensions, in flasks, were kept at 37\u00b0c in a waterbath with agitation. suspension aliquots were removed every hour for reading the optic density (od595) and plating onto pca medium. the results showed that chitosan has a bactericidal effect upon s. enteritidis. films treated with chitosan at different concentrations showed similar antimicrobial efficiency, in addition to being dependent on diffusion. the chitosan\u2010treated films caused a reduction of one to two log cycles in the number of microorganisms, whereas the pure chitosan presented a reduction of four to six log cycles compared with the control and starch film. the films showed good flexibility. copyright \u00a9 2005 john wiley & sons, ltd.",
            "contribution_ids": [
                "R26531"
            ]
        },
        {
            "instance_id": "R26550xR26492",
            "comparison_id": "R26550",
            "paper_id": "R26492",
            "text": "Control of wound infections using a bilayer chitosan wound dressing with sustainable antibiotic delivery a novel bilayer chitosan membrane was prepared by a combined wet/dry phase inversion method and evaluated as a wound dressing. this new type of bilayer chitosan wound dressing, consisting of a dense upper layer (skin layer) and a sponge-like lower layer (sublayer), is very suitable for use as a topical delivery of silver sulfadiazine (agsd) for the control of wound infections. physical characterization of the bilayer wound dressing showed that it has excellent oxygen permeability, that it controls the water vapor transmission rate, and that it promotes water uptake capability. agsd dissolved from bilayer chitosan dressings to release silver and sulfadiazine. the release of sulfadiazine from the bilayer chitosan dressing displayed a burst release on the first day and then tapered off to a much slower release. however, the release of silver from the bilayer chitosan dressing displayed a slow release profile with a sustained increase of silver concentration. the cultures of pseudomonas aeruginosa and staphylococcus aureus in agar plates showed effective antimicrobial activity for 1 week. in vivo antibacterial tests confirmed that this wound dressing is effective for long-term inhibition of the growth of pseudomonas aeruginosa and staphylococcus aureus at an infected wound site. the results in this study indicate that the agsd-incorporated bilayer chitosan wound dressing may be a material with potential antibacterial capability for the treatment of infected wounds.",
            "contribution_ids": [
                "R26493"
            ]
        },
        {
            "instance_id": "R26550xR26511",
            "comparison_id": "R26550",
            "paper_id": "R26511",
            "text": "Anti-biofilm properties of chitosan-coated surfaces surfaces coated with the naturally-occurring polysaccharide chitosan (partially deacetylated poly n-acetyl glucosamine) resisted biofilm formation by bacteria and yeast. reductions in biofilm viable cell numbers ranging from 95% to 99.9997% were demonstrated for staphylococcus epidermidis, staphylococcus aureus, klebsiella pneumoniae, pseudomonas aeruginosa and candida albicans on chitosan-coated surfaces over a 54-h experiment in comparison to controls. for instance, chitosan-coated surfaces reduced s. epidermidis surface-associated growth more than 5.5 10log units (99.9997%) compared to a control surface. as a comparison, coatings containing a combination of the antibiotics minocycline and rifampin reduced s. epidermidis growth by 3.9 10log units (99.99%) and coatings containing the antiseptic chlorhexidine did not significantly reduce s. epidermidis surface associated growth as compared to controls. the chitosan effects were confirmed with microscopy. using time-lapse fluorescence microscopy and fluorescent-dye-loaded s. epidermidis, the permeabilization of these cells was observed as they alighted on chitosan-coated surfaces. this suggests chitosan disrupts cell membranes as microbes settle on the surface. chitosan offers a flexible, biocompatible platform for designing coatings to protect surfaces from infection.",
            "contribution_ids": [
                "R26512"
            ]
        },
        {
            "instance_id": "R26550xR26468",
            "comparison_id": "R26550",
            "paper_id": "R26468",
            "text": "Anti-ulcerogenic effect of chitin and chitosan on mucosal antioxidant defence system in HCl-ethanol-induced ulcer in rats abstract \\n the anti-ulcerogenic effect of chitin and chitosan against ulcer induced by hcl-ethanol in male wistar rats was studied. levels of acid output, pepsin, protein, lipid peroxides and reduced glutathione and the activity of glutathione peroxidase (gpx), glutathione-s-transferase (gst), catalase (cat) and superoxide dismutase (sod) were determined in the gastric mucosa of normal and experimental groups of rats. a significant increase in volume and acidity of the gastric juice was observed in the ulcer-induced group of rats. peptic activity was significantly decreased as compared with that of normal controls. in the rats pre-treated with chitin and chitosan 2% along with feed, the volume and acid output and peptic activity of gastric mucosa were maintained at near normal levels. the level of lipid peroxidation was significantly higher in the ulcerated mucosa when compared with that of normal controls. this was paralleled by a decline in the level of reduced glutathione and in the activity of antioxidant enzymes like gpx, gst, cat and sod in the gastric mucosa of ulcer-induced rats. also, the levels of mucosal proteins and glycoprotein components were significantly depleted in ulcerated mucosa. the pre-treatment with chitin and chitosan was found to exert a significant anti-ulcer effect by preventing all the hcl-ethanol-induced ulcerogenic effects in experimental rats.",
            "contribution_ids": [
                "R26469"
            ]
        },
        {
            "instance_id": "R26550xR26447",
            "comparison_id": "R26550",
            "paper_id": "R26447",
            "text": "The use of chitosan formulations in cancer therapy with the advent of the theranostics era in biomedical research, gene therapy is poised to offer more, provided that more efficient delivery vehicles are discovered and developed. chitosan is a biomatrix that is abundant, biocompatible, biodegradable, versatile, inexpensive and safe. these features have paved the way for its use in gene therapy, mainly for delivery of therapeutic plasmids and more recently for sirna. recent studies show that chitosan per se exhibits anticancer properties both in vitro and in animal models, most probably through the p21/cip and p27/kip pathways. this review looks at the in vivo studies using chitosan technology towards cancer gene therapy, drawing some support from non-cancer studies. the future of this promising technology lies in the evolution of new ideas for enhanced nucleic acid drug pharmacokinetics and, consequently, pharmacodynamics for cancer patients.",
            "contribution_ids": [
                "R26448"
            ]
        },
        {
            "instance_id": "R26550xR26438",
            "comparison_id": "R26550",
            "paper_id": "R26438",
            "text": "Chitosan as Tear Substitute: A Wetting Agent Endowed with Antimicrobial Efficacy a cationic biopolymer, chitosan, is proposed for use in artificial tear formulations. it is endowed with good wetting properties as well as an antibacterial effect that are desirable in cases of dry eye, which is often complicated by secondary infections. solutions containing 0.5% w/v of a low molecular weight (m(w)) chitosan (160 kda) were assessed for antibacterial efficacy against e. coli and s. aureus by using the usual broth-dilution technique. the in vitro evaluation showed that concentrations of chitosan as low as 0.0375% still exert a bacteriostatic effect against e. coli. minimal inhibitory concentration (mic) values of chitosan were calculated to be as low as 0.375 mg/ml for e. coli and 0.15 mg/ml for s. aureus. gamma scintigraphic studies demonstrated that chitosan formulations remain on the precorneal surface as long as commonly used commercial artificial tears (protagent collyrium and protagent-se unit-dose) having a 5-fold higher viscosity.",
            "contribution_ids": [
                "R26439"
            ]
        },
        {
            "instance_id": "R26550xR26459",
            "comparison_id": "R26550",
            "paper_id": "R26459",
            "text": "Chitosan Nanoparticles for Non-Viral Gene Therapy orthopedic research laboratory hopital du sacre-c\u0153ur de montreal universite de montreal, montreal, que. h4j 1c5",
            "contribution_ids": [
                "R26460"
            ]
        },
        {
            "instance_id": "R26550xR26514",
            "comparison_id": "R26550",
            "paper_id": "R26514",
            "text": "Application of Glutaraldehyde-Crosslinked Chitosan as a Scaffold for Hepatocyte Attachment. the effectiveness of chitosan, a biocompatible polymer derived by the deacetylation of chitin, as a scaffold of hepatocyte attachment, was examined. since chitosan gel was too fragile to use for cell culture, its free amino groups were crosslinked by glutaraldehyde to increase its strength. rat hepatocytes seeded onto glutaraldehyde-crosslinked chitosan (ga-chitosan) gel could stably attach to the surface, retaining its spherical form, the same as in vivo, and then release a very small amount of lactate dehydrogenase during the 5 d culture period. by contrast, hepatocytes on a collagen-coated surface spread flat, and they released much more lactate dehydrogenase than those on the ga-chitosan gel. hepatocytes on ga-chitosan also retained higher urea synthesis activity, a liver-specific function, than those on the collagen-coated surface. these results indicate that chitosan is a promising biopolymer as a scaffold of hepatocyte attachment, which can be applied to an effective bioartificial liver support system.",
            "contribution_ids": [
                "R26515"
            ]
        },
        {
            "instance_id": "R26550xR26429",
            "comparison_id": "R26550",
            "paper_id": "R26429",
            "text": "Chitosan-alginate films prepared with chitosans of different molecular weights chitosan-alginate polyelectrolyte complex (cs-al pec) is water insoluble and more effective in limiting the release of encapsulated materials compared to chitosan or alginate. coherent cs-al pec films have been prepared in our laboratory by casting and drying suspensions of chitosan-alginate coacervates. the objective of this study was to evaluate the properties of the cs-al pec films prepared with chitosans of different molecular weights. films prepared with low-molecular-weight chitosan (mv 1.30 x 10(5)) were twice as thin and transparent, as well as 55% less permeable to water vapor, compared to films prepared with high-molecular-weight chitosan (mv 10.0 x 10(5)). it may be inferred that the low-molecular-weight chitosan reacted more completely with the sodium alginate (m(v) 1.04 x 10(5)) than chitosan of higher molecular weight. a threshold molecular weight may be required, because chitosans of mv 10.0 x 10(5) and 5.33 x 10(5) yielded films with similar physical properties. the pec films exhibited different surface properties from the parent films, and contained a higher degree of chain alignment with the possible formation of new crystal types. the pec films exhibited good in vitro biocompatibility with mouse and human fibroblasts, suggesting that they can be further explored for biomedical applications.",
            "contribution_ids": [
                "R26430"
            ]
        },
        {
            "instance_id": "R26550xR26503",
            "comparison_id": "R26550",
            "paper_id": "R26503",
            "text": "Comparative Study of Protective Effects of Chitin, Chitosan, and N-Acetyl Chitohexaose against Pseudomonas aeruginosa and Listeria monocytogenes Infections in Mice we conducted a comparative study of the protective effects of chitin, chitosan, and n-acetyl chitohexaose (nacos-6) against mice infected intravenously or intraperitoneally with pseudomonas aeruginosa and listeria monocytogenes. mice pretreated with chitin, chitosan, and nacos-6 showed resistance to intraperitoneal infections by both microbes. only mice pretreated with chitin and chitosan showed resistance to intravenous infections by both microbes. the number, active oxygen generation, and myeloperoxidase activity of peritoneal exudate cells (pec) in the chitin, chitosan, and nacos-6-treated mice were greater than those of the untreated mice. also, these pec factors from mice pretreated with chitin and chitosan were greater than those from the nacos-6-treated mice.",
            "contribution_ids": [
                "R26504"
            ]
        },
        {
            "instance_id": "R26550xR26498",
            "comparison_id": "R26550",
            "paper_id": "R26498",
            "text": "A synergistic chlorhexidine/chitosan combination for improved antiplaque strategies background\\nthe minor efficacy of chlorhexidine (chx) on other cariogenic bacteria than mutans streptococci such as streptococcus sanguinis may contribute to uneffective antiplaque strategies.\\n\\n\\nmethods and results\\nin addition to chx (0.1%) as positive control and saline as negative control, two chitosan derivatives (0.2%) and their chx combinations were applied to planktonic and attached sanguinis streptococci for 2 min. in a preclinical biofilm model, the bacteria suspended in human sterile saliva were allowed to attach to human enamel slides for 60 min under flow conditions mimicking human salivation. the efficacy of the test agents on streptococci was screened by the following parameters: vitality status, colony-forming units (cfu)/ml and cell density on enamel. the first combination reduced the bacterial vitality to approximately 0% and yielded a strong cfu reduction of 2-3 log(10) units, much stronger than chx alone. furthermore, the first chitosan derivative showed a significant decrease of the surface coverage with these treated streptococci after attachment to enamel.\\n\\n\\nconclusions\\nbased on these results, a new chx formulation would be beneficial unifying the bioadhesive properties of chitosan with the antibacterial activity of chx synergistically resulting in a superior antiplaque effect than chx alone.",
            "contribution_ids": [
                "R26499"
            ]
        },
        {
            "instance_id": "R26608xR26586",
            "comparison_id": "R26608",
            "paper_id": "R26586",
            "text": "Distributed clustering in ad-hoc sensor networks: a hybrid, energy-efficient approach prolonged network lifetime, scalability, and load balancing are important requirements for many ad-hoc sensor network applications. clustering sensor nodes is an effective technique for achieving these goals. in this work, we propose a new energy-efficient approach for clustering nodes in ad-hoc sensor networks. based on this approach, we present a protocol, heed (hybrid energy-efficient distributed clustering), that periodically selects cluster heads according to a hybrid of their residual energy and a secondary parameter, such as node proximity to its neighbors or node degree. heed does not make any assumptions about the distribution or density of nodes, or about node capabilities, e.g., location-awareness. the clustering process terminates in o(1) iterations, and does not depend on the network topology or size. the protocol incurs low overhead in terms of processing cycles and messages exchanged. it also achieves fairly uniform cluster head distribution across the network. a careful selection of the secondary clustering parameter can balance load among cluster heads. our simulation results demonstrate that heed outperforms weight-based clustering protocols in terms of several cluster characteristics. we also apply our approach to a simple application to demonstrate its effectiveness in prolonging the network lifetime and supporting data aggregation.",
            "contribution_ids": [
                "R26587",
                "R26670"
            ]
        },
        {
            "instance_id": "R26608xR26566",
            "comparison_id": "R26608",
            "paper_id": "R26566",
            "text": "A clustering scheme for hierarchical control in multi-hop wireless networks in this paper we present a clustering scheme to create a hierarchical control structure for multi-hop wireless networks. a cluster is defined as a subset of vertices, whose induced graph is connected. in addition, a cluster is required to obey certain constraints that are useful for management and scalability of the hierarchy. all these constraints cannot be met simultaneously for general graphs, but we show how such a clustering can be obtained for wireless network topologies. finally, we present an efficient distributed implementation of our clustering algorithm for a set of wireless nodes to create the set of desired clusters.",
            "contribution_ids": [
                "R26567",
                "R26700"
            ]
        },
        {
            "instance_id": "R26608xR26594",
            "comparison_id": "R26608",
            "paper_id": "R26594",
            "text": "Cluster-Head Election Using Fuzzy Logic for Wireless Sensor Networks wireless sensor networks (wsns) present a new generation of real-time embedded systems with limited computation, energy and memory resources that are being used in a wide variety of applications where traditional networking infrastructure is practically infeasible. appropriate cluster-head node election can drastically reduce the energy consumption and enhance the lifetime of the network. in this paper, a fuzzy logic approach to cluster-head election is proposed based on three descriptors-energy, concentration and centrality. simulation shows that depending upon network configuration, a substantial increase in network lifetime can be accomplished as compared to probabilistically selecting the nodes as cluster-heads using only local information.",
            "contribution_ids": [
                "R26595",
                "R26697"
            ]
        },
        {
            "instance_id": "R26608xR26602",
            "comparison_id": "R26608",
            "paper_id": "R26602",
            "text": "WSN16-5: Distributed Formation of Overlapping Multi-hop Clusters in Wireless Sensor Networks clustering is a standard approach for achieving efficient and scalable performance in wireless sensor networks. most of the published clustering algorithms strive to generate the minimum number of disjoint clusters. however, we argue that guaranteeing some degree of overlap among clusters can facilitate many applications, like inter-cluster routing, topology discovery and node localization, recovery from cluster head failure, etc. we formulate the overlapping multi-hop clustering problem as an extension to the k-dominating set problem. then we propose moca; a randomized distributed multi-hop clustering algorithm for organizing the sensors into overlapping clusters. we validate moca in a simulated environment and analyze the effect of different parameters, e.g. node density and network connectivity, on its performance. the simulation results demonstrate that moca is scalable, introduces low overhead and produces approximately equal-sized clusters.",
            "contribution_ids": [
                "R26603",
                "R26667"
            ]
        },
        {
            "instance_id": "R26608xR26554",
            "comparison_id": "R26608",
            "paper_id": "R26554",
            "text": "Energy-efficient communication protocol for wireless microsensor networks wireless distributed microsensor systems will enable the reliable monitoring of a variety of environments for both civil and military applications. in this paper, we look at communication protocols, which can have significant impact on the overall energy dissipation of these networks. based on our findings that the conventional protocols of direct transmission, minimum-transmission-energy, multi-hop routing, and static clustering may not be optimal for sensor networks, we propose leach (low-energy adaptive clustering hierarchy), a clustering-based protocol that utilizes randomized rotation of local cluster based station (cluster-heads) to evenly distribute the energy load among the sensors in the network. leach uses localized coordination to enable scalability and robustness for dynamic networks, and incorporates data fusion into the routing protocol to reduce the amount of information that must be transmitted to the base station. simulations show the leach can achieve as much as a factor of 8 reduction in energy dissipation compared with conventional outing protocols. in addition, leach is able to distribute energy dissipation evenly throughout the sensors, doubling the useful system lifetime for the networks we simulated.",
            "contribution_ids": [
                "R26555",
                "R26614",
                "R26657"
            ]
        },
        {
            "instance_id": "R26608xR26582",
            "comparison_id": "R26608",
            "paper_id": "R26582",
            "text": "Design and analysis of a fast local clustering service for wireless sensor networks we present a fast local clustering service, floc, that partitions a multi-hop wireless network into nonoverlapping and approximately equal-sited clusters. each cluster has a clusterhead such that all nodes within unit distance of the clusterhead belong to the cluster but no node beyond distance m from the clusterhead belongs to the cluster. by asserting m /spl ges/ 2, floc achieves locality: effects of cluster formation and faults/changes at any part of the network are contained within most m units. by taking unit distance to be the reliable communication radius and m to be the maximum communication radius, floc exploits the double-band nature of wireless radio-model and achieves clustering in constant time regardless of the network size. through simulations and experiments with actual deployments, we analyze the tradeoffs between clustering time and the quality of clustering, and suggest suitable parameters for floc to achieve a fast completion time without compromising the quality of the resulting clustering.",
            "contribution_ids": [
                "R26583",
                "R26666"
            ]
        },
        {
            "instance_id": "R26654xR26634",
            "comparison_id": "R26654",
            "paper_id": "R26634",
            "text": "SEP: A Stable Election Protocol for clustered heterogeneous wireless sensor networks we study the impact of heterogeneity of nodes, in terms of their energy, in wireless sensor networks that are hierarchically clustered. in these networks some of the nodes become cluster heads, aggregate the data of their cluster members and transmit it to the sink. we assume that a percentage of the population of sensor nodes is equipped with additional energy resources\u2014this is a source of heterogeneity which may result from the initial setting or as the operation of the network evolves. we also assume that the sensors are randomly (uniformly) distributed and are not mobile, the coordinates of the sink and the dimensions of the sensor field are known. we show that the behavior of such sensor networks becomes very unstable once the first node dies, especially in the presence of node heterogeneity. classical clustering protocols assume that all the nodes are equipped with the same amount of energy and as a result, they can not take full advantage of the presence of node heterogeneity. we propose sep, a heterogeneous-aware protocol to prolong the time interval before the death of the first node (we refer to as stability period), which is crucial for many applications where the feedback from the sensor network must be reliable. sep is based on weighted election probabilities of each node to become cluster head according to the remaining energy in each node. we show by simulation that sep always prolongs the stability period compared to (and that the average throughput is greater than) the one obtained using current clustering protocols. we conclude by studying the sensitivity of our sep protocol to heterogeneity parameters capturing energy imbalance in the network. we found that sep yields longer stability region for higher values of extra energy brought by more powerful nodes.",
            "contribution_ids": [
                "R26635"
            ]
        },
        {
            "instance_id": "R26654xR26649",
            "comparison_id": "R26654",
            "paper_id": "R26649",
            "text": "An Adaptive Data Dissemination Strategy for Wireless Sensor Networks \" future large-scale sensor networks may comprise thousands of wirelessly connected sensor nodes that could provide an unimaginable opportunity to interact with physical phenomena in real time. however, the nodes are typically highly resource-constrained. since the communication task is a significant power consumer, various attempts have been made to introduce energy-awareness at different levels within the communication stack. clustering is one such attempt to control energy dissipation for sensor data dissemination in a multihop fashion. the time-controlled clustering algorithm (tcca) is proposed to realize a network-wide energy reduction. a realistic energy dissipation model is derived probabilistically to quantify the sensor network's energy consumption using the proposed clustering algorithm. a discrete-event simulator is developed to verify the mathematical model and to further investigate tcca in other scenarios. the simulator is also extended to include the rest of the communication stack to allow a comprehensive evaluation of the proposed algorithm. \"",
            "contribution_ids": [
                "R26650"
            ]
        },
        {
            "instance_id": "R26654xR26646",
            "comparison_id": "R26654",
            "paper_id": "R26646",
            "text": "A clustering method for energy efficient routing in wireless sensor networks low-energy adaptive clustering hierarchy (leach) is one of the most popular distributed cluster-based routing protocols in wireless sensor networks. clustering algorithm of the leach is simple but offers no guarantee about even distribution of cluster heads over the network. and it assumes that each cluster head transmits data to sink over a single hop. in this paper, we propose a new method for selecting cluster heads to evenly distribute cluster heads. it avoids creating redundant cluster heads within a small geographical range. simulation results show that our scheme reduces energy dissipation and prolongs network lifetime as compared with leach.",
            "contribution_ids": [
                "R26647"
            ]
        },
        {
            "instance_id": "R26654xR26628",
            "comparison_id": "R26654",
            "paper_id": "R26628",
            "text": "The Concentric Clustering Scheme for Efficient Energy Consumption in the PEGASIS \"the wireless sensor network is a type of the wireless ad-hoc networks. it is composed of a collection of sensor nodes. sensor nodes collect and deliver necessary data in response to user's specific requests. it is expected to apply the wireless sensor network technology to various application areas such as the health, military and home. however, because of several limitations of sensor nodes, the routing protocols used in the wireless ad-hoc network are not suitable for the wireless sensor networks. for this reasons, many novel routing protocols for the wireless sensor networks are proposed recently. one of these protocols, the pegasis (power-efficient gathering in sensor information systems) protocol is a chain-based protocol. in general, the pegasis protocol presents twice or more performance in comparison with the leach (low energy adaptive clustering hierarchy) protocol. however, the pegasis protocol causes the redundant data transmission since one of nodes on the chain is selected as the head node regardless of the base station's location. in this paper, we propose the enhanced pegasis protocol based on the concentric clustering scheme to solve this problem. the main idea of the concentric clustering scheme is to consider the location of the base station to enhance its performance and to prolong the lifetime of the wireless sensor networks. as simulation results, the enhanced pegasis protocol using the concentric clustering scheme performs better than the current pegasis protocol by about 35%.\"",
            "contribution_ids": [
                "R26629"
            ]
        },
        {
            "instance_id": "R26654xR26640",
            "comparison_id": "R26654",
            "paper_id": "R26640",
            "text": "An energy-efficient unequal clustering mechanism for wireless sensor networks unequal clustering mechanism, in combination with inter-cluster multihop routing, provides a new effective way to balance the energy dissipation among nodes and prolong the lifetime of wireless sensor networks. in this paper, a distributed energy-efficient unequal clustering mechanism (deeuc) is proposed and evaluated. by a time based competitive clustering algorithm, deeuc partitions all nodes into clusters of unequal size, in which the clusters closer to the base station have smaller size. the cluster heads of these clusters can preserve some more energy for the inter-cluster relay traffic and the \u201chot-spots\u201d problem can be avoided. for inter-cluster communication, deeuc adopts an energy-aware multihop routing to reduce the energy consumption of the cluster heads. simulation results demonstrate that the protocol can efficiently decrease the dead speed of the nodes and prolong the network lifetime",
            "contribution_ids": [
                "R26641",
                "R26736"
            ]
        },
        {
            "instance_id": "R26654xR26637",
            "comparison_id": "R26654",
            "paper_id": "R26637",
            "text": "A two-levels hierarchy for low-energy adaptive clustering hierarchy (TL-LEACH) wireless sensor networks with thousands of tiny sensor nodes are expected to find wide applicability and increasing deployment in coming years, as they enable reliable monitoring and analysis of the environment. in this paper we propose a modification to a well-known protocol for sensor networks called low energy adaptive clustering hierarchy (leach). this last is designed for sensor networks where end- user wants to remotely monitor the environment. in such situation, the data from the individual nodes must be sent to a central base station, often located far from the sensor network, through which the end-user can access the data. in this context our contribution is represented by building a two-level hierarchy to realize a protocol that saves better the energy consumption. our tl-leach uses random rotation of local cluster base stations (primary cluster-heads and secondary cluster-heads). in this way we build, where it is possible, a two-level hierarchy. this permits to better distribute the energy load among the sensors in the network especially when the density of network is higher. tl- leach uses localized coordination to enable scalability and robustness. we evaluated the performances of our protocol with ns-2 and we observed that our protocol outperforms the leach in terms of energy consumption and lifetime of the network.",
            "contribution_ids": [
                "R26638"
            ]
        },
        {
            "instance_id": "R26654xR26554",
            "comparison_id": "R26654",
            "paper_id": "R26554",
            "text": "Energy-efficient communication protocol for wireless microsensor networks wireless distributed microsensor systems will enable the reliable monitoring of a variety of environments for both civil and military applications. in this paper, we look at communication protocols, which can have significant impact on the overall energy dissipation of these networks. based on our findings that the conventional protocols of direct transmission, minimum-transmission-energy, multi-hop routing, and static clustering may not be optimal for sensor networks, we propose leach (low-energy adaptive clustering hierarchy), a clustering-based protocol that utilizes randomized rotation of local cluster based station (cluster-heads) to evenly distribute the energy load among the sensors in the network. leach uses localized coordination to enable scalability and robustness for dynamic networks, and incorporates data fusion into the routing protocol to reduce the amount of information that must be transmitted to the base station. simulations show the leach can achieve as much as a factor of 8 reduction in energy dissipation compared with conventional outing protocols. in addition, leach is able to distribute energy dissipation evenly throughout the sensors, doubling the useful system lifetime for the networks we simulated.",
            "contribution_ids": [
                "R26555",
                "R26614",
                "R26657"
            ]
        },
        {
            "instance_id": "R26654xR26562",
            "comparison_id": "R26654",
            "paper_id": "R26562",
            "text": "TEEN: a routing protocol for enhanced efficiency in wireless sensor networks wireless sensor networks are expected to find wide applicability and increasing deployment in the near future. in this paper, we propose a formal classification of sensor networks, based on their mode of functioning, as proactive and reactive networks. reactive networks, as opposed to passive data collecting proactive networks, respond immediately to changes in the relevant parameters of interest. we also introduce a new energy efficient protocol, teen (threshold sensitive energy efficient sensor network protocol) for reactive networks. we evaluate the performance of our protocol for a simple temperature sensing application. in terms of energy efficiency, our protocol has been observed to outperform existing conventional sensor network protocols.",
            "contribution_ids": [
                "R26563",
                "R26621"
            ]
        },
        {
            "instance_id": "R26654xR26570",
            "comparison_id": "R26654",
            "paper_id": "R26570",
            "text": "PEGASIS: power efficient gathering in sensor informa- tion systems sensor webs consisting of nodes with limited battery power and wireless communications are deployed to collect useful information from the field. gathering sensed information in an energy efficient manner is critical to operate the sensor network for a long period of time. in w. heinzelman et al. (proc. hawaii conf. on system sci., 2000), a data collection problem is defined where, in a round of communication, each sensor node has a packet to be sent to the distant base station. if each node transmits its sensed data directly to the base station then it will deplete its power quickly. the leach protocol presented by w. heinzelman et al. is an elegant solution where clusters are formed to fuse data before transmitting to the base station. by randomizing the cluster heads chosen to transmit to the base station, leach achieves a factor of 8 improvement compared to direct transmissions, as measured in terms of when nodes die. in this paper, we propose pegasis (power-efficient gathering in sensor information systems), a near optimal chain-based protocol that is an improvement over leach. in pegasis, each node communicates only with a close neighbor and takes turns transmitting to the base station, thus reducing the amount of energy spent per round. simulation results show that pegasis performs better than leach by about 100 to 300% when 1%, 20%, 50%, and 100% of nodes die for different network sizes and topologies.",
            "contribution_ids": [
                "R26571",
                "R26626"
            ]
        },
        {
            "instance_id": "R26729xR26691",
            "comparison_id": "R26729",
            "paper_id": "R26691",
            "text": "Distributed Clustering-Based Aggregation Algorithm for Spatial Correlated Sensor Networks in wireless sensor networks, it is already noted that nearby sensor nodes monitoring an environmental feature typically register similar values. this kind of data redundancy due to the spatial correlation between sensor observations inspires the research of in-network data aggregation. in this paper, an \u03b1 -local spatial clustering algorithm for sensor networks is proposed. by measuring the spatial correlation between data sampled by different sensors, the algorithm constructs a dominating set as the sensor network backbone used to realize the data aggregation based on the information description/summarization performance of the dominators. in order to evaluate the performance of the algorithm a pattern recognition scenario over environmental data is presented. the evaluation shows that the resulting network achieved by our algorithm can provide environmental information at higher accuracy compared to other algorithms.",
            "contribution_ids": [
                "R26692"
            ]
        },
        {
            "instance_id": "R26729xR26715",
            "comparison_id": "R26729",
            "paper_id": "R26715",
            "text": "Mobility-based clustering protocol for wireless sensor networks with mobile nodes in this study, the authors propose a mobility-based clustering (mbc) protocol for wireless sensor networks with mobile nodes. in the proposed clustering protocol, a sensor node elects itself as a cluster-head based on its residual energy and mobility. a non-cluster-head node aims at its link stability with a cluster head during clustering according to the estimated connection time. each non-cluster-head node is allocated a timeslot for data transmission in ascending order in a time division multiple address (tdma) schedule based on the estimated connection time. in the steady-state phase, a sensor node transmits its sensed data in its timeslot and broadcasts a joint request message to join in a new cluster and avoid more packet loss when it has lost or is going to lose its connection with its cluster head. simulation results show that the mbc protocol can reduce the packet loss by 25% compared with the cluster-based routing (cbr) protocol and 50% compared with the low-energy adaptive clustering hierarchy-mobile (leach-mobile) protocol. moreover, it outperforms both the cbr protocol and the leach-mobile protocol in terms of average energy consumption and average control overhead, and can better adapt to a highly mobile environment.",
            "contribution_ids": [
                "R26716"
            ]
        },
        {
            "instance_id": "R26729xR26718",
            "comparison_id": "R26729",
            "paper_id": "R26718",
            "text": "Topology-controlled adaptive clustering for uniformity and increased lifetime in wireless sensor networks \"owing to the dynamic nature of sensor network applications the adoption of adaptive cluster-based topologies has many untapped desirable benefits for the wireless sensor networks. in this study, the authors explore such possibility and present an adaptive clustering algorithm to increase the network's lifetime while maintaining the required network connectivity. the proposed scheme features capability of cluster heads to adjust their power level to achieve optimal degree and maintain this value throughout the network operation. under the proposed method a topology control allows an optimal degree, which results in a better distributed sensors and well-balanced clustering system enhancing networks' lifetime. the simulation results show that the proposed clustering algorithm maintains the required degree for inter-cluster connectivity on many more rounds compared with hybrid energy-efficient distributed clustering (heed), energy-efficient clustering scheme (eecs), low-energy adaptive clustering hierarchy (leach) and energy-based leach.\"",
            "contribution_ids": [
                "R26719"
            ]
        },
        {
            "instance_id": "R26729xR26566",
            "comparison_id": "R26729",
            "paper_id": "R26566",
            "text": "A clustering scheme for hierarchical control in multi-hop wireless networks in this paper we present a clustering scheme to create a hierarchical control structure for multi-hop wireless networks. a cluster is defined as a subset of vertices, whose induced graph is connected. in addition, a cluster is required to obey certain constraints that are useful for management and scalability of the hierarchy. all these constraints cannot be met simultaneously for general graphs, but we show how such a clustering can be obtained for wireless network topologies. finally, we present an efficient distributed implementation of our clustering algorithm for a set of wireless nodes to create the set of desired clusters.",
            "contribution_ids": [
                "R26567",
                "R26700"
            ]
        },
        {
            "instance_id": "R26729xR26554",
            "comparison_id": "R26729",
            "paper_id": "R26554",
            "text": "Energy-efficient communication protocol for wireless microsensor networks wireless distributed microsensor systems will enable the reliable monitoring of a variety of environments for both civil and military applications. in this paper, we look at communication protocols, which can have significant impact on the overall energy dissipation of these networks. based on our findings that the conventional protocols of direct transmission, minimum-transmission-energy, multi-hop routing, and static clustering may not be optimal for sensor networks, we propose leach (low-energy adaptive clustering hierarchy), a clustering-based protocol that utilizes randomized rotation of local cluster based station (cluster-heads) to evenly distribute the energy load among the sensors in the network. leach uses localized coordination to enable scalability and robustness for dynamic networks, and incorporates data fusion into the routing protocol to reduce the amount of information that must be transmitted to the base station. simulations show the leach can achieve as much as a factor of 8 reduction in energy dissipation compared with conventional outing protocols. in addition, leach is able to distribute energy dissipation evenly throughout the sensors, doubling the useful system lifetime for the networks we simulated.",
            "contribution_ids": [
                "R26555",
                "R26614",
                "R26657"
            ]
        },
        {
            "instance_id": "R26729xR26687",
            "comparison_id": "R26729",
            "paper_id": "R26687",
            "text": "TASC: topology adaptive spatial clustering for sensor networks \"the ability to extract topological regularity out of large randomly deployed sensor networks holds the promise to maximally leverage correlation for data aggregation and also to assist with sensor localization and hierarchy creation. this paper focuses on extracting such regular structures from physical topology through the development of a distributed clustering scheme. the topology adaptive spatial clustering (tasc) algorithm presented here is a distributed algorithm that partitions the network into a set of locally isotropic, non-overlapping clusters without prior knowledge of the number of clusters, cluster size and node coordinates. this is achieved by deriving a set of weights that encode distance measurements, connectivity and density information within the locality of each node. the derived weights form the terrain for holding a coordinated leader election in which each node selects the node closer to the center of mass of its neighborhood to become its leader. the clustering algorithm also employs a dynamic density reachability criterion that groups nodes according to their neighborhood's density properties. our simulation results show that the proposed algorithm can trace locally isotropic structures in non-isotropic network and cluster the network with respect to local density attributes. we also found out that tasc exhibits consistent behavior in the presence of moderate measurement noise levels\"",
            "contribution_ids": [
                "R26688"
            ]
        },
        {
            "instance_id": "R26729xR26594",
            "comparison_id": "R26729",
            "paper_id": "R26594",
            "text": "Cluster-Head Election Using Fuzzy Logic for Wireless Sensor Networks wireless sensor networks (wsns) present a new generation of real-time embedded systems with limited computation, energy and memory resources that are being used in a wide variety of applications where traditional networking infrastructure is practically infeasible. appropriate cluster-head node election can drastically reduce the energy consumption and enhance the lifetime of the network. in this paper, a fuzzy logic approach to cluster-head election is proposed based on three descriptors-energy, concentration and centrality. simulation shows that depending upon network configuration, a substantial increase in network lifetime can be accomplished as compared to probabilistically selecting the nodes as cluster-heads using only local information.",
            "contribution_ids": [
                "R26595",
                "R26697"
            ]
        },
        {
            "instance_id": "R26729xR26708",
            "comparison_id": "R26729",
            "paper_id": "R26708",
            "text": "A dynamic clustering and energy efficient routing technique for sensor networks in the development of various large-scale sensor systems, a particularly challenging problem is how to dynamically organize the sensors into a wireless communication network and route sensed information from the field sensors to a remote base station. this paper presents a new energy-efficient dynamic clustering technique for large-scale sensor networks. by monitoring the received signal power from its neighboring nodes, each node estimates the number of active nodes in realtime and computes its optimal probability of becoming a cluster head, so that the amount of energy spent in both intra- and inter-cluster communications can be minimized. based on the clustered architecture, this paper also proposes a simple multihop routing algorithm that is designed to be both energy-efficient and power-aware, so as to prolong the network lifetime. the new clustering and routing algorithms scale well and converge fast for large-scale dynamic sensor networks, as shown by our extensive simulation results.",
            "contribution_ids": [
                "R26709"
            ]
        },
        {
            "instance_id": "R26729xR26672",
            "comparison_id": "R26729",
            "paper_id": "R26672",
            "text": "A probabilistic clustering algorithm in wireless sensor networks a wireless sensor network consists of nodes that can communicate with each other via wireless links. one way to support efficient communication between sensors is to organize the network into several groups, called clusters, with each cluster electing one node as the head of cluster. the paper describes a constant time clustering algorithm that can be applied on wireless sensor networks. this approach is an extension to the younis and fahmy method (1). the simulation results show that the extension can generate a small number of cluster heads in relatively few rounds, especially in sparse networks.",
            "contribution_ids": [
                "R26673"
            ]
        },
        {
            "instance_id": "R26729xR26676",
            "comparison_id": "R26729",
            "paper_id": "R26676",
            "text": "Automatic Decentralized Clustering for Wireless Sensor Networks we propose a decentralized algorithm for organizing an ad hoc sensor network into clusters. each sensor uses a random waiting timer and local criteria to determine whether to form a new cluster or to join a current cluster. the algorithm operates without a centralized controller, it operates asynchronously, and does not require that the location of the sensors be known a priori. simplified models are used to estimate the number of clusters formed, and the energy requirements of the algorithm are investigated. the performance of the algorithm is described analytically and via simulation.",
            "contribution_ids": [
                "R26677"
            ]
        },
        {
            "instance_id": "R26729xR26558",
            "comparison_id": "R26729",
            "paper_id": "R26558",
            "text": "An application-specific protocol architecture for wireless microsensor networks networking together hundreds or thousands of cheap microsensor nodes allows users to accurately monitor a remote environment by intelligently combining the data from the individual nodes. these networks require robust wireless communication protocols that are energy efficient and provide low latency. we develop and analyze low-energy adaptive clustering hierarchy (leach), a protocol architecture for microsensor networks that combines the ideas of energy-efficient cluster-based routing and media access together with application-specific data aggregation to achieve good performance in terms of system lifetime, latency, and application-perceived quality. leach includes a new, distributed cluster formation technique that enables self-organization of large numbers of nodes, algorithms for adapting clusters and rotating cluster head positions to evenly distribute the energy load among all the nodes, and techniques to enable distributed signal processing to save communication resources. our results show that leach can improve system lifetime by an order of magnitude compared with general-purpose multihop approaches.",
            "contribution_ids": [
                "R26559",
                "R26617",
                "R26658"
            ]
        },
        {
            "instance_id": "R26729xR26724",
            "comparison_id": "R26729",
            "paper_id": "R26724",
            "text": "Load-balanced clustering algorithm with distributed selforganization for wireless sensor networks wireless sensor networks (wsns) are composed of a large number of inexpensive power-constrained wireless sensor nodes, which detect and monitor physical parameters around them through self-organization. utilizing clustering algorithms to form a hierarchical network topology is a common method of implementing network management and data aggregation in wsns. assuming that the residual energy of nodes follows the random distribution, we propose a load-balanced clustering algorithm for wsns on the basis of their distance and density distribution, making it essentially different from the previous clustering algorithms. simulated tests indicate that the new algorithm can build more balanceable clustering structure and enhance the network life cycle.",
            "contribution_ids": [
                "R26725"
            ]
        },
        {
            "instance_id": "R26729xR26664",
            "comparison_id": "R26729",
            "paper_id": "R26664",
            "text": "An energy efficient hierarchical clustering algorithm for wireless sensor networks a wireless network consisting of a large number of small sensors with low-power transceivers can be an effective tool for gathering data in a variety of environments. the data collected by each sensor is communicated through the network to a single processing center that uses all reported data to determine characteristics of the environment or detect an event. the communication or message passing process must be designed to conserve the limited energy resources of the sensors. clustering sensors into groups, so that sensors communicate information only to clusterheads and then the clusterheads communicate the aggregated information to the processing center, may save energy. in this paper, we propose a distributed, randomized clustering algorithm to organize the sensors in a wireless sensor network into clusters. we then extend this algorithm to generate a hierarchy of clusterheads and observe that the energy savings increase with the number of levels in the hierarchy. results in stochastic geometry are used to derive solutions for the values of parameters of our algorithm that minimize the total energy spent in the network when all sensors report data through the clusterheads to the processing center.",
            "contribution_ids": [
                "R26665"
            ]
        },
        {
            "instance_id": "R26775xR26742",
            "comparison_id": "R26775",
            "paper_id": "R26742",
            "text": "An energy-efficient distributed unequal clustering protocol for wireless sensor networks due to the imbalance of energy consumption of nodes in wireless sensor networks (wsns), some local nodes die prematurely, which causes the network partitions and then shortens the lifetime of the network. the phenomenon is called \u201chot spot\u201d or \u201cenergy hole\u201d problem. for this problem, an energy-aware distributed unequal clustering protocol (eaduc) in multihop heterogeneous wsns is proposed. compared with the previous protocols, the cluster heads obtained by eaduc can achieve balanced energy, good distribution, and seamless coverage for all the nodes.moreover, the complexity of time and control message is low. simulation experiments show that eaduc can prolong the lifetime of the network significantly.",
            "contribution_ids": [
                "R26743"
            ]
        },
        {
            "instance_id": "R26775xR26640",
            "comparison_id": "R26775",
            "paper_id": "R26640",
            "text": "An energy-efficient unequal clustering mechanism for wireless sensor networks unequal clustering mechanism, in combination with inter-cluster multihop routing, provides a new effective way to balance the energy dissipation among nodes and prolong the lifetime of wireless sensor networks. in this paper, a distributed energy-efficient unequal clustering mechanism (deeuc) is proposed and evaluated. by a time based competitive clustering algorithm, deeuc partitions all nodes into clusters of unequal size, in which the clusters closer to the base station have smaller size. the cluster heads of these clusters can preserve some more energy for the inter-cluster relay traffic and the \u201chot-spots\u201d problem can be avoided. for inter-cluster communication, deeuc adopts an energy-aware multihop routing to reduce the energy consumption of the cluster heads. simulation results demonstrate that the protocol can efficiently decrease the dead speed of the nodes and prolong the network lifetime",
            "contribution_ids": [
                "R26641",
                "R26736"
            ]
        },
        {
            "instance_id": "R26775xR26763",
            "comparison_id": "R26775",
            "paper_id": "R26763",
            "text": "UHEED - An Unequal Clustering Algorithm for Wireless Sensor Networks prolonging the lifetime of wireless sensor networks has always been a determining factor when designing and deploying such networks. clustering is one technique that can be used to extend the lifetime of sensor networks \\nby grouping sensors together. however, there exists the hot spot problem which causes an unbalanced energy consumption in equally formed clusters. in this paper, we propose uheed, an unequal clustering algorithm which mitigates this problem and which leads to a more uniform residual energy in the network and improves the network lifetime. furthermore, from the simulation results presented, we were able to deduce the most appropriate unequal cluster size to be used.",
            "contribution_ids": [
                "R26764"
            ]
        },
        {
            "instance_id": "R26775xR26773",
            "comparison_id": "R26775",
            "paper_id": "R26773",
            "text": "An energy aware fuzzy unequal clustering algorithm for wireless sensor networks in order to gather information more efficiently, wireless sensor networks (wsns) are partitioned into clusters. the most of the proposed clustering algorithms do not consider the location of the base station. this situation causes hot spots problem in multi-hop wsns. unequal clustering mechanisms, which are designed by considering the base station location, solve this problem. in this paper, we introduce a fuzzy unequal clustering algorithm (eaucf) which aims to prolong the lifetime of wsns. eaucf adjusts the cluster-head radius considering the residual energy and the distance to the base station parameters of the sensor nodes. this helps decreasing the intra-cluster work of the sensor nodes which are closer to the base station or have lower battery level. we utilize fuzzy logic for handling the uncertainties in cluster-head radius estimation. we compare our algorithm with some popular algorithms in literature, namely leach, chef and eeuc, according to first node dies (fnd), half of the nodes alive (hna) and energy-efficiency metrics. our simulation results show that eaucf performs better than the other algorithms in most of the cases. therefore, eaucf is a stable and energy-efficient clustering algorithm to be utilized in any real time wsn application.",
            "contribution_ids": [
                "R26774"
            ]
        },
        {
            "instance_id": "R26775xR26748",
            "comparison_id": "R26775",
            "paper_id": "R26748",
            "text": "An Energy-Efficient Clustering Solution for Wireless Sensor Networks hot spots in a wireless sensor network emerge as locations under heavy traffic load. nodes in such areas quickly deplete energy resources, leading to disruption in network services. this problem is common for data collection scenarios in which cluster heads (ch) have a heavy burden of gathering and relaying information. the relay load on chs especially intensifies as the distance to the sink decreases. to balance the traffic load and the energy consumption in the network, the ch role should be rotated among all nodes and the cluster sizes should be carefully determined at different parts of the network. this paper proposes a distributed clustering algorithm, energy-efficient clustering (ec), that determines suitable cluster sizes depending on the hop distance to the data sink, while achieving approximate equalization of node lifetimes and reduced energy consumption levels. we additionally propose a simple energy-efficient multihop data collection protocol to evaluate the effectiveness of ec and calculate the end-to-end energy consumption of this protocol; yet ec is suitable for any data collection protocol that focuses on energy conservation. performance results demonstrate that ec extends network lifetime and achieves energy equalization more effectively than two well-known clustering algorithms, heed and ucr.",
            "contribution_ids": [
                "R26749"
            ]
        },
        {
            "instance_id": "R26775xR26766",
            "comparison_id": "R26775",
            "paper_id": "R26766",
            "text": "Multihop Routing Protocol with Unequal Clustering for Wireless Sensor Networks in order to prolong the lifetime of wireless sensor networks, this paper presents a multihop routing protocol with unequal clustering (mrpuc). on the one hand, cluster heads deliver the data to the base station with relay to reduce energy consumption. on the other hand, mrpuc uses many measures to balance the energy of nodes. first, it selects the nodes with more residual energy as cluster heads, and clusters closer to the base station have smaller sizes to preserve some energy during intra-cluster communication for inter-cluster packets forwarding. second, when regular nodes join clusters, they consider not only the distance to cluster heads but also the residual energy of cluster heads. third, cluster heads choose those nodes as relay nodes, which have minimum energy consumption for forwarding and maximum residual energy to avoid dying earlier. simulation results show that mrpuc performs much better than similar protocols.",
            "contribution_ids": [
                "R26767"
            ]
        },
        {
            "instance_id": "R26850xR26828",
            "comparison_id": "R26850",
            "paper_id": "R26828",
            "text": "An Integrated Model and Solution Approach for Fleet Sizing with Heterogeneous Assets this paper addresses a fleet-sizing problem in the context of the truck-rental industry. specifically, trucks that vary in capacity and age are utilized over space and time to meet customer demand. operational decisions (including demand allocation and empty truck repositioning) and tactical decisions (including asset procurements and sales) are explicitly examined in a linear programming model to determine the optimal fleet size and mix. the method uses a time-space network, common to fleet-management problems, but also includes capital cost decisions, wherein assets of different ages carry different costs, as is common to replacement analysis problems. a two-phase solution approach is developed to solve large-scale instances of the problem. phase i allocates customer demand among assets through benders decomposition with a demand-shifting algorithm assuring feasibility in each subproblem. phase ii uses the initial bounds and dual variables from phase i and further improves the solution convergence without increasing computer memory requirements through the use of lagrangian relaxation. computational studies are presented to show the effectiveness of the approach for solving large problems within reasonable solution gaps.",
            "contribution_ids": [
                "R26829"
            ]
        },
        {
            "instance_id": "R26850xR26797",
            "comparison_id": "R26850",
            "paper_id": "R26797",
            "text": "The mixed fleet stochastic vehicle routing problem the mixed fleet stochastic vehicle routing problem is considered in the paper. it is assumed that operations are performed by vehicles of different types. the model developed is based on the \u201croute first \u2014 cluster second\u201d approach. a heuristic algorithm based on space-filling curves is used to produce a giant travelling salesman tour. the giant tour is divided into smaller parts using the generalized floyd algorithm. the final set of routes may be chosen after making a suitable multi-attribute decision making analysis.",
            "contribution_ids": [
                "R26798"
            ]
        },
        {
            "instance_id": "R26850xR26808",
            "comparison_id": "R26850",
            "paper_id": "R26808",
            "text": "A heuristic column generation method for the heterogeneous fleet VRP this paper presents a heuristic column generation method for solving vehicle routing problems with a heterogeneous fleet of vehicles. the method may also solve the fleet size and composition vehicle routing problem and new best known solutions are reported for a set of classical problems. numerical results show that the method is robust and efficient, particularly for medium and large size problem instances.",
            "contribution_ids": [
                "R26809",
                "R26852"
            ]
        },
        {
            "instance_id": "R26918xR26893",
            "comparison_id": "R26918",
            "paper_id": "R26893",
            "text": "Minimum Vehicle Fleet Size Under Time-Window Constraints at a Container Terminal products can be transported in containers from one port to another. at a container terminal these containers are transshipped from one mode of transportation to another. cranes remove containers from a ship and put them at a certain time (i.e., release time) into a buffer area with limited capacity. a vehicle lifts a container from the buffer area before the buffer area is full (i.e., in due time) and transports the container from the buffer area to the storage area. at the storage area the container is placed in another buffer area. the advantage of using these buffer areas is the resultant decoupling of the unloading and transportation processes. we study the case in which each container has a time window [release time, due time] in which the transportation should start. the objective is to minimize the vehicle fleet size such that the transportation of each container starts within its time window. no literature has been found studying this relevant problem. we have developed an integer linear programming model to solve the problem of determining vehicle requirements under time-window constraints. we use simulation to validate the estimates of the vehicle fleet size by the analytical model. we test the ability of the model under various conditions. from these numerical experiments we conclude that the results of the analytical model are close to the results of the simulation model. furthermore, we conclude that the analytical model performs well in the context of a container terminal.",
            "contribution_ids": [
                "R26894"
            ]
        },
        {
            "instance_id": "R26918xR26900",
            "comparison_id": "R26918",
            "paper_id": "R26900",
            "text": "Economic Heuristic Optimization for Heterogeneous Fleet VRPHESTW a three-step local search algorithm based on a probabilistic variable neighborhood search is presented for the vehicle routing problem with a heterogeneous fleet of vehicles and soft time windows (vrphestw). a generation mechanism based on a greedy randomized adaptive search procedure, a diversification procedure using an extinctive selection evolution strategy, and a postoptimization method based on a threshold algorithm with restarts are considered to solve the problem. the results show the convenience of using an economic objective function to analyze the influence of the changes in the economic environment on the transportation average profit of vehicle routing problems. near real-world vehicle routing problems need (1) an economic objective function to measure the quality of the solutions as well as (2) an appropriate guide function, which may be different from the economic objective function, for each heuristic method and for each economic scenario.",
            "contribution_ids": [
                "R26901"
            ]
        },
        {
            "instance_id": "R26918xR26883",
            "comparison_id": "R26918",
            "paper_id": "R26883",
            "text": "Lagrangian Relaxation Methods for Solving the Minimum Fleet Size Multiple Traveling Salesman Problem with Time Windows we consider the problem of finding the minimum number of vehicles required to visit once a set of nodes subject to time window constraints, for a homogeneous fleet of vehicles located at a common depot. this problem can be formulated as a network flow problem with additional time constraints. the paper presents an optimal solution approach using the augmented lagrangian method. two lagrangian relaxations are studied. in the first one, the time constraints are relaxed producing network subproblems which are easy to solve, but the bound obtained is weak. in the second relaxation, constraints requiring that each node be visited are relaxed producing shortest path subproblems with time window constraints and integrality conditions. the bound produced is always excellent. numerical results for several actual school busing problems with up to 223 nodes are discussed. comparisons with a set partitioning formulation solved by column generation are given.",
            "contribution_ids": [
                "R26884"
            ]
        },
        {
            "instance_id": "R26982xR26966",
            "comparison_id": "R26982",
            "paper_id": "R26966",
            "text": "Fleet Size and Mix Optimization for Paratransit Services most paratransit agencies use a mix of different types of vehicles ranging from small sedans to large converted vans as a cost-effective way to meet the diverse travel needs and seating requirements of their clients. currently, decisions on what types of vehicles and how many vehicles to use are mostly made by service managers on an ad hoc basis without much systematic analysis and optimization. the objective of this research is to address the underlying fleet size and mix problem and to develop a practical procedure that can be used to determine the optimal fleet mix for a given application. a real-life example illustrates the relationship between the performance of a paratransit service system and the size of its service vehicles. a heuristic procedure identifies the optimal fleet mix that maximizes the operating efficiency of a service system. a set of recommendations is offered for future research; the most important is the need to incorporate a life-cycle cost framework into the paratransit service planning process.",
            "contribution_ids": [
                "R26967"
            ]
        },
        {
            "instance_id": "R26982xR26980",
            "comparison_id": "R26982",
            "paper_id": "R26980",
            "text": "Coca-Cola Enterprises Optimizes Vehicle Routes for Efficient Product Delivery \" in 2004 and 2005, coca-cola enterprises (cce)\u2014the world's largest bottler and distributor of coca-cola products\u2014implemented ortec's vehicle-routing software. today, over 300 cce dispatchers use this software daily to plan the routes of approximately 10,000 trucks. in addition to handling nonstandard constraints, the implementation is notable for its progressive transition from the prior business practice. cce has realized an annual cost saving of $45 million and major improvements in customer service. this approach has been so successful that coca-cola has extended it beyond cce to other coca-cola bottling companies and beer distributors. \"",
            "contribution_ids": [
                "R26981"
            ]
        },
        {
            "instance_id": "R27039xR27011",
            "comparison_id": "R27039",
            "paper_id": "R27011",
            "text": "A dynamic model and algorithm for fleet planning by analysing the merits and demerits of the existing linear model for fleet planning, this paper presents an algorithm which combines the linear programming technique with that of dynamic programming to improve the solution to linear model for fleet planning. this new approach has not only the merits that the linear model for fleet planning has, but also the merit of saving computing time. the numbers of ships newly added into the fleet every year are always integers in the final optimal solution. the last feature of the solution directly meets the requirements of practical application. both the mathematical model of the dynamic fleet planning and its algorithm are put forward in this paper. a calculating example is also given.",
            "contribution_ids": [
                "R27012",
                "R28322"
            ]
        },
        {
            "instance_id": "R27039xR27015",
            "comparison_id": "R27039",
            "paper_id": "R27015",
            "text": "Strategic fleet size planning for maritime refrigerated containers in the present economic climate, it is often the case that profits can only be improved, or for that matter maintained, by improving efficiency and cutting costs. this is particularly notorious in the shipping business, where it has been seen that the competition is getting tougher among carriers, thus alliances and partnerships are resulting for cost effective services in recent years. in this scenario, effective planning methods are important not only for strategic but also operating tasks, covering their entire transportation systems. container fleet size planning is an important part of the strategy of any shipping line. this paper addresses the problem of fleet size planning for refrigerated containers, to achieve cost-effective services in a competitive maritime shipping market. an analytical model is first discussed to determine the optimal size of an own dry container fleet. then, this is extended for an own refrigerated container fleet, which is the case when an extremely unbalanced trade represents one of the major investment decisions to be taken by liner operators. next, a simulation model is developed for fleet sizing in a more practical situation and, by using this, various scenarios are analysed to determine the most convenient composition of refrigerated fleet between own and leased containers for the transpacific cargo trade.",
            "contribution_ids": [
                "R27016"
            ]
        },
        {
            "instance_id": "R27039xR27007",
            "comparison_id": "R27039",
            "paper_id": "R27007",
            "text": "Optimal fleet design in a ship routing problem abstract the problem of deciding an optimal fleet (the type of ships and the number of each type) in a real liner shipping problem is considered. the liner shipping problem is a multi-trip vehicle routing problem, and consists of deciding weekly routes for the selected ships. a solution method consisting of three phases is presented. in phase 1, all feasible single routes are generated for the largest ship available. some of these routes will use only a small portion of the ship\u2019s capacity and can be performed by smaller ships at less cost. this fact is used when calculating the cost of each route. in phase 2, the single routes generated in phase 1 are combined into multiple routes. by solving a set partitioning problem (phase 3), where the columns are the routes generated in phases 1 and 2, we find both the optimal fleet and the coherent routes for the fleet.",
            "contribution_ids": [
                "R27008",
                "R28387"
            ]
        },
        {
            "instance_id": "R27039xR26984",
            "comparison_id": "R27039",
            "paper_id": "R26984",
            "text": "Transporting Sludge to the 106-Mile Site: An Inventory/Routing Model for Fleet Sizing and Logistics System Design this paper develops a model that is being used by the city of new york to design a new logistics system to transport municipal sewage sludge from city-operated wastewater treatment plants to a new ocean dumping site 106 miles offshore. the model provides an integrative framework for considering such strategic planning issues as fleet sizing, choice of vessel size, sizing local inventory holding capacities, and analyzing system behavior with and without transshipment. a unique feature of the model is that plant visitation frequencies are determined naturally by the characteristics of the problem (vessel size, inventory holding capacities, statistics of sludge production, proximity of other plants), rather than stated as exogeneous constraints. the formulation should be useful in a more general class of depot-to-customer distribution systems, including the distribution of industrial gases. the paper concludes with a description of additional research that is required in refining both the assumptions and the mechanisms of execution of the model.",
            "contribution_ids": [
                "R26985"
            ]
        },
        {
            "instance_id": "R27039xR26998",
            "comparison_id": "R27039",
            "paper_id": "R26998",
            "text": "Modeling the Increased Complexity of New York City's Refuse Marine Transport System \" the new york city department of sanitation operates the world's largest refuse marine transport system. waste trucks unload their cargo at land-based transfer stations where refuse is placed in barges and then towed by tugboats to the fresh kills landfill in staten island. in the early 1980s, the city commissioned the development of a computer-based model for use in fleet sizing and operations planning. as a result of the complexities introduced by environmental regulation and technological innovation, the marine transport system operations changed and the existing model became obsolete. based on the success achieved with the first model in 1993, the city commissioned the development of a new model. in this paper, we present a pc-based model developed to meet the increased complexity of the system. analysis performed for validation and calibration of the model demonstrates that it tracks well the operations of the real system. we illustrate through a detailed design exercise how to use the model to configure the system in a way that meets the requirements of the refuse marine transport system. \"",
            "contribution_ids": [
                "R26999"
            ]
        },
        {
            "instance_id": "R27039xR27018",
            "comparison_id": "R27039",
            "paper_id": "R27018",
            "text": "Robust ship scheduling with multiple time windows \"we present a ship scheduling problem concerned with the pickup and delivery of bulk cargoes within given time windows. as the ports are closed for service at night and during weekends, the wide time windows can be regarded as multiple time windows. another issue is that the loading/discharging times of cargoes may take several days. this means that a ship will stay idle much of the time in port, and the total time at port will depend on the ship's arrival time. ship scheduling is associated with uncertainty due to bad weather at sea and unpredictable service times in ports. our objective is to make robust schedules that are less likely to result in ships staying idle in ports during the weekend, and impose penalty costs for arrivals at risky times (i.e., close to weekends). a set partitioning approach is proposed to solve the problem. the columns correspond to feasible ship schedules that are found a priori. they are generated taking the uncertainty and multiple time windows into account. the computational results show that we can increase the robustness of the schedules at the sacrifice of increased transportation costs. \u00a9 2002 wiley periodicals, inc. naval research logistics 49: 611\u2013625, 2002; published online in wiley interscience (www.interscience.wiley.com). doi 10.1002/nav.10033\"",
            "contribution_ids": [
                "R27019"
            ]
        },
        {
            "instance_id": "R27039xR26992",
            "comparison_id": "R27039",
            "paper_id": "R26992",
            "text": "Optimal liner fleet routeing strategies the objective of this paper is to suggest practical optimization models for routing strategies for liner fleets. many useful routing and scheduling problems have been studied in the transportation literature. as for ship scheduling or routing problems, relatively less effort has been devoted, in spite of the fact that sea transportation involves large capital and operating costs. this paper suggests two optimization models that can be useful to liner shipping companies. one is a linear programming model of profit maximization, which provides an optimal routing mix for each ship available and optimal service frequencies for each candidate route. the other model is a mixed integer programming model with binary variables which not only provides optimal routing mixes and service frequencies but also best capital investment alternatives to expand fleet capacity. this model is a cost minimization model.",
            "contribution_ids": [
                "R26993",
                "R28386"
            ]
        },
        {
            "instance_id": "R27061xR27043",
            "comparison_id": "R27061",
            "paper_id": "R27043",
            "text": "Smart cities ranking: an effective instrument for the positioning of the cities? due to different reasons cities are increasingly challenged to improve their competitiveness.&#x0d;\\ndifferent strategic efforts are discussed in planning sciences, new approaches and instruments&#x0d;\\nare elaborated and applied, steering the positioning of cities in a competitive urban world. as&#x0d;\\none specific consequence city rankings have experienced a remarkable boom. however, there&#x0d;\\nis some evidence that public attention of city rankings is mainly concentrated simply on the&#x0d;\\nranks themselves totally neglecting its meaning as an instrument for strategic planning.&#x0d;\\nin order to elaborate this potential meaning of rankings the paper gives an overview of different&#x0d;\\ntypes and introduces an own approach called \u2018smart city ranking\u2019. based on this ranking&#x0d;\\napproach and corresponding experiences of different cities reacting on its dissemination in the&#x0d;\\nsecond part the paper shows how this approach can be used as an effective instrument&#x0d;\\ndetecting strengths and weaknesses and improving a city\u2019s competitiveness through relevant&#x0d;\\nstrategic efforts. \\n per diferents motius, les ciutats es troben cada vegada en major mesura front el repte de millorar la seva competitivitat. diferents esfor\u00e7os estrat\u00e8gics s\u00f3n discutits en les ci\u00e8ncies del planejament, nous enfocaments i instruments s\u00f3n elaborats i posats en pr\u00e0ctica, guiant el posicionament de les ciutats en un competitiu m\u00f3n urb\u00e0. una conseq\u00fc\u00e8ncia espec\u00edfica d\u2019aix\u00f2 \u00e9s que la categoritzaci\u00f3 de ciutats ha experimentat un augment notable. no obstant, hi ha certs indicis de que l\u2019atenci\u00f3 p\u00fablica respecte de la categoritzaci\u00f3 de ciutats es centra principalment en les \u00faltimes posicions, oblidant completament la seva significan\u00e7a com instrument de planificaci\u00f3 estrat\u00e8gica.&#x0d;\\n&#x0d;\\namb la finalitat de desenvolupar aquesta potencial significan\u00e7a de les categoritzacions, l\u2019article fa un rep\u00e0s de diferents tipus i presenta una aproximaci\u00f3 pr\u00f2pia anomenada \u201csmart city ranking\u201d. basat en aquest enfocament a la categoritzaci\u00f3 i les corresponents experi\u00e8ncies de la reacci\u00f3 de diferents ciutats respecte a la seva difusi\u00f3, en una segona part l\u2019article mostra com aquesta aproximaci\u00f3 pot ser utilitzada com instrument efica\u00e7, reconeixent fortaleses i debilitats i millorant la competitivitat de les ciutats a trav\u00e9s d\u2019esfor\u00e7os estrat\u00e8gics adequats. \\n por diferentes motivos, las ciudades se encuentran cada vez en mayor medida ante el reto de mejorar su competitividad. distintos esfuerzos estrat\u00e9gicos son discutidos en las ciencias del planeamiento, nuevos enfoques e instrumentos son elaborados y puestos en pr\u00e1ctica, guiando el posicionamiento de las ciudades en un mundo urbano competitivo. una consecuencia espec\u00edfica de ello es que la categorizaci\u00f3n de ciudades ha experimentado un auge notable. sin embargo, hay ciertos indicios de que la atenci\u00f3n sobre la jerarquizaci\u00f3n de ciudades se centra principalmente en las \u00faltimas posiciones, olvidando completamente su significancia como instrumento de planificaci\u00f3n estrat\u00e9gica.&#x0d;\\n&#x0d;\\ncon el fin de desarrollar esta potencial significancia este art\u00edculo hace un repaso de distintos tipos y presenta una aproximaci\u00f3n propia llamada \u201csmart city ranking\u201d. basado en este enfoque a la categorizaci\u00f3n y las correspondientes experiencias de la reacci\u00f3n de diferentes ciudades en cuanto a su difusi\u00f3n, en una segunda parte el art\u00edculo muestra como esta aproximaci\u00f3n puede ser utilizada como un instrumento eficaz, reconociendo fortalezas y debilidades y mejorando la competitividad de las ciudades a trav\u00e9s de esfuerzos estrat\u00e9gicos adecuados.",
            "contribution_ids": [
                "R27044"
            ]
        },
        {
            "instance_id": "R27061xR27049",
            "comparison_id": "R27061",
            "paper_id": "R27049",
            "text": "Smart City Components Architicture the research is essentially to modularize the structure of utilities and develop a system for following up the activities electronically on the city scale. the gis operational platform will be the base for managing the infrastructure development components with the systems interoperability for the available city infrastructure related systems. the concentration will be on the available utility networks in order to develop a comprehensive, common, standardized geospatial data models. the construction operations for the utility networks such as electricity, water, gas, district cooling, irrigation, sewerage and communication networks; are need to be fully monitored on daily basis, in order to utilize the involved huge resources and man power. these resources are allocated only to convey the operational status for the construction and execution sections that used to do the required maintenance. the need for a system that serving the decision makers for following up these activities with a proper geographical representation will definitely reduce the operational cost for the long term.",
            "contribution_ids": [
                "R27050"
            ]
        },
        {
            "instance_id": "R27061xR27041",
            "comparison_id": "R27061",
            "paper_id": "R27041",
            "text": "Foundations for Smarter Cities this paper describes the information technology (it) foundation and principles for smarter cities\u2122. smarter cities are urban areas that exploit operational data, such as that arising from traffic congestion, power consumption statistics, and public safety events, to optimize the operation of city services. the foundational concepts are instrumented, interconnected, and intelligent. instrumented refers to sources of near-real-time real-world data from both physical and virtual sensors. interconnected means the integration of those data into an enterprise computing platform and the communication of such information among the various city services. intelligent refers to the inclusion of complex analytics, modeling, optimization, and visualization in the operational business processes to make better operational decisions. this approach enables the adaptation of city services to the behavior of the inhabitants, which permits the optimal use of the available physical infrastructure and resources, for example, in sensing and controlling consumption of energy and water, managing waste processing and transportation systems, and applying optimization to achieve new efficiencies among these resources. additional roles exist in intelligent interaction between the city and its inhabitants and further contribute to operational efficiency while maintaining or enhancing quality of life.",
            "contribution_ids": [
                "R27042"
            ]
        },
        {
            "instance_id": "R27235xR27165",
            "comparison_id": "R27235",
            "paper_id": "R27165",
            "text": "Exchange rate variability and trade: why is it so difficult to find any empirical relationship? this paper discusses why previous literature has found little evidence of any effect of exchange rate variability on international trade. methodological and statistical issues are discussed. in particular, comparisons are made of estimations based on different specifications or using different data sets and changes in the results depending on the method used are shown.",
            "contribution_ids": [
                "R27166"
            ]
        },
        {
            "instance_id": "R27235xR27230",
            "comparison_id": "R27235",
            "paper_id": "R27230",
            "text": "Exchange Rate Volatility and Trade Flows of the U.K. in 1990s this paper examines the impact of exchange rate volatility on trade flows in the u.k. over the period 1990\u20132000. according to the conventional approach, exchange rate volatility clamps down trade volumes. this paper, however, identifies the existence of a positive relationship between exchange rate volatility and imports in the u.k. in the 1990s by using a bivariate garch-in-mean model. it highlights a possible emergence of a polarized version with conventional proposition that erv works as an impediment factor on trade flows.",
            "contribution_ids": [
                "R27231"
            ]
        },
        {
            "instance_id": "R27235xR27149",
            "comparison_id": "R27235",
            "paper_id": "R27149",
            "text": "Real Exchange Rate Volatility and U.S. Bilateral Trade: A VAR Approach this paper uses var models to investigate the impact of real exchange rate volatility on u.s. bilateral imports from the united kingdom, france, germany, japan and canada. the var systems include u.s. and foreign macro variables, and are estimated separately for each country. the major results suggest that the effect of volatility on imports is weak, although permanent shocks to volatility do have a negative impact on this measure of trade, and those effects are relatively more important over the flexible rate period. copyright 1989 by mit press.",
            "contribution_ids": [
                "R27150"
            ]
        },
        {
            "instance_id": "R27235xR27217",
            "comparison_id": "R27235",
            "paper_id": "R27217",
            "text": "Exchange Rate Volatility and Trade among the Asia Pacific \"the purpose of this paper is to investigate the impact of exchange rate volatility on exports among 14 asia pacific countries, where various measures to raise the intra-region trade are being implemented. specifically, this paper estimates a gravity model, in which the dependent variable is the product of the exports of two trading countries. in addition, it also estimates a unilateral exports model, in which the dependent variable is not the product of the exports of two trading countries but the exports from one country to another. by doing this, the depreciation rate of the exporting country's currency value can be included as one of the explanatory variables affecting the volume of exports. as the explanatory variables of the export volume, the gravity model adopts the product of the gdps of two trading counties, their bilateral exchange rate volatility, their distance, a time trend and dummies for the share of the border line, the use of the same language, and the apec membership. in the case of the unilateral exports model, the product of the gdps is replaced by the gdp of the importing country, and the depreciation rate of the exporting country's currency value is dded. in addition, considering that the export volume will also depend on various onditions of the exporting country, dummies for exporting countries are also included as an explanatory variable. the empirical tests, using annual data for the period from 1980 to 2002, detect a significant negative impact of exchange rate volatility on the volume of exports. in addition, various tests using the data for sub-sample periods indicate that the negative impact had been weakened since 1989, when apec had launched, and surged again from 1997, when the asian financial crisis broke out. this finding implies that the impact of exchange rate volatility is time-dependent and that it is significantlynegative at least in the present time. this phenomenon is noticed regardless which estimation model is adopted. in addition, the test results show that the gdp of the importing country, the depreciation of the exporting country's currency value, the use of the same language and the membership of apec have positive impacts on exports, while the distance between trading countries have negative impacts. finally, it turns out that the negative impact of exchange rate volatility is much weaker among oecd countries than among non-oecd counties.\"",
            "contribution_ids": [
                "R27218"
            ]
        },
        {
            "instance_id": "R27235xR27144",
            "comparison_id": "R27235",
            "paper_id": "R27144",
            "text": "Exchange Rate Risk, Exchange Rate Regime and the Volume of International Trade the authors examine the effect of exchange-rate regimes on the volume of internatio nal trade. bilateral trade flows among countries with floating exchan ge rates are higher than those among countries with fixed rates. whil e exchange-rate risk does reduce the volume of trade among countries regardless of the nature of their exchange-rate regime, the greater r isk faced by traders in floating exchange-rate countries is more than offset by the trade-reducing effects of restrictive commercial polic ies imposed by fixed exchange rate countries. copyright 1988 by wwz and helbing & lichtenhahn verlag ag",
            "contribution_ids": [
                "R27145"
            ]
        },
        {
            "instance_id": "R27235xR27225",
            "comparison_id": "R27235",
            "paper_id": "R27225",
            "text": "Exchange Rate Uncertainty in Turkey and its Impact on Export Volume this paper investigates the impact of real exchange rate volatility on turkey\u2019s exports to its most important trading partners using quarterly data for the period 1982 to 2001. cointegration and error correction modeling approaches are applied, and estimates of the cointegrating relations are obtained using johansen\u2019s multivariate procedure. estimates of the short-run dynamics are obtained through the error correction technique. our results indicate that exchange rate volatility has a significant positive effect on export volume in the long run. this result may indicate that firms operating in a small economy, like turkey, have little option for dealing with increased exchange rate risk.",
            "contribution_ids": [
                "R27226"
            ]
        },
        {
            "instance_id": "R27235xR27156",
            "comparison_id": "R27235",
            "paper_id": "R27156",
            "text": "The Effect of Real Exchange Rate Uncertainty on Exports: Empirical Evidence unless very specific assumptions are made, theory alone cannot determine the sign of the relation between real exchange rate uncertainty and exports. on the one hand, convexity of the profit function with respect to prices implies that an increase in price uncertainty raises the expected returns in the export sector. on the other, potential asymmetries in the cost of adjusting factors of production (for example, investment irreversibility) and risk aversion tend to make the uncertainty-exports relation negative. this article examines these issues using a simple risk-aversion model. export equations allowing for uncertainty are then estimated for six developing countries. contrary to the ambiguity of the theory, the empirical relation is strongly negative. estimates indicate that a 5 percent increase in the annual standard deviation of the real exchange rate can reduce exports by 2 to 30 percent in the short run. these effects are substantially magnified in the long run.",
            "contribution_ids": [
                "R27157"
            ]
        },
        {
            "instance_id": "R27235xR27129",
            "comparison_id": "R27235",
            "paper_id": "R27129",
            "text": "Effects of Exchange Rate Volatility on Trade: Some Further Evidence (Effets de l'instabilite des taux de change sur le commerce mondial: nouvelles constatations) (Efectos de la inestabilidad de los tipos de cambio en el comercio internacional: Alguna evidencia adicional) a recent survey of the empirical studies examining the effects of exchange rate volatility on international trade concluded that \"the large majority of empirical studies... are unable to establish a systematically significant link between measured exchange rate variability and the volume of international trade, whether on an aggregated or on a bilateral basis\" (international monetary fund, exchange rate volatility and world trade, washington, july 1984, p. 36). a recent paper by m.a. akhtar and r.s. hilton (\"exchange rate uncertainty and international trade,\" federal reserve bank of new york, may 1984), in contrast, suggests that exchange rate volatility, as measured by the standard deviation of indices of nominal effective exchange rates, has had significant adverse effects on the trade in manufactures of the united states and the federal republic of germany. the purpose of the present study is to test the robustness of akhtar and hilton\\'s empirical results, with their basic theoretical framework taken as given. the study extends their analysis to include france, japan, and the united kingdom; it then examines the robustness of the results with respect to changes in the choice of sample period, volatility measure, and estimation techniques. the main conclusion of the analysis is that the methodology of akhtar and hilton fails to establish a systematically significant link between exchange rate volatility and the volume of international trade. this is not to say that significant adverse effects cannot be detected in individual cases, but rather that, viewed in the large, the results tend to be insignificant or unstable. specifically, the results suggest that straightforward application of akhtar and hilton\\'s methodology to three additional countries (france, japan, and the united kingdom) yields mixed results; that their methodology seems to be flawed in several respects, and that correction for such flaws has the effect of weakening their conclusions; that the estimates are quite sensitive to fairly minor variations in methodology; and that \"revised\" estimates for the five countries do not, for the most part, support the hypothesis that exchange rate volatility has had a systematically adverse effect on trade. /// un ra\u00a9cent apera\u00a7u des a\u00a9tudes empiriques consacra\u00a9es aux effets de l\\'instabilita\u00a9 des taux de change sur le commerce international conclut que \"dans leur grande majorita\u00a9, les a\u00a9tudes empiriques... ne ra\u00a9ussissent pas a a\u00a9tablir un lien significatif et systa\u00a9matique entre la variabilita\u00a9 mesura\u00a9e des taux de change et le volume du commerce international, que celui-ci soit exprima\u00a9 sous forme globale ou bilata\u00a9rale\" (fonds mona\u00a9taire international, exchange rate volatility and world trade, washington, juillet 1984, page 36). par contre, un article publia\u00a9 ra\u00a9cemment par m.a. akhtar et r.s. hilton (\"exchange rate uncertainty and international trade\", federal reserve bank of new york, mai 1984) soutient que l\\'instabilita\u00a9 des taux de change, mesura\u00a9e par l\\'a\u00a9cart type des indices des taux de change effectifs nominaux, a eu un effet da\u00a9favorable significatif sur le commerce de produits manufactura\u00a9s des etats-unis et de la ra\u00a9publique fa\u00a9da\u00a9rale d\\'allemagne. la pra\u00a9sente a\u00a9tude a pour objet d\\'a\u00a9valuer la solidita\u00a9 des ra\u00a9sultats empiriques pra\u00a9senta\u00a9s par akhtar et hilton, en prenant comme donna\u00a9 leur cadre tha\u00a9orique de base. l\\'auteur a\u00a9tend l\\'analyse au cas de la france, du japon et du royaume-uni; elle cherche ensuite dans quelle mesure ces ra\u00a9sultats restent valables si l\\'on modifie la pa\u00a9riode de ra\u00a9fa\u00a9rence, la mesure de l\\'instabilita\u00a9 et les techniques d\\'estimation. la principale conclusion de cette a\u00a9tude est que la ma\u00a9thode utilisa\u00a9e par akhtar et hilton n\\'a\u00a9tablit pas de lien significatif et systa\u00a9matique entre l\\'instabilita\u00a9 des taux de change et le volume du commerce international. ceci ne veut pas dire que l\\'on ne puisse pas constater dans certains cas particuliers des effets da\u00a9favorables significatifs, mais pluta\u00b4t que, pris dans leur ensemble, les ra\u00a9sultats sont peu significatifs ou peu stables. plus pra\u00a9cisa\u00a9ment, cette a\u00a9tude laisse entendre qu\\'une application systa\u00a9matique de la ma\u00a9thode d\\'akhtar et hilton a trois pays suppla\u00a9mentaires (france, japon et royaume-uni) donne des ra\u00a9sultats mitiga\u00a9s; que leur ma\u00a9thode semble pra\u00a9senter plusieurs da\u00a9fauts et que la correction de ces da\u00a9fauts a pour effet d\\'affaiblir la porta\u00a9e de leurs conclusions; que leurs estimations sont tra\u00a8s sensibles a des variations relativement mineures de la ma\u00a9thode utilisa\u00a9e et que la plupart des estimations \"ra\u00a9visa\u00a9es\" pour les cinq pays ne confirment pas l\\'hypotha\u00a8se selon laquelle l\\'instabilita\u00a9 des taux de change aurait eu un effet systa\u00a9matiquement na\u00a9gatif sur le commerce international. /// en un examen reciente de los estudios empa\\xadricos sobre los efectos de la inestabilidad de los tipos de cambio en el comercio internacional se llega a la conclusia\u00b3n de que \"la gran mayora\\xada de estos anailisis empa\\xadricos no consiguen demostrar sistemaiticamente un va\\xadnculo significativo entre los diferentes grados de variabilidad cambiaria y el volumen del comercio internacional, tanto sea en ta\u00a9rminos agregados como bilaterales\". (fondo monetario internacional, exchange rate volatility and world trade, washington, julio de 1984, paig. 36). un estudio reciente de m.a. akhtar y r.s. hilton (\"exchange rate uncertainty and international trade,\" banco de la reserva federal de nueva york, mayo de 1984) indica, por el contrario, que la inestabilidad de los tipos de cambio, expresada segaon la desviacia\u00b3n estaindar de los a\\xadndices de los tipos de cambio efectivos nominales, ha tenido efectos negativos considerables en el comercio de productos manufacturados de estados unidos y de la repaoblica federal de alemania. el presente estudio tiene por objeto comprobar la solidez de los resultados empa\\xadricos de akhtar y hilton, tomando como base de partida su marco tea\u00b3rico baisico. el estudio ampla\\xada su anailisis incluyendo a francia, japa\u00b3n y el reino unido, pasando luego a examinar la solidez de los resultados con respecto a variaciones en la seleccia\u00b3n del pera\\xadodo de la muestra, medida de la inestabilidad y ta\u00a9cnicas de estimacia\u00b3n. la conclusia\u00b3n principal del anailisis es que la metodologa\\xada de akhtar y hilton no logra establecer un va\\xadnculo significativo sistemaitico entre la inestabilidad de los tipos de cambio y el volumen del comercio internacional. esto no quiere decir que no puedan obsevarse en casos especa\\xadficos efectos negativos importantes, sino mais bien que, en ta\u00a9rminos generales, los resultados no suelen ser ni considerables ni estables. en concreto, de los resultados se desprende que la aplicacia\u00b3n directa de la metodologa\\xada de akhtar y hilton a tres nuevos paa\\xadses (francia, japa\u00b3n y el reino unido) arroja resultados dispares; que esta metodologa\\xada parece ser defectuosa en varios aspectos y que la correccia\u00b3n de tales deficiencias tiene como efecto el debilitamiento de sus conclusiones; que las estimaciones son muy sensibles a modificaciones poco importantes de la metodologa\\xada, y que las estimaciones \"revisadas\" para los cinco paa\\xadses no confirman, en su mayor parte, la hipota\u00a9sis de que la inestabilidad de los tipos de cambio ha ejercido un efecto negativo sistemaitico en el comercio exterior.",
            "contribution_ids": [
                "R27130"
            ]
        },
        {
            "instance_id": "R27264xR27238",
            "comparison_id": "R27264",
            "paper_id": "R27238",
            "text": "Middleware for Robotics: A Survey the field of robotics relies heavily on various technologies such as mechatronics, computing systems, and wireless communication. given the fast growing technological progress in these fields, robots can offer a wide range of applications. however real world integration and application development for such a distributed system composed of many robotic modules and networked robotic devices is very difficult. therefore, middleware services provide a novel approach offering many possibilities and drastically enhancing the application development for robots. this paper surveys the current state of middleware approaches in this domain. it discusses middleware challenges in these systems and presents some representative middleware solutions specifically designed for robots. the selection of the studied methods tries to cover most of the middleware platforms, objectives and approaches that have been proposed by researchers in this field.",
            "contribution_ids": [
                "R27239",
                "R27241",
                "R27243",
                "R27245",
                "R27247",
                "R27249"
            ]
        },
        {
            "instance_id": "R27380xR27325",
            "comparison_id": "R27380",
            "paper_id": "R27325",
            "text": "Effect of Cooling and Shot Peening on Residual Stresses and Fatigue Performance of Milled Inconel 718 the present study highlights the effect of cooling and post-machining surface treatment of shot peening on the residual stresses and corresponding fatigue life of milled superalloy inconel 718. it ...",
            "contribution_ids": [
                "R27326"
            ]
        },
        {
            "instance_id": "R27380xR27374",
            "comparison_id": "R27380",
            "paper_id": "R27374",
            "text": "Relaxation of residual stresses induced by turning and shot peening on steels experiments on the relaxation of residual stresses in steels by fatigue loading are described. this question is of interest because it is well known that compressive residual stresses are often induced by special surface treatments (such as shot peening) to improve the fatigue life of metal parts; however, if cyclic relaxation occurs, the beneficial effects can, in part, vanish during service. two hardened and tempered steels of grade c45 and 39nicrmo3 were used in the tests. for both materials, different specimens were given two surface treatments: simple turning without successive surface treatment, inducing on the surface a moderate tensile residual stress state, and shot peening, inducing high residual compressive stresses. the specimens were submitted to constant-amplitude tension-compression fatigue loading, and the surface residual stresses were measured after 0, 1, 10 cycles and more. results show that relaxation occurs from the very first cycle; the amount of residual stress relaxation depends on many parameters and on the type of steel. the results are in agreement with data obtained by other researchers.",
            "contribution_ids": [
                "R27375"
            ]
        },
        {
            "instance_id": "R27380xR27331",
            "comparison_id": "R27380",
            "paper_id": "R27331",
            "text": "Effect of shot peening on residual stress and fatigue life of a spring steel this study describes shot peening effects such as shot hardness, shot size and shot projection pressure, on the residual stress distribution and fatigue life in reversed torsion of a 60sc7 spring steel. there appears to be a correlation between the fatigue strength and the area under the residual stress distribution curve. the biggest shot shows the best fatigue life improvement. however, for a shorter time of shot peening, small hard shot showed the best performance. moreover, the superficial residual stresses and the amount of work hardening (characterised by the width of the x-ray diffraction line) do not remain stable during fatigue cycling. indeed they decrease and their reduction rate is a function of the cyclic stress level and an inverse function of the depth of the plastically deformed surface layer.",
            "contribution_ids": [
                "R27332"
            ]
        },
        {
            "instance_id": "R27380xR27362",
            "comparison_id": "R27380",
            "paper_id": "R27362",
            "text": "Influence of Optimized Warm Peening on Residual Stress Stability and Fatigue Strength of AISI 4140 in Different Material States using a modified air blasting machine warm peening at 20 o c < t i 410 \"c was feasible. an optimized peening temperature of about 310 \"c was identified for a 450 \"c quenched and ternpered steel aisi 4140. warm peening was also investigated for a normalized, a 650 \"c quenched and tempered, and a martensitically hardened material state. the quasi static surface compressive yield strengths as well as the cyclic surface yield strengths were determined from residual stress relaxation tests conducted at different stress amplitudes and numbers of loading cycles. dynamic and static strain aging effects acting during and after warm peening clearly increased the residual stress stability and the alternating bending strength for all material states.",
            "contribution_ids": [
                "R27363"
            ]
        },
        {
            "instance_id": "R27380xR27359",
            "comparison_id": "R27380",
            "paper_id": "R27359",
            "text": "Residual Stress Relaxation and Fatigue Strength of AISI 4140 under Torsional Loading after Conventional Shot Peening, Stress Peening and Warm Peening cylindrical rods of 450\u00b0c quenched and tempered aisi 41 40 were conventionally shot peened, stress peened and warm peened while rotating in the peening device. warm peening at tpeen = 310\u00b0c was conducted using a modified air blast shot peening machine with an electric air flow heater system. to perform stress peening using a torsional pre-stress, a device was conceived which allowed rotating pre-stressed samples without having material of the pre-loading gadget between the shot and the samples. thus, same peening conditions for all peening procedures were ensured. the residual stress distributions present after the different peening procedures were evaluated and compared with results obtained after peening of flat material of the same steel. the differently peened samples were subjected to torsional pulsating stresses (r = 0) at different loadings to investigate their residual stress relaxation behavior. additionally, the pulsating torsional strengths for the differently peened samples were determined.",
            "contribution_ids": [
                "R27360"
            ]
        },
        {
            "instance_id": "R27380xR27297",
            "comparison_id": "R27380",
            "paper_id": "R27297",
            "text": "Relaxation of Shot Peening Induced Compressive Stress During Fatigue of Notched Steelsamples abstractthis paper presents an experimental investigation of the surface residual stress relaxation behaviour of a shot peened 0.4% carbon low alloy steel under fatigue loading. a round specimen with a circumferential notch and a notch factor kt = 1.75 was fatigue loaded in both shot peened and ground conditions. loading conditions included axial fatigue with stress ratio r = \u22121 and r = 0 and also r = \u22121 with an additional peak overload applied at 106 cycles. plain unnotched shot peened specimens were also fatigue loaded with stress ratio r = \u22121. the results show how the relaxation is dependent on load level, how the peak load changes the surface residual stress state, and that relaxation of the smooth and notched conditions is similar. two different shot peening conditions were used, one with almen intensity of 30\u201335a (mm/100) and another of 50\u201355 a (mm/l00).",
            "contribution_ids": [
                "R27298"
            ]
        },
        {
            "instance_id": "R27380xR27295",
            "comparison_id": "R27380",
            "paper_id": "R27295",
            "text": "Relaxationofshot peening induced compressive stress during fatigue of notched steel samples abstractthis paper presents an experimental investigation of the surface residual stress relaxation behaviour of a shot peened 0.4% carbon low alloy steel under fatigue loading. a round specimen with a circumferential notch and a notch factor kt = 1.75 was fatigue loaded in both shot peened and ground conditions. loading conditions included axial fatigue with stress ratio r = \u22121 and r = 0 and also r = \u22121 with an additional peak overload applied at 106 cycles. plain unnotched shot peened specimens were also fatigue loaded with stress ratio r = \u22121. the results show how the relaxation is dependent on load level, how the peak load changes the surface residual stress state, and that relaxation of the smooth and notched conditions is similar. two different shot peening conditions were used, one with almen intensity of 30\u201335a (mm/100) and another of 50\u201355 a (mm/l00).",
            "contribution_ids": [
                "R27296"
            ]
        },
        {
            "instance_id": "R27461xR27407",
            "comparison_id": "R27461",
            "paper_id": "R27407",
            "text": "Experimental Study of Turbulent Flow Heat Transfer and Pressure Drop in a Plate Heat Exchanger With Chevron Plates experimental heat transfer and isothermal pressure drop data for single-phase water flows in a plate heat exchanger (phe) with chevron plates are presented. in a single-pass u-type counterflow phe, three different chevron plate arrangements are considered: two symmetric plate arrangements with \u03b2 = 30 deg/30 deg and 60 deg/60 deg, and one mixed-plate arrangement with \u03b2 = 30 deg/60 deg. for water (2 &lt; pr &lt; 6) flow rates in the 600 &lt; re &lt; 104 regime, data for nu and f are presented. the results show significant effects of both the chevron angle \u03b2 and surface area enlargement factor \u03c6. as \u03b2 increases, and compared to a flat-plate pack, up to two to five times higher nu are obtained; the concomitant f, however, are 13 to 44 times higher. increasing \u03c6 also has a similar, though smaller effect. based on experimental data for re a 7000 and 30 deg \u2264 \u03b2 \u2264 60 deg, predictive correlations of the form nu = c1,(\u03b2) d1(\u03c6) rep1(\u03b2)pr1/3(\u03bc/\u03bcw)0.14 and f = c2(\u03b2) d2(\u03c6) rep2(\u03b2) are devised. finally, at constant pumping power, and depending upon re, \u03b2, and \u03c6, the heat transfer is found to be enhanced by up to 2.8 times that in an equivalent flat-plate channel.",
            "contribution_ids": [
                "R27408"
            ]
        },
        {
            "instance_id": "R27620xR27505",
            "comparison_id": "R27620",
            "paper_id": "R27505",
            "text": "An investigation of cointegration and causality between energy consumption and economic growth this paper reexamines the causality between energy consumption and economic growth with both bivariate and multivariate models by applying the recently developed methods of cointegration and hsiao`s version of the granger causality to transformed u.s. data for the period 1947-1990. the phillips-perron (pp) tests reveal that the original series are not stationary and, therefore, a first differencing is performed to secure stationarity. the study finds no causal linkages between energy consumption and economic growth. energy and gross national product (gnp) each live a life of its own. the results of this article are consistent with some of the past studies that find no relationship between energy and gnp but are contrary to some other studies that find gnp unidirectionally causes energy consumption. both the bivariate and trivariate models produce the similar results. we also find that there is no causal relationship between energy consumption and industrial production. the united states is basically a service-oriented economy and changes in energy consumption can cause little or no changes in gnp. in other words, an implementation of energy conservation policy may not impair economic growth. 27 refs., 5 tabs.",
            "contribution_ids": [
                "R27506"
            ]
        },
        {
            "instance_id": "R27705xR27690",
            "comparison_id": "R27705",
            "paper_id": "R27690",
            "text": "Co-integration and causality relationship between energy consumption and economic growth: further empirical evidence for Nigeria the paper re - examined co\u2010integration and causality relationship between energy consumption and economic growth for nigeria using data covering the period 1970 to 2005. unlike previous related study for nigeria, different proxies of energy consumption (electricity demand, domestic crude oil consumption and gas utilization) were used for the estimation. it also included government activities proxied by health expenditure and monetary policy proxied by broad money supply though; emphasis was on energy consumption. using the johansen co\u2010integration technique, it was found that there existed a long run relationship among the series. it was also found that all the variables used for the study were i(1). furthermore, unidirectional causality was established between electricity consumption and economic growth, domestic crude oil production and economic growth as well as between gas utilization and economic growth in nigeria. while causality runs from electricity consumption to economic growth as well as from gas utilization to economic growth, it was found that causality runs from economic growth to domestic crude oil production. therefore, conservation policy regarding electricity consumption and gas utilization would harm economic growth in nigeria while energy conservation policy as regards domestic crude oil consumption would not. santrauka tyrinejamas energijos suvartojimo ir ekonominio augimo tarpusavio ry\u0161ys bei prie\u017eastingumas ni\u2010gerijoje, remiantis 1970\u20132005 m. statistiniais duomenimis. naujai, lyginant su ankstesniais nigerijos tyrimais, parenkami energijos vartojimo matavimo b\u016bdai (elektros energijos paklausa, vietines naftos \u017ealiavos suvartojimas, duju utilizavimas). straipsnyje atsi\u017evelgiama i socialine ir monetarine valstybes politika, kurios atspindi valstybes gerove. pritaikius johansen tarpusavio priklausomybes metodabuvo gauta, kad tarp visu energijos vartojima atspindin\u010diu rodikliu ir ekonominio augimo yra netiesioginis prie\u017eastinis ry\u0161ys. manoma, kad elektros bei dujunaudojimo apribojimas stabdytu nigerijos ekonomini augima, o naftos \u017ealiavos vartojimo masto ma\u017einimas nepaveiktu tolesnes \u0161alies pletros.",
            "contribution_ids": [
                "R27691"
            ]
        },
        {
            "instance_id": "R27705xR27685",
            "comparison_id": "R27705",
            "paper_id": "R27685",
            "text": "Structural breaks, electricity consumption and economic growth: evidence from Turkey this study examines the causal relationship between electricity consumption and economic growth for ghana during the period 1970 to 2010. the study employed unit root and cointegration tests taking into account structural breaks. the following findings were made: first, a plot of the series indicated a trend pattern. the series also experienced structural breaks in 1979 and 1983 but after taking structural breaks into account they became stationary. second, the series exhibited one cointegration vector implying a long\u2013run relationship between them. third, the results revealed the presence of unidirectional granger causality running from economic growth to electricity consumption. in general, the study identified the presence of structural break dates which corresponded with the critical economic events in ghana. \\n \\n \\xa0 \\n \\n key\\xa0words:\\xa0electricity consumption, economic growth, structural break, vector error correction mode (vecm), causality.",
            "contribution_ids": [
                "R27686"
            ]
        },
        {
            "instance_id": "R27705xR27638",
            "comparison_id": "R27705",
            "paper_id": "R27638",
            "text": "Electricity consumption and economic growth: evidence from Korea th e paper investigates the relationship between electricity consumption and economic growth in poland for the period 2000 to 2012. understanding the behavior of electricity consumption in relation to the economy is very important for improve a stable economic growth and development. th e obtained results indicate that there is the causal relationship between electricity consumption and economic growth in poland and the relationship is bi-directional. we also discovered the bi-directional causality between capital and economic growth. on the basis of the causality results we estimated a one-sector aggregate production function, where the electricity consumption was one of the input variables. th e evaluated growth model showed that electricity consumption is a pro-growth variable, so the results indicate that economic growth of poland is electricity-dependent. th at\u2019s allows to state that electricity is a limiting factor to economic growth of poland.",
            "contribution_ids": [
                "R27639"
            ]
        },
        {
            "instance_id": "R27835xR27748",
            "comparison_id": "R27835",
            "paper_id": "R27748",
            "text": "Effect of computer-based video games on children: An experimental study \"this experimental study investigated whether computer-based video games facilitate children's cognitive learning. in comparison to traditional computer-assisted instruction (cai), this study explored the impact of the varied types of instructional delivery strategies on children's learning achievement. one major research null hypothesis was tested: no statistically significant differences in students' achievement when they receive two different instructional treatments: (1) traditional cai; and (2) a computer-based video game. one hundred and eight third-graders from a middle/high socio-economic standard school district in taiwan participated in the study. results indicate that computer-based video game playing not only improves participants' fact/recall processes (f=5.288, p<;.05), but also promotes problem-solving skills by recognizing multiple solutions for problems (f=5.656, p<;.05).\"",
            "contribution_ids": [
                "R27749"
            ]
        },
        {
            "instance_id": "R27835xR27735",
            "comparison_id": "R27835",
            "paper_id": "R27735",
            "text": "A video game improves behavioral outcomes in adolescents and young adults with cancer: A randomized trial objective. suboptimal adherence to self-administered medications is a common problem. the purpose of this study was to determine the effectiveness of a video-game intervention for improving adherence and other behavioral outcomes for adolescents and young adults with malignancies including acute leukemia, lymphoma, and soft-tissue sarcoma. \\n methods. a randomized trial with baseline and 1- and 3-month assessments was conducted from 2004 to 2005 at 34 medical centers in the united states, canada, and australia. a total of 375 male and female patients who were 13 to 29 years old, had an initial or relapse diagnosis of a malignancy, and currently undergoing treatment and expected to continue treatment for at least 4 months from baseline assessment were randomly assigned to the intervention or control group. the intervention was a video game that addressed issues of cancer treatment and care for teenagers and young adults. outcome measures included adherence, self-efficacy, knowledge, control, stress, and quality of life. for patients who were prescribed prophylactic antibiotics, adherence to trimethoprim-sulfamethoxazole was tracked by electronic pill-monitoring devices (n = 200). adherence to 6-mercaptopurine was assessed through serum metabolite assays (n = 54). \\n results. adherence to trimethoprim-sulfamethoxazole and 6-mercaptopurine was greater in the intervention group. self-efficacy and knowledge also increased in the intervention group compared with the control group. the intervention did not affect self-report measures of adherence, stress, control, or quality of life. \\n conclusions. the video-game intervention significantly improved treatment adherence and indicators of cancer-related self-efficacy and knowledge in adolescents and young adults who were undergoing cancer therapy. the findings support current efforts to develop effective video-game interventions for education and training in health care.",
            "contribution_ids": [
                "R27736"
            ]
        },
        {
            "instance_id": "R27835xR27810",
            "comparison_id": "R27835",
            "paper_id": "R27810",
            "text": "Developing and evaluating dialogue games for collaborative e-learning \"this paper argues that developments in collaborative e-learning dialogue should be based on pedagogically sound principles of discourse, and therefore, by implication, there is a need to develop methodologies which transpose \u2014 typically informal \u2014 models of educational dialogue into cognitive tools that are suitable for students. a methodology of 'investigation by design' is described which has been used to design computer-based dialogue games supporting conceptual change and development in science \u2014 based on the findings of empirical studies. an evaluation of two dialogue games for collaborative interaction, a facilitating game and an elicit-inform game, has shown that they produce significant improvements in students conceptual understanding, and they are differentially successful \u2014 depending on the nature of the conceptual difficulties experienced by the learners. the implications this study has for the role of collaborative dialogue in learning and designing computer- based and computer-mediated collaborative interaction are discussed.\"",
            "contribution_ids": [
                "R27811"
            ]
        },
        {
            "instance_id": "R27835xR27774",
            "comparison_id": "R27835",
            "paper_id": "R27774",
            "text": "Deal or No Deal: using games to improve student learning, retention and decision-making \"student understanding and retention can be enhanced and improved by providing alternative learning activities and environments. education theory recognizes the value of incorporating alternative activities (games, exercises and simulations) to stimulate student interest in the educational environment, enhance transfer of knowledge and improve learned retention with meaningful repetition. in this case study, we investigate using an online version of the television game show, \u2018deal or no deal\u2019, to enhance student understanding and retention by playing the game to learn expected value in an introductory statistics course, and to foster development of critical thinking skills necessary to succeed in the modern business environment. enhancing the thinking process of problem solving using repetitive games should also improve a student's ability to follow non-mathematical problem-solving processes, which should improve the overall ability to process information and make logical decisions. learning and retention are measured to evaluate the success of the students\u2019 performance.\"",
            "contribution_ids": [
                "R27775"
            ]
        },
        {
            "instance_id": "R27835xR27743",
            "comparison_id": "R27835",
            "paper_id": "R27743",
            "text": "Experimental Validation of the Learning Effect for a Pedagogical Game on Computer Fundamentals the question/answer-based computer game age of computers was introduced to replace traditional weekly paper exercises in a course in computer fundamentals in 2003. questionnaire evaluations and observation of student behavior have indicated that the students found the game more motivating than paper exercises and that a majority of the students also perceived the game to have a higher learning effect than paper exercises or textbook reading. this paper reports on a controlled experiment to compare the learning effectiveness of game play with traditional paper exercises, as well as with textbook reading. the results indicated that with equal time being spent on the various learning activities, the effect of game play was only equal to that of the other activities, not better. yet this result is promising enough, as the increased motivation means that students work harder in the course. also, the results indicate that the game has potential for improvement, in particular with respect to its feedback on the more complicated questions.",
            "contribution_ids": [
                "R27744"
            ]
        },
        {
            "instance_id": "R27835xR27777",
            "comparison_id": "R27835",
            "paper_id": "R27777",
            "text": "Computer games for the math achievement of diverse students \"introduction as a way to improve student academic performance, educators have begun paying special attention to computer games (gee, 2005; oblinger, 2006). reflecting the interests of the educators, studies have been conducted to explore the effects of computer games on student achievement. however, there has been no consensus on the effects of computer games: some studies support computer games as educational resources to promote students' learning (annetta, mangrum, holmes, collazo, & cheng, 2009; vogel et al., 2006). other studies have found no significant effects on the students' performance in school, especially in math achievement of elementary school students (ke, 2008). researchers have also been interested in the differential effects of computer games between gender groups. while several studies have reported various gender differences in the preferences of computer games (agosto, 2004; kinzie & joseph, 2008), a few studies have indicated no significant differential effect of computer games between genders and asserted generic benefits for both genders (vogel et al., 2006). to date, the studies examining computer games and gender interaction are far from conclusive. moreover, there is a lack of empirical studies examining the differential effects of computer games on the academic performance of diverse learners. these learners included linguistic minority students who speak languages other than english. recent trends in the k-12 population feature the increasing enrollment of linguistic minority students, whose population reached almost four million (nces, 2004). these students have been a grieve concern for american educators because of their reported low performance. in response, this study empirically examined the effects of math computer games on the math performance of 4th-graders with focused attention on differential effects for gender and linguistic groups. to achieve greater generalizability of the study findings, the study utilized a us nationally representative database--the 2005 national assessment of educational progress (naep). the following research questions guided the current study: 1. are computer games in math classes associated with the 4th-grade students' math performance? 2. how does the relationship differ by linguistic group? 3. how does the association vary by gender? 4. is there an interaction effect of computer games on linguistic and gender groups? in other words, how does the effect of computer games on linguistic groups vary by gender group? literature review academic performance and computer games according debell and chapman (2004), of 58,273,000 students of nursery and k-12 school age in the usa, 56% of students played computer games. along with the popularity among students, computer games have received a lot of attention from educators as a potential way to provide learners with effective and fun learning environments (oblinger, 2006). gee (2005) agreed that a game would turn out to be good for learning when the game is built to incorporate learning principles. some researchers have also supported the potential of games for affective domains of learning and fostering a positive attitude towards learning (ke, 2008; ke & grabowski, 2007; vogel et al., 2006). for example, based on the study conducted on 1,274 1st- and 2nd-graders, rosas et al. (2003) found a positive effect of educational games on the motivation of students. although there is overall support for the idea that games have a positive effect on affective aspects of learning, there have been mixed research results regarding the role of games in promoting cognitive gains and academic achievement. in the meta-analysis, vogel et al. (2006) examined 32 empirical studies and concluded that the inclusion of games for students' learning resulted in significantly higher cognitive gains compared with traditional teaching methods without games. \u2026\"",
            "contribution_ids": [
                "R27778"
            ]
        },
        {
            "instance_id": "R27835xR27804",
            "comparison_id": "R27835",
            "paper_id": "R27804",
            "text": "Outdoor natural science learning with an RFID-supported immersive ubiquitous learning environment despite their successful use in many conscientious studies involving outdoor learning applications, mobile learning systems still have certain limitations. for instance, because students cannot obtain real-time, contextaware content in outdoor locations such as historical sites, endangered animal habitats, and geological landscapes, they are unable to search, collect, share, and edit information by using information technology. to address such concerns, this work proposes an environment of ubiquitous learning with educational resources (euler) based on radio frequency identification (rfid), augmented reality (ar), the internet, ubiquitous computing, embedded systems, and database technologies. euler helps teachers deliver lessons on site and cultivate student competency in adopting information technology to improve learning. to evaluate its effectiveness, we used the proposed euler for natural science learning at the guandu nature park in taiwan. the participants were elementary school teachers and students. the analytical results revealed that the proposed euler improves student learning. moreover, the largely positive feedback from a post-study survey confirms the effectiveness of euler in supporting outdoor learning and its ability to attract the interest of students.",
            "contribution_ids": [
                "R27805"
            ]
        },
        {
            "instance_id": "R27835xR27829",
            "comparison_id": "R27835",
            "paper_id": "R27829",
            "text": "Surgical experience correlates with performance on a virtual reality simulator for shoulder arthroscopy background the traditional process of surgical education is being increasingly challenged by economic constraints and concerns about patient safety. sophisticated computer-based devices have become available to simulate the surgical experience in a protected environment. as with any new educational tool, these devices have generated controversy about the validity of the training experience. hypothesis performance on a virtual reality simulator correlates with actual surgical experience. study design controlled laboratory study. methods forty-three test subjects of various experience levels in shoulder arthroscopy were tested on an arthroscopy simulator according to a standardized protocol. subjects were evaluated for time to completion, distance traveled with the tip of the simulated probe compared with a computer-determined optimal distance, average probe velocity, and number of probe collisions with the tissues. results subjects were grouped according to prior experience with shoulder arthroscopy. comparing the least experienced with most experienced groups, the average time to completion decreased by 62% from 128.8 seconds to 49.2 seconds; path length and hook collisions were more than halved from 8.2 to 3.8 and 34.1 to 16.8, respectively; and average probe velocity more than doubled from 0.18 to 0.4 cm/second. there were no significant differences for any parameter tested between subjects with video game experience compared to those without. conclusions the study demonstrated a close and statistically significant correlation between simulator results and surgical experience, thus confirming the hypothesis. conversely, experience with video games was not associated with improved simulator performance. this indicates that the skill set tested may be similar to the one developed in the operating room, thus suggesting its use as a potential tool for future evaluation of surgical trainees. clinical relevance the results have implications for the future of orthopaedic surgical training programs, the majority of which have not embraced virtual reality technology for physician education.",
            "contribution_ids": [
                "R27830"
            ]
        },
        {
            "instance_id": "R27835xR27831",
            "comparison_id": "R27835",
            "paper_id": "R27831",
            "text": "Individual Skill Progression on a Virtual Reality Simulator for Shoulder Arthroscopy A 3-Year Follow-up Study background previous studies have demonstrated a correlation between surgical experience and performance on a virtual reality arthroscopy simulator but only provided single time point evaluations. additional longitudinal studies are necessary to confirm the validity of virtual reality simulation before these teaching aids can be more fully recommended for surgical education. hypothesis subjects will show improved performance on simulator retesting several years after an initial baseline evaluation, commensurate with their advanced surgical experience. study design controlled laboratory study. methods after gaining further arthroscopic experience, 10 orthopaedic residents underwent retesting 3 years after initial evaluation on a procedicus virtual reality arthroscopy simulator. using a paired t test, simulator parameters were compared in each subject before and after additional arthroscopic experience. subjects were evaluated for time to completion, number of probe collisions with the tissues, average probe velocity, and distance traveled with the tip of the simulated probe compared to an optimal computer-determined distance. in addition, to evaluate consistency of simulator performance, results were compared to historical controls of equal experience. results subjects improved significantly ( p &lt; .02 for all) in the 4 simulator parameters: completion time (\u221251 %), probe collisions (\u221229%), average velocity (+122%), and distance traveled (\u2212;32%). with the exception of probe velocity, there were no significant differences between the performance of this group and that of a historical group with equal experience, indicating that groups with similar arthroscopic experience consistently demonstrate equivalent scores on the simulator. conclusion subjects significantly improved their performance on simulator retesting 3 years after initial evaluation. additionally, across independent groups with equivalent surgical experience, similar performance can be expected on simulator parameters; thus it may eventually be possible to establish simulator benchmarks to indicate likely arthroscopic skill. clinical relevance these results further validate the use of surgical simulation as an important tool for the evaluation of surgical skills.",
            "contribution_ids": [
                "R27832"
            ]
        },
        {
            "instance_id": "R27835xR27815",
            "comparison_id": "R27835",
            "paper_id": "R27815",
            "text": "Idea Storming Cube: A Game-based System to Support Creative Thinking this paper describes a collaborative game-based creativity support system, idea storming cube, in support of creative thinking. it aims to make people form a creative and perspective-shift thinking habit. the system acquires knowledge from domain expert, user inputs history, and individuals in the current brainstorming group, and then provides user-, goal- and context-sensitive supports. comparing to classic tutoring systems, it focuses more on stimulating divergent thinking. the system can be put into the basic mode or the idea generation mode in order to support different gaming objectives. a case study for preliminary evaluation of the proposed hci tool for collaborative idea generation is also reported in this paper.",
            "contribution_ids": [
                "R27816"
            ]
        },
        {
            "instance_id": "R27835xR27767",
            "comparison_id": "R27835",
            "paper_id": "R27767",
            "text": "What Do Students Learn When Collaboratively Using A Computer Game in the Study of Historical Disease Epidemics, and Why? the use of computer games and virtual environments has been shown to engage and motivate students and can provide opportunities to visualize the historical period and make sense of complex visual information. this article presents the results of a study in which university students were asked to collaboratively solve inquiry-based problems related to historical disease epidemics using game-based learning. a multimethod approach to the data collection was used. initial results indicated that students attended to visual information with more specificity than text-based information when using a virtual environment. models of student\u2019s decision-making processes when interacting with the world confirmed that students were making decisions related to these visual elements, and not the inquiry process. building on theories from the learning sciences, such as learning from animations/visualizations and computer-supported collaborative learning, in this article, the authors begin to answer the question of why students learned what they did about historical disease epidemics.",
            "contribution_ids": [
                "R27768"
            ]
        },
        {
            "instance_id": "R27835xR27808",
            "comparison_id": "R27835",
            "paper_id": "R27808",
            "text": "The application of an occupational therapy nutrition education programme for children who are obese the aim of this study was to evaluate an occupational therapy nutrition education programme for children who are obese with the use of two interactive games. a quasi-experimental study was carried out at a municipal school in fortaleza, brazil. a convenient sample of 200 children ages 8-10 years old participated in the study. data collection comprised a semi-structured interview, direct and structured observation, and focus group, comparing two interactive games based on the food pyramid (video game and board game) used individually and then combined. both play activities were efficient in the mediation of nutritional concepts, with a preference for the board game. in the learning strategies, intrinsic motivation and metacognition were analysed. the attention strategy was most applied at the video game. we concluded that both games promoted the learning of nutritional concepts. we confirmed the effectiveness of the simultaneous application of interactive games in an interdisciplinary health environment. it is recommended that a larger sample should be used in evaluating the effectiveness of play and video games in teaching healthy nutrition to children in a school setting.",
            "contribution_ids": [
                "R27809"
            ]
        },
        {
            "instance_id": "R27835xR27788",
            "comparison_id": "R27835",
            "paper_id": "R27788",
            "text": "My-Mini-Pet: a handheld pet-nurturing game to engage students in arithmetic practices in the last decade, more and more games have been developed for handheld devices. furthermore, the popularity of handheld devices and increase of wireless computing can be taken advantage of to provide students with more learning opportunities. games also could bring promising benefits \u2010 specifically, motivating students to learn/play, sustaining their interest, reflectingtheirlearning/playingstatus,andfacilitatingthelearning/playingprogress.however, most of these have been designed for entertainment rather than education. hence, in this study weincorporategameelementsintoalearningenvironment.themy-mini-petsystemisahandheldpet-nurturinggameenvironment,inwhichstudentslearnwithananimallearningcompanion, their my-mini-pet. three design strategies are adopted. first, the pet-nurturing strategy, which simulates the relationship between the pet and its owner, the my-mini-pet becomes a motivator/sustainer of learning. second, the pet appearance-changing strategy, which externalizesthelearningstatusofthestudent.inotherwords,themy-mini-petplaystheroleofareflector. third, the pet feedback strategy, which links the behaviours of the student and his/her pet, the my-mini-pet acts as a facilitator of learning. a pilot study was also conducted to preliminarily investigate the effectiveness and experiences of the strategies on allowing the student to understand arithmetic practices. the results showed that the strategy was effective, encouraging the students to engage in learning activities. furthermore, the game attracted the students\u2019 attention and stimulated discussion between peers. some implications about the further developments are also discussed.",
            "contribution_ids": [
                "R27789"
            ]
        },
        {
            "instance_id": "R27835xR27819",
            "comparison_id": "R27835",
            "paper_id": "R27819",
            "text": "Collaborative Game\u00e2\u0080\u0090play as a Site for Participation and Situated Learning of a Second Language this paper addresses additional language learning as rooted in participation in the social activity of collaborative game\u2010play. building on a social\u2010interactional view of learning, it analyses some of the detailed practices through which players attend to a video game as the material and semiotic structure that shapes play and creates affordances for additional language learning. we describe how players engage with the language resources offered by the game, drawing on the vocabulary, constructions, prosodic features and utterances modelled on game dialogue, in building their own actions during collaborative play. with these resources, the players display their ongoing engagement with the game as well as their competences in recognising, reproducing and creatively reshaping the available linguistic resources in their own activities.",
            "contribution_ids": [
                "R27820"
            ]
        },
        {
            "instance_id": "R27835xR27764",
            "comparison_id": "R27835",
            "paper_id": "R27764",
            "text": "Mobile game-based learning in secondary education: engagement, motivation and learning in a mobile city game using mobile games in education combines situated and active learning with fun in a potentially excellent manner. the effects of a mobile city game called frequency 1550, which was developed by the waag society to help pupils in their first year of secondary education playfully acquire historical knowledge of medieval amsterdam, were investigated in terms of pupil engagement in the game, historical knowledge, and motivation for history in general and the topic of the middle ages in particular. a quasi-experimental design was used with 458 pupils from 20 classes from five schools. the pupils in 10 of the classes played the mobile history game whereas the pupils in the other 10 classes received a regular, project-based lesson series. the results showed those pupils who played the game to be engaged and to gain significantly more knowledge about medieval amsterdam than those pupils who received regular project-based instruction. no significant differences were found between the two groups with respect to motivation for history or the middle ages. the impact of location-based technology and game-based learning on pupil knowledge and motivation are discussed along with suggestions for future research.",
            "contribution_ids": [
                "R27765"
            ]
        },
        {
            "instance_id": "R28099xR27932",
            "comparison_id": "R28099",
            "paper_id": "R27932",
            "text": "Efficient hierarchical matching algorithm for processing uncalibrated stereo vision images and its hardware architecture in motion estimation, the sub-pixel matching technique involves the search of sub-sample positions as well as integer-sample positions between the image pairs, choosing the one that gives the best match. based on this idea, this work proposes an estimation algorithm, which performs a 2-d correspondence search using a hierarchical search pattern. the intermediate results are refined by 3-d cellular automata (ca). the disparity value is then defined using the distance of the matching position. therefore the proposed algorithm can process uncalibrated and non-rectified stereo image pairs, maintaining the computational load within reasonable levels. additionally, a hardware architecture of the algorithm is deployed. its performance has been evaluated on both synthetic and real self-captured image sets. its attributes, make the proposed method suitable for autonomous outdoor robotic applications.",
            "contribution_ids": [
                "R27933"
            ]
        },
        {
            "instance_id": "R28099xR27876",
            "comparison_id": "R28099",
            "paper_id": "R27876",
            "text": "Stereo matching with color-weighted correlation, hierarchical belief propagation, and occlusion handling in this paper, we formulate an algorithm for the stereo matching problem with careful handling of disparity, discontinuity and occlusion. the algorithm works with a global matching stereo model based on an energy- minimization framework. the global energy contains two terms, the data term and the smoothness term. the data term is first approximated by a color-weighted correlation, then refined in occluded and low-texture areas in a repeated application of a hierarchical loopy belief propagation algorithm. the experimental results are evaluated on the middlebury data set, showing that our algorithm is the top performer.",
            "contribution_ids": [
                "R27877"
            ]
        },
        {
            "instance_id": "R28099xR27947",
            "comparison_id": "R28099",
            "paper_id": "R27947",
            "text": "A non-local cost aggregation method for stereo matching matching cost aggregation is one of the oldest and still popular methods for stereo correspondence. while effective and efficient, cost aggregation methods typically aggregate the matching cost by summing/averaging over a user-specified, local support region. this is obviously only locally-optimal, and the computational complexity of the full-kernel implementation usually depends on the region size. in this paper, the cost aggregation problem is re-examined and a non-local solution is proposed. the matching cost values are aggregated adaptively based on pixel similarity on a tree structure derived from the stereo image pair to preserve depth edges. the nodes of this tree are all the image pixels, and the edges are all the edges between the nearest neighboring pixels. the similarity between any two pixels is decided by their shortest distance on the tree. the proposed method is non-local as every node receives supports from all other nodes on the tree. as can be expected, the proposed non-local solution outperforms all local cost aggregation methods on the standard (middlebury) benchmark. besides, it has great advantage in extremely low computational complexity: only a total of 2 addition/subtraction operations and 3 multiplication operations are required for each pixel at each disparity level. it is very close to the complexity of unnormalized box filtering using integral image which requires 6 addition/subtraction operations. unnormalized box filter is the fastest local cost aggregation method but blurs across depth edges. the proposed method was tested on a macbook air laptop computer with a 1.8 ghz intel core i7 cpu and 4 gb memory. the average runtime on the middlebury data sets is about 90 milliseconds, and is only about 1.25\u00d7 slower than unnormalized box filter. a non-local disparity refinement method is also proposed based on the non-local cost aggregation method.",
            "contribution_ids": [
                "R27948"
            ]
        },
        {
            "instance_id": "R28099xR28008",
            "comparison_id": "R28099",
            "paper_id": "R28008",
            "text": "Matching Cost Filtering for Dense Stereo Correspondence dense stereo correspondence enabling reconstruction of depth information in a scene is of great importance in the field of computer vision. recently, some local solutions based on matching cost filtering with an edge-preserving filter have been proved to be capable of achieving more accuracy than global approaches. unfortunately, the computational complexity of these algorithms is quadratically related to the window size used to aggregate the matching costs. the recent trend has been to pursue higher accuracy with greater efficiency in execution. therefore, this paper proposes a new cost-aggregation module to compute the matching responses for all the image pixels at a set of sampling points generated by a hierarchical clustering algorithm. the complexity of this implementation is linear both in the number of image pixels and the number of clusters. experimental results demonstrate that the proposed algorithm outperforms state-of-the-art local methods in terms of both accuracy and speed. moreover, performance tests indicate that parameters such as the height of the hierarchical binary tree and the spatial and range standard deviations have a significant influence on time consumption and the accuracy of disparity maps.",
            "contribution_ids": [
                "R28009"
            ]
        },
        {
            "instance_id": "R28099xR28037",
            "comparison_id": "R28099",
            "paper_id": "R28037",
            "text": "A performance and energy comparison of convolution on GPUs, FPGAs, and multicore processors recent architectural trends have focused on increased parallelism via multicore processors and increased heterogeneity via accelerator devices (e.g., graphics-processing units, field-programmable gate arrays). although these architectures have significant performance and energy potential, application designers face many device-specific challenges when choosing an appropriate accelerator or when customizing an algorithm for an accelerator. to help address this problem, in this article we thoroughly evaluate convolution, one of the most common operations in digital-signal processing, on multicores, graphics-processing units, and field-programmable gate arrays. whereas many previous application studies evaluate a specific usage of an application, this article assists designers with design space exploration for numerous use cases by analyzing effects of different input sizes, different algorithms, and different devices, while also determining pareto-optimal trade-offs between performance and energy.",
            "contribution_ids": [
                "R28038"
            ]
        },
        {
            "instance_id": "R28099xR27913",
            "comparison_id": "R28099",
            "paper_id": "R27913",
            "text": "Vision based autonomous vehicle navigation with self-organizing map feature matching technique vision is becoming more and more common in applications such as localization, autonomous navigation, path finding and many other computer vision applications. this paper presents an improved technique for feature matching in the stereo images captured by the autonomous vehicle. the scale invariant feature transform (sift) algorithm is used to extract distinctive invariant features from images but this algorithm has a high complexity and a long computational time. in order to reduce the computation time, this paper proposes a sift improvement technique based on a self-organizing map (som) to perform the matching procedure more efficiently for feature matching problems. experimental results on real stereo images show that the proposed algorithm performs feature group matching with lower computation time than the original sift algorithm. the results showing improvement over the original sift are validated through matching examples between different pairs of stereo images. the proposed algorithm can be applied to stereo vision based autonomous vehicle navigation for obstacle avoidance, as well as many other feature matching and computer vision applications.",
            "contribution_ids": [
                "R27914"
            ]
        },
        {
            "instance_id": "R28099xR28004",
            "comparison_id": "R28099",
            "paper_id": "R28004",
            "text": "Local Disparity Estimation With Three-Moded Cross Census and Advanced Support Weight the classical local disparity methods use simple and efficient structure to reduce the computation complexity. to increase the accuracy of the disparity map, new local methods utilize additional processing steps such as iteration, segmentation, calibration and propagation, similar to global methods. in this paper, we present an efficient one-pass local method with no iteration. the proposed method is also extended to video disparity estimation by using motion information as well as imposing spatial temporal consistency. in local method, the accuracy of stereo matching depends on precise similarity measure and proper support window. for the accuracy of similarity measure, we propose a novel three-moded cross census transform with a noise buffer, which increases the robustness to image noise in flat areas. the proposed similarity measure can be used in the same form in both stereo images and videos. we further improve the reliability of the aggregation by adopting the advanced support weight and incorporating motion flow to achieve better depth map near moving edges in video scene. the experimental results show that the proposed method is the best performing local method on the middlebury stereo benchmark test and outperforms the other state-of-the-art methods on video disparity evaluation.",
            "contribution_ids": [
                "R28005"
            ]
        },
        {
            "instance_id": "R28099xR27891",
            "comparison_id": "R28099",
            "paper_id": "R27891",
            "text": "Comparison of FPGA and GPU implementations of real-time stereo vision real-time stereo vision systems have many applications - from autonomous navigation for vehicles through surveillance to materials handling. accurate scene interpretation depends on an ability to process high resolution images in real-time, but, although the calculations for stereo matching are basically simple, a practical system needs to evaluate at least 109 disparities every second - beyond the capability of a single processor. stereo correspondence algorithms have high degrees of inherent parallelism and are thus good candidates for parallel implementations. in this paper, we compare the performance obtainable with an fpga and a gpu to understand the trade-off between the flexibility but relatively low speed of an fpga and the high speed and fixed architecture of the gpu. our comparison highlights the relative strengths and limitations of the two systems. our experiments show that, for a range of image sizes, the gpu manages 2 \u00d7 109 disparities per second, compared with 2\u22366 \u00d7 109 disparities per second for an fpga.",
            "contribution_ids": [
                "R27892"
            ]
        },
        {
            "instance_id": "R28099xR27896",
            "comparison_id": "R28099",
            "paper_id": "R27896",
            "text": "Real-time disparity estimation algorithm for stereo camera systems this paper proposes a real-time stereo matching algorithm using gpu programming. the likelihood model is implemented using gpu programming for real-time operation. and the prior model is proposed to improve the accuracy of disparity estimation. first, the likelihood matching based on rank transform is implemented in gpu programming. the shared memory handling in graphic hardware is introduced in calculating the likelihood model. the prior model considers the smoothness of disparity map and is defined as a pixel-wise energy function using adaptive interaction among neighboring disparities. the disparity is determined by minimizing the joint energy function which combines the likelihood model with prior model. these processes are performed in the multi-resolution approach. the disparity map is interpolated using the reliability of likelihood model and color-based similarity in the neighborhood. this paper evaluates the proposed approach with the middlebury stereo images. according to the experiments, the proposed algorithm shows good estimation accuracy over 30 frames/second for 640\u00d7480 image and 60 disparity range. the proposed disparity estimation algorithm is applied to real-time stereo camera system such as 3-d image display, depth-based object extraction, 3-d rendering, and so on.",
            "contribution_ids": [
                "R27897"
            ]
        },
        {
            "instance_id": "R28099xR27920",
            "comparison_id": "R28099",
            "paper_id": "R27920",
            "text": "Dense Disparity Real-Time Stereo Vision Algorithm for Resource-Limited Systems \"it is evident that the accuracy of stereo vision algorithms has continued to increase based on commonly used quantitative evaluations of the resulting disparity maps. this paper focuses on the development of promising stereo vision algorithms that efficiently tradeoff accuracy for large reductions in required computational resources. an intensity profile shape-matching algorithm is introduced as an example of an algorithm that makes such tradeoffs. the proposed algorithm is compared to both a basic sum-of-absolute-differences (sad) block-matching algorithm, as well as a stereo vision algorithm that is highly ranked for its accuracy based on the middlebury evaluation criteria. this comparison shows that the proposed algorithm's accuracy on the commonly used tsukuba stereo image pair is lower than many published stereo vision algorithms, but that for unrectified stereo image pairs that have even the slightest differences in brightness, it is potentially more robust than algorithms that rely on sad block matching. an example application that requires 3-d information is implemented to show that the accuracy of the proposed algorithm is sufficient for this use. timing results show that this is a very fast dense-disparity stereo vision algorithm when compared to other algorithms capable of running on a standard microprocessor.\"",
            "contribution_ids": [
                "R27921"
            ]
        },
        {
            "instance_id": "R28099xR27975",
            "comparison_id": "R28099",
            "paper_id": "R27975",
            "text": "Effective stereo matching using reliable points based graph cut in this paper, we propose an effective stereo matching algorithm using reliable points and region-based graph cut. firstly, the initial disparity maps are calculated via local windowbased method. secondly, the unreliable points are detected according to the dsi(disparity space image) and the estimated disparity values of each unreliable point are obtained by considering its surrounding points. then, the scheme of reliable points is introduced in region-based graph cut framework to optimize the initial result. finally, remaining errors in the disparity results are effectively handled in a multi-step refinement process. experiment results show that the proposed algorithm achieves a significant reduction in computation cost and guarantee high matching quality.",
            "contribution_ids": [
                "R27976"
            ]
        },
        {
            "instance_id": "R28099xR28030",
            "comparison_id": "R28099",
            "paper_id": "R28030",
            "text": "Stereo Vision Algorithms for FPGAs in recent years, with the advent of cheap and accurate rgbd (rgb plus depth) active sensors like the microsoft kinect and devices based on time-of-flight (tof) technology, there has been increasing interest in 3d-based applications. at the same time, several effective improvements to passive stereo vision algorithms have been proposed in the literature. despite these facts and the frequent deployment of stereo vision for many research activities, it is often perceived as a bulky and expensive technology not well suited to consumer applications. in this paper, we will review a subset of state-of-the-art stereo vision algorithms that have the potential to fit a target computing architecture based on low-cost field-programmable gate arrays (fpgas), without additional external devices (e.g., fifos, ddr memories, etc.). mapping these algorithms into a similar low-power, low-cost architecture would make rgbd sensors based on stereo vision suitable to a wider class of application scenarios currently not addressed by this technology.",
            "contribution_ids": [
                "R28031"
            ]
        },
        {
            "instance_id": "R28099xR28041",
            "comparison_id": "R28099",
            "paper_id": "R28041",
            "text": "Real-time high-quality stereo vision system in FPGA stereo vision is a well-known technique for acquiring depth information. in this paper, we propose a real-time high-quality stereo vision system in field-programmable gate array (fpga). using absolute difference-census cost initialization, cross-based cost aggregation, and semiglobal optimization, the system provides high-quality depth results for high-definition images. this is the first complete real-time hardware system that supports both cost aggregation on variable support regions and semiglobal optimization in fpgas. furthermore, the system is designed to be scaled with image resolution, disparity range, and parallelism degree for maximum parallel efficiency. we present the depth map quality on the middlebury benchmark and some real-world scenarios with different image resolutions. the results show that our system performs the best among fpga-based stereo vision systems and its accuracy is comparable with those of current top-performing software implementations. the first version of the system was demonstrated on an altera stratix-iv fpga board, processing 1024 \u00d7 768 pixel images with 96 disparity levels at 67 frames/s. the system is then scaled up on a new altera stratix-v fpga and the processing ability is enhanced to 1600 \u00d7 1200 pixel images with 128 disparity levels at 42 frames/s.",
            "contribution_ids": [
                "R28042"
            ]
        },
        {
            "instance_id": "R28099xR27960",
            "comparison_id": "R28099",
            "paper_id": "R27960",
            "text": "Efficient Disparity Estimation Using Hierarchical Bilateral Disparity Structure Based Graph Cut Algorithm With a Foreground Boundary Refinement Mechanism the disparity estimation problem is commonly solved using graph cut (gc) methods, in which the disparity assignment problem is transformed to one of minimizing global energy function. although such an approach yields an accurate disparity map, the computational cost is relatively high. accordingly, this paper proposes a hierarchical bilateral disparity structure (hbds) algorithm in which the efficiency of the gc method is improved without any loss in the disparity estimation performance by dividing all the disparity levels within the stereo image hierarchically into a series of bilateral disparity structures of increasing fineness. to address the well-known foreground fattening effect, a disparity refinement process is proposed comprising a fattening foreground region detection procedure followed by a disparity recovery process. the efficiency and accuracy of the hbds-based gc algorithm are compared with those of the conventional gc method using benchmark stereo images selected from the middlebury dataset. in addition, the general applicability of the proposed approach is demonstrated using several real-world stereo images.",
            "contribution_ids": [
                "R27961"
            ]
        },
        {
            "instance_id": "R28099xR27862",
            "comparison_id": "R28099",
            "paper_id": "R27862",
            "text": "Region-based dense depth extraction from multi-view video a novel multi-view region-based dense depth map estimation problem is presented, based on a modified plane-sweeping strategy. in this approach, the whole scene is assumed to be region-wise planar. these planar regions are defined by back-projections of the over-segmented homogenous color regions on the images and the plane parameters are determined by angle-sweeping at different depth levels. the position and rotation of the plane patches are estimated robustly by minimizing a segment-based cost function, which considers occlusions, as well. the quality of depth map estimates is measured via reconstruction quality of the conjugate views, after warping segments into these views by the resulting homographies. finally, a greedy-search algorithm is applied to refine the reconstruction quality and update the plane equations with visibility constraint. based on the simulation results, it is observed that the proposed algorithm handles large un-textured regions, depth discontinuities at object boundaries, slanted surfaces, as well as occlusions.",
            "contribution_ids": [
                "R27863"
            ]
        },
        {
            "instance_id": "R28099xR28097",
            "comparison_id": "R28099",
            "paper_id": "R28097",
            "text": "A fast trilateral filterbased adaptive support weight method for stereo matching adaptive support weight (asw) approach represents the state-of-the-art local stereo matching method. recent extensive evaluation studies on asw approaches show that the bilateral filter weight function enables outstanding performance on a large dataset in comparison with various weight functions. however, it does not resolve the ambiguity induced by nearby pixels at different disparities but with similar colors. in this paper, we propose a novel trilateral filter based asw method which remedies such ambiguities by considering disparity discontinuities through color discontinuity boundaries, i.e., the strength of the boundary between two pixels. the experimental evaluation on the middlebury benchmark shows that the proposed algorithm ranks 15th out of 150 submissions and is the current most accurate local stereo matching algorithm.",
            "contribution_ids": [
                "R28098"
            ]
        },
        {
            "instance_id": "R28099xR28059",
            "comparison_id": "R28099",
            "paper_id": "R28059",
            "text": "Fast and Accurate Stereo Vision System on FPGA in this article, we present a fast and high quality stereo matching algorithm on fpga using cost aggregation (ca) and fast locally consistent (flc) dense stereo. in many software programs, global matching algorithms are used in order to obtain accurate disparity maps. although their error rates are considerably low, their processing speeds are far from that required for real-time processing because of their complex processing sequences. in order to realize real-time processing, many hardware systems have been proposed to date. they have achieved considerably high processing speeds; however, their error rates are not as good as those of software programs, because simple local matching algorithms have been widely used in those systems. in our system, sophisticated local matching algorithms (ca and flc) that are suitable for fpga implementation are used to achieve low error rate while maintaining the high processing speed. we evaluate the performance of our circuit on xilinx vertex-6 fpgas. its error rate is comparable to that of top-level software algorithms, and its processing speed is nearly 2 clock cycles per pixel, which reaches 507.9 fps for 640 480 pixel images.",
            "contribution_ids": [
                "R28060"
            ]
        },
        {
            "instance_id": "R28099xR28074",
            "comparison_id": "R28099",
            "paper_id": "R28074",
            "text": "Hardware implementation of a full HD real-time disparity estimation algorithm disparity estimation is a common task in stereo vision and usually requires a high computational effort. high resolution disparity maps are necessary to provide a good image quality on autostereoscopic displays which deliver stereo content without the need for 3d glasses. in this paper, an fpga architecture for a disparity estimation algorithm is proposed, that is capable of processing high-definition content in real-time. the resulting architecture is efficient in terms of power consumption and can be easily scaled to support higher resolutions.",
            "contribution_ids": [
                "R28075"
            ]
        },
        {
            "instance_id": "R28099xR27957",
            "comparison_id": "R28099",
            "paper_id": "R27957",
            "text": "Reducing computation complexity for disparity matching to facilitate the realization of free-viewpoint 3d video systems, disparity matching and view synthesis are two of the most significant operations. however, disparity matching demands high computation complexity which motivates the development of the proposed techniques. in this paper, we propose a shape-adaptive low-complexity (salc) technique to remove computation redundancy between stereo image pairs for disparity matching. the novel idea takes advantage of that depth values of pixels inside the same object are either the same or gracefully changed, which implies that the operations of depth map generation may be reused, and are not necessarily computed pixel by pixel as conventional works did. instead, the pixels with the same depth value should be treated as a group which becomes the basic unit in computing disparity matching. meanwhile, the matching accuracy of stereo matching has been obviously improved by using searching blocks with shape information. from the experimental results, the proposed salc technique accelerates the disparity matching for more than 26 times as well as improves quality of resulted depth maps with a 71.69% of bad pixel reduction compared with the conventional pixel-by-pixel disparity estimation.",
            "contribution_ids": [
                "R27958"
            ]
        },
        {
            "instance_id": "R28099xR27843",
            "comparison_id": "R28099",
            "paper_id": "R27843",
            "text": "Segmentation based disparity estimation using color and depth information the well-known cooperative stereo uses two dimensional rectangular window for a local block matching, and three dimensional box-shaped volume for a global optimization procedure. in many cases, appropriate selections of these matching regions can provide satisfactory matching results. this paper presents a new method for iteratively modifying sizes and shapes of matching regions based on color and depth information. this algorithm computes the aggregated matching costs with two ideas. the first idea is to select matching regions based on object boundaries to avoid projective distortion. this provides the reliable matching scores as well as the prevention of the foreground fattening phenomenon. the second idea is to iteratively modify the segmentation map by merging the regions where the disparities are likely to be the same. experimental results show that the proposed algorithm provides more accurate disparity map than other algorithms. especially, the computed disparity map shows the advantage of our algorithm in disparity discontinuity regions.",
            "contribution_ids": [
                "R27844",
                "R28061"
            ]
        },
        {
            "instance_id": "R28099xR27936",
            "comparison_id": "R28099",
            "paper_id": "R27936",
            "text": "Multiresolution energy minimisation framework for stereo matching \"global optimisation algorithms for stereo dense depth map estimation have demonstrated how to outperform other stereo algorithms such as local methods or dynamic programming. the energy minimisation framework, using markov random fields model and solved using graph cuts or belief propagation, has especially obtained good results. the main drawback of these methods is that, although they achieve accurate reconstruction, they are not suited for real-time applications. subsampling the input images does not reduce the complexity of the problem because it also reduces the resolution of the output in the disparity space. nonetheless, some real-time applications such as navigation would tolerate the reduction of the depth map resolutions (width and height) while maintaining the resolution in the disparity space (number of labels). in this study a new multiresolution energy minimisation framework for real-time robotics applications is proposed where a global optimisation algorithm is applied. a reduction by a factor r of the final depth map's resolution is considered and a speed of up to 50 times has been achieved. using high-resolution stereo pair input images guarantees that a high resolution on the disparity dimension is preserved. the proposed framework has shown how to obtain real-time performance while keeping accurate results in the middlebury test data set.\"",
            "contribution_ids": [
                "R27937"
            ]
        },
        {
            "instance_id": "R28099xR27857",
            "comparison_id": "R28099",
            "paper_id": "R27857",
            "text": "Adaptive support-weight approach for correspondence search in this paper, we present a new area-based method for visual correspondence search that focuses on the dissimilarity computation. local and area-based matching methods generally measure the similarity (or dissimilarity) between the image pixels using local support windows. in this approach, an appropriate support window should be selected adaptively for each pixel to make the measure reliable and certain. finding the optimal support window with an arbitrary shape and size is, however, very difficult and generally known as an np-hard problem. for this reason, unlike the existing methods that try to find an optimal support window, we adjusted the support-weight of each pixel in a given support window. the adaptive support-weight of a pixel is computed based on the photometric and geometric relationship with the pixel under consideration. dissimilarity is then computed using the raw matching costs and support-weights of both support windows, and the correspondence is finally selected by the wta (winner-takes-all) method. the experimental results for the rectified real images show that the proposed method successfully produces piecewise smooth disparity maps while preserving sharp depth discontinuities accurately.",
            "contribution_ids": [
                "R27858"
            ]
        },
        {
            "instance_id": "R28099xR27870",
            "comparison_id": "R28099",
            "paper_id": "R27870",
            "text": "Stereo Processing by Semiglobal Matching and Mutual Information this paper describes the semi-global matching (sgm) stereo method. it uses a pixelwise, mutual information based matching cost for compensating radiometric differences of input images. pixelwise matching is supported by a smoothness constraint that is usually expressed as a global cost function. sgm performs a fast approximation by pathwise optimizations from all directions. the discussion also addresses occlusion detection, subpixel refinement and multi-baseline matching. additionally, postprocessing steps for removing outliers, recovering from specific problems of structured environments and the interpolation of gaps are presented. finally, strategies for processing almost arbitrarily large images and fusion of disparity images using orthographic projection are proposed.a comparison on standard stereo images shows that sgm is among the currently top-ranked algorithms and is best, if subpixel accuracy is considered. the complexity is linear to the number of pixels and disparity range, which results in a runtime of just 1-2s on typical test images. an in depth evaluation of the mutual information based matching cost demonstrates a tolerance against a wide range of radiometric transformations. finally, examples of reconstructions from huge aerial frame and pushbroom images demonstrate that the presented ideas are working well on practical problems.",
            "contribution_ids": [
                "R27871"
            ]
        },
        {
            "instance_id": "R28099xR27987",
            "comparison_id": "R28099",
            "paper_id": "R27987",
            "text": "Window-based approach for fast stereo correspondence in this study, the authors present a new area-based stereo matching algorithm that computes dense disparity maps for a real-time vision system. although many stereo matching algorithms have been proposed in recent years, correlation-based algorithms still have an edge because of speed and less memory requirements. the selection of appropriate shape and size of the matching window is a difficult problem for correlation-based algorithms. in the proposed approach, two correlation windows are used to improve the performance of the algorithm while maintaining its real-time suitability. the cpu implementation of the proposed algorithm computes more than 10 frame/s. unlike other area-based stereo matching algorithms, this method works very well at disparity boundaries as well as in low textured image areas and computes a dense and sharp disparity map. evaluations on the benchmark middlebury stereo datasets have been performed to demonstrate the qualitative and quantitative performance of the proposed algorithm.",
            "contribution_ids": [
                "R27988"
            ]
        },
        {
            "instance_id": "R28099xR28083",
            "comparison_id": "R28099",
            "paper_id": "R28083",
            "text": "Efficient edge-awareness propagation via single-map filtering for edge-preserving stereo matching in this paper, we propose an efficient framework for edge-preserving stereo matching. local methods for stereo matching are more suitable than global methods for real-time applications. moreover, we can obtain accurate depth maps by using edge-preserving filter for the cost aggregation process in local stereo matching. the computational cost is high, since we must perform the filter for every number of disparity ranges if the order of the edge-preserving filter is constant time. therefore, we propose an efficient iterative framework which propagates edge-awareness by using single time edge preserving filtering. in our framework, box filtering is used for the cost aggregation, and then the edge-preserving filtering is once used for refinement of the obtained depth map from the box aggregation. after that, we iteratively estimate a new depth map by local stereo matching which utilizes the previous result of the depth map for feedback of the matching cost. note that the kernel size of the box filter is varied as coarse-to-fine manner at each iteration. experimental results show that small and large areas of incorrect regions are gradually corrected. finally, the accuracy of the depth map estimated by our framework is comparable to the state-of-the-art of stereo matching methods with global optimization methods. moreover, the computational time of our method is faster than the optimization based method.",
            "contribution_ids": [
                "R28084"
            ]
        },
        {
            "instance_id": "R28099xR28064",
            "comparison_id": "R28099",
            "paper_id": "R28064",
            "text": "Using the GPU for fast symmetry-based dense stereo matching in high resolution images symstereo is a new algorithm used for stereo estimation. instead of measuring photo-similarity, it proposes novel cost functions that measure symmetry for evaluating the likelihood of two pixels being a match. in this work we propose a parallel approach of the logn matching cost variant of symstereo capable of processing pairs of images in real-time for depth estimation. the power of the graphics processing units utilized allows exploring more efficiently the bank of log-gabor wavelets developed to analyze symmetry, in the spectral domain. we analyze tradeoffs and propose different parameter-izations of the signal processing algorithm to accommodate image size, dimension of the filter bank, number of wavelets and also the number of disparities that controls the space density of the estimation, and still process up to 53 frames per second (fps) for images with size 288 \u00d7 384 and up to 3 fps for 768 \u00d7 1024 images.",
            "contribution_ids": [
                "R28065"
            ]
        },
        {
            "instance_id": "R28099xR28016",
            "comparison_id": "R28099",
            "paper_id": "R28016",
            "text": "Domain Transformation-Based Efficient Cost Aggregation for Local Stereo Matching binocular stereo matching is one of the most important algorithms in the field of computer vision. adaptive support-weight approaches, the current state-of-the-art local methods, produce results comparable to those generated by global methods. however, excessive time consumption is the main problem of these algorithms since the computational complexity is proportionally related to the support window size. in this paper, we present a novel cost aggregation method inspired by domain transformation, a recently proposed dimensionality reduction technique. this transformation enables the aggregation of 2-d cost data to be performed using a sequence of 1-d filters, which lowers computation and memory costs compared to conventional 2-d filters. experiments show that the proposed method outperforms the state-of-the-art local methods in terms of computational performance, since its computational complexity is independent of the input parameters. furthermore, according to the experimental results with the middlebury dataset and real-world images, our algorithm is currently one of the most accurate and efficient local algorithms.",
            "contribution_ids": [
                "R28017"
            ]
        },
        {
            "instance_id": "R28099xR27906",
            "comparison_id": "R28099",
            "paper_id": "R27906",
            "text": "A revisit to cost aggregation in stereo matching: How far can we reduce its computational redundancy? this paper presents a novel method for performing an efficient cost aggregation in stereo matching. the cost aggregation problem is re-formulated with a perspective of a histogram, and it gives us a potential to reduce the complexity of the cost aggregation significantly. different from the previous methods which have tried to reduce the complexity in terms of the size of an image and a matching window, our approach focuses on reducing the computational redundancy which exists among the search range, caused by a repeated filtering for all disparity hypotheses. moreover, we also reduce the complexity of the window-based filtering through an efficient sampling scheme inside the matching window. the trade-off between accuracy and complexity is extensively investigated into parameters used in the proposed method. experimental results show that the proposed method provides high-quality disparity maps with low complexity. this work provides new insights into complexity-constrained stereo matching algorithm design.",
            "contribution_ids": [
                "R27907"
            ]
        },
        {
            "instance_id": "R28140xR28116",
            "comparison_id": "R28140",
            "paper_id": "R28116",
            "text": "A Case Report of Duodenal Gangliocytic Paraganglioma with Lymph Node Metastasis. \u4eca\u56de, \u6211\u3005\u306f\u5341\u4e8c\u6307\u8178\u306egangliocytic paraganglioma\u3067, \u81b5\u982d\u90e8\u524d\u9762\u30ea\u30f3\u30d1\u7bc0\u306b\u8ee2\u79fb\u304c\u307f\u3089\u308c\u305f\u75c7\u4f8b\u3092\u7d4c\u9a13\u3057\u305f.\u75c7\u4f8b\u306f63\u6b73\u306e\u5973\u6027\u3067\u4e3b\u8a34\u306f\u4e0a\u8179\u90e8\u75db\u3067\u3042\u3063\u305f.\u8179\u90e8\u8d85\u97f3\u6ce2\u691c\u67fb\u3067\u7dcf\u80c6\u7ba1\u62e1\u5f35\u3092\u8a8d\u3081, \u3055\u3089\u306b\u5185\u8996\u93e1, \u4f4e\u7dca\u5f35\u6027\u5341\u4e8c\u6307\u8178\u9020\u5f71\u3067\u5341\u4e8c\u6307\u8178\u306b\u816b\u760d\u3092\u767a\u898b\u3057\u305f, \u3053\u306e\u816b\u760d\u306f\u8868\u9762\u306b\u591a\u6570\u306e\u6f70\u760d\u3092\u4f34\u3046\u7c98\u819c\u4e0b\u816b\u760d\u69d8\u306e\u6240\u898b\u3092\u5448\u3057\u305f.\u5168\u80c3\u5e7d\u9580\u8f2a\u6e29\u5b58\u81b5\u982d\u5341\u4e8c\u6307\u8178\u5207\u9664\u3092\u65bd\u884c\u3057\u305f.\u816b\u760d\u306e\u7d44\u7e54\u50cf\u304a\u3088\u3073nse, s-100 protein, somatostatin\u306a\u3069\u306e\u514d\u75ab\u7d44\u7e54\u5316\u5b66\u7684\u691c\u7d22\u306b\u3088\u308agangliocytic paraganglioma\u3068\u8a3a\u65ad\u3057\u305f.\u3055\u3089\u306b\u81b5\u5468\u56f2\u306e\u30ea\u30f3\u30d1\u7bc0\u306b\u3082\u5c0f\u3055\u306a\u8ee2\u79fb\u5de3\u3092\u8a8d\u3081\u305f.\u3053\u308c\u307e\u3067\u306bgangliocytic paraganglioma\u306e\u30ea\u30f3\u30d1\u7bc0\u8ee2\u79fb\u4f8b\u306f6\u4f8b\u5831\u544a\u3055\u308c\u3066\u3044\u308b\u304c, \u518d\u767a\u306e\u5831\u544a\u306f\u306a\u304f\u4e88\u5f8c\u306f\u826f\u597d\u3067\u3042\u3063\u305f.\u672c\u816b\u760d\u306b\u5bfe\u3057\u3066\u306f\u62e1\u5927\u624b\u8853\u306f\u5fc5\u8981\u3067\u306a\u3044\u3068\u8003\u3048\u3089\u308c\u305f.",
            "contribution_ids": [
                "R28117"
            ]
        },
        {
            "instance_id": "R28140xR28119",
            "comparison_id": "R28140",
            "paper_id": "R28119",
            "text": "Recurrent duodenal gangliocytic paraganglioma with lymph node metastases \"gangliocytic paraganglioma is a rare tumour which occurs almost exclusively in the second portion of the duodenum',2. histologically, it shows features reminiscent of paraganglioma, ganglioneuroma and carcinoid tumour. the lesion is composed of variable admixtures of three cell types: spindle cells with features of schwann cells, ganglion-like cells and epithelioid cells. gangliocytic paraganglioma is generally considered benign and most cases are cured by simple excision of the tumour mass. metastatic spread to regional lymph nodes has been reported in five cases3-5. no instances of systemic metastatic spread or patient death attributed to the tumour are known. here we report one additional case of duodenal gangliocytic paraganglioma which recurred in the mesentery 11 years following the original excision and also metastasized to the regional lymph nodes.\"",
            "contribution_ids": [
                "R28120"
            ]
        },
        {
            "instance_id": "R28140xR28124",
            "comparison_id": "R28140",
            "paper_id": "R28124",
            "text": "Paraganglioma of the ampulla of vater: a potentially malignant neoplasm paragangliomas are rare tumours originating from neuroectodermic remnants and are usually considered as benign. we present two cases of paraganglioma of the ampulla of vater that were treated surgically by pancreaticoduodenectomy. in one case, histopathology revealed malignant characteristics of the tumour with invasion of the pancreas and simultaneous duodenal lymph\u2010node metastases. both patients had a favourable outcome without disease recurrence at 40 and 44 months postoperatively. only 21 cases of ampullary paraganglioma have been reported in the literature, 7 of them with malignant characteristics. in conclusion, paragangliomas of the ampulla of vater have malignant potential. surgical therapy of these tumours should not be limited to local resection, as disease recurrence and lymph node involvement have been reported. we propose that paragangliomas of the ampulla of vater should be operated by cephalic pancreaticoduodenectomy, which allows long\u2010term and disease\u2010free survival.",
            "contribution_ids": [
                "R28125"
            ]
        },
        {
            "instance_id": "R28140xR28108",
            "comparison_id": "R28140",
            "paper_id": "R28108",
            "text": "Duodenal gangliocytic paraganglioma with lymph node metastasis in a 17-year-old boy a case of duodenal gangliocytic paraganglioma (dgp) in a 17\u2010year\u2010old boy is presented. in this case a lymph node in the peripancreatic region was involved by a metastatic tumor. a review of the literature on dgp indicates that this case represents the youngest patient and is the second case of dgp with metastasis. immunohistochemical staining for neuron\u2010specific enolase (nse), neurofilament (nf), pancreatic polypeptide, and somatostatin showed positive results for epithelioid and ganglion\u2010like cells, whereas spindle cells showed immunoreactivities for s\u2010100 protein, nse, and nf. the histogenesis of dgp is discussed.",
            "contribution_ids": [
                "R28109"
            ]
        },
        {
            "instance_id": "R28191xR28179",
            "comparison_id": "R28191",
            "paper_id": "R28179",
            "text": "An optimal containership slot allocation for liner shipping revenue management in the competitive liner shipping market, carriers may utilize revenue management systems to increase profits by using slot allocation and pricing. in this paper, related research on revenue management for transportation industries is reviewed. a conceptual model for liner shipping revenue management (lsrm) is proposed and a slot allocation model is formulated through mathematical programming to maximize freight contribution. we illustrate this slot allocation model with a case study of a taiwan liner shipping company and the results show the applicability and better performances than the previous allocation used in practice.",
            "contribution_ids": [
                "R28180"
            ]
        },
        {
            "instance_id": "R28191xR28163",
            "comparison_id": "R28191",
            "paper_id": "R28163",
            "text": "Multicommodity network flow model for Asia's container ports \"this paper seeks to develop a multi-commodity network model to analyse the flow of containers within the asia pacific context. the model is used to evaluate the impact of container throughput in asia's port by varying terminal handling charges and turnaround time. the three main regions analysed are north-east asia, east asia (chinese port region) and south east asia. using the model, it could be shown that busan port, which is an important transhipment hub in north-east asia, could boost the container activities in the north-eastern part of china by improving its service quality. it is also found that the efficiency of the land link between hong kong and mainland china plays a crucial role for the future of hong kong port. while singapore port maintains its position as a transhipment hub in south-east asia, there would be expected competition from neighbouring low costs ports.\"",
            "contribution_ids": [
                "R28164"
            ]
        },
        {
            "instance_id": "R28191xR28169",
            "comparison_id": "R28191",
            "paper_id": "R28169",
            "text": "Empty container repositioning in liner shipping1 the efficient and effective management of empty containers is an important problem in the shipping industry. not only does it have an economic effect, but it also has an environmental and sustainability impact, since the reduction of empty container movements will reduce fuel consumption and reduce congestion and emissions. the purposes of this paper are: to identify critical factors that affect empty container movements; to quantify the scale of empty container repositioning in major shipping routes; and to evaluate and contrast different strategies that shipping lines, and container operators, could adopt to reduce their empty container repositioning costs. the critical factors that affect empty container repositioning are identified through a review of the literature and observations of industrial practice. taking three major routes (trans-pacific, trans-atlantic, europe\u2013asia) as examples, with the assumption that trade demands could be balanced among the whole network regardless the identities of individual shipping lines, the most optimistic estimation of empty container movements can be calculated. this quantifies the scale of the empty repositioning problem. depending on whether shipping lines are coordinating the container flows over different routes and whether they are willing to share container fleets, four strategies for empty container repositioning are presented. mathematical programming is then applied to evaluate and contrast the performance of these strategies in three major routes. 1a preliminary version was presented in iame annual conference at dalian, china, 2\u20134 april 2008.",
            "contribution_ids": [
                "R28170"
            ]
        },
        {
            "instance_id": "R28235xR28193",
            "comparison_id": "R28235",
            "paper_id": "R28193",
            "text": "A Two-Stage Stochastic Network Model and Solution Methods for the Dynamic Empty Container Allocation Problem \" containerized liner trades have been growing steadily since the globalization of world economies intensified in the early 1990s. however, these trades are typically imbalanced in terms of the numbers of inbound and outbound containers. as a result, the relocation of empty containers has become one of the major problems faced by liner operators. in this paper, we consider the dynamic empty container allocation problem where we need to reposition empty containers and to determine the number of leased containers needed to meet customers' demand over time. we formulate this problem as a two-stage stochastic network: in stage one, the parameters such as supplies, demands, and ship capacities for empty containers are deterministic; whereas in stage two, these parameters are random variables. we need to make decisions in stage one such that the total of the stage one cost and the expected stage two cost is minimized. by taking advantage of the network structure, we show how a stochastic quasi-gradient method and a stochastic hybrid approximation procedure can be applied to solve the problem. in addition, we propose some new variations of these methods that seem to work faster in practice. we conduct numerical tests to evaluate the value of the two-stage stochastic model over a rolling horizon environment and to investigate the behavior of the solution methods with different implementations. \"",
            "contribution_ids": [
                "R28194"
            ]
        },
        {
            "instance_id": "R28235xR28214",
            "comparison_id": "R28235",
            "paper_id": "R28214",
            "text": "Liner shipping cargo allocation with repositioning of empty containers abstract this paper is concerned with the cargo allocation problem considering empty repositioning of containers for a liner shipping company. the aim is to maximize the profit of transported cargo in a network, subject to the cost and availability of empty containers. the formulation is a multi-commodity flow problem with additional inter-balancing constraints to control repositioning of empty containers. in a study of the cost efficiency of the global container-shipping network, song et al. (2005) estimate that empty repositioning cost constitutes 27% of the total world fleet running cost. an arc-flow formulation is decomposed using the dantzig-wolfe principle to a path-flow formulation. a linear relaxation is solved with a delayed column generation algorithm. a feasible integer solution is found by rounding the fractional solution and adjusting flow balance constraints with leased containers. computational results are reported for seven instances based on real-life shipping networks. solving the relaxed linear path-flow model with a column generation algorithm outperforms solving the relaxed linear arc-flow model with the cplex barrier solver even for very small instances. the proposed algorithm is able to solve instances with 234 ports, 16,278 demands over 9 time periods in 34 min. the integer solutions found by rounding down are computed in less than 5 s and the gap is within 0.01% from the upper bound of the linear relaxation. the solved instances are quite large compared to those tested in the reviewed literature.",
            "contribution_ids": [
                "R28215"
            ]
        },
        {
            "instance_id": "R28333xR28285",
            "comparison_id": "R28333",
            "paper_id": "R28285",
            "text": "Fleet deployment optimization for liner shipping. Part 2. Implementation and results we use linear programming (lp) for solving the problem of the optimal deployment of an existing fleet of multipurpose or fully containerized ships, among a given set of routes, including information for lay-up time, if any, and type and number of extra ships to charter, based on a detailed and realistic model for the calculation of the operating costs of all the ship types in every route and on a suitable lp formulation developed in earlier work of the authors. the optimization model is also applicable to the problem of finding the best fleet compostion and deployment, in a given set of trade routes, which may be the case when a shipping company is considering new or modified services, or a renewal of the existing fleet. in addition, two promising mixed linear-integer programming formulations are suggested.",
            "contribution_ids": [
                "R28286"
            ]
        },
        {
            "instance_id": "R28333xR28283",
            "comparison_id": "R28333",
            "paper_id": "R28283",
            "text": "Fleet deployment optimization for liner shipping. Part 1: background, problem formulation and solution approaches the background and the literature in liner fleet scheduling is reviewed and the objectives and assumptions of our approach are explained. we develop a detailed and realistic model for the estimation of the operating costs of liner ships on various routes, and present a linear programming formulation for the liner fleet deployment problem. independent approaches for fixing both the service frequencies in the different routes and the speeds of the ships, are presented.",
            "contribution_ids": [
                "R28284",
                "R28355",
                "R28431"
            ]
        },
        {
            "instance_id": "R28333xR28307",
            "comparison_id": "R28333",
            "paper_id": "R28307",
            "text": "Schedule Design and Container Routing in Liner Shipping a liner shipping company seeks to provide liner services with shorter transit time compared with the benchmark of market-level transit time because of the ever-increasing competition. when the itineraries of its liner service routes are determined, the liner shipping company designs the schedules of the liner routes such that the wait time at transshipment ports is minimized. as a result of transshipment, multiple paths are available for delivering containers from the origin port to the destination port. therefore, the medium-term (3 to 6 months) schedule design problem and the operational-level container-routing problem must be investigated simultaneously. the schedule design and container-routing problems were formulated by minimization of the sum of the total transshipment cost and penalty cost associated with longer transit time than the market-level transit time, minus the bonus for shorter transit time. the formulation is nonlinear, noncontinuous, and nonconvex. a genetic local search approach was developed to find good solutions to the problem. the proposed solution method was applied to optimize the asia\u2013europe\u2013oceania liner shipping services of a global liner company.",
            "contribution_ids": [
                "R28308"
            ]
        },
        {
            "instance_id": "R28333xR28264",
            "comparison_id": "R28333",
            "paper_id": "R28264",
            "text": "Purification and Characterization of Heparin Lyase I from Bacteroides stercoris HJ-15 heparin lyase i was purified to homogeneity from bacteroides stercoris hj-15 isolated from human intestine, by a combination of deae-sepharose, gel-filtration, hydroxyapatite, and cm-sephadex c-50 column chromatography. this enzyme preferred heparin to heparan sulfate, but was inactive at cleaving acharan sulfate. the apparent molecular mass of heparin lyase i was estimated as 48,000 daltons by sds-page and its isoelectric point was determined as 9.0 by ief. the purified enzyme required 500 mm nacl in the reaction mixture for maximal activity and the optimal activity was obtained at ph 7.0 and 50 degrees c. it was rather stable within the range of 25 to 50 degrees c but lost activity rapidly above 50 degrees c. the enzyme was activated by co(2+) or edta and stabilized by dithiothreitol. the kinetic constants, k(m) and v(max) for heparin were 1.3 10(-5) m and 8.8 micromol/min.mg. the purified heparin lyase i was an eliminase that acted best on porcine intestinal heparin, and to a lesser extent on porcine intestinal mucosa heparan sulfate. it was inactive in the cleavage of n-desulfated heparin and acharan sulfate. in conclusion, heparin lyase i from bacteroides stercoris was specific to heparin rather than heparan sulfate and its biochemical properties showed a substrate specificity similar to that of flavobacterial heparin lyase i.",
            "contribution_ids": [
                "R28265"
            ]
        },
        {
            "instance_id": "R28333xR28287",
            "comparison_id": "R28333",
            "paper_id": "R28287",
            "text": "Fleet deployment optimization for liner shipping: an integer programming model extending and improving an earlier work of the second author, an integer programming (ip) model is developed to minimize the operating and lay-up costs for a fleet of liner ships operating on various routes. the ip model determines the optimal deployment of an existing fleet, given route, service, charter, and compatibility constraints. two examples are worked with extensive actual data provided by flota mercante grancolombiana (fmg). the optimal deployment is solved for their existing ship and service requirements and results and conclusions are given.",
            "contribution_ids": [
                "R28288"
            ]
        },
        {
            "instance_id": "R28333xR28247",
            "comparison_id": "R28333",
            "paper_id": "R28247",
            "text": "Liner shipping service optimisation with reefer containers capacity: an application to northern Europe\u00e2\u0080\u0093South America trade increasing the number of vessels in a container liner service while reducing speeds, known as slow steaming strategy, has been a short-term response since 2008 to the challenges of over-capacity and the rise in bunker prices faced by shipping lines. this strategy, which reduces the fuel cost per voyage but increases the operating costs as more vessels are added to the service, is difficult to sustain when the transit time significantly affects the transportation demand. this article proposes a model applied to this situation, referred to as a case of optimal speed under semi-elastic demand, for which containerised perishable product transport is sensitive to time, while frozen and dry products are not. it investigates if slow steaming is still optimal when working to maximise the total profit on the cycle. in order to demonstrate the proposed model, a numerical application is carried out for a direct northern europe to east coast of south america container service, a route selected due to the high volume of fresh products. for this application, the speed that maximises the total profit with inelastic and semi-elastic demand is then estimated for several bunker fuel prices.",
            "contribution_ids": [
                "R28248"
            ]
        },
        {
            "instance_id": "R28333xR28266",
            "comparison_id": "R28333",
            "paper_id": "R28266",
            "text": "Tactical planning models for managing container flow and ship deployment this paper addresses two practical problems from a liner shipping company, i.e. the container flow management problem and the ship deployment problem, at the tactical planning level. a sequential model and a joint optimisation model are formulated to solve the problems. our results show that the company should implement the joint optimisation model at the tactical planning level to improve the shipping capacity utilisation rather than the sequential model used in the current practice. repositioning empty containers also need to be considered jointly with the nonempty container flow at the tactical planning level. some important managerial insights into the operational and business processes are gained.",
            "contribution_ids": [
                "R28267"
            ]
        },
        {
            "instance_id": "R28333xR28304",
            "comparison_id": "R28333",
            "paper_id": "R28304",
            "text": "Liner shipping fleet deployment with cargo transshipment and demand uncertainty this paper addresses a novel liner shipping fleet deployment problem characterized by cargo transshipment, multiple container routing options and uncertain demand, with the objective of maximizing the expected profit. this problem is formulated as a stochastic program and solved by the sample average approximation method. in this technique the objective function of the stochastic program is approximated by a sample average estimate derived from a random sample, and then the resulting deterministic program is solved. this process is repeated with different samples to obtain a good candidate solution along with the statistical estimate of its optimality gap. we apply the proposed model to a case study inspired from real-world problems faced by a major liner shipping company. results show that the case is efficiently solved to 1% of relative optimality gap at 95% confidence level.",
            "contribution_ids": [
                "R28305"
            ]
        },
        {
            "instance_id": "R28369xR28344",
            "comparison_id": "R28369",
            "paper_id": "R28344",
            "text": "Designing container shipping network under changing demand and freight rates this paper focuses on the optimization of container shipping network and its operations under changing cargo demand and freight rates. the problem is formulated as a mixed integer non-linear programming problem (minp) with an objective of maximizing the average unit ship-slot profit at three stages using analytical methodology. the issues such as empty container repositioning, ship-slot allocating, ship sizing, and container configuration are simultaneously considered based on a series of the matrices of demand for a year. to solve the model, a bi-level genetic algorithm based method is proposed. finally, numerical experiments are provided to illustrate the validity of the proposed model and algorithms. the obtained results show that the suggested model can provide a more realistic solution to the issues on the basis of changing demand and freight rates and arrange a more effective approach to the optimization of container shipping network structures and operations than does the model based on the average demand.",
            "contribution_ids": [
                "R28345"
            ]
        },
        {
            "instance_id": "R28369xR28283",
            "comparison_id": "R28369",
            "paper_id": "R28283",
            "text": "Fleet deployment optimization for liner shipping. Part 1: background, problem formulation and solution approaches the background and the literature in liner fleet scheduling is reviewed and the objectives and assumptions of our approach are explained. we develop a detailed and realistic model for the estimation of the operating costs of liner ships on various routes, and present a linear programming formulation for the liner fleet deployment problem. independent approaches for fixing both the service frequencies in the different routes and the speeds of the ships, are presented.",
            "contribution_ids": [
                "R28284",
                "R28355",
                "R28431"
            ]
        },
        {
            "instance_id": "R28407xR28394",
            "comparison_id": "R28407",
            "paper_id": "R28394",
            "text": "Planning and scheduling for efficiency in liner shipping analysis of the capacity required to serve a specific trade route,with application to australianorth american west coast trade",
            "contribution_ids": [
                "R28395"
            ]
        },
        {
            "instance_id": "R28407xR28383",
            "comparison_id": "R28407",
            "paper_id": "R28383",
            "text": "A Base Integer Programming Model and Benchmark Suite for Liner-Shipping Network Design the liner-shipping network design problem is to create a set of nonsimple cyclic sailing routes for a designated fleet of container vessels that jointly transports multiple commodities. the objective is to maximize the revenue of cargo transport while minimizing the costs of operation. the potential for making cost-effective and energy-efficient liner-shipping networks using operations research (or) is huge and neglected. the implementation of logistic planning tools based upon or has enhanced performance of airlines, railways, and general transportation companies, but within the field of liner shipping, applications of or are scarce. we believe that access to domain knowledge and data is a barrier for researchers to approach the important liner-shipping network design problem. the purpose of the benchmark suite and the paper at hand is to provide easy access to the domain and the data sources of liner shipping for or researchers in general. we describe and analyze the liner-shipping domain applied to network design and present a rich integer programming model based on services that constitute the fixed schedule of a liner shipping company. we prove the liner-shipping network design problem to be strongly np-hard. a benchmark suite of data instances to reflect the business structure of a global liner shipping network is presented. the design of the benchmark suite is discussed in relation to industry standards, business rules, and mathematical programming. the data are based on real-life data from the largest global liner-shipping company, maersk line, and supplemented by data from several industry and public stakeholders. computational results yielding the first best known solutions for six of the seven benchmark instances is provided using a heuristic combining tabu search and heuristic column generation.",
            "contribution_ids": [
                "R28384"
            ]
        },
        {
            "instance_id": "R28407xR28403",
            "comparison_id": "R28407",
            "paper_id": "R28403",
            "text": "Study on a Liner Shipping Network Design Considering Empty Container Reposition empty container allocation problems arise due to imbalance on trades. imbalanced trade is a common fact in the liner shipping,creating the necessity of repositioning empty containers from import-dominant ports to export-dominant ports in an economic and efficient way. the present work configures a liner shipping network, by performing the routes assignment and their integration to maximize the profit for a liner shipping company. the empty container repositioning problem is expressly taken into account in whole process. by considering the empty container repositioning problem in the network design, the choice of routes will be also influenced by the empty container flow, resulting in an optimum network, both for loaded and empty cargo. the liner shipping network design program (ls-net program) will define the best set of routes among a set of candidate routes, the best composition of the fleet for the network and configure the empty container repositioning network. further, a network of asian ports was studied and the results obtained show that considering the empty container allocation problem in the designing process can influence the final configuration of the network.",
            "contribution_ids": [
                "R28404"
            ]
        },
        {
            "instance_id": "R28407xR28372",
            "comparison_id": "R28407",
            "paper_id": "R28372",
            "text": "Ship Scheduling and Network Design for Cargo Routing in Liner Shipping \" acommon problem faced by carriers in liner shipping is the design of their service network. given a set of demands to be transported and a set of ports, a carrier wants to design service routes for its ships as efficiently as possible, using the underlying facilities. furthermore, the profitability of the service routes designed depends on the paths chosen to ship the cargo. we present an integrated model, a mixed-integer linear program, to solve the ship-scheduling and the cargo-routing problems, simultaneously. the proposed model incorporates relevant constraints, such as the weekly frequency constraint on the operated routes, and emerging trends, such as the transshipment of cargo between two or more service routes. to solve the mixed-integer program, we propose algorithms that exploit the separability of the problem. more specifically, a greedy heuristic, a column generation-based algorithm, and a two-phase benders decomposition-based algorithm are developed, and their computational efficiency in terms of the solution quality and the computational time taken is discussed. an efficient iterative search algorithm is proposed to generate schedules for ships. computational experiments are performed on randomly generated instances simulating real life with up to 20 ports and 100 ships. our results indicate high percentage utilization of ships' capacities and a significant number of transshipments in the final solution. \"",
            "contribution_ids": [
                "R28373"
            ]
        },
        {
            "instance_id": "R28407xR26992",
            "comparison_id": "R28407",
            "paper_id": "R26992",
            "text": "Optimal liner fleet routeing strategies the objective of this paper is to suggest practical optimization models for routing strategies for liner fleets. many useful routing and scheduling problems have been studied in the transportation literature. as for ship scheduling or routing problems, relatively less effort has been devoted, in spite of the fact that sea transportation involves large capital and operating costs. this paper suggests two optimization models that can be useful to liner shipping companies. one is a linear programming model of profit maximization, which provides an optimal routing mix for each ship available and optimal service frequencies for each candidate route. the other model is a mixed integer programming model with binary variables which not only provides optimal routing mixes and service frequencies but also best capital investment alternatives to expand fleet capacity. this model is a cost minimization model.",
            "contribution_ids": [
                "R26993",
                "R28386"
            ]
        },
        {
            "instance_id": "R28446xR28428",
            "comparison_id": "R28446",
            "paper_id": "R28428",
            "text": "From multi-porting to a hub port configuration: the South African container port system in transition \"this paper addresses the tension that exists between multi-porting and a hub configuration in the south african container port system. we apply a generalised cost model to two alternative network configurations: the actual situation of multi-porting and an alternative hub port configuration. the results demonstrate that south african import and export flows are likely to face small cost increases when the port system moves to a hub port configuration. however, from a ship operator's perspective, the hub configuration is more attractive given considerable cost reductions in marine charges, port dues and ship costs. the paper concludes by underlining transnet's pivotal role in the attractiveness of the hub option and the need for a wider sub-saharan strategy in view of making the hub port concept work.\"",
            "contribution_ids": [
                "R28429"
            ]
        },
        {
            "instance_id": "R28446xR28283",
            "comparison_id": "R28446",
            "paper_id": "R28283",
            "text": "Fleet deployment optimization for liner shipping. Part 1: background, problem formulation and solution approaches the background and the literature in liner fleet scheduling is reviewed and the objectives and assumptions of our approach are explained. we develop a detailed and realistic model for the estimation of the operating costs of liner ships on various routes, and present a linear programming formulation for the liner fleet deployment problem. independent approaches for fixing both the service frequencies in the different routes and the speeds of the ships, are presented.",
            "contribution_ids": [
                "R28284",
                "R28355",
                "R28431"
            ]
        },
        {
            "instance_id": "R28487xR28464",
            "comparison_id": "R28487",
            "paper_id": "R28464",
            "text": "A Containerized Liner Routing in Eastern Asia new partnerships has been made in containerized liner services. this likely results in drastic changes in ship size and hub location in eastern asia. in this study we address strategies of the containerized liner services by using a mathematical programming with two objectives of shipping company and customer.",
            "contribution_ids": [
                "R28465"
            ]
        },
        {
            "instance_id": "R28487xR28460",
            "comparison_id": "R28487",
            "paper_id": "R28460",
            "text": "The marine single assignment nonstrict Hub location problem: formulations and experimental examples marine hub-and-spoke networks have been applied to routing containerships for over two decades, but few papers have devoted their attention to these networks. the marine network problems are known as single assignment nonstrict hub location problems (snhlps), which deal with the optimal location of hubs and allocation of spokes to hubs in a network, allowing direct routes between some spokes. in this paper we present a satisfactory approach for solving shnlps. the quadratic integer profit programming consists of two-stage computational algorithms: a hub location model and a spoke allocation model. we apply a heuristic scheme based on the shortest distance rule and an experimental case based on the trans-pacific routes is presented to illustrate the model\u2019s formulation and solution methods. the results indicate that the model is a concave function, exploiting the economies of scale for total profit with respect to the number of hubs. the spoke allocation may change an optimal choice of hub",
            "contribution_ids": [
                "R28461"
            ]
        },
        {
            "instance_id": "R28614xR28546",
            "comparison_id": "R28614",
            "paper_id": "R28546",
            "text": "Primary malignant mesenchymal tumour of the liver in an elderly female a case of primary malignant mesenchymal tumour of the liver occurring in an 86\u2010year\u2010old woman is described. this very uncommon tumour has previously only been described in children and young adults, the previous oldest being 28 years of age. the tumour was large, rapidly growing though well circumscribed and extensively necrotic. microscopically it was mostly composed of spindle cell sarcoma without differentiating features. epithelial lined ductules were seen throughout the tumour and degenerate hepatocytes were enveloped in the tumour peripherally. intracytoplasmic and extracellular pas\u2010positive, diastase\u2010resistant bodies were present, some showing positive staining for alpha\u20101\u2010antitrypsin. the tumour is compared with previous reports and its differential diagnosis and nomenclature discussed.",
            "contribution_ids": [
                "R28547"
            ]
        },
        {
            "instance_id": "R28614xR28558",
            "comparison_id": "R28614",
            "paper_id": "R28558",
            "text": "Undifferentiated Sarcoma of the Liver in a 21-year-old Woman: Case Report \"a successful surgical case of malignant undifferentiated (embryonal) sarcoma of the liver (usl), a rare tumor normally found in children, is reported. the patient was a 21-year-old woman, complaining of epigastric pain and abdominal fullness. chemical analyses of the blood and urine and complete blood counts revealed no significant changes, and serum alpha-fetoprotein levels were within normal limits. a physical examination demonstrated a film, slightly tender lesion at the liver's edge palpable 10 cm below the xiphoid process. ct scan and ultrasonography showed an oval mass, confined to the left lobe of the liver, which proved to be hypovascular on angiography. at laparotomy, a large, 18 x 15 x 13 cm tumor, found in the left hepatic lobe was resected. the lesion was dark red in color, encapsulated, smooth surfaced and of an elastic firm consistency. no metastasis was apparent. histological examination resulted in a diagnosis of undifferentiated sarcoma of the liver. three courses of adjuvant chemotherapy, including adriamycin, cis-diaminodichloroplatinum, vincristine and dacarbazine were administered following the surgery with no serious adverse effects. the patient remains well with no evidence of recurrence 12 months after her operation.\"",
            "contribution_ids": [
                "R28559"
            ]
        },
        {
            "instance_id": "R28614xR28560",
            "comparison_id": "R28614",
            "paper_id": "R28560",
            "text": "Undifferentiated (Embryonal) Sarcoma of the Liver undifferentiated (embryonal) sarcoma of the liver is a primitive mesenchymal neoplasm with predilection for individuals in the first 2 decades of life. in this study (10 boys, 6 girls), children in the age range of 6\u201310 years were most commonly affected (63%). clinical features most frequently noted on presentation were abdominal pain or a palpable mass. in two cases there was cardiac involvement caused by invasion of the inferior vena cava with extension into the right atrium and ventricle; both children died of progressive dyspnea from tumor embolization to the lungs. one patient was a member of a kindred with the cancer family syndrome (li-fraumeni syndrome). there were 13 tumor-related deaths (86% mortality); one child was alive with recurrent tumor in the upper abdomen. complete surgical resection was attempted in 10 of 15 children who underwent exploratory laparotomy; 2 were alive and well 1 and 5 years later, whereas 1 patient had a recurrence in the upper abdomen 3 years after diagnosis. ultrastructural study (five cases) and immunohistochemistry (11 cases) supported a mesenchymal origin for the tumor, but failed to identify any diagnostic immunophenotype or specific line of differentiation. coexpression of vimentin and cytokeratin was seen in three cases. prompt detection of this aggressive tumor with complete surgical resection is the key to a successful outcome, but this is very difficult to achieve. recent experience suggests that aggressive adjuvant chemotherapy may improve survival in some cases.",
            "contribution_ids": [
                "R28561",
                "R28562",
                "R28564",
                "R28565",
                "R28566"
            ]
        },
        {
            "instance_id": "R28614xR28556",
            "comparison_id": "R28614",
            "paper_id": "R28556",
            "text": "Undifferentiated (embryonal) sarcoma of the liver. Epithelial features as shown by immunohistochemical analysis and electron microscopic examination the cell differentiation properties of two undifferentiated (embryonal) sarcomas of the liver (usl), one in a 9\u2010year\u2010old boy and one in a 23\u2010year\u2010old man, were studied by immunohistochemistry and electron microscopic examination. both tumors showed a part pleomorphic pattern and a part myxoid spindle cell sarcomatous pattern. an electron microscopic examination showed some tonofilament\u2010like bundles of intermediate filaments and cell junctions in one case, suggesting the presence of epithelial differentiation in that tumor. an immunohistochemical analysis showed a large number of cytokeratin\u2010positive neoplastic cells in both cases as studied with two different monoclonal antibodies, and most cells were positive for vimentin. no cells showed desmin, glial fibrillary acidic protein, or epithelial membrane antigen (ema). due to the presence of cytokeratin immunoreactivity, the possibility was considered that these tumors would represent anaplastic sarcomatoid variants of hepatocellular carcinoma. the tumor cells showed cytoplasmic alpha\u20101\u2010antitrypsin (aat) positivity, and were negative for alpha\u2010fetoprotein. because the immunoreactivity of aat is widespread in different types of tumors, it is not possible to conclude that the aat positivity would indicate the hepatoma nature of usl; however, this remains a possibility, especially when considering that in vitro transformed hepatocytes have been shown to be capable of forming sarcomatous tumors.",
            "contribution_ids": [
                "R28557"
            ]
        },
        {
            "instance_id": "R28614xR28522",
            "comparison_id": "R28614",
            "paper_id": "R28522",
            "text": "RIGHT HEPATOLOBECTOMY FOR PRIMARY MESENCHYMOMA OF THE LIVER* summarya case report of a large primary malignant mesenchymoma of the liver is presented. this tumor was successfully removed with normal liver tissue surrounding the tumor by right hepatolobectomy. the pathologic characteristics and clinical behavior of tumors falling into this general category are",
            "contribution_ids": [
                "R28523"
            ]
        },
        {
            "instance_id": "R28614xR28572",
            "comparison_id": "R28614",
            "paper_id": "R28572",
            "text": "Primary Gastrointestinal Sarcomas \u00e2\u0080\u0093 A Report of 21 Cases twenty-one patients with primary gastrointestinal sarcomas underwent surgery at the university clinics of hamburg from 1970 to 1990. main symptoms were gastrointestinal bleeding and abdominal pain. al",
            "contribution_ids": [
                "R28573"
            ]
        },
        {
            "instance_id": "R28614xR28542",
            "comparison_id": "R28614",
            "paper_id": "R28542",
            "text": "Primary sarcoma of the liver six cases of hepatic sarcoma are reported: leiomyosarcoma in two, malignant fibrous histiocytoma in two malignant hemagiopericytoma in one and fibrosarcoma in one. in addition to the routine paraffin section and he stain, immuno-histochemical studies with antibodies against vimentin, ema, ck, s100, act, aat, desmin, afp, lysozyme and factor viii and masson trichrome staining and argyrophilia staining were done. afp was negative in all 6 patients and the primary sarcoma was characterized by the absence of accompanying liver cirrhosis. the diagnosis, histogenesis and prognosis of primary liver sarcoma are discussed.",
            "contribution_ids": [
                "R28543"
            ]
        },
        {
            "instance_id": "R28614xR28549",
            "comparison_id": "R28614",
            "paper_id": "R28549",
            "text": "Hepatic sarcomas in adults: a review of 25 cases. twenty-five patients with an apparently primary sarcoma of the liver are reviewed. presenting complaints were non-specific, but hepatomegaly and abnormal liver function tests were usual. use of the contraceptive pill (four of 11 women) was identified as a possible risk factor; one patient had previously been exposed to vinyl chloride monomer. detailed investigation showed that the primary tumour was extrahepatic in nine of the 25 patients. distinguishing features of the 15 patients with confirmed primary hepatic sarcoma included a lower incidence of multiple hepatic lesions and a shorter time from first symptoms to diagnosis, but the most valuable discriminator was histology. angiosarcomas and undifferentiated tumours were all of hepatic origin, epithelioid haemangioendotheliomas (ehae) occurred as primary and secondary lesions and all other differentiated tumours arose outside the liver. the retroperitoneum was the most common site of an occult primary tumour and its careful examination therefore crucial: computed tomography scanning was found least fallible in this respect in the present series. where resection (or transplantation), the best treatment, was not possible, results of therapy were disappointing, prognosis being considerably worse for patients with primary hepatic tumours. patients with ehae had a better overall prognosis regardless of primary site.",
            "contribution_ids": [
                "R28550",
                "R28551",
                "R28552",
                "R28553"
            ]
        },
        {
            "instance_id": "R28614xR28601",
            "comparison_id": "R28614",
            "paper_id": "R28601",
            "text": "Mutation of TP53 gene is involved in carcinogenesis of hepatic undifferentiated (embryonal) sarcoma of the adult, in contrast with Wnt or telomerase pathways: an immunohistochemical study of three cases with genomic relation in two cases background/aims: hepatic undifferentiated (embryonal) sarcoma (hus) is an exc eptional hepatic malignant tumor in adults. genetic studies were never reported in adult cases. methods: in this study concerning three cases of hus occurring i n adult, we studied the three classical ways of carcinogenesis i.e. the tp53 (p5 3), wnt (ctnnb1/\u03b2 - catenin and axin1) and telomerase (htert) pathways. we stu died the expression of p53, \u03b2 - catenin and telomerase catalytic subunit htert by immunohistochemistry in the three cases; we determined tp53 gene mutation in two cases and the genome- wide allelotype, axin1, and ctnnb1/\u03b2 - catenin gen e mutation in one case. results: immunohistochemistry showed an overexpression o f p53 in more than 80% of tumoral cells; furthermore, mutations of tp53 were o bserved in two cases, involving the sequence- specific dna binding domain. in c ontrast, no mutation was found in ctnnb1/\u03b2 - catenin and axin1 genes. tumoral cells did not show htert staining nor nuclear expression of \u03b2 - catenin. in ad dition, allelotype analysis in one case showed loss of heterozygosity of chromos ome 7p, 11p, 17p, 22q, and allelic imbalance of 1p, 8p, 20q. conclusions: in thi s report of hus in three adult patients, we emphasize the role of tp53 pathway i n carcinogenesis of this rare tumor. this point could be of interest for therape utic strategies.",
            "contribution_ids": [
                "R28602",
                "R28603",
                "R28604"
            ]
        },
        {
            "instance_id": "R28614xR28605",
            "comparison_id": "R28614",
            "paper_id": "R28605",
            "text": "Pediatric and Adult Hepatic Embryonal Sarcoma: A Comparative Ultrastructural Study with Morphologic Correlations hepatic embryonal (undifferentiated) sarcoma (es) is a rare pediatric tumor occurring predominantly in the first decade of life, but a few examples of adult es have also been described. isolated ultrastructural reports describe contradictory lines of differentiation in these tumors. four pediatric and 3 adult es cases were studied ultrastructurally and features were correlated with morphology. morphologically, tumors were composed of mixture of plump spindle cells and bizarre giant cells, showing abundant cytoplasmic eosinophilic globules. ultrastructurally, the hallmark features in all cases included dilated rers and secondary lysosomes with dense precipitates. dilated mitochondria and mitochondrial\u2013rer complexes were often seen. other features included intracytoplasmic fat droplets, scant actin microfilaments, and focal glycogen pools. in summary, pediatric and adult es show similar morphologic and ultrastructural features. ultrastructurally, hepatic es have distinctive findings, including dilated rer and electron-dense lysosomal precipitates, which correlate with the eosinophilic hyaline bodies seen microscopically. these findings suggest that es are composed of fibroblastic, fibrohistiocytic, and undifferentiated cells. other lines of differentiation were not identified.",
            "contribution_ids": [
                "R28606",
                "R28607",
                "R28608"
            ]
        },
        {
            "instance_id": "R28614xR28529",
            "comparison_id": "R28614",
            "paper_id": "R28529",
            "text": "Malignant Mesenchymoma and Birth Defects malignant mesenchymoma developed in an 18-year-old patient with phenytoin-associated cleft lip and palate. although these conditions may be related by chance, the possibility of transplacental carcinogenesis by phenytoin should be considered, especially since neuroblastoma was reported recently in two children with phenytoin-induced malformations. following combination chemotherapy for metastases, the patient experienced a 7-year disease-free interval, which is consistent with recent improvement in the treatment of soft-tissue sarcomas.",
            "contribution_ids": [
                "R28530"
            ]
        },
        {
            "instance_id": "R28614xR28609",
            "comparison_id": "R28614",
            "paper_id": "R28609",
            "text": "Undifferentiated embryonal sarcoma of the liver mimicking acute appendicitis. Case report and review of the literature abstract \\n \\n background \\n undifferentiated embryonal sarcoma (ues) of liver is a rare malignant neoplasm, which affects mostly the pediatric population accounting for 13% of pediatric hepatic malignancies, a few cases has been reported in adults. \\n \\n \\n case presentation \\n we report a case of undifferentiated embryonal sarcoma of the liver in a 20-year-old caucasian male. the patient was referred to us for further investigation after a laparotomy in a district hospital for spontaneous abdominal hemorrhage, which was due to a liver mass. after a through evaluation with computed tomography scan and magnetic resonance imaging of the liver and taking into consideration the previous history of the patient, it was decided to surgically explore the patient. resection of i\u2013iv and viii hepatic lobe. patient developed disseminated intravascular coagulation one day after the surgery and died the next day. \\n \\n \\n conclusion \\n it is a rare, highly malignant hepatic neoplasm, affecting almost exclusively the pediatric population. the prognosis is poor but recent evidence has shown that long-term survival is possible after complete surgical resection with or without postoperative chemotherapy. \\n",
            "contribution_ids": [
                "R28610"
            ]
        },
        {
            "instance_id": "R28614xR28567",
            "comparison_id": "R28614",
            "paper_id": "R28567",
            "text": "Embryonal sarcoma of the liver in an adult treated with preoperative chemotherapy, radiation therapy, and hepatic lobectomy a rare case of embryonal sarcoma of the liver in a 28\u2010year\u2010old man is reported. the patient was treated preoperatively with a combination of chemotherapy and radiation therapy. complete surgical resection, 4.5 months after diagnosis, consisted of a left hepatic lobectomy. no viable tumor was found in the operative specimen. the patient was disease\u2010free 20 months postoperatively.",
            "contribution_ids": [
                "R28568"
            ]
        },
        {
            "instance_id": "R28614xR28569",
            "comparison_id": "R28614",
            "paper_id": "R28569",
            "text": "Undifferentiated (embryonal) sarcoma of the liver: Pathologic findings and long-term survival after complete surgical resection undifferentiated (embryonal) sarcoma of liver is a rare tumor with a reputed poor prognosis. four patients with this tumor are reported, of whom three were alive without recurrence 1.5, 2.5, and 12 years after initial complete surgical resection, and two of whom received no adjuvant therapy. the fourth patient, in whom complete surgical resection of tumor was not achieved, died with recurrent tumor at 13 months. the latter tumor differed histologically and consisted mainly of closely packed smaller undifferentiated cells with a higher mitotic and apoptotic rate. eosinophilic globules, characteristic of embryonal sarcoma, were found in some cases to contain condensed nuclear chromatin, evidence of origin from tumor cells dying by apoptosis. one tumor mainly contained large cysts lined by biliary\u2010type epithelium; this suggested an origin from a multipotent precursor cell able to differentiate along both stromal and epithelial lines.",
            "contribution_ids": [
                "R28570",
                "R28571"
            ]
        },
        {
            "instance_id": "R28614xR28574",
            "comparison_id": "R28614",
            "paper_id": "R28574",
            "text": "Undifferentiated sarcoma of the liver in childhood undifferentiated (embryonal) sarcoma of the liver (uesl) is a rare childhood hepatic tumor, and it is generally considered an aggressive neoplasm with an unfavorable prognosis.",
            "contribution_ids": [
                "R28575"
            ]
        },
        {
            "instance_id": "R28614xR28576",
            "comparison_id": "R28614",
            "paper_id": "R28576",
            "text": "Undifferentiated embryonal sarcoma of the liver imaging findings case 1: initial abdominal ultrasound scan demonstrated a large heterogeneous, echogenic mass within the liver displaying poor blood flow (figure 1). a contrast-enhanced ct scan of the chest, abdomen and pelvis was then performed, revealing a well-defined, hypodense mass in the right lobe of the liver (figure 2) measuring approximately 11.3 cm ap x 9.8 cm transverse x 9.2 cm in the sagittal plane. an arterial phase ct scan showed a hypodense mass with a hyperdense rim (figure 3a) and a delayed venous phase scan showed the low-density mass with areas of increased density displaying the solid nature of the lesion (figure 3a). these findings combined with biopsy confirmed undifferentiated embryonal sarcoma (ues). case 2: an abdominal ultrasound scan initially revealed a large heterogeneous lesion in the center of the liver with a small amount of blood flow (figure 4). inconclusive ultrasound results warranted a ct scan of the chest, abdomen and pelvis with contrast, which showed a heterogeneous low-density lesion within the right lobe of the liver that extended to the left lobe (figure 5). the mass measured approximately 12.3 ap x 12.3 transverse x 10.7 in the sagittal plane. arterial-phase ct showed a well-defined hypodense mass with vessels coursing throughout (figure 6a). delayed venous phase demonstrated the solid consistency of the mass by showing continued filling in of the mass (figure 6b). a pet scan was done to evaluate the extent of the disease. fdg-avid tissue was documented in the large lobulated hepatic mass (figure 7a,7b).",
            "contribution_ids": [
                "R28577",
                "R28578",
                "R28580",
                "R28581",
                "R28582"
            ]
        },
        {
            "instance_id": "R28889xR28848",
            "comparison_id": "R28889",
            "paper_id": "R28848",
            "text": "Generating Integration Test Orders for Aspect-Oriented Software with Multi-objective Algorithms \"the problem known as caito refers to the determination of an order to integrate and test classes and aspects that minimizes stubbing costs. such problem is np-hard and to solve it efficiently, search based algorithms have been used, mainly evolutionary ones. however, the problem is very complex since it involves different factors that may influence the stubbing process, such as complexity measures, contractual issues and so on. these factors are usually in conflict and different possible solutions for the problem exist. to deal properly with this problem, this work explores the use of multi-objective optimization algorithms. the paper presents results from the application of two evolutionary algorithms - nsga-ii and spea2 - to the caito problem in four real systems, implemented in aspectj. both multi-objective algorithms are evaluated and compared with the traditional tarjan's algorithm and with a mono-objective genetic algorithm. moreover, it is shown how the tester can use the found solutions, according to the test goals.\"",
            "contribution_ids": [
                "R28849"
            ]
        },
        {
            "instance_id": "R28889xR28793",
            "comparison_id": "R28889",
            "paper_id": "R28793",
            "text": "Multiobjective Optimization of SLA-Aware Service Composition in service oriented architecture, each application is often designed as a set of abstract services, which defines its functions. a concrete service(s) is selected at runtime for each abstract service to fulfill its function. since different concrete services may operate at different quality of service measures, application developers are required to select an appropriate set of concrete services that satisfies a given service level agreement when a number of concrete services are available for each abstract service. this problem, the qos-aware service composition problem, is known np-hard, which takes a significant amount of time and costs to find optimal solutions (optimal combinations of concrete services) from a huge number of possible solutions. this paper proposes an optimization framework, called e3, to address the issue. by leveraging a multiobjective genetic algorithm, e3 heuristically solves the qos-aware service composition problem in a reasonably short time. the algorithm e3 proposes can consider multiple slas simultaneously and produce a set of pareto solutions, which have the equivalent quality to satisfy multiple slas.",
            "contribution_ids": [
                "R28794"
            ]
        },
        {
            "instance_id": "R28889xR28808",
            "comparison_id": "R28889",
            "paper_id": "R28808",
            "text": "An Analysis of the Effects of Composite Objectives in Multiobjective Software Module Clustering the application of multiobjective optimization to address software engineering problems is a growing trend. multiobjective algorithms provide a balance between the ability of the computer to search a large solution space for valuable solutions and the capacity of the human decision-maker to select an alternative when two or more incomparable objectives are presented. however, when more than a single objective is available, the set of objectives to be considered by the search becomes part of the decision. in this paper, we address the efficiency and effectiveness of using two composite objectives while searching solutions for the software clustering problem. we designed an experimental study which shows that a multiobjective genetic algorithm can find a set of solutions with increased quality and using less processing time if these composite objectives are suppressed from the formulation for the software clustering problem.",
            "contribution_ids": [
                "R28809"
            ]
        },
        {
            "instance_id": "R28889xR28619",
            "comparison_id": "R28889",
            "paper_id": "R28619",
            "text": "The Multi- Objective Next Release Problem this paper is concerned with the multi-objective next release problem (monrp), a problem in search-based requirements engineering. previous work has considered only single objective formulations. in the multi-objective formulation, there are at least two (possibly conflicting) objectives that the software engineer wishes to optimize. it is argued that the multi-objective formulation is more realistic, since requirements engineering is characterised by the presence of many complex and conflicting demands, for which the software engineer must find a suitable balance. the paper presents the results of an empirical study into the suitability of weighted and pareto optimal genetic algorithms, together with the nsga-ii algorithm, presenting evidence to support the claim that nsga-ii is well suited to the monrp. the paper also provides benchmark data to indicate the size above which the monrp becomes non--trivial.",
            "contribution_ids": [
                "R28620",
                "R28774"
            ]
        },
        {
            "instance_id": "R28889xR28637",
            "comparison_id": "R28889",
            "paper_id": "R28637",
            "text": "Simulating and Optimising Design Decisions in Quantitative Goal Models \"making decisions among a set of alternative system designs is an essential activity of requirements engineering. it involves evaluating how well each alternative satisfies the stakeholders' goals and selecting one alternative that achieves some optimal tradeoffs between possibly conflicting goals. quantitative goal models support such activities by describing how alternative system designs \u2014 expressed as alternative goal refinements and responsibility assignments \u2014 impact on the levels of goal satisfaction specified in terms of measurable objective functions. analyzing large numbers of alternative designs in such models is an expensive activity for which no dedicated tool support is currently available. this paper takes a first step towards providing such support by presenting automated techniques for (i) simulating quantitative goal models so as to estimate the levels of goal satisfaction contributed by alternative system designs and (ii) optimising the system design by applying a multi-objective optimisation algorithm to search through the design space. these techniques are presented and validated using a quantitative goal model for a well-known ambulance service system.\"",
            "contribution_ids": [
                "R28638",
                "R28780"
            ]
        },
        {
            "instance_id": "R28889xR28654",
            "comparison_id": "R28889",
            "paper_id": "R28654",
            "text": "A Multiobjective Module-Order Model for Software Quality Enhancement the knowledge, prior to system operations, of which program modules are problematic is valuable to a software quality assurance team, especially when there is a constraint on software quality enhancement resources. a cost-effective approach for allocating such resources is to obtain a prediction in the form of a quality-based ranking of program modules. subsequently, a module-order model (mom) is used to gauge the performance of the predicted rankings. from a practical software engineering point of view, multiple software quality objectives may be desired by a mom for the system under consideration: e.g., the desired rankings may be such that 100% of the faults should be detected if the top 50% of modules with highest number of faults are subjected to quality improvements. moreover, the management team for the same system may also desire that 80% of the faults should be accounted if the top 20% of the modules are targeted for improvement. existing work related to mom(s) use a quantitative prediction model to obtain the predicted rankings of program modules, implying that only the fault prediction error measures such as the average, relative, or mean square errors are minimized. such an approach does not provide a direct insight into the performance behavior of a mom. for a given percentage of modules enhanced, the performance of a mom is gauged by how many faults are accounted for by the predicted ranking as compared with the perfect ranking. we propose an approach for calibrating a multiobjective mom using genetic programming. other estimation techniques, e.g., multiple linear regression and neural networks cannot achieve multiobjective optimization for mom(s). the proposed methodology facilitates the simultaneous optimization of multiple performance objectives for a mom. case studies of two industrial software systems are presented, the empirical results of which demonstrate a new promise for goal-oriented software quality modeling.",
            "contribution_ids": [
                "R28655",
                "R28784"
            ]
        },
        {
            "instance_id": "R28889xR28831",
            "comparison_id": "R28889",
            "paper_id": "R28831",
            "text": "Generating Feasible Test Paths from an Executable Model Using a Multi-Objective Approach search-based testing techniques using meta-heuristics, like evolutionary algorithms, has been largely used for test data generation, but most approaches were proposed for white-box testing. in this paper we present an evolutionary approach for test sequence generation from a behavior model, in particular, extended finite state machine. an open problem is the production of infeasible paths, as these should be detected and discarded manually. to circumvent this problem, we use an executable model to obtain feasible paths dynamically. an evolutionary algorithm is used to search for solutions that cover a given test purpose, which is a transition of interest. the target transition is used as a criterion to get slicing information, in this way, helping to identify the parts of the model that affect the test purpose. we also present a multi-objective search: the test purpose coverage and the sequence size minimization, as longer sequences require more effort to be executed.",
            "contribution_ids": [
                "R28832"
            ]
        },
        {
            "instance_id": "R28889xR28842",
            "comparison_id": "R28889",
            "paper_id": "R28842",
            "text": "Multi-Objective Approaches to Optimal Testing Resource Allocation in Modular Software Systems software testing is an important issue in software engineering. as software systems become increasingly large and complex, the problem of how to optimally allocate the limited testing resource during the testing phase has become more important, and difficult. traditional optimal testing resource allocation problems (otraps) involve seeking an optimal allocation of a limited amount of testing resource to a number of activities with respect to some objectives (e.g., reliability, or cost). we suggest solving otraps with multi-objective evolutionary algorithms (moeas). specifically, we formulate otraps as two types of multi-objective problems. first, we consider the reliability of the system and the testing cost as two objectives. second, the total testing resource consumed is also taken into account as the third objective. the advantages of moeas over state-of-the-art single objective approaches to otraps will be shown through empirical studies. our study has revealed that a well-known moea, namely nondominated sorting genetic algorithm ii (nsga-ii), performs well on the first problem formulation, but fails on the second one. hence, a harmonic distance based multi-objective evolutionary algorithm (had-moea) is proposed and evaluated in this paper. comprehensive experimental studies on both parallel-series, and star-structure modular software systems have shown the superiority of had-moea over nsga-ii for otraps.",
            "contribution_ids": [
                "R28843"
            ]
        },
        {
            "instance_id": "R28889xR28817",
            "comparison_id": "R28889",
            "paper_id": "R28817",
            "text": "Search-based Genetic Optimization for Deployment and Reconfiguration of Software in the Cloud migrating existing enterprise software to cloud platforms involves the comparison of competing cloud deployment options (cdos). a cdo comprises a combination of a specific cloud environment, deployment architecture, and runtime reconfiguration rules for dynamic resource scaling. our simulator cdosim can evaluate cdos, e.g., regarding response times and costs. however, the design space to be searched for well-suited solutions is extremely huge. in this paper, we approach this optimization problem with the novel genetic algorithm cdoxplorer. it uses techniques of the search-based software engineering field and cdosim to assess the fitness of cdos. an experimental evaluation that employs, among others, the cloud environments amazon ec2 and microsoft windows azure, shows that cdoxplorer can find solutions that surpass those of other state-of-the-art techniques by up to 60%. our experiment code and data and an implementation of cdoxplorer are available as open source software.",
            "contribution_ids": [
                "R28818"
            ]
        },
        {
            "instance_id": "R28889xR28880",
            "comparison_id": "R28889",
            "paper_id": "R28880",
            "text": "Single and Multi Objective Genetic Programming for Software Development Effort Estimation the idea of exploiting genetic programming (gp) to estimate software development effort is based on the observation that the effort estimation problem can be formulated as an optimization problem. indeed, among the possible models, we have to identify the one providing the most accurate estimates. to this end a suitable measure to evaluate and compare different models is needed. however, in the context of effort estimation there does not exist a unique measure that allows us to compare different models but several different criteria (e.g., mmre, pred(25), mdmre) have been proposed. aiming at getting an insight on the effects of using different measures as fitness function, in this paper we analyzed the performance of gp using each of the five most used evaluation criteria. moreover, we designed a multi-objective genetic programming (mogp) based on pareto optimality to simultaneously optimize the five evaluation measures and analyzed whether mogp is able to build estimation models more accurate than those obtained using gp. the results of the empirical analysis, carried out using three publicly available datasets, showed that the choice of the fitness function significantly affects the estimation accuracy of the models built with gp and the use of some fitness functions allowed gp to get estimation accuracy comparable with the ones provided by mogp.",
            "contribution_ids": [
                "R28881"
            ]
        },
        {
            "instance_id": "R28889xR28823",
            "comparison_id": "R28889",
            "paper_id": "R28823",
            "text": "A Multi-Objective Approach to Search-based Test Data Generation there has been a considerable body of work on search-based test data generation for branch coverage. however, hitherto, there has been no work on multi-objective branch coverage. in many scenarios a single-objective formulation is unrealistic; testers will want to find test sets that meet several objectives simultaneously in order to maximize the value obtained from the inherently expensive process of running the test cases and examining the output they produce. this paper introduces multi-objective branch coverage.the paper presents results from a case study of the twin objectives of branch coverage and dynamic memory consumption for both real and synthetic programs. several multi-objective evolutionary algorithms are applied. the results show that multi-objective evolutionary algorithms are suitable for this problem, and illustrates the way in which a pareto optimal search can yield insights into the trade-offs between the two simultaneous objectives.",
            "contribution_ids": [
                "R28824"
            ]
        },
        {
            "instance_id": "R28889xR28887",
            "comparison_id": "R28889",
            "paper_id": "R28887",
            "text": "The human competitiveness of search based software engineering this paper reports a comprehensive experimental study regarding the human competitiveness of search based software engineering (sbse). the experiments were performed over four well-known sbse problem formulations: next release problem, multi-objective next release problem, workgroup formation problem and the multi-objective test case selection problem. for each of these problems, two instances, with increasing sizes, were synthetically generated and solved by both metaheuristics and human subjects. a total of 63 professional software engineers participated in the experiment by solving some or all problem instances, producing together 128 responses. the comparison analysis strongly suggests that the results generated by search based software engineering can be said to be human competitive.",
            "contribution_ids": [
                "R28888"
            ]
        },
        {
            "instance_id": "R28889xR28877",
            "comparison_id": "R28889",
            "paper_id": "R28877",
            "text": "A Hybrid Approach to Solve the Agile Team Allocation Problem the success of the team allocation in a agile software development project is essential. the agile team allocation is a np-hard problem, since it comprises the allocation of self-organizing and cross-functional teams. many researchers have driven efforts to apply computational intelligence techniques to solve this problem. this work presents a hybrid approach based on nsga-ii multi-objective metaheuristic and mamdani fuzzy inference systems to solve the agile team allocation problem, together with an initial evaluation of its use in a real environment.",
            "contribution_ids": [
                "R28878"
            ]
        },
        {
            "instance_id": "R28889xR28826",
            "comparison_id": "R28889",
            "paper_id": "R28826",
            "text": "A Multi-objective Approach to Testing Resource Allocation in Modular Software Systems nowadays, as the software systems become increasingly large and complex, the problem of allocating the limited testing-resource during the testing phase has become more and more difficult. in this paper, we propose to solve the testing-resource allocation problem (trap) using multi-objective evolutionary algorithms. specifically, we formulate trap as two multi-objective problems. first, we consider the reliability of the system and the testing cost as two objectives. in the second formulation, the total testing-resource consumed is also taken into account as the third goal. two multi-objective evolutionary algorithms, non-dominated sorting genetic algorithm ii (nsga2) and multi-objective differential evolution algorithms (mode), are applied to solve the trap in the two scenarios. this is the first time that the trap is explicitly formulated and solved by multi-objective evolutionary approaches. advantages of our approaches over the state-of-the-art single-objective approaches are demonstrated on two parallel-series modular software models.",
            "contribution_ids": [
                "R28827"
            ]
        },
        {
            "instance_id": "R28889xR28805",
            "comparison_id": "R28889",
            "paper_id": "R28805",
            "text": "Software Module Clustering as a Multi-Objective Search Problem software module clustering is the problem of automatically organizing software units into modules to improve program structure. there has been a great deal of recent interest in search-based formulations of this problem in which module boundaries are identified by automated search, guided by a fitness function that captures the twin objectives of high cohesion and low coupling in a single-objective fitness function. this paper introduces two novel multi-objective formulations of the software module clustering problem, in which several different objectives (including cohesion and coupling) are represented separately. in order to evaluate the effectiveness of the multi-objective approach, a set of experiments was performed on 17 real-world module clustering problems. the results of this empirical study provide strong evidence to support the claim that the multi-objective approach produces significantly better solutions than the existing single-objective approach.",
            "contribution_ids": [
                "R28806"
            ]
        },
        {
            "instance_id": "R28889xR28873",
            "comparison_id": "R28889",
            "paper_id": "R28873",
            "text": "Using Multi- objective Metaheuristics to Solve the Software Project Scheduling Problem the software project scheduling (sps) problem relates to the decision of who does what during a software project lifetime. this problem has a capital importance for software companies. in the sps problem, the total budget and human resources involved in software development must be optimally managed in order to end up with a successful project. companies are mainly concerned with reducing both the duration and the cost of the projects, and these two goals are in conflict with each other. a multi-objective approach is therefore the natural way of facing the sps problem. in this paper, a number of multi-objective metaheuristics have been used to address this problem. they have been thoroughly compared over a set of 36 publicly available instances that cover a wide range of different scenarios. the resulting project schedulings of the algorithms have been analyzed in order to show their relevant features. the algorithms used in this paper and the analysis performed may assist project managers in the difficult task of deciding who does what in a software project.",
            "contribution_ids": [
                "R28874"
            ]
        },
        {
            "instance_id": "R28889xR28861",
            "comparison_id": "R28889",
            "paper_id": "R28861",
            "text": "A Multi-Objective Software Quality Classification Model Using Genetic Programming a key factor in the success of a software project is achieving the best-possible software reliability within the allotted time & budget. classification models which provide a risk-based software quality prediction, such as fault-prone & not fault-prone, are effective in providing a focused software quality assurance endeavor. however, their usefulness largely depends on whether all the predicted fault-prone modules can be inspected or improved by the allocated software quality-improvement resources, and on the project-specific costs of misclassifications. therefore, a practical goal of calibrating classification models is to lower the expected cost of misclassification while providing a cost-effective use of the available software quality-improvement resources. this paper presents a genetic programming-based decision tree model which facilitates a multi-objective optimization in the context of the software quality classification problem. the first objective is to minimize the \"modified expected cost of misclassification\", which is our recently proposed goal-oriented measure for selecting & evaluating classification models. the second objective is to optimize the number of predicted fault-prone modules such that it is equal to the number of modules which can be inspected by the allocated resources. some commonly used classification techniques, such as logistic regression, decision trees, and analogy-based reasoning, are not suited for directly optimizing multi-objective criteria. in contrast, genetic programming is particularly suited for the multi-objective optimization problem. an empirical case study of a real-world industrial software system demonstrates the promising results, and the usefulness of the proposed model",
            "contribution_ids": [
                "R28862"
            ]
        },
        {
            "instance_id": "R28889xR28884",
            "comparison_id": "R28889",
            "paper_id": "R28884",
            "text": "Not Going to Take this Anymore: Multi-Objective Overtime Planning for Software Engineering Projects software engineering and development is well-known to suffer from unplanned overtime, which causes stress and illness in engineers and can lead to poor quality software with higher defects. in this paper, we introduce a multi-objective decision support approach to help balance project risks and duration against overtime, so that software engineers can better plan overtime. we evaluate our approach on 6 real world software projects, drawn from 3 organisations using 3 standard evaluation measures and 3 different approaches to risk assessment. our results show that our approach was significantly better (p <; 0.05) than standard multi-objective search in 76% of experiments (with high cohen effect size in 85% of these) and was significantly better than currently used overtime planning strategies in 100% of experiments (with high effect size in all). we also show how our approach provides actionable overtime planning results and investigate the impact of the three different forms of risk assessment.",
            "contribution_ids": [
                "R28885"
            ]
        },
        {
            "instance_id": "R28889xR28621",
            "comparison_id": "R28889",
            "paper_id": "R28621",
            "text": "Fairness Analysis\u00e2\u0080\u009d in Requirements Assignments requirements engineering for multiple customers, each of whom have competing and often conflicting priorities, raises issues of negotiation, mediation and conflict resolution. this paper uses a multi-objective optimisation approach to support investigation of the trade-offs in various notions of fairness between multiple customers. results are presented to validate the approach using two real-world data sets and also using data sets created specifically to stress test the approach. simple graphical techniques are used to visualize the solution space.",
            "contribution_ids": [
                "R28622",
                "R28775"
            ]
        },
        {
            "instance_id": "R28889xR28647",
            "comparison_id": "R28889",
            "paper_id": "R28647",
            "text": "Software Requirements Selection using Quantum-inspired Elitist Multi- objective Evolutionary Algorithm this paper presents a quantum-inspired multi-objective differential evolution algorithm (qmdea) for the selection of software requirements, an issue in requirements engineering phase of software development life cycle. generally the software development process is iterative or incremental in nature, as request for new requirements keep coming from the customers from time to time for inclusion in the next release of the software. due to the feasibility reasons it is not possible for a company to incorporate all the requirements in the software product. consequently, it becomes a challenging task for the company to select a subset of the requirements to be included, by keeping the business goals in view. the problem is to identify a set of requirements to be included in the next release of the product, by minimizing the cost and maximizing the customer satisfaction. as minimizing the cost and maximizing the customer satisfaction are contradictory objectives, the problem is multi-objective and is also np-hard in nature. therefore it cannot be solved efficiently using traditional optimization techniques especially for the large problem instances. qmdea combines the preeminent features of differential evolution and quantum computing. the features of qmdea help in achieving quality pareto-optimal front solutions with faster convergence. the performance of qmdea is tested on six benchmark problems derived from the literature. the comparison of the obtained results indicates superior performance over the other methods reported in the literature.",
            "contribution_ids": [
                "R28648",
                "R28782"
            ]
        },
        {
            "instance_id": "R28889xR28790",
            "comparison_id": "R28889",
            "paper_id": "R28790",
            "text": "Optimal Web Service Selection based on Multi-Objective Genetic Algorithm \"considering that there are three aspects of constrains in the service selection process, such as control structure within a composition plan, relationship between concrete services, and tradeoff among multiple qos indexes, a qos based optimal web services selection method by multi-objective genetic algorithm is presented. first we design a chromosome coding method to represent a feasible service selection solution, and then develop genetic operators and strategies for maintaining diversity of population and avoiding getting trapped in local optima. experimental results show that within a finite number of evolving generations this algorithm can generate a set of nondominated pareto optimal sol.utions which satisfy to user's qos requirements.\"",
            "contribution_ids": [
                "R28791"
            ]
        },
        {
            "instance_id": "R28889xR28799",
            "comparison_id": "R28889",
            "paper_id": "R28799",
            "text": "Solving the Class Responsibility Assignment Problem in Object-Oriented Analysis with Multi-Objective Genetic Algorithms in the context of object-oriented analysis and design (ooad), class responsibility assignment is not an easy skill to acquire. though there are many methodologies for assigning responsibilities to classes, they all rely on human judgment and decision making. our objective is to provide decision-making support to reassign methods and attributes to classes in a class diagram. our solution is based on a multi-objective genetic algorithm (moga) and uses class coupling and cohesion measurement for defining fitness functions. our moga takes as input a class diagram to be optimized and suggests possible improvements to it. the choice of a moga stems from the fact that there are typically many evaluation criteria that cannot be easily combined into one objective, and several alternative solutions are acceptable for a given oo domain model. using a carefully selected case study, this paper investigates the application of our proposed moga to the class responsibility assignment problem, in the context of object-oriented analysis and domain class models. our results suggest that the moga can help correct suboptimal class responsibility assignment decisions and perform far better than simpler alternative heuristics such as hill climbing and a single-objective ga.",
            "contribution_ids": [
                "R28800"
            ]
        },
        {
            "instance_id": "R28889xR28797",
            "comparison_id": "R28889",
            "paper_id": "R28797",
            "text": "Interactive, evolutionary search in upstream object-oriented class design although much evidence exists to suggest that early life cycle software engineering design is a difficult task for software engineers to perform, current computational tool support for software engineers is limited. to address this limitation, interactive search-based approaches using evolutionary computation and software agents are investigated in experimental upstream design episodes for two example design domains. results show that interactive evolutionary search, supported by software agents, appears highly promising. as an open system, search is steered jointly by designer preferences and software agents. directly traceable to the design problem domain, a mass of useful and interesting class designs is arrived at which may be visualized by the designer with quantitative measures of structural integrity, such as design coupling and class cohesion. the class designs are found to be of equivalent or better coupling and cohesion when compared to a manual class design for the example design domains, and by exploiting concurrent execution, the runtime performance of the software agents is highly favorable.",
            "contribution_ids": [
                "R28798"
            ]
        },
        {
            "instance_id": "R28889xR28866",
            "comparison_id": "R28889",
            "paper_id": "R28866",
            "text": "A Multi-objective approach to Redundancy Allocation Problem in Parallel-series systems the redundancy allocation problem (rap) is a kind of reliability optimization problems. it involves the selection of components with appropriate levels of redundancy or reliability to maximize the system reliability under some predefined constraints. we can formulate the rap as a combinatorial problem when just considering the redundancy level, while as a continuous problem when considering the reliability level. the rap employed in this paper is that kind of combinatorial optimization problems. during the past thirty years, there have already been a number of investigations on rap. however, these investigations often treat rap as a single objective problem with the only goal to maximize the system reliability (or minimize the designing cost). in this paper, we regard rap as a multi-objective optimization problem: the reliability of the system and the corresponding designing cost are considered as two different objectives. consequently, we can utilize a classical multi-objective evolutionary algorithm (moea), named non-dominated sorting genetic algorithm ii (nsga-ii), to cope with this multi-objective redundancy allocation problem (morap) under a number of constraints. the experimental results demonstrate that the multi-objective evolutionary approach can provide more promising solutions in comparison with two widely used single-objective approaches on two parallel-series systems which are frequently studied in the field of reliability optimization.",
            "contribution_ids": [
                "R28867"
            ]
        },
        {
            "instance_id": "R28889xR28641",
            "comparison_id": "R28889",
            "paper_id": "R28641",
            "text": "Understanding Clusters of Optimal Solutions in Multi-Objective Decision Problems multi-objective decisions problems are ubiquitous in requirements engineering. a common approach to solve them is to apply search-based techniques to generate a set of non-dominated solutions, formally known as the pareto front, that characterizes all solutions for which no other solution performs better on all objectives simultaneously. analysing the shape of the pareto front helps decision makers understand the solution space and possible tradeoffs among the conflicting objectives. interpreting the optimal solutions, however, remains a significant challenge. it is in particular difficult to identify whether solutions that have similar levels of goals attainment correspond to minor variants within a same design or to very different designs involving completely different sets of decisions. our goal is to help decision makers identify groups of strongly related solutions in a pareto front so that they can understand more easily the range of design choices, identify areas where strongly different solutions achieve similar levels of objectives, and decide first between major groups of solutions before deciding for a particular variant within the chosen group. the benefits of the approach are illustrated on a small example and validated on a larger independently-produced example representative of industrial problems.",
            "contribution_ids": [
                "R28642",
                "R28781"
            ]
        },
        {
            "instance_id": "R28889xR28812",
            "comparison_id": "R28889",
            "paper_id": "R28812",
            "text": "Multi- objective Coevolutionary Automated Software Correction \"for a given program, testing, locating the errors identified, and correcting those errors is a critical, yet expensive process. the field of search based software engineering (sbse) addresses these phases by formulating them as search problems. the coevolutionary automated software correction (casc) system targets the correction phase by coevolving test cases and programs at the source code level. this paper presents the latest version of the casc system featuring multi-objective optimization and an enhanced representation language. results are presented demonstrating casc's ability to successfully correct five seeded bugs in two non-trivial programs from the siemens test suite. additionally, evidence is provided substantiating the hypothesis that multi-objective optimization is beneficial to sbse.\"",
            "contribution_ids": [
                "R28813"
            ]
        },
        {
            "instance_id": "R28889xR28661",
            "comparison_id": "R28889",
            "paper_id": "R28661",
            "text": "Solving Multi- objective and Fuzzy Multi-attributive Integrated Technique for QoS-Aware Web Service Selection \"the paper focuses on developing a new multiple criteria decision-making (mcdm) methodology for global web services selection based on qos criteria, which integrates the multi-objective optimization with a fuzzy multi-attributive group decision-making (fmagdm) technique. the study concentrates on the task of finding and then evaluating (or ranking) the finite number of pareto-optimal design alternatives (podas). a genetic algorithm based multi-objective optimization technique is employed for optimization purpose in terms of experts' opinions. subjective attribute based aggregation technique for homogeneous and heterogeneous groups of experts is employed and used for dealing with the fuzzy opinion aggregation. finally, we will discuss the integrated technique for web services selection on global qos optimization.\"",
            "contribution_ids": [
                "R28662",
                "R28786"
            ]
        },
        {
            "instance_id": "R28889xR28629",
            "comparison_id": "R28889",
            "paper_id": "R28629",
            "text": "Today/Future Importance Analysis sbse techniques have been widely applied to requirements selection and prioritization problems in order to ascertain a suitable set of requirements for the next release of a system. unfortunately, it has been widely observed that requirements tend to be changed as the development process proceeds and what is suitable for today, may not serve well into the future. though sbse has been widely applied to requirements analysis, there has been no previous work that seeks to balance the requirements needs of today with those of the future. this paper addresses this problem. it introduces a multi-objective formulation of the problem which is implemented using multi-objective pareto optimal evolutionary algorithms. the paper presents the results of experiments on both synthetic and real world data.",
            "contribution_ids": [
                "R28630",
                "R28777"
            ]
        },
        {
            "instance_id": "R29012xR28998",
            "comparison_id": "R29012",
            "paper_id": "R28998",
            "text": "Annotated facial landmarks in the wild: A large-scale, real- world database for facial landmark localization face alignment is a crucial step in face recognition tasks. especially, using landmark localization for geometric face normalization has shown to be very effective, clearly improving the recognition results. however, no adequate databases exist that provide a sufficient number of annotated facial landmarks. the databases are either limited to frontal views, provide only a small number of annotated images or have been acquired under controlled conditions. hence, we introduce a novel database overcoming these limitations: annotated facial landmarks in the wild (aflw). aflw provides a large-scale collection of images gathered from flickr, exhibiting a large variety in face appearance (e.g., pose, expression, ethnicity, age, gender) as well as general imaging and environmental conditions. in total 25,993 faces in 21,997 real-world images are annotated with up to 21 landmarks per image. due to the comprehensive set of annotations aflw is well suited to train and test algorithms for multi-view face detection, facial landmark localization and face pose estimation. further, we offer a rich set of tools that ease the integration of other face databases and associated annotations into our joint framework.",
            "contribution_ids": [
                "R28999",
                "R29107"
            ]
        },
        {
            "instance_id": "R29012xR28992",
            "comparison_id": "R29012",
            "paper_id": "R28992",
            "text": "XM2VTSDB: The extended M2VTS database keywords: vision reference epfl-conf-82502 url: ftp://ftp.idiap.ch/pub/papers/vision/avbpa99.pdf record created on 2006-03-10, modified on 2017-05-10",
            "contribution_ids": [
                "R28993"
            ]
        },
        {
            "instance_id": "R29012xR28984",
            "comparison_id": "R29012",
            "paper_id": "R28984",
            "text": "From few to many: illumination cone models for face recognition under variable lighting and pose we present a generative appearance-based method for recognizing human faces under variation in lighting and viewpoint. our method exploits the fact that the set of images of an object in fixed pose, but under all possible illumination conditions, is a convex cone in the space of images. using a small number of training images of each face taken with different lighting directions, the shape and albedo of the face can be reconstructed. in turn, this reconstruction serves as a generative model that can be used to render (or synthesize) images of the face under novel poses and illumination conditions. the pose space is then sampled and, for each pose, the corresponding illumination cone is approximated by a low-dimensional linear subspace whose basis vectors are estimated using the generative model. our recognition algorithm assigns to a test image the identity of the closest approximated illumination cone. test results show that the method performs almost without error, except on the most extreme lighting directions.",
            "contribution_ids": [
                "R28985"
            ]
        },
        {
            "instance_id": "R29012xR28988",
            "comparison_id": "R29012",
            "paper_id": "R28988",
            "text": "Comprehensive database for facial expression analysis within the past decade, significant effort has occurred in developing methods of facial expression analysis. because most investigators have used relatively limited data sets, the generalizability of these various methods remains unknown. we describe the problem space for facial expression analysis, which includes level of description, transitions among expressions, eliciting conditions, reliability and validity of training and test data, individual differences in subjects, head orientation and scene complexity image characteristics, and relation to non-verbal behavior. we then present the cmu-pittsburgh au-coded face expression image database, which currently includes 2105 digitized image sequences from 182 adult subjects of varying ethnicity, performing multiple tokens of most primary facs action units. this database is the most comprehensive testbed to date for comparative studies of facial expression analysis.",
            "contribution_ids": [
                "R28989"
            ]
        },
        {
            "instance_id": "R29012xR28994",
            "comparison_id": "R29012",
            "paper_id": "R28994",
            "text": "Overview of the Face Recognition Grand Challenge over the last couple of years, face recognition researchers have been developing new techniques. these developments are being fueled by advances in computer vision techniques, computer design, sensor design, and interest in fielding face recognition systems. such advances hold the promise of reducing the error rate in face recognition systems by an order of magnitude over face recognition vendor test (frvt) 2002 results. the face recognition grand challenge (frgc) is designed to achieve this performance goal by presenting to researchers a six-experiment challenge problem along with data corpus of 50,000 images. the data consists of 3d scans and high resolution still imagery taken under controlled and uncontrolled conditions. this paper describes the challenge problem, data corpus, and presents baseline performance and preliminary results on natural statistics of facial imagery.",
            "contribution_ids": [
                "R28995"
            ]
        },
        {
            "instance_id": "R29012xR29006",
            "comparison_id": "R29012",
            "paper_id": "R29006",
            "text": "A Semi-automatic Methodology for Facial Landmark Annotation developing powerful deformable face models requires massive, annotated face databases on which techniques can be trained, validated and tested. manual annotation of each facial image in terms of landmarks requires a trained expert and the workload is usually enormous. fatigue is one of the reasons that in some cases annotations are inaccurate. this is why, the majority of existing facial databases provide annotations for a relatively small subset of the training images. furthermore, there is hardly any correspondence between the annotated land-marks across different databases. these problems make cross-database experiments almost infeasible. to overcome these difficulties, we propose a semi-automatic annotation methodology for annotating massive face datasets. this is the first attempt to create a tool suitable for annotating massive facial databases. we employed our tool for creating annotations for multipie, xm2vts, ar, and frgc ver. 2 databases. the annotations will be made publicly available from http://ibug.doc.ic.ac.uk/ resources/facial-point-annotations/. finally, we present experiments which verify the accuracy of produced annotations.",
            "contribution_ids": [
                "R29007"
            ]
        },
        {
            "instance_id": "R29012xR28996",
            "comparison_id": "R29012",
            "paper_id": "R28996",
            "text": "A high-resolution 3D dynamic facial expression database face information processing relies on the quality of data resource. from the data modality point of view, a face database can be 2d or 3d, and static or dynamic. from the task point of view, the data can be used for research of computer based automatic face recognition, face expression recognition, face detection, or cognitive and psychological investigation. with the advancement of 3d imaging technologies, 3d dynamic facial sequences (called 4d data) have been used for face information analysis. in this paper, we focus on the modality of 3d dynamic data for the task of facial expression recognition. we present a newly created high-resolution 3d dynamic facial expression database, which is made available to the scientific research community. the database contains 606 3d facial expression sequences captured from 101 subjects of various ethnic backgrounds. the database has been validated through our facial expression recognition experiment using an hmm based 3d spatio-temporal facial descriptor. it is expected that such a database shall be used to facilitate the facial expression analysis from a static 3d space to a dynamic 3d space, with a goal of scrutinizing facial behavior at a higher level of detail in a real 3d spatio-temporal domain.",
            "contribution_ids": [
                "R28997",
                "R29084"
            ]
        },
        {
            "instance_id": "R29034xR29010",
            "comparison_id": "R29034",
            "paper_id": "R29010",
            "text": "Robust Face Landmark Estimation under Occlusion \"human faces captured in real-world conditions present large variations in shape and occlusions due to differences in pose, expression, use of accessories such as sunglasses and hats and interactions with objects (e.g. food). current face landmark estimation approaches struggle under such conditions since they fail to provide a principled way of handling outliers. we propose a novel method, called robust cascaded pose regression (rcpr) which reduces exposure to outliers by detecting occlusions explicitly and using robust shape-indexed features. we show that rcpr improves on previous landmark estimation methods on three popular face datasets (lfpw, lfw and helen). we further explore rcpr's performance by introducing a novel face dataset focused on occlusion, composed of 1,007 faces presenting a wide range of occlusion patterns. rcpr reduces failure cases by half on all four datasets, at the same time as it detects face occlusions with a 80/40% precision/recall.\"",
            "contribution_ids": [
                "R29011",
                "R29029",
                "R29063"
            ]
        },
        {
            "instance_id": "R29034xR29030",
            "comparison_id": "R29034",
            "paper_id": "R29030",
            "text": "One millisecond face alignment with an ensemble of regression trees \"this paper addresses the problem of face alignment for a single image. we show how an ensemble of regression trees can be used to estimate the face's landmark positions directly from a sparse subset of pixel intensities, achieving super-realtime performance with high quality predictions. we present a general framework based on gradient boosting for learning an ensemble of regression trees that optimizes the sum of square error loss and naturally handles missing or partially labelled data. we show how using appropriate priors exploiting the structure of image data helps with efficient feature selection. different regularization strategies and its importance to combat overfitting are also investigated. in addition, we analyse the effect of the quantity of training data on the accuracy of the predictions and explore the effect of data augmentation using synthesized data.\"",
            "contribution_ids": [
                "R29031",
                "R29065"
            ]
        },
        {
            "instance_id": "R29034xR29032",
            "comparison_id": "R29034",
            "paper_id": "R29032",
            "text": "Face Alignment at 3000 FPS via Regressing Local Binary Features this paper presents a highly efficient, very accurate regression approach for face alignment. our approach has two novel components: a set of local binary features, and a locality principle for learning those features. the locality principle guides us to learn a set of highly discriminative local binary features for each facial landmark independently. the obtained local binary features are used to jointly learn a linear regression for the final output. our approach achieves the state-of-the-art results when tested on the current most challenging benchmarks. furthermore, because extracting and regressing local binary features is computationally very cheap, our system is much faster than previous methods. it achieves over 3, 000 fps on a desktop or 300 fps on a mobile phone for locating a few dozens of landmarks.",
            "contribution_ids": [
                "R29033",
                "R29061"
            ]
        },
        {
            "instance_id": "R29034xR29025",
            "comparison_id": "R29034",
            "paper_id": "R29025",
            "text": "Regressing a 3D Face Shape from a Single Image in this work we present a method to estimate a 3d face shape from a single image. our method is based on a cascade regression framework that directly estimates face landmarks locations in 3d. we include the knowledge that a face is a 3d object into the learning pipeline and show how this information decreases localization errors while keeping the computational time low. we predict the actual positions of the landmarks even if they are occluded due to face rotation. to support the ability of our method to reliably reconstruct 3d shapes, we introduce a simple method for head pose estimation using a single image that reaches higher accuracy than the state of the art. comparison of 3d face landmarks localization with the available state of the art further supports the feasibility of a single-step face shape estimation. the code, trained models and our 3d annotations will be made available to the research community.",
            "contribution_ids": [
                "R29026"
            ]
        },
        {
            "instance_id": "R29034xR29023",
            "comparison_id": "R29034",
            "paper_id": "R29023",
            "text": "Supervised descent method and its applications to face alignment many computer vision problems (e.g., camera calibration, image alignment, structure from motion) are solved through a nonlinear optimization method. it is generally accepted that 2nd order descent methods are the most robust, fast and reliable approaches for nonlinear optimization of a general smooth function. however, in the context of computer vision, 2nd order descent methods have two main drawbacks: (1) the function might not be analytically differentiable and numerical approximations are impractical. (2) the hessian might be large and not positive definite. to address these issues, this paper proposes a supervised descent method (sdm) for minimizing a non-linear least squares (nls) function. during training, the sdm learns a sequence of descent directions that minimizes the mean of nls functions sampled at different points. in testing, sdm minimizes the nls objective using the learned descent directions without computing the jacobian nor the hessian. we illustrate the benefits of our approach in synthetic and real examples, and show how sdm achieves state-of-the-art performance in the problem of facial feature detection. the code is available at www.humansensing.cs. cmu.edu/intraface.",
            "contribution_ids": [
                "R29024",
                "R29059"
            ]
        },
        {
            "instance_id": "R29034xR28977",
            "comparison_id": "R29034",
            "paper_id": "R28977",
            "text": "Face Alignment Across Large Poses: A 3D Solution face alignment, which fits a face model to an image and extracts the semantic meanings of facial pixels, has been an important topic in cv community. however, most algorithms are designed for faces in small to medium poses (below 45), lacking the ability to align faces in large poses up to 90. the challenges are three-fold: firstly, the commonly used landmark-based face model assumes that all the landmarks are visible and is therefore not suitable for profile views. secondly, the face appearance varies more dramatically across large poses, ranging from frontal view to profile view. thirdly, labelling landmarks in large poses is extremely challenging since the invisible landmarks have to be guessed. in this paper, we propose a solution to the three problems in an new alignment framework, called 3d dense face alignment (3ddfa), in which a dense 3d face model is fitted to the image via convolutional neutral network (cnn). we also propose a method to synthesize large-scale training samples in profile views to solve the third problem of data labelling. experiments on the challenging aflw database show that our approach achieves significant improvements over state-of-the-art methods.",
            "contribution_ids": [
                "R28978",
                "R29018"
            ]
        },
        {
            "instance_id": "R29080xR29030",
            "comparison_id": "R29080",
            "paper_id": "R29030",
            "text": "One millisecond face alignment with an ensemble of regression trees \"this paper addresses the problem of face alignment for a single image. we show how an ensemble of regression trees can be used to estimate the face's landmark positions directly from a sparse subset of pixel intensities, achieving super-realtime performance with high quality predictions. we present a general framework based on gradient boosting for learning an ensemble of regression trees that optimizes the sum of square error loss and naturally handles missing or partially labelled data. we show how using appropriate priors exploiting the structure of image data helps with efficient feature selection. different regularization strategies and its importance to combat overfitting are also investigated. in addition, we analyse the effect of the quantity of training data on the accuracy of the predictions and explore the effect of data augmentation using synthesized data.\"",
            "contribution_ids": [
                "R29031",
                "R29065"
            ]
        },
        {
            "instance_id": "R29080xR29004",
            "comparison_id": "R29080",
            "paper_id": "R29004",
            "text": "Face detection, pose estimation, and landmark localization in the wild we present a unified model for face detection, pose estimation, and landmark estimation in real-world, cluttered images. our model is based on a mixtures of trees with a shared pool of parts; we model every facial landmark as a part and use global mixtures to capture topological changes due to viewpoint. we show that tree-structured models are surprisingly effective at capturing global elastic deformation, while being easy to optimize unlike dense graph structures. we present extensive results on standard face benchmarks, as well as a new \u201cin the wild\u201d annotated dataset, that suggests our system advances the state-of-the-art, sometimes considerably, for all three tasks. though our model is modestly trained with hundreds of faces, it compares favorably to commercial systems trained with billions of examples (such as google picasa and face.com).",
            "contribution_ids": [
                "R29005",
                "R29045",
                "R29090"
            ]
        },
        {
            "instance_id": "R29080xR29069",
            "comparison_id": "R29080",
            "paper_id": "R29069",
            "text": "Incremental Face Alignment in the Wild \"the development of facial databases with an abundance of annotated facial data captured under unconstrained 'in-the-wild' conditions have made discriminative facial deformable models the de facto choice for generic facial landmark localization. even though very good performance for the facial landmark localization has been shown by many recently proposed discriminative techniques, when it comes to the applications that require excellent accuracy, such as facial behaviour analysis and facial motion capture, the semi-automatic person-specific or even tedious manual tracking is still the preferred choice. one way to construct a person-specific model automatically is through incremental updating of the generic model. this paper deals with the problem of updating a discriminative facial deformable model, a problem that has not been thoroughly studied in the literature. in particular, we study for the first time, to the best of our knowledge, the strategies to update a discriminative model that is trained by a cascade of regressors. we propose very efficient strategies to update the model and we show that is possible to automatically construct robust discriminative person and imaging condition specific models 'in-the-wild' that outperform state-of-the-art generic face alignment strategies.\"",
            "contribution_ids": [
                "R29070"
            ]
        },
        {
            "instance_id": "R29080xR29010",
            "comparison_id": "R29080",
            "paper_id": "R29010",
            "text": "Robust Face Landmark Estimation under Occlusion \"human faces captured in real-world conditions present large variations in shape and occlusions due to differences in pose, expression, use of accessories such as sunglasses and hats and interactions with objects (e.g. food). current face landmark estimation approaches struggle under such conditions since they fail to provide a principled way of handling outliers. we propose a novel method, called robust cascaded pose regression (rcpr) which reduces exposure to outliers by detecting occlusions explicitly and using robust shape-indexed features. we show that rcpr improves on previous landmark estimation methods on three popular face datasets (lfpw, lfw and helen). we further explore rcpr's performance by introducing a novel face dataset focused on occlusion, composed of 1,007 faces presenting a wide range of occlusion patterns. rcpr reduces failure cases by half on all four datasets, at the same time as it detects face occlusions with a 80/40% precision/recall.\"",
            "contribution_ids": [
                "R29011",
                "R29029",
                "R29063"
            ]
        },
        {
            "instance_id": "R29080xR29042",
            "comparison_id": "R29080",
            "paper_id": "R29042",
            "text": "Optimization Problems for Fast AAM Fitting in-the-Wild we describe a very simple framework for deriving the most-well known optimization problems in active appearance models (aams), and most importantly for providing efficient solutions. our formulation results in two optimization problems for fast and exact aam fitting, and one new algorithm which has the important advantage of being applicable to 3d. we show that the dominant cost for both forward and inverse algorithms is a few times mn which is the cost of projecting an image onto the appearance subspace. this makes both algorithms not only computationally realizable but also very attractive speed-wise for most current systems. because exact aam fitting is no longer computationally prohibitive, we trained aams in-the-wild with the goal of investigating whether aams benefit from such a training process. our results show that although we did not use sophisticated shape priors, robust features or robust norms for improving performance, aams perform notably well and in some cases comparably with current state-of-the-art methods. we provide matlab source code for training, fitting and reproducing the results presented in this paper at http://ibug.doc.ic.ac.uk/resources.",
            "contribution_ids": [
                "R29043"
            ]
        },
        {
            "instance_id": "R29080xR29023",
            "comparison_id": "R29080",
            "paper_id": "R29023",
            "text": "Supervised descent method and its applications to face alignment many computer vision problems (e.g., camera calibration, image alignment, structure from motion) are solved through a nonlinear optimization method. it is generally accepted that 2nd order descent methods are the most robust, fast and reliable approaches for nonlinear optimization of a general smooth function. however, in the context of computer vision, 2nd order descent methods have two main drawbacks: (1) the function might not be analytically differentiable and numerical approximations are impractical. (2) the hessian might be large and not positive definite. to address these issues, this paper proposes a supervised descent method (sdm) for minimizing a non-linear least squares (nls) function. during training, the sdm learns a sequence of descent directions that minimizes the mean of nls functions sampled at different points. in testing, sdm minimizes the nls objective using the learned descent directions without computing the jacobian nor the hessian. we illustrate the benefits of our approach in synthetic and real examples, and show how sdm achieves state-of-the-art performance in the problem of facial feature detection. the code is available at www.humansensing.cs. cmu.edu/intraface.",
            "contribution_ids": [
                "R29024",
                "R29059"
            ]
        },
        {
            "instance_id": "R29080xR28969",
            "comparison_id": "R29080",
            "paper_id": "R28969",
            "text": "Deep Convolutional Network Cascade for Facial Point Detection we propose a new approach for estimation of the positions of facial key points with three-level carefully designed convolutional networks. at each level, the outputs of multiple networks are fused for robust and accurate estimation. thanks to the deep structures of convolutional networks, global high-level features are extracted over the whole face region at the initialization stage, which help to locate high accuracy key points. there are two folds of advantage for this. first, the texture context information over the entire face is utilized to locate each key point. second, since the networks are trained to predict all the key points simultaneously, the geometric constraints among key points are implicitly encoded. the method therefore can avoid local minimum caused by ambiguity and data corruption in difficult image samples due to occlusions, large pose variations, and extreme lightings. the networks at the following two levels are trained to locally refine initial predictions and their inputs are limited to small regions around the initial predictions. several network structures critical for accurate and robust facial point detection are investigated. extensive experiments show that our approach outperforms state-of-the-art methods in both detection accuracy and reliability.",
            "contribution_ids": [
                "R28970",
                "R29067"
            ]
        },
        {
            "instance_id": "R29080xR29075",
            "comparison_id": "R29080",
            "paper_id": "R29075",
            "text": "3D constrained local model for rigid and non-rigid facial tracking we present 3d constrained local model (clm-z) for robust facial feature tracking under varying pose. our approach integrates both depth and intensity information in a common framework. we show the benefit of our clm-z method in both accuracy and convergence rates over regular clm formulation through experiments on publicly available datasets. additionally, we demonstrate a way to combine a rigid head pose tracker with clm-z that benefits rigid head tracking. we show better performance than the current state-of-the-art approaches in head pose tracking with our extension of the generalised adaptive view-based appearance model (gavam).",
            "contribution_ids": [
                "R29076"
            ]
        },
        {
            "instance_id": "R29080xR29072",
            "comparison_id": "R29080",
            "paper_id": "R29072",
            "text": "Real-time facial feature detection using conditional regression forests although facial feature detection from 2d images is a well-studied field, there is a lack of real-time methods that estimate feature points even on low quality images. here we propose conditional regression forest for this task. while regression forest learn the relations between facial image patches and the location of feature points from the entire set of faces, conditional regression forest learn the relations conditional to global face properties. in our experiments, we use the head pose as a global property and demonstrate that conditional regression forests outperform regression forests for facial feature detection. we have evaluated the method on the challenging labeled faces in the wild [20] database where close-to-human accuracy is achieved while processing images in real-time.",
            "contribution_ids": [
                "R29073"
            ]
        },
        {
            "instance_id": "R29153xR29151",
            "comparison_id": "R29153",
            "paper_id": "R29151",
            "text": "Sustaining the Momentum: Archival Analysis of Enterprise Resource Planning Systems (2006\u00e2\u0080\u00932012) here",
            "contribution_ids": [
                "R29152"
            ]
        },
        {
            "instance_id": "R29153xR29133",
            "comparison_id": "R29153",
            "paper_id": "R29133",
            "text": "Enterprise resource planning research: where are we now and where should we go from here? abstract the research related to enterprise resource planning (erp) has grown over the past several years. this growing body of erp research results in an increased need to review this extant literature with the intent of identifying gaps and thus motivate researchers to close this breach. therefore, this research was intended to critique, synthesize and analyze both the content (e.g., topics, focus) and processes (i.e., methods) of the erp literature, and then enumerates and discusses an agenda for future research efforts. to accomplish this, we analyzed 49 erp articles published (1999-2004) in top information systems (is) and operations management (om) journals. we found an increasing level of activity during the 5-year period and a slightly biased distribution of erp articles targeted at is journals compared to om. we also found several research methods either underrepresented or absent from the pool of erp research. we identified several areas of need within the erp literature, none more prevalent than the need to analyze erp within the context of the supply chain. introduction davenport (1998) described the strengths and weaknesses of using enterprise resource planning (erp). he called attention to the growth of vendors like sap, baan, oracle, and people-soft, and defined this software as, \"...the seamless integration of all the information flowing through a companyfinancial and accounting information, human resource information, supply chain information, and customer information.\" (davenport, 1998). since the time of that article, there has been a growing interest among researchers and practitioners in how organization implement and use erp systems (amoako-gyampah and salam, 2004; bendoly and jacobs, 2004; gattiker and goodhue, 2004; lander, purvis, mccray and leigh, 2004; luo and strong, 2004; somers and nelson, 2004; zoryk-schalla, fransoo and de kok, 2004). this interest is a natural continuation of trends in information technology (it), such as mrp ii, (olson, 2004; teltumbde, 2000; toh and harding, 1999) and in business practice improvement research, such as continuous process improvement and business process reengineering (markus and tanis, 2000; ng, ip and lee, 1999; reijers, limam and van der aalst, 2003; toh and harding, 1999). this growing body of erp research results in an increased need to review this extant literature with the intent of \"identifying critical knowledge gaps and thus motivate researchers to close this breach\" (webster and watson, 2002). also, as noted by scandura & williams (2000), in order for research to advance, the methods used by researchers must periodically be evaluated to provide insights into the methods utilized and thus the areas of need. these two interrelated needs provide the motivation for this paper. in essence, this research critiques, synthesizes and analyzes both the content (e.g., topics, focus) and processes (i.e., methods) of the erp literature and then enumerates and discusses an agenda for future research efforts. the remainder of the paper is organized as follows: section 2 describes the approach to the analysis of the erp research. section 3 contains the results and a review of the literature. section 4 discusses our findings and the needs relative to future erp research efforts. finally, section 5 summarizes the research. research study we captured the trends pertaining to (1) the number and distribution of erp articles published in the leading journals, (2) methodologies employed in erp research, and (3) emphasis relative to topic of erp research. during the analysis of the erp literature, we identified gaps and needs in the research and therefore enumerate and discuss a research agenda which allows the progression of research (webster and watson, 2002). in short, we sought to paint a representative landscape of the current erp literature base in order to influence the direction of future research efforts relative to erp. \u2026",
            "contribution_ids": [
                "R29134"
            ]
        },
        {
            "instance_id": "R29153xR29119",
            "comparison_id": "R29153",
            "paper_id": "R29119",
            "text": "The Iceberg on the sea: what do you see? although organizations began to adopt enterprise systems (es) in the 1980s (hayman, 2000), academic interests have just started. this literature review of es articles appearing in academic information systems (is) journals indicates that while previous es studies have provided some interesting findings, only limited aspects of enterprise systems have been explored. we have essentially focused on the iceberg above the sea, ignoring what is going on under the water. this paper contributes to the es research by identifying strengths and weaknesses of es research to date, and suggesting future research opportunities.",
            "contribution_ids": [
                "R29120"
            ]
        },
        {
            "instance_id": "R29153xR29114",
            "comparison_id": "R29153",
            "paper_id": "R29114",
            "text": "Enterprise Resource Planning Systems Research: An Annotated Bibliography despite growing interest, publications on erp systems within the academic information systems community, as reflected by contributions to journals and international conferences, is only now emerging. this article provides an annotated bibliography of the erp publications published in the main information systems journals and conferences and reviews the state of the erp art. the publications surveyed are categorized through a framework that is structured in phases that correspond to the different stages of an erp system lifecycle within an organization. we also present topics for further research in each phase. .",
            "contribution_ids": [
                "R29115"
            ]
        },
        {
            "instance_id": "R29153xR29149",
            "comparison_id": "R29153",
            "paper_id": "R29149",
            "text": "A comprehensive literature review of the ERP research field over a Decade purpose the purpose of this paper is first, to develop a methodological framework for conducting a comprehensive literature review on an empirical phenomenon based on a vast amount of papers published. second, to use this framework to gain an understanding of the current state of the enterprise resource planning (erp) research field, and third, based on the literature review, to develop a conceptual framework identifying areas of concern with regard to erp systems. design/methodology/approach abstracts from 885 peer\u2010reviewed journal publications from 2000 to 2009 have been analysed according to journal, authors and year of publication, and further categorised into research discipline, research topic and methods used, using the structured methodological framework. findings the body of academic knowledge about erp systems has reached a certain maturity and several different research disciplines have contributed to the field from different points of view using different methods, showing that the erp research field is very much an interdisciplinary field. it demonstrates that the number of erp publications has decreased, and it indicates that the academic interest in erp is driven by an interest in an empirical phenomenon rather than that erp is a new research discipline. different research topics of interest are identified and used in developing a conceptual framework for \u201careas of concern\u201d regarding erp systems. finally the usefulness of the framework is confirmed by analysing one specific aspect of erp research; business process reengineering (bpr) to establish which theories different authors and journals have used in their efforts to explore bpr and erp. research limitations/implications the findings of the literature study, the structured methodological framework for comprehensive literature review and the conceptual framework identifying different areas of concern are believed to be useful for other researchers in their effort to obtain an overview of the evolution of the erp research field and in positioning their own erp research. practical implications the paper provides guidance for researchers with insight into what has been published, where to publish erp\u2010related research and how to study it, and in positioning their own interest in erp systems in the interdisciplinary research field. access to the endnote database containing bibliographical data of more than 880 papers can be used in future research and literature analysis. for managers, the conceptual framework can be useful in increasing their understanding of the complexity and areas of concern with regard to the erp system. originality/value the paper presents a structured methodological framework for analysing a vast amount of academic publications with an interest in an empirical phenomenon, demonstration of how academic interdisciplinary interest in erp has evolved over time and reached a certain amount of maturity and a conceptual framework of areas of concern with regard to erp systems.",
            "contribution_ids": [
                "R29150"
            ]
        },
        {
            "instance_id": "R29153xR34965",
            "comparison_id": "R29153",
            "paper_id": "R34965",
            "text": "Enterprise resource planning: An integrative review \"enterprise resource planning (erp) system solutions are currently in high demand by both manufacturing and service organisations because they provide a tightly integrated solution to an organisation's information system needs. during the last decade, erp systems have received a significant amount of attention from researchers and practitioners from a variety of functional disciplines. in this paper, a comprehensive review of the research literature (1990\u20102003) concerning erp systems is presented. the literature is further classified and the major outcomes of each study are addressed and analysed. following a comprehensive review of the literature, proposals for future research are formulated to identify topics where fruitful opportunities exist.\"",
            "contribution_ids": [
                "R29127",
                "R34967"
            ]
        },
        {
            "instance_id": "R29153xR29137",
            "comparison_id": "R29153",
            "paper_id": "R29137",
            "text": "Work, organisation and Enterprise Resource Planning systems: an alternative research agenda this paper reviews literature that examines the design, implementation and use of enterprise resource planning systems (erps). it finds that most of this literature is managerialist in orientation, and concerned with the impact of erps in terms of efficiency, effectiveness and business performance. the paper seeks to provide an alternative research agenda, one that emphasises work- and organisation-based approaches to the study of the implementation and use of erps.",
            "contribution_ids": [
                "R29138"
            ]
        },
        {
            "instance_id": "R29184xR29166",
            "comparison_id": "R29184",
            "paper_id": "R29166",
            "text": "A Comprehensive Review of the Enterprise Systems Research enterprise systems (es) can be considered as a novel phenomenon for the information system research and other academic fields (e.g. operations and supply chain), which has opened an immense potential and opportunities for research. although the interest of the scholars on es is recent, the number of publications is continuously growing since 2000. the aim of this paper is to review a sample of important contributions of the es works published to date. to do this, the selected works have been classified in four key topics: business implications, technical issues, managerial issues, and implementation issues.",
            "contribution_ids": [
                "R29167"
            ]
        },
        {
            "instance_id": "R29184xR29156",
            "comparison_id": "R29184",
            "paper_id": "R29156",
            "text": "Process orientation through enterprise resource planning (ERP): a review of critical issues the significant development in global information technologies and the ever-intensifying competitive market climate have both pushed many companies to transform their businesses. enterprise resource planning (erp) is seen as one of the most recently emerging process-orientation tools that can enable such a transformation. its development has presented both researchers and practitioners with new challenges and opportunities. this paper provides a comprehensive review of the state of research in the erp field relating to process management, organizational change and knowledge management. it surveys current practices, research and development, and suggests several directions for future investigation. copyright \u00a9 2001 john wiley & sons, ltd.",
            "contribution_ids": [
                "R29157"
            ]
        },
        {
            "instance_id": "R29184xR29174",
            "comparison_id": "R29184",
            "paper_id": "R29174",
            "text": "Research on ERP Application from an Integrative Review enterprise resource planning (erp) system is an enterprise management system, currently in high demand by both manufacturing and service organizations. recently, erp systems have been drawn an important amount of attention by researchers and top managers. this paper will summarize the previous research literature about erp application from an integrative review, and further research issues have been introduced to guide the future direction of research.",
            "contribution_ids": [
                "R29175"
            ]
        },
        {
            "instance_id": "R29184xR29176",
            "comparison_id": "R29184",
            "paper_id": "R29176",
            "text": "A Review of ERP Research: A Future Agenda for Accounting Information Systems abstract: erp systems are typically the largest, most complex, and most demanding information systems implemented by firms, representing a major departure from the individual and departmental information systems prevalent in the past. firms and individuals are extensively impacted, and many problematic issues remain to be researched. erp and related integrated technologies are a transformative force on the accounting profession. as the nature of business evolves, accounting expertise is being called on to make broader contributions such as reporting on nonfinancial measures, auditing information systems, implementing management controls within information systems, and providing management consulting services. this review of erp research is drawn from an extensive examination of the breadth of erp-related literature without constraints as to a narrow timeframe or limited journal list, although particular attention is directed to the leading journals in information systems and accounting information systems. early research consisted of descriptive studies of firms implementing erp systems. then researchers started to address other research questions about the factors that lead to successful implementations: the need for change management and expanded forms of user education, whether the financial benefit outweighed the cost, and whether the issues are different depending on organizational type and cultural factors. this research encouraged the development of several major erp research areas: (1) critical success factors, (2) the organizational impact, and (3) the economic impact of erp systems. we use this taxonomy to establish (1) what we know, (2) what we need, and (3) where we are going in erp research. the objective of this review is to synthesize the extant erp research reported without regard to publication domain and make this readily available to accounting researchers. we organize key erp research by topics of interest in accounting, and map erp topics onto existing accounting information systems research areas. an emphasis is placed on topics important to accounting, including (but not limited to) the risk management and auditing of erp systems, regulatory issues, the internal and external economic impacts of erp systems, extensions needed in erp systems for xbrl, for interorganizational support, and for the design of management control systems. see supplemental material.",
            "contribution_ids": [
                "R29177"
            ]
        },
        {
            "instance_id": "R29240xR29233",
            "comparison_id": "R29240",
            "paper_id": "R29233",
            "text": "A new framework of effective external and internal factors on the success of enterprise resource planning (ERP) true understanding of the managers of the organizations that implement the system of the success factors and conditions and their fulfillment is very helpful. many researches are done regarding the identification of key factors of this system but most of them had one-dimensional view to the subject or they only studied internal organizational factors so, the lack of a multi-purpose and coherent framework is evident. the researcher by a deep review on review of literature separated the success factors of erp in 7 factors of country environment, erp vendors\u2019 environment, software package environment, leadership and strategic criterions, organizational environment variables, organization users environment, it environment in the organization in the form of two external and internal set and finally attempted to present a coherent framework.",
            "contribution_ids": [
                "R29234"
            ]
        },
        {
            "instance_id": "R29240xR29224",
            "comparison_id": "R29240",
            "paper_id": "R29224",
            "text": "Comparing risk and success factors in ERP projects: a literature review although research and practice has attributed considerable attention to enterprise resource planning (erp) projects their failure rate is still high. there are two main fields of research, which aim at increasing the success rate of erp projects: research on risk factors and research on success factors. despite their topical relatedness, efforts to integrate these two fields have been rare. against this background, this paper analyzes 68 articles dealing with risk and success factors and categorizes all identified factors into twelve categories. though some topics are equally important in risk and success factor research, the literature on risk factors emphasizes topics which ensure achieving budget, schedule and functionality targets. in contrast, the literature on success factors concentrates more on strategic and organizational topics. we argue that both fields of research cover important aspects of project success. the paper concludes with the presentation of a possible holistic consideration to integrate both, the understanding of risk and success factors.",
            "contribution_ids": [
                "R29225"
            ]
        },
        {
            "instance_id": "R29240xR29186",
            "comparison_id": "R29240",
            "paper_id": "R29186",
            "text": "Towards the unification of critical success factors for ERP implementations abstract despite the benefits that can be achieved from a successful erp system implementation, there is already evidence of high failure risks in erp implementation projects. too often, project managers focus mainly on the technical and financial aspects of the implementation project, while neglecting or putting less effort on the nontechnical issues. therefore, one of the major research issues in erp systems today is the study of erp implementation success. some authors have shown that erp implementation success definition and measurement depends on the points of view of the involved stakeholders. a typical approach used to define and measure erp implementation success has been critical success factors approach.",
            "contribution_ids": [
                "R29187"
            ]
        },
        {
            "instance_id": "R29240xR29238",
            "comparison_id": "R29240",
            "paper_id": "R29238",
            "text": "Critical success factors in enterprise resource planning systems organizations perceive erp as a vital tool for organizational competition as it integrates dispersed organizational systems and enables flawless transactions and production. this review examines studies investigating critical success factors (csfs) in implementing enterprise resource planning (erp) systems. keywords relating to the theme of this study were defined and used to search known web engines and journal databases for studies on both implementing erp systems per se and integrating erp systems with other well- known systems (e.g., scm, crm) whose importance to business organizations and academia is acknowledged to work in a complementary fashion. a total of 341 articles were reviewed to address three main goals. this study structures previous research by presenting a comprehensive taxonomy of csfs in the area of erp. second, it maps studies, identified through an exhaustive and comprehensive literature review, to different dimensions and facets of erp system implementation. third, it presents studies investigating csfs in terms of a specific erp lifecycle phase and across the entire erp life cycle. this study not only reviews articles in which an erp system is the sole or primary field of research, but also articles that refer to an integration of erp systems and other popular systems (e.g., scm, crm). finally it provides a comprehensive bibliography of the articles published during this period that can serve as a guide for future research.",
            "contribution_ids": [
                "R29239"
            ]
        },
        {
            "instance_id": "R29240xR29196",
            "comparison_id": "R29240",
            "paper_id": "R29196",
            "text": "Critical success factors for ERP projects over the past decade, enterprise resource planning systems (erp) have become one of the most important developments in the corporate use of information technology. erp implementations are usually large, complex projects, involving large groups of people and other resources, working together under considerable time pressure and facing many unforeseen developments. in order for an organization to compete in this rapidly expanding and integrated marketplace, erp systems must be employed to ensure access to an efficient, effective, and highly reliable information infrastructure. despite the benefits that can be achieved from a successful erp system implementation, there is evidence of high failure in erp implementation projects. too frequently key development practices are ignored and early warn ing signs that lead to project failure are not understood. identifying project success and failure factors and their consequences as early as possible can provide valuable clues to help project managers improve their chances of success. it is the long-lange goal of our research to shed light on these factors and to provide a tool that project managers can use to help better manage their software development projects. this paper will present a review of the general background to our work; the results from the current research and conclude with a discussion of the findings thus far. the findings will include a list of 23 unique critical success factors identified throughout the literature, which we believe to be essential for project managers. the implications of these results will be discussed along with the lessons learnt.",
            "contribution_ids": [
                "R29197"
            ]
        },
        {
            "instance_id": "R29240xR29226",
            "comparison_id": "R29240",
            "paper_id": "R29226",
            "text": "A FRAMEWORK FOR CLASSIFYING RISKS IN ERP MAINTENANCE PROJECTS enterprise resource planning (erp) is one the most common applications implemented by firms around the world. these systems cannot remain static after their implementation, they need maintenance. this process is required by the rapidly-changing business environment and the usual software maintenance needs. however, these projects are highly complex and risky. so, the risks management associated with erp maintenance projects is crucial to attain a satisfactory performance. unfortunately, erp maintenance risks have not been studied in depth. for this reason, this paper presents a framework, which gathers together the risks affecting the performance of erp maintenance.",
            "contribution_ids": [
                "R29227"
            ]
        },
        {
            "instance_id": "R29240xR29210",
            "comparison_id": "R29240",
            "paper_id": "R29210",
            "text": "Identification and assessment of risks associated with ERP post-implementation in China purpose \u2013 the purpose of this paper is to identify, assess and explore potential risks that chinese companies may encounter when using, maintaining and enhancing their enterprise resource planning (erp) systems in the post\u2010implementation phase.design/methodology/approach \u2013 the study adopts a deductive research design based on a cross\u2010sectional questionnaire survey. this survey is preceded by a political, economic, social and technological analysis and a set of strength, weakness, opportunity and threat analyses, from which the researchers refine the research context and select state\u2010owned enterprises (soes) in the electronic and telecommunications industry in guangdong province as target companies to carry out the research. the questionnaire design is based on a theoretical risk ontology drawn from a critical literature review process. the questionnaire is sent to 118 selected chinese soes, from which 42 (84 questionnaires) valid and usable responses are received and analysed.findings \u2013 the findings ident...",
            "contribution_ids": [
                "R29211"
            ]
        },
        {
            "instance_id": "R29240xR29212",
            "comparison_id": "R29240",
            "paper_id": "R29212",
            "text": "Challenges and influential factors in ERP adoption and implementation the adoption and implementation of enterprise resource planning (erp) systems is a challenging and expensive task that not only requires rigorous efforts but also demands to have a detailed analysis of such factors that are critical to the adoption or implementation of erp systems. many efforts have been made to identify such influential factors for erp; however, they are not filtered comprehensively in terms of the different perspectives. this paper focuses on the erp critical success factors from five different perspectives such as: stakeholders; process; technology; organisation; and project. results from the literature review are presented and 19 such factors are identified that are imperative for a successful erp implementation, which are listed in order of their importance. considering these factors can realize several benefits such as reducing costs and saving time or extra effort.",
            "contribution_ids": [
                "R29213"
            ]
        },
        {
            "instance_id": "R29240xR29221",
            "comparison_id": "R29240",
            "paper_id": "R29221",
            "text": "A Comparative Study of Critical Success Factors (CSFs) in Implementation of ERP in Developed and Developing Countries the main goal of this research is to understand is there any difference between erp implementation\\'s csf in developed and developing countries? understanding this subject can help us to implement erp systems properly in developing nations. this research showed that in developed and developing countries \"change management\" was most important factor and in developed countries \"country-related functional requirements\" factor was less important factor and \"fit between erp and business/process\" was the least cited factor among developing nations. in last it concluded that national culture of developing countries has an impressive effect on erp implementation in these countries. in other hand developing countries companies more depend on erp vendors in compare to developed countries companies. in addition it seems developing countries underestimate business process reengineering (bpr) and fit between erp and business/process factors in comparison with developed countries.",
            "contribution_ids": [
                "R29222"
            ]
        },
        {
            "instance_id": "R29240xR29231",
            "comparison_id": "R29240",
            "paper_id": "R29231",
            "text": "Evaluation of Key Success Factors Influencing ERP Implementation Success \"enterprise resource planning (erp) application is often viewed as a strategic investment that can provide significant competitive advantage with positive return thus contributing to the firms' revenue and growth. despite such strategic importance given to erp the implementation success to achieve the desired goal has been viewed disappointing. there have been numerous industry stories about failures of erp initiatives. there have also been stories reporting on the significant benefits achieved from successful erp initiatives. this study review the industry and academic literature on erp results and identify possible trends or factors which may help future erp initiatives achieve greater success and less failure. the purpose of this study is to review the industry and academic literature on erp results, identify and discuss critical success factors which may help future erp initiatives achieve greater success and less failure.\"",
            "contribution_ids": [
                "R29232"
            ]
        },
        {
            "instance_id": "R29240xR29198",
            "comparison_id": "R29240",
            "paper_id": "R29198",
            "text": "ERP implementation: a compilation and analysis of critical success factors purpose to explore the current literature base of critical success factors (csfs) of erp implementations, prepare a compilation, and identify any gaps that might exist. design/methodology/approach hundreds of journals were searched using key terms identified in a preliminary literature review. successive rounds of article abstract reviews resulted in 45 articles being selected for the compilation. csf constructs were then identified using content analysis methodology and an inductive coding technique. a subsequent critical analysis identified gaps in the literature base. findings the most significant finding is the lack of research that has focused on the identification of csfs from the perspectives of key stakeholders. additionally, there appears to be much variance with respect to what exactly is encompassed by change management, one of the most widely cited csfs, and little detail of specific implementation tactics. research limitations/implications there is a need to focus future research efforts on the study of csfs as they apply to the perspectives of key stakeholders and to ensure that this stakeholder approach is also comprehensive in its coverage of csfs. as well, there is need to conduct more in\u2010depth research into the concept of change management. one key limitation of this research is the occurrence of duplication in the frequency analysis of the success factors. this is attributed to secondary research being the main methodology for a large number of the articles cited. originality/value this research provides a comprehensive compilation of all previously identified erp implementation success factors, through a clearly structured methodological approach.",
            "contribution_ids": [
                "R29199"
            ]
        },
        {
            "instance_id": "R29351xR29291",
            "comparison_id": "R29351",
            "paper_id": "R29291",
            "text": "Organisational readiness for ERP implementation \"an erp implementation is a significant intervention in organisational life. as such, it affects and is affected by many variables including the organisation's culture, decision-making strategies, risk taking orientation, leadership strategies and perceptions of the value of information technology. for organisations to achieve business benefit in their erp implementation, the implementation must be short, raise appropriate issues for business to make decisions on, and effectively implement those decisions.. this paper describes the research program being undertaken to identify the variables that inhibit an erp implementation.\"",
            "contribution_ids": [
                "R29292"
            ]
        },
        {
            "instance_id": "R29351xR29306",
            "comparison_id": "R29351",
            "paper_id": "R29306",
            "text": "Developing a cultural perspective on ERP purpose to develop an analytical framework through which the organizational cultural dimension of enterprise resource planning (erp) implementations can be analyzed. design/methodology/approach this paper is primarily based on a review of the literature. findings erp is an enterprise system that offers, to a certain extent, standard business solutions. this standardization is reinforced by two processes: erp systems are generally implemented by intermediary it organizations, mediating between the development of erp\u2010standard software packages and specific business domains of application; and erp systems integrate complex networks of production divisions, suppliers and customers. originality/value in this paper, erp itself is presented as problematic, laying heavy burdens on organizations \u2013 erp is a demanding technology. while in some cases recognizing the mutual shaping of technology and organization, research into erp mainly addresses the economic\u2010technological rationality of erp (i.e. matters of effectiveness and efficiency). we want to supplement and complement this perspective with a cultural approach. how do individuals in organizations define and experience erp\u2010standards? how and to what extent are management and working positions redefined in the process of developing and implementing erp? in the paper, we highlight three perspectives from which erp systems can be experienced, defined and analyzed. these perspectives are specified as the \u201cconstitution\u201d of erp, erp as a \u201ccondition\u201d of organizations, and the (unintended) \u201cconsequences\u201d of erp.",
            "contribution_ids": [
                "R29307"
            ]
        },
        {
            "instance_id": "R29351xR29320",
            "comparison_id": "R29351",
            "paper_id": "R29320",
            "text": "ERP systems business value: a critical review of empirical literature the business value generated by information and communication technologies (ict) has been for long time a major research topic. recently there is a growing research interest in the business value generated by particular types of information systems (is). one of them is the enterprise resource planning (erp) systems, which are increasingly adopted by organizations for supporting and integrating key business and management processes. the current paper initially presents a critical review of the existing empirical literature concerning the business value of the erp systems, which investigates the impact of erp systems adoption on various measures of organizational performance. then is critically reviewed the literature concerning the related topic of critical success factors (csfs) in erp systems implementation, which aims at identifying and investigating factors that result in more successful erp systems implementation that generate higher levels of value for organizations. finally, future directions of research concerning erp systems business value are proposed.",
            "contribution_ids": [
                "R29321"
            ]
        },
        {
            "instance_id": "R29351xR29295",
            "comparison_id": "R29351",
            "paper_id": "R29295",
            "text": "Limits to using ERP systems the paper examines limitations that restrict the potential benefits from the use of enterprise resource planning (erp) systems in business firms. in the first part we discuss a limitation that arises from the strategic decision of top managers for mergers, acquisitions and divestitures as well as outsourcing. managers tend to treat their companies like component-based business units, which are to be arranged and re-arranged to yet higher market values. outsourcing of in-house activities to suppliers means disintegrating processes and information. such consequences of strategic business decisions impose severe restrictions on what business organizations can benefit from erp systems. the second part of the paper reflects upon the possibility of imbedding best practice business processes in erp systems. we critically review the process of capturing and transferring best practices with a particular focus on context-dependence and nature of it innovations.",
            "contribution_ids": [
                "R29296"
            ]
        },
        {
            "instance_id": "R29351xR29302",
            "comparison_id": "R29351",
            "paper_id": "R29302",
            "text": "Benefit realisation through ERP: the re-emergence of data warehousing the need for an integrated enterprise-wide set of management information pronounced data warehousing the \u2018hot topic\u2019 of the early-to-mid 1990\u2019s, however, it became unfashionable through the mid-to-late 1990s, with the approach of y2k and with it the widespread implementation of erp systems. however, in recent times, the re-emergence of data warehousing, to address the limitations and unrealised benefits of erp systems implementation, provides researchers with a new challenge in understanding the \u2018double learning curve\u2019 for an organisation, undertaking in quick succession both an erp systems project and a data warehousing project, in an attempt to finally achieve the benefits expected but never realised.",
            "contribution_ids": [
                "R29303"
            ]
        },
        {
            "instance_id": "R29351xR29334",
            "comparison_id": "R29351",
            "paper_id": "R29334",
            "text": "The role and impact of project management in ERP project implementation life cycle recent advancement of information technology in business management processes has flourished erp as one of the most widely implemented business software systems in variety of industries and organizations. this paper presents review on the impact of project management in erp project life cycle by studying various project management methodologies. also the role and critical activities of project manager, project team and hence project management is explored in erp projects implementation in organization of different sizes and culture.",
            "contribution_ids": [
                "R29335"
            ]
        },
        {
            "instance_id": "R29351xR29336",
            "comparison_id": "R29351",
            "paper_id": "R29336",
            "text": "Justifying ERP investment: the role and impacts of business case a literature survey erp systems are booming these days. but it suffers from high rates of failure among different industries. consequently, clear vision, objectives and compelling justification is needed to increase the rates of success. there are different approaches to justify it investment in general and erp investment in specific. this paper focuses on business case approach. a comprehensive model based on best practices for business case is proposed.",
            "contribution_ids": [
                "R29337"
            ]
        },
        {
            "instance_id": "R29351xR29338",
            "comparison_id": "R29351",
            "paper_id": "R29338",
            "text": "Barriers of ERP while implementing ERP: a literature review purpose the main purpose of the paper is to do literature survey of erp papers (from refereed and international journals like elsevier, inderscience, asme, springer and acm( digital library) to find out the barriers of erp when implementing it. thus, the objective of the paper is to study the literature review papers and find out the barriers of erp. research findings of the paper: while implementing this erp in an enterprise(s), it is found that there are obviously some barriers which need to be addressed. out of 200 or so literature papers on erp, 51 papers were reviewed for barriers and studied in depth. these barriers are mentioned in the form of table in the literature survey. while implementing erp, the barriers which are commonly observed arehuge capital incurred for software, poor planning or poor management, lack of perfection, lack of training and predetermined corporate goals, lack of good vendors, lack of risk assessment, lack of approach, lack of data models (support), lack of erp systems\u2019 benefits, lack of system performance, lack of hierarchical attribute structure and lack of management support etc. outline of the paper: the tool or methodology applied to overcome these barriers is ahp. it analyses the barriers (of erp) and can help to solve the issues of erp for its implementation. the results after overcoming the barriers and implementing it are excellent, found to be more productive for the enterprises.",
            "contribution_ids": [
                "R29339"
            ]
        },
        {
            "instance_id": "R29351xR29298",
            "comparison_id": "R29351",
            "paper_id": "R29298",
            "text": "Potential impact of cultural differences on enterprise resource planning (ERP) projects over the last ten years, there has been a dramatic growth in the acquisition of enterprise resource planning (erp) systems, where the market leader is the german company, sap ag. however, more recently, there has been an increase in reported erp failures, suggesting that the implementation issues are not just technical, but encompass wider behavioural factors.",
            "contribution_ids": [
                "R29299"
            ]
        },
        {
            "instance_id": "R29351xR29340",
            "comparison_id": "R29351",
            "paper_id": "R29340",
            "text": "Taxonomy of cost of quality (COQ) across the enterprise resource planning (ERP) implementation phases\u00e2\u0080\u009d companies declare that quality or customer satisfaction is their top priority in order to keep and attract more business in an increasingly competitive marketplace. the cost of quality (coq) is a tool which can help determine the optimal level of quality investment. coq analysis enables organizations to identify measure and control the consequences of poor quality. this study attempts to identify the coq elements across the enterprise resource planning (erp) implementation phases for the erp implementation services of consultancy companies. the findings provide guidance to project managers on how best to utilize their limited resources. in summary, we suggest that project teams should focus on \u201cvalue-added\u201d activities and minimize the cost of \u201cnon-value-added\u201d activities at each phase of the erp implementation project. \\n \\n \\xa0 \\n \\n key words:\\xa0services, erp implementation services, quality standard, service quality standard, cost of quality, project management, project quality management, project financial management.",
            "contribution_ids": [
                "R29341"
            ]
        },
        {
            "instance_id": "R29351xR29308",
            "comparison_id": "R29351",
            "paper_id": "R29308",
            "text": "Training for ERP: does the is training literature have value? this paper examines end-user training (eut) in enterprise resource planning (erp) systems, with the aim of\\nidentifying whether current eut research is applicable to erp systems. an extensive review and analysis of\\neut research in mainstream is journals was undertaken. the findings of this analysis were compared to views\\nexpressed by a leading erp trainer in a large australian company. the principles outlined in the eut literature\\nwere used to construct the training, education and learning strategy model for an erp environment. our\\nanalysis found very few high-quality empirical studies involving eut training in such an environment.\\nmoreover, we argue that while the extensive eut literature provides a rich source of ideas about erp training,\\nthe findings of many studies cannot be transferred to erp systems, as these systems are inherently more complex than the office-based, non-mandatory applications upon which most is eut research is based.",
            "contribution_ids": [
                "R29309"
            ]
        },
        {
            "instance_id": "R29351xR29310",
            "comparison_id": "R29351",
            "paper_id": "R29310",
            "text": "Understanding the impact of enterprise systems on management decision making: an agenda for future research enterprise systems have been widely sold on the basis that they reduce costs through process efficiency and enhance decision making by providing accurate and timely enterprise wide information. although research shows that operational efficiencies can be achieved, erp systems are notoriously poor at delivering management information in a form that would support effective decision-making. research suggests managers are not helped in their decision-making abilities simply by increasing the flow of information. this paper calls for a new approach to researching the impact of erp implementations on global organizations by examining decision making processes at 3 levels in the organisation (corporate, core implementation team and local site).",
            "contribution_ids": [
                "R29311"
            ]
        },
        {
            "instance_id": "R29351xR29342",
            "comparison_id": "R29351",
            "paper_id": "R29342",
            "text": "ERP measure success model: a new perspective this paper addresses the problem of defining and evaluating the success of erp throughout the life cycle of the information system. in order to solve this problem, many of the theoretical and empirical contributions on the success of the information system are analysed and discussed.\\n this approach allows the development of a new model; especially in delone & mclean supported research.\\n this work will try to establish a different perspective on the success of the erp and can be an encouragement to some organizations or the many researchers that will be engaging in these areas, in order to help achieve more clearly the expected performance in the acquisition phase of erps. many times that performance does not always happen [1].",
            "contribution_ids": [
                "R29343"
            ]
        },
        {
            "instance_id": "R30476xR29841",
            "comparison_id": "R30476",
            "paper_id": "R29841",
            "text": "An Econometric Analysis for CO<sub>2</sub> Emissions, Energy Consumption, Economic Growth, Foreign Trade and Urbanization of Japan this paper examines the dynamic causal relationship between carbon dioxide emissions, energy consumption, economic growth, foreign trade and urbanization using time series data for the period of 1960-2009. short-run unidirectional causalities are found from energy consumption and trade openness to carbon dioxide emissions, from trade openness to energy consumption, from carbon dioxide emissions to economic growth, and from economic growth to trade openness. the test results also support the evidence of existence of long-run relationship among the variables in the form of equation (1) which also conform the results of bounds and johansen conintegration tests. it is found that over time higher energy consumption in japan gives rise to more carbon dioxide emissions as a result the environment will be polluted more. but in respect of economic growth, trade openness and urbanization the environmental quality is found to be normal good in the long-run.",
            "contribution_ids": [
                "R29842"
            ]
        },
        {
            "instance_id": "R30476xR29676",
            "comparison_id": "R30476",
            "paper_id": "R29676",
            "text": "Environmental Kuznets curves, carbon emissions, and public choice abstract concern about global climate change has elicited responses from governments around the world. these responses began with the 1997 kyoto protocol and have continued with other negotiations, including the 2009 copenhagen summit. these negotiations raised important questions about whether countries will reduce greenhouse gas emissions and, if so, how the burden of emissions reductions will be shared. to investigate these questions, we utilize environmental kuznets curves for carbon emissions for the g8 plus five main developing countries. our findings raise doubts about the feasibility of reducing global carbon emissions and shed light on the different positions taken by countries on the distribution of emissions reductions.",
            "contribution_ids": [
                "R29677"
            ]
        },
        {
            "instance_id": "R30476xR29587",
            "comparison_id": "R30476",
            "paper_id": "R29587",
            "text": "Does One Size Fit All? A Reexamination of the Environmental Kuznets Curve Using the Dynamic Panel Data Approach this article applies the dynamic panel generalized method of moments technique to reexamine the environmental kuznets curve (ekc) hypothesis for carbon dioxide (co_2) emissions and asks two critical questions: \"does the global data set fit the ekc hypothesis?\" and \"do different income levels or regions influence the results of the ekc?\" we find evidence of the ekc hypothesis for co_2 emissions in a global data set, middle-income, and american and european countries, but not in other income levels and regions. thus, the hypothesis that one size fits all cannot be supported for the ekc, and even more importantly, results, robustness checking, and implications emerge. copyright 2009 agricultural and applied economics association",
            "contribution_ids": [
                "R29588"
            ]
        },
        {
            "instance_id": "R30476xR29711",
            "comparison_id": "R30476",
            "paper_id": "R29711",
            "text": "A panel data heterogeneous Bayesian estimation of environmental Kuznets curves for CO2emissions this article investigates the environmental kuznets curves (ekc) for co2 emissions in a panel of 109 countries during the period 1959 to 2001. the length of the series makes the application of a heterogeneous estimator suitable from an econometric point of view. the results, based on the hierarchical bayes estimator, show that different ekc dynamics are associated with the different sub-samples of countries considered. on average, more industrialized countries show evidence of ekc in quadratic specifications, which nevertheless are probably evolving into an n-shape based on their cubic specification. nevertheless, it is worth noting that the eu, and not the umbrella group led by us, has been driving currently observed ekc-like shapes. the latter is associated to monotonic income\u2013co2 dynamics. the eu shows a clear ekc shape. evidence for less-developed countries consistently shows that co2 emissions rise positively with income, though there are some signs of an ekc. analyses of future performance, nevertheless, favour quadratic specifications, thus supporting ekc evidence for wealthier countries and non-ekc shapes for industrializing regions.",
            "contribution_ids": [
                "R29712"
            ]
        },
        {
            "instance_id": "R30476xR29854",
            "comparison_id": "R30476",
            "paper_id": "R29854",
            "text": "An Empirical Analysis of the Environmental Kuznets Curve for CO2 Emissions in Indonesia: The Role of Energy Consumption and Foreign Trade this study examines the dynamic relationship among carbon dioxide (co2) emissions, economic growth, energy consumption and foreign trade based on the environmental kuznets curve (ekc) hypothesis in indonesia for the period 1971\u20132007, using the auto regressive distributed lag (ardl) methodology. the results do not support the ekc hypothesis, which assumes an inverted u-shaped relationship between income and environmental degradation. the long-run results indicate that foreign trade is the most significant variable in explaining co2 emissions in indonesia followed by energy consumption and economic growth. the stability of the variables in estimated model is also examined. the result suggests that the estimated model is stable over the study period.",
            "contribution_ids": [
                "R29855"
            ]
        },
        {
            "instance_id": "R30476xR30042",
            "comparison_id": "R30476",
            "paper_id": "R30042",
            "text": "GREENHOUSE GASES EMISSIONS AND ECONOMIC GROWTH \u00e2\u0080\u0093 EVIDENCE SUBSTANTIATING THE PRESENCE OF ENVIRONMENTAL KUZNETS CURVE IN THE EU the paper considers the relationship between greenhouse gas emissions (ghg) as the main variable of climate change and gross domestic product (gdp), using the environmental kuznets curve (ekc) technique. at early stages of economic growth, ekc indicates the increase of pollution related to the growing use of resources. however, when a certain level of income per capita is reached, the trend reverses and at a higher stage of development, further economic growth leads to improvement of the environment. according to the researchers, this implies that the environmental impact indicator is an inverted u-shaped function of income per capita. in this paper, the cubic equation is used to empirically check the validity of the ekc relationship for european countries. the analysis is based on the survey of eu-27, norway and switzerland in the period of 1995\u20132010. the data is taken from the eurostat database. to gain some insights into the environmental trends in each country, the article highlights the specific relationship in the country based on the level of its development. the similarities between individual countries are analysed in order to identify their basic common features.",
            "contribution_ids": [
                "R30043"
            ]
        },
        {
            "instance_id": "R30476xR30280",
            "comparison_id": "R30476",
            "paper_id": "R30280",
            "text": "Estimating the relationship between economic growth and environmental quality for the brics economies - a dynamic panel data approach it has been forecasted by many economists that in the next couple of decades the brics economies are going to experience an unprecedented economic growth. this massive economic growth would definitely have a detrimental impact on the environment since these economies, like others, would extract their environmental and natural resource to a larger scale in the process of their economic growth. therefore, maintaining environmental quality while growing has become a major challenge for these economies. however, the proponents of environmental kuznets curve (ekc) hypothesis - an inverted u shape relationship between income and emission per capita, suggest brics economies need not bother too much about environmental quality while growing because growth would eventually take care of the environment once a certain level of per capita income is achieved. in this backdrop, the present study makes an attempt to estimate ekc type relationship, if any, between income and emission in the context of the brics countries for the period 1997 to 2011. therefore, the study first adopts fixed effect (fe) panel data model to control time constant country specific effects, and then uses generalized method of moments (gmm) approach for dynamic panel data to address endogeneity of income variable and dynamism in emission per capita. apart from income, we also include variables related to financial sector development and energy utilization to explain emission. the fixed effect model shows a significant ekc type relation between income and emission supporting the previous literature. however, gmm estimates for the dynamic panel model show the relationship between income and emission is actually u shaped with the turning point being out of sample. this out of sample turning point indicates that emission has been growing monotonically with growth in income. factors like, net energy imports and share of industrial output in gdp are found to be significant and having detrimental impact on the environment in the dynamic panel model. however, these variables are found to be insignificant in fe model. capital account convertibility shows significant and negative impact on the environment irrespective of models used. the monotonically increasing relationship between income and emission suggests the brics economies must adopt some efficiency oriented action plan so that they can grow without putting much pressure on the environment. these findings can have important policy implications as brics countries are mainly depending on these factors for their growth but at the same time they can cause serious threat to the environment.",
            "contribution_ids": [
                "R30281"
            ]
        },
        {
            "instance_id": "R30476xR30175",
            "comparison_id": "R30476",
            "paper_id": "R30175",
            "text": "Emissions and trade in Southeast and East Asian countries: a panel co-integration analysis \\n purpose \\n \u2013 the purpose of this paper is to analyse the implication of trade on carbon emissions in a panel of eight highly trading southeast and east asian countries, namely, china, indonesia, south korea, malaysia, hong kong, the philippines, singapore and thailand. \\n \\n \\n design/methodology/approach \\n \u2013 the analysis relies on the standard quadratic environmental kuznets curve (ekc) extended to include energy consumption and international trade. a battery of panel unit root and co-integration tests is applied to establish the variables\u2019 stochastic properties and their long-run relations. then, the specified ekc is estimated using the panel dynamic ordinary least square (ols) estimation technique. \\n \\n \\n findings \\n \u2013 the panel co-integration statistics verifies the validity of the extended ekc for the countries under study. estimation of the long-run ekc via the dynamic ols estimation method reveals the environmentally degrading effects of trade in these countries, especially in asean and plus south korea and hong kong. \\n \\n \\n practical implications \\n \u2013 these countries are heavily dependent on trade for their development processes, and as such, their impacts on co 2 emissions would be highly relevant for assessing their trade policies, along the line of the gain-from-trade hypothesis, the race-to-the-bottom hypothesis and the pollution-safe-haven hypothesis. \\n \\n \\n originality/value \\n \u2013 the analysis adds to existing literature by focusing on the highly trading nations of southeast and east asian countries. the results suggest that reassessment of trade policies in these countries is much needed and it must go beyond the sole pursuit of economic development via trade. \\n",
            "contribution_ids": [
                "R30176"
            ]
        },
        {
            "instance_id": "R30476xR30121",
            "comparison_id": "R30476",
            "paper_id": "R30121",
            "text": "Economic growth and environmental degradation in Saudi Arabia this paper has for objective to examine the effects of the economic growth, energy use and trade openness on carbon dioxide (co 2 ) emissions for the case of the kingdom of saudi arabia by estimating what is called the environmental kuznets curve (ekc) model over the period 1970-2012. our findings infirm the existence of ekc whereas they indicate that saudi arabia would be in its ascending phase of the environmental kuznets curve. we notice that the per capita gdp and the per capita energy use increase co 2 emissions whereas trade openness does not have a significant effect on co 2 emissions. our results suggest that growth targets should be accompanied with the measures of adaptation and strategies of development which plan limits in energy use and co 2 emissions in saudi arabia. keywords: economic growth; energy use, co 2 emissions; environmental kuznets curve; saudi arabia.",
            "contribution_ids": [
                "R30122"
            ]
        },
        {
            "instance_id": "R30476xR29487",
            "comparison_id": "R30476",
            "paper_id": "R29487",
            "text": "An Environmental Kuznets Curve Analysis of U.S. State-Level Carbon Dioxide Emissions most environmental kuznets curve (ekc) theories do not apply to carbon dioxide (co 2 )\u2014an unregulated, invisible, odorless gas with no direct human health effects. this analysis addresses the hypothesis that the income-co 2 relationship reflects changes in the composition of an economy as it develops and the associated role of trade in an emissions-intensive good (e.g., electricity). to test this hypothesis, i use a novel data set of 1960 to 1999 state-level co 2 emissions to estimate pretrade (production-based) co 2 ekcs and posttrade (consumption-based) co 2 ekcs. based on the first ekc analysis of co 2 emissions in the united states, i find that consumption-based ekcs peak at significantly higher incomes than production-based ekcs, suggesting that emissions-intensive trade drives, at least in part, the income-emissions relationship. i have also investigated the robustness of the estimated income-co 2 relationship through a variety of specifications. estimated ekcs appear to vary by state, and the estimated income-emissions relationships could be spurious for some states with nonstationary income and emissions data. finally, i find that cold winters, warm summers, and historic coal endowments are positively associated with states\u2019 co 2 emissions.",
            "contribution_ids": [
                "R29488"
            ]
        },
        {
            "instance_id": "R30476xR29970",
            "comparison_id": "R30476",
            "paper_id": "R29970",
            "text": "The potential of renewable energy: using the environmental Kuznets curve model this study examines the potential of renewable energy sources (res) in reducing the impact of carbon emission in malaysia and the greenhouse gas (ghg) emissions, which leads to global warming. using the environmental kuznets curve (ekc) hypothesis, this study analyses the impact of electricity generated using res on the environment and trade openness for the period 1980-2009. using the autoregressive distributed lag (ardl) approach the results show that the elasticities of electricity production from renewable sources with respect to co2 emissions are negative and significant in both the short and long-run. this implies the potential of renewable energy in controlling co2 emissions in both short and long-run in malaysia. renewable energy can ensure sustainability of electricity supply and at the same time can reduce co2 emissions. trade openness has a significant negative effect on co2 emissions in the long-run. the granger causality test based on vector error correction mode (vecm) indicates that there is an evidence of positive bi-directional granger causality relationship between economic growth and co2 emissions in the short and long-run suggesting that carbon emissions and economic growth are interrelated to each other. furthermore, there is a negative long-run bi-directional granger causality relationship between electricity production from renewable sources and co2 emissions. the short-run granger causality shows a negative uni-directional causality for electricity production from renewable sources to co2 emissions. this result suggests that there is an inverted u-shaped relationship between co2 emissions and economic growth.",
            "contribution_ids": [
                "R29971"
            ]
        },
        {
            "instance_id": "R30476xR29907",
            "comparison_id": "R30476",
            "paper_id": "R29907",
            "text": "A panel estimation of the relationship between trade liberalization, economic growth and CO2 emissions in BRICS countries in the last few years, several studies have found an inverted-u relationship between per capita income and environmental degradation. this relationship, known as the environmental kuznets curve (ekc), suggests that environmental degradation increases in the early stages of growth, but it eventually decreases as income exceeds a threshold level. however, this paper investigation relationship between per capita co2 emission, growth economics and trade liberalization based on econometric techniques of unit root test, co-integration and a panel data set during the period 1960-1996 for brics countries. data properties were analyzed to determine their stationarity using the llc , ips , adf and pp unit root tests which indicated that the series are i(1). we find a cointegration relationship between per capita co2 emission, growth economics and trade liberalization by applying kao panel cointegration test. the evidence indi cates that in the long-run trade liberalization has a positive significant impact on co2 emissions and impact of trade liberalization on emissions growth depends on the level of income our findings suggest that there is a quadratic relationship between relationship between real gdp and co2 emissions for the region as a whole. the estimated long-run coefficients of real gdp and its square satisfy the ekc hypothesis in all of studied countries. our estimation shows that the inflection point or optimal point real gdp per capita is about 5269.4 dollars. the results show that on average, sample countries are on the positive side of the inverted u curve. the turning points are very low in some cases and very high in other cases, hence providing poor evidence in support of the ekc hypothesis. thus, our findings suggest that all brics countries need to sacrifice economic growth to decrease their emission levels",
            "contribution_ids": [
                "R29908"
            ]
        },
        {
            "instance_id": "R30476xR30016",
            "comparison_id": "R30476",
            "paper_id": "R30016",
            "text": "An Environment Kuznets Curve for GHG Emissions: A Panel Cointegration Analysis in this article, we attempt to use panel unit root and panel cointegration tests as well as the fully-modified ordinary least squares (ols) approach to examine the relationships among carbon dioxide emissions, energy use and gross domestic product for 22 organization for economic cooperation and development (oecd) countries (annex ii parties) over the 1971\u20132000 period. furthermore, in order to investigate these results for other direct greenhouse gases (ghgs), we have estimated the environmental kuznets curve (ekc) hypothesis by using the total ghg, methane, and nitrous oxide. the empirical results support that energy use still plays an important role in explaining the ghg emissions for oecd countries. in terms of the ekc hypothesis, the results showed that a quadratic relationship was found to exist in the long run. thus, other countries could learn from developed countries in this regard and try to smooth the ekc curve at relatively less cost.",
            "contribution_ids": [
                "R30017"
            ]
        },
        {
            "instance_id": "R30476xR30439",
            "comparison_id": "R30476",
            "paper_id": "R30439",
            "text": "Environmental Kuznets Curve with Adjusted Net Savings as a Trade-Off Between Environment and Development \"the environmental kuznets curve (ekc) hypothesises that emissions first increase at low stages of development then decrease once a certain threshold has been reached. the ekc concept is usually used with per capita gross domestic product as the explanatory variable. as others, we find mixed evidence, at best, of such a pattern for co2 emissions with respect to per capita gdp. we also show that the share of manufacture in gdp and governance/institutions play a significant role in the co2 emissions\u2013income relationship. as gdp presents shortcomings in representing income, development in a broad perspective or human well-being, it is then replaced by the world bank's adjusted net savings (ans, also known as genuine savings). using the ans as an explanatory variable, we show that the ekc is generally empirically supported for co2 emissions. we also show that human capital and natural capital are the main drivers of the downward sloping part of the ekc.\"",
            "contribution_ids": [
                "R30440"
            ]
        },
        {
            "instance_id": "R30476xR30185",
            "comparison_id": "R30476",
            "paper_id": "R30185",
            "text": "The role of renewable energy consumption and trade: environmental Kuznets curve analysis for Sub-Saharan Africa countries type=\"main\" xml:lang=\"en\"> based on the environmental kuznets curve (ekc) hypothesis, this paper uses panel cointegration techniques to investigate the short- and long-run relationship between co 2 emissions, gross domestic product (gdp), renewable energy consumption and international trade for a panel of 24 sub-saharan africa countries over the period 1980\u20132010. short-run granger causality results reveal that there is a bidirectional causality between emissions and economic growth; bidirectional causality between emissions and real exports; unidirectional causality from real imports to emissions; and unidirectional causality runs from trade (exports or imports) to renewable energy consumption. there is an indirect short-run causality running from emissions to renewable energy and an indirect short-run causality from gdp to renewable energy. in the long-run, the error correction term is statistically significant for emissions, renewable energy consumption and trade. the long-run estimates suggest that the inverted u-shaped ekc hypothesis is not supported for these countries; exports have a positive impact on co 2 emissions, whereas imports have a negative impact on co 2 emissions. as a policy recommendation, sub-saharan africa countries should expand their trade exchanges particularly with developed countries and try to maximize their benefit from technology transfer occurring when importing capital goods as this may increase their renewable energy consumption and reduce co 2 emissions.",
            "contribution_ids": [
                "R30186"
            ]
        },
        {
            "instance_id": "R30476xR29380",
            "comparison_id": "R30476",
            "paper_id": "R29380",
            "text": "The environmental Kuznets curve: an empirical analysis this paper examines the relationship between per capita income and a wide range of environmental indicators using cross-country panel sets. the manner in which this has been done overcomes several of the weaknesses asscociated with the estimation of environmental kuznets curves (ekcs). outlined by stern et al. (1996). results suggest that meaningful ekcs exist only for local air pollutants whilst indicators with a more global, or indirect, impact either increase monotonically with income or else have predicted turning points at high per capita income levels with large standard errors \u2013 unless they have been subjected to a multilateral policy initiative. two other findings are also made: that concentration of local pollutants in urban areas peak at a lower per capita income level than total emissions per capita; and that transport-generated local air pollutants peak at a higher per capita income level than total emissions per capita. given these findings, suggestions are made regarding the necessary future direction of environmental policy.",
            "contribution_ids": [
                "R29381"
            ]
        },
        {
            "instance_id": "R30476xR29537",
            "comparison_id": "R30476",
            "paper_id": "R29537",
            "text": "Corruption, trade openness, and environmental quality: a panel data analysis of selected South Asian countries the second half of the twentieth century emerged with two\\n important concepts of the economic world. in the start of the second\\n half, economists, developmentalists, etc., introduced the idea of\\n \u201cdevelopment\u201d, while; latter it was replaced by a more meaningful and\\n attractive term \u201csustainable development\u201d. sustainable development is\\n defined as \u201cbalancing the fulfillment of human needs with the protection\\n of the natural environment so that these needs can be met not only in\\n the present, but also in the indefinite future\u201d [wikipedia (2007)]. or\\n \u201csustainable development means that pattern of development that permits\\n future generations to live at least as well as the current generation\u201d\\n [todaro and smith (2005)], eighth edition]. the field of sustainable\\n development can be conceptually broken into four constituent parts:\\n environmental sustainability, economic sustainability, social\\n sustainability and political sustainability. although, the word\\n sustainable development is very vast and deep, but the main emphasis of\\n our study will be on environmental sustainability.",
            "contribution_ids": [
                "R29538"
            ]
        },
        {
            "instance_id": "R30476xR29404",
            "comparison_id": "R30476",
            "paper_id": "R29404",
            "text": "Richer and cleaner? A study on carbon dioxide emissions in developing countries the climate change debate has drawn attention to the problem of greenhouse gases emissions into the atmosphere. one of the most important issues in the policy debate is the role that should be played by developing countries in joining the commitment of developed countries to reduce ghg emissions, and particularly co2 emissions. this debate calls into play the relationship between energy consumption, co2 emissions and economic development. in this paper we use a panel data model for 110 world countries to estimate the relationship between co2 emissions and gdp and to produce emission forecast. the paper contains three major results: (i) the empirical relationship between carbon dioxide and income is well described by non linear gamma and weibull specifications as opposed to more usual linear and log-linear functional forms; (ii) our single equation reduced form model is comparable in terms of forecasted emissions with other more complex, less data driven models; (iii) despite the decreasing marginal propensity to pollute, our forecasts show that future global emissions will rise. the average world growth of co2 emissions between 2000 and 2020 is about 2.2% per year, while that of non annex 1 countries is posted at 3.3% per year.",
            "contribution_ids": [
                "R29405"
            ]
        },
        {
            "instance_id": "R30476xR30082",
            "comparison_id": "R30476",
            "paper_id": "R30082",
            "text": "An empirical examination of environmental Kuznets curve (EKC) in West Africa this study aims to examine the relationship between income and environmental degradation in west africa and ascertain the validity of ekc hypothesis in the region. the study adopted a panel data approach for fifteen west africa countries for the period 1980-2012. the available results from our estimation procedure confirmed the ekc theory in the region. at early development stages, pollution rises with income and reaching a turning point, pollution dwindles with increasing income; as indicated by the significant inverse relation between income and environmental degradation. consequently, literacy level and sound institutional arrangement were found to contribute significantly in mitigating the extent of environmental degradation. among notable recommendation is the need for awareness campaign on environment abatement and adaptation strategies, strengthening of institutions to caution production and dumping pollution emitting commodities and encourage adoption of cleaner technologies.",
            "contribution_ids": [
                "R30083"
            ]
        },
        {
            "instance_id": "R30476xR29415",
            "comparison_id": "R30476",
            "paper_id": "R29415",
            "text": "An Exploration of the Conceptual and Empirical Basis of the Environmental Kuznets Curve we examine the conceptual and empirical basis of the environmental kuznets curve. from both perspectives, the relationship lacks firm foundations. in particular, the empirical relationship is shown to be highly sensitive to the choice of pollutant, sample of countries and time period. this strongly suggests that there is an omitted variables problem. we find that two important omitted variables are education and inequality. also, we show that the observed relationship is sensitive to the measure of income/welfare used. the paper concludes with a discussion of some policy implications of our findings. copyright 2002 by blackwell publishers ltd/university of adelaide and flinders university of south australia",
            "contribution_ids": [
                "R29416"
            ]
        },
        {
            "instance_id": "R30476xR29751",
            "comparison_id": "R30476",
            "paper_id": "R29751",
            "text": "An Empirical Study on the Environmental Kuznets Curve for China\u00e2\u0080\u0099s Carbon Emissions: Based on Provincial Panel Data abstract based on the environmental kuznets curve theory, the authors choose provincial panel data of china in 1990\u20132007 and adopt panel unit root and co-integration testing method to study whether there is environmental kuznets curve for china\u2019s carbon emissions. the research results show that: carbon emissions per capita of the eastern region and the central region of china fit into environmental kuznets curve, but that of the western region does not. on this basis, the authors carry out scenario analysis on the occurrence time of the inflection point of carbon emissions per capita of different regions, and describe a specific time path.",
            "contribution_ids": [
                "R29752"
            ]
        },
        {
            "instance_id": "R30476xR29564",
            "comparison_id": "R30476",
            "paper_id": "R29564",
            "text": "Carbon emissions in Central and Eastern Europe: environmental Kuznets curve and implications for sustainable development this study examines the impact of various factors such as gross domestic product (gdp) per capita, energy use per capita and trade openness on carbon dioxide (co 2 ) emission per capita in the central and eastern european countries. the extended environmental kuznets curve (ekc) was employed, utilizing the available panel data from 1980 to 2002 for bulgaria, hungary, romania and turkey. the results confirm the existence of an ekc for the region such that co 2 emission per capita decreases over time as the per capita gdp increases. energy use per capita is a significant factor that causes pollution in the region, indicating that the region produces environmentally unclean energy. the trade openness variable implies that globalization has not facilitated the emission level in the region. the results imply that the region needs environmentally cleaner technologies in energy production to achieve sustainable development. copyright \u00a9 2008 john wiley & sons, ltd and erp environment.",
            "contribution_ids": [
                "R29565"
            ]
        },
        {
            "instance_id": "R30476xR29843",
            "comparison_id": "R30476",
            "paper_id": "R29843",
            "text": "An econometric study of carbon dioxide (CO2) emissions, energy consumption, and economic growth of Pakistan purpose the purpose of this paper is to examine the relationship among environmental pollution, economic growth and energy consumption per capita in the case of pakistan. the per capital carbon dioxide (co 2 ) emission is used as the environmental indicator, the commercial energy use per capita as the energy consumption indicator, and the per capita gross domestic product (gdp) as the economic indicator. design/methodology/approach the investigation is made on the basis of the environmental kuznets curve (ekc), using time series data from 1971 to 2006, by applying different econometric tools like adf unit root johansen co\u2010integration vecm and granger causality tests. findings the granger causality test shows that there is a long term relationship between these three indicators, with bidirectional causality between per capita co 2 emission and per capita energy consumption. a monotonically increasing curve between gdp and co 2 emission has been found for the sample period, rejecting the ekc relationship, implying that as per capita gdp increases a linear increase will be observed in per capita co 2 emission. research limitations/implications future research should replace the economic growth variable, i.e. gdp by industrial growth variable because industrial sector is major contributor of pollution by emitting co 2 . practical implications the empirical findings will help the policy makers of pakistan in understanding the severity of the co 2 emissions issue and in developing new standards and monitoring networks for reducing co 2 emissions. originality/value energy consumption is the major cause of environmental pollution in pakistan but no substantial work has been done in this regard with reference to pakistan.",
            "contribution_ids": [
                "R29844"
            ]
        },
        {
            "instance_id": "R30476xR29873",
            "comparison_id": "R30476",
            "paper_id": "R29873",
            "text": "Investigating the energy-environmental Kuznets curve: evidence from Egypt \"this study examines to what extent recent empirical evidence can substantiate the claim that annual emission constraints have a modest effect on long run economic growth rates. the paper studies specifically the contribution of carbon dioxide emissions on growth in egyptian economy during the period 1961-2008. results indicate that there is a negative relationship between gdp per capita and carbon dioxide emissions. results suggest that institutions play an important role to achieve progress in setting an effective policies and regulations to decrease pollutants' level that arise from industries and rationalising the consumption of energy. developing countries and especially egypt need to adopt a set of effective policies to face the vulnerable growth and environmental degradation. based on these results, we assert that environmental policy should consider the different characteristics of each country and type of pollutant.\"",
            "contribution_ids": [
                "R29874"
            ]
        },
        {
            "instance_id": "R30476xR29370",
            "comparison_id": "R30476",
            "paper_id": "R29370",
            "text": "Economic Development and Environmental Quality: An Econometric Analysis the relationship between economic development and environmental quality is analyzed econometrically for a large sample of countries over time. the results indicate that some indicators improve with rising incomes (like water and sanitation), others worsen and then improve (particulates and sulfur oxides), and others worsen steadily (dissolved oxygen in rivers, municipal solid wastes, and carbon emissions). growth tends to be associated with environmental improvements where there are generalized local costs and substantial benefits. but where the costs of environomental degradation are borne by others (by the poor or by other countries), there are few incentives to alter damaging behavior. copyright 1994 by royal economic society.",
            "contribution_ids": [
                "R29371"
            ]
        },
        {
            "instance_id": "R30476xR29384",
            "comparison_id": "R30476",
            "paper_id": "R29384",
            "text": "Are environmental Kuznets curves misleading us? The case of CO2 emissions \" environmental kuznets curve (ekc) analysis links changes in environmental quality to national economic growth. the reduced form models, however, do not provide insight into the underlying processes that generate these changes. we compare ekc models to structural transition models of per capita co 2 emissions and per capita gdp, and find that, for the 16 countries which have undergone such a transition, the initiation of the transition correlates not with income levels but with historic events related to the oil price shocks of the 1970s and the policies that followed them. in contrast to previous ekc studies of co 2 the transition away from positive emissions elasticities for these 16 countries is found to occur as a sudden, discontinuous transition rather than as a gradual change. we also demonstrate that the third order polynomial 'n' dependence of emissions on income is the result of data aggregation. we conclude that neither the 'u'- nor the 'n'-shaped relationship between co 2 emissions and income provide a reliable indication of future behaviour. \"",
            "contribution_ids": [
                "R29385"
            ]
        },
        {
            "instance_id": "R30476xR30159",
            "comparison_id": "R30476",
            "paper_id": "R30159",
            "text": "Investigating the impacts of energy consumption, real GDP, tourism and trade on CO 2 emissions by accounting for cross-sectional dependence: a panel study of OECD countries the objective of this study is to analyse the long-run dynamic relationship of carbon dioxide emissions, real gross domestic product (gdp), the square of real gdp, energy consumption, trade and tourism under an environmental kuznets curve (ekc) model for the organization for economic co-operation and development (oecd) member countries. since we find the presence of cross-sectional dependence within the panel time-series data, we apply second-generation unit root tests, cointegration test and causality test which can deal with cross-sectional dependence problems. the cross-sectionally augmented dickey-fuller (cadf) and the cross-sectionally augmented im-pesaran-shin (cips) unit root tests indicate that the analysed variables become stationary at their first differences. the lagrange multiplier bootstrap panel cointegration test shows the existence of a long-run relationship between the analysed variables. the dynamic ordinary least squares (dols) estimation technique indicates that energy consumption and tourism contribute to the levels of gas emissions, while increases in trade lead to environmental improvements. in addition, the ekc hypothesis cannot be supported as the sign of coefficients on gdp and gdp2 is negative and positive, respectively. moreover, the dumitrescu\u2013hurlin causality tests exploit a variety of causal relationship between the analysed variables. the oecd countries are suggested to invest in improving energy efficiency, regulate necessary environmental protection policies for tourism sector in specific and promote trading activities through several types of encouragement act.",
            "contribution_ids": [
                "R30160"
            ]
        },
        {
            "instance_id": "R30476xR29543",
            "comparison_id": "R30476",
            "paper_id": "R29543",
            "text": "Beyond the Environmental Kuznets Curve: a comparative study of SO2 and CO2 emissions between Japan and China this study is the first systematic attempt to test statistically the contrasting hypotheses on the emission of so 2 and co 2 , and energy consumption in japan and china for the last few decades. we postulate the hypotheses that local governments have incentives to internalize the local external diseconomies caused by so 2 emissions, but not the global external diseconomies caused by co 2 emissions. to substantiate our hypotheses, we decompose emissions of so 2 and co 2 into two factors: the emission factor (i.e. emission per energy use) and energy consumption. the results show that the prefectures where past energy consumption was high tend to reduce the emission factor of so 2 significantly in japan, while we do not find such a tendency in china. there is also evidence that neither per capita income nor past energy consumption affects the co 2 emission factor and energy consumption significantly in both japan and china, implying that an individual country has few incentives to reduce co 2 emissions.",
            "contribution_ids": [
                "R29544"
            ]
        },
        {
            "instance_id": "R30512xR30492",
            "comparison_id": "R30512",
            "paper_id": "R30492",
            "text": "Maintaining levels of activity using a haptic personal training application this paper describes the development of a novel mobile phone-based application designed to monitor the walking habits of older adults. haptic cues integrated within the prototype, are designed to inform an individual of changes which should be made to maintain a prescribed level of activity. a pilot study was conducted with fifteen older adults walking at varying speeds, both with and without the presence of assistive haptic feedback from the prototype. the results confirm that more steps were taken when haptic feedback was provided while walking at normal and fast paces. however, results also indicate that further refinements would be needed to improve the identification of haptic cues while individuals are in motion.",
            "contribution_ids": [
                "R30493"
            ]
        },
        {
            "instance_id": "R30512xR30496",
            "comparison_id": "R30512",
            "paper_id": "R30496",
            "text": "Everywhere Run: a virtual personal trainer for supporting people in their running activity in the last years many medical researches have reported an increase of health problems in developed countries, mostly related to a sedentary lifestyle (as obesity and linked pathologies like diabetes and cardiovascular diseases). as a consequence. many research efforts have been carried out for finding strategies for motivating people to exercise regularly.\\n in this paper we present an android-based mobile application, called everywhere run [1], that aims at motivating and supporting people during their running activities, behaving as a virtual personal trainer. everywhere run fosters the interaction between users and real personal trainers, in order to make it easy to non expert people to start working out in a healthy and safe way.",
            "contribution_ids": [
                "R30497"
            ]
        },
        {
            "instance_id": "R30512xR30480",
            "comparison_id": "R30512",
            "paper_id": "R30480",
            "text": "Move2Play throughout the last decade, there has been an alarming decrease in daily physical activity among both children and adults. medical experts agree that physical activity is critical to maintaining fitness, reducing weight and improving health. yet so many people have difficulty increasing and maintaining physical activity in everyday life. we have created a solution called move2play, which encourages a healthier lifestyle and motivates to participate in regular physical activity. we have integrated four essential parts that form the basis for long-term progress and sustainability - activity recommendation, tracking, evaluation and motivation. in order to recognize and assess physical activity, we have developed a system for mobile phones that collects data from various sensors, such as accelerometer, gps and gsm. we provide personalization, i.e. we have proposed and realized activity recommendation for an individual user to ensure that the users engage in regular exercise, as opposed to occasional outbursts of activity, which are unhealthy and even harmful. we discuss our proposed mechanisms of activity recommendation and the concept of motivation, which represent a key element for any system that fights the sedentary lifestyle of the modern generation.",
            "contribution_ids": [
                "R30481"
            ]
        },
        {
            "instance_id": "R30512xR30498",
            "comparison_id": "R30512",
            "paper_id": "R30498",
            "text": "Bringing mobile guides and fitness activities together \"sports and fitness are increasingly attracting the interest of computer science researchers as well as companies. in particular, recent mobile devices with hardware graphics acceleration offer new, still unexplored possibilities. this paper investigates the use of mobile guides in fitness activities, proposing the mobile personal trainer (mopet) application. mopet uses a gps device to monitor user's position during her physical activity in an outdoor fitness trail. it provides navigation assistance by using a fitness trail map and giving speech directions. moreover, mopet provides motivation support and exercise demonstrations by using an embodied virtual trainer, called evita. evita shows how to correctly perform the exercises along the trail with 3d animations and incites the user. to the best of our knowledge, our project is the first to employ a mobile guide for fitness activities. the effects of mopet on motivation, as well as its navigational and training support, have been experimentally evaluated with 12 users. evaluation results encourage the use of mobile guides and embodied virtual trainers in outdoor fitness applications.\"",
            "contribution_ids": [
                "R30499"
            ]
        },
        {
            "instance_id": "R30512xR30502",
            "comparison_id": "R30512",
            "paper_id": "R30502",
            "text": "A mobile health and fitness companion demonstrator multimodal conversational spoken dialogues using physical and virtual agents provide a potential interface to motivate and support users in the domain of health and fitness. the paper presents a multimodal conversational companion system focused on health and fitness, which has both a stationary and a mobile component.",
            "contribution_ids": [
                "R30503"
            ]
        },
        {
            "instance_id": "R30512xR30490",
            "comparison_id": "R30512",
            "paper_id": "R30490",
            "text": "Activity sensing in the wild \"recent advances in small inexpensive sensors, low-power processing, and activity modeling have enabled applications that use on-body sensing and machine learning to infer people's activities throughout everyday life. to address the growing rate of sedentary lifestyles, we have developed a system, ubifit garden, which uses these technologies and a personal, mobile display to encourage physical activity. we conducted a 3-week field trial in which 12 participants used the system and report findings focusing on their experiences with the sensing and activity inference. we discuss key implications for systems that use on-body sensing and activity inference to encourage physical activity.\"",
            "contribution_ids": [
                "R30491"
            ]
        },
        {
            "instance_id": "R30512xR30506",
            "comparison_id": "R30512",
            "paper_id": "R30506",
            "text": "MPTrain \"we present mptrain, a mobile phone based system that takes advantage of the influence of music in exercise performance, enabling users to more easily achieve their exercise goals. mptrain is designed as a mobile and personal system (hardware and software) that users wear while exercising (walking, jogging or running). mptrain's hardware includes a set of physiological sensors wirelessly connected to a mobile phone carried by the user. mptrain's software allows the user to enter a desired exercise pattern (in terms of desired heart-rate over time) and assists the user in achieving his/her exercising goals by: (1) constantly monitoring the user's physiology (heart-rate in number of beats per minute) and movement (speed in number of steps per minute); and (2) selecting and playing music with specific features that will encourage the user to speed up, slow down or keep the pace to be on track with his/her exercise goals.we describe the hardware and software components of the mptrain system, and present some preliminary results when using mptrain while jogging.\"",
            "contribution_ids": [
                "R30507"
            ]
        },
        {
            "instance_id": "R30512xR30488",
            "comparison_id": "R30512",
            "paper_id": "R30488",
            "text": "Harnessing Different Motivational Frames via Mobile Phones to Promote Daily Physical Activity and Reduce Sedentary Behavior in Aging Adults \"mobile devices are a promising channel for delivering just-in-time guidance and support for improving key daily health behaviors. despite an explosion of mobile phone applications aimed at physical activity and other health behaviors, few have been based on theoretically derived constructs and empirical evidence. eighty adults ages 45 years and older who were insufficiently physically active, engaged in prolonged daily sitting, and were new to smartphone technology, participated in iterative design development and feasibility testing of three daily activity smartphone applications based on motivational frames drawn from behavioral science theory and evidence. an \u201canalytically\u201d framed custom application focused on personalized goal setting, self-monitoring, and active problem solving around barriers to behavior change. a \u201csocially\u201d framed custom application focused on social comparisons, norms, and support. an \u201caffectively\u201d framed custom application focused on operant conditioning principles of reinforcement scheduling and emotional transference to an avatar, whose movements and behaviors reflected the physical activity and sedentary levels of the user. to explore the applications' initial efficacy in changing regular physical activity and leisure-time sitting, behavioral changes were assessed across eight weeks in 68 participants using the champs physical activity questionnaire and the australian sedentary behavior questionnaire. user acceptability of and satisfaction with the applications was explored via a post-intervention user survey. the results indicated that the three applications were sufficiently robust to significantly improve regular moderate-to-vigorous intensity physical activity and decrease leisure-time sitting during the 8-week behavioral adoption period. acceptability of the applications was confirmed in the post-intervention surveys for this sample of midlife and older adults new to smartphone technology. preliminary data exploring sustained use of the applications across a longer time period yielded promising results. the results support further systematic investigation of the efficacy of the applications for changing these key health-promoting behaviors.\"",
            "contribution_ids": [
                "R30489"
            ]
        },
        {
            "instance_id": "R30512xR30486",
            "comparison_id": "R30512",
            "paper_id": "R30486",
            "text": "NEAT-o-Games this article describes research that aims to encourage physical activity through a novel pervasive gaming paradigm. data from a wearable accelerometer are logged wirelessly to a cell phone and control the animation of an avatar that represents the player in a virtual race game with other players over the cellular network. winners are declared every day and players with an excess of activity points can spend some to get hints in mental games of the suite, like sudoku. the racing game runs in the background throughout the day and every little move counts. as the gaming platform is embedded in the daily routine of players, it may act as a strong behavioral modifier and increase everyday physical activity other than volitional sporting exercise. such physical activity (e.g., taking the stairs), is termed neat and was shown to play a major role in obesity prevention and intervention. a pilot experiment demonstrates that players are engaged in neat-o-games and become more physically active while having a good dosage of fun.",
            "contribution_ids": [
                "R30487"
            ]
        },
        {
            "instance_id": "R30579xR30577",
            "comparison_id": "R30579",
            "paper_id": "R30577",
            "text": "Security Challenges for Emerging VANETs vehicle ad-hoc networks (vanets) are a prominent form of mobile ad-hoc networks. this paper outlines the architecture of vanets and discusses the security and privacy challenges that need to be overcome to make such networks practically viable. it compares the various security schemes that were suggested for vanets. it then proposes a new implementation of an identity based cryptosystem that is robust and computationally efficient.",
            "contribution_ids": [
                "R30578"
            ]
        },
        {
            "instance_id": "R30579xR30551",
            "comparison_id": "R30579",
            "paper_id": "R30551",
            "text": "Outlier detection in ad hoc networks using dempster-shafer theory mobile ad-hoc networks (manets) are known to be vulnerable to a variety of attacks due to lack of central authority or fixed network infrastructure. many security schemes have been proposed to identify misbehaving nodes. most of these security schemes rely on either a predefined threshold, or a set of well-defined training data to build up the detection mechanism before effectively identifying the malicious peers. however, it is generally difficult to set appropriate thresholds, and collecting training datasets representative of an attack ahead of time is also problematic. we observe that the malicious peers generally demonstrate behavioral patterns different from all the other normal peers, and argue that outlier detection techniques can be used to detect malicious peers in ad hoc networks. a problem with this approach is combining evidence from potentially untrustworthy peers to detect the outliers. in this paper, an outlier detection algorithm is proposed that applies the dempster-shafer theory to combine observation results from multiple nodes because it can appropriately reflect uncertainty as well as unreliability of the observations. the simulation results show that the proposed scheme is highly resilient to attackers and it can converge stably to a common outlier view amongst distributed nodes with a limited communication overhead.",
            "contribution_ids": [
                "R30552"
            ]
        },
        {
            "instance_id": "R30579xR30558",
            "comparison_id": "R30579",
            "paper_id": "R30558",
            "text": "Privacy-Preserving Detection of Sybil Attacks in Vehicular Ad Hoc Networks vehicular ad hoc networks (vanets) are being advocated for traffic control, accident avoidance, and a variety of other applications. security is an important concern in vanets because a malicious user may deliberately mislead other vehicles and vehicular agencies. one type of malicious behavior is called a sybil attack, wherein a malicious vehicle pretends to be multiple other vehicles. reported data from a sybil attacker will appear to arrive from a large number of distinct vehicles, and hence will be credible. this paper proposes a light-weight and scalable framework to detect sybil attacks. importantly, the proposed scheme does not require any vehicle in the network to disclose its identity, hence privacy is preserved at all times. simulation results demonstrate the efficacy of our protocol.",
            "contribution_ids": [
                "R30559"
            ]
        },
        {
            "instance_id": "R30579xR30553",
            "comparison_id": "R30579",
            "paper_id": "R30553",
            "text": "Detection and localization of sybil nodes in VANETs sybil attacks have been regarded as a serious security threat to ad hoc networks and sensor networks. they may also impair the potential applications of vanets (vehicular ad hoc networks) by creating an illusion of traffic congestion. in this paper, we present a lightweight security scheme for detecting and localizing sybil nodes in vanets, based on statistic analysis of signal strength distribution. our scheme is a distributed and localized approach, in which each vehicle on a road can perform the detection of potential sybil vehicles nearby by verifying their claimed positions. we first introduce a basic signal-strength-based position verification scheme. however, the basic scheme proves to be inaccurate and vulnerable to spoof attacks. in order to compensate for the weaknesses of the basic scheme, we propose a technique to prevent sybil nodes from covering up for each other. in this technique, traffic patterns and support from roadside base stations are used to our advantage. we, then, propose two statistic algorithms to enhance the accuracy of position verification. the algorithms can detect potential sybil attacks by observing the signal strength distribution of a suspect node over a period of time. the statistic nature of our algorithms significantly reduces the verification error rate. finally, we conduct simulations to explore the feasibility of our scheme.",
            "contribution_ids": [
                "R30554"
            ]
        },
        {
            "instance_id": "R30579xR30575",
            "comparison_id": "R30579",
            "paper_id": "R30575",
            "text": "Distributed Misbehavior Detection in VANETs in any vehicular adhoc network, there is always a possibility of incorrect messages being transmitted either due to faulty sensors and/or intentional malicious activities. detecting and evicting sources of such misbehavior is an important problem. we observe that the performance of misbehavior detection schemes will depend on the application under consideration and the mobility dynamics of the detecting vehicle. further, the underlying tradeoff in any such detection algorithm is the balance between false positives and false negatives; one would like to detect as many misbehaviors as possible, while at the same time ensuring that the genuine vehicles are not wrongly accused. \\n \\nin this work we propose and analyze (via simulations) the performance of a misbehavior detection scheme (mds) for post crash notification (pcn) application. we observe that the performance of this proposed scheme is not very sensitive to the exact dynamics of the vehicle on small scales, so that slight error in estimating the dynamics of the detecting vehicle does not degrade the performance of the mds.",
            "contribution_ids": [
                "R30576"
            ]
        },
        {
            "instance_id": "R30579xR30556",
            "comparison_id": "R30579",
            "paper_id": "R30556",
            "text": "P2DAP-sybil attacks detection in vehicular ad hoc networks vehicular ad hoc networks (vanets) are being increasingly advocated for traffic control, accident avoidance, and management of parking lots and public areas. security and privacy are two major concerns in vanets. unfortunately, in vanets, most privacy-preserving schemes are vulnerable to sybil attacks, whereby a malicious user can pretend to be multiple (other) vehicles. in this paper, we present a lightweight and scalable protocol to detect sybil attacks. in this protocol, a malicious user pretending to be multiple (other) vehicles can be detected in a distributed manner through passive overhearing by s set of fixed nodes called road-side boxes (rsbs). the detection of sybil attacks in this manner does not require any vehicle in the network to disclose its identity; hence privacy is preserved at all times. simulation results are presented for a realistic test case to highlight the overhead for a centralized authority such as the dmv, the false alarm rate, and the detection latency. the results also quantify the inherent trade-off between security, i.e., the detection of sybil attacks and detection latency, and the privacy provided to the vehicles in the network. from the results, we see our scheme being able to detect sybil attacks at low overhead and delay, while preserving privacy of vehicles.",
            "contribution_ids": [
                "R30557"
            ]
        },
        {
            "instance_id": "R30579xR30564",
            "comparison_id": "R30579",
            "paper_id": "R30564",
            "text": "A novel defense mechanism against sybil attacks in VANET security is an important concern for many vehicular ad hoc network (vanet) applications. one particular serious attack, known as sybil attack, against ad hoc networks involves an attacker illegitimately claiming multiple identities. in this paper, we present a simple security scheme, based on the difference in movement patterns of sybil nodes and normal nodes, for detecting sybil nodes in vanet. our approach is distributed in nature because all nodes contribute for detection of sybil nodes in vanet and it scales well in an expanding network. in this approach, each road side unit (rsu) calculates and stores different parameter values (received signal strength, distance, angle) after receiving the beacon packets from nearby vehicles. the reason for choosing the angle as one of the parameters is that it will always be different for two vehicles (not moving side-by-side), even if they have same values for distance and received signal strength (rss) with reference to a rsu. the combination of the parameters makes our detection approach highly accurate. after a significant observation period, these rsus exchange their records and calculate the difference of the parameters. if some nodes have same values for the parameters during this observation period, these nodes are classified as sybil nodes. our preliminary simulation results show 99% accuracy and approximately 0.5% error rate, lower as compared to existing techniques.",
            "contribution_ids": [
                "R30565"
            ]
        },
        {
            "instance_id": "R30646xR30644",
            "comparison_id": "R30646",
            "paper_id": "R30644",
            "text": "Automatic eye detection and its validation the accuracy of face alignment affects the performance of a face recognition system. since face alignment is usually conducted using eye positions, an accurate eye localization algorithm is therefore essential for accurate face recognition. in this paper, we first study the impact of eye locations on face recognition accuracy, and then introduce an automatic technique for eye detection. the performance of our automatic eye detection technique is subsequently validated using frgc 1.0 database. the validation shows that our eye detector has an overall 94.5% eye detection rate, with the detected eyes very close to the manually provided eye positions. in addition, the face recognition performance based on the automatic eye detection is shown to be comparable to that of using manually given eye positions.",
            "contribution_ids": [
                "R30645"
            ]
        },
        {
            "instance_id": "R30646xR30592",
            "comparison_id": "R30646",
            "paper_id": "R30592",
            "text": "Regression and Classification Approaches to Eye Localization in Face Images we address the task of accurately localizing the eyes in face images extracted by a face detector, an important problem to be solved because of the negative effect of poor localization on face recognition accuracy. we investigate three approaches to the task: a regression approach aiming to directly minimize errors in the predicted eye positions, a simple bayesian model of eye and non-eye appearance, and a discriminative eye detector trained using adaboost. by using identical training and test data for each method we are able to perform an unbiased comparison. we show that, perhaps surprisingly, the simple bayesian approach performs best on databases including challenging images, and performance is comparable to more complex state-of-the-art methods",
            "contribution_ids": [
                "R30593"
            ]
        },
        {
            "instance_id": "R30646xR30606",
            "comparison_id": "R30646",
            "paper_id": "R30606",
            "text": "2D cascaded AdaBoost for eye localization in this paper, 2d cascaded adaboost, a novel classifier designing framework, is presented and applied to eye localization. by the term \"2d\", we mean that in our method there are two cascade classifiers in two directions: the first one is a cascade designed by bootstrapping the positive samples, and the second one, as the component classifiers of the first one, is cascaded by bootstrapping the negative samples. the advantages of the 2d structure include: (1) it greatly facilitates the classifier designing on huge-scale training set; (2) it can easily deal with the significant variations within the positive (or negative) samples; (3) both the training and testing procedures are more efficient. the proposed structure is applied to eye localization and evaluated on four public face databases, extensive experimental results verified the effectiveness, efficiency, and robustness of the proposed method",
            "contribution_ids": [
                "R30607",
                "R30627"
            ]
        },
        {
            "instance_id": "R30646xR30608",
            "comparison_id": "R30646",
            "paper_id": "R30608",
            "text": "A robust eye localization method for low quality face images eye localization is an important part in face recognition system, because its precision closely affects the performance of face recognition. although various methods have already achieved high precision on the face images with high quality, their precision will drop on low quality images. in this paper, we propose a robust eye localization method for low quality face images to improve the eye detection rate and localization precision. first, we propose a probabilistic cascade (p-cascade) framework, in which we reformulate the traditional cascade classifier in a probabilistic way. the p-cascade can give chance to each image patch contributing to the final result, regardless the patch is accepted or rejected by the cascade. second, we propose two extensions to further improve the robustness and precision in the p-cascade framework. there are: (1) extending feature set, and (2) stacking two classifiers in multiple scales. extensive experiments on jaffe, bioid, lfw and a self-collected video surveillance database show that our method is comparable to state-of-the-art methods on high quality images and can work well on low quality images. this work supplies a solid base for face recognition applications under unconstrained or surveillance environments.",
            "contribution_ids": [
                "R30609",
                "R30623",
                "R30631"
            ]
        },
        {
            "instance_id": "R30646xR30594",
            "comparison_id": "R30646",
            "paper_id": "R30594",
            "text": "Eye Localization based on Multi-Scale Gabor Feature Vector Model eye localization is necessary for face recognition and related application areas. most of eye localization algorithms reported thus far still need to be improved about precision and computational time for successful applications. in this paper, we propose an improved eye localization method based on multi-scale gator feature vector models. the proposed method first tries to locate eyes in the downscaled face image by utilizing gabor jet similarity between gabor feature vector at an initial eye coordinates and the eye model bunch of the corresponding scale. the proposed method finally locates eyes in the original input face image after it processes in the same way recursively in each scaled face image by using the eye coordinates localized in the downscaled image as initial eye coordinates. experiments verify that our proposed method improves the precision rate without causing much computational overhead compared with other eye localization methods reported in the previous researches.",
            "contribution_ids": [
                "R30595",
                "R30610",
                "R30624"
            ]
        },
        {
            "instance_id": "R30646xR30629",
            "comparison_id": "R30646",
            "paper_id": "R30629",
            "text": "Enhanced Pictorial Structures for precise eye localization under incontrolled conditions in this paper, we present an enhanced pictorial structure (ps) model for precise eye localization, a fundamental problem involved in many face processing tasks. ps is a computationally efficient framework for part-based object modelling. for face images taken under uncontrolled conditions, however, the traditional ps model is not flexible enough for handling the complicated appearance and structural variations. to extend ps, we 1) propose a discriminative ps model for a more accurate part localization when appearance changes seriously, 2) introduce a series of global constraints to improve the robustness against scale, rotation and translation, and 3) adopt a heuristic prediction method to address the difficulty of eye localization with partial occlusion. experimental results on the challenging lfw (labeled face in the wild) database show that our model can locate eyes accurately and efficiently under a broad range of uncontrolled variations involving poses, expressions, lightings, camera qualities, occlusions, etc.",
            "contribution_ids": [
                "R30630"
            ]
        },
        {
            "instance_id": "R30646xR30596",
            "comparison_id": "R30646",
            "paper_id": "R30596",
            "text": "Combining Face and Eye Detectors in a High- Performance Face-Detection System a combined face and eye detector system based on multiresolution local ternary patterns and local phase quantization descriptors can achieve noticeable performance improvements by extracting features locally.",
            "contribution_ids": [
                "R30597",
                "R30625"
            ]
        },
        {
            "instance_id": "R30646xR30617",
            "comparison_id": "R30646",
            "paper_id": "R30617",
            "text": "Accurate eye center location and tracking using isophote curvature the ubiquitous application of eye tracking is precluded by the requirement of dedicated and expensive hardware, such as infrared high definition cameras. therefore, systems based solely on appearance (i.e. not involving active infrared illumination) are being proposed in literature. however, although these systems are able to successfully locate eyes, their accuracy is significantly lower than commercial eye tracking devices. our aim is to perform very accurate eye center location and tracking, using a simple web cam. by means of a novel relevance mechanism, the proposed method makes use of isophote properties to gain invariance to linear lighting changes (contrast and brightness), to achieve rotational invariance and to keep low computational costs. in this paper we test our approach for accurate eye location and robustness to changes in illumination and pose, using the bioidand the yale face b databases, respectively. we demonstrate that our system can achieve a considerable improvement in accuracy over state of the art techniques.",
            "contribution_ids": [
                "R30618"
            ]
        },
        {
            "instance_id": "R30646xR30611",
            "comparison_id": "R30646",
            "paper_id": "R30611",
            "text": "Robust Facial Features Localization on Rotation Arbitrary Multi-View face in Complex Background focused on facial features localization on multi-view face arbitrarily rotated in plane, a novel detection algorithm based improved svm is proposed. first, the face is located by the rotation invariant multi-view (rimv) face detector and its pose in plane is corrected by rotation. after the searching ranges of the facial features are determined, the crossing detection method which uses the brow-eye and nose-mouth features and the improved svm detectors trained by large scale multi-view facial features examples is adopted to find the candidate eye, nose and mouth regions,. based on the fact that the window region with higher value in the svm discriminant function is relatively closer to the object, and the same object tends to be repeatedly detected by near windows, the candidate eyes, nose and mouth regions are filtered and merged to refine their location on the multi-view face. experiments show that the algorithm has very good accuracy and robustness to the facial features localization with expression and arbitrary face pose in complex background.",
            "contribution_ids": [
                "R30612",
                "R30636"
            ]
        },
        {
            "instance_id": "R30646xR30634",
            "comparison_id": "R30646",
            "paper_id": "R30634",
            "text": "For your eyes only in this paper, we take a look at an enhanced approach for eye detection under difficult acquisition circumstances such as low-light, distance, pose variation, and blur. we present a novel correlation filter based eye detection pipeline that is specifically designed to reduce face alignment errors, thereby increasing eye localization accuracy and ultimately face recognition accuracy. the accuracy of our eye detector is validated using data derived from the labeled faces in the wild (lfw) and the face detection on hard datasets competition 2011 (fdhd) sets. the results on the lfw dataset also show that the proposed algorithm exhibits enhanced performance, compared to another correlation filter based detector, and that a considerable increase in face recognition accuracy may be achieved by focusing more effort on the eye localization stage of the face recognition process. our results on the fdhd dataset show that our eye detector exhibits superior performance, compared to 11 different state-of-the-art algorithms, on the entire set of difficult data without any per set modifications to our detection or preprocessing algorithms. the immediate application of eye detection is automatic face recognition, though many good applications exist in other areas, including medical research, training simulators, communication systems for the disabled, and automotive engineering.",
            "contribution_ids": [
                "R30635"
            ]
        },
        {
            "instance_id": "R30698xR30696",
            "comparison_id": "R30698",
            "paper_id": "R30696",
            "text": "Dental erosion in Cuban children associated with excessive consumption of oranges marked erosion at the mesial edges of upper front teeth was observed during an examination of cuban children. the preferential erosion of mesial edges produced characteristic v-shaped defects on upper central incisors, and the aim of the present study, carried out on 12-yr-old children (n = 1010) in 10 communities in the province of havana was to establish the frequency of dental erosion and explain its occurrence. the symmetrical erosion of teeth 11 and 21 (excluding crown injuries and attrition) were clinically classified into four grades: 0.5 = objectionable; 1 = abnormal mesial shortening of incisal edges; 2 = v-shaped defect of cutting edges; 3 = exposure of dentine and extension of the erosive defect to the lateral incisors. in four of the communities, children did not show or rarely showed incisal erosion. in the other six communities, the frequency was surprisingly high (16.6-40.9%). overall, 17.4% of children exhibited erosion, and the occurrence was significantly higher in girls (20.7%) than in boys (15.0%). the typical v-shaped pattern of erosion seems to be a consequence of the manner in which citrus fruits are eaten. there was also a positive correlation between the frequency of dental erosion and the proximity of citrus plantations, which presumably related to the extent of (daily) orange consumption.",
            "contribution_ids": [
                "R30697"
            ]
        },
        {
            "instance_id": "R30698xR30658",
            "comparison_id": "R30698",
            "paper_id": "R30658",
            "text": "Dental erosion in 12-year-old schoolchildren: A cross- sectional study in Southern Brazil \"objective\\nthe aim of this study was to assess the prevalence and severity of dental erosion among 12-year-old schoolchildren in joa\u00e7aba, southern brazil, and to compare prevalence between boys and girls, and between public and private school students.\\n\\n\\nmethods\\na cross-sectional study was carried out involving all of the municipality's 499, 12-year-old schoolchildren. the dental erosion index proposed by o'sullivan was used for the four maxillary incisors. data analysis included descriptive statistics, location, distribution, and extension of affected area and severity of dental erosion.\\n\\n\\nresults\\nthe prevalence of dental erosion was 13.0% (95% confidence interval = 9.0-17.0). there was no statistically significant difference in prevalence between boys and girls, but prevalence was higher in private schools (21.1%) than in public schools (9.7%) (p < 0.001). labial surfaces were less often affected than palatal surfaces. enamel loss was the most prevalent type of dental erosion (4.86 of 100 incisors). sixty-three per cent of affected teeth showed more than a half of their surface affected.\\n\\n\\nconclusion\\nthe prevalence of dental erosion in 12-year-old schoolchildren living in a small city in southern brazil appears to be lower than that seen in most of epidemiological studies carried out in different parts of the world. further longitudinal studies should be conducted in brazil in order to measure the incidence of dental erosion and its impact on children's quality of life.\"",
            "contribution_ids": [
                "R30659"
            ]
        },
        {
            "instance_id": "R30698xR30689",
            "comparison_id": "R30698",
            "paper_id": "R30689",
            "text": "Erosion, caries and rampant caries in preschool children in Jeddah, Saudi Arabia objectives\\nthe objective of this study was to determine the prevalence of dental erosion in preschool children in jeddah, saudi arabia, and to relate this to caries and rampant caries in the same children.\\n\\n\\nmethods\\na sample of 987 children (2-5 years) was drawn from 17 kindergartens. clinical examinations were carried out under standardised conditions by a trained and calibrated examiner (m.al-m.). measurement of erosion was confined to primary maxillary incisors and used a scoring system and criteria based on those used in the uk national survey of child dental health. caries was diagnosed using bascd criteria. rampant caries was defined as caries affecting the smooth surfaces of two or more maxillary incisors.\\n\\n\\nresults\\nof the 987 children, 309 (31%) had evidence of erosion. for 186 children this was confined to enamel but for 123 it involved dentine and/or pulp. caries were diagnosed in 720 (73%) of the children and rampant caries in 336 (34%). the mean dmft for the 987 children was 4.80 (+/-4.87). of the 384 children who had caries but not rampant caries, 141 (37%) had erosion, a significantly higher proportion than the 72 (27%) out of 267 who were clinically caries free (snd=2.61, p<0.01). of the 336 with rampant caries, 96 (29%) also had evidence of erosion.\\n\\n\\nconclusions\\nthe level of erosion was similar to that seen in children of an equivalent age in the uk. caries was a risk factor for erosion in this group of children.",
            "contribution_ids": [
                "R30690"
            ]
        },
        {
            "instance_id": "R30698xR30680",
            "comparison_id": "R30698",
            "paper_id": "R30680",
            "text": "Oral health of children with gastro-esophageal reflux disease: a controlled study background\\nthe aim of this study was to compare the dental health of children with gastro-esophageal reflux disease (gerd) with a healthy control group.\\n\\n\\nmethods\\ndental examinations were conducted for 52 children (31 boys and 21 girls) with a definitive history of gerd. for every subject enrolled in the study, a healthy control sibling without the condition was recruited. medical histories were obtained from medical records, and dental and dietary histories were obtained from parents. the teeth were examined for erosion, dental caries, and enamel hypoplasia, and sampled for streptococcus mutans.\\n\\n\\nresults\\nthe prevalence of erosion by teeth was found to be statistically significant between gerd patients (14 per cent) and controls (10 per cent) (p<0.05). gerd patients had erosion in more permanent teeth compared to controls (4 per cent vs 0.8 per cent, p<0.05), and more severe erosion (p<0.05). caries experience was also higher in gerd patients compared to controls (p<0.05). although there were more subjects with streptococcus mutans in the gerd group compared to the control group (42 per cent vs 25 per cent), the difference was not statistically significant.\\n\\n\\nconclusions\\nchildren with gerd have more erosion and dental caries compared to healthy controls and should be targeted for increased preventive and restorative care.",
            "contribution_ids": [
                "R30681"
            ]
        },
        {
            "instance_id": "R30698xR30651",
            "comparison_id": "R30698",
            "paper_id": "R30651",
            "text": "Prevalence of erosive tooth wear and associated risk factors in 2-7-year-old German kindergarten children \"objectives\\nthe aims of this study were to (1) investigate prevalence and severity of erosive tooth wear among kindergarten children and (2) determine the relationship between dental erosion and dietary intake, oral hygiene behaviour, systemic diseases and salivary concentration of calcium and phosphate.\\n\\n\\nmaterials and methods\\na sample of 463 children (2-7 years old) from 21 kindergartens were examined under standardized conditions by a calibrated examiner. dental erosion of primary and permanent teeth was recorded using a scoring system based on o'sullivan index [eur j paediatr dent 2 (2000) 69]. data on the rate and frequency of dietary intake, systemic diseases and oral hygiene behaviour were obtained from a questionnaire completed by the parents. unstimulated saliva samples of 355 children were analysed for calcium and phosphate concentration by colorimetric assessment. descriptive statistics and multiple regression analysis were applied to the data.\\n\\n\\nresults\\nprevalence of erosion amounted to 32% and increased with increasing age of the children. dentine erosion affecting at least one tooth could be observed in 13.2% of the children. the most affected teeth were the primary maxillary first and second incisors (15.5-25%) followed by the canines (10.5-12%) and molars (1-5%). erosions on primary mandibular teeth were as follows: incisors: 1.5-3%, canines: 5.5-6% and molars: 3.5-5%. erosions of the primary first and second molars were mostly seen on the occlusal surfaces (75.9%) involving enamel or enamel-dentine but not the pulp. in primary first and second incisors and canines, erosive lesions were often located incisally (51.2%) or affected multiple surfaces (28.9%). none of the permanent incisors (n = 93) or first molars (n=139) showed signs of erosion. dietary factors, oral hygiene behaviour, systemic diseases and salivary calcium and phosphate concentration were not associated with the presence of erosion.\\n\\n\\nconclusions\\nerosive tooth wear of primary teeth was frequently seen in primary dentition. as several children showed progressive erosion into dentine or exhibited severe erosion affecting many teeth, preventive and therapeutic measures are recommended.\"",
            "contribution_ids": [
                "R30652"
            ]
        },
        {
            "instance_id": "R30698xR30673",
            "comparison_id": "R30698",
            "paper_id": "R30673",
            "text": "Smile aesthetics and malocclusion in UK teenage magazines assessed using the Index of Orthodontic Treatment Need (IOTN) \"objective there is a significant demand for orthodontic treatment within the uk from adolescent girls, a group known to be influenced by the media portrayal of body form and body image, which may extend to the presentation of malocclusions. this study examined the portrayal of malocclusion in a media type that targets teenage girls under 16 years of age. materials and methods a representative selection of 1 month's magazines targeting this group were investigated, and the frequency and severity of malocclusions displayed were assessed. two calibrated examiners viewed all the smiles (on two occasions) using a modification of index of orthodontic treatment need (iotn) and assigned an aesthetic component score to each smile. results it was found that the aesthetic score is low (less than 7) for the majority of models (92.8%) indicating no need or a borderline need for treatment. only 7.2% of models exhibited a definite need for treatment. conclusion it appears that the portrayal of malocclusion in teenage magazines does not reflect the general treatment need of the adolescent population.\"",
            "contribution_ids": [
                "R30674"
            ]
        },
        {
            "instance_id": "R30698xR30666",
            "comparison_id": "R30698",
            "paper_id": "R30666",
            "text": "Caries trends 1996-2002 among 6- and 12-year-old children and erosive wear prevalence among 12-year-old children in The Hague in 2002 a dental survey amongst 6- and 12-year-old schoolchildren (n = 832) in the hague was carried out. the caries findings were compared with findings from earlier studies in the hague. caries prevalence (% of caries-free children) and caries experience (mean dmfs scores) among 6-year-old children had not changed significantly in the period 1996\u20132002. however, a significant increase of caries-free 12-year-old children of low socio-economic status was found in the period 1996\u20132002. the proportions of caries-free 12-year-old dutch, turkish and moroccan children of low socio-economic status were 88, 69 and 78%, respectively, in 2002. the average dmft score of 12-year-olds reached a minimum of 0.2. in 2002, 24% of the 12-year-olds exhibited signs of erosion, indicating that the presence of erosive wear was high among youngsters in the hague.",
            "contribution_ids": [
                "R30667"
            ]
        },
        {
            "instance_id": "R30739xR30728",
            "comparison_id": "R30739",
            "paper_id": "R30728",
            "text": "The prevalence, aetiology and clinical appearance of tooth wear: the Nigerian experience \"objective\\nto establish the prevalence and severity of tooth wear among nigerians and to compare the pattern and aetiology with findings of earlier studies in western populations.\\n\\n\\ndesign\\nclinical examinations for tooth wear using the tooth wear index (twi).\\n\\n\\nsetting\\nthe federal republic of nigeria.\\n\\n\\nparticipants\\npatients attending the dental hospital, obafemi awolowo university teaching hospital's complex ile-ife.\\n\\n\\noutcome measures\\nattrition, abrasion and erosion.\\n\\n\\nresults\\nof the 126 patients with tooth wear 81 had attrition, 20 had abrasion, 9 had erosion and 16 had attrition and abrasion combined. a total of 15,480 tooth surfaces were examined. 2,229 (14.4%) surfaces had tooth wear out of which 1,007 (6.5%) were pathologically worn down. the frequency of tooth wear increased with the age of patients. most of the pathologically worn surfaces were just one point above maximum acceptable value.\\n\\n\\nconclusions\\nthe aetiological factors associated with tooth wear are not different from those encountered in western cultures but the pattern of wear differs. pathological tooth wear presents as an age related phenomenon and is probably more severe in nigerians.\"",
            "contribution_ids": [
                "R30729"
            ]
        },
        {
            "instance_id": "R30739xR30733",
            "comparison_id": "R30739",
            "paper_id": "R30733",
            "text": "Oral health status of workers exposed to acid fumes in phosphate and battery industries in Jordan \"objectives\\nto investigate the prevalence and nature of oral health problems among workers exposed to acid fumes in two industries in jordan.\\n\\n\\nsetting\\njordan's phosphate mining company and a main private battery factory.\\n\\n\\ndesign\\ncomparison of general and oral health conditions between workers exposed to acid fumes and control group from the same workplace.\\n\\n\\nsubjects and methods\\nthe sample consisted of 68 subjects from the phosphate industry (37 acid workers and 31 controls) drawn as a sample of convenience and 39 subjects from a battery factory (24 acid workers and 15 controls). structured questionnaires on medical and dental histories were completed by interview. clinical examinations were carried out to assess dental erosion, oral hygiene, and gingival health using the appropriate indices. data were statistically analysed using wilcoxon rank-sum test to assess the significance of differences between results attained by acid workers and control groups for the investigated parameters.\\n\\n\\nresults\\ndifferences in the erosion scores between acid workers in both industries and their controls were highly significant (p<0.05). in both industries, acid workers showed significantly higher oral hygiene scores, obtained by adding the debris and calculus scores, and gingival index scores than their controls (p<0.05). the single most common complaint was tooth hypersensitivity (80%) followed by dry mouth (77%) on average.\\n\\n\\nconclusion\\nexposure to acid fumes in the work place was significantly associated with dental erosion and deteriorated oral health status. such exposure was also detrimental to general health. findings pointed to the need of establishing appropriate educational, preventive and treatment measures coupled with efficient surveillance and environmental monitoring for detection of acid fumes in the workplace atmosphere.\"",
            "contribution_ids": [
                "R30734"
            ]
        },
        {
            "instance_id": "R30739xR30717",
            "comparison_id": "R30739",
            "paper_id": "R30717",
            "text": "The prevalence of non-carious cervical lesions in permanent dentition a non-carious cervical lesion (nccl) is the loss of hard dental tissue on the neck of the tooth, most frequently located on the vestibular plane. causal agents are diverse and mutually interrelated. in the present study all vestibular nccl were observed and recorded by the tooth wear index (twi). the aim of the study was to determine the prevalence and severity of nccl. for this purpose, 18555 teeth from the permanent dentition were examined in a population from the city of rijeka, croatia. subjects were divided into six age groups. the teeth with most nccl were the lower premolars, which also had the largest percentage of higher index levels, indicating the greater severity of the lesions. the most frequent index level was 1, and the prevalence and severity of the lesions increased with age.",
            "contribution_ids": [
                "R30718"
            ]
        },
        {
            "instance_id": "R30739xR30735",
            "comparison_id": "R30739",
            "paper_id": "R30735",
            "text": "Patterns of tooth wear associated with methamphetamine use background\\nmethamphetamine (map) abuse is a significant worldwide problem. this prospective study was conducted to determine if map users had distinct patterns of tooth wear.\\n\\n\\nmethods\\nmethamphetamine users were identified and interviewed about their duration and preferred route of map use. study participants were interviewed in the emergency department of a large urban university hospital serving a geographic area with a high rate of illicit map production and consumption. tooth wear was documented for each study participant and scored using a previously validated index and demographic information was obtained using a questionnaire.\\n\\n\\nresults\\nforty-three map patients were interviewed. preferred route of administration was injection (37%) followed by snorting (33%). patients who preferentially snorted map had significantly higher tooth wear in the anterior maxillary teeth than patients who injected, smoked, or ingested map (p = 0.005).\\n\\n\\nconclusion\\npatients who use map have distinct patterns of wear based on route of administration. this difference may be explained anatomically.",
            "contribution_ids": [
                "R30736"
            ]
        },
        {
            "instance_id": "R30739xR30726",
            "comparison_id": "R30739",
            "paper_id": "R30726",
            "text": "Relationship between sports drinks and dental erosion in 304 university athletes in Columbus acidic soft drinks, including sports drinks, have been implicated in dental erosion with limited supporting data in scarce erosion studies worldwide. the purpose of this study was to determine the prevalence of dental erosion in a sample of athletes at a large midwestern state university in the usa, and to evaluate whether regular consumption of sports drinks was associated with dental erosion. a cross-sectional, observational study was done using a convenience sample of 304 athletes, selected irrespective of sports drinks usage. the lussi index was used in a blinded clinical examination to grade the frequency and severity of erosion of all tooth surfaces excluding third molars and incisal surfaces of anterior teeth. a self-administered questionnaire was used to gather details on sports drink usage, lifestyle, health problems, dietary and oral health habits. intraoral color slides were taken of all teeth with erosion. sports drinks usage was found in 91.8% athletes and the total prevalence of erosion was 36.5%. nonparametric tests and stepwise regression analysis using history variables showed no association between dental erosion and the use of sports drinks, quantity and frequency of consumption, years of usage and nonsport usage of sports drinks. the most significant predictor of erosion was found to be not belonging to the african race (p &lt; 0.0001). the results of this study reveal no relationship between consumption of sports drinks and dental erosion.",
            "contribution_ids": [
                "R30727"
            ]
        },
        {
            "instance_id": "R30817xR30753",
            "comparison_id": "R30817",
            "paper_id": "R30753",
            "text": "The evacuation optimal network design problem: model formulation and comparisons abstract the goal of this paper is twofold. first, we present a stochastic programming-based model that provides optimal design solutions for transportation networks in light of possible emergency evacuations. second, as traffic congestion is a growing problem in metropolitan areas around the world, decision makers might not be willing to design transportation networks solely for evacuation purposes since daily traffic patterns differ tremendously from traffic observed during evacuations. this is especially true when potential disaster locations are limited in number and confined to specific regions (e.g. coastal regions might be more prone to flooding). however, as extreme events such as excessive rainfall become more prevalent everywhere, it is less obvious that the design of transportation networks for evacuation planning and congestion reduction is mutually exclusive. that is, capacity expansion decisions to reduce congestion might also be reasonable from an evacuation planning point of view. conversely, expansion decisions for evacuation planning might turn out to be effective for congestion relief. to date, no numerical evidence has been presented in the literature to support or disprove these conjectures. preliminary numerical evidence is provided in this paper.",
            "contribution_ids": [
                "R30754",
                "R30842",
                "R30921",
                "R30978",
                "R31110"
            ]
        },
        {
            "instance_id": "R30817xR30811",
            "comparison_id": "R30817",
            "paper_id": "R30811",
            "text": "Two-Stage Multiobjective Optimization for Emergency Supplies Allocation Problem under Integrated Uncertainty this paper proposes a new two-stage optimization method for emergency supplies allocation problem with multisupplier, multiaffected area, multirelief, and multivehicle. the triplet of supply, demand, and the availability of path is unknown prior to the extraordinary event and is descriptive with fuzzy random variable. considering the fairness, timeliness, and economical efficiency, a multiobjective expected value model is built for facility location, vehicle routing, and supply allocation decisions. the goals of proposed model aim to minimize the proportion of demand nonsatisfied and response time of emergency reliefs and the total cost of the whole process. when the demand and the availability of path are discrete, the expected values in the objective functions are converted into their equivalent forms. when the supply amount is continuous, the equilibrium chance in the constraint is transformed to its equivalent one. to overcome the computational difficulty caused by multiple objectives, a goal programming model is formulated to obtain a compromise solution. finally, an example is presented to illustrate the validity of the proposed model and the effectiveness of the solution method.",
            "contribution_ids": [
                "R30812",
                "R30913",
                "R30949",
                "R31066",
                "R31155"
            ]
        },
        {
            "instance_id": "R30817xR30763",
            "comparison_id": "R30817",
            "paper_id": "R30763",
            "text": "Stochastic Optimization for Natural Disaster Asset Prepositioning \"a key strategic issue in pre-disaster planning for humanitarian logistics is the pre-establishment of adequate capacity and resources that enable efficient relief operations. this paper develops a two-stage stochastic optimization model to guide the allocation of budget to acquire and position relief assets, decisions that typically need to be made well in advance before a disaster strikes. the optimization focuses on minimizing the expected number of casualties, so our model includes first-stage decisions to represent the expansion of resources such as warehouses, medical facilities with personnel, ramp spaces, and shelters. second-stage decisions concern the logistics of the problem, where allocated resources and contracted transportation assets are deployed to rescue critical population (in need of emergency evacuation), deliver required commodities to stay-back population, and transport the transfer population displaced by the disaster. because of the uncertainty of the event's location and severity, these and other parameters are represented as scenarios. computational results on notional test cases provide guidance on budget allocation and prove the potential benefit of using stochastic optimization.\"",
            "contribution_ids": [
                "R30764",
                "R30857",
                "R30926",
                "R30995",
                "R31118"
            ]
        },
        {
            "instance_id": "R30817xR30747",
            "comparison_id": "R30817",
            "paper_id": "R30747",
            "text": "Decomposition algorithms for the design of a nonsimultaneous capacitated evacuation tree network \"in this article, we examine the design of an evacuation tree, in which evacuation is subject to capacity restrictions on arcs. the cost of evacuating people in the network is determined by the sum of penalties incurred on arcs on which they travel, where penalties are determined according to a nondecreasing function of time. given a discrete set of disaster scenarios affecting network population, arc capacities, transit times, and penalty functions, we seek to establish an optimal a priori evacuation tree that minimizes the expected evacuation penalty. the solution strategy is based on benders decomposition, in which the master problem is a mixed\u2010integer program and each subproblem is a time\u2010expanded network flow problem. we provide efficient methods for obtaining primal and dual subproblem solutions, and analyze techniques for improving the strength of the master problem formulation, thus reducing the number of master problem solutions required for the algorithm's convergence. we provide computational results to compare the efficiency of our methods on a set of randomly generated test instances. \u00a9 2008 wiley periodicals, inc. networks, 2009\"",
            "contribution_ids": [
                "R30748",
                "R30832",
                "R30918",
                "R30967",
                "R31105"
            ]
        },
        {
            "instance_id": "R30817xR30745",
            "comparison_id": "R30817",
            "paper_id": "R30745",
            "text": "Facility location in humanitarian relief \"in this study, we consider facility location decisions for a humanitarian relief chain responding to quick-onset disasters. in particular, we develop a model that determines the number and locations of distribution centres in a relief network and the amount of relief supplies to be stocked at each distribution centre to meet the needs of people affected by the disasters. our model, which is a variant of the maximal covering location model, integrates facility location and inventory decisions, considers multiple item types, and captures budgetary constraints and capacity restrictions. we conduct computational experiments to illustrate how the proposed model works on a realistic problem. results show the effects of pre- and post-disaster relief funding on relief system's performance, specifically on response time and the proportion of demand satisfied. finally, we discuss the managerial implications of the proposed model.\"",
            "contribution_ids": [
                "R30746",
                "R30829",
                "R30917",
                "R30964",
                "R31103"
            ]
        },
        {
            "instance_id": "R30817xR30805",
            "comparison_id": "R30817",
            "paper_id": "R30805",
            "text": "Bi-objective stochastic programming models for determining depot locations in disaster relief operations this paper presents two-stage bi-objective stochastic programming models for disaster relief operations. we consider a problem that occurs in the aftermath of a natural disaster: a transportation system for supplying disaster victims with relief goods must be established. we propose bi-objective optimization models with a monetary objective and humanitarian objective. uncertainty in the accessibility of the road network is modeled by a discrete set of scenarios. the key features of our model are the determination of locations for intermediate depots and acquisition of vehicles. several model variants are considered. first, the operating budget can be fixed at the first stage for all possible scenarios or determined for each scenario at the second stage. second, the assignment of vehicles to a depot can be either fixed or free. third, we compare a heterogeneous vehicle fleet to a homogeneous fleet. we study the impact of the variants on the solutions. the set of pareto-optimal solutions is computed by applying the adaptive epsilon-constraint method. we solve the deterministic equivalents of the two-stage stochastic programs using the mip-solver cplex.",
            "contribution_ids": [
                "R30806",
                "R31089",
                "R31098",
                "R31151"
            ]
        },
        {
            "instance_id": "R30817xR30767",
            "comparison_id": "R30817",
            "paper_id": "R30767",
            "text": "A two\u00e2\u0080\u0090stage procurement model for humanitarian relief supply chains purpose the purpose of this paper is to discuss and to help address the need for quantitative models to support and improve procurement in the context of humanitarian relief efforts. design/methodology/approach this research presents a two\u2010stage stochastic decision model with recourse for procurement in humanitarian relief supply chains, and compares its effectiveness on an illustrative example with respect to a standard solution approach. findings results show the ability of the new model to capture and model both the procurement process and the uncertainty inherent in a disaster relief situation, in support of more efficient and effective procurement plans. research limitations/implications the research focus is on sudden onset disasters and it does not differentiate between local and international suppliers. a number of extensions of the base model could be implemented, however, so as to address the specific needs of a given organization and their procurement process. practical implications despite the prevalence of procurement expenditures in humanitarian efforts, procurement in humanitarian contexts is a topic that previously has only been discussed in a qualitative manner in the literature. this work provides practitioners with a new approach to quantitatively assess and improve their procurement decision processes. originality/value this study adds to the existing literature by demonstrating the applicability and effectiveness of an analytic modeling technique based on uncertainty, such as stochastic programming with recourse, in the context of humanitarian relief procurement activities.",
            "contribution_ids": [
                "R30768",
                "R31082",
                "R31092",
                "R31120"
            ]
        },
        {
            "instance_id": "R30914xR30753",
            "comparison_id": "R30914",
            "paper_id": "R30753",
            "text": "The evacuation optimal network design problem: model formulation and comparisons abstract the goal of this paper is twofold. first, we present a stochastic programming-based model that provides optimal design solutions for transportation networks in light of possible emergency evacuations. second, as traffic congestion is a growing problem in metropolitan areas around the world, decision makers might not be willing to design transportation networks solely for evacuation purposes since daily traffic patterns differ tremendously from traffic observed during evacuations. this is especially true when potential disaster locations are limited in number and confined to specific regions (e.g. coastal regions might be more prone to flooding). however, as extreme events such as excessive rainfall become more prevalent everywhere, it is less obvious that the design of transportation networks for evacuation planning and congestion reduction is mutually exclusive. that is, capacity expansion decisions to reduce congestion might also be reasonable from an evacuation planning point of view. conversely, expansion decisions for evacuation planning might turn out to be effective for congestion relief. to date, no numerical evidence has been presented in the literature to support or disprove these conjectures. preliminary numerical evidence is provided in this paper.",
            "contribution_ids": [
                "R30754",
                "R30842",
                "R30921",
                "R30978",
                "R31110"
            ]
        },
        {
            "instance_id": "R30914xR30807",
            "comparison_id": "R30914",
            "paper_id": "R30807",
            "text": "Implementation of Equity in Resource Allocation for Regional Earthquake Risk Mitigation Using Two-Stage Stochastic Programming this article presents a new methodology to implement the concept of equity in regional earthquake risk mitigation programs using an optimization framework. it presents a framework that could be used by decisionmakers (government and authorities) to structure budget allocation strategy toward different seismic risk mitigation measures, i.e., structural retrofitting for different building structural types in different locations and planning horizons. a two\u2010stage stochastic model is developed here to seek optimal mitigation measures based on minimizing mitigation expenditures, reconstruction expenditures, and especially large losses in highly seismically active countries. to consider fairness in the distribution of financial resources among different groups of people, the equity concept is incorporated using constraints in model formulation. these constraints limit inequity to the user\u2010defined level to achieve the equity\u2010efficiency tradeoff in the decision\u2010making process. to present practical application of the proposed model, it is applied to a pilot area in tehran, the capital city of iran. building stocks, structural vulnerability functions, and regional seismic hazard characteristics are incorporated to compile a probabilistic seismic risk model for the pilot area. results illustrate the variation of mitigation expenditures by location and structural type for buildings. these expenditures are sensitive to the amount of available budget and equity consideration for the constant risk aversion. most significantly, equity is more easily achieved if the budget is unlimited. conversely, increasing equity where the budget is limited decreases the efficiency. the risk\u2010return tradeoff, equity\u2010reconstruction expenditures tradeoff, and variation of per\u2010capita expected earthquake loss in different income classes are also presented.",
            "contribution_ids": [
                "R30808",
                "R30906",
                "R30947",
                "R31058",
                "R31152"
            ]
        },
        {
            "instance_id": "R30914xR30745",
            "comparison_id": "R30914",
            "paper_id": "R30745",
            "text": "Facility location in humanitarian relief \"in this study, we consider facility location decisions for a humanitarian relief chain responding to quick-onset disasters. in particular, we develop a model that determines the number and locations of distribution centres in a relief network and the amount of relief supplies to be stocked at each distribution centre to meet the needs of people affected by the disasters. our model, which is a variant of the maximal covering location model, integrates facility location and inventory decisions, considers multiple item types, and captures budgetary constraints and capacity restrictions. we conduct computational experiments to illustrate how the proposed model works on a realistic problem. results show the effects of pre- and post-disaster relief funding on relief system's performance, specifically on response time and the proportion of demand satisfied. finally, we discuss the managerial implications of the proposed model.\"",
            "contribution_ids": [
                "R30746",
                "R30829",
                "R30917",
                "R30964",
                "R31103"
            ]
        },
        {
            "instance_id": "R30914xR30763",
            "comparison_id": "R30914",
            "paper_id": "R30763",
            "text": "Stochastic Optimization for Natural Disaster Asset Prepositioning \"a key strategic issue in pre-disaster planning for humanitarian logistics is the pre-establishment of adequate capacity and resources that enable efficient relief operations. this paper develops a two-stage stochastic optimization model to guide the allocation of budget to acquire and position relief assets, decisions that typically need to be made well in advance before a disaster strikes. the optimization focuses on minimizing the expected number of casualties, so our model includes first-stage decisions to represent the expansion of resources such as warehouses, medical facilities with personnel, ramp spaces, and shelters. second-stage decisions concern the logistics of the problem, where allocated resources and contracted transportation assets are deployed to rescue critical population (in need of emergency evacuation), deliver required commodities to stay-back population, and transport the transfer population displaced by the disaster. because of the uncertainty of the event's location and severity, these and other parameters are represented as scenarios. computational results on notional test cases provide guidance on budget allocation and prove the potential benefit of using stochastic optimization.\"",
            "contribution_ids": [
                "R30764",
                "R30857",
                "R30926",
                "R30995",
                "R31118"
            ]
        },
        {
            "instance_id": "R30914xR30790",
            "comparison_id": "R30914",
            "paper_id": "R30790",
            "text": "Prepositioning emergency supplies to support disaster relief: a stochastic programming approach abstract this paper studies the strategic problem of designing emergency supply networks to support disaster relief over a planning horizon. the problem addresses decisions on the location and number of distribution centres needed, their capacity, and the quantity of each emergency item to keep in stock. it builds on a case study inspired by real-world data obtained from the north carolina emergency management division (ncem) and the federal emergency management agency (fema). to tackle the problem, a scenario-based approach is proposed involving three phases: disaster scenario generation, design generation and design evaluation. disasters are modelled as stochastic processes and a monte carlo procedure is derived to generate plausible catastrophic scenarios. based on this detailed representation of disasters, a multi-phase modelling framework is proposed to design the emergency supply network. the two-stage stochastic programming model proposed is solved using a sample average approximation method. this scenario-based solution approach is applied to the case study to generate plausible scenarios, to produce alternative designs and to evaluate them on a set of performance measures in order to select the best design.",
            "contribution_ids": [
                "R30791",
                "R30890",
                "R30940",
                "R31039",
                "R31139"
            ]
        },
        {
            "instance_id": "R30950xR30790",
            "comparison_id": "R30950",
            "paper_id": "R30790",
            "text": "Prepositioning emergency supplies to support disaster relief: a stochastic programming approach abstract this paper studies the strategic problem of designing emergency supply networks to support disaster relief over a planning horizon. the problem addresses decisions on the location and number of distribution centres needed, their capacity, and the quantity of each emergency item to keep in stock. it builds on a case study inspired by real-world data obtained from the north carolina emergency management division (ncem) and the federal emergency management agency (fema). to tackle the problem, a scenario-based approach is proposed involving three phases: disaster scenario generation, design generation and design evaluation. disasters are modelled as stochastic processes and a monte carlo procedure is derived to generate plausible catastrophic scenarios. based on this detailed representation of disasters, a multi-phase modelling framework is proposed to design the emergency supply network. the two-stage stochastic programming model proposed is solved using a sample average approximation method. this scenario-based solution approach is applied to the case study to generate plausible scenarios, to produce alternative designs and to evaluate them on a set of performance measures in order to select the best design.",
            "contribution_ids": [
                "R30791",
                "R30890",
                "R30940",
                "R31039",
                "R31139"
            ]
        },
        {
            "instance_id": "R30950xR30747",
            "comparison_id": "R30950",
            "paper_id": "R30747",
            "text": "Decomposition algorithms for the design of a nonsimultaneous capacitated evacuation tree network \"in this article, we examine the design of an evacuation tree, in which evacuation is subject to capacity restrictions on arcs. the cost of evacuating people in the network is determined by the sum of penalties incurred on arcs on which they travel, where penalties are determined according to a nondecreasing function of time. given a discrete set of disaster scenarios affecting network population, arc capacities, transit times, and penalty functions, we seek to establish an optimal a priori evacuation tree that minimizes the expected evacuation penalty. the solution strategy is based on benders decomposition, in which the master problem is a mixed\u2010integer program and each subproblem is a time\u2010expanded network flow problem. we provide efficient methods for obtaining primal and dual subproblem solutions, and analyze techniques for improving the strength of the master problem formulation, thus reducing the number of master problem solutions required for the algorithm's convergence. we provide computational results to compare the efficiency of our methods on a set of randomly generated test instances. \u00a9 2008 wiley periodicals, inc. networks, 2009\"",
            "contribution_ids": [
                "R30748",
                "R30832",
                "R30918",
                "R30967",
                "R31105"
            ]
        },
        {
            "instance_id": "R30950xR30800",
            "comparison_id": "R30950",
            "paper_id": "R30800",
            "text": "Stochastic network design for disaster preparedness this article introduces a risk-averse stochastic modeling approach for a pre-disaster relief network design problem under uncertain demand and transportation capacities. the sizes and locations of the response facilities and the inventory levels of relief supplies at each facility are determined while guaranteeing a certain level of network reliability. a probabilistic constraint on the existence of a feasible flow is introduced to ensure that the demand for relief supplies across the network is satisfied with a specified high probability. responsiveness is also accounted for by defining multiple regions in the network and introducing local probabilistic constraints on satisfying demand within each region. these local constraints ensure that each region is self-sufficient in terms of providing for its own needs with a large probability. in particular, the gale\u2013hoffman inequalities are used to represent the conditions on the existence of a feasible network flow. the solution method rests on two pillars. a preprocessing algorithm is used to eliminate redundant gale\u2013hoffman inequalities and then proposed models are formulated as computationally efficient mixed-integer linear programs by utilizing a method based on combinatorial patterns. computational results for a case study and randomly generated problem instances demonstrate the effectiveness of the models and the solution method.",
            "contribution_ids": [
                "R30801",
                "R30899",
                "R30945",
                "R31053",
                "R31147"
            ]
        },
        {
            "instance_id": "R30950xR30807",
            "comparison_id": "R30950",
            "paper_id": "R30807",
            "text": "Implementation of Equity in Resource Allocation for Regional Earthquake Risk Mitigation Using Two-Stage Stochastic Programming this article presents a new methodology to implement the concept of equity in regional earthquake risk mitigation programs using an optimization framework. it presents a framework that could be used by decisionmakers (government and authorities) to structure budget allocation strategy toward different seismic risk mitigation measures, i.e., structural retrofitting for different building structural types in different locations and planning horizons. a two\u2010stage stochastic model is developed here to seek optimal mitigation measures based on minimizing mitigation expenditures, reconstruction expenditures, and especially large losses in highly seismically active countries. to consider fairness in the distribution of financial resources among different groups of people, the equity concept is incorporated using constraints in model formulation. these constraints limit inequity to the user\u2010defined level to achieve the equity\u2010efficiency tradeoff in the decision\u2010making process. to present practical application of the proposed model, it is applied to a pilot area in tehran, the capital city of iran. building stocks, structural vulnerability functions, and regional seismic hazard characteristics are incorporated to compile a probabilistic seismic risk model for the pilot area. results illustrate the variation of mitigation expenditures by location and structural type for buildings. these expenditures are sensitive to the amount of available budget and equity consideration for the constant risk aversion. most significantly, equity is more easily achieved if the budget is unlimited. conversely, increasing equity where the budget is limited decreases the efficiency. the risk\u2010return tradeoff, equity\u2010reconstruction expenditures tradeoff, and variation of per\u2010capita expected earthquake loss in different income classes are also presented.",
            "contribution_ids": [
                "R30808",
                "R30906",
                "R30947",
                "R31058",
                "R31152"
            ]
        },
        {
            "instance_id": "R30950xR30811",
            "comparison_id": "R30950",
            "paper_id": "R30811",
            "text": "Two-Stage Multiobjective Optimization for Emergency Supplies Allocation Problem under Integrated Uncertainty this paper proposes a new two-stage optimization method for emergency supplies allocation problem with multisupplier, multiaffected area, multirelief, and multivehicle. the triplet of supply, demand, and the availability of path is unknown prior to the extraordinary event and is descriptive with fuzzy random variable. considering the fairness, timeliness, and economical efficiency, a multiobjective expected value model is built for facility location, vehicle routing, and supply allocation decisions. the goals of proposed model aim to minimize the proportion of demand nonsatisfied and response time of emergency reliefs and the total cost of the whole process. when the demand and the availability of path are discrete, the expected values in the objective functions are converted into their equivalent forms. when the supply amount is continuous, the equilibrium chance in the constraint is transformed to its equivalent one. to overcome the computational difficulty caused by multiple objectives, a goal programming model is formulated to obtain a compromise solution. finally, an example is presented to illustrate the validity of the proposed model and the effectiveness of the solution method.",
            "contribution_ids": [
                "R30812",
                "R30913",
                "R30949",
                "R31066",
                "R31155"
            ]
        },
        {
            "instance_id": "R31077xR30807",
            "comparison_id": "R31077",
            "paper_id": "R30807",
            "text": "Implementation of Equity in Resource Allocation for Regional Earthquake Risk Mitigation Using Two-Stage Stochastic Programming this article presents a new methodology to implement the concept of equity in regional earthquake risk mitigation programs using an optimization framework. it presents a framework that could be used by decisionmakers (government and authorities) to structure budget allocation strategy toward different seismic risk mitigation measures, i.e., structural retrofitting for different building structural types in different locations and planning horizons. a two\u2010stage stochastic model is developed here to seek optimal mitigation measures based on minimizing mitigation expenditures, reconstruction expenditures, and especially large losses in highly seismically active countries. to consider fairness in the distribution of financial resources among different groups of people, the equity concept is incorporated using constraints in model formulation. these constraints limit inequity to the user\u2010defined level to achieve the equity\u2010efficiency tradeoff in the decision\u2010making process. to present practical application of the proposed model, it is applied to a pilot area in tehran, the capital city of iran. building stocks, structural vulnerability functions, and regional seismic hazard characteristics are incorporated to compile a probabilistic seismic risk model for the pilot area. results illustrate the variation of mitigation expenditures by location and structural type for buildings. these expenditures are sensitive to the amount of available budget and equity consideration for the constant risk aversion. most significantly, equity is more easily achieved if the budget is unlimited. conversely, increasing equity where the budget is limited decreases the efficiency. the risk\u2010return tradeoff, equity\u2010reconstruction expenditures tradeoff, and variation of per\u2010capita expected earthquake loss in different income classes are also presented.",
            "contribution_ids": [
                "R30808",
                "R30906",
                "R30947",
                "R31058",
                "R31152"
            ]
        },
        {
            "instance_id": "R31077xR30753",
            "comparison_id": "R31077",
            "paper_id": "R30753",
            "text": "The evacuation optimal network design problem: model formulation and comparisons abstract the goal of this paper is twofold. first, we present a stochastic programming-based model that provides optimal design solutions for transportation networks in light of possible emergency evacuations. second, as traffic congestion is a growing problem in metropolitan areas around the world, decision makers might not be willing to design transportation networks solely for evacuation purposes since daily traffic patterns differ tremendously from traffic observed during evacuations. this is especially true when potential disaster locations are limited in number and confined to specific regions (e.g. coastal regions might be more prone to flooding). however, as extreme events such as excessive rainfall become more prevalent everywhere, it is less obvious that the design of transportation networks for evacuation planning and congestion reduction is mutually exclusive. that is, capacity expansion decisions to reduce congestion might also be reasonable from an evacuation planning point of view. conversely, expansion decisions for evacuation planning might turn out to be effective for congestion relief. to date, no numerical evidence has been presented in the literature to support or disprove these conjectures. preliminary numerical evidence is provided in this paper.",
            "contribution_ids": [
                "R30754",
                "R30842",
                "R30921",
                "R30978",
                "R31110"
            ]
        },
        {
            "instance_id": "R31077xR30800",
            "comparison_id": "R31077",
            "paper_id": "R30800",
            "text": "Stochastic network design for disaster preparedness this article introduces a risk-averse stochastic modeling approach for a pre-disaster relief network design problem under uncertain demand and transportation capacities. the sizes and locations of the response facilities and the inventory levels of relief supplies at each facility are determined while guaranteeing a certain level of network reliability. a probabilistic constraint on the existence of a feasible flow is introduced to ensure that the demand for relief supplies across the network is satisfied with a specified high probability. responsiveness is also accounted for by defining multiple regions in the network and introducing local probabilistic constraints on satisfying demand within each region. these local constraints ensure that each region is self-sufficient in terms of providing for its own needs with a large probability. in particular, the gale\u2013hoffman inequalities are used to represent the conditions on the existence of a feasible network flow. the solution method rests on two pillars. a preprocessing algorithm is used to eliminate redundant gale\u2013hoffman inequalities and then proposed models are formulated as computationally efficient mixed-integer linear programs by utilizing a method based on combinatorial patterns. computational results for a case study and randomly generated problem instances demonstrate the effectiveness of the models and the solution method.",
            "contribution_ids": [
                "R30801",
                "R30899",
                "R30945",
                "R31053",
                "R31147"
            ]
        },
        {
            "instance_id": "R31077xR30811",
            "comparison_id": "R31077",
            "paper_id": "R30811",
            "text": "Two-Stage Multiobjective Optimization for Emergency Supplies Allocation Problem under Integrated Uncertainty this paper proposes a new two-stage optimization method for emergency supplies allocation problem with multisupplier, multiaffected area, multirelief, and multivehicle. the triplet of supply, demand, and the availability of path is unknown prior to the extraordinary event and is descriptive with fuzzy random variable. considering the fairness, timeliness, and economical efficiency, a multiobjective expected value model is built for facility location, vehicle routing, and supply allocation decisions. the goals of proposed model aim to minimize the proportion of demand nonsatisfied and response time of emergency reliefs and the total cost of the whole process. when the demand and the availability of path are discrete, the expected values in the objective functions are converted into their equivalent forms. when the supply amount is continuous, the equilibrium chance in the constraint is transformed to its equivalent one. to overcome the computational difficulty caused by multiple objectives, a goal programming model is formulated to obtain a compromise solution. finally, an example is presented to illustrate the validity of the proposed model and the effectiveness of the solution method.",
            "contribution_ids": [
                "R30812",
                "R30913",
                "R30949",
                "R31066",
                "R31155"
            ]
        },
        {
            "instance_id": "R31077xR30763",
            "comparison_id": "R31077",
            "paper_id": "R30763",
            "text": "Stochastic Optimization for Natural Disaster Asset Prepositioning \"a key strategic issue in pre-disaster planning for humanitarian logistics is the pre-establishment of adequate capacity and resources that enable efficient relief operations. this paper develops a two-stage stochastic optimization model to guide the allocation of budget to acquire and position relief assets, decisions that typically need to be made well in advance before a disaster strikes. the optimization focuses on minimizing the expected number of casualties, so our model includes first-stage decisions to represent the expansion of resources such as warehouses, medical facilities with personnel, ramp spaces, and shelters. second-stage decisions concern the logistics of the problem, where allocated resources and contracted transportation assets are deployed to rescue critical population (in need of emergency evacuation), deliver required commodities to stay-back population, and transport the transfer population displaced by the disaster. because of the uncertainty of the event's location and severity, these and other parameters are represented as scenarios. computational results on notional test cases provide guidance on budget allocation and prove the potential benefit of using stochastic optimization.\"",
            "contribution_ids": [
                "R30764",
                "R30857",
                "R30926",
                "R30995",
                "R31118"
            ]
        },
        {
            "instance_id": "R31160xR30800",
            "comparison_id": "R31160",
            "paper_id": "R30800",
            "text": "Stochastic network design for disaster preparedness this article introduces a risk-averse stochastic modeling approach for a pre-disaster relief network design problem under uncertain demand and transportation capacities. the sizes and locations of the response facilities and the inventory levels of relief supplies at each facility are determined while guaranteeing a certain level of network reliability. a probabilistic constraint on the existence of a feasible flow is introduced to ensure that the demand for relief supplies across the network is satisfied with a specified high probability. responsiveness is also accounted for by defining multiple regions in the network and introducing local probabilistic constraints on satisfying demand within each region. these local constraints ensure that each region is self-sufficient in terms of providing for its own needs with a large probability. in particular, the gale\u2013hoffman inequalities are used to represent the conditions on the existence of a feasible network flow. the solution method rests on two pillars. a preprocessing algorithm is used to eliminate redundant gale\u2013hoffman inequalities and then proposed models are formulated as computationally efficient mixed-integer linear programs by utilizing a method based on combinatorial patterns. computational results for a case study and randomly generated problem instances demonstrate the effectiveness of the models and the solution method.",
            "contribution_ids": [
                "R30801",
                "R30899",
                "R30945",
                "R31053",
                "R31147"
            ]
        },
        {
            "instance_id": "R31160xR30811",
            "comparison_id": "R31160",
            "paper_id": "R30811",
            "text": "Two-Stage Multiobjective Optimization for Emergency Supplies Allocation Problem under Integrated Uncertainty this paper proposes a new two-stage optimization method for emergency supplies allocation problem with multisupplier, multiaffected area, multirelief, and multivehicle. the triplet of supply, demand, and the availability of path is unknown prior to the extraordinary event and is descriptive with fuzzy random variable. considering the fairness, timeliness, and economical efficiency, a multiobjective expected value model is built for facility location, vehicle routing, and supply allocation decisions. the goals of proposed model aim to minimize the proportion of demand nonsatisfied and response time of emergency reliefs and the total cost of the whole process. when the demand and the availability of path are discrete, the expected values in the objective functions are converted into their equivalent forms. when the supply amount is continuous, the equilibrium chance in the constraint is transformed to its equivalent one. to overcome the computational difficulty caused by multiple objectives, a goal programming model is formulated to obtain a compromise solution. finally, an example is presented to illustrate the validity of the proposed model and the effectiveness of the solution method.",
            "contribution_ids": [
                "R30812",
                "R30913",
                "R30949",
                "R31066",
                "R31155"
            ]
        },
        {
            "instance_id": "R31160xR30805",
            "comparison_id": "R31160",
            "paper_id": "R30805",
            "text": "Bi-objective stochastic programming models for determining depot locations in disaster relief operations this paper presents two-stage bi-objective stochastic programming models for disaster relief operations. we consider a problem that occurs in the aftermath of a natural disaster: a transportation system for supplying disaster victims with relief goods must be established. we propose bi-objective optimization models with a monetary objective and humanitarian objective. uncertainty in the accessibility of the road network is modeled by a discrete set of scenarios. the key features of our model are the determination of locations for intermediate depots and acquisition of vehicles. several model variants are considered. first, the operating budget can be fixed at the first stage for all possible scenarios or determined for each scenario at the second stage. second, the assignment of vehicles to a depot can be either fixed or free. third, we compare a heterogeneous vehicle fleet to a homogeneous fleet. we study the impact of the variants on the solutions. the set of pareto-optimal solutions is computed by applying the adaptive epsilon-constraint method. we solve the deterministic equivalents of the two-stage stochastic programs using the mip-solver cplex.",
            "contribution_ids": [
                "R30806",
                "R31089",
                "R31098",
                "R31151"
            ]
        },
        {
            "instance_id": "R31160xR30763",
            "comparison_id": "R31160",
            "paper_id": "R30763",
            "text": "Stochastic Optimization for Natural Disaster Asset Prepositioning \"a key strategic issue in pre-disaster planning for humanitarian logistics is the pre-establishment of adequate capacity and resources that enable efficient relief operations. this paper develops a two-stage stochastic optimization model to guide the allocation of budget to acquire and position relief assets, decisions that typically need to be made well in advance before a disaster strikes. the optimization focuses on minimizing the expected number of casualties, so our model includes first-stage decisions to represent the expansion of resources such as warehouses, medical facilities with personnel, ramp spaces, and shelters. second-stage decisions concern the logistics of the problem, where allocated resources and contracted transportation assets are deployed to rescue critical population (in need of emergency evacuation), deliver required commodities to stay-back population, and transport the transfer population displaced by the disaster. because of the uncertainty of the event's location and severity, these and other parameters are represented as scenarios. computational results on notional test cases provide guidance on budget allocation and prove the potential benefit of using stochastic optimization.\"",
            "contribution_ids": [
                "R30764",
                "R30857",
                "R30926",
                "R30995",
                "R31118"
            ]
        },
        {
            "instance_id": "R31160xR30767",
            "comparison_id": "R31160",
            "paper_id": "R30767",
            "text": "A two\u00e2\u0080\u0090stage procurement model for humanitarian relief supply chains purpose the purpose of this paper is to discuss and to help address the need for quantitative models to support and improve procurement in the context of humanitarian relief efforts. design/methodology/approach this research presents a two\u2010stage stochastic decision model with recourse for procurement in humanitarian relief supply chains, and compares its effectiveness on an illustrative example with respect to a standard solution approach. findings results show the ability of the new model to capture and model both the procurement process and the uncertainty inherent in a disaster relief situation, in support of more efficient and effective procurement plans. research limitations/implications the research focus is on sudden onset disasters and it does not differentiate between local and international suppliers. a number of extensions of the base model could be implemented, however, so as to address the specific needs of a given organization and their procurement process. practical implications despite the prevalence of procurement expenditures in humanitarian efforts, procurement in humanitarian contexts is a topic that previously has only been discussed in a qualitative manner in the literature. this work provides practitioners with a new approach to quantitatively assess and improve their procurement decision processes. originality/value this study adds to the existing literature by demonstrating the applicability and effectiveness of an analytic modeling technique based on uncertainty, such as stochastic programming with recourse, in the context of humanitarian relief procurement activities.",
            "contribution_ids": [
                "R30768",
                "R31082",
                "R31092",
                "R31120"
            ]
        },
        {
            "instance_id": "R31160xR30807",
            "comparison_id": "R31160",
            "paper_id": "R30807",
            "text": "Implementation of Equity in Resource Allocation for Regional Earthquake Risk Mitigation Using Two-Stage Stochastic Programming this article presents a new methodology to implement the concept of equity in regional earthquake risk mitigation programs using an optimization framework. it presents a framework that could be used by decisionmakers (government and authorities) to structure budget allocation strategy toward different seismic risk mitigation measures, i.e., structural retrofitting for different building structural types in different locations and planning horizons. a two\u2010stage stochastic model is developed here to seek optimal mitigation measures based on minimizing mitigation expenditures, reconstruction expenditures, and especially large losses in highly seismically active countries. to consider fairness in the distribution of financial resources among different groups of people, the equity concept is incorporated using constraints in model formulation. these constraints limit inequity to the user\u2010defined level to achieve the equity\u2010efficiency tradeoff in the decision\u2010making process. to present practical application of the proposed model, it is applied to a pilot area in tehran, the capital city of iran. building stocks, structural vulnerability functions, and regional seismic hazard characteristics are incorporated to compile a probabilistic seismic risk model for the pilot area. results illustrate the variation of mitigation expenditures by location and structural type for buildings. these expenditures are sensitive to the amount of available budget and equity consideration for the constant risk aversion. most significantly, equity is more easily achieved if the budget is unlimited. conversely, increasing equity where the budget is limited decreases the efficiency. the risk\u2010return tradeoff, equity\u2010reconstruction expenditures tradeoff, and variation of per\u2010capita expected earthquake loss in different income classes are also presented.",
            "contribution_ids": [
                "R30808",
                "R30906",
                "R30947",
                "R31058",
                "R31152"
            ]
        },
        {
            "instance_id": "R31160xR30745",
            "comparison_id": "R31160",
            "paper_id": "R30745",
            "text": "Facility location in humanitarian relief \"in this study, we consider facility location decisions for a humanitarian relief chain responding to quick-onset disasters. in particular, we develop a model that determines the number and locations of distribution centres in a relief network and the amount of relief supplies to be stocked at each distribution centre to meet the needs of people affected by the disasters. our model, which is a variant of the maximal covering location model, integrates facility location and inventory decisions, considers multiple item types, and captures budgetary constraints and capacity restrictions. we conduct computational experiments to illustrate how the proposed model works on a realistic problem. results show the effects of pre- and post-disaster relief funding on relief system's performance, specifically on response time and the proportion of demand satisfied. finally, we discuss the managerial implications of the proposed model.\"",
            "contribution_ids": [
                "R30746",
                "R30829",
                "R30917",
                "R30964",
                "R31103"
            ]
        },
        {
            "instance_id": "R31214xR31185",
            "comparison_id": "R31214",
            "paper_id": "R31185",
            "text": "Terrain-based genetic algorithm (TBGA): modeling parameter space as terrain the terrain-based genetic algorithm (tbga) is a self-tuning version of the traditional cellular genetic algorithm (cga). in a tbga, various combinations of parameter values appear in different physical locations of the population, forming a sort of terrain in which individual solutions evolve. we compare the performance of the tbga against that of the cga on a known suite of problems. our results indicate that the tbga performs better than the cga on the test suite, with less parameter tuning, when the cga is set to parameter values thought in prior studies to be good. while we had hoped that good solutions would cluster around the best parameter settings, this was not observed. however, we were able to use the tbga to automatically determine better parameter settings for the cga. the resulting cga produced even better results than were achieved by the tbga which found those parameter settings.",
            "contribution_ids": [
                "R31186"
            ]
        },
        {
            "instance_id": "R31214xR31208",
            "comparison_id": "R31214",
            "paper_id": "R31208",
            "text": "Cheating for problem solving: a genetic algorithm with social interactions \"we propose a variation of the standard genetic algorithm that incorporates social interaction between the individuals in the population. our goal is to understand the evolutionary role of social systems and its possible application as a non-genetic new step in evolutionary algorithms. in biological populations, i.e. animals, even human beings and microorganisms, social interactions often affect the fitness of individuals. it is conceivable that the perturbation of the fitness via social interactions is an evolutionary strategy to avoid trapping into local optimum, thus avoiding a fast convergence of the population. we model the social interactions according to game theory. the population is, therefore, composed by cooperator and defector individuals whose interactions produce payoffs according to well known game models (prisoner's dilemma, chicken game, and others). our results on knapsack problems show, for some game models, a significant performance improvement as compared to a standard genetic algorithm.\"",
            "contribution_ids": [
                "R31209"
            ]
        },
        {
            "instance_id": "R31214xR31212",
            "comparison_id": "R31214",
            "paper_id": "R31212",
            "text": "MLGA: a multilevel cooperative genetic algorithm this paper incorporate the multilevel selection (mls) theory into the genetic algorithm. based on this theory, a multilevel cooperative genetic algorithm (mlga) is presented. in mlga, a species is subdivided in a set of populations, each population is subdivided in groups, and evolution occurs at two levels so called individual and group level. a fast population dynamics occurs at individual level. at this level, selection occurs between individuals of the same group. the popular genetic operators such as mutation and crossover are applied within groups. a slow population dynamics occurs at group level. at this level, selection occurs between groups of a population. a group level operator so called colonization is applied between groups in which a group is selected as extinct, and replaced by offspring of a colonist group. we used a set of well known numerical functions in order to evaluate performance of the proposed algorithm. the results showed that the mlga is robust, and provides an efficient way for numerical function optimization.",
            "contribution_ids": [
                "R31213"
            ]
        },
        {
            "instance_id": "R31281xR31224",
            "comparison_id": "R31281",
            "paper_id": "R31224",
            "text": "Tracking the Middle-Income Trap: What is it, Who is in it, and Why? this paper provides a working definition of what the middle-income trap is. we start by defining four income groups of gdp per capita in 1990 ppp dollars: low-income below $2,000; lower-middle-income between $2,000 and $7,250; upper-middle-income between $7,250 and $11,750; and high-income above $11,750. we then classify 124 countries for which we have consistent data for 1950\u20132010. in 2010, there were 40 low-income countries in the world, 38 lower-middle-income, 14 upper-middle-income, and 32 high-income countries. then we calculate the threshold number of years for a country to be in the middle-income trap: a country that becomes lower-middle-income (i.e., that reaches $2,000 per capita income) has to attain an average growth rate of per capita income of at least 4.7 percent per annum to avoid falling into the lower-middle-income trap (i.e., to reach $7,250, the upper-middle-income threshold); and a country that becomes upper-middle-income (i.e., that reaches $7,250 per capita income) has to attain an average growth rate of per capita income of at least 3.5 percent per annum to avoid falling into the upper-middle-income trap (i.e., to reach $11,750, the high-income level threshold). avoiding the middle-income trap is, therefore, a question of how to grow fast enough so as to cross the lower-middle-income segment in at most 28 years, and the upper-middle-income segment in at most 14 years. finally, the paper proposes and analyzes one possible reason why some countries get stuck in the middle-income trap: the role played by the changing structure of the economy (from low-productivity activities into high-productivity activities), the types of products exported (not all products have the same consequences for growth and development), and the diversification of the economy. we compare the exports of countries in the middle-income trap with those of countries that graduated from it, across eight dimensions that capture different aspects of a country\u2019s capabilities to undergo structural transformation, and test whether they are different. results indicate that, in general, they are different. we also compare korea, malaysia, and the philippines according to the number of products that each exports with revealed comparative advantage. we find that while korea was able to gain comparative advantage in a significant number of sophisticated products and was well connected, malaysia and the philippines were able to gain comparative advantage in electronics only.",
            "contribution_ids": [
                "R31225",
                "R31267"
            ]
        },
        {
            "instance_id": "R31281xR31217",
            "comparison_id": "R31281",
            "paper_id": "R31217",
            "text": "When Fast-Growing Economies Slow Down: International Evidence and Implications for China using international data starting in 1957, we construct a sample of cases where fast-growing economies slow down. the evidence suggests that rapidly growing economies slow down significantly, in the sense that the growth rate downshifts by at least 2 percentage points, when their per capita incomes reach around us$ 17,000 in year-2005 constant international prices, a level that china should achieve by or soon after 2015. among our more provocative findings is that growth slowdowns are more likely in countries that maintain undervalued real exchange rates.",
            "contribution_ids": [
                "R31218",
                "R31263"
            ]
        },
        {
            "instance_id": "R31669xR31580",
            "comparison_id": "R31669",
            "paper_id": "R31580",
            "text": "Temperature control of a pilot plant reactor system using a genetic algorithm model-based control approach the work described in this paper aims at exploring the use of an artificial intelligence technique, i.e. genetic algorithm (ga), for designing an optimal model-based controller to regulate the temperature of a reactor. ga is utilized to identify the best control action for the system by creating possible solutions and thereby to propose the correct control action to the reactor system. this value is then used as the set point for the closed loop control system of the heat exchanger. a continuous stirred tank reactor is chosen as a case study, where the controller is then tested with multiple set-point tracking and changes in its parameters. the ga model-based control (gambc) is then implemented experimentally to control the reactor temperature of a pilot plant, where an irreversible exothermic chemical reaction is simulated by using the calculated steam flow rate. the dynamic behavior of the pilot plant reactor during the online control studies is highlighted, and comparison with the conventional tuned proportional integral derivative (pid) is presented. it is found that both controllers are able to control the process with comparable performance. copyright \u00a9 2007 curtin university of technology and john wiley & sons, ltd.",
            "contribution_ids": [
                "R31581"
            ]
        },
        {
            "instance_id": "R31669xR31524",
            "comparison_id": "R31669",
            "paper_id": "R31524",
            "text": "Energy efficiency estimation based on data fusion strategy: Case study of ethylene product industry data fusion is an emerging technology to fuse data from multiple data or information of the environment through measurement and detection to make a more accurate and reliable estimation or decision. in this article, energy consumption data are collected from ethylene plants with the high temperature steam cracking process technology. an integrated framework of the energy efficiency estimation is proposed on the basis of data fusion strategy. a hierarchical variable variance fusion (hvvf) algorithm and a fuzzy analytic hierarchy process (fahp) method are proposed to estimate energy efficiencies of ethylene equipments. for different equipment scales with the same process technology, the hvvf algorithm is used to estimate energy efficiency ranks among different equipments. for different technologies based on hvvf results, the fahp method based on the approximate fuzzy eigenvector is used to get energy efficiency indices (eei) of total ethylene industries. the comparisons are used to assess energy utilization...",
            "contribution_ids": [
                "R31525"
            ]
        },
        {
            "instance_id": "R31669xR31626",
            "comparison_id": "R31669",
            "paper_id": "R31626",
            "text": "Control of a batch polymerization system using hybrid neural network - First principle model in this work, the utilization of neural network in hybrid with first principle models for modelling and control of a batch polymerization process was investigated. following the steps of the methodology, hybrid neural network (hnn) forward models and hnn inverse model of the process were first developed and then the performance of the model in direct inverse control strategy and internal model control (imc) strategy was investigated. for comparison purposes, the performance of conventional neural network and pid controller in control was compared with the proposed hnn. the results show that hnn is able to control perfectly for both set points tracking and disturbance rejection studies.",
            "contribution_ids": [
                "R31627"
            ]
        },
        {
            "instance_id": "R31669xR31304",
            "comparison_id": "R31669",
            "paper_id": "R31304",
            "text": "Application of feedforward neural networks for soft sensors in the sugar industry neural networks have been successfully applied as intelligent sensors for process modeling and control. in this paper, the application of soft sensors in the cane sugar industry is discussed. a neural network is trained on historical data to predict process quality variables so that it can replace the lab-test procedure. an immediate benefit of building intelligent sensors is that the neural network can predict product quality in a timely manner.",
            "contribution_ids": [
                "R31305"
            ]
        },
        {
            "instance_id": "R31669xR31345",
            "comparison_id": "R31669",
            "paper_id": "R31345",
            "text": "Accounts of Experiences in the Application of Artificial Neural Networks in Chemical Engineering considerable literature describing the use of artificial neural networks (anns) has evolved for a diverse range of applications such as fitting experimental data, machine diagnostics, pattern recognition, quality control, signal processing, process modeling, and process control, all topics of interest to chemists and chemical engineers. because anns are nets of simple functions, they can provide satisfactory empirical models of complex nonlinear processes useful for a wide variety of purposes. this article describes the characteristics of anns including their advantages and disadvantages, focuses on two types of neural networks that have proved in our experience to be effective in practical applications, and presents short examples of four specific applications. in the competitive field of modeling, anns have secured a niche that now, after two decades, seems secure.",
            "contribution_ids": [
                "R31346",
                "R31349"
            ]
        },
        {
            "instance_id": "R31669xR31662",
            "comparison_id": "R31669",
            "paper_id": "R31662",
            "text": "A Fuzzy-based Adaptive Genetic Algorithm and Its Case Study in Chemical Engineering \u8003\u8651\u5230\u4e00\u4e2a\u57fa\u56e0\u7b97\u6cd5( ga )\u7684\u8868\u6f14\u88ab\u8bb8\u591a\u56e0\u7d20\u548c\u4ed6\u4eec\u7684\u5173\u7cfb\u5f71\u54cd\uff0c\u8fd9\u590d\u6742\u3001\u96be\u88ab\u63cf\u8ff0\uff0c\u4e00\u4e2a\u65b0\u5947\u6a21\u7cca\u5e95\u7684\u9002\u5e94\u57fa\u56e0\u7b97\u6cd5( faga )\u628a\u4e00\u4e2a\u65b0\u4eba\u5de5\u7684\u514d\u75ab\u7cfb\u7edf\u4e0e\u6a21\u7cca\u7cfb\u7edf\u7406\u8bba\u76f8\u7ed3\u5408\u7531\u4e8e\u6a21\u7cca\u7406\u8bba\u80fd\u63cf\u8ff0\u9ad8\u590d\u6742\u7684\u95ee\u9898\u7684\u4e8b\u5b9e\u88ab\u5efa\u8bae\u3002\u5728 faga\uff0c\u6709\u514d\u75ab\u529b\u7684\u7406\u8bba\u88ab\u7528\u6765\u6539\u8fdb\u9009\u62e9\u64cd\u4f5c\u7684\u8868\u6f14\u3002\u5e76\u4e14\uff0c\u8f6c\u7ebf\u8def\u6982\u7387\u548c\u53d8\u5316\u6982\u7387\u88ab\u6a21\u7cca\u63a8\u8bba\u52a8\u6001\u5730\u8c03\u6574\uff0c\u5b83\u6839\u636e\u5728\u7b97\u6cd5\u8868\u6f14\u548c\u63a7\u5236\u53c2\u6570\u4e4b\u95f4\u7684\u542f\u53d1\u5f0f\u7684\u6a21\u7cca\u5173\u7cfb\u88ab\u5f00\u53d1\u3002\u5b9e\u9a8c\u8bc1\u660e faga \u80fd\u9ad8\u6548\u5730\u514b\u670d ga \u7684\u7f3a\u70b9\uff0c\u5373\uff0c\u65e9\u719f\u5e76\u4e14\u6bd4\u4e8c\u5178\u578b\u6a21\u7cca\u6c14\u4f53\u51cf\u7f13\uff0c\u5e76\u4e14\u83b7\u5f97\u66f4\u597d\u7684\u7ed3\u679c\u3002\u6700\u540e\uff0c faga \u88ab\u7528\u4e8e\u53cd\u5e94\u52a8\u529b\u5b66\u6a21\u578b\u7684\u53c2\u6570\u8bc4\u4ef7\uff0c\u4ee4\u4eba\u6ee1\u610f\u7684\u7ed3\u679c\u88ab\u83b7\u5f97\u3002",
            "contribution_ids": [
                "R31663"
            ]
        },
        {
            "instance_id": "R31669xR31519",
            "comparison_id": "R31669",
            "paper_id": "R31519",
            "text": "Design of a fuzzy logic controller for regulating substrate feed to fed-batch fermentation \"fuzzy logic control based on the takagi-sugeno inference method has been applied for the regulation of feed rate to a fed-batch fermentation process. the process chosen is the baker's yeast fermentation. the simulation results show that the conventional fuzzy logic controller produces oscillations in the process response. to improve the performance of the conventional scheme, implementation of adaptive and hybrid control schemes are proposed. significant improvements in the controller performance could be achieved by combining these two approaches. the adaptive control scheme reduces severe oscillations and the hybrid control scheme enhances control precision.\"",
            "contribution_ids": [
                "R31520"
            ]
        },
        {
            "instance_id": "R31669xR31599",
            "comparison_id": "R31669",
            "paper_id": "R31599",
            "text": "Melt index prediction based on fuzzy neural networks and PSO algorithm with online correction strategy a black-box modeling scheme to predict melt index (mi) in the industrial propylene polymerization process is presented. mi is one of the most important quality variables determining product specification, and is influenced by a large number of process variables. considering it is costly and time consuming to measure mi in laboratory, a much cheaper and faster statistical modeling method is presented here to predicting mi online, which involves technologies of fuzzy neural network, particle swarm optimization (pso) algorithm, and online correction strategy (ocs). the learning efficiency and prediction precision of the proposed model are checked based on real plant history data, and the comparison between different learning algorithms is carried out in detail to reveal the advantage of the proposed best-neighbor pso (bnpso) algorithm with ocs. \u00a9 2011 american institute of chemical engineers aiche j, 2012",
            "contribution_ids": [
                "R31600"
            ]
        },
        {
            "instance_id": "R31669xR31536",
            "comparison_id": "R31669",
            "paper_id": "R31536",
            "text": "Application of fuzzy logic for state estimation of a microbial fermentation with dual inhibition and variable product kinetics. Food and Bioproducts Processing fuzzy logic has been applied to a batch microbial fermentation described by a model with two adjustable parameters which associate product formation with the increasing and/or stationary phases of cell growth. the fermentation is inhibited by its product and, beyond a critical concentration, also by the substrate. to mimic an industrial condition, gaussian noise was added and the resulting performance was simulated by fuzzy estimation systems. simple rules with a few membership functions were able to portray bioreactor performance and the feedback interactions between cell growth and the concentrations of substrate and product. through careful choices of the membership functions and the fuzzy logic, accuracies better than previously reported for ideal fermentations could be obtained, suggesting the suitability of fuzzy estimations for on-line applications.",
            "contribution_ids": [
                "R31537"
            ]
        },
        {
            "instance_id": "R31669xR31364",
            "comparison_id": "R31669",
            "paper_id": "R31364",
            "text": "Artificial neural networks to infer biomass and product concentration during the production of penicillin G acylase from Bacillus megaterium background: production of microbial enzymes in bioreactors is a complex process including such phenomena as metabolic networks and mass transport resistances. the use of neural networks (nns) to infer the state of bioreactors may be an interesting option that may handle the nonlinear dynamics of biomass growth and protein production. \\n \\n \\n \\nresults: feedforward multilayer perceptron (mlp) nns were used for identification of the cultivation phase of bacillus megaterium to produce the enzyme penicillin g acylase (ec. 3.5.1.11). the following variables were used as input to the net: run time and carbon dioxide concentration in the exhausted gas. the nn output associates a numerical value to the metabolic state of the cultivation, close to 0 during the lag phase, close to 1 during the exponential phase and approximately 2 for the stationary phase. this is a non-conventional approach for pattern recognition. during the exponential phase, another mlp was used to infer cellular concentration. time, carbon dioxide concentration and stirrer speed form an integrated net input vector. cellular concentrations provided by the nn were used in a hybrid approach to estimate product concentrations of the enzyme. the model employed a first-order approximation. \\n \\n \\n \\nconclusion: results showed that the algorithm was able to infer accurate values of cellular and product concentrations up to the end of the exponential growth phase, where an industrial run should stop. copyright \u00a9 2008 society of chemical industry",
            "contribution_ids": [
                "R31365"
            ]
        },
        {
            "instance_id": "R31669xR31602",
            "comparison_id": "R31669",
            "paper_id": "R31602",
            "text": "Neural-fuzzy modelling of polymer quality in batch polymerization reactors the estimation of parameters and obtaining an accurate and comprehensive mathematical model of the polymerization process is of strategic importance to the control engineering purposes in the polymerization industry. it is characteristic for these processes a grate non-linearity and many difficulties applying traditional estimation techniques. this paper describes an approach based upon neural-fuzzy representation of the model. a concrete model is constructed with the sugeno fuzzy inference technique and a fuzzy-neural network is used to model the dynamic behavior of the polymer process. such neural-fuzzy models of polymer quality could be used successfully for optimization and control of polymerization processes. short example for such implementation is included with additional results for modeling of mn and mw.",
            "contribution_ids": [
                "R31603"
            ]
        },
        {
            "instance_id": "R31689xR31670",
            "comparison_id": "R31689",
            "paper_id": "R31670",
            "text": "Less is more: Active learning with support vector machines we describe a simple active learning heuristic which greatly enhances the generalization behavior of support vector machines (svms) on several practical document classification tasks. we observe a number of benefits, the most surprising of which is that a svm trained on a wellchosen subset of the available corpus frequently performs better than one trained on all available data. the heuristic for choosing this subset is simple to compute, and makes no use of information about the test set. given that the training time of svms depends heavily on the training set size, our heuristic not only offers better performance with fewer data, it frequently does so in less time than the naive approach of training on all available data.",
            "contribution_ids": [
                "R31671",
                "R31676"
            ]
        },
        {
            "instance_id": "R31689xR31672",
            "comparison_id": "R31689",
            "paper_id": "R31672",
            "text": "Support vector machine active learning with applications to text classification support vector machines have met with significant success in numerous real-world learning tasks. however, like most machine learning algorithms, they are generally applied using a randomly selected training set classified in advance. in many settings, we also have the option of using pool-based active learning. instead of using a randomly selected training set, the learner has access to a pool of unlabeled instances and can request the labels for some number of them. we introduce a new algorithm for performing active learning with support vector machines, i.e., an algorithm for choosing which instances to request next. we provide a theoretical motivation for the algorithm using the notion of a version space. we present experimental results showing that employing our active learning method can significantly reduce the need for labeled training instances in both the standard inductive and transductive settings.",
            "contribution_ids": [
                "R31673"
            ]
        },
        {
            "instance_id": "R31689xR31677",
            "comparison_id": "R31689",
            "paper_id": "R31677",
            "text": "Active learning using adaptive resampling classi cation modeling (a.k.a. supervised learning) is an extremely useful analytical technique for developing predictive and forecasting applications. the explosive growth in data warehousing and internet usage has made large amounts of data potentially available for developing classi cation models. for example, natural language text is widely available in many forms (e.g., electronic mail, news articles, reports, and web page contents). categorization of data is a common activity which can be automated to a large extent using supervised learning methods. examples of this include routing of electronic mail, satellite image classi cation, and character recognition. however, these tasks require labeled data sets of su ciently high quality with adequate instances for training the predictive models. much of the on-line data, particularly the unstructured variety (e.g., text), is unlabeled. labeling is usually a expensive manual process done by domain experts. active learning is an approach to solving this problem and works by identifying a subset of the data that needs to be labeled and uses this subset to generate classi cation models. we present an active learning method that uses adaptive resampling in a natural way to signi cantly reduce the size of the required labeled set and generates a classi cation model that achieves the high accuracies possible with current adaptive resampling methods.",
            "contribution_ids": [
                "R31678"
            ]
        },
        {
            "instance_id": "R31689xR31679",
            "comparison_id": "R31689",
            "paper_id": "R31679",
            "text": "Toward optimal active learning through sampling estimation of error reduction this paper presents an active learning method that directly optimizes expected future error. this is in contrast to many other popular techniques that instead aim to reduce version space size. these other methods are popular because for many learning models, closed form calculation of the expected future error is intractable. our approach is made feasible by taking a sampling approach to estimating the expected reduction in error due to the labeling of a query. in experimental results on two real-world data sets we reach high accuracy very quickly, sometimes with four times fewer labeled examples than competing methods.",
            "contribution_ids": [
                "R31680"
            ]
        },
        {
            "instance_id": "R31689xR31685",
            "comparison_id": "R31689",
            "paper_id": "R31685",
            "text": "Active learning using pre-clustering the paper is concerned with two-class active learning. while the common approach for collecting data in active learning is to select samples close to the classification boundary, better performance can be achieved by taking into account the prior data distribution. the main contribution of the paper is a formal framework that incorporates clustering into active learning. the algorithm first constructs a classifier on the set of the cluster representatives, and then propagates the classification decision to the other samples via a local noise model. the proposed model allows to select the most representative samples as well as to avoid repeatedly labeling samples in the same cluster. during the active learning process, the clustering is adjusted using the coarse-to-fine strategy in order to balance between the advantage of large clusters and the accuracy of the data representation. the results of experiments in image databases show a better performance of our algorithm compared to the current methods.",
            "contribution_ids": [
                "R31686"
            ]
        },
        {
            "instance_id": "R31725xR31699",
            "comparison_id": "R31725",
            "paper_id": "R31699",
            "text": "Design Patterns in Software Maintenance: An Experiment Replication at University of Alabama design patterns are widely used within the software engineer community. researchers claim that design patterns improve software quality. in this paper, we describe two experiments, using graduate student participants, to study whether design patterns improve the software quality, specifically maintainability and understandability. we replicated a controlled experiment to compare the maintainability of two implementations of an application, one using a design pattern and the other using a simpler alternative. the maintenance tasks in this replication experiment required the participants to answer questions about a java program and then modify that program. prior to the replication, we performed a preliminary exercise to investigate whether design patterns improve the understandability of software designs. we gave the participants the graphical design of the systems that would be used in the replication study. the participant received either the version of the design containing the design pattern or the version containing the simpler alternative. we asked the participants a series of questions to see how well they understood the given design. the results of two experiments revealed that the design patterns did not improve either the maintainability or the understandability of the software. we found that there was no significant correlation between the maintainability and the understandability of the software even though the participants had received the design of the systems before they performed the maintenance tasks.",
            "contribution_ids": [
                "R31700"
            ]
        },
        {
            "instance_id": "R31725xR31711",
            "comparison_id": "R31725",
            "paper_id": "R31711",
            "text": "Design Patterns and Change Proneness: A Replication Using Proprietary C# Software this paper documents a study of change in commercial, proprietary software and attempts to determine whether a relationship exists between a class\u2019 propensity to change and its design context; more specifically: whether a class is a participant in a design pattern. we identify specific design patterns and their propensity for change. design pattern participants were found to have a higher propensity to change than classes that did not participate in a design pattern, supporting an earlier study by bieman et al.; some design patterns, such as the adaptor, factory method and singleton were found have a higher change propensity than others.",
            "contribution_ids": [
                "R31712"
            ]
        },
        {
            "instance_id": "R31725xR31713",
            "comparison_id": "R31725",
            "paper_id": "R31713",
            "text": "Design patterns and change proneness: an examination of five evolving systems design patterns are recognized, named solutions to common design problems. the use of the most commonly referenced design patterns should promote adaptable and reusable program code. when a system evolves, changes to code involving a design pattern should, in theory, consist of creating new concrete classes that are extensions or subclasses of previously existing classes. changes should not, in theory, involve direct modifications to the classes in prior versions that play roles in a design patterns. we studied five systems, three proprietary systems and two open source systems, to identify the observable effects of the use of design patterns in early versions on changes that occur as the systems evolve. in four of the five systems, pattern classes are more rather than less change prone. pattern classes in one of the systems were less change prone. these results held up after normalizing for the effect of class size - larger classes are more change prone in two of the five systems. these results provide insight into how design patterns are actually used, and should help us to learn to develop software designs that are more easily adapted.",
            "contribution_ids": [
                "R31714"
            ]
        },
        {
            "instance_id": "R31725xR31691",
            "comparison_id": "R31725",
            "paper_id": "R31691",
            "text": "A controlled experiment in maintenance: comparing design patterns to simpler solutions software design patterns package proven solutions to recurring design problems in a form that simplifies reuse. we are seeking empirical evidence whether using design patterns is beneficial. in particular, one may prefer using a design pattern even if the actual design problem is simpler than that solved by the pattern, i.e., if not all of the functionality offered by the pattern is actually required. our experiment investigates software maintenance scenarios that employ various design patterns and compares designs with patterns to simpler alternatives. the subjects were professional software engineers. in most of our nine maintenance tasks, we found positive effects from using a design pattern: either its inherent additional flexibility was achieved without requiring more maintenance time or maintenance time was reduced compared to the simpler alternative. in a few cases, we found negative effects: the alternative solution was less error-prone or required less maintenance time. overall, we conclude that, unless there is a clear reason to prefer the simpler solution, it is probably wise to choose the flexibility provided by the design pattern because unexpected new requirements often appear. we identify several questions for future empirical research.",
            "contribution_ids": [
                "R31692"
            ]
        },
        {
            "instance_id": "R31725xR31705",
            "comparison_id": "R31725",
            "paper_id": "R31705",
            "text": "Impact of the visitor pattern on program comprehension and maintenance in the software engineering literature, many works claim that the use of design patterns improves the comprehensibility of programs and, more generally, their maintainability. yet, little work attempted to study the impact of design patterns on the developers' tasks of program comprehension and modification. we design and perform an experiment to collect data on the impact of the visitor pattern on comprehension and modification tasks with class diagrams. we use an eye-tracker to register saccades and fixations, the latter representing the focus of the developers' attention. collected data show that the visitor pattern plays a role in maintenance tasks: class diagrams with its canonical representation requires less efforts from developers.",
            "contribution_ids": [
                "R31706"
            ]
        },
        {
            "instance_id": "R31725xR31723",
            "comparison_id": "R31725",
            "paper_id": "R31723",
            "text": "Design patterns and fault-proneness a study of commercial C# software in this paper, we document a study of design patterns in commercial, proprietary software and determine whether design pattern participants (i.e. the constituent classes of a pattern) had a greater propensity for faults than non-participants. we studied a commercial software system for a 24 month period and identified design pattern participants by inspecting the design documentation and source code; we also extracted fault data for the same period to determine whether those participant classes were more fault-prone than non-participant classes. results showed that design pattern participant classes were marginally more fault-prone than non-participant classes, the adaptor, method and singleton patterns were found to be the most fault-prone of thirteen patterns explored. however, the primary reason for this fault-proneness was the propensity of design classes to be changed more often than non-design pattern classes.",
            "contribution_ids": [
                "R31724"
            ]
        },
        {
            "instance_id": "R31725xR31709",
            "comparison_id": "R31725",
            "paper_id": "R31709",
            "text": "An empirical study on the evolution of design patterns design patterns are solutions to recurring design problems, conceived to increase benefits in terms of reuse, code quality and, above all, maintainability and resilience to changes. this paper presents results from an empirical study aimed at understanding the evolution of design patterns in three open source systems, namely jhotdraw, argouml, and eclipse-jdt. specifically, the study analyzes how frequently patterns are modified, to what changes they undergo and what classes co-change with the patterns. results show how patterns more suited to support the application purpose tend to change more frequently, and that different kind of changes have a different impact on co-changed classes and a different capability of making the system resilient to changes.",
            "contribution_ids": [
                "R31710"
            ]
        },
        {
            "instance_id": "R31725xR31697",
            "comparison_id": "R31725",
            "paper_id": "R31697",
            "text": "Design Patterns in Software Maintenance: An Experiment Replication at UPM - Experiences with the RESER'11 Joint Replication Project \"replication of software engineering experiments is crucial for dealing with validity threats to experiments in this area. even though the empirical software engineering community is aware of the importance of replication, the replication rate is still very low. the reser'11 joint replication project aims to tackle this problem by simultaneously running a series of several replications of the same experiment. in this article, we report the results of the replication run at the universidad polit\u00e9cnica de madrid. our results are inconsistent with the original experiment. however, we have identified possible causes for them. we also discuss our experiences (in terms of pros and cons) during the replication.\"",
            "contribution_ids": [
                "R31698"
            ]
        },
        {
            "instance_id": "R31725xR31719",
            "comparison_id": "R31725",
            "paper_id": "R31719",
            "text": "An empirical investigation on the impact of design pattern application on computer game defects in this paper, we investigate the correlation between design pattern application and software defects. in order to achieve this goal we conducted an empirical study on java open source games. more specifically, we examined several successful open source games, identified the number of defects, the debugging rate and performed design pattern related measurements. the results of the study suggest that the overall number of design pattern instances is not correlated to defect frequency and debugging effectiveness. however, specific design patterns appear to have a significant impact on the number of reported bugs and debugging rate.",
            "contribution_ids": [
                "R31720"
            ]
        },
        {
            "instance_id": "R31768xR31749",
            "comparison_id": "R31768",
            "paper_id": "R31749",
            "text": "Survival of Campylobacter jejuni in Frozen Chicken Meat and Genetic Analysis of Isolates by Pulsed-Field Gel Electrophoresis \u5e02\u8ca9\u9d8f\u8089\u306e\u30ab\u30f3\u30d4\u30ed\u30d0\u30af\u30bf\u30fc\u6c5a\u67d3\u8abf\u67fb\u3092\u884c\u3063\u305f\u3068\u3053\u308d, 100\u691c\u4f53\u4e2d49\u691c\u4f53 (49.0%) \u304ccampylobacter jejuni\u967d\u6027\u3067\u3042\u3063\u305f.\u305d\u306e49\u691c\u4f53\u306b\u3064\u3044\u3066, \u51b7\u51cd\u4fdd\u5b58\u306b\u3088\u308b\u9d8f\u8089\u4e2d\u306ecampylobacter\u83cc\u6570\u306e\u5909\u5316\u3092mpn\u6cd5\u306b\u3088\u308a\u8abf\u67fb\u3057\u305f\u3068\u3053\u308d, -20\u2103, 7\u65e5\u9593\u4fdd\u5b58\u5f8c\u306e\u83cc\u6570\u306f\u4fdd\u5b58\u524d\u306e\u691c\u4f53\u306b\u6bd4\u3079\u30661/10\uff5e1/100\u306b\u6e1b\u5c11\u3057, 25/49\u691c\u4f53 (51.0%) \u3067\u306f\u691c\u51fa\u9650\u754c\u672a\u6e80 (mpn\u5024<15/100g) \u3068\u306a\u3063\u305f.pfge\u6cd5\u306b\u3088\u308a\u5206\u96e2\u83cc\u682a\u306e\u907a\u4f1d\u5b50\u89e3\u6790\u3092\u884c\u3063\u305f\u3068\u3053\u308d, \u5e02\u8ca9\u9d8f\u8089\u306f\u5358\u4e00\u3067\u306f\u306a\u304f\u8907\u6570\u306e\u907a\u4f1d\u5b50\u578b\u306e\u83cc\u306b\u3088\u3063\u3066\u6c5a\u67d3\u3055\u308c\u3066\u3044\u308b\u3053\u3068\u304c\u793a\u5506\u3055\u308c, \u307e\u305f, 8/24\u691c\u4f53 (33.3%) \u306b\u304a\u3044\u3066, \u51b7\u51cd\u4fdd\u5b58\u524d\u5f8c\u3067\u7570\u306a\u308b\u907a\u4f1d\u5b50\u578b\u306e\u83cc\u304c\u5206\u96e2\u3055\u308c\u305f.\u3053\u306e\u305f\u3081, \u98df\u4e2d\u6bd2\u4e8b\u4ef6\u306e\u539f\u56e0\u7a76\u660e\u306e\u305f\u3081\u306b\u306f, \u98df\u54c1\u691c\u4f53\u304b\u3089\u3067\u304d\u308b\u3060\u3051\u591a\u304f\u306e\u83cc\u682a\u3092\u5206\u96e2\u3057, \u907a\u4f1d\u5b50\u89e3\u6790\u3092\u884c\u3046\u5fc5\u8981\u6027\u304c\u3042\u308b\u3053\u3068\u304c\u8003\u3048\u3089\u308c\u305f.\u9d8f\u8089\u3078\u306ec. jejuni\u63a5\u7a2e\u8a66\u9a13\u3067\u306f, \u89e3\u51cd\u305b\u305a\u306b\u51cd\u7d50\u72b6\u614b\u3067\u4fdd\u5b58\u3057\u305f\u691c\u4f53\u3067\u306f, \u51cd\u7d50\u30fb\u89e3\u51cd\u3092\u7e70\u308a\u8fd4\u3057\u305f\u3082\u306e\u3088\u308a\u3082\u83cc\u6570\u306e\u6e1b\u5c11\u304c\u308f\u305a\u304b\u3067\u3042\u3063\u305f\u3053\u3068\u304b\u3089, \u83cc\u306e\u6b7b\u6ec5\u306f\u4e3b\u306b\u51cd\u7d50\u6642\u3042\u308b\u3044\u306f\u89e3\u51cd\u6642\u306b\u8d77\u3053\u308b\u3053\u3068\u304c\u793a\u5506\u3055\u308c\u305f.",
            "contribution_ids": [
                "R31750"
            ]
        },
        {
            "instance_id": "R31809xR31771",
            "comparison_id": "R31809",
            "paper_id": "R31771",
            "text": "MSAP markers and global cytosine methylation in plants: a literature survey and comparative analysis for a wild-growing species methylation of dna cytosines affects whether transposons are silenced and genes are expressed, and is a major epigenetic mechanism whereby plants respond to environmental change. analyses of methylation\u2010sensitive amplification polymorphism (ms\u2010aflp or msap) have been often used to assess methyl\u2010cytosine changes in response to stress treatments and, more recently, in ecological studies of wild plant populations. msap technique does not require a sequenced reference genome and provides many anonymous loci randomly distributed over the genome for which the methylation status can be ascertained. scoring of msap data, however, is not straightforward, and efforts are still required to standardize this step to make use of the potential to distinguish between methylation at different nucleotide contexts. furthermore, it is not known how accurately msap infers genome\u2010wide cytosine methylation levels in plants. here, we analyse the relationship between msap results and the percentage of global cytosine methylation in genomic dna obtained by hplc analysis. a screening of literature revealed that methylation of cytosines at cleavage sites assayed by msap was greater than genome\u2010wide estimates obtained by hplc, and percentages of methylation at different nucleotide contexts varied within and across species. concurrent hplc and msap analyses of dna from 200 individuals of the perennial herb helleborus foetidus confirmed that methyl\u2010cytosine was more frequent in ccgg contexts than in the genome as a whole. in this species, global methylation was unrelated to methylation at the inner cg site. we suggest that global hplc and context\u2010specific msap methylation estimates provide complementary information whose combination can improve our current understanding of methylation\u2010based epigenetic processes in nonmodel plants.",
            "contribution_ids": [
                "R31772"
            ]
        },
        {
            "instance_id": "R31809xR31776",
            "comparison_id": "R31809",
            "paper_id": "R31776",
            "text": "Genetic and DNA methylation changes in cotton (Gossypium) genotypes and tissues in plants, epigenetic regulation is important in normal development and in modulating some agronomic traits. the potential contribution of dna methylation mediated gene regulation to phenotypic diversity and development in cotton was investigated between cotton genotypes and various tissues. dna methylation diversity, genetic diversity, and changes in methylation context were investigated using methylation-sensitive amplified polymorphism (msap) assays including a methylation insensitive enzyme (bsisi), and the total dna methylation level was measured by high-performance liquid chromatography (hplc). dna methylation diversity was greater than the genetic diversity in the selected cotton genotypes and significantly different levels of dna methylation were identified between tissues, including fibre. the higher dna methylation diversity (chg methylation being more diverse than cg methylation) in cotton genotypes suggest epigenetic regulation may be important for cotton, and the change in dna methylation between fibre and other tissues hints that some genes may be epigenetically regulated for fibre development. the novel approach using bsisi allowed direct comparison between genetic and epigenetic diversity, and also measured cc methylation level that cannot be detected by conventional msap.",
            "contribution_ids": [
                "R31777",
                "R31779"
            ]
        },
        {
            "instance_id": "R31809xR31804",
            "comparison_id": "R31809",
            "paper_id": "R31804",
            "text": "Maize chromomethylase Zea methyltransferase2 is required for CpNpG methylation a cytosine dna methyltransferase containing a chromodomain, zea methyltransferase2 (zmet2), was cloned from maize. the sequence of zmet2 is similar to that of the arabidopsis chromomethylases cmt1 and cmt3, with c-terminal motifs characteristic of eukaryotic and prokaryotic dna methyltransferases. we used a reverse genetics approach to determine the function of the zmet2 gene. plants homozygous for a mutator transposable element insertion into motif ix had a 13% reduction in methylated cytosines. dna gel blot analysis of these plants with methylation-sensitive restriction enzymes and bisulfite sequencing of a 180-bp knob sequence showed reduced methylation only at cpnpg sites. no reductions in methylation were observed at cpg or asymmetric sites in heterozygous or homozygous mutant plants. our research shows that chromomethylase zmet2 is required for in vivo methylation of cpnpg sequences.",
            "contribution_ids": [
                "R31805"
            ]
        },
        {
            "instance_id": "R31878xR31819",
            "comparison_id": "R31878",
            "paper_id": "R31819",
            "text": "Large-scale gasification-based coproduction of fuels and electricity from switchgrass large\u2010scale gasification\u2010based systems for producing fischer\u2010tropsch (f\u2010t) fuels (diesel and gasoline blendstocks), dimethyl ether (dme), or hydrogen from switchgrass \u2013 with electricity as a coproduct in each case are assessed using a self\u2010consistent design, simulation, and cost analysis framework. we provide an overview of alternative process designs for coproducing these fuels and power assuming commercially mature technology performance and discuss the commercial status of key component technologies. overall efficiencies (lower\u2010heating\u2010value basis) of producing fuels plus electricity in these designs ranges from 57% for f\u2010t fuels, 55\u201361% for dme, and 58\u201364% for hydrogen. detailed capital cost estimates for each design are developed, on the basis of which prospective commercial economics of future large\u2010scale facilities that coproduce fuels and power are evaluated. \u00a9 2009 society of chemical industry and john wiley & sons, ltd",
            "contribution_ids": [
                "R31820"
            ]
        },
        {
            "instance_id": "R31903xR31822",
            "comparison_id": "R31903",
            "paper_id": "R31822",
            "text": "Making FischereTropsch fuels and electricity from coal and biomass: performance and cost analysis major challenges posed by crude-oil-derived transportation fuels are high current and prospective oil prices, insecurity of liquid fuel supplies, and climate change risks from the accumulation of fossil fuel co2 and other greenhouse gases in the atmosphere. one option for addressing these challenges simultaneously involves producing ultraclean synthetic fuels from coal and lignocellulosic biomass with co2 capture and storage. detailed process simulations, lifecycle greenhouse gas emissions analyses, and cost analyses carried out in a comprehensive analytical framework are presented for 16 alternative system configurations that involve gasification-based coproduction of fischer\u2212tropsch liquid (ftl) fuels and electricity from coal and/or biomass, with and without capture and storage of byproduct co2. systematic comparisons are made to cellulosic ethanol as an alternative low ghg-emitting liquid fuel and to alternative options for decarbonizing stand-alone fossil-fuel power plants. the analysis indicates tha...",
            "contribution_ids": [
                "R31823",
                "R31824",
                "R31883",
                "R31884",
                "R31940",
                "R31970",
                "R31971",
                "R31997",
                "R31998"
            ]
        },
        {
            "instance_id": "R31928xR31923",
            "comparison_id": "R31928",
            "paper_id": "R31923",
            "text": "Economic analysis for conceptual design of super- critical O2-based PC boiler this report determines the capital and operating costs of two different oxygen-based, pulverized coal-fired (pc) power plants and compares their economics to that of a comparable, air-based pc plant. rather than combust their coal with air, the oxygen-based plants use oxygen to facilitate capture/removal of the plant co{sub 2} for transport by pipeline to a sequestering site. to provide a consistent comparison of technologies, all three plants analyzed herein operate with the same coal (illinois no 6), the same site conditions, and the same supercritical pressure steam turbine (459 mwe). in the first oxygen-based plant, the pulverized coal-fired boiler operates with oxygen supplied by a conventional, cryogenic air separation unit, whereas, in the second oxygen-based plant, the oxygen is supplied by an oxygen ion transport membrane. in both oxygen-based plants a portion of the boiler exhaust gas, which is primarily co{sub 2}, is recirculated back to the boiler to control the combustion temperature, and the balance of the flue gas undergoes drying and compression to pipeline pressure; for consistency, both plants operate with similar combustion temperatures and utilize the same co{sub 2} processing technologies. the capital and operating costs of the pulverized coal-fired boilers required by the three different plants more\\xa0\u00bb were estimated by foster wheeler and the balance of plant costs were budget priced using published data together with vendor supplied quotations. the cost of electricity produced by each of the plants was determined and oxygen-based plant co{sub 2} mitigation costs were calculated and compared to each other as well as to values published for some alternative co{sub 2} capture technologies. \u00ab\\xa0less",
            "contribution_ids": [
                "R31924"
            ]
        },
        {
            "instance_id": "R31928xR31921",
            "comparison_id": "R31928",
            "paper_id": "R31921",
            "text": "Technoeconomic analysis of a lignocellulosic biomass indirect gasification process to make ethanol via mixed alcohols synthesis a technoeconomic analysis of a 2000 tonne/day lignocellulosic biomass conversion process to make mixed alcohols via gasification and catalytic synthesis was completed. the process, modeled using aspen plus process modeling software for mass and energy calculations, included all major process steps to convert biomass into liquid fuels, including gasification, gas cleanup and conditioning, synthesis conversion to mixed alcohols, and product separation. the gas cleanup area features a catalytic fluidized-bed steam reformer to convert tars and hydrocarbons into syngas. conversions for both the reformer and the synthesis catalysts were based on research targets expected to be achieved by 2012 through ongoing research. the mass and energy calculations were used to estimate capital and operating costs that were used in a discounted cash flow rate of return analysis for the process to calculate a minimum ethanol selling price of $0.267/l ($1.01/gal) ethanol (u.s.$2005).",
            "contribution_ids": [
                "R31922"
            ]
        },
        {
            "instance_id": "R31954xR31881",
            "comparison_id": "R31954",
            "paper_id": "R31881",
            "text": "Second generation BtL type biofuels \u00e2\u0080\u0093 a production cost analysis the objective of this paper is to address the issue of the production cost of second generation biofuels via the thermo-chemical route. the last decade has seen a large number of technical\u2013economic studies of second generation biofuels. as there is a large variation in the announced production costs of second generation biofuels in the literature, this paper clarifies some of the reasons for these variations and helps obtain a clearer picture. this paper presents simulations for two pathways and comparative production pathways previously published in the literature in the years between 2000 and 2011. it also includes a critical comparison and analysis of previously published studies. this paper does not include studies where the production is boosted with a hydrogen injection to improve the carbon yield. the only optimisation included is the recycle of tail gas. it is shown that the fuel can be produced on a large scale at prices of around 1.0\u20131.4 \u20ac per l. large uncertainties remain however with regard to the precision of the economic predictions, the technology choices, the investment cost estimation and even the financial models to calculate the production costs. the benefit of a tail gas recycle is also examined; its benefit largely depends on the selling price of the produced electricity.",
            "contribution_ids": [
                "R31882",
                "R31935",
                "R31964",
                "R31965"
            ]
        },
        {
            "instance_id": "R31954xR31929",
            "comparison_id": "R31954",
            "paper_id": "R31929",
            "text": "Hardwood biomass to gasoline, diesel, and jet fuel: I. Process synthesis and global opti- mization of a thermochemical refinery a process synthesis framework is introduced for the conversion of hardwood biomass to liquid (btl) transportation fuels. a process superstructure is postulated that considers multiple thermochemical pathways for the production of gasoline, diesel, and jet fuel from a synthesis gas intermediate. the hardwood is dried and gasified to generate the synthesis gas, which is converted to hydrocarbons via fischer\u2013tropsch or methanol synthesis. six different types of fischer\u2013tropsch units and two methanol conversion pathways are analyzed to determine the topology for liquid fuel production that minimizes the overall system cost. several upgrading technologies, namely, zsm-5 catalytic conversion, oligomerization, hydrocracking, isomerization, alkylation, and hydrotreating, are capable of outputting fuels that meet all necessary physical property standards. the costs associated with utility production and wastewater treatment are directly included within the process synthesis framework using a simultaneous heat, pow...",
            "contribution_ids": [
                "R31930",
                "R31955"
            ]
        },
        {
            "instance_id": "R31991xR31881",
            "comparison_id": "R31991",
            "paper_id": "R31881",
            "text": "Second generation BtL type biofuels \u00e2\u0080\u0093 a production cost analysis the objective of this paper is to address the issue of the production cost of second generation biofuels via the thermo-chemical route. the last decade has seen a large number of technical\u2013economic studies of second generation biofuels. as there is a large variation in the announced production costs of second generation biofuels in the literature, this paper clarifies some of the reasons for these variations and helps obtain a clearer picture. this paper presents simulations for two pathways and comparative production pathways previously published in the literature in the years between 2000 and 2011. it also includes a critical comparison and analysis of previously published studies. this paper does not include studies where the production is boosted with a hydrogen injection to improve the carbon yield. the only optimisation included is the recycle of tail gas. it is shown that the fuel can be produced on a large scale at prices of around 1.0\u20131.4 \u20ac per l. large uncertainties remain however with regard to the precision of the economic predictions, the technology choices, the investment cost estimation and even the financial models to calculate the production costs. the benefit of a tail gas recycle is also examined; its benefit largely depends on the selling price of the produced electricity.",
            "contribution_ids": [
                "R31882",
                "R31935",
                "R31964",
                "R31965"
            ]
        },
        {
            "instance_id": "R31991xR31822",
            "comparison_id": "R31991",
            "paper_id": "R31822",
            "text": "Making FischereTropsch fuels and electricity from coal and biomass: performance and cost analysis major challenges posed by crude-oil-derived transportation fuels are high current and prospective oil prices, insecurity of liquid fuel supplies, and climate change risks from the accumulation of fossil fuel co2 and other greenhouse gases in the atmosphere. one option for addressing these challenges simultaneously involves producing ultraclean synthetic fuels from coal and lignocellulosic biomass with co2 capture and storage. detailed process simulations, lifecycle greenhouse gas emissions analyses, and cost analyses carried out in a comprehensive analytical framework are presented for 16 alternative system configurations that involve gasification-based coproduction of fischer\u2212tropsch liquid (ftl) fuels and electricity from coal and/or biomass, with and without capture and storage of byproduct co2. systematic comparisons are made to cellulosic ethanol as an alternative low ghg-emitting liquid fuel and to alternative options for decarbonizing stand-alone fossil-fuel power plants. the analysis indicates tha...",
            "contribution_ids": [
                "R31823",
                "R31824",
                "R31883",
                "R31884",
                "R31940",
                "R31970",
                "R31971",
                "R31997",
                "R31998"
            ]
        },
        {
            "instance_id": "R32025xR31995",
            "comparison_id": "R32025",
            "paper_id": "R31995",
            "text": "Comparative analysis of the production costs and life-cycle GHG emissions of FT liquid fuels from coal and natural Gas liquid transportation fuels derived from coal and natural gas could helpthe united states reduce its dependence on petroleum. the fuels could be produced domestically or imported from fossil fuel-rich countries. the goal of this paper is to determine the life-cycle ghg emissions of coal- and natural gas-based fischer-tropsch (ft) liquids, as well as to compare production costs. the results show that the use of coal- or natural gas-based ft liquids will likely lead to significant increases in greenhouse gas (ghg) emissions compared to petroleum-based fuels. in a best-case scenario, coal- or natural gas-based ft-liquids have emissions only comparable to petroleum-based fuels. in addition, the economic advantages of gas-to-liquid (gtl) fuels are not obvious: there is a narrow range of petroleum and natural gas prices at which gtl fuels would be competitive with petroleum-based fuels. ctlfuels are generally cheaper than petroleum-based fuels. however, recent reports suggest there is uncertainty about the availability of economically viable coal resources in the united states. if the u.s. has a goal of increasing its energy security, and at the same time significantly reducing its ghg emissions, neither ctl nor gtl consumption seem a reasonable path to follow.",
            "contribution_ids": [
                "R31996"
            ]
        },
        {
            "instance_id": "R32061xR32055",
            "comparison_id": "R32061",
            "paper_id": "R32055",
            "text": "Domain adaptation via pseudo in-domain data selection we explore efficient domain adaptation for the task of statistical machine translation based on extracting sentences from a large general-domain parallel corpus that are most relevant to the target domain. these sentences may be selected with simple cross-entropy based methods, of which we present three. as these sentences are not themselves identical to the in-domain data, we call them pseudo in-domain subcorpora. these subcorpora -- 1% the size of the original -- can then used to train small domain-adapted statistical machine translation (smt) systems which outperform systems trained on the entire corpus. performance is further improved when we use these domain-adapted models in combination with a true in-domain model. the results show that more training data is not always better, and that best results are attained via proper domain-relevant data selection, as well as combining in- and general-domain systems during decoding.",
            "contribution_ids": [
                "R32056"
            ]
        },
        {
            "instance_id": "R32061xR32034",
            "comparison_id": "R32061",
            "paper_id": "R32034",
            "text": "Domain adaptation with structural correspondence learning discriminative learning methods are widely used in natural language processing. these methods work best when their training and test data are drawn from the same distribution. for many nlp tasks, however, we are confronted with new domains in which labeled data is scarce or non-existent. in such cases, we seek to adapt existing models from a resource-rich source domain to a resource-poor target domain. we introduce structural correspondence learning to automatically induce correspondences among features from different domains. we test our technique on part of speech tagging and show performance gains for varying amounts of source and target training data, as well as improvements in target domain parsing accuracy using our improved tagger.",
            "contribution_ids": [
                "R32035"
            ]
        },
        {
            "instance_id": "R32061xR32042",
            "comparison_id": "R32061",
            "paper_id": "R32042",
            "text": "Domain adaptation with latent semantic association for named entity recognition domain adaptation is an important problem in named entity recognition (ner). ner classifiers usually lose accuracy in the domain transfer due to the different data distribution between the source and the target domains. the major reason for performance degrading is that each entity type often has lots of domain-specific term representations in the different domains. the existing approaches usually need an amount of labeled target domain data for tuning the original model. however, it is a labor-intensive and time-consuming task to build annotated training data set for every target domain. we present a domain adaptation method with latent semantic association (lasa). this method effectively overcomes the data distribution difference without leveraging any labeled target domain data. lasa model is constructed to capture latent semantic association among words from the unlabeled corpus. it groups words into a set of concepts according to the related context snippets. in the domain transfer, the original term spaces of both domains are projected to a concept space using lasa model at first, then the original ner model is tuned based on the semantic association features. experimental results on english and chinese corpus show that lasa-based domain adaptation significantly enhances the performance of ner.",
            "contribution_ids": [
                "R32043"
            ]
        },
        {
            "instance_id": "R32061xR32046",
            "comparison_id": "R32061",
            "paper_id": "R32046",
            "text": "Topic-bridged PLSA for cross-domain text classification in many web applications, such as blog classification and new-sgroup classification, labeled data are in short supply. it often happens that obtaining labeled data in a new domain is expensive and time consuming, while there may be plenty of labeled data in a related but different domain. traditional text classification ap-proaches are not able to cope well with learning across different domains. in this paper, we propose a novel cross-domain text classification algorithm which extends the traditional probabilistic latent semantic analysis (plsa) algorithm to integrate labeled and unlabeled data, which come from different but related domains, into a unified probabilistic model. we call this new model topic-bridged plsa, or tplsa. by exploiting the common topics between two domains, we transfer knowledge across different domains through a topic-bridge to help the text classification in the target domain. a unique advantage of our method is its ability to maximally mine knowledge that can be transferred between domains, resulting in superior performance when compared to other state-of-the-art text classification approaches. experimental eval-uation on different kinds of datasets shows that our proposed algorithm can improve the performance of cross-domain text classification significantly.",
            "contribution_ids": [
                "R32047"
            ]
        },
        {
            "instance_id": "R32061xR32052",
            "comparison_id": "R32061",
            "paper_id": "R32052",
            "text": "Estimating class priors in domain adaptation for word sense disambiguation instances of a word drawn from different domains may have different sense priors (the proportions of the different senses of a word). this in turn affects the accuracy of word sense disambiguation (wsd) systems trained and applied on different domains. this paper presents a method to estimate the sense priors of words drawn from a new domain, and highlights the importance of using well calibrated probabilities when performing these estimations. by using well calibrated probabilities, we are able to estimate the sense priors effectively to achieve significant improvements in wsd accuracy.",
            "contribution_ids": [
                "R32053"
            ]
        },
        {
            "instance_id": "R32061xR32057",
            "comparison_id": "R32061",
            "paper_id": "R32057",
            "text": "Instance level transfer learning for cross lingual opinion analysis this paper presents two instance-level transfer learning based algorithms for cross lingual opinion analysis by transferring useful translated opinion examples from other languages as the supplementary training data for improving the opinion classifier in target language. starting from the union of small training data in target language and large translated examples in other languages, the transfer adaboost algorithm is applied to iteratively reduce the influence of low quality translated examples. alternatively, starting only from the training data in target language, the transfer self-training algorithm is designed to iteratively select high quality translated examples to enrich the training data set. these two algorithms are applied to sentence- and document-level cross lingual opinion analysis tasks, respectively. the evaluations show that these algorithms effectively improve the opinion analysis by exploiting small target language training data and large cross lingual training data.",
            "contribution_ids": [
                "R32058"
            ]
        },
        {
            "instance_id": "R32061xR32031",
            "comparison_id": "R32061",
            "paper_id": "R32031",
            "text": "Frustratingly easy domain adaptation over the last years, several authors have signaled that state of the art categorization methods fail to perform well when trained and tested on data from different databases. the general consensus in the literature is that this issue, known as domain adaptation and/or dataset bias, is due to a distribution mismatch between data collections. methods addressing it go from max-margin classifiers to learning how to modify the features and obtain a more robust representation. the large majority of these works use bow feature descriptors, and learning methods based on image-to-image distance functions. following the seminal work of [6], in this paper we challenge these two assumptions. we experimentally show that using the nbnn classifier over existing domain adaptation databases achieves always very strong performances. we build on this result, and present an nbnn-based domain adaptation algorithm that learns iteratively a class metric while inducing, for each sample, a large margin separation among classes. to the best of our knowledge, this is the first work casting the domain adaptation problem within the nbnn framework. experiments show that our method achieves the state of the art, both in the unsupervised and semi-supervised settings.",
            "contribution_ids": [
                "R32032"
            ]
        },
        {
            "instance_id": "R32189xR32113",
            "comparison_id": "R32189",
            "paper_id": "R32113",
            "text": "An evolutionary hybrid scheduler based in Petri net structures for FMS scheduling addresses a hybrid scheduling methodology for flexible manufacturing systems (fms) that uses petri nets (pns) as a modeling tool and several successfully employed scheduling methods: conflict-solving based on heuristic dispatching algorithms, artificial intelligence (ai) heuristic search, problem decomposition and evolutionary approximation algorithms as search tools. pns have been traditionally employed in scheduling approaches based on discrete event simulation and more recently, the combination of pns and ai heuristic search has produced interesting results. pns also allow easy structural analysis towards a decomposition of the problem. in this paper pns are employed as a representation paradigm and a decomposition-construction scheduling method is based on them. a pn-based ai systematic heuristic search is used to solve sub-problems which are progressively joined by an evolutionary building procedure. experimental results based on a preliminary implementation of the method are presented.",
            "contribution_ids": [
                "R32114"
            ]
        },
        {
            "instance_id": "R32189xR32105",
            "comparison_id": "R32189",
            "paper_id": "R32105",
            "text": "Dynamic scheduling of FMS using a real-time genetic algorithm the paper presents a genetic algorithm capable of generating optimised production plans in flexible manufacturing systems. the ability of the system to generate alternative plans following part-flow changes and unforeseen situations is particularly stressed (dynamic scheduling). two contrasting objectives represented by the reduction of machine idle-times, thanks to dynamic scheduling computation and the reduction of the makespan, are taken into account by the proposed system. the key-point is the real-time response obtained by an optimised evolutionary strategy capable of minimising the number of genetic operations needed to reach the optimal schedule in complex manufacturing systems.",
            "contribution_ids": [
                "R32106"
            ]
        },
        {
            "instance_id": "R32189xR32101",
            "comparison_id": "R32189",
            "paper_id": "R32101",
            "text": "Petri Net based modeling and GA based scheduling for a flexible manufacturing system in this paper, a genetic algorithm (ga) embedded adaptive scheduling over a timed place petri net (tppn) model provides a new method for a flexible manufacturing system (fms). the chromosome representation of the search nodes is constructed directly from the tppn model of an fms. a tppn based schedule builder receives a chromosome and an initial marking as input, and then produces a near-optimal schedule.",
            "contribution_ids": [
                "R32102"
            ]
        },
        {
            "instance_id": "R32189xR32138",
            "comparison_id": "R32189",
            "paper_id": "R32138",
            "text": "Deadlock-Free Scheduling Strategy for Automated Production Cell deadlock must be avoided in a manufacturing system. in this paper, an efficient algorithm for finding an optimal deadlock-free schedule in a manufacturing system with very limited buffer is presented. this algorithm is based on the effective genetic algorithm (ga) search method, and a formal petri net structure is introduced to detect the token player assuring deadlock-free. in order to make the scheduling strategy generated by ga meet the required constraint of deadlock-free, petri net is involved to make the implementation of the job scheduling in an fms deadlock-free. the effectiveness and efficiency of the proposed approach is illustrated by using an example.",
            "contribution_ids": [
                "R32139"
            ]
        },
        {
            "instance_id": "R32189xR32111",
            "comparison_id": "R32189",
            "paper_id": "R32111",
            "text": "GA-based discrete dynamic programming approach for scheduling in FMS environments the paper presents a new genetic algorithm (ga)-based discrete dynamic programming (ddp) approach for generating static schedules in a flexible manufacturing system (fms) environment. this ga-ddp approach adopts a sequence-dependent schedule generation strategy, where a ga is employed to generate feasible job sequences and a series of discrete dynamic programs are constructed to generate legal schedules for a given sequence of jobs. in formulating the ga, different performance criteria could be easily included. the developed ddf algorithm is capable of identifying locally optimized partial schedules and shares the computation efficiency of dynamic programming. the algorithm is designed in such a way that it does not suffer from the state explosion problem inherent in pure dynamic programming approaches in fms scheduling. numerical examples are reported to illustrate the approach.",
            "contribution_ids": [
                "R32112"
            ]
        },
        {
            "instance_id": "R32189xR32153",
            "comparison_id": "R32189",
            "paper_id": "R32153",
            "text": "An Introduction of Dominant Genes in Genetic Algorithm for Scheduling of FMS this paper proposed a new idea named dominant genes (dgs) in genetic algorithms (gas) to deal with fms scheduling problem with alternative production routing. in traditional gas approach, the crossover mechanism will randomly select a number of genes to undergo crossover. however, these selected genes may not contain or contain only part of the critical structure of its original chromosome. in addition, since the inherited complexity of the scheduling nature, the changes in the structure of the selected genes will further influence its strength. to tackle this problem, the proposed dgs in this paper are to identify and record the best genes in the chromosome. a new crossover mechanism is also designed to ensure the best genes will undergo crossover, and retain the originality of the structure of the crossover genes. the performance of the proposed dgs is testified by comparing it with other heuristic optimizations. the comparison shows that dgs perform better than other approaches",
            "contribution_ids": [
                "R32154"
            ]
        },
        {
            "instance_id": "R32189xR32176",
            "comparison_id": "R32189",
            "paper_id": "R32176",
            "text": "An introduction of dominant genes in genetic algorithm for FMS this paper proposes a new idea, namely genetic algorithms with dominant genes (gadg) in order to deal with fms scheduling problems with alternative production routing. in the traditional genetic algorithm (ga) approach, crossover and mutation rates should be pre-defined. however, different rates applied in different problems will directly influence the performance of genetic search. determination of optimal rates in every run is time-consuming and not practical in reality due to the infinite number of possible combinations. in addition, this crossover rate governs the number of genes to be selected to undergo crossover, and this selection process is totally arbitrary. the selected genes may not represent the potential critical structure of the chromosome. to tackle this problem, gadg is proposed. this approach does not require a defined crossover rate, and the proposed similarity operator eliminates the determination of the mutation rate. this idea helps reduce the computational time remarkably and improve the performance of genetic search. the proposed gadg will identify and record the best genes and structure of each chromosome. a new crossover mechanism is designed to ensure the best genes and structures to undergo crossover. the performance of the proposed gadg is testified by comparing it with other existing methodologies, and the results show that it outperforms other approaches.",
            "contribution_ids": [
                "R32177"
            ]
        },
        {
            "instance_id": "R32189xR32120",
            "comparison_id": "R32189",
            "paper_id": "R32120",
            "text": "A genetic algorithm to solving the problem of flexible manufacturing system cyclic scheduling we are interested in the determination of the command of flexible manufacturing systems (fms). we have chosen the cyclic behavior to reduce the complexity of the general,scheduling problem. the aim is to propose a new one based on genetic algorithms which can reach the optimal production speed while minimizing the work in process (w.i.p.). in fact we want to minimize the w.l.p. to satisfy economical constraints. the use of genetic algorithms is justified by the huge combinatorial complexity of such problems (np hard in the general case). indeed, this kind of algorithm is able to give a solution at any moment. our approach was validated on a set of five fms cyclic scheduling test problems.",
            "contribution_ids": [
                "R32121"
            ]
        },
        {
            "instance_id": "R32189xR32135",
            "comparison_id": "R32189",
            "paper_id": "R32135",
            "text": "Solving the FMS scheduling problem by critical ratio-based heuristics and the genetic algorithm this paper addresses the fms scheduling problem. the objective concerned here is maximizing the meet-due-date rate. the authors propose two rules for job sequencing and job dispatching, two common subtasks in solving this problem. these two rules are designed based on the critical ratio values of jobs. we also propose a mechanism to obtain better performance than the stand-alone scheduling process via genetic algorithms. with the nature of design of the proposed job sequencing rule, the genetic algorithm is designed not only to improve the schedule quality but also to save computation time. all the proposed rules and idea are carefully examined through several different scenarios.",
            "contribution_ids": [
                "R32136"
            ]
        },
        {
            "instance_id": "R32189xR32129",
            "comparison_id": "R32189",
            "paper_id": "R32129",
            "text": "An intelligent hierarchical workstation control model for FMS hierarchical planning, scheduling and control in flexible manufacturing systems (fms) provide a systematic way to effectively allocate resources along different time horizons. this paper describes the design and development of an intelligent hierarchical control model based on a proposed tool management method. the control model consists of four levels: the process plan selection, the master scheduling, the job sequencing and the control level. the model is developed to optimize the machine utilization and balance tool magazine capacity of a flexible machining workstation (fmw) in a tool-sharing environment. problems are identified and modeled in the level of process plan selection, master scheduling, and job sequencing. a genetic-based algorithm was developed to solve the problem domains throughout the hierarchical planning and scheduling model. fuzzy logic technique could also be incorporated into the master production schedule (mps) level to allow for a more realistic result in the presence of uncertainty and impreciseness in order to fit the realistic nature of actual industrial environments. \u00a9 2003 elsevier science b.v. all rights reserved.",
            "contribution_ids": [
                "R32130"
            ]
        },
        {
            "instance_id": "R32189xR32160",
            "comparison_id": "R32189",
            "paper_id": "R32160",
            "text": "Application of genetic algorithms with dominant genes in a distributed scheduling problem in flexible manufacturing systems multi-factory production networks have increased in recent years. with the factories located in different geographic areas, companies can benefit from various advantages, such as closeness to their customers, and can respond faster to market changes. products (jobs) in the network can usually be produced in more than one factory. however, each factory has its operations efficiency, capacity, and utilization level. allocation of jobs inappropriately in a factory will produce high cost, long lead time, overloading or idling resources, etc. this makes distributed scheduling more complicated than classical production scheduling problems because it has to determine how to allocate the jobs into suitable factories, and simultaneously determine the production scheduling in each factory as well. the problem is even more complicated when alternative production routing is allowed in the factories. this paper proposed a genetic algorithm with dominant genes to deal with distributed scheduling problems, especially in a flexible manufacturing system (fms) environment. the idea of dominant genes is to identify and record the critical genes in the chromosome and to enhance the performance of genetic search. to testify and benchmark the optimization reliability, the proposed algorithm has been compared with other approaches on several distributed scheduling problems. these comparisons demonstrate the importance of distributed scheduling and indicate the optimization reliability of the proposed algorithm.",
            "contribution_ids": [
                "R32161"
            ]
        },
        {
            "instance_id": "R32189xR32182",
            "comparison_id": "R32189",
            "paper_id": "R32182",
            "text": "Appropriate evolutionary algorithm for scheduling in FMS the diffusion of flexible manufacturing systems (fms) has not only invigorated production systems, but has also given considerable impetus to relevant analytical fields like scheduling theory and adaptive controls. depending on the demand of the job there can be variation in batch size. the change in the jobs depends upon the renewal rate. but this does not involve much change in the fms setup. this paper obtains an optimal schedule of operations to minimize the total processing time in a modular fms. the fms setup considered here consists of four numbers of machines to accomplish the desired machining operations. the scheduling deals with optimizing the cost function in terms of machining time. the powers evolutionary algorithms, like genetic algorithm (ga) and simulated annealing (sa), can be beneficially utilized for optimization of scheduling fms. the present work utilizes these powerful approaches and finds out their appropriateness for planning and scheduling of fms producing variety of parts in batch mode.",
            "contribution_ids": [
                "R32183"
            ]
        },
        {
            "instance_id": "R32189xR32073",
            "comparison_id": "R32189",
            "paper_id": "R32073",
            "text": "A Genetics-based hybrid scheduler for generating static schedules in flexible manufacturing contexts \"existing computerized systems that support scheduling decisions for flexible manufacturing systems (fms's) rely largely on knowledge acquired through rote learning for schedule generation. in a few instances, the systems also possess some ability to learn using deduction or supervised induction. we introduce a novel ai-based system for generating static schedules that makes heavy use of an unsupervised learning module in acquiring significant portions of the requisite problem processing knowledge. this scheduler pursues a hybrid schedule generation strategy wherein it effectively combines knowledge acquired via genetics-based unsupervised induction with rote-learned knowledge in generating high-quality schedules in an efficient manner. through a series of experiments conducted on a randomly generated problem of practical complexity, we show that the hybrid scheduler strategy is viable, promising, and, worthy of more in-depth investigations. >\"",
            "contribution_ids": [
                "R32074"
            ]
        },
        {
            "instance_id": "R32189xR32108",
            "comparison_id": "R32189",
            "paper_id": "R32108",
            "text": "An enhanced MPS solution for FMS using GAs presents the master production scheduling (mps) problem of a flexible manufacturing system (fms). earliness/tardiness production scheduling and planning (etpsp) is one of the solutions used to integrate mrp and jit effectively. previous researches on etpsp have only applied to problems of single/parallel machines with earliness and tardiness penalties on a common due date and capacity. proposes a revised etpsp for the purpose of developing an mps that can fit into the fms environment where a multiple machine capacity on multi\u2010processes and batch sizes is included. outlines the application of an enhanced etpsp method using a genetic algorithm (ga) solution to solve a multi\u2010product fms production problem. shows that the use of the improved etpsp model can represent a real life fms environment and that a solution can be effectively and efficiently obtained using the ga approach.",
            "contribution_ids": [
                "R32109"
            ]
        },
        {
            "instance_id": "R32189xR32133",
            "comparison_id": "R32189",
            "paper_id": "R32133",
            "text": "The application of Adaptive Genetic Algorithms in FMS dynamic rescheduling uncertainties in the production process would inevitably result in deviations from the existing schedule in flexible manufacturing systems (fmss). this paper tries to study the problem in an environment with realistic interruptions and a requirement of time-restricted response in rescheduling. in our paper, the rescheduling system is based on the records of a dynamic database (ddb). it is able to reform the up-to-date status of a disturbed system via summarizing the remaining resources and works in process (wips) precisely. by using it as the new initial state, the new schedule is configured smoothly in conjunction with the existing schedule to improve the efficiency of fms at this critical instant. considering both speed and economic benefit, an adaptive genetic algorithm (aga) is proposed for finding the new sub-optimal schedule of a large and complicated job shop fms shortly after the interruption occurred. the aga is designed to prevent the premature convergence and refine the performance of genetic algorithms in re-scheduling. during the aga evolution process, the probabilities of crossover and mutation are varied, depending on both the fitness value and the normalized fitness distances between solutions. with help from ddb, the fms scheduling model and aga, the results obtained in the test examples of rescheduling are quite satisfactory.",
            "contribution_ids": [
                "R32134"
            ]
        },
        {
            "instance_id": "R32189xR32067",
            "comparison_id": "R32189",
            "paper_id": "R32067",
            "text": "Intelligent scheduling for flexible manufacturing systems a scheme for the scheduling of flexible manufacturing systems (fmss) have been developed. it integrates neural networks, parallel monte-carlo simulation, genetic algorithms, and machine learning. modular neural networks are used to generate a small set of attractive plans and schedules from a larger list of such plans and schedules. parallel monte-carlo simulation predicts the impact of each on the future evolution of the manufacturing system. genetic algorithms are utilized to combine attractive alternatives into a single best decision. induction mechanisms are used for learning and simplify the decision process for future performance. the development of a modular neural network architecture for candidate rule selection for a fms cell is investigated. a scheduling example illustrates the scheme capabilities including speed, adaptability, and computational efficiency. >",
            "contribution_ids": [
                "R32068"
            ]
        },
        {
            "instance_id": "R32189xR32171",
            "comparison_id": "R32189",
            "paper_id": "R32171",
            "text": "Due date and cost-based FMS loading, scheduling and tool management in this study, we consider flexible manufacturing system loading, scheduling and tool management problems simultaneously. our aim is to determine relevant tool management decisions, which are machining conditions selection and tool allocation, and to load and schedule parts on non-identical parallel cnc machines. the dual objectives are minimization of the manufacturing cost and total weighted tardiness. the manufacturing cost is comprised of machining and tooling costs (which are affected by machining conditions) and non-machining cost (which is affected by tool replacement decisions). we used both sequential and simultaneous approaches to solve our problem to show the superiority of the simultaneous approach. the proposed heuristics are used in a problem space genetic algorithm in order to generate a series of approximately efficient solutions.",
            "contribution_ids": [
                "R32172"
            ]
        },
        {
            "instance_id": "R32189xR32147",
            "comparison_id": "R32189",
            "paper_id": "R32147",
            "text": "An intelligent integrated scheduling model for flexible manufacturing system this paper deals with the simultaneous scheduling of incoming jobs, machines, and vehicle dispatching in a flexible manufacturing system (fms) having a single device, an automated guided vehicle (agv). the objective is to find an optimal sequence of incoming parts, which will reduce the waiting times due to blocking and starving of resources and deadheading times, resulting in overall minimization of makespan. in this work a genetic algorithm based iterative procedure which accommodates the combinatorial nature of the problem is proposed to approximately solve the integrated scheduling problem. the procedure is evaluated through different benchmark problems and the outcome of the study is encouraging and paves the way for further research in this area.",
            "contribution_ids": [
                "R32148"
            ]
        },
        {
            "instance_id": "R32424xR32277",
            "comparison_id": "R32424",
            "paper_id": "R32277",
            "text": "APPLICATION OF ESSENTIAL OIL OF ARTEMISIA HERBA ALBA AS GREEN CORROSION INHIBITOR FOR STEEL IN 0.5 M H2SO4 essential oil from artemisia herba alba (art) was hydrodistilled and tested as corrosion inhibitor of steel in 0.5 m h 2 so 4 using weight loss measurements and electrochemical polarization methods. results gathered show that this natural oil reduced the corrosion rate by the cathodic action. its inhibition efficiency attains the maximum (74%) at 1 g/l. the inhibition efficiency of arm oil increases with the rise of temperature. the adsorption isotherm of natural product on the steel has been determined. a. herba alba essential oil was obtained by hydrodistillation and its chemical composition oil was investigated by capillary gc and gc/ms. the major components were chrysanthenone (30.6%) and camphor (24.4%).",
            "contribution_ids": [
                "R32278"
            ]
        },
        {
            "instance_id": "R32424xR32197",
            "comparison_id": "R32424",
            "paper_id": "R32197",
            "text": "Chemical Composition of the Essential Oil ofArtemisia herba-albaAsso Grown in Algeria \"abstract the essential oil obtained by hydrodistillation from the aerial parts of artemisia herba-alba asso growing wild in m'sila-algeria, was investigated using both capillary gc and gc/ms techniques. the oil yield was 1.02% based on dry weight. sixty-eight components amounting to 94.7% of the oil were identifed, 33 of them being reported for the frst time in algerian a. herba-alba oil and 21 of these components have not been previously reported in a. herba-alba oils. the oil contained camphor (19.4%), trans-pinocarveol (16.9%), chrysanthenone (15.8%) and \u03b2-thujone (15%) as major components. monoterpenoids are the main components (86.1%), and the irregular monoterpenes fraction represented a 3.1% yield.\"",
            "contribution_ids": [
                "R32198"
            ]
        },
        {
            "instance_id": "R32424xR32350",
            "comparison_id": "R32424",
            "paper_id": "R32350",
            "text": "Essential Oil Composition of Artemisia herba-alba from Southern Tunisia the composition of the essential oil hydrodistilled from the aerial parts of 18 individual artemisia herba-alba asso. plants collected in southern tunisia was determined by gc and gcms analysis. the oil yield varied between 0.68% v/w and 1.93% v/w. one hundred components were identified, 21 of of which are reported for the first time in artemisia herba-alba oil. the oil contained 10 components with percentages higher than 10%. the main components were cineole, thujones, chrysanthenone, camphor, borneol, chrysanthenyl acetate, sabinyl acetate, davana ethers and davanone. twelve samples had monoterpenes as major components, three had sesquiterpenes as major components and the last three samples had approximately the same percentage of monoterpenes and sesquiterpenes. the chemical compositions revealed that ten samples had compositions similar to those of other artemisia herba-alba essential oils analyzed in other countries. the remaining eight samples had an original chemical composition.",
            "contribution_ids": [
                "R32351"
            ]
        },
        {
            "instance_id": "R32424xR32413",
            "comparison_id": "R32424",
            "paper_id": "R32413",
            "text": "Chemical composition and biological activities of a new essential oil chemotype of Tunisian Artemisia herba alba Asso the aim of the present study was to investigate the chemical composition, antioxidant, angiotensin iconverting enzyme (ace) inhibitory, antibacterial and antifungal activities of the essential oil of artemisia herba alba asso (aha), a traditional medicinal plant widely growing in tunisia. the essential oil from the air dried leaves and flowers of aha were extracted by hydrodistillation and analyzed by gc and gc/ms. more than fifty compounds, out of which 48 were identified. the main chemical class of the oil was represented by oxygenated monoterpenes (50.53%). these were represented by 21 derivatives, among which the cis -chrysantenyl acetate (10.60%), the sabinyl acetate (9.13%) and the \u03b1-thujone (8.73%) were the principal compounds. oxygenated sesquiterpenes, particularly arbusculones were identified in the essential oil at relatively high rates. the aha essential oil was found to have an interesting antioxidant activity as evaluated by the 2,2-diphenyl-1-picrylhydrazyl and the \u03b2-carotene bleaching methods. the aha essential oil also exhibited an inhibitory activity towards the ace. the antimicrobial activities of aha essential oil was evaluated against six bacterial strains and three fungal strains by the agar diffusion method and by determining the inhibition zone. the inhibition zones were in the range of 8-51 mm. the essential oil exhibited a strong growth inhibitory activity on all the studied fungi. our findings demonstrated that aha growing wild in south-western of tunisia seems to be a new chemotype and its essential oil might be a natural potential source for food preservation and for further investigation by developing new bioactive substances.",
            "contribution_ids": [
                "R32414"
            ]
        },
        {
            "instance_id": "R32424xR32361",
            "comparison_id": "R32424",
            "paper_id": "R32361",
            "text": "Influence of drying time and process on Artemisia herba-alba Asso essential oil yield and composition abstract the essential oil content of artemisia herba-alba asso decreased along the drying period from 2.5 % to 1.8 %. conversely, the composition of the essential oil was not qualitatively affected by the drying process. the same principle components were found in all essential analyzed such as \u03b1-thujone (13.0 \u2013 22.7 %), \u03b2-thujone (18.0 \u2013 25.0 %), camphor (8.6 - 13 %), 1,8-cineole (7.1 \u2013 9.4 %), chrysanthenone (6.7 \u2013 10.9 %), terpinen-4-ol (3.4 \u2013 4.7 %). quantitatively, during the air-drying process, the content of some components decreased slightly such as \u03b1-thujone (from 22.7 to 15.9 %) and 1,8-cineole (from 9.4 to 7.1 %), while the amount of other compounds increased such as chrysanthenone (from 6.7 to 10.9 %), borneol (from 0.8 to 1.5 %), germacrene-d (from 1.0 to 2.4 %) and spathulenol (from 0.8 to 1.5 %). the chemical composition of the oil was more affected by oven-drying the plant material at 35\u00b0c. \u03b1-thujone and \u03b2-thujone decreased to 13.0 %and 18.0 %respectively, while the percentage of camphor, germacrene-d and spathulenol increased to 13.0 %, 5.5 %and 3.7 %, respectively.",
            "contribution_ids": [
                "R32362"
            ]
        },
        {
            "instance_id": "R32424xR32268",
            "comparison_id": "R32424",
            "paper_id": "R32268",
            "text": "Composition of the Essential Oil fromArtemisia herba-albaGrown in Jordan abstract the composition of the essential oil hydrodistilled from the aerial parts of artemisia herba-alba asso. growing in jordan was determined by gc and gc/ms. the oil yield was 1.3% (v/w) from dried tops (leaves, stems and fowers). forty components corresponding to 95.3% of the oil were identifed, of which oxygenated monoterpenes were the main oil fraction (39.3% of the oil), with \u03b1- and \u03b2-thujones as the principal components (24.7%). the other major identifed components were: santolina alcohol (13.0%), artemisia ketone (12.4%), trans-sabinyl acetate (5.4%), germacrene d (4.6%), \u03b1-eudesmol (4.2%) and caryophyllene acetate (5.7%). the high oil yield and the substantial levels of potentially active components, in particular thujones and santolina alcohol, in the oil of this jordanian species make the plant and the oil thereof promising candidates as natural herbal constituents of antimicrobial drug combinations.",
            "contribution_ids": [
                "R32269"
            ]
        },
        {
            "instance_id": "R32424xR32330",
            "comparison_id": "R32424",
            "paper_id": "R32330",
            "text": "Chemical composition, mutagenic and antimutagenic activities of essential oils from (Tunisian) Artemisia campestris and Artemisia herba-alba abstract the essential oil composition from the aerial parts of artemisia campestris var. glutinosa gay ex bess and artemisia herba-alba asso (asteraceae) of tunisian origin has been studied by gc and gc/ms. the main constituents of the oil from a. campestris collected in benguerdane (south of tunisia) were found to be \u03b2-pinene (41.0%), p-cymene (9.9%), \u03b1-terpinene (7.9%), limonene (6.5%), myrcene (4.1%), \u03b2-phellandrene (3.4%) and a-pinene (3.2%). whereas the oil from a. herba-alba collected in tataouine (south of tunisia) showed, pinocarvone (38.3%), a-copaene (12.18%), limonene (11.0%), isoamyl2-methylbutyrate (19.5%) as major compounds. the mutagenic and antimutagenic activities of the two oils were investigated by the salmonella typhimurium/microsome assay, with and without addition of an extrinsic metabolic activation system. the oils showed no mutagenicity when tested with salmonella typhimurium strains ta98 and ta97. on the other hand, we showed that each oil had antimutagenic activity against the carcinogen benzo (a) pyrene (b[a] p) when tested with ta97 and ta98 assay systems.",
            "contribution_ids": [
                "R32331"
            ]
        },
        {
            "instance_id": "R32424xR32293",
            "comparison_id": "R32424",
            "paper_id": "R32293",
            "text": "Chemical composition and antiproliferative activity of essential oil from aerial parts of a medicinal herb Artemisia herba-alba \"artemisia herba-alba asso., asteraceae, is widely used in morrocan folk medicine for the treatment of different health disorders. however, no scientific or medical studies were carried out to assess the cytotoxicity of a. herba-alba essential oil against cancer cell lines. in this study, eighteen volatile compounds were identified by gc-ms analysis of the essential oil obtained from the plant's aerial parts. the main volatile constituent in a. herba-alba was found to be a monoterpene, verbenol, contributing to about 22% of the total volatile components. the essential oil showed significant antiproliferative activity against the acute lymphoblastic leukaemia (cem) cell line, with 3 \u00b5g/ml as ic50 value. the anticancer bioactivity of moroccan a. herba-alba essential oil is described here for the first time.\"",
            "contribution_ids": [
                "R32294"
            ]
        },
        {
            "instance_id": "R32424xR32407",
            "comparison_id": "R32424",
            "paper_id": "R32407",
            "text": "Chemical Variability ofArtemisia herba-albaAsso Growing Wild in Semi-arid and Arid Land (Tunisia) abstract twenty-six oil samples were isolated by hydrodistillation from aerial parts of artemisia herba-alba asso growing wild in tunisia (semi-arid land) and their chemical composition was determined by gc(ri), gc/ms and 13c-nmr. various compositions were observed, dominated either by a single component (\u03b1-thujone, camphor, chrysanthenone or trans-sabinyl acetate) or characterized by the occurrence, at appreciable contents, of two or more of these compounds. these results confrmed the tremendous chemical variability of a. herba-alba.",
            "contribution_ids": [
                "R32408"
            ]
        },
        {
            "instance_id": "R32424xR32377",
            "comparison_id": "R32424",
            "paper_id": "R32377",
            "text": "IMPACT OF SEASON AND HARVEST FREQUENCY ON BIOMASS AND ESSENTIAL OIL YIELDS OF ARTEMISIA HERBA-ALBA CULTIVATED IN SOUTHERN TUNISIA summary artemisia herba-alba asso has been successfully cultivated in the tunisian arid zone. however, information regarding the effects of the harvest frequency on its biomass and essential oil yields is very limited. in this study, the effects of three different frequencies of harvesting the upper half of the a. herba-alba plant tuft were compared. the harvest treatments were: harvesting the same individual plants at the flowering stage annually; harvesting the same individual plants at the full vegetative growth stage annually and harvesting the same individual plants every six months. statistical analyses indicated that all properties studied were affected by the harvest frequency. essential oil yield, depended both on the dry biomass and its essential oil content, and was significantly higher from plants harvested annually at the flowering stage than the other two treatments. the composition of the \u03b2- and \u03b1-thujone-rich oils did not vary throughout the experimental period.",
            "contribution_ids": [
                "R32378"
            ]
        },
        {
            "instance_id": "R32424xR32422",
            "comparison_id": "R32424",
            "paper_id": "R32422",
            "text": "Chemical constituents and antioxidant activity of the essential oil from aerial parts of Artemisia herba-alba grown in Tunisian semi-arid region essential oils and their components are becoming increasingly popular as naturally occurring antioxidant agents. in this work, the composition of essential oil in artemisia herba-alba from southwest tunisia, obtained by hydrodistillation was determined by gc/ms. eighteen compounds were identified with the main constituents namely, \u03b1-thujone (24.88%), germacrene d (14.48%), camphor (10.81%), 1,8-cineole (8.91%) and \u03b2-thujone (8.32%). the oil was screened for its antioxidant activity with 2,2-diphenyl-1-picrylhydrazyl (dpph) radical scavenging, \u03b2-carotene bleaching and reducing power assays. the essential oil of a. herba-alba exhibited a good antioxidant activity with all assays with dose dependent manner and can be attributed to its presence in the oil. key words: artemisia herba alba, essential oil, chemical composition, antioxidant activity.",
            "contribution_ids": [
                "R32423"
            ]
        },
        {
            "instance_id": "R32424xR32215",
            "comparison_id": "R32424",
            "paper_id": "R32215",
            "text": "Chemical composi- tion of Algerian Artemisia herba-alba essential oils isolated by microwave and hydrodistillation abstract isolation of the essential oil from artemisia herba-alba collected in the north sahara desert has been conducted by hydrodistillation (hd) and a microwave distillation process (md). the chemical composition of the two oils was investigated by gc and gc/ms. in total, 94 constituents were identified. the main components were camphor (49.3 and 48.1% in hd and md oils, respectively), 1,8-cineole (13.4\u201312.4%), borneol (7.3\u20137.1%), pinocarvone (5.6\u20135.5%), camphene (4.9\u20134.5%) and chrysanthenone (3.2\u20133.3%). in comparison with hd, md allows one to obtain an oil in a very short time, with similar yields, comparable qualities and a substantial savings of energy.",
            "contribution_ids": [
                "R32216",
                "R32219"
            ]
        },
        {
            "instance_id": "R32541xR32524",
            "comparison_id": "R32541",
            "paper_id": "R32524",
            "text": "The Impact of Surplus Schooling on Productivity and Earnings \"this article examines the impact of surplus schooling on individual productivity and earnings. it proposes a model that divides workers' education into two components: education that is required and thus fully utilized in the job, and education that exceeds the amount required and thus may be underutilized in the job. the model is tested with data from the 1969, 1973, and 1977 quality of working life surveys (quinn and staines 1979). required schooling for each occupation is derived from estimates by job incumbents and by the dictionary of occupational titles. the results show that surplus or underutilized education is rewarded at a lower rate than required education, with the actual return dependent on the type of job.\"",
            "contribution_ids": [
                "R32525"
            ]
        },
        {
            "instance_id": "R32541xR32446",
            "comparison_id": "R32541",
            "paper_id": "R32446",
            "text": "\u00c2\u00abOvereducation, Undereducation, and the Theory of Career Mobility the theory of career mobility (sicherman and galor, journal of political economy, 98(1), 169\u201392, 1990) claims that wage penalties for overeducated workers are compensated by better promotion prospects. sicherman (journal of labour economics, 9(2), 101\u201322, 1991) was able to confirm this theory in an empirical study using panel data. however, the only retest using panel data so far (robst, eastern economic journal, 21, 539\u201350, 1995) produced rather ambiguous results. in the present paper, random effects models to analyse relative wage growth are estimated using data from the german socio-economic panel. it is found that overeducated workers in germany have markedly lower relative wage growth rates than adequately educated workers. the results cast serious doubt on whether the career mobility model is able to explain overeducation in germany. the plausibility of the results is supported by the finding that overeducated workers have less access to formal and informal on-the-job training, which is usually found to be positively correlated with wage growth even when controlling for selectivity effects (pischke, journal of population economics, 14, 523\u201348, 2001).",
            "contribution_ids": [
                "R32447"
            ]
        },
        {
            "instance_id": "R32541xR32451",
            "comparison_id": "R32541",
            "paper_id": "R32451",
            "text": "The Social and Political Consequences of Overeducation this study employs national survey data to estimate the extent of overeducation in the u.s. labor force and its impact on a variety of worker attitudes. estimates are made of the extent of overeducation and its distribution among different categories of workers, according to sex, race, age, and class background. the effects of overeducation are examined in four areas of worker attitudes: job satisfaction, political leftism, political alienation, and stratification ideology. evidence is found of significant effects of overeducation on job satisfaction and several aspects of stratification ideology. the magnitude of these effects is small, however, and they are concentrated almost exclusively among very highly overeducated workers. no evidence is found of generalized political effects of overeducation, either in the form of increased political leftism or in the form of increased political alienation. these findings fail to support the common prediction of major political repercussions of overeducation and suggest the likelihood of alternative forms of adaptation among overeducated workers.",
            "contribution_ids": [
                "R32452"
            ]
        },
        {
            "instance_id": "R32541xR32427",
            "comparison_id": "R32541",
            "paper_id": "R32427",
            "text": "Unemployment Persistency, Over-education and the Employment Chances of the Less Educated the research question addressed in this article concerns whether unemployment persistency can be regarded as a phenomenon that increases employment difficulties for the less educated and, if so, whether their employment chances are reduced by an overly rapid reduction in the number of jobs with low educational requirements. the empirical case is sweden and the data covers the period 1976-2000. the empirical analyses point towards a negative response to both questions. first, it is shown that jobs with low educational requirements have declined but still constitute a substantial share of all jobs. secondly, educational attainment has changed at a faster rate than the job structure with increasing over-education in jobs with low educational requirements as a result. this, together with changed selection patterns into the low education group, are the main reasons for the poor employment chances of the less educated in periods with low general demand for labour.",
            "contribution_ids": [
                "R32428"
            ]
        },
        {
            "instance_id": "R32541xR32526",
            "comparison_id": "R32541",
            "paper_id": "R32526",
            "text": "A Theory of Career Mobility \"this paper analyzes theoretically and empirically the role and significance of occupational mobility in the labor market focusing on individuals' careers. it provides additional dimensions to the analysis of investment in human capital, wage differences across individuals, and the relationships among promotions, quits, and interfirm occupational mobility. it is shown that part of the returns to education is in the form of higher probabilities of occupational upgrading, within or across firms. given an origin occupation, schooling increases the likelihood of occupational upgrading. furthermore, workers who are not promoted despite a high probability of promotion are more likely to quit.\"",
            "contribution_ids": [
                "R32527"
            ]
        },
        {
            "instance_id": "R32541xR32480",
            "comparison_id": "R32541",
            "paper_id": "R32480",
            "text": "\u00c2\u00abIs There a Genuine Under-utilization of Skills Amongst the Over- qualified? two theories of over-qualification are considered, namely mismatch, whereby workers do not find the most appropriate jobs for their skills, because of imperfect information or labour market rigidities, and \u2018heterogeneous workers\u2019, whereby individuals with the same qualifications have different actual skill levels, so that they can be over-qualified in terms of formal qualifications, while their skills are actually appropriate for the jobs that they do. the evidence suggests that both theories are relevant in certain situations.",
            "contribution_ids": [
                "R32481",
                "R32482"
            ]
        },
        {
            "instance_id": "R32541xR32494",
            "comparison_id": "R32541",
            "paper_id": "R32494",
            "text": "Overeducation and Skill Mismatch \"past research has operationalized the notions of overeducation, overtraining, occupational mismatch, and the like in terms of the deviation of a worker's attained schooling from the estimated mean or required schooling of the worker's occupation\"",
            "contribution_ids": [
                "R32495"
            ]
        },
        {
            "instance_id": "R32541xR32489",
            "comparison_id": "R32541",
            "paper_id": "R32489",
            "text": "The incidence of, and returns to overeducation in the UK the 1991 wave of the british household panel survey is used to examine the extent of, and the returns to overeducation in the uk. about 11% of the workers are overeducated, while another 9% are undereducated for their job. the results show that the allocation of female workers is more efficient than the allocation of males. the probability of being overeducated decreases with work experience, but increases with tenure. overeducated workers earn less, while undereducated workers earn more than correctly allocated workers. both the hypothesis that productivity is fully embodied and the hypothesis that productivity is completely job determined are rejected by the data. it is found that there are substantial wage gains obtainable from a more efficient allocation of skills over jobs.",
            "contribution_ids": [
                "R32490"
            ]
        },
        {
            "instance_id": "R32541xR32505",
            "comparison_id": "R32541",
            "paper_id": "R32505",
            "text": "Gender Differences in Overeducation: A Test of the Theory of Differential Overqualification there is little question that substantial labormarket differences exist between men and women. among the most researched difference is the male-female wage gap. many different theories are used to explain why men earn more than women. one possible reason is based on the limited geographic mobility of married women (robert frank, 1978). family mobility is a joint decision in which the needs of the husband and wife are balanced to maximize family welfare. job-motivated relocations are generally made to benefit the primary earner in the family. this leads to a constrained job search for the secondary earner, as he or she must search for a job in a limited geographic area. since the husband is still the primary wage earner in many families, the job search of the wife may suffer. individuals who are tied to a certain area are labeled \"tied-stayers,\" while secondary earners who move for the benefit of the family are labeled \"tied-movers\" (jacob mincer, 1978). the wages of a tied-stayer or tied-mover may not be substantially lower if the family lives in or moves to a large city. if a large labor market has more vacancies, the wife may locate a wage offer near the maximum she would find with a nationwide job search. however, being a tied-stayer or tied-mover can lower the wife\\'s wage if the family lives in or moves to a small community. a small labor market will reduce the likelihood of her finding a job that utilizes her skills. as a result she may accept a job for which she is overqualified and thus earn a lower wage.\\' this hypothesized relationship between the likelihood of being overqualified and smsa size is termed \"differential overqualification.\" frank ( 1978) and haim ofek and yesook merrill (1994) provide support for the theory of differential overqualification by finding that the malefemale wage gap is greater in smaller smsa\\'s. while the results are consistent with the existence of differential overqualification, they may also result from other situations as well. firms in small labor markets may use their monopsony power to keep wages down.2 local demand shocks are found to be a major source of wage variation both across and within local labor markets (robert topel, 1986). since large labor markets are generally more diversified, a demand shock can have a substantial impact on immobile workers in small labor markets. another reason for examining differential overqualification involves the assumption that there are more vacancies in large labor markets. while there is little doubt that more vacancies exist in large labor markets, there are also likely to be more people searching for jobs in large labor markets. if the greater number of vacancies is offset by the larger number of searchers, it is unclear whether women will be more likely to be overqualified in small labor markets. instead of relying on wages to determine if differential overqualification exists, we consider an explicit form of overqualification based on education.",
            "contribution_ids": [
                "R32506"
            ]
        },
        {
            "instance_id": "R32541xR32433",
            "comparison_id": "R32541",
            "paper_id": "R32433",
            "text": "Educational Mismatches vs. Skill Mismatches: Effects of Wages, Job Satisfaction and On-the-job Search education-job mismatches are reported to have serious effects on wages and other labour market outcomes. such results are often cited in support of assignment theory, but can also be explained by institutional and human capital models. to test the assignment explanation, we examine the relation between educational mismatches and skill mismatches. in line with earlier research, educational mismatches affect wages strongly. contrary to the assumptions of assignment theory, this effect is not explained by skill mismatches. conversely, skill mismatches are much better predictors of job satisfaction and on-the-job search than are educational mismatches. copyright 2001 by oxford university press.",
            "contribution_ids": [
                "R32434"
            ]
        },
        {
            "instance_id": "R32541xR32429",
            "comparison_id": "R32541",
            "paper_id": "R32429",
            "text": "\u00c2\u00abMismatch in the Spanish Labor Market. Overeducation?\u00c2\u00bb the objective of this article is to explain the job match, which is assessed by comparing attained education and job-required education as reported by workers. we frame our empirical work according to the occupational mobility theory. using a cross-section of workers from a representative survey of the spanish labor force, we consider overeducated workers to be those who report that the level of education their jobs require is below the level of education they have attained. our results indicate that overeducated workers have less experience, decreased on-the-job training and higher turnover than other comparable workers. we also observe an improvement in the job match over age and mobility.",
            "contribution_ids": [
                "R32430"
            ]
        },
        {
            "instance_id": "R32541xR32535",
            "comparison_id": "R32541",
            "paper_id": "R32535",
            "text": "The Impact of Surplus Schooling on Worker Productivity \"human capital theory suggests that education enhances worker productivity and is reflected in higher individual earnings. we use data from the 1969 survey of working conditions and the 1973 and 1977 quality of employment surveys, and a model derived from the industrial psychology literature, to test the proposition that workers' education in excess of what their jobs require can have adverse effects on job satisfaction and other correlates of worker productivity. our results support earlier studies that have found surplus schooling has a negative effect on job satisfaction. our findings also indicate that the negative impact of surplus schooling on job satisfaction and turnover is more significant for workers with a higher level of surplus education. finally, the negative effects of surplus schooling appear to change over time.\"",
            "contribution_ids": [
                "R32536"
            ]
        },
        {
            "instance_id": "R32541xR32455",
            "comparison_id": "R32541",
            "paper_id": "R32455",
            "text": "Measuring Over-education previous work on over-education has assumed homogeneity of workers and jobs. relaxing these assumptions, we find that over-educated workers have lower education credentials than matched graduates. among the over-educated graduates we distinguish between the apparently over-educated workers, who have similar unobserved skills as matched graduates, and the genuinely over-educated workers, who have a much lower skill endowment. over-education is associated with a pay penalty of 5%-11% for apparently over-educated workers compared with matched graduates and of 22%-26% for the genuinely over-educated. over-education originates from the lack of skills of graduates. this should be taken into consideration in the current debate on the future of higher education in the uk. copyright the london school of economics and political science 2003.",
            "contribution_ids": [
                "R32456"
            ]
        },
        {
            "instance_id": "R32541xR32444",
            "comparison_id": "R32541",
            "paper_id": "R32444",
            "text": "\u00c2\u00abEducational Mismatch and Labour Mobility of People with Disabilities: The Spanish Case in this paper we analyze the job-matching quality of people with disabilities. we do not find evidence of a greater importance of over-education in this group in comparison to the rest of the population. we find that people with disabilities have a lower probability of being over-educated for a period of 3 or more years, a higher probability of leaving mismatch towards inactivity or marginal employment, a lower probability of leaving mismatch towards a better match, and a higher probability of employment mobility towards inactivity or marginal employment. the empirical analysis is based on spanish data from the european community household panel from 1995 to 2000.",
            "contribution_ids": [
                "R32445"
            ]
        },
        {
            "instance_id": "R32871xR32777",
            "comparison_id": "R32871",
            "paper_id": "R32777",
            "text": "Ship detection from optical satellite images based on visual search mechanism automatic ship detection from high-resolution optical satellite images has attracted great interest in the wide applications of maritime security and traffic control. however, most of the popular methods have much difficulty in extracting targets without false alarms due to the variable appearances of ships and complicated background. in this paper, we propose a ship detection approach based on visual search mechanism to solve this problem. first, salient regions are extracted by a global contrast model fast and easily. second, geometric properties and neighborhood similarity of targets are used for discriminating the ship candidates with ambiguous appearance effectively. furthermore, we utilize the svm algorithm to classify each image as including target(s) or not according to the lbp feature of each ship candidate. extensive experiments validate our proposed scheme outperforms the state-of-the-art methods in terms of detection time and accuracy.",
            "contribution_ids": [
                "R32778"
            ]
        },
        {
            "instance_id": "R32871xR32640",
            "comparison_id": "R32871",
            "paper_id": "R32640",
            "text": "Object recognition in ocean imagery using feature selection and compressive sensing \"ship recognition and classification in electro-optical satellite imagery is a challenging problem with important military applications. the problem is similar to that of face recognition, but with many unique considerations. a ship's appearance can vary dramatically from image to image depending on factors such as lighting condition, sensor angle, and ocean state, and there is often wide variation between ships of the same class. collecting and labeling sufficient training data is another challenge. we consider how appropriate feature selection and description can assist in addressing these challenges. our proposed algorithm for vessel classification combines shape invariant features such as sift with a well known face recognition algorithm from the theory of sparse representation and compressive sensing. we demonstrate improved classification accuracy using invariant features at significant key points instead of random features to represent images. we also discuss how algorithms such as this are currently implemented to detect and classify ships and other objects in ocean imagery.\"",
            "contribution_ids": [
                "R32641"
            ]
        },
        {
            "instance_id": "R32871xR32858",
            "comparison_id": "R32871",
            "paper_id": "R32858",
            "text": "S-CNN-BASED SHIP DETECTION FROM HIGH-RESOLUTION REMOTE SENSING IMAGES abstract. reliable ship detection plays an important role in both military and civil fields. however, it makes the task difficult with high-resolution remote sensing images with complex background and various types of ships with different poses, shapes and scales. related works mostly used gray and shape features to detect ships, which obtain results with poor robustness and efficiency. to detect ships more automatically and robustly, we propose a novel ship detection method based on the convolutional neural networks (cnns), called scnn, fed with specifically designed proposals extracted from the ship model combined with an improved saliency detection method. firstly we creatively propose two ship models, the \u201cv\u201d ship head model and the \u201c||\u201d ship body one, to localize the ship proposals from the line segments extracted from a test image. next, for offshore ships with relatively small sizes, which cannot be efficiently picked out by the ship models due to the lack of reliable line segments, we propose an improved saliency detection method to find these proposals. therefore, these two kinds of ship proposals are fed to the trained cnn for robust and efficient detection. experimental results on a large amount of representative remote sensing images with different kinds of ships with varied poses, shapes and scales demonstrate the efficiency and robustness of our proposed s-cnn-based ship detector.\\n",
            "contribution_ids": [
                "R32859"
            ]
        },
        {
            "instance_id": "R32871xR32739",
            "comparison_id": "R32871",
            "paper_id": "R32739",
            "text": "A new method of inshore ship detection in high-resolution optical remote sensing images ship as an important military target and water transportation, of which the detection has great significance. in the military field, the automatic detection of ships can be used to monitor ship dynamic in the harbor and maritime of enemy, and then analyze the enemy naval power. in civilian field, the automatic detection of ships can be used in monitoring transportation of harbor and illegal behaviors such as illegal fishing, smuggling and pirates, etc. in recent years, research of ship detection is mainly concentrated in three categories: forward-looking infrared images, downward-looking sar image, and optical remote sensing images with sea background. little research has been done into ship detection of optical remote sensing images with harbor background, as the gray-scale and texture features of ships are similar to the coast in high-resolution optical remote sensing images. in this paper, we put forward an effective harbor ship target detection method. first of all, in order to overcome the shortage of the traditional difference method in obtaining histogram valley as the segmentation threshold, we propose an iterative histogram valley segmentation method which separates the harbor and ships from the water quite well. secondly, as landing ships in optical remote sensing images usually lead to discontinuous harbor edges, we use hough transform method to extract harbor edges. first, lines are detected by hough transform. then, lines that have similar slope are connected into a new line, thus we access continuous harbor edges. secondary segmentation on the result of the land-and-sea separation, we eventually get the ships. at last, we calculate the aspect ratio of the rois, thereby remove those targets which are not ship. the experiment results show that our method has good robustness and can tolerate a certain degree of noise and occlusion.",
            "contribution_ids": [
                "R32740"
            ]
        },
        {
            "instance_id": "R32871xR32861",
            "comparison_id": "R32871",
            "paper_id": "R32861",
            "text": "Ship Detection in Spaceborne Optical Image With SVD Networks automatic ship detection on spaceborne optical images is a challenging task, which has attracted wide attention due to its extensive potential applications in maritime security and traffic control. although some optical image ship detection methods have been proposed in recent years, there are still three obstacles in this task: 1) the inference of clouds and strong waves; 2) difficulties in detecting both inshore and offshore ships; and 3) high computational expenses. in this paper, we propose a novel ship detection method called svd networks (svdnet), which is fast, robust, and structurally compact. svdnet is designed based on the recent popular convolutional neural networks and the singular value decompensation algorithm. it provides a simple but efficient way to adaptively learn features from remote sensing images. we evaluate our method on some spaceborne optical images of gaofen-1 and venezuelan remote sensing satellites. the experimental results demonstrate that our method achieves high detection robustness and a desirable time performance in response to all of the above three problems.",
            "contribution_ids": [
                "R32862"
            ]
        },
        {
            "instance_id": "R32871xR32583",
            "comparison_id": "R32871",
            "paper_id": "R32583",
            "text": "Number estimation of small-sized ships in remote sensing image based on cumulative projection curve ship detection is an important stage for the sea- area surveillance and many algorithms have been proposed for dealing with such tasks. nevertheless, most of them are designed for large-sized ships and are not efficient for the small ones. in this paper, we present a novel method based on cumulative projection curve(cpc) to estimate the number of ships of small size. we firstly compute the mahalanobis distance between each pixel of the image and the pixel intensities distribution of water, and then project these mahalanobis distances to their near coastline vertically. the projected one-dimension curve is called cumulative projection curve. by doing this, each ship along the coastline will incur a fluctuating, the ship response, in the cpc. thus, the number of ships can be estimated through the estimation for the number of ship responses in the cpc. this method simplifies the detection problem by converting a two-dimension problem to an one-dimension problem, and its efficiency is illustrated by the experimental results in the paper.",
            "contribution_ids": [
                "R32584"
            ]
        },
        {
            "instance_id": "R32871xR32691",
            "comparison_id": "R32871",
            "paper_id": "R32691",
            "text": "Object Detection in Image with Complex Background abstr act. object detection is the key technology in computer vision, with broad application prospects. object detection has great research value and practical significance as a hot spot of video surveillance in recent years. this paper proposes an algorithm for ship detection in image with complex harbor background. we test the performance of several texture descriptors, and a region growing method based on contrast texture feature is proposed to implement sea-land separation. then, we apply a method combined with adaptive threshold segmentation and shape analysis for offshore ship detection. furthermore, the salient boundary template matching in the sea-land border area is used for docked ship detection. the experimental results show that our algorithm is able to implement ship object detection in complex image with good robustness and real-time performance.",
            "contribution_ids": [
                "R32692"
            ]
        },
        {
            "instance_id": "R32871xR32743",
            "comparison_id": "R32871",
            "paper_id": "R32743",
            "text": "Ship detection from high-resolution imagery based on land masking and cloud filtering \"high resolution satellite images play an important role in target detection application presently. this article focuses on the ship target detection from the high resolution panchromatic images. taking advantage of geographic information such as the coastline vector data provided by noaa medium resolution coastline program, the land region is masked which is a main noise source in ship detection process. after that, the algorithm tries to deal with the cloud noise which appears frequently in the ocean satellite images, which is another reason for false alarm. based on the analysis of cloud noise's feature in frequency domain, we introduce a windowed noise filter to get rid of the cloud noise. with the help of morphological processing algorithms adapted to target detection, we are able to acquire ship targets in fine shapes. in addition, we display the extracted information such as length and width of ship targets in a user-friendly way i.e. a kml file interpreted by google earth.\"",
            "contribution_ids": [
                "R32744"
            ]
        },
        {
            "instance_id": "R32871xR32589",
            "comparison_id": "R32871",
            "paper_id": "R32589",
            "text": "Surveying coastal ship traffic with LANDSAT a semi-automated algorithm was developed to detect ships in landsat 7 images. the algorithm combines multispectral and pattern recognition methods to discriminate ships from ocean clutter. automated processing enables us to process a large number of images and gather a statistical picture of ship traffic patterns. as a test case we applied the algorithm on 54 landsat images in the area of jacksonville, fl, from the period 1999\u20132003. the area and time period are the same as an earlier ship traffic study by ward-geiger et al. using ship reports in the mandatory ship reporting system (msrs). the similarities between the two studies suggest that landsat is a good alternative for surveying nearshore ship traffic.",
            "contribution_ids": [
                "R32590"
            ]
        },
        {
            "instance_id": "R32871xR32608",
            "comparison_id": "R32871",
            "paper_id": "R32608",
            "text": "A complete processing chain for ship detection using optical satellite imagery \"ship detection from remote sensing imagery is a crucial application for maritime security, which includes among others traffic surveillance, protection against illegal fisheries, oil discharge control and sea pollution monitoring. in the framework of a european integrated project global monitoring for environment and security (gmes) security/land and sea integrated monitoring for european security (limes), we developed an operational ship detection algorithm using high spatial resolution optical imagery to complement existing regulations, in particular the fishing control system. the automatic detection model is based on statistical methods, mathematical morphology and other signal-processing techniques such as the wavelet analysis and radon transform. this article presents current progress made on the detection model and describes the prototype designed to classify small targets. the prototype was tested on panchromatic satellite pour l'observation de la terre (spot) 5 imagery taking into account the environmental and fishing context in french guiana. in terms of automatic detection of small ship targets, the proposed algorithm performs well. its advantages are manifold: it is simple and robust, but most of all, it is efficient and fast, which is a crucial point in performance evaluation of advanced ship detection strategies.\"",
            "contribution_ids": [
                "R32609"
            ]
        },
        {
            "instance_id": "R32871xR32804",
            "comparison_id": "R32871",
            "paper_id": "R32804",
            "text": "On-board ship targets detection method based on multi-scale salience enhancement for remote sensing image a on-board ship targets detection method based on multi-scale salience enhancement is proposed. unlike the traditional wavelet filter enhancement methods, the proposed utilizes the wavelet decomposition to obtain the high-low frequency parts, and estimate the salience feature with both parts, which enhance the ship targets efficiently. first, decompose the remote sensing image by 2-d dwt, and obtain the low-frequency part, high-frequency part of horizontal, vertical and diagonal; then, compute the ostu threshold, which is subtracted by the low-frequency coefficients to get the low-frequency salience image; and, the high-frequency parts are used to compose the high-frequency salience image; finally, the high-low parts are fused by addition and normalized to obtain the salience map. the original data of multi sets of remote sensing images are experimented, and the results are compared with the method without the proposed salience enhancement. the proposed shows obvious salience enhancement for the low-resolution, high-noise remote sensing images.",
            "contribution_ids": [
                "R32805"
            ]
        },
        {
            "instance_id": "R32871xR32630",
            "comparison_id": "R32871",
            "paper_id": "R32630",
            "text": "Ship Detection Using Texture Statistics from Optical Satellite Images this paper presents a method for ship detection using texture statistics from optical satellite images. the proposed method focuses on the extraction of ship candidates. first, a structural texture descriptor derived from local multiple patterns is introduced to describe image texture features, and then two statistical histograms are generated by quantizing texture features to describe the texture difference between sea and ships. second, corresponding confidence maps representing the probabilities of ship candidates are created based on back projection of the statistical histograms, and ship candidates are extracted according to the confidence maps. finally, the prior knowledge of ship shapes is employed to remove the false ship candidates. as using texture features, the proposed method is insensitive to different waves, illumination changes, ships with different sizes and bright/dark intensities. experimental results demonstrate the method has good performance in both precision and recall.",
            "contribution_ids": [
                "R32631"
            ]
        },
        {
            "instance_id": "R32871xR32701",
            "comparison_id": "R32871",
            "paper_id": "R32701",
            "text": "A new method for detection of ship docked in harbor in high resolution remote sensing image ship detection using high resolution remote sensing images is a hot research topic in both military and civilian applications. in this paper, a new method for detection of ships docked in a harbor was proposed, in which, harris corner detector combined with local salient region analysis were used to extract the obvious sharp-angled feature related to the fore part of a ship in satellite images. this method can determine the direction of the ship when the ship is detected. the results of experiments on several high resolution remote sensing images verified the effectiveness of the proposed method.",
            "contribution_ids": [
                "R32702"
            ]
        },
        {
            "instance_id": "R32871xR32687",
            "comparison_id": "R32871",
            "paper_id": "R32687",
            "text": "Maritime situation awareness capabilities from satellite and terrestrial sensor systems maritime situation awareness is supported by a combination of satellite, airborne, and terrestrial sensor systems. this paper presents several solutions to process that sensor data into information that supports operator decisions. examples are vessel detection algorithms based on multispectral image techniques in combination with background subtraction, feature extraction techniques that estimate the vessel length to support vessel classification, and data fusion techniques to combine image based information, detections from coastal radar, and reports from cooperative systems such as (satellite) ais. other processing solutions include persistent tracking techniques that go beyond kinematic tracking, and include environmental information from navigation charts, and if available, elint reports. and finally rule-based and statistical solutions for the behavioural analysis of anomalous vessels. with that, trends and future work will be presented.",
            "contribution_ids": [
                "R32688"
            ]
        },
        {
            "instance_id": "R32871xR32718",
            "comparison_id": "R32871",
            "paper_id": "R32718",
            "text": "A Novel Sea-Land Segmentation Algorithm Based on Local Binary Patterns for Ship Detection ship detection is an important application of optical remote sensing image processing. sea-land segmentation is the key step in ship detection. traditional sea-land segment methods only based on the gray-level information of an image to choose a gray threshold to segment the image; however, it is very difficult to establish a self-adapting mechanism to select a suitable threshold for different images. thus, the segmentation result is greatly influenced by the threshold chosen for sea-land segmentation. in this paper, we are integrating the lbp feature information to propose a novel sea-land segmentation algorithm. moreover, a new ship detection method based on our sea-land segmentation algorithm is proposed for optical remote sensing images. the performance of ship detection is measured in terms of precision and false-alarm-rate. experimental results show that, as compared to minimum error method, the proposed algorithm can decrease the false-alarm-rate from 23.2% to 9.24%. and compared to otsu method, the proposed algorithm improve the precision from 82.9% to 90.2%.",
            "contribution_ids": [
                "R32719"
            ]
        },
        {
            "instance_id": "R32871xR32808",
            "comparison_id": "R32871",
            "paper_id": "R32808",
            "text": "Moving ship detection based on visual saliency for video satellite moving ship detection is an important issue with the development of video satellite. however, it is difficult for the registration of sea scenes imaging with motion camera. in this paper, we propose a new method to detect moving ship by combining optical flow and video attention saliency for video satellite with image registration. video visual attention is a consequence of some saliency features such as optical flow, gabor features, intensity. the model proposed for ship detection mainly includes three stages. firstly, the moving region is estimated based on optical flow with corners. secondly, gabor filter is used for texture features extraction of video images. finally, the above saliency features as several channels are integrated to a quaternion, which can indicate where the ships are located. the experimental results show that the proposed model can effectively extract moving ships in video images without image registration.",
            "contribution_ids": [
                "R32809"
            ]
        },
        {
            "instance_id": "R32871xR32646",
            "comparison_id": "R32871",
            "paper_id": "R32646",
            "text": "An Auto-Adapt Multi-Level Threshold Segmentation Method of Ships Detection in Remote Sensing Images with Complex Sea Surface Background \"a new multi-level threshold segmentation approach proposed for ship detection. this method is designed to detect targets in remote sensing images, especially for which with complex sea surface background image. an experiment over 1104 ship samples and 11600 no-ship samples, those from spot, quickbird, ikonos, landsat, shows that the target detection rate of the new method can be as high as 99.5% and the false alarm rate is low. experiments over images with various content and from different aircraft testify to the new method's robustness.\"",
            "contribution_ids": [
                "R32647"
            ]
        },
        {
            "instance_id": "R32871xR32863",
            "comparison_id": "R32871",
            "paper_id": "R32863",
            "text": "Inshore Ship Detection in Remote Sensing Images via Weighted Pose Voting inshore ship detection from high-resolution satellite images is a useful yet challenging task in remote surveillance and military reconnaissance. it is difficult to detect the inshore ships with high precision because various interferences are present in the harbor scene. an inshore ship detection method based on the weighted voting and rotation\u2013scale-invariant pose is proposed to improve the detection performance. the proposed method defines the rotation angle pose and the scaling factor of the detected ship to detect the ship with different directions and different sizes. for each pixel on the ship template, the possible poses of a detection window are estimated according to all possible pose-related pixels. to improve robustness to the shape-similar distractor and various interferences, the score of the detection window is obtained by designing a pose weighted voting method. moreover, the values of some parameters such as similarity threshold and the weight of \u201cv\u201d are investigated. the experimental results on actual satellite images demonstrate that the proposed method is invariant to rotation and scale and robust in the inshore ship detection. in addition, better detection performance is observed in comparison with the existing inshore ship detection algorithms in terms of precision rate and recall rate. the target pose of the detected ship can also be obtained as a byproduct of the ship detection.",
            "contribution_ids": [
                "R32864"
            ]
        },
        {
            "instance_id": "R32871xR32789",
            "comparison_id": "R32871",
            "paper_id": "R32789",
            "text": "OBIA ship detection with multispectral and SAR images: A simulation for Copernicus security applications every day, ships of different type, size and origin cross the world seas. not only for commerce and transport, but also for illegal activities. in addition to conventional positioning and tracking systems, detection with earth observation satellites is an effective means to monitor human movements across the sea. the european copernicus programme operates towards this goal, through the definition of border and maritime surveillance as one of its main tasks. this paper describes an object based image analysis (obia) workflow developed for ship detection, monitoring and tracking with high-resolution satellite images. here, it has been used to simulated medium-resolution multispectral (ms) and synthetic aperture radar (sar) images representative of the sentinel components of copernicus. first results confirm that the method proposed can be efficiently used by european agencies for monitoring the explosive growth of illegal flows in the mediterranean sea.",
            "contribution_ids": [
                "R32790"
            ]
        },
        {
            "instance_id": "R32871xR32614",
            "comparison_id": "R32871",
            "paper_id": "R32614",
            "text": "Characterization of a Bayesian Ship Detection Method in Optical Satellite Images this letter presents the experimental results obtained for an automatic predetection of small ships (about 5 &times; 5 pixels) in high-resolution optical satellite images. our images are panchromatic spot 5 images, whose resolution is 5 m per pixel. our detection method is based on the bayesian decision theory and does not need any preprocessing. here, we describe the method precisely and the tuning of its two parameters, namely, the size of the analysis window and the threshold used to make a decision. both are fixed from the receiver operating-characteristic curves that we draw from different sets of tests. finally, the overall results of the method are given for a set of images, as close as possible to the operational conditions.",
            "contribution_ids": [
                "R32615"
            ]
        },
        {
            "instance_id": "R32871xR32716",
            "comparison_id": "R32871",
            "paper_id": "R32716",
            "text": "Automatic ship detection for optical satellite images based on visual attention model and LBP reliably ship detection in optical satellite images has a wide application in both military and civil fields. however, the problem is extremely difficult in the complex background, such as waves, clouds, and small islands. aiming at these issues, this paper explores an automatic and robust algorithm based on biologically-inspired visual features, combined with visual attention model with local binary pattern (cvlbp). different from traditional studies, the proposed algorithm is simple, general, and not designed for specific types of images. large-area images are cut into small image chips and analyzed in two complementary ways: sparse saliency using visual attention model and detail signatures using lbp features, thus accordant with sparseness of ship distribution on images. then these features are employed to classify each chip as containing ship target or not, using a support vector machine method. experimental results show the proposed method is insensitive to waves, clouds, and illumination, as well as high precision and low false alarms performance.",
            "contribution_ids": [
                "R32717"
            ]
        },
        {
            "instance_id": "R32871xR32741",
            "comparison_id": "R32871",
            "paper_id": "R32741",
            "text": "A remote sensing ship recognition using random forest in order to detect the marine targets reliably and timely, a novel ship recognition method by using optical remote sensing data based on random forest is presented. first, in the feature extraction part, in addition to the common features, we introduce the visual saliency features of the target.; second, an improved random forest based on mutual information (mirf) is utilized to recognize ships in data from the optical remote sensing system; finally, we compare mirf to classical algorithms. the mirf has accelerated the operation speed of the algorithm and the classification accuracy remains robust. theoretical analysis and experiment results show that the proposed method can achieve high recognition rate; therefore, this approach is feasible and efficient in the marine target recognition.",
            "contribution_ids": [
                "R32742"
            ]
        },
        {
            "instance_id": "R32871xR32573",
            "comparison_id": "R32871",
            "paper_id": "R32573",
            "text": "An Enhanced Spatio-spectral Template for Automatic Small Recreational Vessel Detection this paper examines the performance of a spatiospectral template on ikonos imagery to automatically detect small recreational boats. the spatiospectral template is utilized and then enhanced through the use of a weighted euclidean distance metric adapted from the mahalanobis distance metric. the aim is to assist the canadian coast guard in gathering data on recreational boating for the modeling of search and rescue incidence risk. to test the detection accuracy of the enhanced spatiospectral template, a dataset was created by gathering position and attribute data for 53 recreational vessel targets purposely moored for this research within cadboro bay, british columbia, canada. the cadboro bay study site containing the targets was imaged using ikonos. overall detection accuracy was 77%. targets were broken down into 2 categories: 1) category a-less than 6 m in length, and category b-more than 6 m long. the detection rate for category b targets was 100%, while the detection rate for category a targets was 61%. it is important to note that some category a targets were intentionally selected for their small size to test the detection limits of the enhanced spatiospectral template. the smallest target detected was 2.2 m long and 1.1 m wide. the analysis also revealed that the ability to detect targets between 2.2 and 6 m long was diminished if the target was dark in color.",
            "contribution_ids": [
                "R32574"
            ]
        },
        {
            "instance_id": "R32871xR32752",
            "comparison_id": "R32871",
            "paper_id": "R32752",
            "text": "Unsupervised ship detection based on saliency and S-HOG descriptor from optical satellite images with the development of high-resolution imagery, ship detection in optical satellite images has attracted a lot of research interest because of the broad applications in fishery management, vessel salvage, etc. major challenges for this task include cloud, wave, and wake clutters, and even the variability of ship sizes. in this letter, we propose an unsupervised ship detection method toward overcoming these existing issues. visual saliency, which focuses on highlighting salient signals from scenes, is applied to extract candidate regions followed by a homogeneous filter presented to confirm suspected ship targets with complete profiles. then, a novel descriptor, ship histogram of oriented gradient, which characterizes the gradient symmetry of ship sides, is provided to discriminate real ships. experimental results on numerous panchromatic satellite images demonstrate the good performance of our method compared to state-of-the-art methods.",
            "contribution_ids": [
                "R32753"
            ]
        },
        {
            "instance_id": "R32871xR32677",
            "comparison_id": "R32871",
            "paper_id": "R32677",
            "text": "Segmentation and wake removal of seafaring vessels in optical satellite images this paper aims at the segmentation of seafaring vessels in optical satellite images, which allows an accurate length estimation. in maritime situation awareness, vessel length is an important parameter to classify a vessel. the proposed segmentation system consists of robust foreground-background separation, wake detection and ship-wake separation, simultaneous position and profile clustering and a special module for small vessel segmentation. we compared our system with a baseline implementation on 53 vessels that were observed with geoeye-1. the results show that the relative l1 error in the length estimation is reduced from 3.9 to 0.5, which is an improvement of 87%. we learned that the wake removal is an important element for the accurate segmentation and length estimation of ships.",
            "contribution_ids": [
                "R32678"
            ]
        },
        {
            "instance_id": "R32871xR32649",
            "comparison_id": "R32871",
            "paper_id": "R32649",
            "text": "Ship recognition from high resolution remote sensing imagery aided by spatial relationship target recognition is of great importance for information extraction from high resolution remote sensing image. as an important kind of man-made objects, ship recognition is a key point to many applications, such as vessel monitoring and marine traffic. as spatial relationship is invariant to topology change, a method of ship recognition from high resolution remote sensing imagery aided by spatial relationship is proposed and implemented. the method includes four critical steps: water segmentation, potential ship detection, seed growing and result creation. experiments show that this method is robust to object position, orientation, scale, and intensity, and achieve a high accuracy of ship recognition.",
            "contribution_ids": [
                "R32650"
            ]
        },
        {
            "instance_id": "R32871xR32658",
            "comparison_id": "R32871",
            "paper_id": "R32658",
            "text": "An effective method on ship target detection in remote sensing image of complex background \"this paper presents a method for ship target detecting in complex background. it aims at solving two difficulties in detection. the first one is that the ships docking in-shore cannot be segmented because of its gray level similarity to land, and the second is that the ships linked side by side cannot be easily located as separate correct target. the first one is solved by extracting water region firstly by measure of harbor-template matching. in order to reduce the impact of angle difference which leads to error, we update the template by the corresponding angle calculated recur to line feature. then matching fine with the updated template to extract water region wholly in which the segment is effective. for the second difficulty, the smallest minimum bounding rectangle (smbr) of the segmented areas are obtained by contour tracing, and the areas are projected to the two different directions of its smbr, then the projection curves are acquired. if the ships are linking together, the peak-valley-peak pattern will exist in the projection curve and the valley-point indicates the ships' connection position. then the ships can be separated by cutting the area at connection position along the projection direction. the experiment results verify the efficiency and accuracy of our method.\"",
            "contribution_ids": [
                "R32659"
            ]
        },
        {
            "instance_id": "R32871xR32597",
            "comparison_id": "R32871",
            "paper_id": "R32597",
            "text": "Ship detection and classification in high-resolution remote sensing imagery using shape-driven segmentation method high-resolution remote sensing imagery provides an important data source for ship detection and classification. however, due to shadow effect, noise and low-contrast between objects and background existing in this kind of data, traditional segmentation approaches have much difficulty in separating ship targets from complex sea-surface background. in this paper, we propose a novel coarse-to-fine segmentation strategy for identifying ships in 1-meter resolution imagery. this approach starts from a coarse segmentation by selecting local intensity variance as detection feature to segment ship objects from background. after roughly obtaining the regions containing ship candidates, a shape-driven level-set segmentation is used to extract precise boundary of each object which is good for the following stages such as detection and classification. experimental results show that the proposed approach outperforms other algorithms in terms of recognition accuracy.",
            "contribution_ids": [
                "R32598"
            ]
        },
        {
            "instance_id": "R32871xR32811",
            "comparison_id": "R32871",
            "paper_id": "R32811",
            "text": "Ship detection in high spatial resolution remote sensing image based on improved sea-land segmentation a new method to detect ship target at sea based on improved segmentation algorithm is proposed in this paper, in which the improved segmentation algorithm is applied to precisely segment land and sea. firstly, mean value is replaced instead of average variance value in otsu method in order to improve the adaptability. secondly, mean shift algorithm is performed to separate the original high spatial resolution remote sensing image into several homogeneous regions. at last, the final sea-land segmentation result can be located combined with the regions in preliminary sea-land segmentation result. the proposed segmentation algorithm performs well on the segment between water and land with affluent texture features and background noise, and produces a result that can be well used in shape and context analyses. ships are detected with settled shape characteristics, including width, length and its compactness. mean shift algorithm can smooth the background noise, utilize the wave\u2019s texture features and helps highlight offshore ships. mean shift algorithm is combined with improved otsu threshold method in order to maximizes their advantages. experimental results show that the improved sea-land segmentation algorithm on high spatial resolution remote sensing image with complex texture and background noise performs well in sea-land segmentation, not only enhances the accuracy of land and sea boarder, but also preserves detail characteristic of ships. compared with traditional methods, this method can achieve accuracy over 90 percent. experiments on worldview images show the superior, robustness and precision of the proposed method.",
            "contribution_ids": [
                "R32812"
            ]
        },
        {
            "instance_id": "R32871xR32794",
            "comparison_id": "R32871",
            "paper_id": "R32794",
            "text": "A Direct and Fast Methodology for Ship Recognition in Sentinel-2 Multispectral Imagery the european space agency satellite sentinel-2 provides multispectral images with pixel sizes down to 10 m. this high resolution allows for ship detection and recognition by determining a number of important ship parameters. we are able to show how a ship position, its heading, length and breadth can be determined down to a subpixel resolution. if the ship is moving, its velocity can also be determined from its kelvin waves. the 13 spectrally different visual and infrared images taken using multispectral imagery (msi) are \u201cfingerprints\u201d that allow for the recognition and identification of ships. furthermore, the multispectral image profiles along the ship allow for discrimination between the ship, its turbulent wakes, and the kelvin waves, such that the ship\u2019s length and breadth can be determined more accurately even when sailing. the ship\u2019s parameters are determined by using satellite imagery taken from several ships, which are then compared to known values from the automatic identification system. the agreement is on the order of the pixel resolution or better.",
            "contribution_ids": [
                "R32795"
            ]
        },
        {
            "instance_id": "R32871xR32766",
            "comparison_id": "R32871",
            "paper_id": "R32766",
            "text": "Space shepherd: Search and rescue of illegal immigrants in the mediterranean sea through satellite imagery this paper presents the preliminary results obtained within a research project aimed to assess the feasibility of a system to monitor the immigration flows in the southern mediterranean sea by solely relying on images coming from scientific and commercial satellites, which already operates on a regular basis. \u201cspace shepherd\u201d, a project funded by politecnico di milano, italy, has the ultimate goal of integrating information coming from a number of satellites to 1) monitor remotely the southern mediterranean sea, 2) detect the presence of possible vessels, 3) identify the migrant vessels and keep the authorities informed, 4) track the vessels and issue warnings in case of danger, 5) support the search and rescue operations. the methodology for scheduling image acquisitions is presented, as well as the algorithms for automatic detection of vessels in both optical and sar images. the performances of the system are discussed, and its feasibility is assessed.",
            "contribution_ids": [
                "R32767",
                "R32842"
            ]
        },
        {
            "instance_id": "R32871xR32672",
            "comparison_id": "R32871",
            "paper_id": "R32672",
            "text": "Ship target segmentation and detection in complex optical remote sensing image based on component tree characteristics discrimination under the application background of sea-surface target surveillance based on optical remote sensing image, automatic sea-surface ship target recognition with complicated background is discussed in this paper. the technology this article focused on is divided into two parts, feature classification training and component class discrimination. in the feature classification training process, large numbers of sample images are used for feature selection and classifier determination of ship targets and false targets. component tree characteristics discrimination achieves extraction of suspected target areas from complicated remote sensing image, and their features are entered to fisher for ship target recognition. experimental results show that the method discussed in this paper can deal with complex sea surface environment, and can avoid the interference of cloud cover, sea clutter and islands. the method can effectively achieve ship target recognition in complex sea background.",
            "contribution_ids": [
                "R32673"
            ]
        },
        {
            "instance_id": "R32871xR32723",
            "comparison_id": "R32871",
            "paper_id": "R32723",
            "text": "Ship detection from optical satellite images based on sea surface analysis automatic ship detection in high-resolution optical satellite images with various sea surfaces is a challenging task. in this letter, we propose a novel detection method based on sea surface analysis to solve this problem. the proposed method first analyzes whether the sea surface is homogeneous or not by using two new features. then, a novel linear function combining pixel and region characteristics is employed to select ship candidates. finally, compactness and length-width ratio are adopted to remove false alarms. specifically, based on the sea surface analysis, the proposed method cannot only efficiently block out no-candidate regions to reduce computational time, but also automatically assign weights for candidate selection function to optimize the detection performance. experimental results on real panchromatic satellite images demonstrate the detection accuracy and computational efficiency of the proposed method.",
            "contribution_ids": [
                "R32724"
            ]
        },
        {
            "instance_id": "R32871xR32580",
            "comparison_id": "R32871",
            "paper_id": "R32580",
            "text": "Fully automated procedure for ship detection using optical satellite imagery ship detection from remote sensing imagery is a crucial application for maritime security which includes among others traffic surveillance, protection against illegal fisheries, oil discharge control and sea pollution monitoring. in the framework of a european integrated project gmes-security/limes, we developed an operational ship detection algorithm using high spatial resolution optical imagery to complement existing regulations, in particular the fishing control system. the automatic detection model is based on statistical methods, mathematical morphology and other signal processing techniques such as the wavelet analysis and radon transform. this paper presents current progress made on the detection model and describes the prototype designed to classify small targets. the prototype was tested on panchromatic spot 5 imagery taking into account the environmental and fishing context in french guiana. in terms of automatic detection of small ship targets, the proposed algorithm performs well. its advantages are manifold: it is simple and robust, but most of all, it is efficient and fast, which is a crucial point in performance evaluation of advanced ship detection strategies.",
            "contribution_ids": [
                "R32581"
            ]
        },
        {
            "instance_id": "R32871xR32869",
            "comparison_id": "R32871",
            "paper_id": "R32869",
            "text": "Ship Detection From Optical Satellite Images Based on Saliency Segmentation and Structure-LBP Feature automatic ship detection from optical satellite imagery is a challenging task due to cluttered scenes and variability in ship sizes. this letter proposes a detection algorithm based on saliency segmentation and the local binary pattern (lbp) descriptor combined with ship structure. first, we present a novel saliency segmentation framework with flexible integration of multiple visual cues to extract candidate regions from different sea surfaces. then, simple shape analysis is adopted to eliminate obviously false targets. finally, a structure-lbp feature that characterizes the inherent topology structure of ships is applied to discriminate true ship targets. experimental results on numerous panchromatic satellite images validate that our proposed scheme outperforms other state-of-the-art methods in terms of both detection time and detection accuracy.",
            "contribution_ids": [
                "R32870"
            ]
        },
        {
            "instance_id": "R32871xR32726",
            "comparison_id": "R32871",
            "paper_id": "R32726",
            "text": "Texture-based vessel classifier for electro-optical satellite imagery satellite imagery provides a valuable source of information for maritime surveillance. the vast majority of the research regarding satellite imagery for maritime surveillance focuses on vessel detection and image enhancement, whilst vessel classification remains a largely unexplored research topic. this paper presents a vessel classifier for spaceborne electro-optical imagery based on a feature representative across all satellite imagery, texture. local binary patterns were selected to represent vessels for their high distinctivity and low computational complexity. considering vessels characteristic super-structure, the extracted vessel signatures are sub-divided in three sections bow, middle and stern. a hierarchical decision-level classification is proposed, analysing first each vessel section individually and then combining the results in the second stage. the proposed approach is evaluated with the electro-optical satellite image dataset presented in [1]. experimental results reveal an accuracy of 85.64% across four vessel categories.",
            "contribution_ids": [
                "R32727"
            ]
        },
        {
            "instance_id": "R32871xR32756",
            "comparison_id": "R32871",
            "paper_id": "R32756",
            "text": "Fusing local texture description of saliency map and enhanced global statistics for ship scene detection in this paper, we introduce a new feature representation based on fusing local texture description of saliency map and enhanced global statistics for ship scene detection in very high-resolution remote sensing images in inland, coastal, and oceanic regions. first, two low computational complexity methods are adopted. specifically, the itti attention model is used to extract saliency map, from which local texture histograms are extracted by lbp with uniform pattern. meanwhile, gabor filters with multi-scale and multi-orientation are convolved with the input image to extract gist, means and variances which are used to form the enhanced global statistics. second, sliding window-based detection is applied to obtain local image patches and extract the fusion of local and global features. svm with rbf kernel is then used for training and classification. such detection manner could remove coastal and oceanic regions effectively. moreover, the ship scene region of interest can be detected accurately. experiments on 20 very high-resolution remote sensing images collected by google earth shows that the fusion feature has advantages than lbp, saliency map-based lbp and gist, respectively. furthermore, desirable results can be obtained in the ship scene detection.",
            "contribution_ids": [
                "R32757"
            ]
        },
        {
            "instance_id": "R32871xR32729",
            "comparison_id": "R32871",
            "paper_id": "R32729",
            "text": "Inshore ship detection in high-resolution satellite images: approximation of harbors using sea-land segmentation this paper proposes a novel inshore ship detection method that is based on the approximation of harbour area with piecewise linear line segments. the method heavily depends on a very fine sea-land segmentation, which is realized in two steps in this work. first, an initial mask is generated by thresholding the normalized difference water index (ndwi) using the zero-level of available global elevation data. in the second step, border of the segmentation result is further enhanced via graph-cut algorithm since spectral characteristics of sea close to sea-land border may differ from the ones of deep parts of the sea. the resultant borderline is used for finding line segments that are assumed to represent the man-made harbours. after being merged and eliminated properly, these line segments are used to extract harbour area so that the remaining connected components of the binary mask can be tested for being ship according to their shapes. test results show that the proposed method is capable of detecting different kinds of ships in a variety of sea states.",
            "contribution_ids": [
                "R32730"
            ]
        },
        {
            "instance_id": "R32871xR32854",
            "comparison_id": "R32871",
            "paper_id": "R32854",
            "text": "Coarse-to-fine ship detection using visual saliency fusion and feature encoding for optical satellite images in order to overcome cloud clutters and varied sizes of objects in high-resolution optical satellite images, a novel coarse-to-fine ship detection framework is proposed. initially, a modified saliency fusion algorithm is derived to reduce cloud clutters and extract ship candidates. then, in coarse discrimination stage, candidates are described by introducing shape feature to eliminate regions which are not conform to ship characteristics. in fine discrimination stage, candidates are represented by local descriptor-based feature encoding, and then linear svm is used for discrimination. experiments on 60 images (including 467 objects) collected from microsoft virtual earth demonstrate the effectiveness of the proposed framework. specifically, the fusion of visual saliency achieves 17.07% higher precision and 7.23% higher recall compared with those of individual one. moreover, using local descriptor in fine discrimination makes precision and f-measure further be improved by 7.23% and 1.74%, respectively.",
            "contribution_ids": [
                "R32855"
            ]
        },
        {
            "instance_id": "R32871xR32747",
            "comparison_id": "R32871",
            "paper_id": "R32747",
            "text": "Multi-layer Sparse Coding Based Ship Detection for Remote Sensing Images with the development of remote sensing technology, it becomes possible for the detection and identification of targets from remote sensing images. in this paper, we propose a new method integrating the bottom-up and the top-down mechanisms for the ship detection in high resolution satellite images. we use the multi-layer sparse coding to extract the features of the rs images. then, we get the ship candidate regions by calculating the global saliency map which may have ships in it. deformable part model is used to extract the ship features and latent support vector machine is used for the ship identification. as demonstrated in our experiments, the proposed approach can effectively detect ship in remote sensing images.",
            "contribution_ids": [
                "R32748"
            ]
        },
        {
            "instance_id": "R32871xR32786",
            "comparison_id": "R32871",
            "paper_id": "R32786",
            "text": "SENTINEL-1/2 DATA FOR SHIP TRAFFIC MONITORING ON THE DANUBE RIVER abstract. after a long period of drought, the water level of the danube river has significantly dropped especially on the romanian sector, in july-august 2015. danube reached the lowest water level recorded in the last 12 years, causing the blockage of the ships in the sector located close to zimnicea harbour. the rising sand banks in the navigable channel congested the commercial traffic for a few days with more than 100 ships involved. the monitoring of the decreasing water level and the traffic jam was performed based on sentinel-1 and sentinel-2 free data provided by the european space agency and the european commission within the copernicus programme. specific processing methods (calibration, speckle filtering, geocoding, change detection, image classification, principal component analysis, etc.) were applied in order to generate useful products that the responsible authorities could benefit from. the sentinel data yielded good results for water mask extraction and ships detection. the analysis continued after the closure of the crisis situation when the water reached the nominal level again. the results indicate that sentinel data can be successfully used for ship traffic monitoring, building the foundation of future endeavours for a durable monitoring of the danube river.\\n",
            "contribution_ids": [
                "R32787"
            ]
        },
        {
            "instance_id": "R32871xR32769",
            "comparison_id": "R32871",
            "paper_id": "R32769",
            "text": "Salient target detection in remote sensing image via cellular automata in order to detect salient target in remote sensing images effectively and accurately, this paper propose a target segmentation method based on cellular automata which is usually used as a dynamic evolution model. first, we introduce the background based map to obtain saliency map with the help of a widely used superpixel segmentation method named simple linear iterative clustering. secondly, cellular automata are employed to produce the elementary saliency map. then enhanced saliency map can be obtained by maximum contrast of image patch method. adaptive threshold is calculated to segment the enhanced saliency map. consequently, the salient target detection and segmentation result can be obtained. experiments on optical remote sensing images and synthetic aperture radar (sar) images demonstrate that the proposed algorithm outperforms other methods such as k-means, otsu and region growing method.",
            "contribution_ids": [
                "R32770"
            ]
        },
        {
            "instance_id": "R32871xR32553",
            "comparison_id": "R32871",
            "paper_id": "R32553",
            "text": "Automatic ship detection in satellite multispectral imagery in recent years, very little attention in the literature has been given to the task of automatically detecting shipping vessels in optical satellite imagery. a method for achieving this goal is described for both spot multispectral and landsat thematic mapper data. essentially a task in pattern recognition, the method utilizes masking, filtering, and shape analysis techniques. results showing a high degree of accuracy have been obtained with test data.",
            "contribution_ids": [
                "R32554"
            ]
        },
        {
            "instance_id": "R32871xR32591",
            "comparison_id": "R32871",
            "paper_id": "R32591",
            "text": "Ship detection and recognitionin high-resolution satellite images nowadays, the availability of high-resolution images taken from satellites, like quickbird, orbview, and others, offers the remote sensing community the possibility of monitoring and surveying vast areas of the earth for different purposes, e.g. monitoring forest regions for ecological reasons. a particular application is the use of satellite images to survey the bottom of the seas around the iberian peninsula which is flooded with innumerable treasures that are being plundered by specialized ships. in this paper we present a gis-based application aimed to catalog areas of the sea with archeological interest and to monitor the risk of plundering of ships that stay within such areas during a suspicious period of time.",
            "contribution_ids": [
                "R32592"
            ]
        },
        {
            "instance_id": "R32871xR32816",
            "comparison_id": "R32871",
            "paper_id": "R32816",
            "text": "A multi-scale fractal dimension based onboard ship saliency detection algorithm detection of ship targets in the sea area is an important field in remote sensing image target detection. as the ships and the surrounding areas are very different in texture, that makes it a possible solution to detect the ships using the texture feature. aiming at the detection of ship targets, a novel ship target detection algorithm in a large scene of the optical remote sensing image is proposed in this paper. this algorithm is based on the conspicuity of ship targets of multi-scale fractal dimension feature in the sea background, and then the detection of ship targets is realized by the method of visual saliency model. in this paper, the accuracy of fractal dimension feature of small or medium-sized window by using differential box counting algorithm has been improved. the novel algorithm proposed in this paper is based on the significant difference of natural background and man-made objects in multi-scale fractal dimension feature. then, the conspicuous fractal feature is obtained by using center-surround difference arithmetic operator, in order to highlight the target in the saliency map normalization is need in the final step. on the basis of the saliency map the rapid detection of ship targets in the sea background can be realized. experimental results show that ship targets in the sea background can be detected accurately with this algorithm, and also the false alarm rate has been effectively reduced.",
            "contribution_ids": [
                "R32817"
            ]
        },
        {
            "instance_id": "R32871xR32559",
            "comparison_id": "R32871",
            "paper_id": "R32559",
            "text": "The Potential for Using Very High Spatial Resolution Imagery for Marine Search and Rescue Surveillance abstract recreational boating activities represent one of the highest risk populations in the marine environment. moreover, there is a trend of increased risk exposure by recreational boaters such as those who undertake adventure tourism, sport fishing/hunting, and personal watercraft (pwc) activities. when trying to plan search and rescue activities, there are data deficiencies regarding inventories, activity type, and spatial location of small, recreational boats. this paper examines the current body of research in the application of remote sensing technology in marine search and rescue. the research suggests commercially available very high spatial resolution satellite (vhsr) imagery can be used to detect small recreational vessels using a sub\u2010pixel detection methodology. the sub\u2010pixel detection method utilizes local image statistics based on spatio\u2010spectral considerations. this methodology would have to be adapted for use with vhsr imagery as it was originally used in hyperspectral imaging. further, the authors examine previous research on \u2018target characterization\u2019 which uses a combination of spectral based classification, and context based feature extraction to generate information such as: length, heading, position, and material of construction for target vessels. this technique is based on pixel\u2010based processing used in generic digital image processing and computer vision. finally, a preliminary recreational vessel surveillance system \u2010 called marine recreational vessel reconnaissance (mrv recon) is tested on some modified vhsr imagery.",
            "contribution_ids": [
                "R32560"
            ]
        },
        {
            "instance_id": "R32871xR32665",
            "comparison_id": "R32871",
            "paper_id": "R32665",
            "text": "A novel method of ship detection from spaceborne optical image based on spatial pyramid matching in this paper we propose an automatic ship detection method in high resolution optical satellite images based on neighbor context information. first, a pre-detection of targets gives us candidates. for each candidate, we choose an extended region called candidate with neighborhood which comprises candidate and its neighbor area. second, the patches of candidate with neighborhood are got by a regular grid, and their sift(scale invariant feature transform) features are extracted. then the sift features of training images are clustered with the k-means algorithm to form a codebook of the patches. we quantize the patches of candidate with neighborhood according to this codebook and get the visual word representation. finally by applying spatial pyramid matching, the candidates are classified with svm (support vector machine). experiment results are given for a set of images show that our method has got predominant performance.",
            "contribution_ids": [
                "R32666"
            ]
        },
        {
            "instance_id": "R32871xR32689",
            "comparison_id": "R32871",
            "paper_id": "R32689",
            "text": "Ship detection from optical satellite image using optical flow and saliency this paper present an effective method for ship detection using optical flow and saliency methods from optical satellite images, which can be able to identify more than one ship targets in the complex dynamic sea background and succeeds to reduce the false positive rate compared to traditional methods. in this paper, moving targets in the image are highlighted through the classical optical flow method, and the dynamic waves are restrained by combining the state-of-art saliency method. we make the best of the low-level (size, color, etc.) and high-level (adjacent frames information, etc.) features of image, which can adapt to different dynamic background situation. compared to existing method, experimental results demonstrate the robustness of the proposed method with high performance.",
            "contribution_ids": [
                "R32690"
            ]
        },
        {
            "instance_id": "R32871xR32685",
            "comparison_id": "R32871",
            "paper_id": "R32685",
            "text": "Automatic ship detection from commercial multispectral satellite imagery commercial multispectral satellite sensors spend much of their time over the oceans. nrl has demonstrated an automatic processing system for finding ships at sea using commercially available multispectral data. to distinguish ships from whitecaps and clouds, a water/cloud clutter subspace is estimated and a continuum fusion derived anomaly detection algorithm is applied. this provides a maritime awareness capability with an acceptable detection rate while maintaining a low rate of false alarms. the system also provides a confidence metric, which can be used to further limit the false alarm rate.",
            "contribution_ids": [
                "R32686"
            ]
        },
        {
            "instance_id": "R32871xR32754",
            "comparison_id": "R32871",
            "paper_id": "R32754",
            "text": "In-shore ship extraction from HR optical remote sensing image via salience structure and GIS information in order to solve the problem of in-shore ship extraction from remote sensing image, a novel method for in-shore ship extraction from high resolution (hr) optical remote sensing image is proposed via salience structure feature and gis information. firstly, the berth roi is located in the image with the aid of the prior gis auxiliary information. secondly, the salient corner features at ship bow are extracted from the berth roi precisely. finally, a recursive algorithm concerning the symmetric geometry of the ship target is conducted to discriminate the multi docked in-shore targets into mono in-shore ships. the results of the experiments show that the method proposed in this paper can detect the majority of large and medium scale in-shore ships from the optical remote sensing image, including both the mono and the multi adjacent docked in-shore ship cases.",
            "contribution_ids": [
                "R32755"
            ]
        },
        {
            "instance_id": "R32871xR32660",
            "comparison_id": "R32871",
            "paper_id": "R32660",
            "text": "A visual search inspired computational model for ship detection in optical satellite images in this letter, we propose a novel computational model for automatic ship detection in optical satellite images. the model first selects salient candidate regions across entire detection scene by using a bottom-up visual attention mechanism. then, two complementary types of top-down cues are employed to discriminate the selected ship candidates. specifically, in addition to the detailed appearance analysis of candidates, a neighborhood similarity-based method is further exploited to characterize their local context interactions. furthermore, the framework of our model is designed in a multiscale and hierarchical manner which provides a plausible approximation to a visual search process and reasonably distributes the computational resources. experiments over panchromatic spot5 data prove the effectiveness and computational efficiency of the proposed model.",
            "contribution_ids": [
                "R32661"
            ]
        },
        {
            "instance_id": "R32871xR32867",
            "comparison_id": "R32871",
            "paper_id": "R32867",
            "text": "A Hierarchical Maritime Target Detection Method for Optical Remote Sensing Imagery maritime target detection from optical remote sensing images plays an important role in related military and civil applications and its weakness lies in its compromised performance under complex uncertain conditions. in this paper, a novel hierarchical ship detection method is proposed to overcome this issue. in the ship detection stage, based on entropy information, we construct a combined saliency model with self-adaptive weights to prescreen ship candidates from across the entire maritime domain. to characterize ship targets and further reduce the false alarms, we introduce a novel and practical descriptor based on gradient features, and this descriptor is robust against clutter introduced by heavy clouds, islands, ship wakes as well as variation in target size. furthermore, the proposed method is effective for not only color images but also gray images. the experimental results obtained using real optical remote sensing images have demonstrated that the locations and the number of ships can be determined accurately and that the false alarm rate is greatly decreased. a comprehensive comparison is performed between the proposed method and the state-of-the-art methods, which shows that the proposed method achieves higher accuracy and outperforms all the competing methods. furthermore, the proposed method is robust under various backgrounds of maritime images and has great potential for providing more accurate target detection in engineering applications.",
            "contribution_ids": [
                "R32868"
            ]
        },
        {
            "instance_id": "R32871xR32782",
            "comparison_id": "R32871",
            "paper_id": "R32782",
            "text": "Marine vessel detection comparing GPRS and satellite images for security applications unauthorized and unregistered sea going fishing vessels are being used for criminal activities in the coastal areas. the issue of piracy against merchant ships using illegal fishing vessels poses a significant threat to world shipping. unfortunately counter piracy efforts and maritime security of our own and other nation enforcement often affects the innocent fishermen who conduct the trans-border fishing. hence a proper vessel monitoring system is required to protect the maritime security without tampering the routine fishing activity of the sea going fishermen. this paper discusses about the feasibility of a system for the detection of registered marine fishing vessels comparing the satellite images and gprs signal information. a review on various algorithms for identifying marine boats from satellite images is also conducted in this paper.",
            "contribution_ids": [
                "R32783"
            ]
        },
        {
            "instance_id": "R32871xR32635",
            "comparison_id": "R32871",
            "paper_id": "R32635",
            "text": "Sea object detection using colour and texture classification sea target detection from remote sensing imagery is very important, with a wide array of applications in areas such as fishery management, vessel traffic services, and naval warfare. this paper focuses on the issue of ship detection from spaceborne optical images (sdsoi). although advantages of synthetic aperture radar (sar) result in that most of current ship detection approaches are based on sar images. but disadvantages of sar still exist. such as the limited number of sar sensors, the relatively long revisit cycle, and the relatively lower resolution. to overcome these disadvantages a new classification algorithm using colour and texture is introduced for ship detection. colour information is computationally cheap to learn and process. however in many cases, colour alone does not provide enough information for classification. texture information also can improve classification performance. this algorithm uses both colour and texture features. in this approach for the construction of a hybrid colour-texture space we are using mutual information. feature extraction is done by the co- occurrence matrix with svm (support vectors machine) as a classifier. therefore this algorithm may attain a very good classification rate.",
            "contribution_ids": [
                "R32636"
            ]
        },
        {
            "instance_id": "R32871xR32720",
            "comparison_id": "R32871",
            "paper_id": "R32720",
            "text": "Automatic detection of inshore ships in highresolution remote sensing images using robust invariant generalized Hough transform in this letter, we propose a new detection framework based on robust invariant generalized hough transform (right) to solve the problem of detecting inshore ships in high-resolution remote sensing imagery. the invariant generalized hough transform is an effective shape extraction technique, but it is not adaptive to shape deformation well. in order to improve its adaptability, we use an iterative training method to learn a robust shape model automatically. the model could capture the shape variability of the target contained in the training data set, and every point in the model is equipped with an individual weight according to its importance, which greatly reduces the false-positive rate. through the iteration process, the model performance is gradually improved by extending the shape model with these necessary weighted points. experimental result demonstrates the precision, robustness, and effectiveness of our detection framework based on right.",
            "contribution_ids": [
                "R32721"
            ]
        },
        {
            "instance_id": "R32871xR32704",
            "comparison_id": "R32871",
            "paper_id": "R32704",
            "text": "A unified algorithm for ship detection on optical and SAR spaceborne images synthetic aperture radar (sar) is the most widely used sensor for ship detection from space but optical sensors are increasingly used in addition of these. the combined use of these sensors in an operational framework becomes a major stake of the efficiency of the current systems. it becomes also a source of the increased complexity of these systems. optical and sar signals of a maritime scene have many similarities. these similarities allow us to define a common detection approach presented in this paper. beyond the definition of a single algorithm for both types of data, this study aims to define an algorithm for the detection of vessels of any size in any resolution images. after studying the signatures of vessels, this second goal leads us to define a detection strategy based on multi-scale processes. it has been implemented in a processing chain into two major steps: first targets that are potentially vessels are identified using a discrete wavelet transform (dwt) and constant false alarm rate (cfar) detector. second among these targets, false alarms are rejected using a multi-scale reasoning on the contours of the targets. the definition of this processing chain is made with respect to three constraints: the detection rate should be 100%, the false alarm rate should be as low as possible and finally the processing time must be compatible with operations at sea. the method was developed and tested on the basis of a very large data set containing real images and associated detections. the obtained results validate this approach but with limitations mainly related to the sea state.",
            "contribution_ids": [
                "R32705"
            ]
        },
        {
            "instance_id": "R32871xR32779",
            "comparison_id": "R32871",
            "paper_id": "R32779",
            "text": "Object Detection Based on Sparse Representation and Hough Voting for Optical Remote Sensing Imagery we present a novel method for detecting instances of an object class or specific object in high-spatial-resolution optical remote sensing images. the proposed method integrates sparse representations for local-feature detection into generalized-hough-transform object detection. object parts are detected via class-specific sparse image representations of patches using learned target and background dictionaries, and their co-occurrence is spatially integrated by hough voting, which enables object detection. we aim to efficiently detect target objects using a small set of positive training samples by matching essential object parts with a target dictionary while the residuals are explained by a background dictionary. experimental results show that the proposed method achieves state-of-the-art performance for several examples including object-class detection and specific-object identification.",
            "contribution_ids": [
                "R32780"
            ]
        },
        {
            "instance_id": "R32871xR32619",
            "comparison_id": "R32871",
            "paper_id": "R32619",
            "text": "A Novel Hierarchical Method of Ship Detection from Spaceborne Optical Image Based on Shape and Texture Features \"ship detection from remote sensing imagery is very important, with a wide array of applications in areas such as fishery management, vessel traffic services, and naval warfare. this paper focuses on the issue of ship detection from spaceborne optical images (sdsoi). although advantages of synthetic-aperture radar (sar) result in that most of current ship detection approaches are based on sar images, disadvantages of sar still exist, such as the limited number of sar sensors, the relatively long revisit cycle, and the relatively lower resolution. with the increasing number of and the resulting improvement in continuous coverage of the optical sensors, sdsoi can partly overcome the shortcomings of sar-based approaches and should be investigated to help satisfy the requirements of real-time ship monitoring. in sdsoi, several factors such as clouds, ocean waves, and small islands affect the performance of ship detection. this paper proposes a novel hierarchical complete and operational sdsoi approach based on shape and texture features, which is considered a sequential coarse-to-fine elimination process of false alarms. first, simple shape analysis is adopted to eliminate evident false candidates generated by image segmentation with global and local information and to extract ship candidates with missing alarms as low as possible. second, a novel semisupervised hierarchical classification approach based on various features is presented to distinguish between ships and nonships to remove most false alarms. besides a complete and operational sdsoi approach, the other contributions of our approach include the following three aspects: 1) it classifies ship candidates by using their class probability distributions rather than the direct extracted features; 2) the relevant classes are automatically built by the samples' appearances and their feature attribute in a semisupervised mode; and 3) besides commonly used shape and texture features, a new texture operator, i.e., local multiple patterns, is introduced to enhance the representation ability of the feature set in feature extraction. experimental results of sdsoi on a large image set captured by optical sensors from multiple satellites show that our approach is effective in distinguishing between ships and nonships, and obtains a satisfactory ship detection performance.\"",
            "contribution_ids": [
                "R32620"
            ]
        },
        {
            "instance_id": "R32871xR32843",
            "comparison_id": "R32871",
            "paper_id": "R32843",
            "text": "Multi-class remote sensing object recognition based on discriminative sparse representation the automatic recognition of multi-class objects with various backgrounds is a big challenge in the field of remote sensing (rs) image analysis. in this paper, we propose a novel recognition framework for multi-class rs objects based on the discriminative sparse representation. in this framework, the recognition problem is implemented in two stages. in the first, or discriminative dictionary learning stage, considering the characterization of remote sensing objects, the scale-invariant feature transform descriptor is first combined with an improved bag-of-words model for multi-class objects feature extraction and representation. then, information about each class of training samples is fused into the dictionary learning process; by using the k-singular value decomposition algorithm, a discriminative dictionary can be learned for sparse coding. in the second, or recognition, stage, to improve the computational efficiency, the phase spectrum of a quaternion fourier transform model is applied to the test image to predict a small set of object candidate locations. then, a multi-scale sliding window mechanism is utilized to scan the image over those candidate locations to obtain the object candidates (or objects of interest). subsequently, the sparse coding coefficients of these candidates under the discriminative dictionary are mapped to the discriminative vectors that have a good ability to distinguish different classes of objects. finally, multi-class object recognition can be accomplished by analyzing these vectors. the experimental results show that the proposed work outperforms a number of state-of-the-art methods for multi-class remote sensing object recognition.",
            "contribution_ids": [
                "R32844"
            ]
        },
        {
            "instance_id": "R32871xR32712",
            "comparison_id": "R32871",
            "paper_id": "R32712",
            "text": "Ship extraction and categorization from ASTER VNIR imagery we present a methodology for ship extraction and categorization from relatively low resolution multispectral aster imagery, corresponding to the sea region south east of athens in greece. at a first level, in the radiometrically corrected image, quad tree decomposition and bounding rectangular extraction automatically outline location of objects - possible ships, by statistically evaluating spectral responses throughout the segmented image. subsequently, the object borders within the rectangular regions are extracted, while connected component labelling combined by size and shape filtering allows ship characterization. the ships\u2019 spectral signature is determined in green, red and infrared bands while cluster analysis allows the identification of ship categories on the basis of their size and reflectance. additional pixel- based measures reveal estimated ship orientation, direction, movement, stability and turning. the results are complemented with additional geographic information and inference tools are formed towards the determination of probable ship type and its destination.",
            "contribution_ids": [
                "R32713"
            ]
        },
        {
            "instance_id": "R32871xR32653",
            "comparison_id": "R32871",
            "paper_id": "R32653",
            "text": "An Invariant Generalized Hough Transform Based Method of Inshore Ships Detection na",
            "contribution_ids": [
                "R32654"
            ]
        },
        {
            "instance_id": "R32871xR32791",
            "comparison_id": "R32871",
            "paper_id": "R32791",
            "text": "A NOVEL SHIP DETECTION METHOD FOR LARGE-SCALE OPTICAL SATELLITE IMAGES BASED ON VISUAL LBP FEATURE AND VISUAL ATTENTION MODEL abstract. reliably ship detection in optical satellite images has a wide application in both military and civil fields. however, this problem is very difficult in complex backgrounds, such as waves, clouds, and small islands. aiming at these issues, this paper explores an automatic and robust model for ship detection in large-scale optical satellite images, which relies on detecting statistical signatures of ship targets, in terms of biologically-inspired visual features. this model first selects salient candidate regions across large-scale images by using a mechanism based on biologically-inspired visual features, combined with visual attention model with local binary pattern (cvlbp). different from traditional studies, the proposed algorithm is high-speed and helpful to focus on the suspected ship areas avoiding the separation step of land and sea. largearea images are cut into small image chips and analyzed in two complementary ways: sparse saliency using visual attention model and detail signatures using lbp features, thus accordant with sparseness of ship distribution on images. then these features are employed to classify each chip as containing ship targets or not, using a support vector machine (svm). after getting the suspicious areas, there are still some false alarms such as microwaves and small ribbon clouds, thus simple shape and texture analysis are adopted to distinguish between ships and nonships in suspicious areas. experimental results show the proposed method is insensitive to waves, clouds, illumination and ship size.\\n",
            "contribution_ids": [
                "R32792"
            ]
        },
        {
            "instance_id": "R32871xR32694",
            "comparison_id": "R32871",
            "paper_id": "R32694",
            "text": "NEAR REAL-TIME AUTOMATIC MARINE VESSEL DETECTION ON OPTICAL SATELLITE IMAGES abstract. vessel monitoring and surveillance is important for maritime safety and security, environment protection and border control. ship monitoring systems based on synthetic-aperture radar (sar) satellite images are operational. on sar images the ships made of metal with sharp edges appear as bright dots and edges, therefore they can be well distinguished from the water. since the radar is independent from the sun light and can acquire images also by cloudy weather and rain, it provides a reliable service. vessel detection from spaceborne optical images (vdsoi) can extend the sar based systems by providing more frequent revisit times and overcoming some drawbacks of the sar images (e.g. lower spatial resolution, difficult human interpretation). optical satellite images (osi) can have a higher spatial resolution thus enabling the detection of smaller vessels and enhancing the vessel type classification. the human interpretation of an optical image is also easier than as of sar image. in this paper i present a rapid automatic vessel detection method which uses pattern recognition methods, originally developed in the computer vision field. in the first step i train a binary classifier from image samples of vessels and background. the classifier uses simple features which can be calculated very fast. for the detection the classifier is slided along the image in various directions and scales. the detector has a cascade structure which rejects most of the background in the early stages which leads to faster execution. the detections are grouped together to avoid multiple detections. finally the position, size(i.e. length and width) and heading of the vessels is extracted from the contours of the vessel. the presented method is parallelized, thus it runs fast (in minutes for 16000 \u00d7 16000 pixels image) on a multicore computer, enabling near real-time applications, e.g. one hour from image acquisition to end user.\\n",
            "contribution_ids": [
                "R32695"
            ]
        },
        {
            "instance_id": "R32871xR32674",
            "comparison_id": "R32871",
            "paper_id": "R32674",
            "text": "Multi-evidence fusion recognition of ship targets in sea battlefield's remote sensing images reliably recognizing ship targets in the sea battlefield has become an increasingly pressing need, as the capabilities for image acquisition are growing rapidly. in the research, a modified ship targets fusion recognition model based on the dempster-shafer evidence theory is proposed. the algorithm firstly detects ship targets from the sea battlefield\u2019s remote sensing image. then extracts the multiple image features of these target candidate areas as the evidence to recognize the ship targets. finally, recognizes the ship targets from the image using the dempster-shafer evidence theory based on multiple ship features, and sends the recognition result. experiment show that this method can be used to reliably and effectively recognize targets information in the sea battlefield.",
            "contribution_ids": [
                "R32675"
            ]
        },
        {
            "instance_id": "R32871xR32828",
            "comparison_id": "R32871",
            "paper_id": "R32828",
            "text": "Fusion detection of ship targets in low resolution multi-spectral images aiming at ship detection in multi-spectral images at low resolution, this paper proposes a new method for ship detection based on fusion detection which combines spectral feature with thermal feature. firstly, it selects infrared band instead of visible band image to detect cloud according to size feature. with cloud available, it does segmentation work in thermal infrared image for the removal of cloud pixels. then, the result is mapped to the ir images and cloud masking is completed. next, the fusion of two kinds of images using wavelet transform is adopted. at last, the fused image is used to detect ships and morphological operations are used to discriminate ships. the experiment result on multi-spectral data of landsat 8 shows that the proposed method which is robust against clutter can detect ships effectively.",
            "contribution_ids": [
                "R32829"
            ]
        },
        {
            "instance_id": "R32871xR32760",
            "comparison_id": "R32871",
            "paper_id": "R32760",
            "text": "Combined use of optical imaging satellite data and electronic intelligence satellite data for large scale ship group surveillance we propose a novel framework for large-scale maritime ship group surveillance using spaceborne optical imaging satellite data and electronic intelligence (elint) satellite data. considering that the size of a ship is usually less than the distance between different ships for large-scale maritime surveillance, we treat each ship as a mass point and ship groups are modelled as point sets. motivated by the observation that ship groups performing tactical or strategic operations often have a stable topology and their attributes remain unchanged, we combine both topological features and attributive features within the framework of dempster-shafer (d-s) theory for coherent ship group analysis. our method has been tested using different sets of simulated data and recorded data. experimental results demonstrate our method is robust and efficient for large-scale maritime surveillance.",
            "contribution_ids": [
                "R32761"
            ]
        },
        {
            "instance_id": "R32871xR32575",
            "comparison_id": "R32871",
            "paper_id": "R32575",
            "text": "Enhanced ship detection from overhead imagery \"in the authors' previous work, a sequence of image-processing algorithms was developed that was suitable for detecting and classifying ships from panchromatic quickbird electro-optical satellite imagery. presented in this paper are several new algorithms, which improve the performance and enhance the capabilities of the ship detection software, as well as an overview on how land masking is performed. specifically, this paper describes the new algorithms for enhanced detection including for the reduction of false detects such as glint and clouds. improved cloud detection and filtering algorithms are described as well as several texture classification algorithms are used to characterize the background statistics of the ocean texture. these detection algorithms employ both cloud and glint removal techniques, which we describe. results comparing ship detection with and without these false detect reduction algorithms are provided. these are components of a larger effort to develop a low-cost solution for detecting the presence of ships from readily-available overhead commercial imagery and comparing this information against various open-source ship-registry databases to categorize contacts for follow-on analysis.\"",
            "contribution_ids": [
                "R32576"
            ]
        },
        {
            "instance_id": "R32914xR32897",
            "comparison_id": "R32914",
            "paper_id": "R32897",
            "text": "Municipal Government Financial Reporting: Administrative and Ethical Climate \"this article examines financial disclosure in u.s. cities. it considers factors that affect the level of municipal financial disclosure, in particular the effect of administrative factors. it finds that participation in the government finance officers association certificate of excellence in financial reporting program, and the chief financial officer's familiarity with the activities of the governmental accounting standards board are positively associated with more disclosure. these latter factors are interpreted as measures of professionalism and are furthered by the adoption of municipal codes of ethics which stress openness and responsiveness to stakeholder interests. such general policies are indirectly associated with heightened levels of financial disclosure. financial disclosure is also associated with city size and demands from capital markets.\"",
            "contribution_ids": [
                "R32898"
            ]
        },
        {
            "instance_id": "R32914xR32875",
            "comparison_id": "R32914",
            "paper_id": "R32875",
            "text": "Determinants of web site information by Spanish city councils purpose the purpose of this research is to analyse the web sites of large spanish city councils with the objective of assessing the extent of information disseminated on the internet and determining what factors are affecting the observed levels of information disclosure. design/methodology/approach the study takes as its reference point the existing literature on the examination of the quality of web sites, in particular the provisions of the web quality model (wqm) and the importance of content as a key variable in determining web site quality. in order to quantify the information on city council web sites, a disclosure index has been designed which takes into account the content, navigability and presentation of the web sites. in order to contrast which variables determine the information provided on the web sites, our investigation bases itself on the studies about voluntary disclosure in the public sector, and six lineal regressions models have been performed. findings the empirical evidence obtained reveals low disclosure levels among spanish city council web sites. in spite of this, almost 50 per cent of the city councils have reached the \u201capproved\u201d level and of these, around a quarter obtained good marks. our results show that disclosure levels depend on political competition, public media visibility and the access to technology and educational levels of the citizens. practical implications the strategy of communication on the internet by local spanish authorities is limited in general to an ornamental web presence but one that does not respond efficiently to the requirements of the digital society. during the coming years, local spanish politicians will have to strive to take advantage of the opportunities that the internet offers to increase both the relational and informational capacity of municipal web sites as well as the digital information transparency of their public management. originality/value the internet is a potent channel of communication that is modifying the way in which people access and relate to information and each other. the public sector is not unaware of these changes and is incorporating itself gradually into the new network society. this study systematises the analysis of local administration web sites, showing the lack of digital transparency, and orients politicians in the direction to follow in order to introduce improvements in their electronic relationships with the public.",
            "contribution_ids": [
                "R32876"
            ]
        },
        {
            "instance_id": "R32914xR32877",
            "comparison_id": "R32914",
            "paper_id": "R32877",
            "text": "Communicating performance: the extent and effectiveness of performance reporting by U.S. colleges and universities performance measures have long been a topic of interest in higher education although no consensus on the best way to measure performance has been achieved. this paper examines the extent and effectiveness of service efforts and accomplishment reporting by public and not-for-profit u.s. colleges and universities using survey data provided by the national association of college and university business officers. effectiveness is evaluated using the government accounting standards board (gasb) suggested criteria. regression analysis suggests an association between the extent of disclosure and size, leverage, level of education provided, and regional accreditation agency. private institutions rate themselves as more effective communicators. effectiveness of communication is also associated with the extent of disclosure, level of education provided and accreditation region.",
            "contribution_ids": [
                "R32878"
            ]
        },
        {
            "instance_id": "R32914xR32883",
            "comparison_id": "R32914",
            "paper_id": "R32883",
            "text": "Cultural contexts and governmental digital reporting the way in which public sector entities disseminate information publicly is affected by the degree of transparency adopted, and the construction and management of websites are increasingly essential elements of modern public administration. nonetheless, differences in this process exist among governments worldwide, probably due to different contextual factors. this article examines and discusses the approach of anglo-saxon, south american and continental european central governments to the use of the web as a means of making financial disclosures. to measure the disclosure of governmental financial information on the internet, an index has been defined, taking into consideration the data considered to be relevant for a potential user, gathering the data visiting their websites. the results show that the way different countries use the web for financial disclosure is deeply rooted in and follows from their administrative culture. in conclusion, the continental european and south american governments should improve their digital reporting.",
            "contribution_ids": [
                "R32884"
            ]
        },
        {
            "instance_id": "R32914xR32873",
            "comparison_id": "R32914",
            "paper_id": "R32873",
            "text": "e-Government process and incentives for online public financial information purpose \u2013 the aim of this paper is to examine the extent of financial information made available by public administrations on their web sites and to discover whether this communications policy is influenced by the context in which the public entity operates.design/methodology/approach \u2013 the study took as its reference the prior literature and distinguished three dimensions \u2013 information content, qualitative characteristics of information and accessibility \u2013 which were converted into a disclosure index that was used to assess government web sites. a multivariable linear regression analysis was performed in search of a relationship between seven external factors and the provision of public financial information online.findings \u2013 the empirical research revealed that the sample municipalities were not fully aware of the potential importance of the internet in enabling the achievement of e\u2010democracy initiatives as a tool of new public management. the factors previously found to be important in paper\u2010based repo...",
            "contribution_ids": [
                "R32874"
            ]
        },
        {
            "instance_id": "R32940xR32926",
            "comparison_id": "R32940",
            "paper_id": "R32926",
            "text": "Error in Byline in: Long-term and Perioperative Corticosteroids in Anastomotic Leakage: A Prospective Study of 259 Left-Sided Colorectal Anastomoses prediction model based on the anatomic injury scale. ann surg. 2008;247(6): 1041-1048. 13. van buuren s, boshuizen hc, knook dl. multiple imputation of missing blood pressure covariates in survival analysis. stat med. 1999;18(6):681-694. 14. white h. a heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity. econometrica. 1980;48(4):817-838. 15. davidson gh, hamlat ca, rivara fp, koepsell td, jurkovich gj, arbabi s. longterm survival of adult trauma patients. jama. 2011;305(10):1001-1007. 16. dutton rp, stansbury lg, leone s, kramer e, hess jr, scalea tm. trauma mortality in mature trauma systems: are we doing better? an analysis of trauma mortality patterns, 1997-2008. j trauma. 2010;69(3):620-626. 17. nathens ab, jurkovich gj, cummings p, rivara fp, maier rv. the effect of organized systems of trauma care on motor vehicle crash mortality. jama. 2000; 283(15):1990-1994. 18. mackenzie ej, rivara fp, jurkovich gj, et al. a national evaluation of the effect of trauma-center care on mortality. n engl j med. 2006;354(4):366-378. 19. acute respiratory distress syndrome network. ventilation with lower tidal volumes as compared with traditional tidal volumes for acute lung injury and the acute respiratory distress syndrome. n engl j med. 2000;342(18):1301-1308. 20. moore fa, feliciano dv, andrassy rj, et al. early enteral feeding, compared with parenteral, reduces postoperative septic complications: the results of a meta-analysis. ann surg. 1992;216(2):172-183. 21. rotondo mf, zonies dh. the damage control sequence and underlying logic. surg clin north am. 1997;77(4):761-777. 22. holcomb jb, jenkins d, rhee p, et al. damage control resuscitation: directly addressing the early coagulopathy of trauma. j trauma. 2007;62(2):307-310. 23. nathens ab, jurkovich gj, mackenzie ej, rivara fp. a resource-based assessment of trauma care in the united states. j trauma. 2004;56(1):173-178. 24. hsiary,shenyc.risingclosuresofhospital traumacentersdisproportionatelyburden vulnerable populations. health aff (millwood). 2011;30(10):1912-1920. 25. mullins rj, mann nc, hedges jr, et al. adequacy of hospital discharge status as a measure of outcome among injured patients. jama. 1998;279(21):17271731. 26. shafi s, friese r, gentilello lm. moving beyond personnel and process: a case for incorporating outcome measures in the trauma center designation process. arch surg. 2008;143(2):115-120. 27. glance lg, dick aw, osler tm, meredith w, mukamel db. the association between cost and quality in trauma: is greater spending associated with higherquality care? ann surg. 2010;252(2):217-222. 28. eddy dm, billings j. the quality of medical evidence: implications for quality of care. health aff (millwood). 1988;7(1):19-32. 29. glance lg, dick aw, mukamel db, osler tm. association between trauma quality indicators and outcomes for injured patients. arch surg. 2012;147(4):308315.",
            "contribution_ids": [
                "R32927"
            ]
        },
        {
            "instance_id": "R32940xR32934",
            "comparison_id": "R32940",
            "paper_id": "R32934",
            "text": "Biologic treatment or immunomodulation is not associated with postoperative anastomotic complications in abdominal surgery for Crohn's disease \"abstract objectives. there are concerns that biologic treatments or immunomodulation may negatively influence anastomotic healing. this study investigates the relationship between these treatments and anastomotic complications after surgery for crohn's disease. patients and methods. retrospective study on 417 operations for crohn's disease performed at four danish hospitals in 2000\u20132007. thirty-two patients were preoperatively treated with biologics and 166 were on immunomodulation. in total, 154 were treated with corticosteroids of which 66 had prednisolone 20 mg or more. results. anastomotic complications occurred at 13% of the operations. there were no difference in patients on biologic treatment (9% vs. 12% (p = 0.581)) or in patients on immunomodulation (10% vs. 14% (p = 0.263)). patients on 20 mg prednisolone or more had more anastomotic complications (20% vs. 11% (p = 0.04)). anastomotic complications were more frequent after a colo-colic anastomosis than after an entero-enteric or entero-colic (33% vs. 12% (p = 0.013)). patients with anastomotic complications were older (40 years vs. 35 years (p = 0.014)), had longer disease duration (7.5 years vs. 4 years (p = 0.04)), longer operation time (155 min vs. 115 min (p = 0.018)) and more operative bleeding (200 ml vs. 130 ml (p = 0.029)). multivariate analysis revealed preoperative treatment with prednisolone 20 mg or more, operation time and a colo-colic anastomosis as negative predictors of anastomotic complications. conclusions. preoperative biologic treatment or immunomodulation had no influence on anastomotic complications. the study confirms previous findings of corticosteroids and a colo-colic anastomosis as negative predictors and also that surgical complexity, as expressed by bleeding and operation time, may contribute to anastomotic complications.\"",
            "contribution_ids": [
                "R32935"
            ]
        },
        {
            "instance_id": "R32940xR32938",
            "comparison_id": "R32940",
            "paper_id": "R32938",
            "text": "Factors influencing the outcome of intestinal anastomosis anastomotic leak (al) is one of the most serious complications after gastrointestinal surgery. all patients aged 16 years or older who underwent a surgery with single intestinal anastomosis at morristown medical center from january 2006 to june 2008 were entered into a prospective database. to compare the rate of al, patients were divided into the following surgery-related groups: 1) stapled versus hand-sewn, 2) small bowel versus large bowel, 3) right versus left colon, 4) emergent versus elective, 5) laparoscopic versus converted (laparoscopic to open) versus open, 6) inflammatory bowel disease versus non inflammatory bowel disease, and 7) diverticulitis versus nondiverticulitis. we also looked for surgical site infection, estimated intraoperative blood loss, blood transfusion, comorbidities, preoperative chemotherapy, radiation, and anticoagulation treatment. the overall rate of al was 3.8 per cent. mortality rate was higher among patients with als (13.3%) versus patients with no al (1.7%). open surgery had greater risk of al than laparoscopic operations. surgical site infection and intraoperative blood transfusions were also associated with significantly higher rates of al. operations involving the left colon had greater risk of al when compared with those of the right colon, sigmoid, and rectum. prior chemotherapy, anticoagulation, and intraoperative blood loss all increased the al rates. in conclusion, we identified several significant risk factors for als. this knowledge should help us better understand and prevent this serious complication, which has significant morbidity and mortality rates.",
            "contribution_ids": [
                "R32939"
            ]
        },
        {
            "instance_id": "R33008xR32984",
            "comparison_id": "R33008",
            "paper_id": "R32984",
            "text": "The importance of diagnostic cytogenetics on outcome in AML: analysis of 1,612 patients entered into the MRC AML 10 trial abstract \\n cytogenetics is considered one of the most valuable prognostic determinants in acute myeloid leukemia (aml). however, many studies on which this assertion is based were limited by relatively small sample sizes or varying treatment approach, leading to conflicting data regarding the prognostic implications of specific cytogenetic abnormalities. the medical research council (mrc) aml 10 trial, which included children and adults up to 55 years of age, not only affords the opportunity to determine the independent prognostic significance of pretreatment cytogenetics in the context of large patient groups receiving comparable therapy, but also to address their impact on the outcome of subsequent transplantation procedures performed in first complete remission (cr). on the basis of response to induction treatment, relapse risk, and overall survival, three prognostic groups could be defined by cytogenetic abnormalities detected at presentation in comparison with the outcome of patients with normal karyotype. aml associated with t(8;21), t(15;17) or inv(16) predicted a relatively favorable outcome. whereas in patients lacking these favorable changes, the presence of a complex karyotype, \u22125, del(5q), \u22127, or abnormalities of 3q defined a group with relatively poor prognosis. the remaining group of patients including those with 11q23 abnormalities, +8, +21, +22, del(9q), del(7q) or other miscellaneous structural or numerical defects not encompassed by the favorable or adverse risk groups were found to have an intermediate prognosis. the presence of additional cytogenetic abnormalities did not modify the outcome of patients with favorable cytogenetics. subgroup analysis demonstrated that the three cytogenetically defined prognostic groups retained their predictive value in the context of secondary as well as de novo aml, within the pediatric age group and furthermore were found to be a key determinant of outcome from autologous or allogeneic bone marrow transplantation (bmt) in first cr. this study highlights the importance of diagnostic cytogenetics as an independent prognostic factor in aml, providing the framework for a stratified treatment approach of this disease, which has been adopted in the current mrc aml 12 trial.",
            "contribution_ids": [
                "R32985"
            ]
        },
        {
            "instance_id": "R33008xR32967",
            "comparison_id": "R33008",
            "paper_id": "R32967",
            "text": "Exploring polycythaemia vera with fluorescence in situ hybridization: additional cryptic 9p is the most frequent abnormality detected summary. between 1986 and 2001, 220 patients with polycythaemia vera (pv) were studied using conventional cytogenetics. of 204 evaluable patients, 52 (25\u00b74%) had clonal abnormalities. the recurrent chromosomal rearrangements were those of chromosome 9 (21\u00b71%), del(20q) (19\u00b72%), trisomy 8 (19\u00b72%), rearrangements of 13q (13\u00b74%), abnormalities of 1q (11\u00b75%), and of chromosomes 5 and 7 (9\u00b76%). subsequent analysis of 32 patients, performed at follow\u2010up of up to 14\u00b78\\u2003years, revealed new clonal abnormalities in five patients and the disappearance of an abnormal clone in four. eleven patients remained normal up to 11\u00b75\\u2003years and seven patients maintained an abnormality for over 10\\u2003years. fifty\u2010three patients were studied retrospectively using interphase fluorescence in\\u2003situ hybridization (i\u2010fish), utilizing probes for centromere enumeration of chromosomes 8 and 9, and for 13q14 and 20q12 loci. conventional cytogenetics demonstrated clonal chromosome abnormalities in 23% of these 53 patients. the addition of i\u2010fish increased the detection of abnormalities to 29% and permitted clarification of chromosome 9 rearrangements in an additional 5\u00b76% of patients. fish uncovered rearrangements of chromosome 9 in 53% of patients with an abnormal fish pattern, which represented the most frequent genomic alteration in this series.",
            "contribution_ids": [
                "R32968",
                "R33077"
            ]
        },
        {
            "instance_id": "R33008xR32998",
            "comparison_id": "R33008",
            "paper_id": "R32998",
            "text": "Cytogenetic studies in untreated Hodgkin's disease \" abstract \\n very little data have been published on cytogenetic abnormalities in hodgkin's disease (hd) and their correlation with clinicopathologic features are scanty. we have performed chromosomal analysis of lymph nodes from 60 previously untreated hd patients and obtained analyzable metaphases in 49 patients (82%). chromosomal abnormalities were found in 33 patients (55%) but only 31 karyotypes could be, at least partially, described. twenty-nine cases showed numerical abnormalities that involved all chromosomes with the exception of chromosomes 13 and y, which were gained less frequently and lost more frequently than other chromosomes. structural abnormalities were found in 30 cases, involving all chromosomes except y. chromosomal regions 12p11\u201313, 13p11\u2013 13, 3q26\u201328, 6q15\u201316, and 7q31\u201335 were rearranged in more than 20% of the analyzable cases. no correlation was found between cytogenetic findings and initial characteristics. when compared with diffuse b-cell lymphomas, defects in regions 2p25 (p less than .01), 12p11\u201313 (p less than .01), 13p11\u201313 (p less than .01), 14p11 (p less than .01), 15p11\u2013 13 (p less than .02), and 20q12\u201313 (p less than .05) were more frequent in hd. when compared with t-cell lymphomas, only defects in regions 12p12\u201313 (p less than .01) and 13p11\u201313 (p less than .01) were more frequent in hd. failure to obtain analyzable metaphases was correlated with stage iv of the disease (p less than .05) and with a poor survival (p less than .01), but cytogenetic results showed no other correlation with clinical outcome. we conclude that molecular studies in hd should be focused on the short arms of chromosomes 12 and 13. determination of the clinical significance of cytogenetic findings will require a larger number of patients and a longer follow-up period. \"",
            "contribution_ids": [
                "R32999"
            ]
        },
        {
            "instance_id": "R33008xR32964",
            "comparison_id": "R33008",
            "paper_id": "R32964",
            "text": "Conventional cyto- genetics in myelofibrosis: literature review and discussion the clinical phenotype of myelofibrosis (mf) is recognized either de novo (primary) or in the setting of polycythemia vera (post\u2010pv) or essential thrombocythemia (post\u2010et). approximately one\u2010third of patients with primary mf (pmf) present with cytogenetic abnormalities; the most frequent are del(20q), del(13q), trisomy 8 and 9, and abnormalities of chromosome 1 including duplication 1q. other less frequent lesions include \u22127/del(7q), del(5q), del(12p), +21 and der(6)t(1;6)(q21;p21.3). in general, cytogenetic abnormalities are qualitatively similar among pmf, post\u2010et mf and post\u2010pv mf although their individual frequencies may differ. based on prognostic effect, cytogenetic findings in mf are classified as either \u2018favorable\u2019 or \u2018unfavorable\u2019. the former include normal karyotype or isolated del(20q) or del(13q) and the latter all other abnormalities. unfavorable cytogenetic profile in both pmf and post\u2010pv/et mf confers an independent adverse effect on survival; it is also associated with higher jak2v617f mutational frequency. in addition to their prognostic value, cytogenetic studies in mf ensure diagnostic exclusion of other myeloid neoplasms that are sometimes associated with bone marrow fibrosis (e.g. bcr\u2010abl1\u2010positive or pdgfrb\u2010rearranged) and also assist in specific treatment selection (e.g. lenalidomide therapy is active in mf associated with del(5q).",
            "contribution_ids": [
                "R32965"
            ]
        },
        {
            "instance_id": "R33008xR32987",
            "comparison_id": "R33008",
            "paper_id": "R32987",
            "text": "New insights into the prognostic impact of the karyotype in MDS and correlation with subtypes: evidence from a core dataset of 2124 patients we have generated a large, unique database that includes morphologic, clinical, cytogenetic, and follow-up data from 2124 patients with myelodysplastic syndromes (mdss) at 4 institutions in austria and 4 in germany. cytogenetic analyses were successfully performed in 2072 (97.6%) patients, revealing clonal abnormalities in 1084 (52.3%) patients. numeric and structural chromosomal abnormalities were documented for each patient and subdivided further according to the number of additional abnormalities. thus, 684 different cytogenetic categories were identified. the impact of the karyotype on the natural course of the disease was studied in 1286 patients treated with supportive care only. median survival was 53.4 months for patients with normal karyotypes (n = 612) and 8.7 months for those with complex anomalies (n = 166). a total of 13 rare abnormalities were identified with good (+1/+1q, t(1q), t(7q), del(9q), del(12p), chromosome 15 anomalies, t(17q), monosomy 21, trisomy 21, and \u2212x), intermediate (del(11q), chromosome 19 anomalies), or poor (t(5q)) prognostic impact, respectively. the prognostic relevance of additional abnormalities varied considerably depending on the chromosomes affected. for all world health organization (who) and french-american-british (fab) classification system subtypes, the karyotype provided additional prognostic information. our analyses offer new insights into the prognostic significance of rare chromosomal abnormalities and specific karyotypic combinations in mds.",
            "contribution_ids": [
                "R32988",
                "R33069"
            ]
        },
        {
            "instance_id": "R33008xR33001",
            "comparison_id": "R33008",
            "paper_id": "R33001",
            "text": "Prognos- tic and biologic significance of chromosomal imbalances assessed by comparative genomic hybridization in multiple myeloma abstract \\n cytogenetic abnormalities, evaluated either by karyotype or by fluorescence in situ hybridization (fish), are considered the most important prognostic factor in multiple myeloma (mm). however, there is no information about the prognostic impact of genomic changes detected by comparative genomic hybridization (cgh). we have analyzed the frequency and prognostic impact of genetic changes as detected by cgh and evaluated the relationship between these chromosomal imbalances and igh translocation, analyzed by fish, in 74 patients with newly diagnosed mm. genomic changes were identified in 51 (69%) of the 74 mm patients. the most recurrent abnormalities among the cases with genomic changes were gains on chromosome regions 1q (45%), 5q (24%), 9q (24%), 11q (22%), 15q (22%), 3q (16%), and 7q (14%), while losses mainly involved chromosomes 13 (39%), 16q (18%), 6q (10%), and 8p (10%). remarkably, the 6 patients with gains on 11q had igh translocations. multivariate analysis selected chromosomal losses, 11q gains, age, and type of treatment (conventional chemotherapy vs autologous transplantation) as independent parameters for predicting survival. genomic losses retained the prognostic value irrespective of treatment approach. according to these results, losses of chromosomal material evaluated by cgh represent a powerful prognostic factor in mm patients. (blood. 2004;104:2661-2666)",
            "contribution_ids": [
                "R33002"
            ]
        },
        {
            "instance_id": "R33008xR32972",
            "comparison_id": "R33008",
            "paper_id": "R32972",
            "text": "Cytogenetic abnormalities in essential thrombocythemia: prevalence and prognostic significance objectives:\\u2002 in the current study we describe cytogenetic findings as well as clinical correlates and long\u2010term prognostic relevance of abnormal cytogenetics at the time of diagnosis of essential thrombocythemia (et).",
            "contribution_ids": [
                "R32973"
            ]
        },
        {
            "instance_id": "R33008xR32990",
            "comparison_id": "R33008",
            "paper_id": "R32990",
            "text": "Chromosomal abnormalities in Philadelphia chromosome negative metaphases appearing during imatinib mesylate therapy in patients with newly diagnosed chronic myeloid leukemia in chronic phase abstract \\n the development of chromosomal abnormalities (cas) in the philadelphia chromosome (ph)\u2013negative metaphases during imatinib (im) therapy in patients with newly diagnosed chronic myecloid leukemia (cml) has been reported only anecdotally. we assessed the frequency and significance of this phenomenon among 258 patients with newly diagnosed cml in chronic phase receiving im. after a median follow-up of 37 months, 21 (9%) patients developed 23 cas in ph-negative cells; excluding \u2212y, this incidence was 5%. sixteen (70%) of all cas were observed in 2 or more metaphases. the median time from start of im to the appearance of cas was 18 months. the most common cas were \u2212y and + 8 in 9 and 3 patients, respectively. cas were less frequent in young patients (p = .02) and those treated with high-dose im (p = .03). in all but 3 patients, cas were transient and disappeared after a median of 5 months. one patient developed acute myeloid leukemia (associated with \u2212 7). at last follow-up, 3 patients died from transplantation-related complications, myocardial infarction, and progressive disease and 2 lost cytogenetic response. cas occur in ph-negative cells in a small percentage of patients with newly diagnosed cml treated with im. in rare instances, these could reflect the emergence of a new malignant clone.",
            "contribution_ids": [
                "R32991"
            ]
        },
        {
            "instance_id": "R33008xR32969",
            "comparison_id": "R33008",
            "paper_id": "R32969",
            "text": "Cyto- genetic studies at diagnosis in polycythemia vera: clinical and JAK2V617F allele burden correlates abstract \\n background: previous cytogenetic studies in polycythemia vera (pv) have included a relatively small number of patients (\u201cn\u201d ranging 10\u201364). in the current study (n=137), we describe cytogenetic findings at presentation and examine their relationship to clinical and laboratory features, including bone marrow jak2v617f allele burden. \\n methods: the study consisted of a consecutive group of patients with pv who fulfilled the world health organization (who) diagnostic criteria and in whom bone marrow biopsy and cytogenetic studies were performed at diagnosis. \\n results i: cytogenetic details at diagnosis: a total of 137 patients (median age, 64 years; 49% females) were studied at diagnosis and had adequate metaphases for interpretation. cytogenetics were normal in 117 patients (85%) and displayed either a sole -y abnormality in 5 patients (7% of the male patients), and other chromosomal abnormalities in 15 (11%). the latter included trisomy 8 in five patients, trisomy 9 in three patients, two patients each with del(13q), del(20q), and abnormalities of chromosome 1, and one patient each with del(3)(p13p21), dup(13)(q12q14), and del(11)(q21). at follow-up: repeat cytogenetic studies while still in the chronic phase of the disease were performed in 19 patients at a median of 60 months (range, 8\u2013198) from diagnosis. of these, 4 had aquired new cytogenetic clones including 3 with normal cytogenetics at time of initial pv diagnosis. the new abnormalities included del(20q), del(5q), del(1p), chromosome 1 abnormality, and inv(3)(q21q26.2). at time of disease transformation: leukemic transformation was documented in 3 patients of whom cytogenetic information at the time was available in 2 patients; both patients had normal results at time of initial pv diagnosis and complex cytogenetic abnormalities at time of leukemic transformation. in contrast, among 6 patients with available cytogenetic information at time of fibrotic transformation, the results were unchanged from those obtained at time of diagnosis in 5 patients. ii) correlation between cytogenetics at diagnosis and jak2v617f allele burden: allele-specific, quantitative pcr analysis for jak2v617f was performed in 71 patients using genomic dna from archived bone marrow obtained at the time of the initial cytogenetic studies. jak2v617f mutation was detected in 64 of the 71 (90%) patients; median mutant allele burden was 16% (range 3\u201380%) without significant difference among the different cytogenetic groups: normal vs. \u2013y vs. other cytogenetic abnormalities (p=0.72). iii) clinical correlates and prognostic relevance of cytogenetic findings at diagnosis: among several parameters studied for significant correlations with cytogenetic findings at diagnosis, an association was evident only for age (p=0.02); all \u2013y abnormalities (n=5) as well as 13 of the 15 (87%) other cytogenetic abnormalities occurred in patients \u2265 60 years of age. stated another way, the incidence of abnormal cytogenetics (other than -y) was 4% for patients younger than age 60 years and 15% otherwise. the presence of abnormal cytogenetics at diagnosis had no significant impact on either overall or leukemia-free survival. \\n conclusions: abnormal cytogenetic findings at diagnosis are infrequent in pv, especially in patients below age 60 years. furthermore, their clinical relevance is limited and there is not significant correlation with bone marrow jak2v617f allele burden.",
            "contribution_ids": [
                "R32970",
                "R33090"
            ]
        },
        {
            "instance_id": "R33091xR33072",
            "comparison_id": "R33091",
            "paper_id": "R33072",
            "text": "Compari- son of peripheral blood interphase cytogenetics with bone marrow karyotype analysis in myelofibrosis with myeloid metaplasia in a prospective study of 42 patients with myelofibrosis with myeloid metaplasia (mmm), peripheral blood (pb) and bone marrow (bm) interphase cytogenetics and pb cd34 enumeration were performed concomitantly with bm karyotype analysis. interphase cytogenetics was performed with a panel of fluorescence in situ hybridization (fish) probes that were capable of detecting most of the known recurrent cytogenetic lesions in mmm. there was a close concordance in the results of interphase cytogenetics between pb and bm, regardless of the pb cd34 count. in general, fish\u2010detectable abnormalities were also detected by bm karyotype. although complementary, interphase cytogenetics may not always provide the necessary karyotypic information in mmm.",
            "contribution_ids": [
                "R33073"
            ]
        },
        {
            "instance_id": "R33091xR33080",
            "comparison_id": "R33091",
            "paper_id": "R33080",
            "text": "Prognostic diver- sity among cytogenetic abnormalities in myelofibrosis with myeloid metaplasia approximately 30\u201350% of patients with myelofibrosis with myeloid metaplasia (mmm) demonstrate detectable cytogenetic abnormalities, the prognostic value of which has not been completely defined by previous retrospective studies. the current prospective study addresses this issue in the context of currently accepted independent prognostic variables.",
            "contribution_ids": [
                "R33081"
            ]
        },
        {
            "instance_id": "R33091xR33064",
            "comparison_id": "R33091",
            "paper_id": "R33064",
            "text": "Acute myeloid leukemia and myelodysplastic syndromes following essential thrombocythemia treated with hydroxyurea: high proportion of cases with 17p deletion treatment with alkylating agents or radiophosphorous (32p) has been shown to carry a certain leukemogenic risk in myeloproliferative disorders (mpds), including essential thrombocytemia (et). the leukemogenic risk associated to treatment with hydroxyurea in et, on the other hand, is generally considered to be relatively low. between 1970 and 1991, we diagnosed et in 357 patients, who were monitored until 1996. one or several therapeutic agents had been admistered to 326 patients, including hydroxyurea (hu) in 251 (as only treatment in 201), pipobroman in 43, busulfan in 41, and32p in 40. with a median follow-up duration of 98 months, 17 patients (4.5%) had progressed to acute myeloid leukemia (aml; six cases) or myelodysplastic syndrome (mds; 11 cases). fourteen of these patients had received hu, as sole treatment in seven cases, and preceded or followed by other treatment in seven cases, mainly pipobroman (five cases). the remaining three leukemic progressions occurred in patients treated with 32p (two cases) and busulfan (one case). the incidence of aml and mds after treatment, using 32p alone and 32p with other agents, busulfan alone and with other agents, hu alone and with others agents, and pipobroman alone and with other agents was 7% and 9%, 3% and 17%, 3.5% and 14%, and 0% and 16%, respectively. thirteen of 17 patients who progressed to aml or mds had successful cytogenetic analysis. seven of them had rearrangements of chromosome 17 (unbalanced translocation, partial or complete deletion, isochromosome 17q) that resulted in 17p deletion. they also had a typical form of dysgranulopoiesis combining pseudo pelger hu\u0308et hypolobulation and vacuoles in neutrophils, and p53 mutation, as previously described in aml and mds with 17p deletion. those seven patients had all received hu, as the only therapeutic agent in three, and followed by pipobroman in three. the three patients who had received no hu and progressed to aml or mds had no 17p deletion. a review of the literature found cytogenetic analysis in 35 cases of aml and mds occurring after et, 11 of whom had been treated with hu alone. five of 35 patients had rearrangements that resulted in 17p deletion. four of them had been treated with hu alone. these results show that treatment with hu alone is associated with a leukemic risk of approximately 3.5%. a high proportion of aml and mds occurring in et treated with hu (alone or possibly followed by pipobroman) have morphologic, cytogenetic, and molecular characteristics of the 17p\u2212 syndrome. these findings suggest that widespread and prolonged use of hu in et may have to be reconsidered in some situations, such as asymptomatic et.",
            "contribution_ids": [
                "R33065"
            ]
        },
        {
            "instance_id": "R33091xR33020",
            "comparison_id": "R33091",
            "paper_id": "R33020",
            "text": "The pattern and clinical significance of karyotypic abnormalities in patients with idiopathic and postpolycythemic myelofibro- sis six of eight (75%) patients with postpolycythemic myelofibrosis (ppmf) and 11 of 20 (55%) patients with idiopathic myelofibrosis (mf), seen at the university of chicago, had abnormal karyotypes in cells of bone marrow origin. the specific chromosomal findings and their clinical significance in these patients were analyzed. a review of the literature added the findings from abnormal karyotype studies in 10 patients with ppmf and 36 patients with mf to this series. the demonstration of an increased frequency of cytogenetic abnormalities after cytotoxic therapy in polycythemia vera (pv) implies that such therapy may have a role in the development of chromosomal changes seen in treated pv and ppmf. the cytogenetic abnormalities in mf appear to be unrelated to therapy except possibly for an association with partial or complete losses of chromosome 5 or 7. trisomy 8 is the only finding that is more common in mf than in ppmf. other abnormalities were more common in ppmf, particularly 20q\u2010, loss of 7 or 7q\u2010, and trisomy 9, and to a lesser extent trisomy iq and 5q\u2010. cytogenetic abnormalities do not show a pattern that can be used to distinguish between ppmf and mf, nor are they useful in the prognosis of mf or in initial studies in ppmf. ppmf does appear to have a higher tendency toward leukemic transformation than does mf, and an evolution in karyotype appears to have serious prognostic implications in ppmf in regard to this transition.",
            "contribution_ids": [
                "R33021"
            ]
        },
        {
            "instance_id": "R33091xR32962",
            "comparison_id": "R33091",
            "paper_id": "R32962",
            "text": "Cytogenetic abnormalities and their prognostic significance in idiopathic myelo- fibrosis: a study of 106 cases \"the prognostic significance of cytogenetic abnormalities was determined in 106 patients with well\u2010characterized idiopathic myelofibrosis who were successfully karyotyped at diagnosis. 35% of the cases exhibited a clonal abnormality (37/106), whereas 65% (69/106) had a normal karyotype. three characteristic defects, namely del(13q) (nine cases), del(20q) (eight cases) and partial trisomy 1q (seven cases), were present in 64.8% (24/37) of patients with clonal abnormalities. kaplan\u2010meier plots and log rank analysis demonstrated an abnormal karyotype to be an adverse prognostic variable (p\\u2003 10.3\\u2003\u00d7\\u2003109/l; p\\u2003=\\u20030.06) were also associated with a shorter survival. in contrast, sex, spleen and liver size, and percentage blast cells were not found to be significant. multivariate analysis, using cox's regression, revealed karyotype, haemoglobin concentration, platelet and leucocyte counts to retain their unfavourable prognostic significance. a simple and useful schema for predicting survival in idiopathic myelofibrosis has been produced by combining age, haemoglobin concentration and karyotype with median survival times varying from 180 months (good\u2010risk group) to 16 months (poor\u2010risk group).\"",
            "contribution_ids": [
                "R32963",
                "R33043"
            ]
        },
        {
            "instance_id": "R33091xR33024",
            "comparison_id": "R33091",
            "paper_id": "R33024",
            "text": "Trisomy 1q in polycythe- mia vera and its relation to disease transition clinical and cytogenetic details of 12 patients with polycythemia vera and complete or partial trisomy of the long arm of chromosome 1 are reported. all patients had trisomy for at least the segments 1q22 to 1qter. the 1q or material from 1q was translocated to another chromosome in eight patients. this was chromosome 9 in four patients, and those cases all had trisomy also for 9p. the trisomy 1q was found at the time of diagnosis in three patients, later during the polycythemic phase in five, and in four patients when they were first examined during a late stage of the disease. acute leukemia or a myelodysplastic syndrome developed in eight of the 12 patients. signs of advanced disease, eg, myeloid metaplasia or myelofibrosis, preceded the leukemia in four cases and was noted in one more patient.",
            "contribution_ids": [
                "R33025",
                "R33051"
            ]
        },
        {
            "instance_id": "R33091xR33082",
            "comparison_id": "R33091",
            "paper_id": "R33082",
            "text": "Der(6)t(1;6)(q21-23;p21.3): a specific cytogenetic abnormality in myelofibrosis with myeloid metaplasia chromosome anomalies are detected in approximately half of patients with myelofibrosis with myeloid metaplasia (mmm) although none of the most prevalent lesions are specific to the disease. in a prospective cytogenetic study of 81 patients with mmm, we encountered three with an unbalanced translocation between chromosomes 1 and 6 with specific breakpoints; der(6)t(1;6)(q21\u201323;p21.3). a subsequent mayo clinic cytogenetic database search identified 12 patients with this chromosome anomaly among 17\\u2003791 consecutive patients. a similar database search from royal hallamshire hospital in sheffield, uk revealed two additional patients among 8000 cases. the clinical phenotype and survival for each of these 14 patients was typical of mmm. these findings suggested that der(6)t(1;6)(q21\u201323;p21.3) is a highly specific cytogenetic anomaly that may harbour gene(s) specifically associated with mmm. in a preliminary fluorescence in situ hybridization study, the breakpoints on chromosome 6 in two additional cases were found to be telomeric to the gene for 51\\u2003kda fk506\u2010binding protein (fkbp51).",
            "contribution_ids": [
                "R33083"
            ]
        },
        {
            "instance_id": "R33091xR33088",
            "comparison_id": "R33091",
            "paper_id": "R33088",
            "text": "The role of cytogenetic abnormalities as a prognostic marker in primary myelofibrosis: applicability at the time of diagnosis and later during disease course abstract \\n although cytogenetic abnormalities are important prognostic factors in myeloid malignancies, they are not included in current prognostic scores for primary myelofibrosis (pmf). to determine their relevance in pmf, we retrospectively examined the impact of cytogenetic abnormalities and karyotypic evolution on the outcome of 256 patients. baseline cytogenetic status impacted significantly on survival: patients with favorable abnormalities (sole deletions in 13q or 20q, or trisomy 9 \u00b1 one other abnormality) had survivals similar to those with normal diploid karyotypes (median, 63 and 46 months, respectively), whereas patients with unfavorable abnormalities (rearrangement of chromosome 5 or 7, or \u2265 3 abnormalities) had a poor median survival of 15 months. patients with abnormalities of chromosome 17 had a median survival of only 5 months. a model containing karyotypic abnormalities, hemoglobin, platelet count, and performance status effectively risk-stratified patients at initial evaluation. among 73 patients assessable for clonal evolution during stable chronic phase, those who developed unfavorable or chromosome 17 abnormalities had median survivals of 18 and 9 months, respectively, suggesting the potential role of cytogenetics as a risk factor applicable at any time in the disease course. dynamic prognostic significance of cytogenetic abnormalities in pmf should be further prospectively evaluated.",
            "contribution_ids": [
                "R33089"
            ]
        },
        {
            "instance_id": "R33091xR33031",
            "comparison_id": "R33091",
            "paper_id": "R33031",
            "text": "A prospective long-term cytogenetic study in polycythemia vera in relation to treatment and clinical course abstract \\n this paper reports the results of cytogenetic studies in a consecutive series of 64 patients with polycythemia vera, 57 of whom could be followed prospectively. the median length of the cytogenetic observation time was 93 months (range, 24 to 224 months) after diagnosis. clonal chromosome abnormalities were observed initially in 11 patients (17%) and later during the course of the disease in another 20 patients. an abnormal karyotype was found in 71% to 80% of the patients who were examined after the development of myeloid metaplasia, myelofibrosis, or leukemia. patients treated with myelosuppressive agents showed a significantly greater risk of chromosome abnormalities developing than did patients who had been phlebotomized. acute leukemia developed in eight patients, all of whom had been treated with myelosuppressive agents. a chromosome abnormality preceded the leukemia in only two of the patients. the initial presence of an abnormal karyotype did not predict a greater risk of development of leukemia. no consistent relationship was demonstrated between the occurrence of chromosome abnormalities and the development of myeloid metaplasia and/or myelofibrosis, which was observed in 42% of the patients. the chromosome abnormalities followed a nonrandom pattern, and those most frequently observed were trisomies for 1 q, 8, 9, or 9p and deletion of 20q. deletions seem to be common and were found in 14 patients.",
            "contribution_ids": [
                "R33032",
                "R33053"
            ]
        },
        {
            "instance_id": "R33091xR33039",
            "comparison_id": "R33091",
            "paper_id": "R33039",
            "text": "Karyotypic and ras gene mutational analysis in idiopathic myelofibrosis summary. karyotypic analysis was performed in a total of 69 patients with well\u2010characterized idiopathic myelofibrosis. karyotypic abnormalities were detected in 46% of cases examined during the chronic phase (29/63); with three abnormalities, del (13q), del(20q) and partial trisomy 1q, accounting for 75% of all abnormalities at diagnosis. the absence of del(5q), trisomy 8 and 21, as well as the rarity of monosomy 7, contrasts with pooled published data and may reflect our exclusion of closely related disorders, in particular mds with fibrosis. chromosomal aberrations increased to approximately 90% (8/9) in patients analysed during acute transformation. mutational activation of codons 12, 13 and 61 of n\u2010, ha\u2010 and ki\u2010ras genes were assessed by polymerase chain reaction and hydridization with synthetic non\u2010radioactive digoxigenin\u2010labelled probes. three mutations were detected in samples of peripheral blood dna taken from 50 patients during the chronic phase of their disease: one n12 asp (ggt gat) and two n12 ser (ggt agt) mutations. the results from this study indicate that karyotypic abnormalities are present in at least 29% of cases at diagnosis and that del(13q), del(20q) and partial trisomy 1q are the most frequent findings. ras mutations were relatively infrequent (6%) and appeared restricted to the n\u2010ras gene. karyotypic analysis at diagnosis was found to be of prognostic significance.",
            "contribution_ids": [
                "R33040",
                "R33056"
            ]
        },
        {
            "instance_id": "R33091xR33041",
            "comparison_id": "R33091",
            "paper_id": "R33041",
            "text": "Prognostic factors in agnogenic myeloid metaplasia: a report on 195 cases with a new scoring system we studied the survival of 195 patients with agnogenic myeloid metaplasia (amm) diagnosed between 1962 and 1992 in an attempt to stratify patients into risk groups. median survival was 42 months. adverse prognostic factors for survival were age &gt; 60 years, hepatomegaly, weight loss, low hemoglobin level (hb), low or very high leukocyte count (wbc), high percentage of circulating blasts, male sex, and low platelet count. a new scoring system based on two adverse prognostic factors, namely hb &lt; 10 g/dl and wbc &lt; 4 or &gt; 30 x 10(3)/l, was able to separate patients in three groups with low (0 factor), intermediate (1 factor), and high (2 factors) risks, associated with a median survival of 93, 26, and 13 months, respectively. an abnormal karyotype (32 cases of 94 tested patients) was associated with a short survival, especially in the low-risk group (median survival of 50 v 112 months in patients with normal karyotype). the prognostic factors for acute conversion were wbc &gt; 30 x 10(3)/l and abnormal karyotype. thus, hemoglobin level and leukocyte count provide a simple prognostic model for survival in amm, and the adverse prognostic value of abnormal karyotype may be related to a higher rate of acute conversion.",
            "contribution_ids": [
                "R33042"
            ]
        },
        {
            "instance_id": "R33091xR32967",
            "comparison_id": "R33091",
            "paper_id": "R32967",
            "text": "Exploring polycythaemia vera with fluorescence in situ hybridization: additional cryptic 9p is the most frequent abnormality detected summary. between 1986 and 2001, 220 patients with polycythaemia vera (pv) were studied using conventional cytogenetics. of 204 evaluable patients, 52 (25\u00b74%) had clonal abnormalities. the recurrent chromosomal rearrangements were those of chromosome 9 (21\u00b71%), del(20q) (19\u00b72%), trisomy 8 (19\u00b72%), rearrangements of 13q (13\u00b74%), abnormalities of 1q (11\u00b75%), and of chromosomes 5 and 7 (9\u00b76%). subsequent analysis of 32 patients, performed at follow\u2010up of up to 14\u00b78\\u2003years, revealed new clonal abnormalities in five patients and the disappearance of an abnormal clone in four. eleven patients remained normal up to 11\u00b75\\u2003years and seven patients maintained an abnormality for over 10\\u2003years. fifty\u2010three patients were studied retrospectively using interphase fluorescence in\\u2003situ hybridization (i\u2010fish), utilizing probes for centromere enumeration of chromosomes 8 and 9, and for 13q14 and 20q12 loci. conventional cytogenetics demonstrated clonal chromosome abnormalities in 23% of these 53 patients. the addition of i\u2010fish increased the detection of abnormalities to 29% and permitted clarification of chromosome 9 rearrangements in an additional 5\u00b76% of patients. fish uncovered rearrangements of chromosome 9 in 53% of patients with an abnormal fish pattern, which represented the most frequent genomic alteration in this series.",
            "contribution_ids": [
                "R32968",
                "R33077"
            ]
        },
        {
            "instance_id": "R33091xR32979",
            "comparison_id": "R33091",
            "paper_id": "R32979",
            "text": "Cytogenetic findings and their clinical relevance in myelofibrosis with myeloid metaplasia the prognostic significance of bone marrow cytogenetic lesions in myelofibrosis with myeloid metaplasia (mmm) was investigated in a retrospective series of 165 patients. an abnormal karyotype was demonstrated in 57% of patients. at diagnosis (n\\u2003=\\u200392), 48% of the patients had detectable cytogenetic abnormalities, and clonal evolution was frequently demonstrated in sequential studies. more than 90% of the anomalies were represented by 20q\u2013, 13q\u2013, +8, +9, 12p\u2013, and abnormalities of chromosomes 1 and 7. of these, 20q\u2013, 13q\u2013 and +8 were the most frequent sole abnormalities, each occurring in 15\u201325% of the abnormal cases. trisomy 9 and abnormalities of chromosomes 1 and 7 were equally prevalent but were usually associated with additional cytogenetic lesions. chromosome 5 abnormalities were infrequent but were over\u2010represented in the group of patients exposed to genotoxic therapy. in a multivariate analysis that incorporated other clinical and laboratory variables, the presence of an abnormal karyotype did not carry an adverse prognosis. instead, +8, 12p\u2013, advanced age and anaemia were independent prognostic determinants of inferior survival. in particular, survival was not adversely affected by the presence of either 20q\u2013 or 13q\u2013.",
            "contribution_ids": [
                "R32980",
                "R32982",
                "R33044"
            ]
        },
        {
            "instance_id": "R33581xR33171",
            "comparison_id": "R33581",
            "paper_id": "R33171",
            "text": "The successful management of a small logistics company \" in this paper, a case study conducted on a small third\u2010party logistics (3pl) company in hong kong is presented. this company is interesting in that it has been designated as the \u201cking\u201d of hong kong's 3pl (in\u2010bound) logistics companies. the company has been successful in its overall business performance and in satisfying customers. this company's strategic alliances with both clients and customers have helped to improve the utilization of its resources, such as warehouse space and transportation fleets. also, the company is in the process of expanding its operations across greater china, with the objective of becoming a full\u2010pledged 3pl company. the analysis of this case focuses on the critical success factors (strategies and technologies) that have allowed a small company started only in 1996 to become so successful in its operations. also, a framework has been provided for the company to develop its logistics operations as a full\u2010pledged 3pl company. \"",
            "contribution_ids": [
                "R33172"
            ]
        },
        {
            "instance_id": "R33581xR33426",
            "comparison_id": "R33581",
            "paper_id": "R33426",
            "text": "Determination of the success factors in supply chain networks: a Hong Kong\u00e2\u0080\u0090based manufacturer's perspective purpose the purpose of the paper is to investigate the factors that affect the decision\u2010making process of hong kong\u2010based manufacturers when they select a third\u2010party logistics (3pl) service provider and how 3pl service providers manage to retain customer loyalty in times of financial turbulence. design/methodology/approach the paper presents a survey\u2010based study targeting hong kong\u2010based manufacturers currently using 3pl companies. it investigates the relationship between the reasons for using 3pl services and the requirements for selecting a provider, and examines the relationship between customer satisfaction and loyalty. in addition, the relationships among various dimensions \u2013 in small to medium\u2010sized enterprises (smes), large enterprises and companies \u2013 of contracts of various lengths are investigated. findings in general, the reasons for using 3pl services and the requirements for selecting 3pl service providers are positive\u2010related. the dimension of \u201creputation\u201d of satisfaction influences \u201cprimary customer loyalty\u201d positively. practical implications constructive suggestions are provided to help 3pl service providers allocate their limited resources to business areas that help them to meet the demands of their target customers, increase the number of customers, and improve customer loyalty. originality/value the paper is an attempt to help 3pl service providers find ways to survive in a climate of financial crisis.",
            "contribution_ids": [
                "R33427"
            ]
        },
        {
            "instance_id": "R33581xR33205",
            "comparison_id": "R33581",
            "paper_id": "R33205",
            "text": "An Exploratory Study of the Success Factors for Extranet Adoption in E-Supply Chain extranet is an enabler/system that enriches the information service quality in e-supply chain. this paper uses factor analysis to determine four extranet success factors: system quality, information quality, service quality, and work performance quality. a critical analysis of areas that require improvement is also conducted.",
            "contribution_ids": [
                "R33206"
            ]
        },
        {
            "instance_id": "R33581xR33529",
            "comparison_id": "R33581",
            "paper_id": "R33529",
            "text": "Supply chain issues in SMEs: select insights from cases of Indian origin this article reports the supply chain issues in small and medium scale enterprises (smes) using insights from select cases of indian origin (manufacturing smes). a broad range of qualitative and quantitative data were collected during interviews and plant visits in a multi-case study (of 10 smes) research design. company documentation and business reports were also employed. analysis is carried out using diagnostic tools like \u2018ebm-rep\u2019 (thakkar, j., kanda, a., and deshmukh, s.g., 2008c. an enquiry-analysis framework \u201cebm-rep\u201d for qualitative research. international journal of innovation and learning (ijil), 5 (5), 557\u2013580.) and \u2018role interaction model\u2019 (thakkar j., kanda, a., and deshmukh, s.g., 2008b. a conceptual role interaction model for supply chain management in smes. journal of small business and enterprise development (jsbed), 15 (1), 74\u201395). this article reports a set of critical success factors and evaluates six critical research questions for the successful supply chain planning and management in smes. the results of this article will help sme managers to assess their supply chain function more rigorously. this article addresses the issue on supply chain management in smes using case study approach and diagnostic tools to add select new insights to the existing body of knowledge on supply chain issues in smes.",
            "contribution_ids": [
                "R33530"
            ]
        },
        {
            "instance_id": "R33581xR33305",
            "comparison_id": "R33581",
            "paper_id": "R33305",
            "text": "Supply chain management in SMEs: development of constructs and propositions purpose the purpose of this paper is to review the literature on supply chain management (scm) practices in small and medium scale enterprises (smes) and outlines the key insights. design/methodology/approach the paper describes a literature\u2010based research that has sought understand the issues of scm for smes. the methodology is based on critical review of 77 research papers from high\u2010quality, international refereed journals. mainly, issues are explored under three categories \u2013 supply chain integration, strategy and planning and implementation. this has supported the development of key constructs and propositions. findings the research outcomes are three fold. firstly, paper summarizes the reported literature and classifies it based on their nature of work and contributions. second, paper demonstrates the overall approach towards the development of constructs, research questions, and investigative questions leading to key proposition for the further research. lastly, paper outlines the key findings and insights gained. practical implications survival of smes will be determined first and foremost by their ability to provide/produce more, at less cost, in less time, with few \u201cdefects\u201d. the key to this is effective scm. the issue is much explored in the context of large enterprises but less attention is paid to smes. paper aims to surface out some facts for the same. originality/value the paper reports\u2010classifies the literature and development of construct and propositions.",
            "contribution_ids": [
                "R33306"
            ]
        },
        {
            "instance_id": "R33581xR33118",
            "comparison_id": "R33581",
            "paper_id": "R33118",
            "text": "The elements of a successful logistics partnership describes the elements of a successful logistics partnership. looks at what can cause failure and questions whether the benefits of a logistics partnership are worth the effort required. concludes that strategic alliances are increasingly becoming a matter of survival, not merely a matter of competitive advantage. refers to the example of the long\u2010term relationship between kimberly\u2010clark corporation and interamerican group\u2019s tricor warehousing, inc.",
            "contribution_ids": [
                "R33119"
            ]
        },
        {
            "instance_id": "R33581xR33476",
            "comparison_id": "R33581",
            "paper_id": "R33476",
            "text": "An empirical study on the impact of critical success factors on the balanced scorecard performance in Korean green supply chain management enterprises rapid industrial modernisation and economic reform have been features of the korean economy since the 1990s, and have brought with it substantial environmental problems. in response to these problems, the korean government has been developing approaches to promote cleaner production technologies. green supply chain management (gscm) is emerging to be an important approach for korean enterprises to improve performance. the purpose of this study is to examine the impact of gscm csfs (critical success factors) on the bsc (balanced scorecard) performance by the structural equation modelling, using empirical results from 249 enterprise respondents involved in national gscm business in korea. planning and implementation was a dominant antecedent factor in this study, followed by collaboration with partners and integration of infrastructure. however, activation of support was a negative impact to the finance performance, raising the costs and burdens. it was found out that there were important implications in the implementation of gscm.",
            "contribution_ids": [
                "R33477"
            ]
        },
        {
            "instance_id": "R33581xR33455",
            "comparison_id": "R33581",
            "paper_id": "R33455",
            "text": "Perceptions of service providers and customers of key success factors of third-party logistics relationships \u00e2\u0080\u0093 an empirical study this paper provides a comparison of third-party logistics (3pl) service providers and 3pl customers with respect to the perception of key success factors (ksfs) for building and fostering relationships. the ksfs and their related sub-factors were derived from the extant literature and modified to reflect the nature of 3pl arrangements. the relevant data were collected from separate, but consistent, mail surveys that were sent to 3pl service providers and 3pl customers. the results indicate statistically significant differences in the perception of critical success factors between 3pl service providers and 3pl customers. the results show that customers see a focus on service-based solutions as being an important feature of 3pl provision providing a set of benefits beyond mere cost control.",
            "contribution_ids": [
                "R33456"
            ]
        },
        {
            "instance_id": "R33581xR33571",
            "comparison_id": "R33581",
            "paper_id": "R33571",
            "text": "Critical success factors of green supply chain management for achieving sustainability in Indian automobile industry the aim of this study was to identify and analyse the key success factors behind successful achievement of environment sustainability in indian automobile industry supply chains. here, critical success factors (csfs) and performance measures of green supply chain management (gscm) have been identified through extensive literature review and discussions with experts from indian automobile industry. based on the literature review, a questionnaire was designed and 123 final responses were considered. six csfs to implement gscm for achieving sustainability and four expected performance measures of gscm practices implementation were extracted using factor analysis. interpretive ranking process (irp) modelling approach is employed to examine the contextual relationships among csfs and to rank them with respect to performance measures. the developed irp model shows that the csf \u2018competitiveness\u2019 is the most important csf for achieving sustainability in indian automobile industry through gscm practices. this study is one of the few that have considered the environmental sustainability practices in the automobile industry in india and their implications on sectoral economy. the results of this study may help the mangers/sc practitioners/governments/customers in making strategic and tactical decisions regarding successful implementation of gscm practices in indian automobile industry with a sustainability focus. the developed framework provides a comprehensive perspective for assessing the synergistic impact of csfs on gscm performances and can act as ready reckoner for the practitioners. as there is very limited work presented in literature using irp, this piece of work would provide a better understanding of this relatively new ranking methodology.",
            "contribution_ids": [
                "R33572"
            ]
        },
        {
            "instance_id": "R33581xR33321",
            "comparison_id": "R33581",
            "paper_id": "R33321",
            "text": "Drivers and impacts of ICT adoption on transport and logistics services summary the availability of high\u2010quality transport and logistics services (tls) is of paramount importance for the growth and competitiveness of an economy. the objective of this paper is to describe how european companies in this industry use information and communication technology (ict) for conducting business and to assess the impact of this development for firms and the industry as a whole. a comparison with some important asia pacific economies is also presented, indicating that some of these countries (singapore, hong kong, japan, taiwan, and korea) boast very good transport infrastructure compared with the most developed european economies. using the structure\u2010conduct\u2010performance (scp) model and the bi\u2010directional relationships of its elements, the paper identifies the links between ict adoption and market structure, innovation dynamics, and firm performance. a set of recommendations on how to further improve the actual scenario of e\u2010business in the tls industry is also presented. the model could also be implemented in asian countries.",
            "contribution_ids": [
                "R33322"
            ]
        },
        {
            "instance_id": "R33581xR33506",
            "comparison_id": "R33581",
            "paper_id": "R33506",
            "text": "Key success factor analysis for e\u00e2\u0080\u0090SCM project implementation and a case study in semiconductor manufacturers purpose the semiconductor market exceeded us$250 billion worldwide in 2010 and has had a double\u2010digit compound annual growth rate (cagr) in the last 20 years. as it is located far upstream of the electronic product market, the semiconductor industry has suffered severely from the \u201cbullwhip\u201d effect. therefore, effective e\u2010based supply chain management (e\u2010scm) has become imperative for the efficient operation of semiconductor manufacturing (sm) companies. the purpose of this research is to define and analyze the key success factors (ksf) for e\u2010scm system implementation in the semiconductor industry. design/methodology/approach a hierarchy of ksfs is defined first by a combination of a literature review and a focus group discussion with experts who successfully implemented an inter\u2010organizational e\u2010scm project. fuzzy analytic hierarchy process (fahp) is then employed to rank the importance of these identified ksfs. to confirm the research result and further explore the managerial implications, a second in\u2010depth interview with the e\u2010scm project executives is conducted. findings the ksf hierarchy is constructed with two levels: a top\u2010level consisting of four dimensions and a detailed\u2010level consisting of 15 individual factors. the research shows that, in the top\u2010level, strategy is the most critically successful dimension followed by process, organization, and technical; whereas in the detailed\u2010level, the top management commitment, clear project goal and business requirements, and business process re\u2010engineering are the top three critical successful factors. research limitations/implications research surveys and interviews were conducted with two leading companies: taiwan semiconductor manufacturing company (tsmc) and ase; they are the largest front\u2010end and back\u2010end sm companies in the world, respectively. although the data collected was primarily based on the experience of one successful e\u2010scm project, the significant roles of these two companies and compelling contribution made by the e\u2010scm project leading to the research resulted in valuable guidelines for the companies in the semiconductor industry and a useful reference for companies in other manufacturing industries. originality/value e\u2010scm system has a high failure rate and there is little literature discussing the ksf of e\u2010scm implementation from a holistic view for certain industries. this paper not only provides a structured and comprehensive list of ksfs but also illustrates the application of the most critical factors by examples. in addition to the contributions made to industries, the research results can also serve as a foundation for related academic research when comparing the ksfs of implementing e\u2010scm by different industries.",
            "contribution_ids": [
                "R33507"
            ]
        },
        {
            "instance_id": "R33581xR33102",
            "comparison_id": "R33581",
            "paper_id": "R33102",
            "text": "The integrated logistics management system: a framework and case study presents a framework for distribution companies to establish and\\nimprove their logistics systems continuously. recently, much attention\\nhas been given to automation in services, the use of new information\\ntechnology and the integration of the supply chain. discusses these\\nareas, which have great potential to increase logistics productivity and\\nprovide customers with high level service. the exploration of each area\\nis enriched with taiwanese logistics management practices and\\nexperiences. includes a case study of one prominent food processor and\\nretailer in taiwan in order to demonstrate the pragmatic operations of\\nthe integrated logistics management system. also, a survey of 45\\ntaiwanese retailers was conducted to investigate the extent of logistics\\nmanagement in taiwan. concludes by suggesting how distribution companies\\ncan overcome noticeable logistics management barriers, build store\\nautomation systems, and follow the key steps to logistics success.",
            "contribution_ids": [
                "R33103"
            ]
        },
        {
            "instance_id": "R33581xR33251",
            "comparison_id": "R33581",
            "paper_id": "R33251",
            "text": "<p class=MsoNormal align=left style='text-align:left;mso-layout-grid-align: none;text-autospace:none'>Critical Factors of Attracting Supply Chain Network Members to Electronic Marketplaces: The Case of Sunbooks Ltd. and the Hungarian Book Trade</p> <p class=MsoNormal align=left style='margin-left:3.5pt;text-align:left; text-indent:-3.5pt;mso-layout-grid-align:none;text-autospace:none'> </p> <p class=MsoNormal> </p> vertical electronic marketplaces often suffer from the low level of liquidity. attracting members is critical, however, not even a sound and efficient it and logistic background is enough to convince both the supplier and the customer side. in this paper the authors present the case study of sunbooks ltd. this venture has started to transform the hungarian book trade market that suffers from serious deficiencies in field of information and material flow. despite the vast investments and that the marketplace is prepared to serve the whole hungarian book industry, the market share started to grow very slowly. the authors identify three contingency factors which can be accounted for the evolution dynamics of this virtual network. they explain how the business model is subjected to the evolution of market characteristics, and how the third factor, the \u201csoft issues\u201d determine the evolution opportunities even in a supporting market situation.",
            "contribution_ids": [
                "R33252"
            ]
        },
        {
            "instance_id": "R33581xR33486",
            "comparison_id": "R33581",
            "paper_id": "R33486",
            "text": "Understanding the Success Factors of Sustainable Supply Chain Management: Empirical Evidence from the Electrics and Electronics Industry recent studies have reported that organizations are often unable to identify the key success factors of sustainable supply chain management (sscm) and to understand their implications for management practice. for this reason, the implementation of sscm often does not result in noticeable benefits. so far, research has failed to offer any explanations for this discrepancy. in view of this fact, our study aims at identifying and analyzing the factors that underlie successful sscm. success factors are identified by means of a systematic literature review and are then integrated into an explanatory model. consequently, the proposed success factor model is tested on the basis of an empirical study focusing on recycling networks of the electrics and electronics industry. we found that signaling, information provision and the adoption of standards are crucial preconditions for strategy commitment, mutual learning, the establishment of ecological cycles and hence for the overall success of sscm. copyright \u00a9 2011 john wiley & sons, ltd and erp environment.",
            "contribution_ids": [
                "R33487"
            ]
        },
        {
            "instance_id": "R33581xR33153",
            "comparison_id": "R33581",
            "paper_id": "R33153",
            "text": "Strategic Alliance Success Factors \"summary \\nthere is recognition that competition is shifting from a \u201cfirm versus firm perspective\u201d to a \u201csupply chain versus supply chain perspective.\u201d in response to this shift, firms seeking competitive advantage are participating in cooperative supply chain arrangements, such as strategic alliances, which combine their individual strengths and unique resources. buyer-supplier sourcing relationships are a primary focus of alliance improvement efforts. while interest in such arrangements remains strong, it is well accepted that creating, developing, and maintaining a successful alliance is a very daunting task. this research addresses several critical issues regarding that challenge. first, what factors contribute most to long-term alliance success? second, what conditions define the presence of those success factors? third, do buyers and suppliers in an alliance agree on those success factors and defining conditions? the research results demonstrate a remarkably consistent perspective among alliance partners regarding key success factors, despite the acknowledgment that the resultant success is based on a relatively even, but not equal, exchange of benefits and resources. additionally, within an alliance's intended \u201cwin-win\u201d foundation, suppliers must recognize their innate dependence on customers. finally, significant opportunities for improvement exist with respect to alliance goal clarification, communication, and performance evaluation.\"",
            "contribution_ids": [
                "R33154"
            ]
        },
        {
            "instance_id": "R33581xR33189",
            "comparison_id": "R33581",
            "paper_id": "R33189",
            "text": "Critical success factors of web-based supply-chain management systems: an exploratory study this paper reports the results of a survey on the critical success factors (csfs) of web-based supply-chain management systems (wscms). an empirical study was conducted and an exploratory factor analysis of the survey data revealed five major dimensions of the csfs for wscms implementation, namely (1) communication, (2) top management commitment, (3) data security, (4) training and education, and (5) hardware and software reliability. the findings of the results provide insights for companies using or planning to use wscms.",
            "contribution_ids": [
                "R33190"
            ]
        },
        {
            "instance_id": "R33581xR33280",
            "comparison_id": "R33581",
            "paper_id": "R33280",
            "text": "Identifying the factors influencing the performance of reverse supply chains (RSC) this paper aims to extract the factors influencing the performance of reverse supply chains (rscs) based on the structure equation model (sem). we first introduce the definition of rsc and describe its current status and follow this with a literature review of previous rsc studies and the technology acceptance model . we next develop our research model and 11 hypotheses and then use sem to test our model and identify those factors that actually influence the success of rsc. next, we use both questionnaire and web\u2010based methods to survey five companies which have rsc operation experience in china and korea. using the 168 responses, we used measurement modeling test and sem to validate our proposed hypotheses. as a result, nine hypotheses were accepted while two were rejected. we found that ease of use, perceived usefulness, service quality, channel relationship and rsc cost were the five most important factors which influence the success of rsc. finally, we conclude by highlighting our research contribution and propose future research.",
            "contribution_ids": [
                "R33281"
            ]
        },
        {
            "instance_id": "R33581xR33237",
            "comparison_id": "R33581",
            "paper_id": "R33237",
            "text": "Supply chain software implementations: getting it right purpose to highlight key success factors in supply chain projects. design/methodology/approach the paper presents insights from a number of supply chain projects in which it has played an important part in the business solution. findings successful supply chain projects have four things in common: the right leadership, the right focus, the right approach and effective communication of kpis to all stakeholders engaged in the project. research limitations/implications the focus of the paper is on supply chain projects with a significant it component, but the key success factors identified are common to the majority of supply chain projects. practical implications companies must not assume that investment in it is, by itself, a solution to their supply chain solutions. a lack of leadership, focus and communication will invariably result in sub\u2010optimal outcomes which are all too frequently attributed to the complex nature of the project or the inflexibility of the software when in most cases the problems are internal to the businesses involved and the project management process. originality/value this paper provides practical tips for improving the likelihood of getting the most out of it\u2010based supply chain projects.",
            "contribution_ids": [
                "R33238"
            ]
        },
        {
            "instance_id": "R33581xR33564",
            "comparison_id": "R33581",
            "paper_id": "R33564",
            "text": "Identification of critical success factors 261 to achieve high green supply chain management performances in Indian automobile industry\u00e2\u0080\u009d \"green supply chain management (gscm) has been receiving the spotlight in last few years. the study aims to identify critical success factors (csfs) to achieve high gscm performances from three perspectives i.e., environmental, social and economic performance. csfs to achieve high gscm performances relevant to indian automobile industry have been identified and categorised according to three perspectives from the literature review and experts' opinions. conceptual models also have been put forward. this paper may play vital role to understand csfs to achieve gscm performances in indian automobile industry and help the supply chain managers to understand how they may improve environmental, social and economic performance.\"",
            "contribution_ids": [
                "R33565"
            ]
        },
        {
            "instance_id": "R33581xR33127",
            "comparison_id": "R33581",
            "paper_id": "R33127",
            "text": "Outsourcing of logistics functions: a literature survey recent times have witnessed a heightened global interest in outsourcing of logistics functions. this is indicated by the volume of writings on the subject in various scholarly journals, trade publications and popular magazines. however, efforts to organize them in an integrated body of knowledge appear to be very limited. keeping this in view, this paper makes an attempt to develop a comprehensive literature on outsourcing based on more than 100 published articles, papers and books on the subject.",
            "contribution_ids": [
                "R33128"
            ]
        },
        {
            "instance_id": "R33581xR33109",
            "comparison_id": "R33581",
            "paper_id": "R33109",
            "text": "Benchmarking logistics performance with an application of the analytic hierarchy process in the increasingly turbulent environment, logistics strategic management has become a necessity for achieving competitive advantage. the use of benchmarking is widening as a technique for supporting logistics strategic management. benchmarking can be described as the search for the best practices leading to a superior performance of a company. in this paper, we demonstrate how the analytic hierarchy process (ahp) can be used for supporting a generic logistics benchmarking process. first, the customers of a company are interviewed in order to define the logistic critical success factors and to determine their importance. the performance levels of the companies to be benchmarked are then evaluated with regard to each success factor. second, the factors enabling the companies to achieve superior logistics performance are determined and prioritized with respect to each success factor. third, the strengths, weaknesses, and problems of the company conducting the benchmarking process are analyzed and prioritized with respect to each enabler. then the potential developmental actions for achieving superior logistics performance are defined and prioritized. in addition to supporting the three steps mentioned above, the ahp-based approach forms the basic framework for a continuous logistics benchmarking process.",
            "contribution_ids": [
                "R33110"
            ]
        },
        {
            "instance_id": "R33581xR33534",
            "comparison_id": "R33581",
            "paper_id": "R33534",
            "text": "Application of critical success factors in supply chain management this study is the first attempt that assembled published academic work on critical success factors (csfs) in supply chain management (scm) fields. the purpose of this study are to review the csfs in scm and to uncover the major csfs that are apparent in scm literatures. this study apply literature survey techniques from published csfs studies in scm. a collection of 42 csfs studies in various scm fields are obtained from major databases. the search uses keywords such as as supply chain management, critical success factors, logistics management and supply chain drivers and barriers. from the literature survey, four major csfs are proposed. the factors are collaborative partnership, information technology, top management support and human resource. it is hoped that this review will serve as a platform for future research in scm and csfs studies. plus, this study contribute to existing scm knowledge and further appraise the concept of csfs.",
            "contribution_ids": [
                "R33535"
            ]
        },
        {
            "instance_id": "R33581xR33579",
            "comparison_id": "R33581",
            "paper_id": "R33579",
            "text": "Critical success factors of customer involvement in greening the supply chain: an empirical study the role of customers and their involvement in green supply chain management (gscm) has been recognised as an important research area. this paper is an attempt to explore factors influencing involvement of customers towards greening the supply chain (sc). twenty-five critical success factors (csfs) of customer involvement in gscm have been identified from literature review and through extensive discussions with senior and middle level sc professionals. interviews and questionnaire-based survey have been used to indicate the significance of these csfs. a total of 478 valid responses were received to rate these csfs on a five-point likert scale (ranging from unimportant to most important). statistical analysis has been carried out to establish the reliability and to test the validity of the questionnaires. subsequent factor analysis has identified seven major components covering 79.24% of total variance. this paper may help to establish the importance of customer role in promoting green concept in scs and to develop an understanding of factors influencing customer involvement \u2013 key input towards creating \u2018greening pull system\u2019 (gpsys). this understanding may further help in framing the policies and strategies to green the sc.",
            "contribution_ids": [
                "R33580"
            ]
        },
        {
            "instance_id": "R33581xR33261",
            "comparison_id": "R33581",
            "paper_id": "R33261",
            "text": "Supply Base Reduction: An Empirical Study of Critical Success Factors \"summary \\none important factor in the design of an organization's supply chain is the number of suppliers used for a given product or service. supply base reduction is one option useful in managing the supply base. the current paper reports the results of case studies in 10 organizations that recently implemented supply base reduction activities. specifically, the paper identifies the key success factors in supply base reduction efforts and prescribes processes to capture the benefits of supply base reduction.\"",
            "contribution_ids": [
                "R33262"
            ]
        },
        {
            "instance_id": "R33581xR33381",
            "comparison_id": "R33581",
            "paper_id": "R33381",
            "text": "Aggregated construction supply chains: success factors in implementation of strategic partnerships purpose \u2013 the purpose of this paper is to address the management of supply chains within the construction industry. supply chains in this sector evidence a marked tendency to waste and inefficiency. one approach to improving this situation, which is the subject of intense discussion by both scientists and practitioners, is the establishment of strategic partnerships integrated with the scientific observation of the processes involved. this paper aims to present a case study of such a strategic alliance among german building contractors whose goal it is to cover the entire life cycle of a building, from its planning to its ultimate facility management. the paper seeks to focus on the establishment and implementation of an aggregated strategic alliance and its success factors.design/methodology/approach \u2013 the research methodology is based on a case study of a german network of builders and trade contracting companies. data collection tools included observation of workshops and meetings, semi\u2010structured inte...",
            "contribution_ids": [
                "R33382"
            ]
        },
        {
            "instance_id": "R33581xR33287",
            "comparison_id": "R33581",
            "paper_id": "R33287",
            "text": "Implementing supply chain quality management this paper describes a strategic framework for the development of supply chain quality management (scqm). the framework integrates both vision- and gap-driven change approaches to evaluate not only the implementation gaps but also their potential countermeasures. based on literature review, drivers of supply chain quality are identified. they are: supply chain competence, critical success factors (csf), strategic components, and scq practices/activities/programmes. based on scqm literature, five survey items are also presented in this study for each drive. the analytic hierarchy process (ahp) is used to develop priority indices for these survey items. knowledge of these critical dimensions and possible implementation discrepancies could help multinational enterprises and their supply chain partners lay out effective and efficient scqm plans.",
            "contribution_ids": [
                "R33288"
            ]
        },
        {
            "instance_id": "R33581xR33136",
            "comparison_id": "R33581",
            "paper_id": "R33136",
            "text": "Success factors in the fresh produce supply chain: insights from the UK presents recent evidence of supply chain developments in the uk fresh produce industry, based on interviews with chief executives from some of the country\u2019s most successful suppliers. a number of success factors were evident, to varying degrees, in all of the companies interviewed. these included: continuous investment (despite increasingly tight margins), good staff (to drive the process of innovation and develop good trading relationships with key customers), volume growth (to fund the necessary investments and provide a degree of confidence in the future), improvement of measurement and control of costs (in the pursuit of further gains in efficiency), and innovation (not just the product offer but also the level of service and the way of doing business with key customers).",
            "contribution_ids": [
                "R33137"
            ]
        },
        {
            "instance_id": "R33581xR33375",
            "comparison_id": "R33581",
            "paper_id": "R33375",
            "text": "Critical factors for implementing green supply chain management practice purpose the purpose of this paper is to explore critical factors for implementing green supply chain management (gscm) practice in the taiwanese electrical and electronics industries relative to european union directives. design/methodology/approach a tentative list of critical factors of gscm was developed based on a thorough and detailed analysis of the pertinent literature. the survey questionnaire contained 25 items, developed based on the literature and interviews with three industry experts, specifically quality and product assurance representatives. a total of 300 questionnaires were mailed out, and 87 were returned, of which 84 were valid, representing a response rate of 28 percent. using the data collected, the identified critical factors were performed via factor analysis to establish reliability and validity. findings the results show that 20 critical factors were extracted into four dimensions, which denominated supplier management, product recycling, organization involvement and life cycle management. research limitations/implications this study obtained 84 valid responses from the taiwanese electrical and electronics industries, the limitation of the study is the insufficient sampling. future researches need to be performed using a larger sample and studying more countries. practical implications the taiwanese electrical and electronics industry plays a decisive role in the global information and communications technology (ict) industry. consequently, the validated instrument enables decision makers at ict manufacturers to evaluate the perceptions of gscm in their organizations. in addition, the critical factors of implementing gscm practices validated in this work can help enterprises identify those areas of gscm where acceptance and improvements will be made, and in prioritizing gscm efforts. originality/value this study presents an empirical investigation of gscm practices, and fills a gap in the literature on the identification and establishment of critical factors for gscm implementation in electrical and electronics industries.",
            "contribution_ids": [
                "R33376"
            ]
        },
        {
            "instance_id": "R33581xR33144",
            "comparison_id": "R33581",
            "paper_id": "R33144",
            "text": "Distinguishing the critical success factors between e-commerce, enterprise resource planning, and supply chain management the rapid deployment of e-business systems has surprised even the most futuristic management thinkers. unfortunately very little empirical research has documented the many variations of e-business solutions as major software vendors release complex it products into the marketplace. the literature holds simultaneous evidence of major success and major failure as implementations evolve. it is not clear from the literature just what the difference is between e-commerce and its predecessor concepts of supply chain management and enterprise resource planning. in this paper we use existing case studies, industrial interviews, and survey data to describe how these systems are similar and how they differ. we develop a conceptual model to show how these systems are related and how they serve significantly different strategic objectives. finally, we suggest the critical success factors that are the key issues to resolve in order to successfully implement these systems in practice.",
            "contribution_ids": [
                "R33145"
            ]
        },
        {
            "instance_id": "R33581xR33198",
            "comparison_id": "R33581",
            "paper_id": "R33198",
            "text": "Understanding supply chain management: critical research and a theoretical framework increasing global cooperation, vertical disintegration and a focus on core activities have led to the notion that firms are links in a networked supply chain. this strategic viewpoint has created the challenge of coordinating effectively the entire supply chain, from upstream to downstream activities. while supply chains have existed ever since businesses have been organized to bring products and services to customers, the notion of their competitive advantage, and consequently supply chain management (scm), is a relatively recent thinking in management literature. although research interests in and the importance of scm are growing, scholarly materials remain scattered and disjointed, and no research has been directed towards a systematic identification of the core initiatives and constructs involved in scm. thus, the purpose of this study is to develop a research framework that improves understanding of scm and stimulates and facilitates researchers to undertake both theoretical and empirical investigation on the critical constructs of scm, and the exploration of their impacts on supply chain performance. to this end, we analyse over 400 articles and synthesize the large, fragmented body of work dispersed across many disciplines such as purchasing and supply, logistics and transportation, marketing, organizational dynamics, information management, strategic management, and operations management literature.",
            "contribution_ids": [
                "R33199"
            ]
        },
        {
            "instance_id": "R33581xR33163",
            "comparison_id": "R33581",
            "paper_id": "R33163",
            "text": "Critical success factors in agile supply chain management \u00e2\u0080\u0090 An empirical study this paper analyses results from a survey of 962 australian manufacturing companies in order to identify some of the factors critical for successful agile organizations in managing their supply chains. analysis of the survey results provided some interesting insights into factors differentiating \u201cmore agile\u201d organizations from \u201cless agile\u201d organizations. \u201cmore agile\u201d companies from this study can be characterized as more customer focused, and applying a combination of \u201csoft\u201d and \u201chard\u201d methodologies in order to meet changing customer requirements. they also see the involvement of suppliers in this process as being crucial to their ability to attain high levels of customer satisfaction. the \u201cless agile\u201d group, on the other hand, can be characterized as more internally focused with a bias toward internal operational outcomes. they saw no link between any of the independent variables and innovation, and appear to see technology as more closely linked to the promotion of these operational outcomes than to customer satisfaction. the role of suppliers for this group is to support productivity and process improvement rather than to promote customer satisfaction.",
            "contribution_ids": [
                "R33164"
            ]
        },
        {
            "instance_id": "R33581xR33223",
            "comparison_id": "R33581",
            "paper_id": "R33223",
            "text": "Successful use of e\u00e2\u0080\u0090procurement in supply chains purpose electronic support of internal supply chains for direct or production goods has been a major element during the implementation of enterprise resource planning (erp) systems that has taken place since the late 1980s. however, supply chains to indirect material suppliers were not usually included due to low transaction volumes, low product values and low strategic importance of these goods. dedicated information systems for streamlining indirect goods supply chains have emerged since the late 1990s and subsequently have faced a broad diffusion in practice. the concept of these e\u2010procurement solutions has also been described broadly in the literature. however, studies on how companies use these e\u2010procurement solutions and what factors are critical to their implementation are only emerging. this research aims to explore the introduction of e\u2010procurement systems and their contribution to the management of indirect goods supply chain. design/methodology/approach chooses a two\u2010part qualitative approach. first, summarizes the results of a benchmarking study that was conducted by a consortium of 12 multinational companies. during the benchmarking process 120 questionnaires were distributed, ten phone\u2010based interviews were conducted, and finally five successful practice companies were selected and analyzed in detail. second, draws together the success factors identified in the benchmarking study and maps them against the successful practice companies. findings although e\u2010procurement has substantially streamlined the procurement and coordination processes for indirect goods, many companies operate multiple e\u2010procurement solutions. for integrated procurement solutions, the paper recognizes the need of an overall procurement strategy and organization, an alignment of various e\u2010procurement solutions along the procurement process and the need for integrated system architectures. companies also have to realize that a no standardized e\u2010procurement solutions exists and that important success factors are \u201cnon\u2010technical\u201d in nature. originality/value this paper presents a first step towards a systematic analysis of factors that may guide companies in the implementation of e\u2010procurement solutions. besides providing a direct contribution to the project work in companies it may stimulate further research in e\u2010procurement success factors.",
            "contribution_ids": [
                "R33224"
            ]
        },
        {
            "instance_id": "R33783xR33725",
            "comparison_id": "R33783",
            "paper_id": "R33725",
            "text": "Neural Network Hysteresis Control of three-phase Switched Capacitor Active Power Filter \"the switched capacitor active filter is different from the traditional active filter. it removes the requirement for a large current or voltage source, which leads to the reduction in cost and in physical size. a control method that combines the neural network technology with the hysteresis band technology is presented. through training the neural network can learn the control rules by itself and can replace the real hysteresis comparator in power converter control. the computer simulation results show this filter's advantage.\"",
            "contribution_ids": [
                "R33726",
                "R33776"
            ]
        },
        {
            "instance_id": "R33783xR33721",
            "comparison_id": "R33783",
            "paper_id": "R33721",
            "text": "Compensation Current of Active Power Filter Generated by Artificial Neural Network Approach the semiconductor switches are presented in many applications and they can be considered the main source of harmonic distortion presented in the electrical power system. the use of filters - active or passive - has played an important role in order to minimize the harmonic effects injected in the power system. the proposal of this work is to present an alternative approach to estimate the harmonic content of a single-phase system with non-linear loads. it uses artificial neural networks to determine the compensation current. the system is composed of ac single-phase controllers and parallel active power filter. simulation results are presented to validate the proposed approach",
            "contribution_ids": [
                "R33722",
                "R33774"
            ]
        },
        {
            "instance_id": "R33783xR33659",
            "comparison_id": "R33783",
            "paper_id": "R33659",
            "text": "The Harmonic Currents Detecting Algorithm Based on Adaptive Neural Network in order to decrease the harmonics and improve the power factors in power system, a detecting algorithm of harmonics and reactive currents based on neural networks and adaptive noise canceling technology is proposed. the structure of neural network and the adaptive weights adjusting algorithm are presented. the contradiction of the detecting speed and the precision has been settled preferably. the proposed algorithm is simulated for detecting the harmonics and the reactive currents of` active power filters, simulation results show that both the tracking speed and steady state error have good effects. the base wave current can be detected in half a period and the steady state error is better. it is benefit to the detecting of harmonics and reactive currents of active power filters in power system.",
            "contribution_ids": [
                "R33660",
                "R33743"
            ]
        },
        {
            "instance_id": "R33783xR33671",
            "comparison_id": "R33783",
            "paper_id": "R33671",
            "text": "Current Harmonic Compensation by a Single-Phase Shunt Active Power Filter Controlled by Adaptive Neural Filtering \"this paper presents a single-phase shunt active power filter (apf) for current harmonic compensation based on neural filtering. the shunt active filter, realized by a current-controlled inverter, has been used to compensate a nonlinear current load by receiving its reference from a neural adaptive notch filter. this is a recursive notch filter for the fundamental grid frequency (50 hz) and is based on the use of a linear adaptive neuron (adaline). the filter's parameters are made adaptive with respect to the grid frequency fluctuations. a phase-locked loop system is used to extract the fundamental component from the coupling point voltage and to estimate the actual grid frequency. the current control of the inverter has been performed by a multiresonant controller. the estimated grid frequency is fed to the neural adaptive filter and to the multiresonant controller. in this way, the inverter creates a current equal in amplitude and opposite in sign to the load harmonic current, thus producing an almost sinusoidal grid current. an automatic tuning of the multiresonant controller is implemented, which recognizes the largest three harmonics of the load current to be compensated by the apf. the stability analysis of the proposed control system is shown. the methodology has been applied in numerical simulations and experimentally to a properly devised test setup, also in comparison with the classic sinusoidal current control based on the p-q theory.\"",
            "contribution_ids": [
                "R33672",
                "R33749"
            ]
        },
        {
            "instance_id": "R33783xR33693",
            "comparison_id": "R33783",
            "paper_id": "R33693",
            "text": "Learning and adaptive techniques for harmonics compensation in power supply networks this paper compares different variants of the least mean squares (lms) algorithm. the objective consists in finding the best compromise between on-line learning and computational costs. indeed, an algorithm with low computational complexity for updating adalines weights is required for a real-time implementation of a modular neural active power filter (apf). this filtering scheme is inserted in an electric distribution system to identify and compensate for harmonic distortions. adaline learning schemes are used in two neural apf frameworks. the first one is a neural approach of the instantaneous power theory (ipt) where the instantaneous powers are decomposed in a linear manner and are learned on-line with adalines. the second one is a neural diphase currents method based on the dq-currents which are linearly decomposed and learned with adalines. the overall complexity of the neural frameworks is evaluated in terms of basic operators such as adders, multipliers, and signum functions. simulation and experimental results demonstrate the applicability of neural approaches for the control of apf frameworks for power quality improvement. the complexity of the neural apf frameworks are equivalent than methods based on the conventional instantaneous power theory (ipt), while their performances are superior.",
            "contribution_ids": [
                "R33694",
                "R33760"
            ]
        },
        {
            "instance_id": "R33783xR33717",
            "comparison_id": "R33783",
            "paper_id": "R33717",
            "text": "Adaptive Filtering for Unstable Power System Harmonics using Artificial Network conventional approaches for harmonics filtering usually employ either passive, active filtering techniques or hybrid filters. this paper proposes an adaptive harmonic filtering approach using a modified discrete hopfield network model. the advantage of the scheme is that it can extract the fundamental component of the distorted current and provide a suitable compensation current as the power harmonics may vary in amplitude and frequency from time to time. therefore, the time-variant harmonic environments in real-time machine systems can be adapted successfully. real-time performance experiments verify that the proposed scheme is feasible in term of real-time tracking, adaptive low frequency harmonics filtering, fast training and convergence speed.",
            "contribution_ids": [
                "R33718",
                "R33772"
            ]
        },
        {
            "instance_id": "R33783xR33681",
            "comparison_id": "R33783",
            "paper_id": "R33681",
            "text": "A Neural Networks-Based Method for Single-Phase Harmonic Content Identification a neural method is presented in this paper to identify the harmonic components of an ac controller. the components are identified by analyzing the single-phase current waveform. the method effectiveness is verified by applying it to an active power filter (apf) model dedicated to the selective harmonic compensation. simulation results using theoretical and experimental data are presented to validate the proposed approach.",
            "contribution_ids": [
                "R33682",
                "R33754"
            ]
        },
        {
            "instance_id": "R33783xR33719",
            "comparison_id": "R33783",
            "paper_id": "R33719",
            "text": "Synchronous Reference Frame Based Active Filter Current Reference Generation Using Neural Networks \"the increased use of nonlinear devices in industry has resulted in direct increase of harmonic distortion in the industrial power system in recent years. the significant harmonics are almost always 5th, 7th, 11th and the 13th with the 5th harmonic being the largest in most instances. active filter systems have been proposed to mitigate harmonic currents of the industrial loads. the most important requirement for any active filter is the precise detection of the individual harmonic component's amplitude and phase. fourier transform based techniques provide an excellent method for individual harmonic isolation, but it requires a minimum of two cycles of data for the analysis, does not perform well in the presence of subharmonics which are not integral multiples of the fundamental frequency and most importantly introduces phase shifts. to overcome these difficulties, this paper proposes a multilayer perceptron neural network trained with back-propagation training algorithm to identify the harmonic characteristics of the nonlinear load. the operation principle of the synchronous-reference-frame-based harmonic isolation is discussed. this proposed method is applied to a thyristor controlled dc drive to obtain the accurate amplitude and phase of the dominant harmonics. this technique can be integrated with any active filter control algorithm for reference generation\"",
            "contribution_ids": [
                "R33720",
                "R33773"
            ]
        },
        {
            "instance_id": "R33783xR33637",
            "comparison_id": "R33783",
            "paper_id": "R33637",
            "text": "Harmonic content extraction in converter waveforms using radial basis function neural networks (RBFNN) and p-q power theory in this paper radial basis function neural network (rbfnn) is used to extract total harmonics in converter waveforms. the methodology is based on p-q (real power-imaginary power) theory. the converter waveforms are analyzed and the harmonics over a wide operating range are extracted. the proposed rbfnn filtering training algorithms are based on an efficient training method called hybrid learning method \u2014 computation is systematic. the method requires small size network, very robust, and the proposed algorithms are very effective. the analysis is verified using matlab/simulink simulation.",
            "contribution_ids": [
                "R33638",
                "R33732"
            ]
        },
        {
            "instance_id": "R33783xR33661",
            "comparison_id": "R33783",
            "paper_id": "R33661",
            "text": "The Study of the Electric Power Harmonics Detecting Method Based on the Immune RBF Neural Network nonlinear loads of the power system pour a lot of harmonics into the power network, and the harmonics endanger the power system and the safety of the electric power equipment. the power active wave filter provides a best sufficient method to restrain the harmonics. the key technique of the power active wave filter is the detecting the harmonics. this article makes a good research of astringency of the immune optimization and the bacterin extraction of the immune radial basis function network. it proposes to combine the immune optimization with the rbf neural network, developing a new method which is called the electric power harmonics current detecting method based on the immune rbf neural network. through the stimulating test, it is proved that this technique has the advantages of learning the speed of the astringent signal rapidly and higher precision. so, it can detect the harmonics of the current timely and precisely in the power network.",
            "contribution_ids": [
                "R33662",
                "R33744"
            ]
        },
        {
            "instance_id": "R33783xR33665",
            "comparison_id": "R33783",
            "paper_id": "R33665",
            "text": "A Power Harmonic Detection Method Based On Wavelet Neural Network \"harmonic detection technology is one of the key technologies used for active power filter (apf), and its development has determined the development of apf technology. it is difficult to detect the harmonic accurately because of the features of power network harmonic, such as inherent nonlinear, random, distribution, non-stationary and the complexity of impact factors, so the study of the power system harmonic's detection methods is very important. this paper proposes a harmonic detection method based on wavelet neural network combining wavelet with neural network, and designs for the wavelet neural network. the simulation results show that this method can detect the power network harmonic accurately and real-time.\"",
            "contribution_ids": [
                "R33666",
                "R33746"
            ]
        },
        {
            "instance_id": "R33783xR33657",
            "comparison_id": "R33783",
            "paper_id": "R33657",
            "text": "Study on Improved Neural Network PID Control of APF DC Voltage according to the active power balance principle, the paper analyzed the approximate mathematical model of apf. in order to optimize the control effect of dc bus voltage in apf, pid control method based on improved bp neural network is adopted to do closed-loop control to the system. the two strategies, adding momentum method and adaptive learning rate adjustment, are combined to improve bp network, which can not only effectively suppress the network appearing local minimum but also good to shorten learning time and improve stability of the network furthermore. the improved bp network adjusted the parameters such as kp and ki of pid controller according to the operation state of the system and realized optimum pid control. the experiment studies show that on condition of load power and harmonic content changing, apf system, controlled by pid control method based on improved bp network, can assure the harmonic distortion keeps in an allowed range and the dc side voltage becomes stable in a short time.",
            "contribution_ids": [
                "R33658",
                "R33742"
            ]
        },
        {
            "instance_id": "R33783xR33703",
            "comparison_id": "R33783",
            "paper_id": "R33703",
            "text": "Power System Harmonic Estimation Using Neural Networks the increasing application of power electronic facilities in the industrial environment has led to serious concerns about source line pollution and the resulting impacts on system equipment and power distribution systems. consequently, active power filters (apfs) have been used as an effective way to compensate harmonic components in nonlinear loads. obviously, fast and precise harmonic detection is one of the key factors to design apfs. various digital signal analysis techniques are being used for the measurement and estimation of power system harmonics. presently, neural network has received special attention from the researchers because of its simplicity, learning and generalization ability. this paper presents a neural network-based algorithm that can identify both in magnitude and phase of harmonics. experimental results have testified its performance with a variety of generated harmonies and interharmonics. comparison with the conventional dft method is also presented to demonstrate its very fast response and high accuracy.",
            "contribution_ids": [
                "R33704",
                "R33765"
            ]
        },
        {
            "instance_id": "R33783xR33715",
            "comparison_id": "R33783",
            "paper_id": "R33715",
            "text": "Neural-Network-Based Inverse Control Method for Active Power Filter System a new type of active power filter (apf) is described. a multi-layered neural network based inverse control method for this apf system is proposed. the functioning of the apf system is based on a switching network whose characteristics are nonlinear. the characteristic of the switching on-off time of the switching network and the output current of the apf was demonstrated. the switching on-off time can be instantaneously calculated by using the neural-network-based inverse control algorithm proposed. the neural network was designed. an all digital control way may be realized by using the algorithm. the validation of the results of inverse control for apf is proposed as well",
            "contribution_ids": [
                "R33716",
                "R33771"
            ]
        },
        {
            "instance_id": "R33783xR33669",
            "comparison_id": "R33783",
            "paper_id": "R33669",
            "text": "Harmonic elimination and reactive power compensation through a shunt active power filter by twin neural networks with predictive and adaptive properties a method for controlling an active power filter using artificial neural network(ann) is presented in this paper. this paper applies ann based predictive and adaptive reference generation technique. predictive scheme extracts the information of the fundamental component through an ann that replaces a low pass filter. this ann based low pass-filter is trained offline with large number of training set to predict the fundamental magnitude of load current. this predictive reference generation technique works well for clean source voltage. however, the performance deteriorates in case of distortion in source voltage and also with noise. to overcome this, an adaline based ann is applied after the operation of the predictive algorithm. it has been shown that the combined predictive-adaptive approach offers better performance. simulation results and experimental results are presented to confirm the usefulness of the proposed technique..",
            "contribution_ids": [
                "R33670",
                "R33748"
            ]
        },
        {
            "instance_id": "R33783xR33707",
            "comparison_id": "R33783",
            "paper_id": "R33707",
            "text": "Harmonic Detection Based on Artificial Neural Networks for Current Distortion Compensation in this paper a method for the determination of part of the current harmonic components for the selective compensation harmonic by single-phase active power filter is presented. the non-linear load is composed by an ac controller with variable resistive load. the first six components are identified through artificial neural network. the effectiveness of the proposed method and its application in the single-phase active power filters with selective harmonic compensation are verified. simulation results are presented to validate the proposed approach.",
            "contribution_ids": [
                "R33708",
                "R33767"
            ]
        },
        {
            "instance_id": "R33783xR33649",
            "comparison_id": "R33783",
            "paper_id": "R33649",
            "text": "A Novel Hysteresis Current Control Strategy Based on Neural Network the relationship among principle of variable-band hysteresis current control, compensation capacity of hysteresis and switching frequency is dissertated in this paper. aimed at changing the disadvantages of variable-band current control strategy resulted from the fuzzy controller, a control strategy based on command current and current error is proposed and realized by neural network. power electronics model is built by matlab and psim and logical control circuit is built according to the fuzzy rules and neural network respectively. co-simulation results indicate that the hysteresis based on neural network controller has better compensation capacity than the hysteresis based on fuzzy controller and reduces switching frequency.",
            "contribution_ids": [
                "R33650",
                "R33738"
            ]
        },
        {
            "instance_id": "R33783xR33683",
            "comparison_id": "R33783",
            "paper_id": "R33683",
            "text": "An ANN based Digital Controller for a Three-phase Active Power Filter three-phase shunt active power filters are designed to effectively compensate for the current harmonics and reactive power requirements in a three-phase system with harmonic loads. an ann (artificial neural network) based controller selects the amount of harmonic current injection based on the percentage of harmonic distortion present in the source current and also on the reactive power requirement of the load. the selection is done by the ann with the help of a properly tuned knowledge base.",
            "contribution_ids": [
                "R33684",
                "R33755"
            ]
        },
        {
            "instance_id": "R33783xR33697",
            "comparison_id": "R33783",
            "paper_id": "R33697",
            "text": "An Artificial Neural Network Based Method for Harmonic Detection in power system a novel advanced harmonic detection method based on neural network (nn) is proposed in this paper. it is an adaptive harmonic detection method with variable step-size based on adaptive linear nn and self-adaptive noise countervailing principle. and this proposed method adopts a sliding integrator to extract the real tracing error and then uses a fuzzy adjuster with self-adjustable factor to modify the step-size. so the novel harmonic detection method can obtain fast convergence speed and high steady-state precision at the same time. comparisons are made between conventional harmonic detection methods based on nn and the advanced method based on nn proposed in this paper. finally detailed simulation and experimental results verify the validity and superiority of the advanced methods.",
            "contribution_ids": [
                "R33698",
                "R33762"
            ]
        },
        {
            "instance_id": "R33783xR33695",
            "comparison_id": "R33783",
            "paper_id": "R33695",
            "text": "Harmonic and reactive power compensation with artificial neural network technology this paper presents a new method for harmonic and reactive power compensation with an artificial neural network (ann) controller and a new control algorithm for active power filter (apf) to eliminate harmonics and compensate the reactive power of a three-phase thyristor bridge rectifier. the artificial neural network (ann) current controller is adapted to active power filter (apf) and the current controller based on modified hysteresis current controller is used to generate the firing pulses. all of the studies have been carried out using the detail digital dynamic simulation with the matlab simulink power system toolbox. the results of simulation study of new apf control technique and algorithm presented in this paper are found quite satisfactory to eliminate harmonics and reactive power components from utility current.",
            "contribution_ids": [
                "R33696",
                "R33761"
            ]
        },
        {
            "instance_id": "R33783xR33673",
            "comparison_id": "R33783",
            "paper_id": "R33673",
            "text": "Neural Network and Bandless Hysteresis Approach to Control Switched Capacitor Active Power Filter for Reduction of Harmonics \"this paper proposes a combination of neural network and a bandless hysteresis controller, for a switched capacitor active power filter (scapf), to improve line power factor and to reduce line current harmonics. the proposed active power filter controller forces the supply current to be sinusoidal, in phase with line voltage, and has low current harmonics. two main controls are proposed for it: neural network detection of harmonics and bandless digital hysteresis switching algorithm. a mathematical algorithm and a suitable learning rate determine the filter's optimal operation. a digital signal controller (tms320f2812) verifies the proposed scapf, implementing the neural network and bandless hysteresis algorithms. a laboratory scapf system is built to test its feasibility. simulation and experimental results are provided to verify performance of the proposed scapf system.\"",
            "contribution_ids": [
                "R33674",
                "R33750"
            ]
        },
        {
            "instance_id": "R33783xR33667",
            "comparison_id": "R33783",
            "paper_id": "R33667",
            "text": "Neuron adaptive control of a shunt active power filter and its realization of analog circuit there have been a number of harmonic current detecting methods for the active power filter (apf), including the filtration approach by fixed frequency filters, the composition method of the imaginary and the real power based on the instantaneous reactive power theory, and so on. in this paper, first according to the adaptive noise canceling technology (anct) in signal processing, an adaptive detecting approach of harmonic current based on a neuron is presented. next, on the basis of the configuration and learning algorithm for the developed system, the realization scheme of an analog circuit of the system is discussed. third, in the light of psim software, the computer simulation studies of the circuit are done. finally, the performance and feasibility of the approach are tested and verifified by the simulation results.",
            "contribution_ids": [
                "R33668",
                "R33747"
            ]
        },
        {
            "instance_id": "R33783xR33641",
            "comparison_id": "R33783",
            "paper_id": "R33641",
            "text": "A Comparative Experimental Study of Neural and Conventional Controllers for an Active Power Filter \"this paper will consider the benefits of neural controllers over model-based current regulators to supervise the current generation of a shunt active power filter. the task consists in generating appropriate compensation currents with a system composed of a voltage source inverter and a low-pass filter. these currents cancel the harmonic terms introduced by nonlinear loads in a power distribution grid. the performances of conventional controllers such as a pi and resonant current regulators are confronted to neural controllers. if conventional regulators present some advantages in terms of engineering specifications, their tuning remains difficult and their design relies on a rough linearization of the system. their performances are acceptable without perturbations. however, fast changes of nonlinear loads lead to different operating points of the system. furthermore, the inverter's nonlinearities and low-pass filter parameters have to be considered for generating precise currents. two neural approaches have therefore been proposed, one which estimates the input-output relationship of the system, and one which relies on a state-space representation of the system. these approaches combine learning capabilities with a priori knowledge of the system. the benefits of the neural approaches are discussed and illustrated by simulations and by experimental tests with real-time implementations on a digital signal processing board.\"",
            "contribution_ids": [
                "R33642",
                "R33734"
            ]
        },
        {
            "instance_id": "R33783xR33691",
            "comparison_id": "R33783",
            "paper_id": "R33691",
            "text": "Intelligent Control and Application of All-Function Active Power Filter an all-function active power filter which can compensate harmonics inter-harmonics, asymmetries, fundamental sequence reactive powers and so on is introduced in this paper. its basic concept and main features working process are illuminated briefly. to solve the difficulty problem of control for all-function active power filter, its intelligent control strategy and working process based on bp neural network are expounded. first, basic theory of bp neural network to control all-function active power is analyzed. then, the basic configuration and working process of an all-function active power filter based on bp neural network control strategy is detailed. finally, simulations and simulative results are given. theory analysis and the simulative results show that the intelligent control strategy based on bp neural network can make all-function active power filter in possession of full function and predominant working characteristics.",
            "contribution_ids": [
                "R33692",
                "R33759"
            ]
        },
        {
            "instance_id": "R33783xR33653",
            "comparison_id": "R33783",
            "paper_id": "R33653",
            "text": "Neural Network Control Techniques of Hybrid Active Power Filter a multi-object optimization approach was developed for the design of hybrid active power filters (hapf) to give better mitigation of the harmonics and better reactive power compensation. the neural network technique was used with optimization theory to improve the algorithm precision and stability. the optimization is more effective since the performance goals and optimization parameters were optimized together. secondly, this paper presents the design of a hierarchical fuzzy current control scheme for a shunt active power filter compared with a single fuzzy controller scheme. it provides superior current tracking capability and switch frequency signal is limit in the permit range. finally, many simulations and experimental result demonstrate the validity of the theory.",
            "contribution_ids": [
                "R33654",
                "R33740"
            ]
        },
        {
            "instance_id": "R33783xR33687",
            "comparison_id": "R33783",
            "paper_id": "R33687",
            "text": "Artificial Neural Networks to Control an Inverter in a Harmonic Distortion Compensation Scheme in this paper, two efficient and reliable neural approaches to control an inverter are developed. the objective is to improve the compensation performance of a conventional active power filter (apf) with a homogeneous neural structure allowing an efficient hardware implementation. the first control approach is based on a neural pi regulator. this technique uses an adaline to determine the pi parameters. the second control approach is a direct inverse control method. it uses two multilayer neural networks with the backpropagation learning in order to identify the jacobian of the process and to control the inverter. the originality lies in the error signal used for the weight adaption in the first approach, and in the choice of the inputs of the neural networks in the second approach. the performance of the two methods is evaluated through simulation and experimental results and demonstrates the effectiveness of the proposed neural approaches.",
            "contribution_ids": [
                "R33688",
                "R33757"
            ]
        },
        {
            "instance_id": "R33783xR33679",
            "comparison_id": "R33783",
            "paper_id": "R33679",
            "text": "Artificial neural networks for harmonic currents identification in active power filtering schemes this paper presents a new harmonic currents identification method called neural synchronous method and based on artificial neural networks. its theoretical aspect relies on a new decomposition of the load current signals. adaline neural networks are used in order to learn this decomposition on-line; the fundamental currents can therefore be estimated at each sampling time. the fundamental currents are then synchronized with the direct component of the voltage obtained by a pll (phase locked loop). the harmonic currents are deduced and re-injected phase-opposite in the power distribution system through an active power filtering scheme. this harmonic currents identification method is compared to other similar methods by simulation results.",
            "contribution_ids": [
                "R33680",
                "R33753"
            ]
        },
        {
            "instance_id": "R33783xR33705",
            "comparison_id": "R33783",
            "paper_id": "R33705",
            "text": "Single-Phase Shunt Hybrid Active Power Filter Based on ANN in this paper, a single-phase shunt hybrid active power filter (apf) is presented to compensate reactive power and eliminate harmonics in power system. the hybrid active filter consists of one active filter and one passive filter connected in series. by controlling the equivalent output voltage of active filter, the harmonic currents generated by the nonlinear load are blocked and flowed into the passive filter. sensing load current, dc bus voltage, dc bus reference voltage and source voltage compute reference voltage of apf through modified adaptive artificial neural network (ann). and a voltage controller is used to generate the firing pulses of the voltage source inverter. the proposed system is implemented using digital signal processor (dsp). simulating results are presented to confirm the validity of the scheme.",
            "contribution_ids": [
                "R33706",
                "R33766"
            ]
        },
        {
            "instance_id": "R33783xR33639",
            "comparison_id": "R33783",
            "paper_id": "R33639",
            "text": "Harmonic estimation using Modified ADALINE algorithm with Time-Variant Widrow \u0014 Hoff (TVWH) learning rule algorithms are well developed for adaptive estimation of selected harmonic components in digital signal processing. in power electronic applications, objectives like fast response of a system is of primary importance. an effective active power filtering for estimation of instantaneous harmonic components is presented in this paper. a signal processing technique using modified adaptive neural network (modified ann) algorithm has been proposed for harmonic estimation. its primary function is to estimate harmonic components from selected signal (current or voltage) and it requires only the knowledge of the frequency of the component to be estimated. this method can be applied to a wide range of equipments. the validity of the proposed method to estimate voltage harmonics is proved with a dc/ac inverter as an example and the simulation results are compared with adaline algorithm for illustrating its effectiveness.",
            "contribution_ids": [
                "R33640",
                "R33733"
            ]
        },
        {
            "instance_id": "R33783xR33727",
            "comparison_id": "R33783",
            "paper_id": "R33727",
            "text": "Artificial Neural Network Controlled Shunt Active Power Filter this paper presents neural based proportional integral (pi) control applicable for active power filters for single-phase system, which are comprised of multiple nonlinear loads. the system consists of an uncontrolled rectifier and ac controller as the non-linear loads, with an active filter to compensate for the harmonic current injected by the load. the active filter is based on a single-phase inverter with four controllable switches, a standard h-bridge inverter. the ac side of the inverter is connected in parallel with the other nonlinear loads through a filter inductance. the dc side of the inverter is connected to a filter capacitor. the neural pi controller is used to shape the current through the filter inductor such that the line current is in phase with and of the same shape as the input voltage. the spectral analysis of the supply current shows the harmonics produced by the load has been successfully compensated by the active filter. the system is modeled in matlab simulink and simulation results prove that the injected harmonics are greatly reduced and system efficiency and power factor are improved",
            "contribution_ids": [
                "R33728",
                "R33777"
            ]
        },
        {
            "instance_id": "R33783xR33701",
            "comparison_id": "R33783",
            "paper_id": "R33701",
            "text": "Harmonic Components Identification through the Adaline with Fuzzy Learning Parameter identification of different harmonic components of current/voltage signals is required in many power system applications e.g. power quality monitoring, active power filtering, and digital system protection. in this paper, a method based on the adaptive linear combiner (adaline) is presented for harmonic components identification. the convergence speed and the estimation error of the adaline are governed by the learning parameter (lp) in the weight adaptation rule of this artificial neural network. thus, instead of a constant lp utilized in the conventional adaline, this paper proposes the implementation of a fuzzy inference system (fis) for suitable adjustment of the lp. two simulation studies are conducted on the matlab and pscad/emtdc to show the validity and performance of the proposed method.",
            "contribution_ids": [
                "R33702",
                "R33764"
            ]
        },
        {
            "instance_id": "R33783xR33677",
            "comparison_id": "R33783",
            "paper_id": "R33677",
            "text": "Voltage source inverter control with Adaline approach for the compensation of harmonic currents in electrical power systems this paper presents a complete strategy for harmonics identification and neural control of a three-phase voltage inverter used for the power active filtering. based on the use of neural techniques, this approach of compensation is done in two stages. the first stage extracts the harmonic currents with the diphase currents method by using adaline neural networks. the second stage injects the harmonic currents in the electrical supply network; it uses a control based on a pi-neural controller. our approach is automatically able to adapt itself to any change of the non-linear load and thus to the harmonic currents generated. furthermore, comparisons with hysteresis control and results of application of a conventional low-pass filter for harmonics identification are presented. the proposed neural compensation approach has been evaluated in simulations. the results show excellent behaviours and performances, as well as robustness and usefulness.",
            "contribution_ids": [
                "R33678",
                "R33752"
            ]
        },
        {
            "instance_id": "R33783xR33635",
            "comparison_id": "R33783",
            "paper_id": "R33635",
            "text": "A Shunt Active Power Filter With Enhanced Performance Using ANN-Based Predictive and Adaptive Controllers this paper attempts to improve the dynamic performance of a shunt-type active power filter. the predictive and adaptive properties of artificial neural networks (anns) are used for fast estimation of the compensating current. the dynamics of the dc-link voltage is utilized in a predictive controller to generate the first estimate followed by convergence of the algorithm by an adaptive ann (adaline) based network. weights in adaline are tuned to minimize the total harmonic distortion of the source current. extensive simulations and experimentations confirm the validity of the proposed scheme for all kinds of load (balanced and unbalanced) for a three-phase three-wire system.",
            "contribution_ids": [
                "R33636",
                "R33731"
            ]
        },
        {
            "instance_id": "R33783xR33643",
            "comparison_id": "R33783",
            "paper_id": "R33643",
            "text": "Neural network based active power filter for power quality improvement in this paper, a neural network based reference current computation method for active power filter (apf) control under non-ideal mains voltage with different load condition is proposed. the neural network controller has been designed to extract fundamental frequency components from non-sinusoidal and unbalanced currents. these fundamental frequency components will be used as unit templates. the apf realized by a current controlled igbt based pwm-vsi bridges with a common dc bus capacitor. current controller based on pulse width modulation with suitable carrier frequency is used to generate the firing pulse. the proposed neural network reference generation approach has been evaluated in simulations. the results show excellent performance, as well as robustness and usefulness of the system.",
            "contribution_ids": [
                "R33644",
                "R33735"
            ]
        },
        {
            "instance_id": "R33851xR33802",
            "comparison_id": "R33851",
            "paper_id": "R33802",
            "text": "Assessment of algorithms for high throughput detection of genomic copy number variation in oligonucleotide microarray data abstract \\n \\n background \\n genomic deletions and duplications are important in the pathogenesis of diseases, such as cancer and mental retardation, and have recently been shown to occur frequently in unaffected individuals as polymorphisms. affymetrix genechip whole genome sampling analysis (wgsa) combined with 100 k single nucleotide polymorphism (snp) genotyping arrays is one of several microarray-based approaches that are now being used to detect such structural genomic changes. the popularity of this technology and its associated open source data format have resulted in the development of an increasing number of software packages for the analysis of copy number changes using these snp arrays. \\n \\n \\n results \\n we evaluated four publicly available software packages for high throughput copy number analysis using synthetic and empirical 100 k snp array data sets, the latter obtained from 107 mental retardation (mr) patients and their unaffected parents and siblings. we evaluated the software with regards to overall suitability for high-throughput 100 k snp array data analysis, as well as effectiveness of normalization, scaling with various reference sets and feature extraction, as well as true and false positive rates of genomic copy number variant (cnv) detection. \\n \\n \\n conclusion \\n we observed considerable variation among the numbers and types of candidate cnvs detected by different analysis approaches, and found that multiple programs were needed to find all real aberrations in our test set. the frequency of false positive deletions was substantial, but could be greatly reduced by using the snp genotype information to confirm loss of heterozygosity. \\n",
            "contribution_ids": [
                "R33803"
            ]
        },
        {
            "instance_id": "R33851xR33815",
            "comparison_id": "R33851",
            "paper_id": "R33815",
            "text": "Comparative analyses of seven algorithms for copy number variant identification from single nucleotide polymorphism arrays determination of copy number variants (cnvs) inferred in genome wide single nucleotide polymorphism arrays has shown increasing utility in genetic variant disease associations. several cnv detection methods are available, but differences in cnv call thresholds and characteristics exist. we evaluated the relative performance of seven methods: circular binary segmentation, cnvfinder, cnvpartition, gain and loss of dna, nexus algorithms, penncnv and quantisnp. tested data included real and simulated illumina humhap 550 data from the singapore cohort study of the risk factors for myopia (scorm) and simulated data from affymetrix 6.0 and platform-independent distributions. the normalized singleton ratio (nsr) is proposed as a metric for parameter optimization before enacting full analysis. we used 10 scorm samples for optimizing parameter settings for each method and then evaluated method performance at optimal parameters using 100 scorm samples. the statistical power, false positive rates, and receiver operating characteristic (roc) curve residuals were evaluated by simulation studies. optimal parameters, as determined by nsr and roc curve residuals, were consistent across datasets. quantisnp outperformed other methods based on roc curve residuals over most datasets. nexus rank and snprank have low specificity and high power. nexus rank calls oversized cnvs. penncnv detects one of the fewest numbers of cnvs.",
            "contribution_ids": [
                "R33816"
            ]
        },
        {
            "instance_id": "R33851xR33808",
            "comparison_id": "R33851",
            "paper_id": "R33808",
            "text": "Comparing CNV detection methods for SNP arrays data from whole genome association studies can now be used for dual purposes, genotyping and copy number detection. in this review we discuss some of the methods for using snp data to detect copy number events. we examine a number of algorithms designed to detect copy number changes through the use of signal-intensity data and consider methods to evaluate the changes found. we describe the use of several statistical models in copy number detection in germline samples. we also present a comparison of data using these methods to assess accuracy of prediction and detection of changes in copy number.",
            "contribution_ids": [
                "R33809"
            ]
        },
        {
            "instance_id": "R33851xR33827",
            "comparison_id": "R33851",
            "paper_id": "R33827",
            "text": "Assessment of copy number variation using the Illumina Infinium 1M SNP-array: A comparison of methodological approaches in the Spanish Bladder Cancer/EPICURO study high\u2010throughput single nucleotide polymorphism (snp)\u2010array technologies allow to investigate copy number variants (cnvs) in genome\u2010wide scans and specific calling algorithms have been developed to determine cnv location and copy number. we report the results of a reliability analysis comparing data from 96 pairs of samples processed with cnvpartition, penncnv, and quantisnp for infinium illumina human 1million probe chip data. we also performed a validity assessment with multiplex ligation\u2010dependent probe amplification (mlpa) as a reference standard. the number of cnvs per individual varied according to the calling algorithm. higher numbers of cnvs were detected in saliva than in blood dna samples regardless of the algorithm used. all algorithms presented low agreement with mean kappa index (ki) 0.62). our results indicate that the current calling algorithms should be improved for high performance cnv analysis in genome\u2010wide scans. further refinement is required to assess cnvs as risk factors in complex diseases.hum mutat 32:1\u201310, 2011. \u00a9 2011 wiley\u2010liss, inc.",
            "contribution_ids": [
                "R33828"
            ]
        },
        {
            "instance_id": "R33953xR33877",
            "comparison_id": "R33953",
            "paper_id": "R33877",
            "text": "IntelligenTester - Software Test Sequence Optimization Using Graph Based Intelligent Search Agent due to the abundantly available imaging technologies, manipulation of digital images has become a serious problem nowadays, in various fields like medical imaging, digital forensics, journalism, scientific publications, etc. in this paper, we concentrate on detection of a specific category of digital image forgery known as region duplication forgery or copy-move forgery, which is done by copying a block of an image and pasting it on to some other block of the same image. we present a novel approach based on the application of wavelet transform that detects and localizes such forgeries. our technique works by first applying wavelet transform to the input image to yield a reduced dimension representation. we then perform exhaustive search to identify the similar blocks in the image by mapping them to log-polar coordinates and using phase correlation as the similarity criterion. this is done only once at the lowest resolution of the wavelet transform. only the matched blocks are carried for comparison to the next level. this drastically reduces the time needed for the detection process. this approach works even if the pasted region has undergone transformations like translation and rotation.",
            "contribution_ids": [
                "R33878"
            ]
        },
        {
            "instance_id": "R33953xR33884",
            "comparison_id": "R33953",
            "paper_id": "R33884",
            "text": "Generating Method of Pair-wise Covering Test Data Based on ACO optimizing test suite can reduce the cost of time and resources, and improve the efficiency of regression test when test cases are generated. the generation of pair-wise covering test data is an np question, which can be solved by heuristic method, greedy arithmetic and algebra method at present. in this paper, ant colony arithmetic is adopted, which is a new way to solve the pair-wise test data generating question. it can generate fewer test cases which can cover more pair combinations,and can solve questions with fast calculate speed. the method can get the goal of optimizing in the process of regression test. the result shows that the method is feasible.",
            "contribution_ids": [
                "R33885"
            ]
        },
        {
            "instance_id": "R33953xR33888",
            "comparison_id": "R33953",
            "paper_id": "R33888",
            "text": "A Non- Pheromone based Intelligent Swarm Optimization Technique in Software Test Suite Optimization in our paper, we applied a non-pheromone based intelligent swarm optimization technique namely artificial bee colony optimization (abc) for test suite optimization. our approach is a population based algorithm, in which each test case represents a possible solution in the optimization problem and happiness value which is a heuristic introduced to each test case corresponds to the quality or fitness of the associated solution. the functionalities of three groups of bees are extended to three agents namely search agent, selector agent and optimizer agent to select efficient test cases among near infinite number of test cases. because of the parallel behavior of these agents, the solution generation becomes faster and makes the approach an efficient one. since, the test adequacy criterion we used is path coverage; the quality of the test cases is improved during each iteration to cover the paths in the software. finally, we compared our approach with ant colony optimization (aco), a pheromone based optimization technique in test suite optimization and finalized that, abc based approach has several advantages over aco based optimization.",
            "contribution_ids": [
                "R33889"
            ]
        },
        {
            "instance_id": "R33953xR33924",
            "comparison_id": "R33953",
            "paper_id": "R33924",
            "text": "Structured Testing Using Ant Colony Optimization structural testing is one of the most widely used testing paradigms to test software. the aim of this paper is to present a simple and efficient algorithm that can automatically generate all possible paths in a control flow graph for structural testing. pheromone releasing behavior of ants is used in this algorithm for extracting optimal paths. this algorithm generates paths equal to the cyclomatic complexity.",
            "contribution_ids": [
                "R33925"
            ]
        },
        {
            "instance_id": "R33953xR33933",
            "comparison_id": "R33953",
            "paper_id": "R33933",
            "text": "Automatic Test Data Generation Based on Ant Colony Optimization software testing is a crucial measure used to assure the quality of software. path testing can detect bugs earlier because of it performs higher error coverage. this paper presents a model of generating test data based on an improved ant colony optimization and path coverage criteria. experiments show that the algorithm has a better performance than other two algorithms and improve the efficiency of test data generation notably.",
            "contribution_ids": [
                "R33934"
            ]
        },
        {
            "instance_id": "R33953xR33951",
            "comparison_id": "R33953",
            "paper_id": "R33951",
            "text": "Test Case Prioritization Using Ant Colony optimization,\u00e2\u0080\u009d Association in Computing Machinery regression testing is primarily a maintenance activity that is performed frequently to ensure the validity of the modified software. in such cases, due to time and cost constraints, the entire test suite cannot be run. thus, it becomes essential to prioritize the tests in order to cover maximum faults in minimum time. in this paper, ant colony optimization is used, which is a new way to solve time constraint prioritization problem. this paper presents the regression test prioritization technique to reorder test suites in time constraint environment along with an algorithm that implements the technique.",
            "contribution_ids": [
                "R33952"
            ]
        },
        {
            "instance_id": "R33953xR33912",
            "comparison_id": "R33953",
            "paper_id": "R33912",
            "text": "Optimized Test Sequence Generation from Usage Models using Ant Colony Optimization software testing is the process of testing the software in order to ensure that it is free of errors and produces the desired outputs in any given situation. model based testing is an approach in which software is viewed as a set of states. a usage model describes software on the basis of its statistical usage data. one of the major problems faced in such an approach is the generation of optimal sets of test sequences. the model discussed in this paper is a markov chain based usage model. the analytical operations and results associated with markov chains make them an appropriate choice for checking the feasibility of test sequences while they are being generated. the statistical data about the estimated usage has been used to build a stochastic model of the software under test. this paper proposes a technique to generate optimized test sequences from a markov chain based usage model. the proposed technique uses ant colony optimization as its basis and also incorporates factors like cost and criticality of various states in the model. it further takes into consideration the average number of visits to any state and the trade-off between cost considerations and optimality of the test coverage.",
            "contribution_ids": [
                "R33913"
            ]
        },
        {
            "instance_id": "R33953xR33931",
            "comparison_id": "R33953",
            "paper_id": "R33931",
            "text": "Generation of test data using Meta heuristic approach software testing is of huge importance to development of any software. the prime focus is to minimize the expenses on the testing. in software testing the major problem is generation of test data. several metaheuristic approaches in this field have become very popular. the aim is to generate the optimum set of test data, which would still not compromise on exhaustive testing of software. our objective is to generate such efficient test data using genetic algorithm and ant colony optimization for a given software. we have also compared the two approaches of software testing to determine which of these are effective towards generation of test data and constraints if any.",
            "contribution_ids": [
                "R33932"
            ]
        },
        {
            "instance_id": "R33953xR33939",
            "comparison_id": "R33953",
            "paper_id": "R33939",
            "text": "An Optimization Method of Test Suite in Regression Test Model original test cases should be reused and new ones should be supplemented in regression test. for optimizing test suite, pair-wise combination test cases generating method is adopted in this paper, which was realized by ant colony algorithm with monolepsis diagnostic. when original and new generated test suite was united, improved greedy arithmetic was adopted to reduce test suite and random off-trap strategy was introduced. the test case study result shows the method can reduce the scale of test suite effectively and decrease the regression test cost.",
            "contribution_ids": [
                "R33940"
            ]
        },
        {
            "instance_id": "R33953xR33943",
            "comparison_id": "R33953",
            "paper_id": "R33943",
            "text": "A New Software Data-Flow Testing Approach via Ant Colony Algorithms search-based optimization techniques (e.g., hill climbing, simulated annealing, and genetic algorithms) have been applied to a wide variety of software engineering activities including cost estimation, next release problem, and test generation. several search based test generation techniques have been developed. these techniques had focused on finding suites of test data to satisfy a number of control-flow or data-flow testing criteria. genetic algorithms have been the most widely employed search-based optimization technique in software testing issues. recently, there are many novel search-based optimization techniques have been developed such as ant colony optimization (aco), particle swarm optimization (pso), artificial immune system (ais), and bees colony optimization. aco and ais have been employed only in the area of control-flow testing of the programs. this paper aims at employing the aco algorithms in the issue of software data-flow testing. the paper presents an ant colony optimization based approach for generating set of optimal paths to cover all definition-use associations (du-pairs) in the program under test. then, this approach uses the ant colony optimization to generate suite of test-data for satisfying the generated set of paths. in addition, the paper introduces a case study to illustrate our approach. keywordsdata-flow testing; path-cover generation, test-data generation; ant colony optimization algorithms",
            "contribution_ids": [
                "R33944"
            ]
        },
        {
            "instance_id": "R33953xR33918",
            "comparison_id": "R33953",
            "paper_id": "R33918",
            "text": "Automated Software Testing Using Metaheuristic Technique Based on an Ant Colony Optimization software testing is an important and valuable part of the software development life cycle. due to time, cost and other circumstances, exhaustive testing is not feasible that\u2019s why there is a need to automate the testing process. testing effectiveness can be achieved by the state transition testing (stt) which is commonly used in real time, embedded and web-based kinds of software systems. the tester\u2019s main job to test all the possible transitions in the system. this paper proposed an ant colony optimization (aco) technique for the automated and full coverage of all state-transitions in the system. present paper approach generates test sequence in order to obtain the complete software coverage. this paper also discusses the comparison between two metaheuristic techniques (genetic algorithm and ant colony optimization) for transition based testing.",
            "contribution_ids": [
                "R33919"
            ]
        },
        {
            "instance_id": "R34099xR34014",
            "comparison_id": "R34099",
            "paper_id": "R34014",
            "text": "Dynamics of white perch Morone americana population contingents in the Patuxent River estuary, Maryland, USA alternative migratory pathways in the life histories of fishes can be difficult to assess but may have great importance to the dynamics of spatially structured populations. we used sr/ca in otoliths as a tracer of time spent in freshwater and brackish habitats to study the ontogenetic mov- ments of white perch morone americana in the patuxent river estuary. we observed that, soon after the larvae metamorphose, juveniles either move to brackish habitats (brackish contingent) or take up residency in tidal fresh water (freshwater contingent) for the first year of life. in one intensively stud- ied cohort of juveniles, the mean age at which individuals moved into brackish environments was 45 d (post-hatch), corresponding to the metamorphosis of lavae to juveniles and settlement in littoral habitats. back-calculated growth rates of the freshwater contingent at this same age (median = 0.6 mm d -1 ) were significantly higher than the brackish contingent (median = 0.5 mm d -1 ). strong year-class variability (>100-fold) was evident from juvenile surveys and from the age composition of adults sampled during spawning. adult samples were dominated by the brackish contingent (93% of n = 363), which exhibited a significantly higher growth rate (von bertalanffy, k = 0.67 yr -1 ) than the freshwater contingent (k = 0.39 yr -1 ). combined with evidence that the relative frequency of the brackish contingent has increased in year-classes with high juvenile recruitment, these results impli- cate brackish environments as being important for maintaining abundance and productivity of the population. by comparison, disproportionately greater recruitment to the adult population by the freshwater contingent during years of low juvenile abundance suggested that freshwater habitats sustain a small but crucial reproductive segment of the population. thus, both contingents appeared to have unique and complementary roles in the population dynamics of white perch.",
            "contribution_ids": [
                "R34015",
                "R34016"
            ]
        },
        {
            "instance_id": "R34099xR34039",
            "comparison_id": "R34099",
            "paper_id": "R34039",
            "text": "Stable isotope (\u00ce\u00b413C and \u00ce\u00b418O) and Sr/Ca composition of otoliths as proxies for environmental salinity experienced by an estuarine fish the ability to identify past patterns of salinity habitat use in coastal fishes is viewed as a critical development in evaluating nursery habitats and their role in population dynamics. the utility of otolith tracers (\u03b4 13 c, \u03b4 18 o, and sr/ca) as proxies for environmental salinity was tested for the estuarine-dependent juvenile white perch morone americana. analysis of water samples revealed a positive relationship between the salinity gradient and \u03b4 18 o, \u03b4 13 c, and sr/ca values of water in the patuxent river estuary. similarly, analysis of otolith material from young-of-the-year white perch (2001, 2004, 2005) revealed a positive relationship between salinity and otolith \u03b4 13 c, \u03b4 18 o, and sr/ca values. in classifying fish to their known salinity habitat, \u03b4 18 o and sr/ca were moderately accurate tracers (53 to 79% and 75% correct classification, respectively), and \u03b4 13 c provided near complete dis- crimination between habitats (93 to 100% correct classification). further, \u03b4 13 c exhibited the lowest inter-annual variability and the largest range of response across salinity habitats. thus, across estuaries, it is expected that resolution and reliability of salinity histories of juvenile white perch will be improved through the application of stable isotopes as tracers of salinity history.",
            "contribution_ids": [
                "R34040"
            ]
        },
        {
            "instance_id": "R34099xR34072",
            "comparison_id": "R34099",
            "paper_id": "R34072",
            "text": "Migratory environmental history of the grey mullet Mugil cephalus as revealed by otolith Sr:Ca ratios we used an electron probe microanalyzer (epma) to determine the migratory environ- mental history of the catadromous grey mullet mugil cephalus from the sr:ca ratios in otoliths of 10 newly recruited juveniles collected from estuaries and 30 adults collected from estuaries, nearshore (coastal waters and bay) and offshore, in the adjacent waters off taiwan. mean (\u00b1sd) sr:ca ratios at the edges of adult otoliths increased significantly from 6.5 \u00b1 0.9 \u00d7 10 -3 in estuaries and nearshore waters to 8.9 \u00b1 1.4 \u00d7 10 -3 in offshore waters (p < 0.01), corresponding to increasing ambi- ent salinity from estuaries and nearshore to offshore waters. the mean sr:ca ratios decreased sig- nificantly from the core (11.2 \u00b1 1.2 \u00d7 10 -3 ) to the otolith edge (6.2 \u00b1 1.4 \u00d7 10 -3 ) in juvenile otoliths (p < 0.001). the mullet generally spawned offshore and recruited to the estuary at the juvenile stage; therefore, these data support the use of sr:ca ratios in otoliths to reconstruct the past salinity history of the mullet. a life-history scan of the otolith sr:ca ratios indicated that the migratory environmen- tal history of the mullet beyond the juvenile stage consists of 2 types. in type 1 mullet, sr:ca ratios range between 4.0 \u00d7 10 -3 and 13.9 \u00d7 10 -3 , indicating that they migrated between estuary and offshore waters but rarely entered the freshwater habitat. in type 2 mullet, the sr:ca ratios decreased to a minimum value of 0.4 \u00d7 10 -3 , indicating that the mullet migrated to a freshwater habitat. most mullet beyond the juvenile stage migrated from estuary to offshore waters, but a few mullet less than 2 yr old may have migrated into a freshwater habitat. most mullet collected nearshore and offshore were of type 1, while those collected from the estuaries were a mixture of types 1 and 2. the mullet spawning stock consisted mainly of type 1 fish. the growth rates of the mullet were similar for types 1 and 2. the migratory patterns of the mullet were more divergent than indicated by previous reports of their catadromous behavior.",
            "contribution_ids": [
                "R34073"
            ]
        },
        {
            "instance_id": "R34099xR33976",
            "comparison_id": "R34099",
            "paper_id": "R33976",
            "text": "Reconstructing habitat use of Coilia mystus and Coilia ectenes of the Yangtze River estuary, and of Coilia ectenes of Taihu Lake, based on otolith strontium and calcium the habitat use and migratory patterns of osbeck\u2019s grenadier anchovy coilia mystus in the yangtze estuary and the estuarine tapertail anchovy coilia ectenes from the yangtze estuary and taihu lake, china, were studied by examining the environmental signatures of strontium and calcium in their otoliths using electron probe microanalysis. the results indicated that taihu c. ectenes utilizes only freshwater habitats, whereas the habitat use patterns of yangtze c. ectenes and c. mystus were much more flexible, apparently varying among fresh, brackish and marine areas. the present study suggests that the spawning populations of yangtze c. ectenes and c. mystus in the yangtze estuary consist of individuals with different migration histories, and individuals of these two yangtze coilia species seem to use a variety of different habitats during the non-spawning seasons.",
            "contribution_ids": [
                "R33977",
                "R33979",
                "R33980"
            ]
        },
        {
            "instance_id": "R34099xR33991",
            "comparison_id": "R34099",
            "paper_id": "R33991",
            "text": "Facultative catadromy of the eel Anguilla japonica between freshwater and seawater habitats \"to confirm the occurrence of marine residents of the japanese eel, anguilla japonica, which have never entered freshwater ('sea eels'), we measured sr and ca concentrations by x-ray electron microprobe analysis of the otoliths of 69 yellow and silver eels, collected from 10 localities in seawater and freshwater habitats around japan, and classified their migratory histories. two-dimen- sional images of the sr concentration in the otoliths showed that all specimens generally had a high sr core at the center of their otolith, which corresponded to a period of their leptocephalus and early glass eel stages in the ocean, but there were a variety of different patterns of sr concentration and concentric rings outside the central core. line analysis of sr/ca ratios along the radius of each otolith showed peaks (ca 15 \u00d7 10 -3 ) between the core and out to about 150 \u00b5m (elver mark). the pattern change of the sr/ca ratio outside of 150 \u00b5m indicated 3 general categories of migratory history: 'river eels', 'estuarine eels' and 'sea eels'. these 3 categories corresponded to mean values of sr/ca ratios of \u2265 6.0 \u00d7 10 -3 for sea eels, which spent most of their life in the sea and did not enter freshwater, of 2.5 to 6.0 \u00d7 10 -3 for estuarine eels, which inhabited estuaries or switched between different habitats, and of <2.5 \u00d7 10 -3 for river eels, which entered and remained in freshwater river habitats after arrival in the estuary. the occurrence of sea eels was 20% of all specimens examined and that of river eels, 23%, while estuarine eels were the most prevalent (57%). the occurrence of sea eels was confirmed at 4 localities in japanese coastal waters, including offshore islands, a small bay and an estuary. the finding of estuarine eels as an intermediate type, which appear to frequently move between different habitats, and their presence at almost all localities, suggested that a. japonica has a flexible pattern of migration, with an ability to adapt to various habitats and salinities. thus, anguillid eel migrations into freshwater are clearly not an obligatory migratory pathway, and this form of diadromy should be defined as facultative catadromy, with the sea eel as one of several ecophenotypes. furthermore, this study indicates that eels which utilize the marine environment to various degrees during their juve- nile growth phase may make a substantial contribution to the spawning stock each year.\"",
            "contribution_ids": [
                "R33992"
            ]
        },
        {
            "instance_id": "R34099xR34001",
            "comparison_id": "R34099",
            "paper_id": "R34001",
            "text": "Use of otolith Sr:Ca ratios to study the riverine migratory behaviors of Japanese eel Anguilla japonica to understand the migratory behavior and habitat use of the japanese eel anguilla japonica in the kaoping river, sw taiwan, the temporal changes of strontium (sr) and calcium (ca) contents in otoliths of the eels in combination with age data were examined by wavelength dispersive x-ray spectrometry with an electron probe microanalyzer. ages of the eel were determined by the annulus mark in their otolith. the pattern of the sr:ca ratios in the otoliths, before the elver stage, was similar among all specimens. post-elver stage sr:ca ratios indicated that the eels experienced different salinity histories in their growth phase yellow stage. the mean (\u00b1sd) sr:ca ratios in otoliths beyond elver check of the 6 yellow eels from the freshwater middle reach were 1.8 \u00b1 0.2 x 10 -3 with a maximum value of 3.73 x 10 -3 . sr:ca ratios of less than 4 x 10-3 were used to discriminate the freshwater from seawater resident eels. eels from the lower reach of the river were classified into 3 types: (1) freshwater contingents, sr:ca ratio <4 x 10 -3 , constituted 14 % of the eels examined; (2) seawater contingent, sr:ca ratio 5.1 \u00b1 1.1 x 10-3 (5%); and (3) estuarine contingent, sr:ca ratios ranged from 0 to 10 x 10 -3 , with migration between freshwater and seawater (81 %). the frequency distribution of the 3 contingents differed between yellow and silver eel stages (0.01 < p < 0.05 for each case) and changed with age of the eel, indicating that most of the eels stayed in the estuary for the first year then migrated to the freshwater until 6 yr old. the eel population in the river system was dominated by the estuarine contingent, probably because the estuarine environment was more stable and had a larger carrying capacity than the freshwater middle reach did, and also due to a preference for brackish water by the growth-phase, yellow eel.",
            "contribution_ids": [
                "R34002"
            ]
        },
        {
            "instance_id": "R34099xR34060",
            "comparison_id": "R34099",
            "paper_id": "R34060",
            "text": "Population structure of sympatric anadromous and nonanadromous Oncorhynchus mykiss: evidence from spawning surveys and otolith microchemistry reproductive isolation between steelhead and resident rainbow trout (oncorhynchus mykiss) was examined in the deschutes river, oregon, through surveys of spawning timing and location. otolith microchemistry was used to determine the occurrence of steelhead and resident rainbow trout progeny in the adult populations of steelhead and resident rainbow trout in the deschutes river and in the babine river, british columbia. in the 3 years studied, steelhead spawning occurred from mid march through may and resident rainbow trout spawning occurred from mid march through august. the timing of 50% spawning was 9-10 weeks earlier for steelhead than for resident rainbow trout. spawning sites selected by steelhead were in deeper water and had larger substrate than those selected by resident rainbow trout. maternal origin was identified by comparing sr/ca ratios in the primordia and freshwater growth regions of the otolith with a wavelength-dispersive electron microprobe. in the deschutes river, only steelhead of steelhead maternal origin and resident rainbow trout of resident rainbow trout origin were observed. in the babine river, steelhead of resident rainbow trout origin and resident rainbow trout of steelhead maternal origin were also observed. based on these findings, we suggest that steelhead and resident rainbow trout in the deschutes river may constitute reproductively isolated populations.",
            "contribution_ids": [
                "R34061"
            ]
        },
        {
            "instance_id": "R34099xR33999",
            "comparison_id": "R34099",
            "paper_id": "R33999",
            "text": "Migratory behaviour and habitat use by American eels Anguilla rostrata as revealed by otolith microchemistry the environmental history of american eels anguilla rostrata from the east river, nova scotia, was investigated by electron microprobe analysis of the sr:ca ratio along transects of the eel otolith. the mean (\u00b1sd) sr:ca ratio in the otoliths of juvenile american eels was 5.42 \u00d7 10 -3 \u00b1 1.22 \u00d7 10 -3 at the elver check and decreased to 2.38 \u00d7 10 -3 \u00b1 0.99 \u00d7 10 -3 at the first annulus for eels that migrated directly into the river but increased to 7.28 \u00d7 10 -3 \u00b1 1.09 \u00d7 10 -3 for eels that had remained in the estuary for 1 yr or more before entering the river. at the otolith edge, sr:ca ratios of 4.0 \u00d7 10 -3 or less indicated freshwater residence and ratios of 5.0 \u00d7 10 -3 or more indicated estuarine residence. four distinct but interrelated behavioural groups were identified by the temporal changes in sr:ca ratios in their otoliths: (1) entrance into freshwater as an elver, (2) coastal or estuarine residence for 1y r or more before entering freshwater, and, after entering freshwater, (3) continuous freshwater res- idence until the silver eel stage and (4) freshwater residence for 1 yr or more before engaging in peri- odic, seasonal movements between estuary and freshwater until the silver eel stage. small (< 70 mm total length), highly pigmented elvers that arrived early in the elver run were confirmed as slow growing age-1 juvenile eels. juvenile eels that remained 1 yr or more in the estuary before entering the river contributed to the production of silver eels to a relatively greater extent than did elvers that entered the river during the year of continental arrival.",
            "contribution_ids": [
                "R34000"
            ]
        },
        {
            "instance_id": "R34099xR34050",
            "comparison_id": "R34099",
            "paper_id": "R34050",
            "text": "Evidence of multiple migrations between freshwater and marine habitats of Salvelinus leucomaenis. the migratory history of the white-spotted charr salvelinus leucomaenis was examined using otolith microchemical analysis. the fish migrated between freshwater and marine environments multiple times during their life history. some white-spotted charr used an estuarine habitat prior to smolting and repeated seaward migration within a year.",
            "contribution_ids": [
                "R34051"
            ]
        },
        {
            "instance_id": "R34126xR34117",
            "comparison_id": "R34126",
            "paper_id": "R34117",
            "text": "Correlation of clinical, magnetic resonance imaging, and cerebrospinal fluid findings in optic neuritis we found 42 of 74 patients (57%) with isolated monosymptomatic optic neuritis to have 1 to 20 brain lesions, by magnetic resonance imaging (mri). all of the brain lesions were clinically silent and had characteristics consistent with multiple sclerosis (ms). none of the patients had ever experienced neurologic symptoms prior to the episode of optic neuritis. during 5.6 years of follow\u2010up, 21 patients (28%) developed definite ms on clinical grounds. sixteen of the 21 converting patients (76%) had abnormal mris; the other 5 (24%) had mris that were normal initially (when they had optic neuritis only) and when repeated after they had developed clinical ms in 4 of the 5. of the 53 patients who have not developed clinically definite ms, 26 (49%) have abnormal mris and 27 (51%) have normal mris. the finding of an abnormal mri at the time of optic neuritis was significantly related to the subsequent development of ms on clinical grounds, but interpretation of the strength of that relationship must be tempered by the fact that some of the converting patients had normal mris and approximately half of the patients who did not develop clinical ms had abnormal mris. we found that abnormal igg levels in the cerebrospinal fluid correlated more strongly than abnormal mris with the subsequent development of clinically definite ms.",
            "contribution_ids": [
                "R34118"
            ]
        },
        {
            "instance_id": "R34126xR34111",
            "comparison_id": "R34126",
            "paper_id": "R34111",
            "text": "A long-term prospective study of optic neuritis: evaluation of risk factors eighty\u2010six patients with monosymptomatic optic neuritis of unknown cause were followed prospectively for a median period of 12.9 years. at onset, cerebrospinal fluid (csf) pleocytosis was present in 46 patients (53%) but oligoclonal immunoglobulin in only 40 (47%) of the patients. the human leukocyte antigen (hla)\u2010dr2 was present in 45 (52%). clinically definite multiple sclerosis (ms) was established in 33 patients. actuarial analysis showed that the cumulative probability of developing ms within 15 years was 45%. three risk factors were identified: low age and abnormal csf at onset, and early recurrence of optic neuritis. female gender, onset in the winter season, and the presence of hla\u2010dr2 antigen increased the risk for ms, but not significantly. magnetic resonance imaging detected bilateral discrete white matter lesions, similar to those in ms, in 11 of 25 patients, 7 to 18 years after the isolated attack of optic neuritis. nine were among the 13 with abnormal csf and only 2 belonged to the group of 12 with normal csf (p = 0.01). normal csf at the onset of optic neuritis conferred better prognosis but did not preclude the development of ms.",
            "contribution_ids": [
                "R34112"
            ]
        },
        {
            "instance_id": "R34126xR34113",
            "comparison_id": "R34126",
            "paper_id": "R34113",
            "text": "Clinically isolated syndromes: a new oligoclonal band test accurately predicts conversion to MS background: patients with a clinically isolated demyelinating syndrome (cis) are at risk of developing a second attack, thus converting into clinically definite multiple sclerosis (cdms). therefore, an accurate prognostic marker for that conversion might allow early treatment. brain mri and oligoclonal igg band (ocgb) detection are the most frequent paraclinical tests used in ms diagnosis. a new ocgb test has shown high sensitivity and specificity in differential diagnosis of ms. objective: to evaluate the accuracy of the new ocgb method and of current mri criteria (mri-c) to predict conversion of cis to cdms. methods: fifty-two patients with cis were studied with ocgb detection and brain mri, and followed up for 6 years. the sensitivity and specificity of both methods to predict conversion to cdms were analyzed. results: ocgb detection showed a sensitivity of 91.4% and specificity of 94.1%. mri-c had a sensitivity of 74.23% and specificity of 88.2%. the presence of either ocgb or mri-c studied simultaneously showed a sensitivity of 97.1% and specificity of 88.2%. conclusions: the presence of oligoclonal igg bands is highly specific and sensitive for early prediction of conversion to multiple sclerosis. mri criteria have a high specificity but less sensitivity. the simultaneous use of both tests shows high sensitivity and specificity in predicting clinically isolated demyelinating syndrome conversion to clinically definite multiple sclerosis.",
            "contribution_ids": [
                "R34114"
            ]
        },
        {
            "instance_id": "R34126xR34115",
            "comparison_id": "R34126",
            "paper_id": "R34115",
            "text": "Predicting multiple sclerosis at optic neuritis onset using multivariate analyses, individual risk of clinically definite multiple sclerosis (c dms) after monosymptomatic optic neuritis (mo n) was quantified in a prospective study with clinical mo n onset during 1990 -95 in stockholm, sweden. during a mean follow-up time of 3.8 years, the presence of ms-like brain magnetic resonance imaging (mri) lesions and oligoclonal immunoglobulin (ig) g bands in cerebrospinal fluid (csf) were strong prognostic markers of c dms, with relative hazard ratios of 4.68 {95% confidence interval (ci) 2.21 -9.91} and 5.39 (95% c i 1.56 -18.61), respectively. age and season of clinical onset were also significant predictors, with relative hazard ratios of 1.76 (95% c i 1.02 -3.04) and 2.21 (95% c i 1.13 -3.98), respectively. based on the above two strong predicto rs, individual probability of c dms development after mo n was calculated in a three-quarter sample drawn from a cohort, with completion of follow-up at three years. the highest probability, 0.66 (95% c i 0.48 -0.80), was obtained for individuals presenting with three or more brain mri lesions and oligoclonal bands in the c sf, and the lowest, 0.09 (95% c i 0.02 -0.32), for those not presenting with these traits. medium values, 0.29 (95% c i 0.13 -0.53) and 0.32 (95% c i 0.07 -0.73), were obtained for individuals discordant for the presence of brain mri lesions and oligoclonal bands in the c sf. these predictions were validated in an external one-quarter sample.",
            "contribution_ids": [
                "R34116"
            ]
        },
        {
            "instance_id": "R34126xR34122",
            "comparison_id": "R34126",
            "paper_id": "R34122",
            "text": "Uncomplicated retrobul- bar neuritis and the development of multiple sclerosis abstract a retrospective study of 30 patients hospitalized with a diagnosis of uncomplicated retrobulbar neuritis was carried out. the follow\u2010up period was 2\u201311 years; 57% developed multiple sclerosis. when the initial examination revealed oligoclonal bands in the cerebrospinal fluid, the risk of developing multiple sclerosis increased to 79%. with normal cerebrospinal fluid the risk decreased to only 10%. in the majority of cases, the diagnosis of ms was made during the first 3 years after retrobulbar neuritis.",
            "contribution_ids": [
                "R34123"
            ]
        },
        {
            "instance_id": "R34183xR34138",
            "comparison_id": "R34183",
            "paper_id": "R34138",
            "text": "The impact of the introduction of transgenic crops in Argentinean agriculture since the early 1990s, argentinean grain production underwent a dramatic increase in grains production (from 26 million tons in 1988/89 to over 75 million tons in 2002/2003). several factors contributed to this \"revolution,\" but probably one of the most important was the introduction of new genetic modification (gm) technologies, specifically herbicide-tolerant soybeans. this article analyses this process, reporting on the economic benefits accruing to producers and other participating actors as well as some of the environmental and social impacts that could be associated with the introduction of the new technologies. in doing so, it lends attention to the synergies between gm soybeans and reduced-tillage technologies and also explores some of the institutional factors that shed light on the success of this case, including aspects such as the early availability of a reliable biosafety mechanism and a special intellectual property rights (ipr) situation. in its concluding comments, this article also posts a number of questions about the replicability of the experience and some pending policy issues regarding the future exploitation of gm technologies in argentina.",
            "contribution_ids": [
                "R34139",
                "R34166",
                "R34176"
            ]
        },
        {
            "instance_id": "R34183xR34177",
            "comparison_id": "R34183",
            "paper_id": "R34177",
            "text": "Biodiversity versus transgenic sugar beet: the one euro question the decision of whether to release transgenic crops in the eu is one subject to flexibility, uncertainty, and irreversibility. we analyse the case of herbicide tolerant sugar beet and reassess whether the 1998 de facto moratorium of the eu on transgenic crops for sugar beet was correct from a cost-benefit perspective using a real option approach. we show that the decision was correct, if households value possible annual irreversible costs of herbicide tolerant sugar beet with about 1 euro or more on average. on the other hand, the total net private reversible benefits forgone if the de facto moratorium is not lifted are in the order of 169 mio euro per year.",
            "contribution_ids": [
                "R34178"
            ]
        },
        {
            "instance_id": "R34183xR34132",
            "comparison_id": "R34183",
            "paper_id": "R34132",
            "text": "Evaluation of Transgenic Corn Against European Corn Borer, Central Minnesota, 1996 abstract \\n this experiment was conducted to assess the performance of bacillus thuringiensis (bt) transgenic corn [cryla(b) gene] against a natural ecb infestation in rosemount, mn. plots measuring 50 ft by 8 rows (30 inch row spacing) were established in dakota silty loam soil on 23 may at a rate of 26,100 seeds per acre. plots were arranged in a rcb with four replications. first generation ecb measurements recorded jul to aug included % shot-holing, leaf injury ratings, and tunnel length and number. measurements for second generation ecb recorded in sept included cumulative tunnel length and number, fall larvae, and ear and shank damage. yield data were corrected to 15.5% moisture.",
            "contribution_ids": [
                "R34133"
            ]
        },
        {
            "instance_id": "R34183xR34147",
            "comparison_id": "R34183",
            "paper_id": "R34147",
            "text": "Size and Distribution of Market Benefits From Adopting Biotech Crops \"this study estimates the total benefit arising from the adoption of agricultural biotechnology in one year (1997) and its distribution among key stakeholders along the production and marketing chain. the analysis focuses on three biotech crops: herbicide-tolerant soybeans, insect-resistant (bt) cotton, and herbicide-tolerant cotton. adoption of these crops resulted in estimated market benefits of $212.5-$300.7 million for bt cotton, $231.8 million for herbicide-tolerant cotton, and $307.5 million for herbicide-tolerant soybeans. these benefits accounted for small shares of crop production value, ranging from 2 percent to 5 percent. u.s. farmers captured a much larger share (about a third) of the benefits for bt cotton than with herbicide-tolerant soybeans (20 percent) and herbicide-tolerant cotton (4 percent). innovators' share ranged from 30 percent for bt cotton to 68 percent for herbicide-tolerant soybeans. for herbicide-tolerant cotton, u.s. consumers and the rest of the world (including both producers and consumers) received the bulk of the estimated benefits in 1997. estimated benefits and their distribution depend on the specification of the analytical framework, supply and demand elasticity assumptions, the inclusion of market and nonmarket benefits, crops considered, and year-specific factors (such as weather and pest infestation levels).\"",
            "contribution_ids": [
                "R34148",
                "R34149",
                "R34167",
                "R34175"
            ]
        },
        {
            "instance_id": "R34183xR34130",
            "comparison_id": "R34183",
            "paper_id": "R34130",
            "text": "First impact of biotechnology in the EU: Bt maize adoption in Spain summary in the present paper we build a bio-economic model to estimate the impact of a biotechnology innovation in eu agriculture. transgenic bt maize offers the potential to efficiently control corn borers, that cause economically important losses in maize growing in spain. since 1998, syngenta has commercialised the variety compa cb, equivalent to an annual maize area of about 25,000 ha. during the six-year period 1998-2003 a total welfare gain of \u20ac15.5 million is estimated from the adoption of bt maize, of which spanish farmers captured two thirds, the rest accruing to the seed industry.",
            "contribution_ids": [
                "R34131"
            ]
        },
        {
            "instance_id": "R34183xR34173",
            "comparison_id": "R34183",
            "paper_id": "R34173",
            "text": "Rent creation and distribution from biotechnology innovation: the case of Bt cotton and herbicide-tolerant soybeans in 1997 \"we examine the distribution of welfare from the second-year planting of bt cotton in the united states in 1997. we also provide preliminary estimates of the planting of herbicide-tolerant soybeans in 1997. for bt cotton, total increase in world surplus was $190.1 million and us farmer share of total surplus was 42%. the gene developer, monsanto, received 35% and the rest of the world 6% of the total world surplus. delta and pine land received 9%, whereas us consumers received 7%. for herbicide-tolerant soybeans, total world surplus was $1,061.7 million. us farmers' surplus was 76%, monsanto's was 7%, us consumers received 4%, and seed companies captured 3% of total surplus. leconolit: q120, d600, o330r \u00a9 2000 john wiley & sons, inc.\"",
            "contribution_ids": [
                "R34174"
            ]
        },
        {
            "instance_id": "R34183xR34153",
            "comparison_id": "R34183",
            "paper_id": "R34153",
            "text": "Five years of Bt cotton in China - the benefits continue bt cotton is spreading very rapidly in china, in response to demand from farmers for technology that will reduce both the cost of pesticide applications and exposure to pesticides, and will free up time for other tasks. based on surveys of hundreds of farmers in the yellow river cotton-growing region in northern china in 1999, 2000 and 2001, over 4 million smallholders have been able to increase yield per hectare, and reduce pesticide costs, time spent spraying dangerous pesticides, and illnesses due to pesticide poisoning. the expansion of this cost-saving technology is increasing the supply of cotton and pushing down the price, but prices are still sufficiently high for adopters of bt cotton to make substantial gains in net income.",
            "contribution_ids": [
                "R34154"
            ]
        },
        {
            "instance_id": "R34183xR34143",
            "comparison_id": "R34183",
            "paper_id": "R34143",
            "text": "Surplus distribution from the introduction of a biotechnology innovation we examine the distribution of welfare from the introduction of bt cotton in the united states in 1996. the welfare framework explicitly recognizes that research protected by intellectual property rights generates monopoly profits, and makes it possible to partition these rents among consumers, farmers, and the innovating input firms. we calculate a total increase in world surplus of $240.3 million for 1996. of this total, the largest share (59%) went to u.s. farmers. the gene developer, monsanto, received the next largest share (21%), followed by u.s. consumers (9%), the rest of the world (6%), and the germplasm supplier, delta and pine land company (5%).",
            "contribution_ids": [
                "R34144"
            ]
        },
        {
            "instance_id": "R34183xR34171",
            "comparison_id": "R34183",
            "paper_id": "R34171",
            "text": "Roundup Ready soybeans and welfare effects in the soybean complex \"a three-region world model for the soybean complex is developed to evaluate the welfare effects of roundup ready (rr) soybean adoption. the structural modeling of the innovation accounts for farmers' adoption incentives and for the observed pricing of rr soybean seeds as a proprietary technology. the calibrated model is solved for various scenarios to evaluate the production, price, and welfare impacts of rr soybean adoption. the united states gains substantially from the innovation, with the innovator capturing the larger share of the welfare gains. us farmers benefit in the base scenario, but would be adversely affected if the rr innovation were to increase yields. spillover of the new technology to foreign competitors erodes the competitive position of domestic soybean producers, and export of the technology per se may not improve the welfare position of the innovating country. consumers in every region gain from the adoption of rr soybeans. ljel classification: f14, o33, q16r. \u00a9 2000 john wiley & sons, inc.\"",
            "contribution_ids": [
                "R34172"
            ]
        },
        {
            "instance_id": "R34251xR34187",
            "comparison_id": "R34251",
            "paper_id": "R34187",
            "text": "An evaluation of the viability of a single monetary zone in ECOWAS currency convertibility and monetary integration activities of the economic community of west african states (ecowas) are directed at addressing the problems of multiple currencies and exchange rate changes that are perceived as stumbling blocks to regional integration. a real exchange rate (rer) variability model shows that ecowas is closer to a monetary union now than before. as expected, the implementation of structural adjustment programmes (saps) by various governments in the subregion has brought about a reasonable level of convergence. however, wide differences still exist between rer shocks facing cfa zone and non-cfa zone west african countries. further convergence in economic policy and alternatives to dependence on revenues from taxes on international transactions are required for a stable region-wide monetary union in west africa.",
            "contribution_ids": [
                "R34188"
            ]
        },
        {
            "instance_id": "R34251xR34234",
            "comparison_id": "R34251",
            "paper_id": "R34234",
            "text": "A Short-Run Schumpeterian Trip to Embryonic African Monetary Zones with the spectre of the euro crisis looming substantially large and scaring potential monetary unions, this study is a short-run trip to embryonic african monetary zones to assess the schumpeterian thesis for positive spillovers of financial services on growth. causality analysis is performed with seven financial development and three growth indicators in the proposed west african monetary zone (wamz) and east african monetary zone (eamz). the journey is promising for the eamz and lamentable for the wamz. results of the eamz are broadly consistent with the traditional discretionary monetary policy arrangements while those of the wamz are in line with the non-traditional strand of regimes in which, policy instruments in the short-run cannot be used to offset adverse shocks to output. policy implications are discussed.",
            "contribution_ids": [
                "R34235",
                "R34274"
            ]
        },
        {
            "instance_id": "R34251xR34238",
            "comparison_id": "R34251",
            "paper_id": "R34238",
            "text": "REER Imbalances and Macroeconomic Adjustments in the Proposed West African Monetary Union with the spectre of the euro crisis hunting embryonic monetary unions, we use a dynamic model of a small open economy to analyze reers imbalances and examine whether the movements in the aggregate real exchange rates are consistent with the underlying macroeconomic fundamentals in the proposed west african monetary union (wamu). using both country-oriented and wamu panel-based specifications, we show that the long-run behavior of the reers can be explained by fluctuations in the terms of trade, productivity, investment, debt and openness. while there is still significant evidence of cross-country differences in the relationship between underlying macroeconomic fundamentals and corresponding reers, the embryonic wamu has a stable error correction mechanism with four of the five cointegration relations having signs that are consistent with the predictions from economic theory. policy implications are discussed and the conclusions of the analysis are a valuable contribution to the scholarly and policy debate over whether the creation of a sustainable monetary union should precede convergence in macroeconomic fundamentals that determine reer adjustments.",
            "contribution_ids": [
                "R34239"
            ]
        },
        {
            "instance_id": "R34251xR34210",
            "comparison_id": "R34251",
            "paper_id": "R34210",
            "text": "Currency Unions in Africa: Is the Trade Effect Substantial Enough to Justify their Formation? using estimates that currency unions double trade, we quantify the welfare effects of forming currency unions for the african regional economic communities and for the african union as a whole. the potential increase in trade is shown to be small, and much less than that resulting from the adoption of the euro. allowing for increased african trade does not overturn the negative assessment of african currency unions, due to asymmetries in countries' terms-of-trade shocks and their degree of fiscal discipline. copyright 2007 the author.",
            "contribution_ids": [
                "R34211",
                "R34306"
            ]
        },
        {
            "instance_id": "R34251xR34196",
            "comparison_id": "R34251",
            "paper_id": "R34196",
            "text": "On the adequacy of monetary arrangements in Sub-Saharan Africa \"we examine the economic rationale for monetary union(s) in sub-saharan africa through the use of cluster analysis on a sample of 17 countries. the variables used stem from the theory of optimum currency areas and from the fear-of-floating literature. it is found that the existing cfa franc zone cannot be viewed as an optimum currency area: cemac and uemoa countries do not belong to the same clusters, and a 'core' of the uemoa can be defined on economic grounds. the results support the inclusion of the gambia, ghana and sierra leone in an extended uemoa arrangement, or the creation of a separate monetary union with the 'core' of the uemoa and the gambia, rather than the creation of a monetary union around nigeria. finally, the creation of the west african monetary zone (wamz) around nigeria is not supported by the data. copyright blackwell publishing ltd 2005.\"",
            "contribution_ids": [
                "R34197"
            ]
        },
        {
            "instance_id": "R34251xR34205",
            "comparison_id": "R34251",
            "paper_id": "R34205",
            "text": "Exchange rate volatility and optimum currency area: evidence from Africa in this paper we use a system of simultaneous equations and generalized method of moment (gmm) to investigate the relation between bilateral exchange rate volatility and the relevant variables pointed out by the theory of optimum currency areas (oca) for 21 selected african countries for the period 1990-2003. the evidence turns out to be strongly supported by the data. an oca index for african countries is derived by adapting a method initially proposed by bayoumi and eichengreen (1997). the results have important policy implications for proposed monetary unions in africa. citation: bangak\u00e9, chrysost, (2008) \"exchange rate volatility and optimum currency area: evidence from africa.\" economics bulletin, vol. 6, no. 12 pp. 1-10 submitted: december 13, 2007. accepted: march 26, 2008. url: http://economicsbulletin.vanderbilt.edu/2008/volume6/eb-07f30021a.pdf",
            "contribution_ids": [
                "R34206",
                "R34258",
                "R34305"
            ]
        },
        {
            "instance_id": "R34251xR34240",
            "comparison_id": "R34251",
            "paper_id": "R34240",
            "text": "Are proposed African monetary unions optimal currency areas? Real, monetary and fiscal policy convergence analysis purpose \u2013 a spectre is hunting embryonic african monetary zones: the european monetary union crisis. the purpose of this paper is to assess real, monetary and fiscal policy convergence within the proposed wam and eam zones. the introduction of common currencies in west and east africa is facing stiff challenges in the timing of monetary convergence, the imperative of central bankers to apply common modeling and forecasting methods of monetary policy transmission, as well as the requirements of common structural and institutional characteristics among candidate states. design/methodology/approach \u2013 in the analysis: monetary policy targets inflation and financial dynamics of depth, efficiency, activity and size; real sector policy targets economic performance in terms of gdp growth at macro and micro levels; while, fiscal policy targets debt-to-gdp and deficit-to-gdp ratios. a dynamic panel gmm estimation with data from different non-overlapping intervals is employed. the implied rate of convergence and the time required to achieve full (100 percent) convergence are then computed from the estimations. findings \u2013 findings suggest overwhelming lack of convergence: initial conditions for financial development are different across countries; fundamental characteristics as common monetary policy initiatives and imf-backed financial reform programs are implemented differently across countries; there is remarkable evidence of cross-country variations in structural characteristics of macroeconomic performance; institutional cross-country differences could also be responsible for the deficiency in convergence within the potential monetary zones; absence of fiscal policy convergence and no potential for eliminating idiosyncratic fiscal shocks due to business cycle incoherence. practical implications \u2013 as a policy implication, heterogeneous structural and institutional characteristics across countries are giving rise to different levels and patterns of financial intermediary development. thus, member states should work towards harmonizing cross-country differences in structural and institutional characteristics that hamper the effectiveness of convergence in monetary, real and fiscal policies. this could be done by stringently monitoring the implementation of existing common initiatives and/or the adoption of new reforms programs. originality/value \u2013 it is one of the few attempts to investigate the issue of convergence within the proposed wam and eam unions.",
            "contribution_ids": [
                "R34241",
                "R34280"
            ]
        },
        {
            "instance_id": "R34282xR34272",
            "comparison_id": "R34282",
            "paper_id": "R34272",
            "text": "Monetary Transmission Mechanism in the East African Community: An Empirical Investigation do changes in monetary policy affect inflation and output in the east african community (eac)? we find that (i) monetary transmission mechanism (mtm) tends to be generally weak when using standard statistical inferences, but somewhat strong when using non-standard inference methods; (ii) when mtm is present, the precise transmission channels and their importance differ across countries; and (iii) reserve money and the policy rate, two frequently used instruments of monetary policy, sometimes move in directions that exert offsetting expansionary and contractionary effects on inflation - posing challenges to harmonization of monetary policies across the eac and transition to a future east african monetary union. the paper offers some suggestions for strengthening the mtm in the eac.",
            "contribution_ids": [
                "R34273"
            ]
        },
        {
            "instance_id": "R34282xR34242",
            "comparison_id": "R34282",
            "paper_id": "R34242",
            "text": "How Would Monetary Policy Matter in the Proposed African Monetary Unions? Evidence from Output and Prices we analyze the effects of monetary policy on economic activity in the proposed african monetary unions. findings broadly show that: (1) but for financial efficiency in the eamz, monetary policy variables affect output neither in the short-run nor in the long-term and; (2) with the exception of financial size that impacts inflation in the eamz in the short-term, monetary policy variables generally have no effect on prices in the short-run. the wamz may not use policy instruments to offset adverse shocks to output by pursuing either an expansionary or a contractionary policy, while the eamz can do with the \u2018financial allocation efficiency\u2019 instrument. policy implications are discussed.",
            "contribution_ids": [
                "R34243",
                "R34281"
            ]
        },
        {
            "instance_id": "R34282xR34268",
            "comparison_id": "R34282",
            "paper_id": "R34268",
            "text": "Monetary union for the development process in the East African community: business cycle synchronization approach this paper empirically examines the suitability of monetary union in east african community members namely, burundi, kenya, rwanda, tanzania and uganda, on the basis of business cycle synchronization. this research considers annual gdp (gross domestic product) data from imf (international monetary fund) for the period of 1980 to 2010. in order to extract the business cycles and trends, the study uses hp (hodrick-prescott) and the bp (band pass) filters. after identifying the cycles and trends of the business cycle, the study considers cross country correlation analysis and analysis of variance technique to examine whether eac (east african community) countries are characterized by synchronized business cycles or not. the results show that four eac countries (burundi, kenya, tanzania and uganda) among five countries are having similar pattern of business cycle and trend from the last ten years of the formation of the eac. the research concludes that these countries, except rwanda, do not differ significantly in transitory or cycle components but do differ in permanent components especially in growth trend. \\n \\n \\xa0 \\n \\n key words:\\xa0business cycle synchronization, optimum currency area, east african community, monetary union, development.",
            "contribution_ids": [
                "R34269"
            ]
        },
        {
            "instance_id": "R34282xR34266",
            "comparison_id": "R34282",
            "paper_id": "R34266",
            "text": "Business Cycle Synchronization in the Proposed East African Monetary Union: An Unobserved Component Approach this paper uses the business cycle synchronization criteria of the theory of optimum currency area (oca) to examine the feasibility of the east african community (eac) as a monetary union. we also investigate whether the degree of business cycle synchronization has increased after the 1999 eac treaty. we use an unobserved component model to measure business cycle synchronization as the proportion of structural shocks that are common across different countries, and a time-varying parameter model to examine the dynamics of synchronization over time. we find that although the degree of synchronization has increased since 2000 when the eac treaty came into force, the proportion of shocks that is common across different countries is still small implying weak synchronization. this evidence casts doubt on the feasibility of a monetary union for the eac as scheduled by 2012.",
            "contribution_ids": [
                "R34267"
            ]
        },
        {
            "instance_id": "R34282xR34205",
            "comparison_id": "R34282",
            "paper_id": "R34205",
            "text": "Exchange rate volatility and optimum currency area: evidence from Africa in this paper we use a system of simultaneous equations and generalized method of moment (gmm) to investigate the relation between bilateral exchange rate volatility and the relevant variables pointed out by the theory of optimum currency areas (oca) for 21 selected african countries for the period 1990-2003. the evidence turns out to be strongly supported by the data. an oca index for african countries is derived by adapting a method initially proposed by bayoumi and eichengreen (1997). the results have important policy implications for proposed monetary unions in africa. citation: bangak\u00e9, chrysost, (2008) \"exchange rate volatility and optimum currency area: evidence from africa.\" economics bulletin, vol. 6, no. 12 pp. 1-10 submitted: december 13, 2007. accepted: march 26, 2008. url: http://economicsbulletin.vanderbilt.edu/2008/volume6/eb-07f30021a.pdf",
            "contribution_ids": [
                "R34206",
                "R34258",
                "R34305"
            ]
        },
        {
            "instance_id": "R34282xR34278",
            "comparison_id": "R34282",
            "paper_id": "R34278",
            "text": "Monetary, Financial and Fiscal Stability in the East African Community: Ready for a Monetary Union? \"we examine prospects for a monetary union in the east african community (eac) by developing a stylized model of policymakers' decision problem that allows for uncertain benefits derived from monetary,financial and fiscal stability, and then calibrating the model for the eac for the period 2003-2010. when policymakers properly allow for uncertainty, none of the countries wants to pursue a monetary union based on either monetary or financial stability grounds, and only rwanda might favor it on fiscal stability grounds; we argue that robust institutional arrangements assuring substantial improvements in monetary, financial and fiscal stability are needed to compensate. (this abstract was borrowed from another version of this item.)\"",
            "contribution_ids": [
                "R34279"
            ]
        },
        {
            "instance_id": "R34282xR34276",
            "comparison_id": "R34282",
            "paper_id": "R34276",
            "text": "Macroeconomic Shock Synchronization in the East African Community the east african community\u2019s (eac) economic integration has gained momentum recently, with the eac countries aiming to adopt a single currency in 2015. this article evaluates empirically the readiness of the eac countries for monetary union. first, structural similarity in terms of similarity of production and exports of the eac countries is measured. second, the symmetry of shocks is examined with structural vector auto-regression analysis (svar). the lack of macroeconomic convergence gives evidence against a hurried transition to a monetary union. given the divergent macroeconomic outcomes, structural reforms, including closing infrastructure gaps and harmonizing macroeconomic policies that would raise synchronization of business cycles, need to be in place before moving to monetary union.",
            "contribution_ids": [
                "R34277"
            ]
        },
        {
            "instance_id": "R34316xR34288",
            "comparison_id": "R34316",
            "paper_id": "R34288",
            "text": "Macroeconomic Convergence in Southern Africa \"in this paper we aim to answer the following two questions: 1) has the common monetary area in southern africa (henceforth cma) ever been an optimal currency area (oca)? 2) what are the costs and benefits of the cma for its participating countries? in order to answer these questions, we carry out a two-step econometric exercise based on the theory of generalised purchasing power parity (g-ppp). the econometric evidence shows that the cma (but also botswana as a de facto member) form an oca given the existence of common long-run trends in their bilateral real exchange rates. second, we also test that in the case of the cma and botswana the smoothness of the operation of the common currency area \u2014 measured through the degree of relative price correlation \u2014 depends on a variety of factors. these factors signal both the advantages and disadvantages of joining a monetary union. on the one hand, the more open and more similarly diversified the economies are, the higher the benefits they ... ce document de travail s'efforce de repondre a deux questions : 1) la zone monetaire commune de l'afrique australe (common monetary area - cma) a-t-elle vraiment reussi a devenir une zone monetaire optimale ? 2) quels sont les couts et les avantages de la cma pour les pays participants ? nous avons effectue un exercice econometrique en deux etapes base sur la theorie des parites de pouvoir d'achat generalisees. d'apres les resultats econometriques, la cma (avec le botswana comme membre de facto) est effectivement une zone monetaire optimale etant donne les evolutions communes sur le long terme de leurs taux de change bilateraux. nous avons egalement mis en evidence que le bon fonctionnement de l'union monetaire \u2014 mesure par le degre de correlation des prix relatifs \u2014 depend de plusieurs facteurs. ces derniers revelent a la fois les couts et les avantages de l'appartenance a une union monetaire. d'un cote, plus les economies sont ouvertes et diversifiees de facon comparable, plus ...\"",
            "contribution_ids": [
                "R34289"
            ]
        },
        {
            "instance_id": "R34316xR34205",
            "comparison_id": "R34316",
            "paper_id": "R34205",
            "text": "Exchange rate volatility and optimum currency area: evidence from Africa in this paper we use a system of simultaneous equations and generalized method of moment (gmm) to investigate the relation between bilateral exchange rate volatility and the relevant variables pointed out by the theory of optimum currency areas (oca) for 21 selected african countries for the period 1990-2003. the evidence turns out to be strongly supported by the data. an oca index for african countries is derived by adapting a method initially proposed by bayoumi and eichengreen (1997). the results have important policy implications for proposed monetary unions in africa. citation: bangak\u00e9, chrysost, (2008) \"exchange rate volatility and optimum currency area: evidence from africa.\" economics bulletin, vol. 6, no. 12 pp. 1-10 submitted: december 13, 2007. accepted: march 26, 2008. url: http://economicsbulletin.vanderbilt.edu/2008/volume6/eb-07f30021a.pdf",
            "contribution_ids": [
                "R34206",
                "R34258",
                "R34305"
            ]
        },
        {
            "instance_id": "R34316xR34210",
            "comparison_id": "R34316",
            "paper_id": "R34210",
            "text": "Currency Unions in Africa: Is the Trade Effect Substantial Enough to Justify their Formation? using estimates that currency unions double trade, we quantify the welfare effects of forming currency unions for the african regional economic communities and for the african union as a whole. the potential increase in trade is shown to be small, and much less than that resulting from the adoption of the euro. allowing for increased african trade does not overturn the negative assessment of african currency unions, due to asymmetries in countries' terms-of-trade shocks and their degree of fiscal discipline. copyright 2007 the author.",
            "contribution_ids": [
                "R34211",
                "R34306"
            ]
        },
        {
            "instance_id": "R34316xR34310",
            "comparison_id": "R34316",
            "paper_id": "R34310",
            "text": "Modelling Monetary Union in Southern Africa: Welfare Evaluation for the CMA and SADC this paper proposes a quantitative assessment of the welfare effects arising from the common monetary area (cma) and an array of broader groupings among southern african development community (sadc) countries. model simulations suggest that (i) participating in the cma benefits all members; (ii) joining the cma individually is beneficial for all sadc members except angola, mauritius and tanzania; (iii) creating a symmetric cma-wide monetary union with a regional central bank carries some costs in terms of foregone anti-inflationary credibility; and (iv) sadc-wide symmetric monetary union continues to be beneficial for all except mauritius, although the gains for existing cma members are likely to be limited.",
            "contribution_ids": [
                "R34311"
            ]
        },
        {
            "instance_id": "R34411xR34344",
            "comparison_id": "R34411",
            "paper_id": "R34344",
            "text": "Pseudomembra- nous colitis associated with changes in an ileal conduit a case of antibiotic associated pseudomembranous colitis following total cystectomy is reported, in which there was involvement of the ileal conduit. the small bowel remaining in situ was uninvolved. bacteriological studies revealed clostridium difficile and the toxin in both colon and ileal conduit. relevant publications concerning pathogenesis are discussed, in relation to the unusual site described in this case. epidemiological evidence is reviewed which suggests that isolation of patients with pseudomembranous colitis is a logical course of action.",
            "contribution_ids": [
                "R34345"
            ]
        },
        {
            "instance_id": "R34411xR34382",
            "comparison_id": "R34411",
            "paper_id": "R34382",
            "text": "Extracolonic manifestations of Clostridium difficile infections: presentation of 2 cases and review of the literature \"clostridium difficile is most commonly associated with colonic infection. it may, however, also cause disease in a variety of other organ systems. small bowel involvement is often associated with previous surgical procedures on the small intestine and is associated with a significant mortality rate (4 of 7 patients). when associated with bacteremia, the infection is, as expected, frequently polymicrobial in association with usual colonic flora. the mortality rate among patients with c. difficile bacteremia is 2 of 10 reported patients. visceral abscess formation involves mainly the spleen, with 1 reported case of pancreatic abscess formation. frequently these abscesses are only recognized weeks to months after the onset of diarrhea or other colonic symptoms. c. difficile-related reactive arthritis is frequently polyarticular in nature and is not related to the patient's underlying hla-b27 status. fever is not universally present. the most commonly involved joints are the knee and wrist (involved in 18 of 36 cases). reactive arthritis begins an average of 11.3 days after the onset of diarrhea and is a prolonged illness, taking an average of 68 days to resolve. other entities, such as cellulitis, necrotizing fasciitis, osteomyelitis, and prosthetic device infections, can also occur. localized skin and bone infections frequently follow traumatic injury, implying the implantation of either environmental or the patient's own c. difficile spores with the subsequent development of clinical infection. it is noteworthy that except for cases involving the small intestine and reactive arthritis, most of the cases of extracolonic c. difficile disease do not appear to be strongly related to previous antibiotic exposure. the reason for this is unclear. we hope that clinicians will become more aware of these extracolonic manifestations of infection, so that they may be recognized and treated promptly and appropriately. such early diagnosis may also serve to prevent extensive and perhaps unnecessary patient evaluations, thus improving resource utilization and shortening length of hospital stay.\"",
            "contribution_ids": [
                "R34383"
            ]
        },
        {
            "instance_id": "R34411xR34392",
            "comparison_id": "R34411",
            "paper_id": "R34392",
            "text": "Treatment of metronidazole-refractory Clostridium difficile enteritis with vancomycin background\\nclostridium difficile infection of the colon is a common and well-described clinical entity. clostridium difficile enteritis of the small bowel is believed to be less common and has been described sparsely in the literature.\\n\\n\\nmethods\\ncase report and literature review.\\n\\n\\nresults\\nwe describe a patient who had undergone total proctocolectomy with ileal pouch-anal anastomosis who was treated with broad-spectrum antibiotics and contracted c. difficile refractory to metronidazole. the enteritis resolved quickly after initiation of combined oral vancomycin and metronidazole. a literature review found that eight of the fifteen previously reported cases of c. difficile-associated small-bowel enteritis resulted in death.\\n\\n\\nconclusions\\nit is important for physicians who treat acolonic patients to be aware of c. difficile enteritis of the small bowel so that it can be suspected, diagnosed, and treated.",
            "contribution_ids": [
                "R34393"
            ]
        },
        {
            "instance_id": "R34411xR34366",
            "comparison_id": "R34411",
            "paper_id": "R34366",
            "text": "Perforation Complicating Rifampin-Associated Pseudomembranous Enteritis an 18-year-old man developed a perforated jejunum while receiving rifampin antituberculous chemotherapy. the perforations were located within longitudinal ulcers characteristic of pseudomembranous enterocolitis. pseudomembranous inflammation was limited to the small intestine. the absence of colonic involvement delayed establishment of the diagnosis. successful surgical intervention consisting of small-bowel resection with primary anastomosis was accomplished for this rare and potentially fatal complication of antituberculous chemotherapy.",
            "contribution_ids": [
                "R34367"
            ]
        },
        {
            "instance_id": "R34411xR34405",
            "comparison_id": "R34411",
            "paper_id": "R34405",
            "text": "Enteral Clostrid- ium difficile, an emerging cause for high-output ileostomy the loss of fluid and electrolytes from a high-output ileostomy (&gt;1200 ml/day) can quickly result in dehydration and if not properly managed may cause acute renal failure. the management of a high-output ileostomy is based upon three principles: correction of electrolyte disturbance and fluid balance, pharmacological reduction of ileostomy output, and treatment of any underlying identifiable cause. there is an increasing body of evidence to suggest that clostridium difficile may behave pathologically in the small intestine producing a spectrum of enteritis that mirrors the well-recognised colonic disease manifestation. clinically this can range from high-output ileostomy to fulminant enteritis. this report describes two cases of high-output ileostomy associated with enteric c difficile infection and proposes that the management algorithm of a high-output ileostomy should include exclusion of small bowel c difficile .",
            "contribution_ids": [
                "R34406"
            ]
        },
        {
            "instance_id": "R34411xR34394",
            "comparison_id": "R34411",
            "paper_id": "R34394",
            "text": "Fulminant small bowel enteritis: a rare complication of Clostridium difficile-associated disease to the editor: a 54-year-old male was admitted to a community hospital with a 3-month history of diarrhea up to 8 times a day associated with bloody bowel motions and weight loss of 6 kg. he had no past medical history or family history of note. a clinical diagnosis of colitis was made and the patient underwent a limited colonoscopy which demonstrated continuous mucosal inflammation and ulceration that was most marked in the rectum. the clinical and endoscopic findings were suggestive of acute ulcerative colitis (uc), which was subsequently supported by histopathology. the patient was managed with bowel rest and intravenous steroids. however, he developed toxic megacolon on day 4 of his admission and underwent a total colectomy with end ileostomy. on the third postoperative day the patient developed a pyrexia of 39\u00b0c, a septic screen was performed, and the central venous line (cvp) was changed with the tip culturing methicillin-resistant staphylococcus aureus (mrsa). intravenous gentamycin was commenced and discontinued after 5 days, with the patient remaining afebrile and stable. on the tenth postoperative day the patient became tachycardic (pulse 110/min), diaphoretic (temperature of 39.4\u00b0c), hypotensive (diastolic of 60 mm hg), and with a high volume nasogastric aspirates noted (2000 ml). a diagnosis of septic shock was considered although the etiology was unclear. the patient was resuscitated with intravenous fluids and transferred to the regional surgical unit for intensive care unit monitoring and management. a computed tomography (ct) of the abdomen showed a marked inflammatory process with bowel wall thickening along the entire small bowel with possible intramural air, raising the suggestion of ischemic bowel (fig. 1). however, on clinical assessment the patient elicited no signs of peritonism, his vitals were stable, he was not acidotic (ph 7.40), urine output was adequate, and his blood pressure was being maintained without inotropic support. furthermore, his ileostomy appeared healthy and well perfused, although a high volume (2500 ml in the previous 18 hours), malodorous output was noted. a sample of the stoma output was sent for microbiological analysis. given that the patient was not exhibiting evidence of peritonitis with normal vital signs, a conservative policy of fluid resuscitation was pursued with plans for exploratory laparotomy if he disimproved. ileostomy output sent for microbiology assessment was positive for clostridium difficile toxin a and b utilizing culture and enzyme immunoassays (eia). intravenous vancomycin, metronidazole, and rifampicin via a nasogastric tube were commenced in conjunction with bowel rest and total parenteral nutrition. the ileostomy output reduced markedly within 2 days and the patient\u2019s clinical condition improved. follow-up culture of the ileostomy output was negative for c. difficile toxins. the patient was discharged in good health on full oral diet 12 days following transfer. review of histopathology relating to the resected colon and subsequent endoscopic assessment of the retained rectum confirmed the initial diagnosis of uc, rather than a primary diagnosis of pseudomembranous colitis. clostridium difficile is the leading cause of nosocomial diarrhea associated with antibiotic therapy and is almost always limited to the colonic mucosa.1 small bowel enteritis secondary to c. difficile is exceedingly rare, with only 21 previous cases cited in the literature.2,3 of this cohort, 18 patients had a surgical procedure at some timepoint prior to the development of c. difficile enteritis, while the remaining 3 patients had no surgical procedure prior to the infection. the time span between surgery and the development of enteritis ranged from 4 days to 31 years. antibiotic therapy predisposed to the development of c. difficile enteritis in 20 of the cases. a majority of the patients (n 11) had a history of inflammatory bowel disease (ibd), with 8 having uc similar to our patient and the remaining 3 patients having a history of crohn\u2019s disease. the etiology of small bowel enteritis remains unclear. c. difficile has been successfully isolated from the small bowel in both autopsy specimens and from jejunal aspirate of patients with chronic diarrhea, suggesting that the small bowel may act as a reservoir for c. difficile.4 this would suggest that c. difficile could become pathogenic in the small bowel following a disruption in the small bowel flora in the setting of antibiotic therapy. this would be supported by the observation that the majority of cases reported occurred within 90 days of surgery with attendant disruption of bowel function. the prevalence of c. difficile-associated disease (cdad) in patients with ibd is increasing. issa et al5 examined the impact of cdad in a cohort of patients with ibd. they found that more than half of the patients with a positive culture for c. difficile were admitted and 20% required a colectomy. they reported that maintenance immunomodulator use and colonic involvement were independent risk factors for c. difficile infection in patients with ibd. the rising incidence of c. difficile in patients with ibd coupled with the use of increasingly potent immunomodulatory therapies means that clinicians must have a high index of suspicopyright \u00a9 2008 crohn\u2019s & colitis foundation of america, inc. doi 10.1002/ibd.20758 published online 22 october 2008 in wiley interscience (www.interscience.wiley.com).",
            "contribution_ids": [
                "R34395"
            ]
        },
        {
            "instance_id": "R34411xR34374",
            "comparison_id": "R34411",
            "paper_id": "R34374",
            "text": "Clostridium difficile small bowel enteritis occurring after total colectomy clostridium difficile infection is usually associated with antibiotic therapy and is almost always limited to the colonic mucosa. small bowel enteritis is rare: only 9 cases have been previously cited in the literature. this report describes a case of c. difficile small bowel enteritis that occurred in a patient after total colectomy and reviews the 9 previously reported cases of c. difficile enteritis.",
            "contribution_ids": [
                "R34375"
            ]
        },
        {
            "instance_id": "R34454xR34436",
            "comparison_id": "R34454",
            "paper_id": "R34436",
            "text": "Facial Expression Recognition using PCA and Gabor with JAFFE Database abstract \u2014 in this paper i discussed facial expression recognition system in two different ways and with two different databases. principal component analysis is used here for feature extraction. i used jaffe (japanese female facial expression). i implemented system with jaffe database, i got accuracy of the algorithm is about 70-71% which gives quite poor efficiency of the system. then i implemented facial expression recognition system with gabor filter and pca. here gabor filter selected because of its good feature extraction property. the output of the gabor filter was used as an input for the pca. pca has a good feature of dimension reduction so it was choose for that purpose.",
            "contribution_ids": [
                "R34437"
            ]
        },
        {
            "instance_id": "R34454xR34446",
            "comparison_id": "R34454",
            "paper_id": "R34446",
            "text": "Robust Facial Expression Recognition Using Local Binary Patterns a novel low-computation discriminative feature space is introduced for facial expression recognition capable of robust performance over a rang of image resolutions. our approach is based on the simple local binary patterns (lbp) for representing salient micro-patterns of face images. compared to gabor wavelets, the lbp features can be extracted faster in a single scan through the raw image and lie in a lower dimensional space, whilst still retaining facial information efficiently. template matching with weighted chi square statistic and support vector machine are adopted to classify facial expressions. extensive experiments on the cohn-kanade database illustrate that the lbp features are effective and efficient for facial expression discrimination. additionally, experiments on face images with different resolutions show that the lbp features are robust to low-resolution images, which is critical in real-world applications where only low-resolution video input is available.",
            "contribution_ids": [
                "R34447"
            ]
        },
        {
            "instance_id": "R34454xR34438",
            "comparison_id": "R34454",
            "paper_id": "R34438",
            "text": "A Region Based Methodology for Facial Expression Recognition this work investigates the use of a point distribution model to detect prominent features in a face (eyes, brows, mouth, etc) and the subsequent facial feature extraction and facial expression classification into seven categories (anger, fear, surprise, happiness, disgust, neutral and sadness). a multi-scale and multi-orientation gabor filter bank, designed in such a way so as to avoid redundant information, is used to extract facial features at selected locations of the prominent features of a face (fiducial points). a region based approach is employed at the location of the fiducial points using different region sizes to allow some degree of flexibility and avoid artefacts due to incorrect automatic discovery of these points. a feed forward back propagation artificial neural network is employed to classify the extracted feature vectors. the methodology is evaluated by forming 7 different regions and the feature vector is extracted at the location of 20 fiducial points.",
            "contribution_ids": [
                "R34439"
            ]
        },
        {
            "instance_id": "R34454xR34432",
            "comparison_id": "R34454",
            "paper_id": "R34432",
            "text": "Constants across cultures in the face and emotion. this study addresses the question of whether any facial expressions of emotion are universal. recent studies showing that members of literate cultures associated the same emotion concepts with the same facial behaviors could not demonstrate that at least some facial expressions of emotion are universal; the cultures compared had all been exposed to some of the same mass media presentations of facial expression, and these may have taught the people in each culture to recognize the unique facial expressions of other cultures. to show that members of a preliterate culture who had minimal exposure to literate cultures would associate the same emotion concepts with the same facial behaviors as do members of western and eastern literate cultures, data were gathered in new guinea by telling subjects a story, showing them a set of three faces, and asking them to select the face which showed the emotion appropriate to the story. the results provide evidence in support of the hypothesis that the association between particular facial muscular patterns and discrete emotions is universal.",
            "contribution_ids": [
                "R34433"
            ]
        },
        {
            "instance_id": "R34605xR34538",
            "comparison_id": "R34605",
            "paper_id": "R34538",
            "text": "Anonymizing graphs against weight-based attacks the increasing popularity of graph data, such as social and online communities, has initiated a prolific research area in knowledge discovery and data mining. as more real-world graphs are released publicly, there is growing concern about privacy breaching for the entities involved. an adversary may reveal identities of individuals in a published graph by having the topological structure and/or basic graph properties as background knowledge. many previous studies addressing such attack as identity disclosure, however, concentrate on preserving privacy in simple graph data only. in this paper, we consider the identity disclosure problem in weighted graphs. the motivation is that, a weighted graph can introduce much more unique information than its simple version, which makes the disclosure easier. we first formalize a general anonymization model to deal with weight-based attacks. then two concrete attacks are discussed based on weight properties of a graph, including the sum and the set of adjacent weights for each vertex. we also propose a complete solution for the weight anonymization problem to prevent a graph from both attacks. our approaches are efficient and practical, and have been validated by extensive experiments on both synthetic and real-world datasets.",
            "contribution_ids": [
                "R34539"
            ]
        },
        {
            "instance_id": "R34605xR34581",
            "comparison_id": "R34605",
            "paper_id": "R34581",
            "text": "Edge Anonymity in Social Network Graphs edges in social network graphs may represent sensitive relationships. in this paper, we consider the problem of edges anonymity in graphs. we propose a probabilistic notion of edge anonymity, called graph confidence, which is general enough to capture the privacy breach made by an adversary who can pinpoint target persons in a graph partition based on any given set of topological features of vertexes. we consider a special type of edge anonymity problem which uses vertex degree to partition a graph. we analyze edge disclosure in real-world social networks and show that although some graphs can preserve vertex anonymity, they may still not preserve edge anonymity. we present three heuristic algorithms that protect edge anonymity using edge swap or edge deletion. our experimental results, based on three real-world social networks and several utility measures, show that these algorithms can effectively preserve edge anonymity yet obtain anonymous graphs of acceptable utility.",
            "contribution_ids": [
                "R34582"
            ]
        },
        {
            "instance_id": "R34605xR34526",
            "comparison_id": "R34605",
            "paper_id": "R34526",
            "text": "Preserving Privacy in Social Networks Against Neighborhood Attacks \"recently, as more and more social network data has been published in one way or another, preserving privacy in publishing social network data becomes an important concern. with some local knowledge about individuals in a social network, an adversary may attack the privacy of some victims easily. unfortunately, most of the previous studies on privacy preservation can deal with relational data only, and cannot be applied to social network data. in this paper, we take an initiative towards preserving privacy in social network data. we identify an essential type of privacy attacks: neighborhood attacks. if an adversary has some knowledge about the neighbors of a target victim and the relationship among the neighbors, the victim may be re-identified from a social network even if the victim's identity is preserved using the conventional anonymization techniques. we show that the problem is challenging, and present a practical solution to battle neighborhood attacks. the empirical study indicates that anonymized social networks generated by our method can still be used to answer aggregate network queries with high accuracy.\"",
            "contribution_ids": [
                "R34527"
            ]
        },
        {
            "instance_id": "R34605xR34603",
            "comparison_id": "R34605",
            "paper_id": "R34603",
            "text": "Anonimos: an LP based approach for anonymizing weighted social network graphs the increasing popularity of social networks has initiated a fertile research area in information extraction and data mining. anonymization of these social graphs is important to facilitate publishing these data sets for analysis by external entities. prior work has concentrated mostly on node identity anonymization and structural anonymization. but with the growing interest in analyzing social networks as a weighted network, edge weight anonymization is also gaining importance. we present ano\u0301nimos, a linear programming-based technique for anonymization of edge weights that preserves linear properties of graphs. such properties form the foundation of many important graph-theoretic algorithms such as shortest paths problem, k-nearest neighbors, minimum cost spanning tree, and maximizing information spread. as a proof of concept, we apply ano\u0301nimos to the shortest paths problem and its extensions, prove the correctness, analyze complexity, and experimentally evaluate it using real social network data sets. our experiments demonstrate that ano\u0301nimos anonymizes the weights, improves k-anonymity of the weights, and also scrambles the relative ordering of the edges sorted by weights, thereby providing robust and effective anonymization of the sensitive edge-weights. we also demonstrate the composability of different models generated using ano\u0301nimos, a property that allows a single anonymized graph to preserve multiple linear properties.",
            "contribution_ids": [
                "R34604"
            ]
        },
        {
            "instance_id": "R34605xR34574",
            "comparison_id": "R34605",
            "paper_id": "R34574",
            "text": "Randomizing Social Networks: a Spectrum Preserving Approach understanding the general properties of real social networks has gained much attention due to the proliferation of networked data. the nodes in the network are the individuals and the links among them denote their relationships. many applications of networks such as anonymous web browsing require relationship anonymity due to the sensitive, stigmatizing, or confidential nature of the relationship. one general approach for this problem is to randomize the edges in true networks, and only disclose the randomized networks. in this paper, we investigate how various properties of networks may be affected due to randomization. specifically, we focus on the spectrum since the eigenvalues of a network are intimately connected to many important topological features. we also conduct theoretical analysis on the extent to which edge anonymity can be achieved. a spectrum preserving graph randomization method, which can better preserve network properties while protecting edge anonymity, is then presented and empirically evaluated.",
            "contribution_ids": [
                "R34575"
            ]
        },
        {
            "instance_id": "R34605xR34519",
            "comparison_id": "R34605",
            "paper_id": "R34519",
            "text": "Measuring Topological Anonymity in Social Networks this paper presents new clustering algorithms which are based on agglomerative hierarchical clustering (ahc) with centroid method. the algorithms can handle with data with tolerance of which the concept includes some errors, ranges, or missing values in data. first, the tolerance is introduced into optimization problems of clustering. second, an objective function is introduced for calculating the centroid of cluster and the problem is solved using kuhn-tucker conditions. next, new algorithms are constructed based on the solution of the problem. finally, the effectiveness of the proposed algorithms in this paper is verified through some numeric examples for the artificial data.",
            "contribution_ids": [
                "R34520",
                "R34570"
            ]
        },
        {
            "instance_id": "R34605xR34596",
            "comparison_id": "R34605",
            "paper_id": "R34596",
            "text": "k-ANONYMITY: A MODEL FOR PROTECTING PRIVACY consider a data holder, such as a hospital or a bank, that has a privately held collection of person-specific, field structured data. suppose the data holder wants to share a version of the data with researchers. how can a data holder release a version of its private data with scientific guarantees that the individuals who are the subjects of the data cannot be re-identified while the data remain practically useful? the solution provided in this paper includes a formal protection model named k-anonymity and a set of accompanying policies for deployment. a release provides k-anonymity protection if the information for each person contained in the release cannot be distinguished from at least k-1 individuals whose information also appears in the release. this paper also examines re-identification attacks that can be realized on releases that adhere to k-anonymity unless accompanying policies are respected. the k-anonymity protection model is important because it forms the basis on which the real-world systems known as datafly, \u03bc-argus and k-similar provide guarantees of privacy protection.",
            "contribution_ids": [
                "R34597"
            ]
        },
        {
            "instance_id": "R34605xR34503",
            "comparison_id": "R34605",
            "paper_id": "R34503",
            "text": "The union-split algorithm and cluster-based anonymization of social networks \"knowledge discovery on social network data can uncover latent social trends and produce valuable findings that benefit the welfare of the general public. a growing amount of research finds that social networks play a surprisingly powerful role in people's behaviors. before the social network data can be released for research purposes, the data needs to be anonymized to prevent potential re-identification attacks. most of the existing anonymization approaches were developed for relational data, and cannot be used to handle social network data directly.\\n in this paper, we model social networks as undirected graphs and formally define privacy models, attack models for the anonymization problem, in particular an i-hop degree-based anonymization problem, i.e., the adversary's prior knowledge includes the target's degree and the degrees of neighbors within i hops from the target. we present two new and efficient clustering methods for undirected graphs: bounded t-means clustering and union-split clustering algorithms that group similar graph nodes into clusters with a minimum size constraint. these clustering algorithms are contributions beyond the specific social network problems studied and can be used to cluster general data types besides graph vertices. we also develop a simple-yet-effective inter-cluster matching method for anonymizing social networks by strategically adding and removing edges based on nodes' social roles. we carry out a series of experiments to evaluate the graph utilities of the anonymized social networks produced by our algorithms.\"",
            "contribution_ids": [
                "R34504",
                "R34546"
            ]
        },
        {
            "instance_id": "R34605xR34506",
            "comparison_id": "R34605",
            "paper_id": "R34506",
            "text": "Preserving Privacy in Social Networks: A Structure-Aware Approach graph structured data can be ubiquitously found in the real world. for example, social networks can easily be represented as graphs where the graph connotes the complex sets of relationships between members of social systems. while their analysis could be beneficial in many aspects, publishing certain types of social networks raises significant privacy concerns. this brings the problem of graph anonymization into sharp focus. unlike relational data, the true information in graph structured data is encoded within the structure and graph properties. motivated by this, we propose a structure aware anonymization approach that maximally preserves the structure of the original network as well as its structural properties while anonymizing it. instead of anonymizing each node one by one independently, our approach treats each partitioned substructural component of the network as one single unit to be anonymized. this maximizes utility while enabling anonymization. we apply our method to both synthetic and real datasets and demonstrate its effectiveness and practical usefulness.",
            "contribution_ids": [
                "R34507"
            ]
        },
        {
            "instance_id": "R34605xR34529",
            "comparison_id": "R34605",
            "paper_id": "R34529",
            "text": "Preservation of Privacy in Publishing Social Network Data \"this paper consider the privacy disclosure in social network data publishing. we assume that adversaries know the degree of a target individual and the target's immediate neighbors, and identify an essential type of privacy attacks: background knowledge attacks. we propose a practical solution to defend against background knowledge attacks. the experimental results confirm that the anonymized social networks obtained by our method can still be used to answer aggregate network queries with high accuracy.\"",
            "contribution_ids": [
                "R34530"
            ]
        },
        {
            "instance_id": "R34605xR34958",
            "comparison_id": "R34605",
            "paper_id": "R34958",
            "text": "K-isomorphism: privacy preserving network publication against structural attacks serious concerns on privacy protection in social networks have been raised in recent years; however, research in this area is still in its infancy. the problem is challenging due to the diversity and complexity of graph data, on which an adversary can use many types of background knowledge to conduct an attack. one popular type of attacks as studied by pioneer work [2] is the use of embedding subgraphs. we follow this line of work and identify two realistic targets of attacks, namely, nodeinfo and linkinfo. our investigations show that k-isomorphism, or anonymization by forming k pairwise isomorphic subgraphs, is both sufficient and necessary for the protection. the problem is shown to be np-hard. we devise a number of techniques to enhance the anonymization efficiency while retaining the data utility. a compound vertex id mechanism is also introduced for privacy preservation over multiple data releases. the satisfactory performance on a number of real datasets, including hep-th, euemail and livejournal, illustrates that the high symmetry of social networks is very helpful in mitigating the difficulty of the problem.",
            "contribution_ids": [
                "R34543",
                "R34587",
                "R34960"
            ]
        },
        {
            "instance_id": "R34605xR34556",
            "comparison_id": "R34605",
            "paper_id": "R34556",
            "text": "A New Approach to Manage Security against Neighborhood Attacks in Social Networks now a days, more and more of social network data are being published in one way or other. so, preserving privacy in publishing social network data has become an important concern. with some local knowledge about individuals in a social network, an adversary may attack the privacy of some victims easily. most of the work done so far towards privacy preservation can deal with relational data only. however, bin zhou and jian pei [11] proposed a scheme for anonymization of social networks, which is an initiative in this direction and provides a partial solution to this problem. in fact, their algorithm cannot handle the situations in which an adversary has knowledge about vertices in the second or higher hops of a vertex, in addition to its immediate neighbors. in this paper, we propose a modification to their algorithm for the network anonymization which can handle such situations. in doing so, we use an algorithm for graph isomorphism based on adjacency matrix instead of their approach using dfs technique [11]. more importantly, the time complexity of our algorithm is less than that of zhou and pei.",
            "contribution_ids": [
                "R34557"
            ]
        },
        {
            "instance_id": "R34605xR34561",
            "comparison_id": "R34605",
            "paper_id": "R34561",
            "text": "Preserving the Privacy of Sensitive Relationships in Graph Data utilizing the online social networks like face-book etc were increased a lot in the recent years. these applications provides good interface to share the data to people on the internet. this will provide an advantage to the attackers to gather user\u2019s personnel information. we propose a new approach to protect the user\u2019s data even the shared link is visible to malicious users. the proposed algorithm uses sanitizing techniques to hide the user\u2019s data. graph theory is used to find the growth of the shared data on online social networks. our method will not disturb the actual relationships and provides the basic details to the relations.",
            "contribution_ids": [
                "R34562",
                "R34566",
                "R34572"
            ]
        },
        {
            "instance_id": "R34663xR34658",
            "comparison_id": "R34663",
            "paper_id": "R34658",
            "text": "Data quality assessment in healthcare: a 365-day chart review of inpatients' health records at a Nigerian tertiary hospital \"background\\nhealth records are essential for good health care. their quality depends on accurate and prompt documentation of the care provided and regular analysis of content. this study assessed the quantitative properties of inpatient health records at the federal medical centre, bida, nigeria.\\n\\n\\nmethod\\na retrospective study was carried out to assess the documentation of 780 paper-based health records of inpatients discharged in 2009.\\n\\n\\nresults\\n732 patient records were reviewed from the departments of obstetrics (45.90%), pediatrics (24.32%), and other specialties (29.78%). documentation performance was very good (98.49%) for promptness recording care within the first 24 h of admission, fair (58.80%) for proper entry of patient unit number (unique identifier), and very poor (12.84%) for utilization of discharge summary forms. overall, surgery records were nearly always (100%) prompt regarding care documentation, obstetrics records were consistent (80.65%) in entering patients' names in notes, and the principal diagnosis was properly documented in all (100%) completed discharge summary forms in medicine. 454 (62.02%) folders were chronologically arranged, 456 (62.29%) were properly held together with file tags, and most (80.60%) discharged folders reviewed, analyzed and appropriate code numbers were assigned.\\n\\n\\nconclusions\\ninadequacies were found in clinical documentation, especially gross underutilization of discharge summary forms. however, some forms were properly documented, suggesting that hospital healthcare providers possess the necessary skills for quality clinical documentation but lack the will. there is a need to institute a clinical documentation improvement program and promote quality clinical documentation among staff.\"",
            "contribution_ids": [
                "R34659"
            ]
        },
        {
            "instance_id": "R34663xR34647",
            "comparison_id": "R34663",
            "paper_id": "R34647",
            "text": "Electronic immunization data collection systems: application of an evaluation framework abstract \\n \\n background \\n evaluating the features and performance of health information systems can serve to strengthen the systems themselves as well as to guide other organizations in the process of designing and implementing surveillance tools. we adapted an evaluation framework in order to assess electronic immunization data collection systems, and applied it in two ontario public health units. \\n \\n \\n methods \\n the centers for disease control and prevention\u2019s guidelines for evaluating public health surveillance systems are broad in nature and serve as an organizational tool to guide the development of comprehensive evaluation materials. based on these guidelines, and informed by other evaluation resources and input from stakeholders in the public health community, we applied an evaluation framework to two examples of immunization data collection and examined several system attributes: simplicity, flexibility, data quality, timeliness, and acceptability. data collection approaches included key informant interviews, logic and completeness assessments, client surveys, and on-site observations. \\n \\n \\n results \\n both evaluated systems allow high-quality immunization data to be collected, analyzed, and applied in a rapid fashion. however, neither system is currently able to link to other providers\u2019 immunization data or provincial data sources, limiting the comprehensiveness of coverage assessments. we recommended that both organizations explore possibilities for external data linkage and collaborate with other jurisdictions to promote a provincial immunization repository or data sharing platform. \\n \\n \\n conclusions \\n electronic systems such as the ones described in this paper allow immunization data to be collected, analyzed, and applied in a rapid fashion, and represent the infostructure required to establish a population-based immunization registry, critical for comprehensively assessing vaccine coverage. \\n",
            "contribution_ids": [
                "R34648"
            ]
        },
        {
            "instance_id": "R34706xR34686",
            "comparison_id": "R34706",
            "paper_id": "R34686",
            "text": "HEFT based workflow scheduling algorithm for cost optimization within deadline in hybrid clouds cloud computing nowadays is playing major role in storage and processing huge tasks with scalability options. deadline based scheduling is the main focus when we process the tasks using available resources. private cloud is owned by an organization and resources are free for user whereas public clouds charge users using pay-as-you-go model. when the private cloud is not enough for processing user tasks, resources can be acquired from public cloud. the combination of a public cloud and a private cloud gives rise to hybrid cloud. in hybrid clouds, task scheduling is a complex process as tasks can be allocated resources of either the private cloud or the public cloud. this paper presents an algorithm that decides which resources should be taken on lease from public cloud to complete the workflow execution within deadline and with minimum monetary cost for user. a hybrid scheduling algorithm has been proposed which uses a new concept of sub-deadline for rescheduling and allocation of resources in public cloud. the algorithm helps in finding best resources on public cloud for cost saving and complete workflow execution within deadlines. three rescheduling policies have been evaluated in this paper. for performance analysis, we have compared the heft (heterogeneous earliest finish time) based hybrid scheduling algorithm with greedy approach and min-min approach. results have shown that the proposed algorithm optimizes a large amount of cost compared to greedy and min-min approaches and completes all tasks within deadline.",
            "contribution_ids": [
                "R34687"
            ]
        },
        {
            "instance_id": "R34706xR34682",
            "comparison_id": "R34706",
            "paper_id": "R34682",
            "text": "An Improved Max-Min Task-Scheduling Algorithm for Elastic Cloud in cloud computing, load balancing aids in minimizing resource consumption and avoids bottlenecks. although many load balancing schemes have been presented, there is no scheme providing the elasticity in cloud computing. a max-min task-scheduling algorithm for load balance in the elastic cloud is proposed in this paper. to realize the load balancing, the proposed algorithm maintains a task status table to estimate the real-time load of virtual machines and the expected completion time of tasks, which can allocate the workload among nodes and realize the load balance. the extensive experiments demonstrate that the proposed max-min task-scheduling algorithm can improve the resource utilization as well as reduce the response time of tasks.",
            "contribution_ids": [
                "R34683"
            ]
        },
        {
            "instance_id": "R34706xR34701",
            "comparison_id": "R34706",
            "paper_id": "R34701",
            "text": "Performance evaluation of web servers using central load balancing policy over virtual machines on cloud cloud computing adds more power to the existing internet technologies. virtualization harnesses the power of the existing infrastructure and resources. with virtualization we can simultaneously run multiple instances of different commodity operating systems. since we have limited processors and jobs work in concurrent fashion, overload situations can occur. things become even more challenging in distributed environment. we propose central load balancing policy for virtual machines (clbvm) to balance the load evenly in a distributed virtual machine/cloud computing environment. this work tries to compare the performance of web servers based on our clbvm policy and independent virtual machine(vm) running on a single physical server using xen virtualizaion. the paper discusses the efficacy and feasibility of using this kind of policy for overall performance improvement.",
            "contribution_ids": [
                "R34702"
            ]
        },
        {
            "instance_id": "R34706xR34704",
            "comparison_id": "R34706",
            "paper_id": "R34704",
            "text": "A Min-Min Max-Min selective algorihtm for grid task scheduling today, the high cost of supercomputers in the one hand and the need for large-scale computational resources on the other hand, has led to use network of computational resources known as grid. numerous research groups in universities, research labs, and industries around the world are now working on a type of grid called computational grids that enable aggregation of distributed resources for solving large-scale data intensive problems in science, engineering, and commerce. several institutions and universities have started research and teaching programs on grid computing as part of their parallel and distributed computing curriculum. to better use tremendous capabilities of this distributed system, effective and efficient scheduling algorithms are needed. in this paper, we introduce a new scheduling algorithm based on two conventional scheduling algorithms, min-min and max-min, to use their cons and at the same time, cover their pros. it selects between the two algorithms based on standard deviation of the expected completion time of tasks on resources. we evaluate our scheduling heuristic, the selective algorithm, within a grid simulator called gridsim. we also compared our approach to its two basic heuristics. the experimental results show that the new heuristic can lead to significant performance gain for a variety of scenarios.",
            "contribution_ids": [
                "R34705"
            ]
        },
        {
            "instance_id": "R34845xR34799",
            "comparison_id": "R34845",
            "paper_id": "R34799",
            "text": "Eggshells of arctic terns from Finland e effects of incubation and geography \"-seventy-four eggs from seven colonies of arctic terns (sterna paradisaea) in the quark and the bothnian bay of finland were collected in 1981 shortly after laying and immediately before hatching. shell thickness, weight, thickness index, and egg weight index were determined and compared with the same characteristics of 200 eggs collected between 1874 and 1935. we found no significant differences in these measures of egg thickness between recent and museum shells from the same geographical areas. shells of museum specimens from different geographical regions did show significant variations. the weight and the wing and tarsus length of the embryos correlated negatively and significantly with all measured characteristics of the shell except its thickness when the shell membranes were present. during the incubation period, the shell's thickness (without membranes) decreased 8%; thickness index and weight decreased 4%; and the shell's thickness with shell membranes present decreased 12%. in this paper, we discuss reasons for these changes. pesticide-related reproductive failures have been reported in both american and european terns (sterna spp.; switzer and lewin 1971, koeman and van genderen 1972, switzer et al. 1973, gochfield 1975, fox 1976). for example, high levels of chlorinated hydrocarbons were found in the tissues of marine animals from the baltic sea (jensen et al. 1969, koivusaari et al. 1972, anderson and hickey 1974), an area where eggshell thinning of 1117% was reported in white-tailed eagles (haliaeetus albicilla) and ospreys (pandion haliaetus; koivusaari et al. 1980, odsjo 1982). in contrast, lemmetyinen and rantamiki (1980) reported low pesticide contamination in the eggs of arctic terns (s. paradisaea) from the archipelago of southwestern finland. the thickness of eggshells from these terns has recently increased significantly (5.2%, p < 0.05) in finland (gulf of bothnia; pulliainen and marjakangas 1980). several studies concerning geographic variations in eggshells have been published (e.g., anderson and hickey 1970, 1972; sutcliffe 1978; olsen 1982), but there are almost no studies of this kind from europe (e.g., svensson 1978). besides effects of pesticides and geography, the mobilization of eggshell calcium for the developing embryo is known to affect eggshell thickness (e.g., kreitzer 1972). our objectives, ther fore, were (1) to describe recent changes in the thickness and size of arctic tern eggshells in comparison to museum material; (2) to check the reliability of available museum material for use as a standard; and (3) to find a method for measuring shell variables that is independent of the shell thinning that occurs naturally during embryonic development. materials and methods we collected arctic tern eggs in 1981 from three colonies in quark (6 310'n, 2 12 5'e) and from four colonies in bothnian bay (65003'n, 25010'e) in the gulf of bothnia (fig. 1). at ach nest, one egg was chosen randomly at an early stage of incubation (little or no embryonic development). nine of these nests in the quark colony were marked and two more eggs were taken from each shortly before hatching was expected. where arctic and common terns (s. hirundo) bred in the same colonies, we confirmed identification of arctic tern nests by observation from a blind or by flushing a parent from its nest before taking an egg. eggs were kept in a refrigerator until prepared. their length and breadth were measured with a vernier caliper to the nearest 0.1 mm. a piece of shell, 16-18 mm in diameter, was cut out from the equator of each egg. the contents of the egg were then removed, the shells were rinsed with water, and the shell\"",
            "contribution_ids": [
                "R34800"
            ]
        },
        {
            "instance_id": "R34845xR34769",
            "comparison_id": "R34845",
            "paper_id": "R34769",
            "text": "Eggshell of the domestic guinea fowl abstract 1. physical characteristics of eggs of the domestic guinea fowl, numida meleagris galeata, were measured and compared with those of its wild counterpart and with other birds using allometric relationships. 2. the shell thickness increased and the area density of pores decreased from the blunt to the pointed end of the egg. during incubation, shell thickness decreased, but the shell diffusive conductance to water vapour (gh2o) remained constant. 3. fresh egg mass (m0), length and breadth of the egg, gh2o and specific water vapour conductance, spgh2o (gh2o per g of m0 ), were affected by the age of the laying flock. 4. eggs of the domestic guinea fowl were bigger and heavier than eggs of the wild one. 5. allometry showed that guinea fowl eggs differ from those of the other birds by their greater shell thickness and density of pores. however spgh2o was normal, the thickness of the shell being compensated for by a greater density of pores for gas exchanges.",
            "contribution_ids": [
                "R34770"
            ]
        },
        {
            "instance_id": "R34845xR34835",
            "comparison_id": "R34845",
            "paper_id": "R34835",
            "text": "Water Loss, Conductance, and Structure of Eggs of Pied Flycatchers during Egg Laying and Incubation \"eggs of pied flycatchers (ficedula hypoleuca) lose water at a slow, constant rate ($$\\\\dot{m}_{h_{2}o}$$) during egg laying but at a much higher, linear rate during incubation. prepipping losses average 20% of the egg's mass when freshly laid. the watervapor conductance ($$g_{h_{2}o}$$) of the eggshell increases (linearly) fourfold between the time the egg is laid and the end of incubation. linear increases in $$\\\\dot{m}_{h_{2}o}$$ and $$g_{h_{2}o}$$ have previously been associated with the eggs of large, precocial birds rather than those of altricial songbirds. at least 88% of the increase in $$\\\\dot{m}_{h_{2}o}$$ during the incubation period can be accounted for by changes in the egg's $$g_{h_{2}o}$$. the high water loss that occurs during the second half of incubation appears to result from shell erosion, which reduces pore length and shell thickness, and perhaps increases pore size, in the equatorial and sharp regions of the egg. increasing $$\\\\dot{m}_{h_{2}o}$$ and $$g_{h_{2}o}$$ are not due to losses of cuticle from the egg's surface or to increases in pore number, the number of open pores in the shell, or egg temperature during incubation. flycatcher eggshells have four types of pores. they are usually open, frequently bent, and evenly distributed over the egg's surface.\"",
            "contribution_ids": [
                "R34836"
            ]
        },
        {
            "instance_id": "R34845xR34843",
            "comparison_id": "R34845",
            "paper_id": "R34843",
            "text": "Variation in the Incidence of Hatching Failure in the Cedar Waxwing and Other Species hatching failure due to embryonic death or sterility is an important aspect of the breeding biology of songbirds, yet it has received little attention. many nesting studies present the overall success rate of eggs but lump the failures due to predation and other factors with those due to sterility and embryonic death. two recent exceptions are studies by ricklefs (1969) and jehl (1971). during 1968 and 1969, i conducted studies (rothstein 1971a) which provided data relevant to egg hatchability in several species. the cedar waxwing (bombycilla cedrorum) yielded especially significant data because eggs in nests near farms suffered a greater incidence of sterility or embryonic death than eggs in nests from other areas. field work was conducted",
            "contribution_ids": [
                "R34844"
            ]
        },
        {
            "instance_id": "R34845xR34803",
            "comparison_id": "R34845",
            "paper_id": "R34803",
            "text": "Incubation Water Loss in King Penguin Egg. I. Change in Egg and Brood Pouch Parameters water loss and thermal relations of the king penguin egg and its microenvironment (brood pouch) were studied under natural conditions. despite the low ambient humidity (pamb = 6.8 torr, tamb = 6.9\u00b0 c), diffusive water loss during the prolonged 53-d incubation was within the range for other bird eggs, being 13% of the mean 302-g initial egg mass. daily water loss increased throughout incubation to 1.54 times the initial value, while the low initial water vapor conductance of the shell, gsb = 28.1 \u00b7 mg \u00b7 (d \u00b7 torr)\u22121, increased by 16%. the increase in gsb was correlated withpartial loss of the organic shell cover by contact with the moist brood pouch. brood patch temperature remained constant at 38. 2\u00b0 c, while egg core temperature increased throughout incubation by 3\u00b0c the accompanying decrease in the vertical gradient of temperature inside the egg was explained mainly by a warming from 28\u00b0 to 35\u00b0c of the foot region in contact with the shell. the influence of the embryo on egg temperature increase appears secondary, as the fertile eggs at day 50 had a core temperature only 0.7\u00b0c higher than unfertile eggs.",
            "contribution_ids": [
                "R34804"
            ]
        },
        {
            "instance_id": "R34845xR34784",
            "comparison_id": "R34845",
            "paper_id": "R34784",
            "text": "Regional changes in shell thickness, shell conductance, and pore structure during incubation in eggs of the Mute Swan shell thickness, water vapor conductance, pore density, and pore structure were examined in three regions (blunt pole, equator, sharp pole) of both unincubated and hatched mute swan eggs. there was a trend for shell thickness to increase from the blunt pole to the sharp pole in unincubated eggs. during incubation, shell in the equatorial and sharp pole regions was eroded so that shell thickness in all regions was similar in hatched eggs. pore density and water-vapor conductance of unincubated eggs were significantly smaller in the equatorial region, compared with that in either the blunt or sharp pole regions, but increased during incubation. pore structure of unincubated eggs was similar in all three regions. the removal of the mammillary knobs from the equatorial and sharp pole regions during incubation caused the shell to thin but had a negligible effect on pore structure. therefore, the increase in water-vapor conductance in the equatorial region during incubation was directly related to the increase in pore density that occurred in this region.",
            "contribution_ids": [
                "R34785"
            ]
        },
        {
            "instance_id": "R34845xR34791",
            "comparison_id": "R34845",
            "paper_id": "R34791",
            "text": "Clutch Size, Hatching Success, and Eggshell-Thinning in Western Gulls author(s): hunt, gl; hunt, mw | abstract: average clutch size for large larus gulls is close to three eggs, and the production of a clutch of four is uncommon (keith 1966; paludan 1951; vermeer 1963). we report here on a colony of western gulls (larms occidentalis) in which many clutches containing four and five eggs were found. it is of particular interest that in these large clutches not only was hatching success low but also eggshell thickness was reduced.",
            "contribution_ids": [
                "R34792"
            ]
        },
        {
            "instance_id": "R36153xR36151",
            "comparison_id": "R36153",
            "paper_id": "R36151",
            "text": "Effects of voluntary event cancellation and school closure as countermeasures against COVID-19 outbreak in Japan abstract background to control the covid-19 outbreak in japan, sports and entertainment events were canceled and schools were closed throughout japan from february 26 through march 19. that policy has been designated as voluntary event cancellation and school closure (vecsc). object this study assesses vecsc effectiveness based on predicted outcomes. method: a simple susceptible\u2013infected\u2013recovery model was applied to data of patients with symptoms in japan during january 14 through march 25. the respective reproduction numbers were estimated before vecsc (r), during vecsc (r e ), and after vecsc (r a ). results results suggest r before vecsc as 1.987 [1.908, 2.055], r e during vecsc as 1.122 [0.980, 1.260], and r a after vecsc as 3.086 [2.529, 3.739]. discussion and conclusion results demonstrated that vecsc can reduce covid-19 infectiousness considerably, but the value of r rose to exceed 2.5 after vecsc.",
            "contribution_ids": [
                "R36152"
            ]
        },
        {
            "instance_id": "R36153xR36143",
            "comparison_id": "R36153",
            "paper_id": "R36143",
            "text": "A Cybernetics-based Dynamic Infection Model for Analyzing SARS-COV-2 Infection Stability and Predicting Uncontrollable Risks abstract since december 2019, covid-19 has raged in wuhan and subsequently all over china and the world. we propose a cybernetics-based dynamic infection model (cdim) to the dynamic infection process with a probability distributed incubation delay and feedback principle. reproductive trends and the stability of the sars-cov-2 infection in a city can then be analyzed, and the uncontrollable risks can be forecasted before they really happen. the infection mechanism of a city is depicted using the philosophy of cybernetics and approaches of the control engineering. distinguished with other epidemiological models, such as sir, seir, etc., that compute the theoretical number of infected people in a closed population, cdim considers the immigration and emigration population as system inputs, and administrative and medical resources as dynamic control variables. the epidemic regulation can be simulated in the model to support the decision-making for containing the outbreak. city case studies are demonstrated for verification and validation.",
            "contribution_ids": [
                "R36144"
            ]
        },
        {
            "instance_id": "R36153xR36146",
            "comparison_id": "R36153",
            "paper_id": "R36146",
            "text": "COVID-19 outbreak in Algeria: A mathematical model to predict the incidence abstract introduction since december 29, 2019 a pandemic of new novel coronavirus-infected pneumonia named covid-19 has started from wuhan, china, has led to 254 996 confirmed cases until midday march 20, 2020. sporadic cases have been imported worldwide, in algeria, the first case reported on february 25, 2020 was imported from italy, and then the epidemic has spread to other parts of the country very quickly with 139 confirmed cases until march 21, 2020. methods it is crucial to estimate the cases number growth in the early stages of the outbreak, to this end, we have implemented the alg-covid-19 model which allows to predict the incidence and the reproduction number r0 in the coming months in order to help decision makers. the alg-covis-19 model initial equation 1, estimates the cumulative cases at t prediction time using two parameters: the reproduction number r0 and the serial interval si. results we found r0=2.55 based on actual incidence at the first 25 days, using the serial interval si= 4,4 and the prediction time t=26. the herd immunity hi estimated is hi=61%. also, the covid-19 incidence predicted with the alg-covid-19 model fits closely the actual incidence during the first 26 days of the epidemic in algeria fig. 1.a. which allows us to use it. according to alg-covid-19 model, the number of cases will exceed 5000 on the 42 th day (april 7 th ) and it will double to 10000 on 46th day of the epidemic (april 11 th ), thus, exponential phase will begin (table 1; fig.1.b) and increases continuously until reaching \u00e0 herd immunity of 61% unless serious preventive measures are considered. discussion this model is valid only when the majority of the population is vulnerable to covid-19 infection, however, it can be updated to fit the new parameters values.",
            "contribution_ids": [
                "R36147"
            ]
        },
        {
            "instance_id": "R36153xR36118",
            "comparison_id": "R36153",
            "paper_id": "R36118",
            "text": "The Novel Coronavirus, 2019-nCoV, is Highly Contagious and More Infectious Than Initially Estimated abstract the novel coronavirus (2019-ncov) is a recently emerged human pathogen that has spread widely since january 2020. initially, the basic reproductive number, r 0 , was estimated to be 2.2 to 2.7. here we provide a new estimate of this quantity. we collected extensive individual case reports and estimated key epidemiology parameters, including the incubation period. integrating these estimates and high-resolution real-time human travel and infection data with mathematical models, we estimated that the number of infected individuals during early epidemic double every 2.4 days, and the r 0 value is likely to be between 4.7 and 6.6. we further show that quarantine and contact tracing of symptomatic individuals alone may not be effective and early, strong control measures are needed to stop transmission of the virus. one-sentence summary by collecting and analyzing spatiotemporal data, we estimated the transmission potential for 2019-ncov.",
            "contribution_ids": [
                "R36119",
                "R36120",
                "R36121",
                "R36122"
            ]
        },
        {
            "instance_id": "R36153xR36128",
            "comparison_id": "R36153",
            "paper_id": "R36128",
            "text": "Risk estimation and prediction by modeling the transmission of the novel coronavirus (COVID-19) in mainland China excluding Hubei province abstract background in december 2019, an outbreak of coronavirus disease (covid-19) was identified in wuhan, china and, later on, detected in other parts of china. our aim is to evaluate the effectiveness of the evolution of interventions and self-protection measures, estimate the risk of partial lifting control measures and predict the epidemic trend of the virus in mainland china excluding hubei province based on the published data and a novel mathematical model. methods a novel covid-19 transmission dynamic model incorporating the intervention measures implemented in china is proposed. covid-19 daily data of mainland china excluding hubei province, including the cumulative confirmed cases, the cumulative deaths, newly confirmed cases and the cumulative recovered cases for the period january 20th-march 3rd, 2020, were archived from the national health commission of china (nhcc). we parameterize the model by using the markov chain monte carlo (mcmc) method and estimate the control reproduction number r c , as well as the effective daily reproduction ratio r e ( t ), of the disease transmission in mainland china excluding hubei province. results the estimation outcomes indicate that r c is 3.36 (95% ci 3.20-3.64) and r e ( t ) has dropped below 1 since january 31st, 2020, which implies that the containment strategies implemented by the chinese government in mainland china excluding hubei province are indeed effective and magnificently suppressed covid-19 transmission. moreover, our results show that relieving personal protection too early may lead to the spread of disease for a longer time and more people would be infected, and may even cause epidemic or outbreak again. by calculating the effective reproduction ratio, we prove that the contact rate should be kept at least less than 30% of the normal level by april, 2020. conclusions to ensure the epidemic ending rapidly, it is necessary to maintain the current integrated restrict interventions and self-protection measures, including travel restriction, quarantine of entry, contact tracing followed by quarantine and isolation and reduction of contact, like wearing masks, etc. people should be fully aware of the real-time epidemic situation and keep sufficient personal protection until april. if all the above conditions are met, the outbreak is expected to be ended by april in mainland china apart from hubei province.",
            "contribution_ids": [
                "R36129"
            ]
        },
        {
            "instance_id": "R36153xR36109",
            "comparison_id": "R36153",
            "paper_id": "R36109",
            "text": "Transmission interval estimates suggest pre-symptomatic spread of COVID-19 abstract background as the covid-19 epidemic is spreading, incoming data allows us to quantify values of key variables that determine the transmission and the effort required to control the epidemic. we determine the incubation period and serial interval distribution for transmission clusters in singapore and in tianjin. we infer the basic reproduction number and identify the extent of pre-symptomatic transmission. methods we collected outbreak information from singapore and tianjin, china, reported from jan.19-feb.26 and jan.21-feb.27, respectively. we estimated incubation periods and serial intervals in both populations. results the mean incubation period was 7.1 (6.13, 8.25) days for singapore and 9 (7.92, 10.2) days for tianjin. both datasets had shorter incubation periods for earlier-occurring cases. the mean serial interval was 4.56 (2.69, 6.42) days for singapore and 4.22 (3.43, 5.01) for tianjin. we inferred that early in the outbreaks, infection was transmitted on average 2.55 and 2.89 days before symptom onset (singapore, tianjin). the estimated basic reproduction number for singapore was 1.97 (1.45, 2.48) secondary cases per infective; for tianjin it was 1.87 (1.65, 2.09) secondary cases per infective. conclusions estimated serial intervals are shorter than incubation periods in both singapore and tianjin, suggesting that pre-symptomatic transmission is occurring. shorter serial intervals lead to lower estimates of r0, which suggest that half of all secondary infections should be prevented to control spread.",
            "contribution_ids": [
                "R36110",
                "R36112"
            ]
        },
        {
            "instance_id": "R36153xR36130",
            "comparison_id": "R36153",
            "paper_id": "R36130",
            "text": "Assessing the plausibility of subcritical transmission of 2019-nCoV in the United States abstract rapid assessment of the transmission potential of an emerging or reemerging pathogen is a cornerstone of public health response. a simple approach is shown for using the number of disease introductions and secondary cases to determine whether the upper bound of the reproduction number exceeds the critical value of one.",
            "contribution_ids": [
                "R36131"
            ]
        },
        {
            "instance_id": "R36153xR36132",
            "comparison_id": "R36153",
            "paper_id": "R36132",
            "text": "Lessons drawn from China and South Korea for managing COVID-19 epidemic: insights from a comparative modeling study abstract we conducted a comparative study of covid-19 epidemic in three different settings: mainland china, the guangdong province of china and south korea, by formulating two disease transmission dynamics models incorporating epidemic characteristics and setting-specific interventions, and fitting the models to multi-source data to identify initial and effective reproduction numbers and evaluate effectiveness of interventions. we estimated the initial basic reproduction number for south korea, the guangdong province and mainland china as 2.6 (95% confidence interval (ci): (2.5, 2.7)), 3.0 (95%ci: (2.6, 3.3)) and 3.8 (95%ci: (3.5,4.2)), respectively, given a serial interval with mean of 5 days with standard deviation of 3 days. we found that the effective reproduction number for the guangdong province and mainland china has fallen below the threshold 1 since february 8 th and 18 th respectively, while the effective reproduction number for south korea remains high, suggesting that the interventions implemented need to be enhanced in order to halt further infections. we also project the epidemic trend in south korea under different scenarios where a portion or the entirety of the integrated package of interventions in china is used. we show that a coherent and integrated approach with stringent public health interventions is the key to the success of containing the epidemic in china and specially its provinces outside its epicenter, and we show that this approach can also be effective to mitigate the burden of the covid-19 epidemic in south korea. the experience of outbreak control in mainland china should be a guiding reference for the rest of the world including south korea.",
            "contribution_ids": [
                "R36133",
                "R36135",
                "R36137"
            ]
        },
        {
            "instance_id": "R38484xR23436",
            "comparison_id": "R38484",
            "paper_id": "R23436",
            "text": "Climate Simulations Using MRI-AGCM3.2 with 20-km Grid a new version of the atmospheric general circulation model of the meteorological research institute (mri), with a horizontal grid size of about 20 km, has been developed. the previous version of the 20-km model, mriagcm3.1, which was developed from an operational numerical weather-prediction model, provided information on possible climate change induced by global warming, including future changes in tropical cyclones, the east asian monsoon, extreme events, and blockings. for the new version, mri-agcm3.2, we have introduced various new parameterization schemes that improve the model climate. using the new model, we performed a present-day climate experiment using observed sea surface temperature. the model shows improvements in simulating heavy monthly-mean precipitation around the tropical western pacific, the global distribution of tropical cyclones, the seasonal march of east asian summer monsoon, and blockings in the pacific. improvements in the model climatologies were confirmed numerically using skill scores (e.g., taylor\u2019s skill score).",
            "contribution_ids": [
                "R23437"
            ]
        },
        {
            "instance_id": "R38484xR23457",
            "comparison_id": "R38484",
            "paper_id": "R23457",
            "text": "Evaluation of the carbon cycle components in the Norwegian Earth System Model (NorESM) abstract. the recently developed norwegian earth system model (noresm) is employed for simulations contributing to the cmip5 (coupled model intercomparison project phase 5) experiments and the fifth assessment report of the intergovernmental panel on climate change (ipcc-ar5). in this manuscript, we focus on evaluating the ocean and land carbon cycle components of the noresm, based on the control and historical simulations. many of the observed large scale ocean biogeochemical features are reproduced satisfactorily by the noresm. when compared to the climatological estimates from the world ocean atlas (woa), the model simulated temperature, salinity, oxygen, and phosphate distributions agree reasonably well in both the surface layer and deep water structure. however, the model simulates a relatively strong overturning circulation strength that leads to noticeable model-data bias, especially within the north atlantic deep water (nadw). this strong overturning circulation slightly distorts the structure of the biogeochemical tracers at depth. advancements in simulating the oceanic mixed layer depth with respect to the previous generation model particularly improve the surface tracer distribution as well as the upper ocean biogeochemical processes, particularly in the southern ocean. consequently, near surface ocean processes such as biological production and air-sea gas exchange, are in good agreement with climatological observations. noresm reproduces the general pattern of land-vegetation gross primary productivity (gpp) when compared to the observationally-based values derived from the fluxnet network of eddy covariance towers. globally, the noresm simulated annual mean gpp and terrestrial respiration are 129.8 and 106.6 pg c yr\u22121, slightly larger than observed of 119.4 \u00b1 5.9 and 96.4 \u00b1 6.0 pg c yr\u22121. the latitudinal distribution of gpp fluxes simulated by noresm shows a gpp overestimation of 10% in the tropics and a substantial underestimation of gpp at high latitudes.",
            "contribution_ids": [
                "R23458"
            ]
        },
        {
            "instance_id": "R38484xR23326",
            "comparison_id": "R38484",
            "paper_id": "R23326",
            "text": "GFDL\u00e2\u0080\u0099s ESM2 Global Coupled Climate\u00e2\u0080\u0093Carbon Earth System Models. Part I: Physical Formulation and Baseline Simulation Characteristics abstract \\n the physical climate formulation and simulation characteristics of two new global coupled carbon\u2013climate earth system models, esm2m and esm2g, are described. these models demonstrate similar climate fidelity as the geophysical fluid dynamics laboratory\u2019s previous climate model version 2.1 (cm2.1) while incorporating explicit and consistent carbon dynamics. the two models differ exclusively in the physical ocean component; esm2m uses modular ocean model version 4p1 with vertical pressure layers while esm2g uses generalized ocean layer dynamics with a bulk mixed layer and interior isopycnal layers. differences in the ocean mean state include the thermocline depth being relatively deep in esm2m and relatively shallow in esm2g compared to observations. the crucial role of ocean dynamics on climate variability is highlighted in el ni\u00f1o\u2013southern oscillation being overly strong in esm2m and overly weak in esm2g relative to observations. thus, while esm2g might better represent climate changes relating to total heat content variability given its lack of long-term drift, gyre circulation, and ventilation in the north pacific, tropical atlantic, and indian oceans, and depth structure in the overturning and abyssal flows, esm2m might better represent climate changes relating to surface circulation given its superior surface temperature, salinity, and height patterns, tropical pacific circulation and variability, and southern ocean dynamics. the overall assessment is that neither model is fundamentally superior to the other, and that both models achieve sufficient fidelity to allow meaningful climate and earth system modeling applications. this affords the ability to assess the role of ocean configuration on earth system interactions in the context of two state-of-the-art coupled carbon\u2013climate models.",
            "contribution_ids": [
                "R23327"
            ]
        },
        {
            "instance_id": "R38484xR23383",
            "comparison_id": "R38484",
            "paper_id": "R23383",
            "text": "Present-Day Atmospheric Simulations Using GISS ModelE: Comparison to In Situ, Satellite, and Reanalysis Data abstract \\n a full description of the modele version of the goddard institute for space studies (giss) atmospheric general circulation model (gcm) and results are presented for present-day climate simulations (ca. 1979). this version is a complete rewrite of previous models incorporating numerous improvements in basic physics, the stratospheric circulation, and forcing fields. notable changes include the following: the model top is now above the stratopause, the number of vertical layers has increased, a new cloud microphysical scheme is used, vegetation biophysics now incorporates a sensitivity to humidity, atmospheric turbulence is calculated over the whole column, and new land snow and lake schemes are introduced. the performance of the model using three configurations with different horizontal and vertical resolutions is compared to quality-controlled in situ data, remotely sensed and reanalysis products. overall, significant improvements over previous models are seen, particularly in upper-atmosphere temperatures and winds, cloud heights, precipitation, and sea level pressure. data\u2013model comparisons continue, however, to highlight persistent problems in the marine stratocumulus regions.",
            "contribution_ids": [
                "R23384"
            ]
        },
        {
            "instance_id": "R38484xR23312",
            "comparison_id": "R38484",
            "paper_id": "R23312",
            "text": "GFDL's CM2 Global Coupled Climate Models. Part I: Formulation and Simulation Characteristics \" abstract \\n the formulation and simulation characteristics of two new global coupled climate models developed at noaa's geophysical fluid dynamics laboratory (gfdl) are described. the models were designed to simulate atmospheric and oceanic climate and variability from the diurnal time scale through multicentury climate change, given our computational constraints. in particular, an important goal was to use the same model for both experimental seasonal to interannual forecasting and the study of multicentury global climate change, and this goal has been achieved. \\n two versions of the coupled model are described, called cm2.0 and cm2.1. the versions differ primarily in the dynamical core used in the atmospheric component, along with the cloud tuning and some details of the land and ocean components. for both coupled models, the resolution of the land and atmospheric components is 2\u00b0 latitude \u00d7 2.5\u00b0 longitude; the atmospheric model has 24 vertical levels. the ocean resolution is 1\u00b0 in latitude and longitude, with meridional resolution equatorward of 30\u00b0 becoming progressively finer, such that the meridional resolution is 1/3\u00b0 at the equator. there are 50 vertical levels in the ocean, with 22 evenly spaced levels within the top 220 m. the ocean component has poles over north america and eurasia to avoid polar filtering. neither coupled model employs flux adjustments. \\n the control simulations have stable, realistic climates when integrated over multiple centuries. both models have simulations of enso that are substantially improved relative to previous gfdl coupled models. the cm2.0 model has been further evaluated as an enso forecast model and has good skill (cm2.1 has not been evaluated as an enso forecast model). generally reduced temperature and salinity biases exist in cm2.1 relative to cm2.0. these reductions are associated with 1) improved simulations of surface wind stress in cm2.1 and associated changes in oceanic gyre circulations; 2) changes in cloud tuning and the land model, both of which act to increase the net surface shortwave radiation in cm2.1, thereby reducing an overall cold bias present in cm2.0; and 3) a reduction of ocean lateral viscosity in the extratropics in cm2.1, which reduces sea ice biases in the north atlantic. \\n both models have been used to conduct a suite of climate change simulations for the 2007 intergovernmental panel on climate change (ipcc) assessment report and are able to simulate the main features of the observed warming of the twentieth century. the climate sensitivities of the cm2.0 and cm2.1 models are 2.9 and 3.4 k, respectively. these sensitivities are defined by coupling the atmospheric components of cm2.0 and cm2.1 to a slab ocean model and allowing the model to come into equilibrium with a doubling of atmospheric co2. the output from a suite of integrations conducted with these models is freely available online (see http://nomads.gfdl.noaa.gov/). \"",
            "contribution_ids": [
                "R23313"
            ]
        },
        {
            "instance_id": "R38484xR23471",
            "comparison_id": "R38484",
            "paper_id": "R23471",
            "text": "INGV-CMCC Carbon (ICC): A Carbon Cycle Earth System Model this document describes the cmcc earth system model (esm) for the representation of the carbon cycle in the atmosphere, land, and ocean system. the structure of the report follows the software architecture of the full system. it is intended to give a technical description of the numerical models at the base of the esm, and how they are coupled with each other.",
            "contribution_ids": [
                "R23472"
            ]
        },
        {
            "instance_id": "R38484xR23398",
            "comparison_id": "R38484",
            "paper_id": "R23398",
            "text": "Development and evaluation of an Earth-System model \u00e2\u0080\u0093 HadGEM2 abstract. we describe here the development and evaluation of an earth system model suitable for centennial-scale climate prediction. the principal new components added to the physical climate model are the terrestrial and ocean ecosystems and gas-phase tropospheric chemistry, along with their coupled interactions. the individual earth system components are described briefly and the relevant interactions between the components are explained. because the multiple interactions could lead to unstable feedbacks, we go through a careful process of model spin up to ensure that all components are stable and the interactions balanced. this spun-up configuration is evaluated against observed data for the earth system components and is generally found to perform very satisfactorily. the reason for the evaluation phase is that the model is to be used for the core climate simulations carried out by the met office hadley centre for the coupled model intercomparison project (cmip5), so it is essential that addition of the extra complexity does not detract substantially from its climate performance. localised changes in some specific meteorological variables can be identified, but the impacts on the overall simulation of present day climate are slight. this model is proving valuable both for climate predictions, and for investigating the strengths of biogeochemical feedbacks.\\n",
            "contribution_ids": [
                "R23399"
            ]
        },
        {
            "instance_id": "R41148xR41144",
            "comparison_id": "R41148",
            "paper_id": "R41144",
            "text": "Up-scalable and controllable electrolytic production of photo-responsive nanostructured silicon the electrochemical reduction of solid silica has been investigated in molten cacl2 at 900 \u00b0c for the one-step, up-scalable, controllable and affordable production of nanostructured silicon with promising photo-responsive properties. cyclic voltammetry of the metallic cavity electrode loaded with fine silica powder was performed to elaborate the electrochemical reduction mechanism. potentiostatic electrolysis of porous and dense silica pellets was carried out at different potentials, focusing on the influences of the electrolysis potential and the microstructure of the precursory silica on the product purity and microstructure. the findings suggest a potential range between \u22120.60 and \u22120.95 v (vs. ag/agcl) for the production of nanostructured silicon with high purity (>99 wt%). according to the elucidated mechanism on the electro-growth of the silicon nanostructures, optimal process parameters for the controllable preparation of high-purity silicon nanoparticles and nanowires were identified. scaling-up the optimal electrolysis was successful at the gram-scale for the preparation of high-purity silicon nanowires which exhibited promising photo-responsive properties.",
            "contribution_ids": [
                "R41145"
            ]
        },
        {
            "instance_id": "R41148xR41134",
            "comparison_id": "R41148",
            "paper_id": "R41134",
            "text": "Oscillatory behavior in electrochemical deposition reaction of polycrystalline silicon thin films through reduction of silicon tetrachloride in a molten salt electrolyte a new electrochemical oscillation is found for reduction reaction of silicon tetrachloride on a partially immersed single crystal n-si electrode in a lithium chloride-potassium chloride eutectic melt electrolyte. the reduction of sicl4, which is almost insoluble in the electrolyte, occurs mainly near the upper edge of an electrolyte meniscus on the electrode, and it is discussed that the oscillation is caused by a change in the height of the meniscus due to a change in the chemical structure (and hence the interfacial tension) of the electrode surface with progress of the silicon deposition reaction.",
            "contribution_ids": [
                "R41135"
            ]
        },
        {
            "instance_id": "R41148xR41122",
            "comparison_id": "R41148",
            "paper_id": "R41122",
            "text": "Direct Electrolytic Reduction of Solid Silicon Dioxide in molten LiCl-KCl-CaCl at 773 K we investigated electrolytic reduction of solid sio 2 by a contacting electrode method in molten licl-kcl-cacl 2 at 773 k. the results of cyclic voltammetry indicated that reduction of sio 2 occurs at potential more negative than 0.85 v (vs ca 2 + , li + /ca-li). samples were prepared by potentiostatic electrolysis for 2 h at 0.25, 0.50, 0.70, and 1.00 v. energy dispersive x-ray analysis and raman spectra clarified that the reduction products at 0.50 and 0.70 v are composed of amorphous si and microcrystalline si. scanning electron microscope (sem) observations revealed that the morphology of the produced si is spongelike with a particle size smaller than 50 nm. the mechanism of si formation was discussed by comparing the sem observations and the raman spectra of the si samples prepared at 773 and 1123 k. the reduction mechanism of the direct electrolytic reduction of sio 2 at lower temperature was also discussed.",
            "contribution_ids": [
                "R41123"
            ]
        },
        {
            "instance_id": "R41148xR41120",
            "comparison_id": "R41148",
            "paper_id": "R41120",
            "text": "Improving purity and process volume during direct electrolytic reduction of solid SiO 2 in molten CaCl 2 for the production of solar-grade silicon the direct electrolytic reduction of solid sio2 is investigated in molten cacl2 at 1123\\u2005k to produce solar-grade silicon. the target concentrations of impurities for the primary si are calculated from the acceptable concentrations of impurities in solar-grade silicon (sog-si) and the segregation coefficients for the impurity elements. the concentrations of most metal impurities are significantly decreased below their target concentrations by using a quartz vessel and new types of sio2-contacting electrodes. the electrolytic reduction rate is increased by improving an electron pathway from the lead material to the sio2, which demonstrates that the characteristics of the electric contact are important factors affecting the reduction rate. pellet- and basket-type electrodes are tested to improve the process volume for powdery and granular sio2. based on the purity of the si product after melting, refining, and solidifying, the potential of the technology is discussed.",
            "contribution_ids": [
                "R41121"
            ]
        },
        {
            "instance_id": "R41148xR41132",
            "comparison_id": "R41148",
            "paper_id": "R41132",
            "text": "The use of silicon wafer barriers in the electrochemical reduction of solid silica to form silicon in molten salts nowadays, silicon is the most critical element in solar cells and/or solar chips. silicon having 98 to 99% si as being metallurgical grade, requires further refinement/purification processes such as zone refining [1,2] and/or siemens process [3] to upgrade it for solar applications. a promising method, based on straightforward electrochemical reduction of oxides by ffc cambridge process [4], was adopted to form silicon from porous sio2 pellets in molten cacl2 and cacl2-nacl salt mixture [5]. it was reported that silicon powder contaminated by iron and nickel emanated from stainless steel cathode, consequently disqualified the product from solar applications. sio2 pellets sintered at 1300oc for 4 hours, were placed in between pure silicon wafer plates to defeat the contamination problem. encouraging results indicated a reliable alternative method of direct solar grade silicon production for expanding solar energy field.",
            "contribution_ids": [
                "R41133"
            ]
        },
        {
            "instance_id": "R41148xR41138",
            "comparison_id": "R41148",
            "paper_id": "R41138",
            "text": "Electrodeposition of crystalline and photoactive silicon directly from silicon dioxide nanoparticles in molten CaCl 2 silicon is a widely used semiconductor for electronic and photovoltaic devices because of its earth-abundance, chemical stability, and the tunable electrical properties by doping. therefore, the production of pure silicon films by simple and inexpensive methods has been the subject of many investigations. the desire for lower-cost silicon-based solar photovoltaic devices has encouraged the quest for solar-grade silicon production through processes alternative to the currently used czochralski process or other processes. electrodeposition is one of the least expensive methods for fabricating films of metals and semiconductors. electrodeposition of silicon has been studied for over 30 years, in various solution media such as molten salts (lif-kf-k2sif6 at 745 8c and bao-sio2-baf2 at 1465 8c ), organic solvents (acetonitrile, tetrahydrofuran), and room-temperature ionic liquids. recently, the direct electrochemical reduction of bulk solid silicon dioxide in a cacl2 melt was reported. [7] a key factor for silicon electrodeposition is the purity of silicon deposit because si for the use in photovoltaic devices is solargrade silicon (> 99.9999% or 6n) and its grade is even higher in electronic devices (electronic-grade silicon or 11n). in most cases, the electrodeposited silicon does not meet these requirements without further purification and, to our knowledge, none have been shown to exhibit a photoresponse. in fact, silicon electrodeposition is not as straightforward as metal deposition, since the deposited semiconductor layer is resistive at room temperature, which complicates electron transfer through the deposit. in many cases, for example in room-temperature aprotic solvents, the deposited silicon acts as an insulating layer and prevents a continuous deposition reaction. in some cases, the silicon deposit contains a high level of impurities (> 2%). moreover, the nucleation and growth of silicon requires a large amount of energy. the deposition is made even more challenging if the si precursor is sio2, which is a very resistive material. we reported previously the electrochemical formation of silicon on molybdenum from a cacl2 molten salt (850 8c) containing a sio2 nanoparticle (np with a diameter of 5\u2013 15 nm) suspension by applying a constant reduction current. however this si film did not show photoactivity. here we show the electrodeposition of photoactive crystalline silicon directly from sio2 nps from cacl2 molten salt on a silver electrode that shows a clear photoresponse. to the best of our knowledge, this is a first report of the direct electrodeposition of photoactive silicon. the electrochemical reduction and the cyclic voltammetry (cv) of sio2 were investigated as described previously. [8] in this study, we found that the replacement of the mo substrate by silver leads to a dramatic change in the properties of the silicon deposit. the silver substrate exhibited essentially the same electrochemical and cv behavior as other metal substrates, that is, a high reduction current for sio2 at negative potentials of 1.0 v with the development of a new redox couple near 0.65 v vs. a graphite quasireference electrode (qre) (figure 1a). figure 1b shows a change in the reduction current as a function of the reduction potential, and the optical images of silver electrodes before and after the electrolysis, which displays a dark gray-colored deposit after the reduction. figure 2 shows sem images of silicon deposits grown potentiostatically ( 1.25 v vs. graphite qre) on silver. the amount of silicon deposit increased with the deposition time, and the deposit finally covered the whole silver surface (figure 2). high-magnification images show that the silicon deposit is not a film but rather platelets or clusters of silicon crystals of domain sizes in the range of tens of micrometers. the average height of the platelets was around 25 mm after a 10000 s deposition (figure 2b), and 45 mm after a 20000s deposition (figure 2c), respectively. the edges of the silicon crystals were clearly observed. contrary to other substrates, silver enhanced the crystallization of silicon produced from silicon dioxide reduction and it is known that silver induces the crystallization of amorphous silicon. energy-dispersive spectrometry (eds) elemental mapping (images shown in the bottom row of figure 2) revealed that small silver islands exist on the top of the silicon deposits, which we think is closely related to the growth mechanism of silicon on silver. the eds spectrum of the silicon deposit (figure 3a) suggested that the deposited silicon was quite pure and the amounts of other elements such as c, ca, and cl were below the detection limit (about 0.1 atom%). since the oxygen signal was probably from the native oxide formed on exposure of the deposit to air and silicon does not form an alloy with silver, the purity of silicon was estimated to be at least 99.9 atom%. the successful reduction of si(4+) in silicon dioxide to elemental silicon (si) was confirmed by xray photoelectron spectroscopy (xps) of the silicon deposit [*] dr. s. k. cho, dr. f.-r. f. fan, prof. a. j. bard center for electrochemistry, department of chemistry and biochemistry, the university of texas at austin austin, tx 78712 (usa) e-mail: ajbard@mail.utexas.edu",
            "contribution_ids": [
                "R41139"
            ]
        },
        {
            "instance_id": "R41466xR37003",
            "comparison_id": "R41466",
            "paper_id": "R37003",
            "text": "Real-Time Estimation of the Risk of Death from Novel Coronavirus (COVID-19) Infection: Inference Using Exported Cases the exported cases of 2019 novel coronavirus (covid-19) infection that were confirmed outside china provide an opportunity to estimate the cumulative incidence and confirmed case fatality risk (ccfr) in mainland china. knowledge of the ccfr is critical to characterize the severity and understand the pandemic potential of covid-19 in the early stage of the epidemic. using the exponential growth rate of the incidence, the present study statistically estimated the ccfr and the basic reproduction number\u2014the average number of secondary cases generated by a single primary case in a na\u00efve population. we modeled epidemic growth either from a single index case with illness onset on 8 december 2019 (scenario 1), or using the growth rate fitted along with the other parameters (scenario 2) based on data from 20 exported cases reported by 24 january 2020. the cumulative incidence in china by 24 january was estimated at 6924 cases (95% confidence interval [ci]: 4885, 9211) and 19,289 cases (95% ci: 10,901, 30,158), respectively. the latest estimated values of the ccfr were 5.3% (95% ci: 3.5%, 7.5%) for scenario 1 and 8.4% (95% ci: 5.3%, 12.3%) for scenario 2. the basic reproduction number was estimated to be 2.1 (95% ci: 2.0, 2.2) and 3.2 (95% ci: 2.7, 3.7) for scenarios 1 and 2, respectively. based on these results, we argued that the current covid-19 epidemic has a substantial potential for causing a pandemic. the proposed approach provides insights in early risk assessment using publicly available data.",
            "contribution_ids": [
                "R37004",
                "R37005",
                "R41002",
                "R41003"
            ]
        },
        {
            "instance_id": "R41466xR41008",
            "comparison_id": "R41466",
            "paper_id": "R41008",
            "text": "Communicating the Risk of Death from Novel Coronavirus Disease (COVID-19) to understand the severity of infection for a given disease, it is common epidemiological practice to estimate the case fatality risk, defined as the risk of death among cases. however, there are three technical obstacles that should be addressed to appropriately measure this risk. first, division of the cumulative number of deaths by that of cases tends to underestimate the actual risk because deaths that will occur have not yet observed, and so the delay in time from illness onset to death must be addressed. second, the observed dataset of reported cases represents only a proportion of all infected individuals and there can be a substantial number of asymptomatic and mildly infected individuals who are never diagnosed. third, ascertainment bias and risk of death among all those infected would be smaller when estimated using shorter virus detection windows and less sensitive diagnostic laboratory tests. in the ongoing covid-19 epidemic, health authorities must cope with the uncertainty in the risk of death from covid-19, and high-risk individuals should be identified using approaches that can address the abovementioned three problems. although covid-19 involves mostly mild infections among the majority of the general population, the risk of death among young adults is higher than that of seasonal influenza, and elderly with underlying comorbidities require additional care.",
            "contribution_ids": [
                "R41009",
                "R41011",
                "R41012"
            ]
        },
        {
            "instance_id": "R44930xR44759",
            "comparison_id": "R44930",
            "paper_id": "R44759",
            "text": "Transmission potential of COVID-19 in Iran abstract we estimated the reproduction number of 2020 iranian covid-19 epidemic using two different methods: r 0 was estimated at 4.4 (95% ci, 3.9, 4.9) (generalized growth model) and 3.50 (1.28, 8.14) (epidemic doubling time) (february 19 - march 1) while the effective r was estimated at 1.55 (1.06, 2.57) (march 6-19).",
            "contribution_ids": [
                "R44766",
                "R44771"
            ]
        },
        {
            "instance_id": "R44930xR44865",
            "comparison_id": "R44930",
            "paper_id": "R44865",
            "text": "Modelling the epidemic trend of the 2019 novel coronavirus outbreak in China we present a timely evaluation of the chinese 2019-ncov epidemic in its initial phase, where 2019-ncov demonstrates comparable transmissibility but lower fatality rates than sars and mers. a quick diagnosis that leads to case isolation and integrated interventions will have a major impact on its future trend. nevertheless, as china is facing its spring festival travel rush and the epidemic has spread beyond its borders, further investigation on its potential spatiotemporal transmission pattern and novel intervention strategies are warranted.",
            "contribution_ids": [
                "R44866"
            ]
        },
        {
            "instance_id": "R44930xR44847",
            "comparison_id": "R44930",
            "paper_id": "R44847",
            "text": "Novel coronavirus 2019-nCoV: early estimation of epidemiological parameters and epidemic predictions abstract since first identified, the epidemic scale of the recently emerged novel coronavirus (2019-ncov) in wuhan, china, has increased rapidly, with cases arising across china and other countries and regions. using a transmission model, we estimate a basic reproductive number of 3.11 (95%ci, 2.39\u20134.13); 58\u201376% of transmissions must be prevented to stop increasing; wuhan case ascertainment of 5.0% (3.6\u20137.4); 21022 (11090\u201333490) total infections in wuhan 1 to 22 january. changes to previous version case data updated to include 22 jan 2020; we did not use cases reported after this period as cases were reported at the province level hereafter, and large-scale control interventions were initiated on 23 jan 2020; improved likelihood function, better accounting for first 41 confirmed cases, and now using all infections (rather than just cases detected) in wuhan for prediction of infection in international travellers; improved characterization of uncertainty in parameters, and calculation of epidemic trajectory confidence intervals using a more statistically rigorous method; extended range of latent period in sensitivity analysis to reflect reports of up to 6 day incubation period in household clusters; removed travel restriction analysis, as different modelling approaches (e.g. stochastic transmission, rather than deterministic transmission) are more appropriate to such analyses.",
            "contribution_ids": [
                "R44852"
            ]
        },
        {
            "instance_id": "R44930xR44743",
            "comparison_id": "R44930",
            "paper_id": "R44743",
            "text": "Estimation of the epidemic properties of the 2019 novel coronavirus: A mathematical modeling study abstract background the 2019 novel coronavirus (covid-19) emerged in wuhan, china in december 2019 and has been spreading rapidly in china. decisions about its pandemic threat and the appropriate level of public health response depend heavily on estimates of its basic reproduction number and assessments of interventions conducted in the early stages of the epidemic. methods we conducted a mathematical modeling study using five independent methods to assess the basic reproduction number (r0) of covid-19, using data on confirmed cases obtained from the china national health commission for the period 10 th january \u2013 8 th february. we analyzed the data for the period before the closure of wuhan city (10 th january \u2013 23 rd january) and the post-closure period (23 rd january \u2013 8 th february) and for the whole period, to assess both the epidemic risk of the virus and the effectiveness of the closure of wuhan city on spread of covid-19. findings before the closure of wuhan city the basic reproduction number of covid-19 was 4.38 (95% ci: 3.63 \u2013 5.13), dropping to 3.41 (95% ci: 3.16 \u2013 3.65) after the closure of wuhan city. over the entire epidemic period covid-19 had a basic reproduction number of 3.39 (95% ci: 3.09 \u2013 3.70), indicating it has a very high transmissibility. interpretation covid-19 is a highly transmissible virus with a very high risk of epidemic outbreak once it emerges in metropolitan areas. the closure of wuhan city was effective in reducing the severity of the epidemic, but even after closure of the city and the subsequent expansion of that closure to other parts of hubei the virus remained extremely infectious. emergency planners in other cities should consider this high infectiousness when considering responses to this virus. funding national natural science foundation of china, china medical board, national science and technology major project of china",
            "contribution_ids": [
                "R44744",
                "R44749",
                "R44754"
            ]
        },
        {
            "instance_id": "R44930xR44910",
            "comparison_id": "R44930",
            "paper_id": "R44910",
            "text": "Estimating the Unreported Number of Novel Coronavirus (2019-nCoV) Cases in China in the First Half of January 2020: A Data-Driven Modelling Analysis of the Early Outbreak background: in december 2019, an outbreak of respiratory illness caused by a novel coronavirus (2019-ncov) emerged in wuhan, china and has swiftly spread to other parts of china and a number of foreign countries. the 2019-ncov cases might have been under-reported roughly from 1 to 15 january 2020, and thus we estimated the number of unreported cases and the basic reproduction number, r0, of 2019-ncov. methods: we modelled the epidemic curve of 2019-ncov cases, in mainland china from 1 december 2019 to 24 january 2020 through the exponential growth. the number of unreported cases was determined by the maximum likelihood estimation. we used the serial intervals (si) of infection caused by two other well-known coronaviruses (cov), severe acute respiratory syndrome (sars) and middle east respiratory syndrome (mers) covs, as approximations of the unknown si for 2019-ncov to estimate r0. results: we confirmed that the initial growth phase followed an exponential growth pattern. the under-reporting was likely to have resulted in 469 (95% ci: 403\u2013540) unreported cases from 1 to 15 january 2020. the reporting rate after 17 january 2020 was likely to have increased 21-fold (95% ci: 18\u201325) in comparison to the situation from 1 to 17 january 2020 on average. we estimated the r0 of 2019-ncov at 2.56 (95% ci: 2.49\u20132.63). conclusion: the under-reporting was likely to have occurred during the first half of january 2020 and should be considered in future investigation.",
            "contribution_ids": [
                "R44914"
            ]
        },
        {
            "instance_id": "R44930xR44836",
            "comparison_id": "R44930",
            "paper_id": "R44836",
            "text": "Estimating the effective reproduction number of the 2019-nCoV in China abstract we estimate the effective reproduction number for 2019-ncov based on the daily reported cases from china cdc. the results indicate that 2019-ncov has a higher effective reproduction number than sars with a comparable fatality rate. article summary line this modeling study indicates that 2019-ncov has a higher effective reproduction number than sars with a comparable fatality rate.",
            "contribution_ids": [
                "R44838"
            ]
        },
        {
            "instance_id": "R44930xR44726",
            "comparison_id": "R44930",
            "paper_id": "R44726",
            "text": "The early phase of the COVID-19 outbreak in Lombardy, Italy in the night of february 20, 2020, the first case of novel coronavirus disease (covid-19) was confirmed in the lombardy region, italy. in the week that followed, lombardy experienced a very rapid increase in the number of cases. we analyzed the first 5,830 laboratory-confirmed cases to provide the first epidemiological characterization of a covid-19 outbreak in a western country. epidemiological data were collected through standardized interviews of confirmed cases and their close contacts. we collected demographic backgrounds, dates of symptom onset, clinical features, respiratory tract specimen results, hospitalization, contact tracing. we provide estimates of the reproduction number and serial interval. the epidemic in italy started much earlier than february 20, 2020. at the time of detection of the first covid-19 case, the epidemic had already spread in most municipalities of southern-lombardy. the median age for of cases is 69 years (range, 1 month to 101 years). 47% of positive subjects were hospitalized. among these, 18% required intensive care. the mean serial interval is estimated to be 6.6 days (95% ci, 0.7 to 19). we estimate the basic reproduction number at 3.1 (95% ci, 2.9 to 3.2). we estimated a decreasing trend in the net reproduction number starting around february 20, 2020. we did not observe significantly different viral loads in nasal swabs between symptomatic and asymptomatic. the transmission potential of covid-19 is very high and the number of critical cases may become largely unsustainable for the healthcare system in a very short-time horizon. we observed a slight decrease of the reproduction number, possibly connected with an increased population awareness and early effect of interventions. aggressive containment strategies are required to control covid-19 spread and catastrophic outcomes for the healthcare system.",
            "contribution_ids": [
                "R44727"
            ]
        },
        {
            "instance_id": "R44930xR44731",
            "comparison_id": "R44930",
            "paper_id": "R44731",
            "text": "Transmission interval estimates suggest pre-symptomatic spread of COVID-19 abstract background as the covid-19 epidemic is spreading, incoming data allows us to quantify values of key variables that determine the transmission and the effort required to control the epidemic. we determine the incubation period and serial interval distribution for transmission clusters in singapore and in tianjin. we infer the basic reproduction number and identify the extent of pre-symptomatic transmission. methods we collected outbreak information from singapore and tianjin, china, reported from jan.19-feb.26 and jan.21-feb.27, respectively. we estimated incubation periods and serial intervals in both populations. results the mean incubation period was 7.1 (6.13, 8.25) days for singapore and 9 (7.92, 10.2) days for tianjin. both datasets had shorter incubation periods for earlier-occurring cases. the mean serial interval was 4.56 (2.69, 6.42) days for singapore and 4.22 (3.43, 5.01) for tianjin. we inferred that early in the outbreaks, infection was transmitted on average 2.55 and 2.89 days before symptom onset (singapore, tianjin). the estimated basic reproduction number for singapore was 1.97 (1.45, 2.48) secondary cases per infective; for tianjin it was 1.87 (1.65, 2.09) secondary cases per infective. conclusions estimated serial intervals are shorter than incubation periods in both singapore and tianjin, suggesting that pre-symptomatic transmission is occurring. shorter serial intervals lead to lower estimates of r0, which suggest that half of all secondary infections should be prevented to control spread.",
            "contribution_ids": [
                "R44732",
                "R44738"
            ]
        },
        {
            "instance_id": "R44930xR44776",
            "comparison_id": "R44930",
            "paper_id": "R44776",
            "text": "Estimating the generation interval for COVID-19 based on symptom onset data abstract background estimating key infectious disease parameters from the covid-19 outbreak is quintessential for modelling studies and guiding intervention strategies. whereas different estimates for the incubation period distribution and the serial interval distribution have been reported, estimates of the generation interval for covid-19 have not been provided. methods we used outbreak data from clusters in singapore and tianjin, china to estimate the generation interval from symptom onset data while acknowledging uncertainty about the incubation period distribution and the underlying transmission network. from those estimates we obtained the proportions pre-symptomatic transmission and reproduction numbers. results the mean generation interval was 5.20 (95%ci 3.78-6.78) days for singapore and 3.95 (95%ci 3.01-4.91) days for tianjin, china when relying on a previously reported incubation period with mean 5.2 and sd 2.8 days. the proportion of pre-symptomatic transmission was 48% (95%ci 32-67%) for singapore and 62% (95%ci 50-76%) for tianjin, china. estimates of the reproduction number based on the generation interval distribution were slightly higher than those based on the serial interval distribution. conclusions estimating generation and serial interval distributions from outbreak data requires careful investigation of the underlying transmission network. detailed contact tracing information is essential for correctly estimating these quantities.",
            "contribution_ids": [
                "R44777",
                "R44781",
                "R44785",
                "R44789"
            ]
        },
        {
            "instance_id": "R44930xR44901",
            "comparison_id": "R44930",
            "paper_id": "R44901",
            "text": "Real-Time Estimation of the Risk of Death from Novel Coronavirus (COVID-19) Infection: Inference Using Exported Cases the exported cases of 2019 novel coronavirus (covid-19) infection that were confirmed outside china provide an opportunity to estimate the cumulative incidence and confirmed case fatality risk (ccfr) in mainland china. knowledge of the ccfr is critical to characterize the severity and understand the pandemic potential of covid-19 in the early stage of the epidemic. using the exponential growth rate of the incidence, the present study statistically estimated the ccfr and the basic reproduction number\u2014the average number of secondary cases generated by a single primary case in a na\u00efve population. we modeled epidemic growth either from a single index case with illness onset on 8 december 2019 (scenario 1), or using the growth rate fitted along with the other parameters (scenario 2) based on data from 20 exported cases reported by 24 january 2020. the cumulative incidence in china by 24 january was estimated at 6924 cases (95% confidence interval [ci]: 4885, 9211) and 19,289 cases (95% ci: 10,901, 30,158), respectively. the latest estimated values of the ccfr were 5.3% (95% ci: 3.5%, 7.5%) for scenario 1 and 8.4% (95% ci: 5.3%, 12.3%) for scenario 2. the basic reproduction number was estimated to be 2.1 (95% ci: 2.0, 2.2) and 3.2 (95% ci: 2.7, 3.7) for scenarios 1 and 2, respectively. based on these results, we argued that the current covid-19 epidemic has a substantial potential for causing a pandemic. the proposed approach provides insights in early risk assessment using publicly available data.",
            "contribution_ids": [
                "R44902",
                "R44906"
            ]
        },
        {
            "instance_id": "R44930xR44819",
            "comparison_id": "R44930",
            "paper_id": "R44819",
            "text": "Report 3: Transmissibility of 2019-nCoV. 2020. WHO Collaborating Centre for Infectious Disease Modelling, MRC Centre for Global Infectious Disease Analysis self-sustaining human-to-human transmission of the novel coronavirus (2019-ncov) is the only plausible explanation of the scale of the outbreak in wuhan. we estimate that, on average, each case infected 2.6 (uncertainty range: 1.5-3.5) other people up to 18 january 2020, based on an analysis combining our past estimates of the size of the outbreak in wuhan with computational modelling of potential epidemic trajectories. this implies that control measures need to block well over 60% of transmission to be effective in controlling the outbreak. it is likely, based on the experience of sars and mers-cov, that the number of secondary cases caused by a case of 2019-ncov is highly variable \u2013 with many cases causing no secondary infections, and a few causing many. whether transmission is continuing at the same rate currently depends on the effectiveness of current control measures implemented in china and the extent to which the populations of affected areas have adopted risk-reducing behaviours. in the absence of antiviral drugs or vaccines, control relies upon the prompt detection and isolation of symptomatic cases. it is unclear at the current time whether this outbreak can be contained within china; uncertainties include the severity spectrum of the disease caused by this virus and whether cases with relatively mild symptoms are able to transmit the virus efficiently. identification and testing of potential cases need to be as extensive as is permitted by healthcare and diagnostic testing capacity \u2013 including the identification, testing and isolation of suspected cases with only mild to moderate disease (e.g. influenza-like illness), when logistically feasible.",
            "contribution_ids": [
                "R44820"
            ]
        },
        {
            "instance_id": "R44930xR44799",
            "comparison_id": "R44930",
            "paper_id": "R44799",
            "text": "Early Transmission Dynamics in Wuhan, China, of Novel Coronavirus\u00e2\u0080\u0093Infected Pneumonia abstract background the initial cases of novel coronavirus (2019-ncov)\u2013infected pneumonia (ncip) occurred in wuhan, hubei province, china, in december 2019 and january 2020. we analyzed data on the first 425 confirmed cases in wuhan to determine the epidemiologic characteristics of ncip. methods we collected information on demographic characteristics, exposure history, and illness timelines of laboratory-confirmed cases of ncip that had been reported by january 22, 2020. we described characteristics of the cases and estimated the key epidemiologic time-delay distributions. in the early period of exponential growth, we estimated the epidemic doubling time and the basic reproductive number. results among the first 425 patients with confirmed ncip, the median age was 59 years and 56% were male. the majority of cases (55%) with onset before january 1, 2020, were linked to the huanan seafood wholesale market, as compared with 8.6% of the subsequent cases. the mean incubation period was 5.2 days (95% confidence interval [ci], 4.1 to 7.0), with the 95th percentile of the distribution at 12.5 days. in its early stages, the epidemic doubled in size every 7.4 days. with a mean serial interval of 7.5 days (95% ci, 5.3 to 19), the basic reproductive number was estimated to be 2.2 (95% ci, 1.4 to 3.9). conclusions on the basis of this information, there is evidence that human-to-human transmission has occurred among close contacts since the middle of december 2019. considerable efforts to reduce transmission will be required to control outbreaks if similar dynamics apply elsewhere. measures to prevent or reduce transmission should be implemented in populations at risk. (funded by the ministry of science and technology of china and others.)",
            "contribution_ids": [
                "R44801"
            ]
        },
        {
            "instance_id": "R44930xR44806",
            "comparison_id": "R44930",
            "paper_id": "R44806",
            "text": "Estimation of the Transmission Risk of 2019-nCov and Its Implication for Public Health Interventions english abstract: background: since the emergence of the first pneumonia cases in wuhan, china, the novel coronavirus (2019-ncov) infection has been quickly spreading out to other provinces and neighbouring countries. estimation of the basic reproduction number by means of mathematical modelling can be helpful for determining the potential and severity of an outbreak, and providing critical information for identifying the type of disease interventions and intensity.\\r\\n\\r\\nmethods: a deterministic compartmental model was devised based on the clinical progression of the disease, epidemiological status of the individuals, and the intervention measures.\\r\\n\\r\\nfindings: the estimation results based on likelihood and model analysis reveal that the control reproduction number may be as high as 6.47 (95% ci 5.71-7.23). sensitivity analyses reveal that interventions, such as intensive contact tracing followed by quarantine and isolation, can effectively reduce the control reproduction number and transmission risk, with the effect of travel restriction of wuhan on 2019-ncov infection in beijing being almost equivalent to increasing quarantine by 100-thousand baseline value.\\r\\n\\r\\ninterpretation: it is essential to assess how the expensive, resource-intensive measures implemented by the chinese authorities can contribute to the prevention and control of the 2019-ncov infection, and how long should be maintained. under the most restrictive measures, the outbreak is expected to peak within two weeks (since january 23rd 2020) with significant low peak value. with travel restriction (no imported exposed individuals to beijing), the number of infected individuals in 7 days will decrease by 91.14% in beijing, compared with the scenario of no travel restriction.\\r\\n\\r\\nmandarin abstract: \u80cc\u666f\uff1a\u81ea\u4ece\u4e2d\u56fd\u6b66\u6c49\u51fa\u73b0\u7b2c\u4e00\u4f8b\u80ba\u708e\u75c5\u4f8b\u4ee5\u6765\uff0c\u65b0\u578b\u51a0\u72b6\u75c5\u6bd2\uff082019-ncov\uff09\u611f\u67d3\u5df2\u8fc5\u901f\u4f20\u64ad\u5230\u5176\u4ed6\u7701\u4efd\u548c\u5468\u8fb9\u56fd\u5bb6\u3002\u901a\u8fc7\u6570\u5b66\u6a21\u578b\u4f30\u8ba1\u57fa\u672c\u518d\u751f\u6570\uff0c\u6709\u52a9\u4e8e\u786e\u5b9a\u75ab\u60c5\u7206\u53d1\u7684\u53ef\u80fd\u6027\u548c\u4e25\u91cd\u6027\uff0c\u5e76\u4e3a\u786e\u5b9a\u75be\u75c5\u5e72\u9884\u7c7b\u578b\u548c\u5f3a\u5ea6\u63d0\u4f9b\u5173\u952e\u4fe1\u606f\u3002\\r\\n\\r\\n\u65b9\u6cd5\uff1a\u6839\u636e\u75be\u75c5\u7684\u4e34\u5e8a\u8fdb\u5c55\uff0c\u4e2a\u4f53\u7684\u6d41\u884c\u75c5\u5b66\u72b6\u51b5\u548c\u5e72\u9884\u63aa\u65bd\uff0c\u8bbe\u8ba1\u786e\u5b9a\u6027\u7684\u4ed3\u5ba4\u6a21\u578b\u3002\\r\\n\\r\\n\u7ed3\u679c\uff1a\u57fa\u4e8e\u4f3c\u7136\u51fd\u6570\u548c\u6a21\u578b\u5206\u6790\u7684\u4f30\u8ba1\u7ed3\u679c\u8868\u660e\uff0c\u63a7\u5236\u518d\u751f\u6570\u53ef\u80fd\u9ad8\u8fbe6.47\uff0895\uff05ci 5.71-7.23\uff09\u3002\u654f\u611f\u6027\u5206\u6790\u663e\u793a\uff0c\u5bc6\u96c6\u63a5\u89e6\u8ffd\u8e2a\u548c\u9694\u79bb\u7b49\u5e72\u9884\u63aa\u65bd\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u63a7\u5236\u518d\u751f\u6570\u548c\u4f20\u64ad\u98ce\u9669\uff0c\u6b66\u6c49\u5c01\u57ce\u63aa\u65bd\u5bf9\u5317\u4eac2019-ncov\u611f\u67d3\u7684\u5f71\u54cd\u51e0\u4e4e\u7b49\u540c\u4e8e\u589e\u52a0\u9694\u79bb\u63aa\u65bd10\u4e07\u7684\u57fa\u7ebf\u503c\u3002\\r\\n\\r\\n\u89e3\u91ca\uff1a\u5fc5\u987b\u8bc4\u4f30\u4e2d\u56fd\u5f53\u5c40\u5b9e\u65bd\u7684\u6602\u8d35\uff0c\u8d44\u6e90\u5bc6\u96c6\u578b\u63aa\u65bd\u5982\u4f55\u6709\u52a9\u4e8e\u9884\u9632\u548c\u63a7\u52362019-ncov\u611f\u67d3\uff0c\u4ee5\u53ca\u5e94\u7ef4\u6301\u591a\u957f\u65f6\u95f4\u3002\u5728\u6700\u4e25\u683c\u7684\u63aa\u65bd\u4e0b\uff0c\u9884\u8ba1\u75ab\u60c5\u5c06\u5728\u4e24\u5468\u5185\uff08\u81ea2020\u5e741\u670823\u65e5\u8d77\uff09\u8fbe\u5230\u5cf0\u503c\uff0c\u5cf0\u503c\u8f83\u4f4e\u3002\u4e0e\u6ca1\u6709\u51fa\u884c\u9650\u5236\u7684\u60c5\u51b5\u76f8\u6bd4\uff0c\u6709\u4e86\u51fa\u884c\u9650\u5236\uff08\u5373\u6ca1\u6709\u8f93\u5165\u7684\u6f5c\u4f0f\u7c7b\u4e2a\u4f53\u8fdb\u5165\u5317\u4eac\uff09\uff0c\u5317\u4eac\u76847\u5929\u611f\u67d3\u8005\u6570\u91cf\u5c06\u51cf\u5c1191.14\uff05\u3002",
            "contribution_ids": [
                "R44808"
            ]
        },
        {
            "instance_id": "R44978xR44702",
            "comparison_id": "R44978",
            "paper_id": "R44702",
            "text": "Randomised controlled trial comparing problem solving treatment with amitriptyline and placebo for major depression in primary care abstract objective: to determine whether, in the treatment of major depression in primary care, a brief psychological treatment (problem solving) was (a) as effective as antidepressant drugs and more effective than placebo; (b) feasible in practice; and (c) acceptable to patients. design: randomised controlled trial of problem solving treatment, amitriptyline plus standard clinical management, and drug placebo plus standard clinical management. each treatment was delivered in six sessions over 12 weeks. setting: primary care in oxfordshire. subjects: 91 patients in primary care who had major depression. main outcome measures: observer and self reported measures of severity of depression, self reported measure of social outcome, and observer measure of psychological symptoms at six and 12 weeks; self reported measure of patient satisfaction at 12 weeks. numbers of patients recovered at six and 12 weeks. results: at six and 12 weeks the difference in score on the hamilton rating scale for depression between problem solving and placebo treatments was significant (5.3 (95% confidence interval 1.6 to 9.0) and 4.7 (0.4 to 9.0) respectively), but the difference between problem solving and amitriptyline was not significant (1.8 (\u22121.8 to 5.5) and 0.9 (\u22123.3 to 5.2) respectively). at 12 weeks 60% (18/30) of patients given problem solving treatment had recovered on the hamilton scale compared with 52% (16/31) given amitriptyline and 27% (8/30) given placebo. patients were satisfied with problem solving treatment; all patients who completed treatment (28/30) rated the treatment as helpful or very helpful. the six sessions of problem solving treatment totalled a mean therapy time of 3 1/2 hours. conclusions: as a treatment for major depression in primary care, problem solving treatment is effective, feasible, and acceptable to patients. key messages key messages patient compliance with antidepressant treatment is often poor, so there is a need for a psychological treatment this study found that problem solving is an effective psychological treatment for major depression in primary care\u2014as effective as amitriptyline and more effective than placebo problem solving is a feasible treatment in primary care, being effective when given over six sessions by a general practitioner problem solving treatment is acceptable to patients",
            "contribution_ids": [
                "R44703"
            ]
        },
        {
            "instance_id": "R44978xR44704",
            "comparison_id": "R44978",
            "paper_id": "R44704",
            "text": "Randomised controlled trial of problem solving treatment, antidepressant medication, and combined treatment for major depression in primary care abstract objectives: to determine whether problem solving treatment combined with antidepressant medication is more effective than either treatment alone in the management of major depression in primary care. to assess the effectiveness of problem solving treatment when given by practice nurses compared with general practitioners when both have been trained in the technique. design: randomised controlled trial with four treatment groups. setting: primary care in oxfordshire. participants: patients aged 18-65 years with major depression on the research diagnostic criteria\u2014a score of 13 or more on the 17 item hamilton rating scale for depression and a minimum duration of illness of four weeks. interventions: problem solving treatment by research general practitioner or research practice nurse or antidepressant medication or a combination of problem solving treatment and antidepressant medication. main outcome measures: hamilton rating scale for depression, beck depression inventory, clinical interview schedule (revised), and the modified social adjustment schedule assessed at 6, 12, and 52 weeks. results: patients in all groups showed a clear improvement over 12 weeks. the combination of problem solving treatment and antidepressant medication was no more effective than either treatment alone. there was no difference in outcome irrespective of who delivered the problem solving treatment. conclusions: problem solving treatment is an effective treatment for depressive disorders in primary care. the treatment can be delivered by suitably trained practice nurses or general practitioners. the combination of this treatment with antidepressant medication is no more effective than either treatment alone. key messages problem solving treatment is an effective treatment for depressive disorders in primary care problem solving treatment can be delivered by suitably trained practice nurses as effectively as by general practitioners the combination of problem solving treatment and antidepressant medication is no more effective than either treatment alone problem solving treatment is most likely to benefit patients who have a depressive disorder of moderate severity and who wish to participate in an active psychological treatment",
            "contribution_ids": [
                "R44705"
            ]
        },
        {
            "instance_id": "R44978xR44719",
            "comparison_id": "R44978",
            "paper_id": "R44719",
            "text": "Treatment of dysthymia and minor depression in primary care: A randomized controlled trial in older adults context\\ninsufficient evidence exists for recommendation of specific effective treatments for older primary care patients with minor depression or dysthymia.\\n\\n\\nobjective\\nto compare the effectiveness of pharmacotherapy and psychotherapy in primary care settings among older persons with minor depression or dysthymia.\\n\\n\\ndesign\\nrandomized, placebo-controlled trial (november 1995-august 1998).\\n\\n\\nsetting\\nfour geographically and clinically diverse primary care practices.\\n\\n\\nparticipants\\na total of 415 primary care patients (mean age, 71 years) with minor depression (n = 204) or dysthymia (n = 211) and a hamilton depression rating scale (hdrs) score of at least 10 were randomized; 311 (74.9%) completed all study visits.\\n\\n\\ninterventions\\npatients were randomly assigned to receive paroxetine (n = 137) or placebo (n = 140), starting at 10 mg/d and titrated to a maximum of 40 mg/d, or problem-solving treatment-primary care (pst-pc; n = 138). for the paroxetine and placebo groups, the 6 visits over 11 weeks included general support and symptom and adverse effects monitoring; for the pst-pc group, visits were for psychotherapy.\\n\\n\\nmain outcome measures\\ndepressive symptoms, by the 20-item hopkins symptom checklist depression scale (hscl-d-20) and the hdrs; and functional status, by the medical outcomes study short-form 36 (sf-36) physical and mental components.\\n\\n\\nresults\\nparoxetine patients showed greater (difference in mean [se] 11-week change in hscl-d-20 scores, 0.21 [0. 07]; p =.004) symptom resolution than placebo patients. patients treated with pst-pc did not show more improvement than placebo (difference in mean [se] change in hscl-d-20 scores, 0.11 [0.13]; p =.13), but their symptoms improved more rapidly than those of placebo patients during the latter treatment weeks (p =.01). for dysthymia, paroxetine improved mental health functioning vs placebo among patients whose baseline functioning was high (difference in mean [se] change in sf-36 mental component scores, 5.8 [2.02]; p =. 01) or intermediate (difference in mean [se] change in sf-36 mental component scores, 4.4 [1.74]; p =.03). mental health functioning in dysthymia patients was not significantly improved by pst-pc compared with placebo (p>/=.12 for low-, intermediate-, and high-functioning groups). for minor depression, both paroxetine and pst-pc improved mental health functioning in patients in the lowest tertile of baseline functioning (difference vs placebo in mean [se] change in sf-36 mental component scores, 4.7 [2.03] for those taking paroxetine; 4.7 [1.96] for the pst-pc treatment; p =.02 vs placebo).\\n\\n\\nconclusions\\nparoxetine showed moderate benefit for depressive symptoms and mental health function in elderly patients with dysthymia and more severely impaired elderly patients with minor depression. the benefits of pst-pc were smaller, had slower onset, and were more subject to site differences than those of paroxetine.",
            "contribution_ids": [
                "R44720"
            ]
        },
        {
            "instance_id": "R44978xR44713",
            "comparison_id": "R44978",
            "paper_id": "R44713",
            "text": "Telephone psychotherapy and telephone care management for primary care patients starting antidepressant treatment: a randomized controlled trial context\\nboth antidepressant medication and structured psychotherapy have been proven efficacious, but less than one third of people with depressive disorders receive effective levels of either treatment.\\n\\n\\nobjective\\nto compare usual primary care for depression with 2 intervention programs: telephone care management and telephone care management plus telephone psychotherapy.\\n\\n\\ndesign\\nthree-group randomized controlled trial with allocation concealment and blinded outcome assessment conducted between november 2000 and may 2002.\\n\\n\\nsetting and participants\\na total of 600 patients beginning antidepressant treatment for depression were systematically sampled from 7 group-model primary care clinics; patients already receiving psychotherapy were excluded.\\n\\n\\ninterventions\\nusual primary care; usual care plus a telephone care management program including at least 3 outreach calls, feedback to the treating physician, and care coordination; usual care plus care management integrated with a structured 8-session cognitive-behavioral psychotherapy program delivered by telephone.\\n\\n\\nmain outcome measures\\nblinded telephone interviews at 6 weeks, 3 months, and 6 months assessed depression severity (hopkins symptom checklist depression scale and the patient health questionnaire), patient-rated improvement, and satisfaction with treatment. computerized administrative data examined use of antidepressant medication and outpatient visits.\\n\\n\\nresults\\ntreatment participation rates were 97% for telephone care management and 93% for telephone care management plus psychotherapy. compared with usual care, the telephone psychotherapy intervention led to lower mean hopkins symptom checklist depression scale depression scores (p =.02), a higher proportion of patients reporting that depression was \"much improved\" (80% vs 55%, p<.001), and a higher proportion of patients \"very satisfied\" with depression treatment (59% vs 29%, p<.001). the telephone care management program had smaller effects on patient-rated improvement (66% vs 55%, p =.04) and satisfaction (47% vs 29%, p =.001); effects on mean depression scores were not statistically significant.\\n\\n\\nconclusions\\nfor primary care patients beginning antidepressant treatment, a telephone program integrating care management and structured cognitive-behavioral psychotherapy can significantly improve satisfaction and clinical outcomes. these findings suggest a new public health model of psychotherapy for depression including active outreach and vigorous efforts to improve access to and motivation for treatment.",
            "contribution_ids": [
                "R44714"
            ]
        },
        {
            "instance_id": "R44978xR44689",
            "comparison_id": "R44978",
            "paper_id": "R44689",
            "text": "Problem solving treatment and group psychoeducation for depression: multicentre randomised controlled trial. Outcomes of Depression International Network (ODIN) Group abstract objectives: to determine the acceptability of two psychological interventions for depressed adults in the community and their effect on caseness, symptoms, and subjective function. design: a pragmatic multicentre randomised controlled trial, stratified by centre. setting: nine urban and rural communities in finland, republic of ireland, norway, spain, and the united kingdom. participants: 452 participants aged 18 to 65, identified through a community survey with depressive or adjustment disorders according to the international classification of diseases, 10th revision or diagnostic and statistical manual of mental disorders, fourth edition. interventions: six individual sessions of problem solving treatment (n=128), eight group sessions of the course on prevention of depression (n=108), and controls (n=189). main outcome measures: completion rates for each intervention, diagnosis of depression, and depressive symptoms and subjective function. results: 63% of participants assigned to problem solving and 44% assigned to prevention of depression completed their intervention. the proportion of problem solving participants depressed at six months was 17% less than that for controls, giving a number needed to treat of 6; the mean difference in beck depression inventory score was \u22122.63 (95% confidence interval \u22124.95 to \u22120.32), and there were significant improvements in sf-36 scores. for depression prevention, the difference in proportions of depressed participants was 14% (number needed to treat of 7); the mean difference in beck depression inventory score was \u22121.50 (\u22124.16 to 1.17), and there were significant improvements in sf-36 scores. such differences were not observed at 12 months. neither specific diagnosis nor treatment with antidepressants affected outcome. conclusions: when offered to adults with depressive disorders in the community, problem solving treatment was more acceptable than the course on prevention of depression. both interventions reduced caseness and improved subjective function.",
            "contribution_ids": [
                "R44690"
            ]
        },
        {
            "instance_id": "R44978xR44716",
            "comparison_id": "R44978",
            "paper_id": "R44716",
            "text": "Randomised controlled trial of non-directive counselling, cognitive-behaviour therapy, and usual general practitioner care for patients with depression abstract objective: to compare the clinical effectiveness of general practitioner care and two general practice based psychological therapies for depressed patients. design: prospective, controlled trial with randomised and patient preference allocation arms. setting: general practices in london and greater manchester. participants: 464 of 627 patients presenting with depression or mixed anxiety and depression were suitable for inclusion. interventions: usual general practitioner care or up to 12 sessions of non-directive counselling or cognitive-behaviour therapy provided by therapists. main outcome measures: beck depression inventory scores, other psychiatric symptoms, social functioning, and satisfaction with treatment measured at baseline and at 4 and 12 months. results: 197 patients were randomly assigned to treatment, 137 chose their treatment, and 130 were randomised only between the two psychological therapies. all groups improved significantly over time. at four months, patients randomised to non-directive counselling or cognitive-behaviour therapy improved more in terms of the beck depression inventory (mean (sd) scores 12.9 (9.3) and 14.3 (10.8) respectively) than those randomised to usual general practitioner care (18.3 (12.4)). however, there was no significant difference between the two therapies. there were no significant differences between the three treatment groups at 12 months (beck depression scores 11.8 (9.6), 11.4 (10.8), and 12.1 (10.3) for non-directive counselling, cognitive-behaviour therapy, and general practitioner care). conclusions: psychological therapy was a more effective treatment for depression than usual general practitioner care in the short term, but after one year there was no difference in outcome.",
            "contribution_ids": [
                "R44717"
            ]
        },
        {
            "instance_id": "R46295xR45116",
            "comparison_id": "R46295",
            "paper_id": "R45116",
            "text": "Dynamics of efficient electron\u00e2\u0080\u0093hole separation in TiO2 nanoparticles revealed by femtosecond transient absorption spectroscopy under the weak-excitation condition the transient absorption of nanocrystalline tio(2) films in the visible and ir wavelength regions was measured under the weak-excitation condition, where the second-order electron-hole recombination process can be ignored. the intrinsic dynamics of the electron-hole pairs in the femtosecond to picosecond time range was elucidated. surface-trapped electrons and surface-trapped holes were generated within approximately 200 fs (time resolution). surface-trapped electrons, which gave an absorption peak at around 800 nm, and bulk electrons, which absorbed in the ir wavelength region, decayed with a 500-ps time constant due to relaxation into deep bulk trapping sites. it is already known that, after this relaxation, electrons and holes survive for microseconds. we interpreted these long lifetimes in terms of the prompt spatial charge separation of electrons in the bulk and holes at the surface.",
            "contribution_ids": [
                "R45117"
            ]
        },
        {
            "instance_id": "R46295xR45120",
            "comparison_id": "R46295",
            "paper_id": "R45120",
            "text": "Mechanism of O2 Production from Water Splitting: Nature of Charge Carriers in Nitrogen Doped Nanocrystalline TiO2 Films and Factors Limiting O2 Production the low efficiency of the extensively investigatedvisible light photocatalyst n-tio2 has been widely assumed to be determined by the dynamics of the charge carriers. the nature of the photoelectrons and photoholes produced on the nanostructured (nc) n-tio2 film has been systematically investigated in this work by the use of time-resolved absorption spectroscopy. here the fingerprints of the two distinct photohole populations on nc-n-tio2 films are reported and the reaction between these photoholes and water has been examined. the origin of the low efficiency of the visible-driven material for water oxidation was explored and rapid electron hole decay following visible excitation is believed to be a key factor. pt deposition on nc-n-tio2 resulted in an 80% enhancement of the quantum yield for o2 production under uv light. finally, it has been summarized that the oxygen production on the nc-n-tio2 film requires photoholes with lifetimes of \u223c0.4s.",
            "contribution_ids": [
                "R45121"
            ]
        },
        {
            "instance_id": "R46295xR45106",
            "comparison_id": "R46295",
            "paper_id": "R45106",
            "text": "How fast is interfacial hole transfer? In situ monitoring of carrier dynamics in anatase TiO 2 nanoparticles by femtosecond laser spectroscopy by comparing the transient absorption spectra of nanosized anatase tio2 colloidal systems with and without scn\u2212, the broad absorption band around 520 nm observed immediately after band-gap excitation for the system without scn\u2212 has been assigned to shallowly trapped holes. in the presence of scn\u2212, the absorption from the trapped holes at 520 nm cannot be observed because of the ultrafast interfacial hole transfer between tio2 nanoparticles and scn\u2212. the hole and electron trapping times were estimated to be <50 and 260 fs, respectively, by the analysis of rise and decay dynamics of transient absorption spectra. the rate of the hole transfer from nanosized tio2 colloid to scn\u2212 is comparable to that of the hole trapping and the time of formation of a weakly coupled (scn\u00b7\u00b7\u00b7scn)\u2022\u2212 is estimated to be \u223d2.3 ps with 0.3 m kscn. a further \\n structural change to form a stable (scn)2\u2022\u2212 is observed in a timescale of 100\u223d150 ps, which is almost independent of the concentration of scn\u2212.",
            "contribution_ids": [
                "R45107"
            ]
        },
        {
            "instance_id": "R46295xR45126",
            "comparison_id": "R46295",
            "paper_id": "R45126",
            "text": "Femtosecond Diffuse-Reflectance Spectroscopy of Various Commercially Available TiO2 Powders abstract the transient absorption properties of several commercially available tio2 photocatalysts were investigated by femtosecond diffuse-reflectance spectroscopy. using femtosecond diffuse-reflectance spectroscopy, the quantities and rates of the initial trapping processes of holes and electrons generated by the photoexcitation of tio2 photocatalysts were investigated. it was found that the total amounts of trapped electrons for the pure-anatase and pure-rutile tio2 became smaller with increasing particle size, but increased again when the particles\u2019 diameters were larger than 50 nm. the anatase\u2013rutile mixed tio2 photocatalysts were found to have smaller amounts of trapped electrons compared with pure-anatase and pure-rutile tio2 photocatalysts. the lifetimes of trapped holes of various tio2 photocatalysts were also investigated, and it was found that the lifetimes were proportional to the anatase\u2013rutile mixed ratios.",
            "contribution_ids": [
                "R45127"
            ]
        },
        {
            "instance_id": "R46295xR45108",
            "comparison_id": "R46295",
            "paper_id": "R45108",
            "text": "Identification of Reactive Species in Photoexcited Nanocrystalline TiO2 Films by Wide-Wavelength-Range (400\u00e2\u0088\u00922500 nm) Transient Absorption Spectroscopy reactive species, holes, and electrons in photoexcited nanocrystalline tio2 films were studied by transient absorption spectroscopy in the wavelength range from 400 to 2500 nm. the electron spectrum was obtained through a hole-scavenging reaction under steady-state light irradiation. the spectrum can be analyzed by a superposition of the free-electron and trapped-electron spectra. by subtracting the electron spectrum from the transient absorption spectrum, the spectrum of trapped holes was obtained. as a result, three reactive speciestrapped holes and free and trapped electronswere identified in the transient absorption spectrum. the reactivity of these species was evaluated through transient absorption spectroscopy in the presence of hole- and electron-scavenger molecules. the spectra indicate that trapped holes and electrons are localized at the surface of the particles and free electrons are distributed in the bulk.",
            "contribution_ids": [
                "R45109"
            ]
        },
        {
            "instance_id": "R46295xR45098",
            "comparison_id": "R46295",
            "paper_id": "R45098",
            "text": "Flash photolysis observation of the absorption spectra of trapped positive holes and electrons in colloidal titanium dioxide \"photolyse laser eclair a 347 nm d'un sol de tio 2 contenant un intercepteur d'electron adsorbe (pt ou mv 2+ ). etude par spectres d'absorption des especes piegees. a \u03bb max =475 nm observation de \u00abtrous\u00bb h + . vitesses de declin de h + en solutions acide et alcaline. trous h + en exces. avec un sol de tio 2 contenant un intercepteur de trous (alcool polyvinylique ou thiocyanate), observation d'un spectre a \u03bb max =650 nm attribue aux electrons pieges en exces, proches de la surface des particules colloidales\"",
            "contribution_ids": [
                "R45099"
            ]
        },
        {
            "instance_id": "R46295xR45102",
            "comparison_id": "R46295",
            "paper_id": "R45102",
            "text": "Picosecond flash spectroscopy of titania colloids with adsorbed dyes spectra for electrons trapped in tio{sub 2} have been reported. in this study, kinetic analysis of processes taking place when tio{sub 2} colloids are flashed in the presence of three dyes leads to assignment of the spectrum of a trapped hole. within the duration of a 20-ps pulse at 350 nm, a transient is formed in tio{sub 2} which decays with a second-order rate constant of 2.4 {times} 10{sup {minus}10} n{sub e} s{sup {minus}1}, where n{sub e} is the number of electrons. the absorbance is probably attributable to electrons in the conduction band (a term that must be used cautiously for these very amorphous systems), and the rate constant measures the rate of hole-electron recombination. upon addition of a dye that may scavenge carriers, a new transient grown with a rate constant of 5 {times} 10{sup 8} s{sup {minus}1}. this feature, with an absorption maximum at 630 nm, is attributed to a trapped hole. the mechanism proposed for the results of this intense pulse experiment involves two photons and excitation of both dye and colloid. the evidence includes observation of spectra of reduced dyes and quantitative consistency not achieved with any other model.",
            "contribution_ids": [
                "R45103"
            ]
        },
        {
            "instance_id": "R46295xR45104",
            "comparison_id": "R46295",
            "paper_id": "R45104",
            "text": "Charge Carrier Dynamics at TiO2 Particles:\u00e2\u0080\u0089 Reactivity of Free and Trapped Holes details of the mechanism of the photocatalytic oxidation of the model compounds dichloroacetate, dca-, and thiocyanate, scn-, have been investigated employing time-resolved laser flash photolysis. nanosized colloidal titanium dioxide (tio2, anatase) particles with a mean diameter of 24 a were used as photocatalysts in optically transparent aqueous suspensions. detailed spectroscopic investigations of the processes occurring upon band gap irradiation in these colloidal aqueous tio2 suspensions in the absence of any hole scavengers showed that while electrons are trapped instantaneously, i.e., within the duration of the laser flash (20 ns), at least two different types of traps have to be considered for the remaining holes. deeply trapped holes, h+tr, are rather long-lived and unreactive, i.e., they are transferred neither to dca- nor to scn- ions. shallowly trapped holes, h+tr*, on the other hand, are in a thermally activated equilibrium with free holes which exhibit a very high oxidation potential. the ov...",
            "contribution_ids": [
                "R45105"
            ]
        },
        {
            "instance_id": "R46296xR46082",
            "comparison_id": "R46296",
            "paper_id": "R46082",
            "text": "Formation of New Structures and Their Synergistic Effects in Boron and Nitrogen Codoped TiO2 for Enhancement of Photocatalytic Performance a novel double hydrothermal method to prepare the boron and nitrogen codoped tio2 is developed. two different ways have been used for the synthesis of the catalysts, one through the addition of boron followed by nitrogen, and the other through the addition of nitrogen first and then by boron. the x-ray photoelectron spectroscopy analysis indicates the synergistic effect of boron and nitrogen with the formation of ti\u2212b\u2212n\u2212ti and ti\u2212n\u2212b\u2212o compounds on the surface of catalysts when nitrogen is introduced to the materials first. when the boron is added first, only ti\u2212n\u2212b\u2212o species occurs on the surface of catalysts. the above two compounds are all thought to enhance the photocatalytic activities of codoped tio2. density functional theory simulations are also performed to investigate the b\u2212n synergistic effect. for the (101) surface, the formation of ti\u2212b\u2212n\u2212ti structures gives rise to the localized states within the tio2 band gap.",
            "contribution_ids": [
                "R46083"
            ]
        },
        {
            "instance_id": "R46296xR46091",
            "comparison_id": "R46296",
            "paper_id": "R46091",
            "text": "Synthesis and Characterization of Nitrogen-Doped TiO2 Nanophotocatalyst with High Visible Light Activity nitrogen-doped tio2 nanocatalysts with a homogeneous anatase structure were successfully synthesized through a microemulsion\u2212hydrothermal method by using some organic compounds such as triethylamine, urea, thiourea, and hydrazine hydrate. analysis by raman and x-ray photoemission spectroscopy indicated that nitrogen was doped effectively and most nitrogen dopants might be present in the chemical environment of ti\u2212o\u2212n and o\u2212ti\u2212n. a shift of the absorption edge to a lower energy and a stronger absorption in the visible light region were observed. the results of photodegradation or the organic pollutant rhodamine b in the visible light irradiation (\u03bb > 420 nm) suggested that the tio2 photocatalysts after nitrogen doping were greatly improved compared with the undoped tio2 photocatalysts and degussa p-25; especially the nitrogen-doped tio2 using triathylamine as the nitrogen source showed the highest photocatalytic activity, which also showed a higher efficiency for photodecomposition of 2,4-dichlorophenol. t...",
            "contribution_ids": [
                "R46092"
            ]
        },
        {
            "instance_id": "R46296xR46123",
            "comparison_id": "R46296",
            "paper_id": "R46123",
            "text": "Effective Visible Light-Activated B-Doped and B,N-Codoped TiO2 Photocatalysts a simple low cost method permits controlled, reproducible doping of tio2 anatase by boron. the resulting materials exhibit red-shifted absorption spectra and unprecedented photocatalytic activity under visible light. xp spectra are consistent with the presence of \u201cactive\u201d and \u201cinactive\u201d forms of b corresponding to substitutional boron and boric oxide-like material, respectively.",
            "contribution_ids": [
                "R46124"
            ]
        },
        {
            "instance_id": "R46296xR46113",
            "comparison_id": "R46296",
            "paper_id": "R46113",
            "text": "Preparation of Polycrystalline TiO2 Photocatalysts Impregnated with Various Transition Metal Ions: Characterization and Photocatalytic Activity for the Degradation of 4-Nitrophenol a set of polycrystalline tio2 photocatalysts loaded with various ions of transition metals (co, cr, cu, fe, mo, v, and w) were prepared by using the wet impregnation method. the samples were characterized by using some bulk and surface techniques, namely x-ray diffraction, bet specific surface area determination, scanning electron microscopy, point of zero charge determination, and femtosecond pump\u2212probe diffuse reflectance spectroscopy (pp-drs). the samples were employed as catalysts for 4-nitrophenol photodegradation in aqueous suspension, used as a probe reaction. the characterization results have confirmed the difficulty to find a straightforward correlation between photoactivity and single specific properties of the powders. diffuse reflectance measurements showed a slight shift in the band gap transition to longer wavelengths and an extension of the absorption in the visible region for almost all the doped samples. sem observation and edx measurements indicated a similar morphology for all the parti...",
            "contribution_ids": [
                "R46114"
            ]
        },
        {
            "instance_id": "R46296xR46111",
            "comparison_id": "R46296",
            "paper_id": "R46111",
            "text": "Photocatalytic Performance of N-Doped TiO2 Adsorbed with Fe3+ Ions under Visible Light by a Redox Treatment a simple method to prepare the n\u2212tio2 adsorbed with fe3+ ions only on the surface of catalysts and modify the catalysts by a redox treatment (nabh4 reduction and air oxidation treatment) was proposed. the samples were characterized by x-ray diffraction (xrd), uv\u2212vis diffuse reflectance spectroscopy, ftir, x-ray photoelectron spectroscopy (xps), and high-resolution transmission electron micrograph (hrtem). the photocatalytic activities of the samples were evaluated for degradation of methylene blue (mb) in aqueous solutions under visible light (\u03bb > 420 nm). the results of xrd, ftir, xps, and hrtem analysis indicated that the structure of fe compounds changed from fe2o3 to \u03b3-feooh after redox treatment. compared to n\u2212tio2 with fe3+ ions, the catalysts after redox treatment showed higher photoactivity under visible light, and the formation of \u03b3-feooh was responsible for the improvement of photocatalytic activity. furthermore, to the catalysts after redox treatment, the mechanism for degradation of mb under v...",
            "contribution_ids": [
                "R46112"
            ]
        },
        {
            "instance_id": "R46296xR46119",
            "comparison_id": "R46296",
            "paper_id": "R46119",
            "text": "Enhancing Visible Light Photo-oxidation of Water with TiO2 Nanowire Arrays via Cotreatment with H2 and NH3: Synergistic Effects between Ti3+ and N we report a synergistic effect involving hydrogenation and nitridation cotreatment of tio(2) nanowire (nw) arrays that improves the water photo-oxidation performance under visible light illumination. the visible light (>420 nm) photocurrent of the cotreated tio(2) is 0.16 ma/cm(2) and accounts for 41% of the total photocurrent under simulated am 1.5 g illumination. electron paramagnetic resonance (epr) spectroscopy reveals that the concentration of ti(3+) species in the bulk of the tio(2) following hydrogenation and nitridation cotreatment is significantly higher than that of the sample treated solely with ammonia. it is believed that the interaction between the n-dopant and ti(3+) is the key to the extension of the active spectrum and the superior visible light water photo-oxidation activity of the hydrogenation and nitridation cotreated tio(2) nw arrays.",
            "contribution_ids": [
                "R46120"
            ]
        },
        {
            "instance_id": "R46296xR46115",
            "comparison_id": "R46296",
            "paper_id": "R46115",
            "text": "Hydrogenated TiO2 Nanocrystals: A Novel Microwave Absorbing Material here, we report, for the first time, hydrogenated tio2 nanocrystals as a novel and exciting microwave absorbing material, based on an innovative collective-movement-of-interfacial-dipole mechanism which causes collective-interfacial-polarization-amplified microwave absorption at the crystalline/disordered and anatase/rutile interfaces. this mechanism is intriguing and upon further exploration may trigger other new concepts and applications.",
            "contribution_ids": [
                "R46116"
            ]
        },
        {
            "instance_id": "R46296xR46129",
            "comparison_id": "R46296",
            "paper_id": "R46129",
            "text": "H\u00e2\u0080\u0090doped black titania with very high solar absorption and excellent photocatalysis enhanced by localized surface plasmon resonance black tio2 attracts enormous attention due to its large solar absorption and induced excellent photocatalytic activity. herein, a new approach assisted by hydrogen plasma to synthesize unique h\u2010doped black titania with a core/shell structure (tio2@tio2\u2010xhx) is presented, superior to the high h2\u2010pressure process (under 20 bar for five days). the black titania possesses the largest solar absorption (\u224883%), far more than any other reported black titania (the record (high\u2010pressure): \u224830%). h doping is favorable to eliminate the recombination centers of light\u2010induced electrons and holes. high absorption and low recombination ensure the excellent photocatalytic activity for the black titania in the photo\u2010oxidation of organic molecules in water and the production of hydrogen. the h\u2010doped amorphous shell is proposed to play the same role as ag or pt loading on tio2 nanocrystals, which induces the localized surface plasma resonance and black coloration. photocatalytic water splitting and cleaning using tio2\u2010xhx is believed to have a bright future for sustainable energy sources and cleaning environment.",
            "contribution_ids": [
                "R46130"
            ]
        },
        {
            "instance_id": "R46296xR46125",
            "comparison_id": "R46296",
            "paper_id": "R46125",
            "text": "A Facile Method to Improve the Photocatalytic and Lithium\u00e2\u0080\u0090Ion Rechargeable Battery Performance of TiO2 Nanocrystals tio2 has been well studied as an ultraviolet (uv) photocatalyst and electrode material for lithium\u2010ion rechargeable batteries. recent studies have shown that hydrogenated tio2 displayed better photocatalytic and lithium ion battery performances. here it is demonstrated that the photocatalytic and battery performances of tio2 nanocrystals can be successfully improved with a facile low\u2010temperature vacuum process. these tio2 nanocrystals extend their optical absorption far into the visible\u2010light region, display nanometer\u2010scale surface atomic rearrangement, possess superoxide ion characteristics at room temperature without light irradiation, show a 4\u2010fold improvement in photocatalytic activity, and has 30% better performance in capacity and charge/discharge rates for lithium ion battery. this facile method could provide an alternative and effective approach to improve the performance of tio2 and other materials towards their practical applications.",
            "contribution_ids": [
                "R46126"
            ]
        },
        {
            "instance_id": "R46296xR46076",
            "comparison_id": "R46296",
            "paper_id": "R46076",
            "text": "One-step hydrothermal synthesis of N-doped TiO 2/C nanocomposites with high visible light photocatalytic activity n-doped tio(2) nanoparticles modified with carbon (denoted n-tio(2)/c) were successfully prepared by a facile one-pot hydrothermal treatment in the presence of l-lysine, which acts as a ligand to control the nanocrystal growth and as a source of nitrogen and carbon. as-prepared nanocomposites were characterized by thermogravimetric analysis (tga), x-ray diffraction (xrd), transmission electron microscopy (tem), high-resolution transmission electron microscopy (hrtem), raman spectroscopy, ultraviolet-visible (uv-vis) diffuse reflectance spectroscopy, x-ray photoelectron spectroscopy (xps), fourier transform infrared spectroscopy (ftir), electron paramagnetic resonance (epr) spectra, and n(2) adsorption-desorption analysis. the photocatalytic activities of the as-prepared photocatalysts were measured by the degradation of methyl orange (mo) under visible light irradiation at \u03bb\u2265 400 nm. the results show that n-tio(2)/c nanocomposites increase absorption in the visible light region and exhibit a higher photocatalytic activity than pure tio(2), commercial p25 and previously reported n-doped tio(2) photocatalysts. we have demonstrated that the nitrogen was doped into the lattice and the carbon species were modified on the surface of the photocatalysts. n-doping narrows the band gap and c-modification enhances the visible light harvesting and accelerates the separation of the photo-generated electrons and holes. as a consequence, the photocatalytic activity is significantly improved. the molar ratio of l-lysine/ticl(4) and the ph of the hydrothermal reaction solution are important factors affecting the photocatalytic activity of the n-tio(2)/c; the optimum molar ratio of l-lysine/ticl(4) is 8 and the optimum ph is ca. 4, at which the catalyst exhibits the highest reactivity. our findings demonstrate that the as-obtained n-tio(2)/c photocatalyst is a better and more promising candidate than well studied n-doped tio(2) alternatives as visible light photocatalysts for potential applications in environmental purification.",
            "contribution_ids": [
                "R46077"
            ]
        },
        {
            "instance_id": "R46296xR46099",
            "comparison_id": "R46296",
            "paper_id": "R46099",
            "text": "Effects of F- Doping on the Photocatalytic Activity and Microstructures of Nanocrystalline TiO2 Powders a novel and simple method for preparing highly photoactive nanocrystalline f--doped tio2 photocatalyst with anatase and brookite phase was developed by hydrolysis of titanium tetraisopropoxide in a mixed nh4f\u2212h2o solution. the prepared f--doped tio2 powders were characterized by differential thermal analysis-thermogravimetry (dta-tg), x-ray diffraction (xrd), x-ray photoelectron spectroscopy (xps), uv\u2212vis absorption spectroscopy, photoluminescence spectra (pl), transmission electron microscopy (tem), and bet surface areas. the photocatalytic activity was evaluated by the photocatalytic oxidation of acetone in air. the results showed that the crystallinity of anatase was improved upon f- doping. moreover, fluoride ions not only suppressed the formation of brookite phase but also prevented phase transition of anatase to rutile. the f--doped tio2 samples exhibited stronger absorption in the uv\u2212visible range with a red shift in the band gap transition. the photocatalytic activity of f--doped tio2 powders prep...",
            "contribution_ids": [
                "R46100"
            ]
        },
        {
            "instance_id": "R46299xR46231",
            "comparison_id": "R46299",
            "paper_id": "R46231",
            "text": "Polymeric g-C3N4 coupled with NaNbO3 nanowires toward enhanced photocatalytic reduction of CO2 into renewable fuel visible-light-responsive g-c3n4/nanbo3 nanowires photocatalysts were fabricated by introducing polymeric g-c3n4 on nanbo3 nanowires. the microscopic mechanisms of interface interaction, charge transfer and separation, as well as the influence on the photocatalytic activity of g-c3n4/nanbo3 composite were systematic investigated. the high-resolution transmission electron microscopy (hr-tem) revealed that an intimate interface between c3n4 and nanbo3 nanowires formed in the g-c3n4/nanbo3 heterojunctions. the photocatalytic performance of photocatalysts was evaluated for co2 reduction under visible-light illumination. significantly, the activity of g-c3n4/nanbo3 composite photocatalyst for photoreduction of co2 was higher than that of either single-phase g-c3n4 or nanbo3. such a remarkable enhancement of photocatalytic activity was mainly ascribed to the improved separation and transfer of photogenerated electron\u2013hole pairs at the intimate interface of g-c3n4/nanbo3 heterojunctions, which originated from the...",
            "contribution_ids": [
                "R46232"
            ]
        },
        {
            "instance_id": "R46299xR46227",
            "comparison_id": "R46299",
            "paper_id": "R46227",
            "text": "Photocatalytic Reduction of Carbon Dioxide to Methane over SiO2-Pillared HNb3O8 carbon dioxide (co2) photoreduction by gaseous water over silica-pillared lamellar niobic acid, viz. hnb3o8, was studied in this work. the physicochemical characteristics of samples were examined by techniques such as xrd, ft-ir, sem, tem, and uv\u2013visible diffuse reflectance spectroscopy. aspects that influence co2 photoreduction, such as the layered structure, the protonic acidity, silica pillaring, and cocatalyst loading, were investigated in detail. pt loading obvious promoted the activity for co2 photoreduction to methane. the loading of pt also promoted the formation of methane from catalyst associated carbon residues, although this contributes insignificantly to the overall amount of methane produced. the layered structure and the protonic acidity of the lamellar niobic acid have significant influences on co2 photoreduction by water in gas phase. with layered structure, expanded interlayer distance, and stronger intercalation ability to water molecules, the silica pillared niobic acid showed much hig...",
            "contribution_ids": [
                "R46228"
            ]
        },
        {
            "instance_id": "R48103xR46656",
            "comparison_id": "R48103",
            "paper_id": "R46656",
            "text": "CRFS-based Chinese named entity recognition with improved tag set chinese named entity recognition is one of the most important tasks in nlp. the paper mainly describes our work on ner tasks. the paper built up a system under the framework of conditional random fields (crfs) model. with an improved tag set the system gets an f-value of 93.49 using sighan2007 msra corpus.",
            "contribution_ids": [
                "R46657"
            ]
        },
        {
            "instance_id": "R48392xR48309",
            "comparison_id": "R48392",
            "paper_id": "R48309",
            "text": "Uncertainty in Sea Level Rise Projections Due to the Dependence Between Contributors sea level rises at an accelerating pace threatening coastal communities all over the world. in this context sea level projections are key tools to help risk mitigation and adaptation. projections are often made using models of the main contributors to sea level rise (e.g., thermal expansion, glaciers, and ice sheets). to obtain the total sea level these contributions are added; therefore, the uncertainty of total sea level depends on the correlation between the uncertainties of the contributors. this fact is important to understand the differences in the uncertainty of sea level projections from different methods. using two process\u2010based models to project sea level for the 21st century, we show how to model the correlation structure and its time dependence. in these models the correlation primarily arises from uncertainty of future global mean surface temperature that correlates with almost all contributors. assuming that sea level contributors are independent of each other, an assumption made in many sea level projections underestimates the uncertainty in sea level projections. as a result, high\u2010end low probability events that are important for decision making are underestimated. the uncertainty in the strength of the dependence between contributors is also explored. new dependence relations between the uncertainty of dynamical processes and surface mass balance in glaciers and ice sheets are introduced in our model. total sea level uncertainty is found to be as sensitive to the dependence between contributors as to uncertainty in certain individual contributors like thermal expansion and greenland ice sheet.",
            "contribution_ids": [
                "R48311",
                "R48313"
            ]
        },
        {
            "instance_id": "R48392xR48367",
            "comparison_id": "R48392",
            "paper_id": "R48367",
            "text": "Linking sea level rise and socioeconomic indicators underthe Shared Socioeconomic Pathways in order to assess future sea level rise and its societal impacts, we need to study climate change pathways combined with different scenarios of socioeconomic development. here, we present sea level rise (slr) projections for the shared socioeconomic pathway (ssp) storylines and different year-2100 radiative forcing targets (fts). future slr is estimated with a comprehensive slr emulator that accounts for antarctic rapid discharge from hydrofracturing and ice cliff instability. across all baseline scenario realizations (no dedicated climate mitigation), we find 2100 median slr relative to 1986\u20132005 of 89\\u2009cm (likely range: 57\u2013130\\u2009cm) for ssp1, 105\\u2009cm (73\u2013150\\u2009cm) for ssp2, 105\\u2009cm (75\u2013147\\u2009cm) for ssp3, 93\\u2009cm (63\u2013133\\u2009cm) for ssp4, and 132\\u2009cm (95\u2013189\\u2009cm) for ssp5. the 2100 sea level responses for combined ssp-ft scenarios are dominated by the mitigation targets and yield median estimates of 52\\u2009cm (34\u201375\\u2009cm) for ft 2.6\\u2009wm\u22122, 62\\u2009cm (40\u201396\\u2009cm) for ft 3.4\\u2009wm\u22122, 75\\u2009cm (47\u2013113\\u2009cm) for ft 4.5\\u2009wm\u22122, and 91\\u2009cm (61\u2013132\\u2009cm) for ft 6.0\\u2009wm\u22122. average 2081\u20132100 annual slr rates are 5 mm yr\u22121 and 19 mm yr\u22121 for ft 2.6\\u2009wm\u22122 and the baseline scenarios, respectively. our model setup allows linking scenario-specific emission and socioeconomic indicators to projected slr. we find that 2100 median ssp slr projections could be limited to around 50\\u2009cm if 2050 cumulative co2 emissions since pre-industrial stay below 850 gtc, with a global coal phase-out nearly completed by that time. for ssp mitigation scenarios, a 2050 carbon price of 100 us$2005 tco2\u22121 would correspond to a median 2100 slr of around 65 cm. our results confirm that rapid and early emission reductions are essential for limiting 2100 slr.",
            "contribution_ids": [
                "R48369",
                "R48371",
                "R48373",
                "R48375",
                "R48377",
                "R48379",
                "R175307",
                "R175310",
                "R175313",
                "R175316"
            ]
        },
        {
            "instance_id": "R48392xR48279",
            "comparison_id": "R48392",
            "paper_id": "R48279",
            "text": "Evolving Understanding of Antarctic Ice\u00e2\u0080\u0090Sheet Physics and Ambiguity in Probabilistic Sea\u00e2\u0080\u0090Level Projections mechanisms such as ice\u2010shelf hydrofracturing and ice\u2010cliff collapse may rapidly increase discharge from marine\u2010based ice sheets. here, we link a probabilistic framework for sea\u2010level projections to a small ensemble of antarctic ice\u2010sheet (ais) simulations incorporating these physical processes to explore their influence on global\u2010mean sea\u2010level (gmsl) and relative sea\u2010level (rsl). we compare the new projections to past results using expert assessment and structured expert elicitation about ais changes. under high greenhouse gas emissions (representative concentration pathway [rcp] 8.5), median projected 21st century gmsl rise increases from 79 to 146 cm. without protective measures, revised median rsl projections would by 2100 submerge land currently home to 153 million people, an increase of 44 million. the use of a physical model, rather than simple parameterizations assuming constant acceleration of ice loss, increases forcing sensitivity: overlap between the central 90% of simulations for 2100 for rcp 8.5 (93\u2013243 cm) and rcp 2.6 (26\u201398 cm) is minimal. by 2300, the gap between median gmsl estimates for rcp 8.5 and rcp 2.6 reaches >10 m, with median rsl projections for rcp 8.5 jeopardizing land now occupied by 950 million people (versus 167 million for rcp 2.6). the minimal correlation between the contribution of ais to gmsl by 2050 and that in 2100 and beyond implies current sea\u2010level observations cannot exclude future extreme outcomes. the sensitivity of post\u20102050 projections to deeply uncertain physics highlights the need for robust decision and adaptive management frameworks.",
            "contribution_ids": [
                "R48289",
                "R48291",
                "R48293",
                "R48295",
                "R48297",
                "R48300"
            ]
        },
        {
            "instance_id": "R48392xR48253",
            "comparison_id": "R48392",
            "paper_id": "R48253",
            "text": "Sea level rise projections for northern Europe under RCP8.5 sea level rise poses a significant threat to coastal communities, infrastructure, and ecosystems. sea level rise is not uniform globally but is affected by a range of regional factors. in this study, we calculate regional projections of 21st century sea level rise in northern europe, focusing on the british isles, the baltic sea, and the north sea. the input to the regional sea level projection is a probabilistic projection of the major components of the global sea level budget. local sea level rise is partly compensated by vertical land movement from glacial isostatic adjustment. we explore the uncertainties beyond the likely range provided by the ipcc, including the risk and potential rate of marine ice sheet collapse. our median 21st century relative sea level rise projection is 0.8 m near london and hamburg, with a relative sea level drop of 0.1 m in the bay of bothnia (near oulu, finland). considerable uncertainties remain in both the sea level budget and in the regional expression of sea level rise. the greatest uncertainties are associated with antarctic ice loss, and uncertainties are skewed towards higher values, with the 95th percentile being characterized by an additional 0.9 m sea level rise above median projections.",
            "contribution_ids": [
                "R48255"
            ]
        },
        {
            "instance_id": "R48401xR48367",
            "comparison_id": "R48401",
            "paper_id": "R48367",
            "text": "Linking sea level rise and socioeconomic indicators underthe Shared Socioeconomic Pathways in order to assess future sea level rise and its societal impacts, we need to study climate change pathways combined with different scenarios of socioeconomic development. here, we present sea level rise (slr) projections for the shared socioeconomic pathway (ssp) storylines and different year-2100 radiative forcing targets (fts). future slr is estimated with a comprehensive slr emulator that accounts for antarctic rapid discharge from hydrofracturing and ice cliff instability. across all baseline scenario realizations (no dedicated climate mitigation), we find 2100 median slr relative to 1986\u20132005 of 89\\u2009cm (likely range: 57\u2013130\\u2009cm) for ssp1, 105\\u2009cm (73\u2013150\\u2009cm) for ssp2, 105\\u2009cm (75\u2013147\\u2009cm) for ssp3, 93\\u2009cm (63\u2013133\\u2009cm) for ssp4, and 132\\u2009cm (95\u2013189\\u2009cm) for ssp5. the 2100 sea level responses for combined ssp-ft scenarios are dominated by the mitigation targets and yield median estimates of 52\\u2009cm (34\u201375\\u2009cm) for ft 2.6\\u2009wm\u22122, 62\\u2009cm (40\u201396\\u2009cm) for ft 3.4\\u2009wm\u22122, 75\\u2009cm (47\u2013113\\u2009cm) for ft 4.5\\u2009wm\u22122, and 91\\u2009cm (61\u2013132\\u2009cm) for ft 6.0\\u2009wm\u22122. average 2081\u20132100 annual slr rates are 5 mm yr\u22121 and 19 mm yr\u22121 for ft 2.6\\u2009wm\u22122 and the baseline scenarios, respectively. our model setup allows linking scenario-specific emission and socioeconomic indicators to projected slr. we find that 2100 median ssp slr projections could be limited to around 50\\u2009cm if 2050 cumulative co2 emissions since pre-industrial stay below 850 gtc, with a global coal phase-out nearly completed by that time. for ssp mitigation scenarios, a 2050 carbon price of 100 us$2005 tco2\u22121 would correspond to a median 2100 slr of around 65 cm. our results confirm that rapid and early emission reductions are essential for limiting 2100 slr.",
            "contribution_ids": [
                "R48369",
                "R48371",
                "R48373",
                "R48375",
                "R48377",
                "R48379",
                "R175307",
                "R175310",
                "R175313",
                "R175316"
            ]
        },
        {
            "instance_id": "R48401xR48309",
            "comparison_id": "R48401",
            "paper_id": "R48309",
            "text": "Uncertainty in Sea Level Rise Projections Due to the Dependence Between Contributors sea level rises at an accelerating pace threatening coastal communities all over the world. in this context sea level projections are key tools to help risk mitigation and adaptation. projections are often made using models of the main contributors to sea level rise (e.g., thermal expansion, glaciers, and ice sheets). to obtain the total sea level these contributions are added; therefore, the uncertainty of total sea level depends on the correlation between the uncertainties of the contributors. this fact is important to understand the differences in the uncertainty of sea level projections from different methods. using two process\u2010based models to project sea level for the 21st century, we show how to model the correlation structure and its time dependence. in these models the correlation primarily arises from uncertainty of future global mean surface temperature that correlates with almost all contributors. assuming that sea level contributors are independent of each other, an assumption made in many sea level projections underestimates the uncertainty in sea level projections. as a result, high\u2010end low probability events that are important for decision making are underestimated. the uncertainty in the strength of the dependence between contributors is also explored. new dependence relations between the uncertainty of dynamical processes and surface mass balance in glaciers and ice sheets are introduced in our model. total sea level uncertainty is found to be as sensitive to the dependence between contributors as to uncertainty in certain individual contributors like thermal expansion and greenland ice sheet.",
            "contribution_ids": [
                "R48311",
                "R48313"
            ]
        },
        {
            "instance_id": "R48401xR48353",
            "comparison_id": "R48401",
            "paper_id": "R48353",
            "text": "Future sea level rise constrained by observations and long-term commitment \" significance \\n anthropogenic sea level rise poses challenges to coastal areas worldwide, and robust projections are needed to assess mitigation options and guide adaptation measures. here we present an approach that combines information about the equilibrium sea level response to global warming and last century's observed contribution from the individual components to constrain projections for this century. this \u201cconstrained extrapolation\u201d overcomes limitations of earlier global semiempirical estimates because long-term changes in the partitioning of total sea level rise are accounted for. while applying semiempirical methodology, our method yields sea level projections that overlap with the process-based estimates of the intergovernmental panel on climate change. the method can thus lead to a better understanding of the gap between process-based and global semiempirical approaches. \"",
            "contribution_ids": [
                "R166795",
                "R166797",
                "R166798",
                "R166799",
                "R48355",
                "R48357",
                "R48359",
                "R48361",
                "R48363",
                "R48365"
            ]
        },
        {
            "instance_id": "R48401xR48279",
            "comparison_id": "R48401",
            "paper_id": "R48279",
            "text": "Evolving Understanding of Antarctic Ice\u00e2\u0080\u0090Sheet Physics and Ambiguity in Probabilistic Sea\u00e2\u0080\u0090Level Projections mechanisms such as ice\u2010shelf hydrofracturing and ice\u2010cliff collapse may rapidly increase discharge from marine\u2010based ice sheets. here, we link a probabilistic framework for sea\u2010level projections to a small ensemble of antarctic ice\u2010sheet (ais) simulations incorporating these physical processes to explore their influence on global\u2010mean sea\u2010level (gmsl) and relative sea\u2010level (rsl). we compare the new projections to past results using expert assessment and structured expert elicitation about ais changes. under high greenhouse gas emissions (representative concentration pathway [rcp] 8.5), median projected 21st century gmsl rise increases from 79 to 146 cm. without protective measures, revised median rsl projections would by 2100 submerge land currently home to 153 million people, an increase of 44 million. the use of a physical model, rather than simple parameterizations assuming constant acceleration of ice loss, increases forcing sensitivity: overlap between the central 90% of simulations for 2100 for rcp 8.5 (93\u2013243 cm) and rcp 2.6 (26\u201398 cm) is minimal. by 2300, the gap between median gmsl estimates for rcp 8.5 and rcp 2.6 reaches >10 m, with median rsl projections for rcp 8.5 jeopardizing land now occupied by 950 million people (versus 167 million for rcp 2.6). the minimal correlation between the contribution of ais to gmsl by 2050 and that in 2100 and beyond implies current sea\u2010level observations cannot exclude future extreme outcomes. the sensitivity of post\u20102050 projections to deeply uncertain physics highlights the need for robust decision and adaptive management frameworks.",
            "contribution_ids": [
                "R48289",
                "R48291",
                "R48293",
                "R48295",
                "R48297",
                "R48300"
            ]
        },
        {
            "instance_id": "R52143xR52133",
            "comparison_id": "R52143",
            "paper_id": "R52133",
            "text": "Is phylogenetic relatedness to native species important for the establishment of reptiles introduced to California and Florida? aim\\u2002 charles darwin posited that introduced species with close relatives were less likely to succeed because of fiercer competition resulting from their similarity to residents. there is much debate about the generality of this rule, and recent studies on plant and fish introductions have been inconclusive. information on phylogenetic relatedness is potentially valuable for explaining invasion outcomes and could form part of screening protocols for minimizing future invasions. we provide the first test of this hypothesis for terrestrial vertebrates using two new molecular phylogenies for native and introduced reptiles for two regions with the best data on introduction histories.",
            "contribution_ids": [
                "R52134",
                "R53247",
                "R53248",
                "R53396",
                "R53398"
            ]
        },
        {
            "instance_id": "R52143xR52081",
            "comparison_id": "R52143",
            "paper_id": "R52081",
            "text": "Strengthening Invasion Filters to Reassemble Native Plant Communities: Soil Resources and Phenological Overlap preventing invasion by exotic species is one of the key goals of restoration, and community assembly theory provides testable predictions about native community attributes that will best resist invasion. for instance, resource availability and biotic interactions may represent \u201cfilters\u201d that limit the success of potential invaders. communities are predicted to resist invasion when they contain native species that are functionally similar to potential invaders; where phenology may be a key functional trait. nutrient reduction is another common strategy for reducing invasion following native species restoration, because soil nitrogen (n) enrichment often facilitates invasion. here, we focus on restoring the herbaceous community associated with coastal sage scrub vegetation in southern california; these communities are often highly invaded, especially by exotic annual grasses that are notoriously challenging for restoration. we created experimental plant communities composed of the same 20 native species, but manipulated functional group abundance (according to growth form, phenology, and n\u2010fixation capacity) and soil n availability. we fertilized to increase n, and added carbon to reduce n via microbial n immobilization. we found that n reduction decreased exotic cover, and the most successful seed mix for reducing exotic abundance varied depending on the invader functional type. for instance, exotic annual grasses were least abundant when the native community was dominated by early active forbs, which matched the phenology of the exotic annual grasses. our findings show that nutrient availability and the timing of biotic interactions are key filters that can be manipulated in restoration to prevent invasion and maximize native species recovery.",
            "contribution_ids": [
                "R52082"
            ]
        },
        {
            "instance_id": "R52143xR52122",
            "comparison_id": "R52143",
            "paper_id": "R52122",
            "text": "Grassland invader responses to realistic changes in native species richness the importance of species richness for repelling exotic plant invasions varies from ecosystem to ecosystem. thus, in order to prioritize conservation objectives, it is critical to identify those ecosystems where decreasing richness will most greatly magnify invasion risks. our goal was to determine if invasion risks greatly increase in response to common reductions in grassland species richness. we imposed treatments that mimic management-induced reductions in grassland species richness (i.e., removal of shallow- and/or deep-rooted forbs and/or grasses and/or cryptogam layers). then we introduced and monitored the performance of a notorious invasive species (i.e., centaurea maculosa). we found that, on a per-gram-of-biomass basis, each resident plant group similarly suppressed invader growth. hence, with respect to preventing c. maculosa invasions, maintaining overall productivity is probably more important than maintaining the productivity of particular plant groups or species. but at the sites we studied, all plant groups may be needed to maintain overall productivity because removing forbs decreased overall productivity in two of three years. alternatively, removing forbs increased productivity in another year, and this led us to posit that removing forbs may inflate the temporal productivity variance as opposed to greatly affecting time-averaged productivity. in either case, overall productivity responses to single plant group removals were inconsistent and fairly modest, and only when all plant groups were removed did c. maculosa growth increase substantially over a no-removal treatment. as such, it seems that intense disturbances (e.g., prolonged drought, overgrazing) that deplete multiple plant groups may often be a prerequisite for c. maculosa invasion.",
            "contribution_ids": [
                "R52123",
                "R57340"
            ]
        },
        {
            "instance_id": "R52143xR52073",
            "comparison_id": "R52143",
            "paper_id": "R52073",
            "text": "Using ecological restoration to constrain biological invasion summary \\n \\n \\n1 \\nbiological invasion can permanently alter ecosystem structure and function. invasive species are difficult to eradicate, so methods for constraining invasions would be ecologically valuable. we examined the potential of ecological restoration to constrain invasion of an old field by agropyron cristatum, an introduced c3 grass. \\n \\n2 \\na field experiment was conducted in the northern great plains of north america. one-hundred and forty restored plots were planted in 1994\u201396 with a mixture of c3 and c4 native grass seed, while 100 unrestored plots were not. vegetation on the plots was measured periodically between 1994 and 2002. \\n \\n3 \\nagropyron cristatum invaded the old field between 1994 and 2002, occurring in 5% of plots in 1994 and 66% of plots in 2002, and increasing in mean cover from 0\u00b72% in 1994 to 17\u00b71% in 2002. however, a. cristatum invaded one-third fewer restored than unrestored plots between 1997 and 2002, suggesting that restoration constrained invasion. further, a. cristatum cover in restored plots decreased with increasing planted grass cover. stepwise regression indicated that a. cristatum cover was more strongly correlated with planted grass cover than with distance from the a. cristatum source, species richness, percentage bare ground or percentage litter. \\n \\n4 \\nthe strength of the negative relationship between a. cristatum and planted native grasses varied among functional groups: the correlation was stronger with species with phenology and physiology similar to a. cristatum (i.e. c3 grasses) than with dissimilar species (c4 grasses). \\n \\n5 \\nrichness and cover of naturally establishing native species decreased with increasing a. cristatum cover. in contrast, restoration had little effect on the establishment and colonization of naturally establishing native species. thus, a. cristatum hindered colonization by native species while planted native grasses did not. \\n \\n6 \\nsynthesis and applications. to our knowledge, this study provides the first indication that restoration can act as a filter, constraining invasive species while allowing colonization by native species. these results suggest that resistance to invasion depends on the identity of species in the community and that restoration seed mixes might be tailored to constrain selected invaders. restoring areas before invasive species become established can reduce the magnitude of biological invasion.",
            "contribution_ids": [
                "R52074"
            ]
        },
        {
            "instance_id": "R52143xR52098",
            "comparison_id": "R52143",
            "paper_id": "R52098",
            "text": "Community assembly and invasion: An experimental test of neutral versus niche processes a species-addition experiment showed that prairie grasslands have a\\n structured, nonneutral assembly process in which resident species inhibit, via\\n resource consumption, the establishment and growth of species with similar\\n resource use patterns and in which the success of invaders decreases as\\n diversity increases. in our experiment, species in each of four functional\\n guilds were introduced, as seed, into 147 prairie\u2013grassland plots that\\n previously had been established and maintained to have different compositions\\n and diversities. established species most strongly inhibited introduced\\n species from their own functional guild. introduced species attained lower\\n abundances when functionally similar species were abundant and when\\n established species left lower levels of resources unconsumed, which occurred\\n at lower species richness. residents of the c4 grass functional guild, the\\n dominant guild in nearby native grasslands, reduced the major limiting\\n resource, soil nitrate, to the lowest levels in midsummer and exhibited the\\n greatest inhibitory effect on introduced species. this simple mechanism of\\n greater competitive inhibition of invaders that are similar to established\\n abundant species could, in theory, explain many of the patterns observed in\\n plant communities.",
            "contribution_ids": [
                "R52099"
            ]
        },
        {
            "instance_id": "R52143xR52077",
            "comparison_id": "R52143",
            "paper_id": "R52077",
            "text": "Plant functional group identity and diversity determine biotic resistance to invasion by an exotic grass biotic resistance, the ability of species in a community to limit invasion, is central to our understanding of how communities at risk of invasion assemble after disturbances, but it has yet to translate into guiding principles for the restoration of invasion\u2010resistant plant communities. we combined experimental, functional, and modelling approaches to investigate processes of community assembly contributing to biotic resistance to an introduced lineage of phragmites australis, a model invasive species in north america. we hypothesized that (i) functional group identity would be a good predictor of biotic resistance to p. australis, while species identity effect would be redundant within functional group (ii) mixtures of species would be more invasion resistant than monocultures. we classified 36 resident wetland plants into four functional groups based on eight functional traits. we conducted two competition experiments based on the additive competition design with p. australis and monocultures or mixtures of wetland plants. as an indicator of biotic resistance, we calculated a relative competition index (rciavg) based on the average performance of p. australis in competition treatment compared with control. to explain diversity effect further, we partitioned it into selection effect and complementarity effect and tested several diversity\u2013interaction models. in monoculture treatments, rciavg of wetland plants was significantly different among functional groups, but not within each functional group. we found the highest rciavg for fast\u2010growing annuals, suggesting priority effect. rciavg of wetland plants was significantly greater in mixture than in monoculture mainly due to complementarity\u2013diversity effect among functional groups. in diversity\u2013interaction models, species interaction patterns in mixtures were described best by interactions between functional groups when fitted to rciavg or biomass, implying niche partitioning. synthesis. functional group identity and diversity of resident plant communities are good indicators of biotic resistance to invasion by introduced phragmites australis, suggesting niche pre\u2010emption (priority effect) and niche partitioning (diversity effect) as underlying mechanisms. guiding principles to understand and/or manage biological invasion could emerge from advances in community theory and the use of a functional framework. targeting widely distributed invasive plants in different contexts and scaling up to field situations will facilitate generalization.",
            "contribution_ids": [
                "R52078",
                "R57143"
            ]
        },
        {
            "instance_id": "R52143xR52088",
            "comparison_id": "R52143",
            "paper_id": "R52088",
            "text": "Evidence of deterministic assembly according to flowering time in an old-field plant community summary 1. theory has produced contrasting predictions related to flowering time overlap among coexisting plant species largely because of the diversity of potential influences on flowering time. in this study, we use a trait-based null modelling approach to test for evidence of deterministic assembly of species according to flowering time in an old-field plant community. 2. plant species coexisting in one-metre-square plots overlapped in flowering time significantly more than expected. this flowering synchrony was more pronounced when analyses focused on bee-pollinated species. flowering synchrony was also observed for wind-pollinated species, although for only one of our two null model tests, highlighting the sensitivity of some results to different randomization methods. in general, these patterns suggest that relationships between pollinators and plants can influence community assembly processes. 3. because our study community is composed of approximately 43% native plant species and 57% exotic species, and because the arrival of new species may complicate plant\u2013pollinator interactions, we tested whether flowering time overlap was altered by introduced species. flowering synchrony was greater in plots with a higher proportion of introduced species. this pattern held for both null model tests, but was slightly stronger when analyses focused on beepollinated species. these results indicate that introduced species alter community flowering distributions and in so doing will inevitably affect pollinator\u2013plant interactions. 4. finally, we tested whether our results were influenced by variation among study plots in above-ground biomass production, which some theory predicts will be related to the importance of competition. our results were not influenced by this variation, suggesting that resource variation among our plots did not contribute to observed patterns. 5. synthesis: our results provide support for predictions that coexisting species should display flowering synchrony, and provide no support for species coexistence via temporal niche partitioning at this scale in this study community. our results also indicate that introduced species significantly alter the community assembly process such that flowering synchrony is more pronounced in plots with a greater proportion of introduced plant species.",
            "contribution_ids": [
                "R52089"
            ]
        },
        {
            "instance_id": "R52143xR52104",
            "comparison_id": "R52143",
            "paper_id": "R52104",
            "text": "Assembly rules operating along a primary riverbed-grassland successional sequence \"1 assembly rules are broadly defined as any filter imposed on a regional species pool that acts to determine the local community structure and composition. environmental filtering is thought to result in the formation of groups of species with similar traits that tend to co\u2010occur more often than expected by chance alone, known as beta guilds. at a smaller scale, within a single beta guild, species may be partitioned into alpha guilds \u2013 groups of species that have similar resource use and hence should tend not to co\u2010occur at small scales due the principle of limiting similarity. 2 this research investigates the effects of successional age and the presence of an invasive exotic species on alpha and beta guild structuring within plant communities along two successional river terrace sequences in the waimakariri braided river system in new zealand. 3 fifteen sites were sampled, six with and nine without the russel lupin (lupinus polyphyllus), an invasive exotic species. at each site, species presence/absence was recorded in 100 circular quadrats (5 cm in diameter) at 30\u2010cm intervals along a 30\u2010m transect. guild proportionality (alpha guild structuring) was tested for using two a priori guild classifications each containing three guilds, and cluster analysis was used to test for environmental structuring between sites. 4 significant assembly rules based on alpha guild structuring were found, particularly for the monocot and dicot guild. guild proportionality increased with increasing ecological age, which indicated an increase in the relative importance of competitive structuring at later stages of succession. this provides empirical support for weiher and keddy's theoretical model of community assembly. 5 lupins were associated with altered alpha and beta guild structuring at early mid successional sites. lupin\u2010containing sites had higher silt content than sites without lupins, and this could have altered the strength and scale of competitive structuring within the communities present. 6 this research adds to the increasing evidence for the existence of assembly rules based on limiting similarity within plant communities, and demonstrates the need to incorporate gradients of environmental and competitive adversity when investigating the rules that govern community assembly.\"",
            "contribution_ids": [
                "R52105"
            ]
        },
        {
            "instance_id": "R52143xR52129",
            "comparison_id": "R52143",
            "paper_id": "R52129",
            "text": "A test of the effects of functional group richness and composition on grassland invasibility \"although many theoretical and observational studies suggest that diverse systems are more resistant to invasion by novel species than are less diverse systems, experimental data are uncommon. in this experiment, i manipulated the functional group richness and composition of a grassland community to test two related hypotheses: (1) diversity and invasion resistance are positively related through diversity's effects on the resources necessary for invading plants' growth. (2) plant communities resist invasion by species in functional groups already present in the community. to test these hypotheses, i removed plant functional groups (forbs, c3 graminoids, and c4 graminoids) from existing grassland vegetation to create communities that contained all possible combinations of one, two, or three functional groups. after three years of growth, i added seeds of 16 different native prairie species (legumes, nonleguminous forbs, c3 graminoids, and c4 graminoids) to a1 3 1 m portion of each 4 3 8 m plot. overall invasion success was negatively related to resident functional group richness, but there was only weak evidence that resident species repelled functionally similar invaders. a weak effect of functional group richness on some resources did not explain the significant diversity-invasibility relationship. other factors, particularly the different responses of resident functional groups to the initial disturbance of the experimental manipulation, seem to have been more important to community in- vasibility.\"",
            "contribution_ids": [
                "R52130"
            ]
        },
        {
            "instance_id": "R52143xR52124",
            "comparison_id": "R52143",
            "paper_id": "R52124",
            "text": "Resistance of Native Plant Functional Groups to Invasion by Medusahead (Taeniatherum caput-medusae) abstract understanding the relative importance of various functional groups in minimizing invasion by medusahead is central to increasing the resistance of native plant communities. the objective of this study was to determine the relative importance of key functional groups within an intact wyoming big sagebrush\u2013bluebunch wheatgrass community type on minimizing medusahead invasion. treatments consisted of removal of seven functional groups at each of two sites, one with shrubs and one without shrubs. removal treatments included (1) everything, (2) shrubs, (3) perennial grasses, (4) taprooted forbs, (5) rhizomatous forbs, (6) annual forbs, and (7) mosses. a control where nothing was removed was also established. plots were arranged in a randomized complete block with 4 replications (blocks) at each site. functional groups were removed beginning in the spring of 2004 and maintained monthly throughout each growing season through 2009. medusahead was seeded at a rate of 2,000 seeds m \u22122 (186 seeds ft \u22122 ) in fall 2005. removing perennial grasses nearly doubled medusahead density and biomass compared with any other removal treatment. the second highest density and biomass of medusahead occurred from removing rhizomatous forbs (phlox). we found perennial grasses played a relatively more significant role than other species in minimizing invasion by medusahead. we suggest that the most effective basis for establishing medusahead-resistant plant communities is to establish 2 or 3 highly productive grasses that are complementary in niche and that overlap that of the invading species.",
            "contribution_ids": [
                "R52125"
            ]
        },
        {
            "instance_id": "R52143xR52138",
            "comparison_id": "R52143",
            "paper_id": "R52138",
            "text": "The role of diversity and functional traits of species in community invasibility \"the invasion of exotic species into assemblages of native plants is a pervasive and widespread phenomenon. many theoretical and observational studies suggest that diverse communities are more resistant to invasion by exotic species than less diverse ones. however, experimental results do not always support such a relationship. therefore, the hypothesis of diversity-community invasibility is still a focus of controversy in the field of invasion ecology. in this study, we established and manipulated communities with different species diversity and different species functional groups (16 species belong to c3, c4, forbs and legumes, respectively) to test elton's hypothesis and other relevant hypotheses by studying the process of invasion. alligator weed (alternanthera philoxeroides) was chosen as the invader. we found that the correlation between the decrement of extractable soil nitrogen and biomass of alligator weed was not significant, and that species diversity, independent of functional groups diversity, did not show a significant correlation with invasibility. however, the communities with higher functional groups diversity significantly reduced the biomass of alligator weed by decreasing its resource opportunity. functional traits of species also influenced the success of the invasion. alternanthera sessilis, in the same morphological and functional group as alligator weed, was significantly resistant to alligator weed invasion. because community invasibility is influenced by many factors and interactions among them, the pattern and mechanisms of community invasibility are likely to be far subtler than we found in this study. more careful manipulated experiments coupled with theoretical modeling studies are essential steps to a more profound understanding of community invasibility.\"",
            "contribution_ids": [
                "R52139",
                "R57396"
            ]
        },
        {
            "instance_id": "R52143xR52135",
            "comparison_id": "R52143",
            "paper_id": "R52135",
            "text": "Testing Fox's assembly rule: does plant invasion depend on recipient community structure? \"fox's assembly rule, that relative dearth of certain functional groups in a community will facilitate invasion of that particular functional group, serves as the basis for investigation into the functional group effects of invasion resistance. we explored resistance to plant invaders by eliminating or decreasing the number of understory plant species in particular functional groups from plots at a riparian site in southwestern virginia, usa. our functional groups comprise combinations of aboveground biomass and rooting structure type. manipulated plots were planted with 10 randomly chosen species from widespread native and introduced plants commonly found throughout the floodplains of big stony creek. we assessed success of an invasion by plant survivorship and growth. we analyzed survivorship of functional groups with loglinear models for the analysis of categorical data in a 4-way table. there was a significant interaction between functional groups removed in a plot and survivorship in the functional groups added to that plot. however, survivorship of species in functional groups introduced into plots with their respective functional group removed did not differ from survivorship when any other functional group was removed. additionally, growth of each of the most abundant species did not differ significantly among plots with different functional groups manipulated. specifically, species did not fare better in those plots that had representatives of their own functional group removed. fox's assembly rule does not hold for these functional groups in this plant community; however, composition of the recipient community is a significant factor in community assembly.\"",
            "contribution_ids": [
                "R52136",
                "R52137"
            ]
        },
        {
            "instance_id": "R52143xR52071",
            "comparison_id": "R52143",
            "paper_id": "R52071",
            "text": "Identifying Native Vegetation for Reducing Exotic Species during the Restoration of Desert Ecosystems \"there is currently much interest in restoration ecology in identifying native vegetation that can decrease the invasibility by exotic species of environments undergoing restoration. however, uncertainty remains about restoration's ability to limit exotic species, particularly in deserts where facilitative interactions between plants are prevalent. using candidate native species for restoration in the mojave desert of the southwestern u.s.a., we experimentally assembled a range of plant communities from early successional forbs to late\u2010successional shrubs and assessed which vegetation types reduced the establishment of the priority invasive annuals bromus rubens (red brome) and schismus spp. (mediterranean grass) in control and n\u2010enriched soils. compared to early successional grass and shrub and late\u2010successional shrub communities, an early forb community best resisted invasion, reducing exotic species biomass by 88% (n added) and 97% (no n added) relative to controls (no native plants). in native species monocultures, sphaeralcea ambigua (desert globemallow), an early successional forb, was the least invasible, reducing exotic biomass by 91%. however, the least\u2010invaded vegetation types did not reduce soil n or p relative to other vegetation types nor was native plant cover linked to invasibility, suggesting that other traits influenced native\u2010exotic species interactions. this study provides experimental field evidence that native vegetation types exist that may reduce exotic grass establishment in the mojave desert, and that these candidates for restoration are not necessarily late\u2010successional communities. more generally, results indicate the importance of careful native species selection when exotic species invasions must be constrained for restoration to be successful.\"",
            "contribution_ids": [
                "R52072"
            ]
        },
        {
            "instance_id": "R52143xR52075",
            "comparison_id": "R52143",
            "paper_id": "R52075",
            "text": "Overlapping resource use in three Great Basin species: implications for community invasibility and vegetation dynamics 1 in the great basin of the western united states of america, the invasive annual grass bromus tectorum has extensively replaced native shrub and bunchgrass communities, but the native bunchgrass elymus elymoides has been reported to suppress bromus. curlew valley, a site in northern utah, provides a model community to test the effects of particular species on invasion by examining competitive relationships among elymus, bromus and the native shrub artemisia tridentata. 2 the site contains bromus/elymus, elymus/artemisia and monodominant elymus stands. transect data indicate that elymus suppresses bromus disproportionately relative to its above\u2010ground cover. artemisia seedlings recruit in elymus stands but rarely in the presence of bromus. this relationship might be explained by competition between the two grasses involving a different resource or occurring in a different season to that between each grass and artemisia. 3 time reflectometry data collected in monodominant patches indicated that in spring, soil moisture use by bromus is rapid, whereas depletion under elymus and artemisia is more moderate. artemisia seedlings may therefore encounter a similar moisture environment in monodominant or mixed perennial stands. however, efficient autumn soil moisture use by elymus may help suppress bromus. 4 in competition plots, target artemisia grown with bromus were stunted relative to those grown with elymus, despite equivalent above\u2010ground biomass of the two grasses. competition for nitrogen in spring and autumn, assessed with 15n tracer, appears to be secondary to moisture availability in determining competitive outcomes. 5 elymus physiology and function appear to play an important role in determining the composition of communities in curlew valley, by maintaining zones free of bromus where artemisia can recruit.",
            "contribution_ids": [
                "R52076"
            ]
        },
        {
            "instance_id": "R52143xR52120",
            "comparison_id": "R52143",
            "paper_id": "R52120",
            "text": "Plant functional group diversity as a mechanism for invasion resistance a commonly cited mechanism for invasion resistance is more complete resource use by diverse plant assemblages with maximum niche complementarity. we investigated the invasion resistance of several plant functional groups against the nonindigenous forb spotted knapweed (centaurea maculosa). the study consisted of a factorial combination of seven functional group removals (groups singularly or in combination) and two c. maculosa treatments (addition vs. no addition) applied in a randomized complete block design replicated four times at each of two sites. we quantified aboveground plant material nutrient concentration and uptake (concentration \u00d7 biomass) by indigenous functional groups: grasses, shallow\u2010rooted forbs, deep\u2010rooted forbs, spikemoss, and the nonindigenous invader c. maculosa. in 2001, c. maculosa density depended upon which functional groups were removed. the highest c. maculosa densities occurred where all vegetation or all forbs were removed. centaurea maculosa densities were the lowest in plots where nothing, shallow\u2010rooted forbs, deep\u2010rooted forbs, grasses, or spikemoss were removed. functional group biomass was also collected and analyzed for nitrogen, phosphorus, potassium, and sulphur. based on covariate analyses, postremoval indigenous plot biomass did not relate to invasion by c. maculosa. analysis of variance indicated that c. maculosa tissue nutrient percentage and net nutrient uptake were most similar to indigenous forb functional groups. our study suggests that establishing and maintaining a diversity of plant functional groups within the plant community enhances resistance to invasion. indigenous plants of functionally similar groups as an invader may be particularly important in invasion resistance.",
            "contribution_ids": [
                "R52121",
                "R57323"
            ]
        },
        {
            "instance_id": "R52143xR52118",
            "comparison_id": "R52143",
            "paper_id": "R52118",
            "text": "OVERLAP OF FOOD AND MICROHABITAT PREFERENCES AMONG SOME NATIVE AND NONNATIVE SLUGS IN MID-ATLANTIC FORESTS OF EASTERN NORTH AMERICA introduced competitors do not share an evolutionary history that would promote coexistence mechanisms, i.e. niche partitioning. thus, nonnative species can harm a trophically similar native species by competing with them more intensely than other native species. however, nonnative species may only be able initially to invade habitats in which resource overlap with native species is small. the nonnative slug arion subfuscus exists in close sympatry with the native philomycid slugs philomycus carolinianus and megapallifera mutabilis in central maryland forests. resource use by most terrestrial gastropods is poorly known, but seems to suggest high dietary and macrohabitat overlap, potentially placing native gastropod species at high risk of competitive pressure from invading species. however, a. subfuscus was introduced to north america 150 years ago, supporting the possibility that a. subfuscus initially entered an empty niche. we tested the hypothesis that p. carolinianus and m. mutabilis would exhibit greater overlap in food and microhabitat use with a. subfuscus than they would with each other. we established food preferences by examining the faecal material of wild-caught slugs, distinguishing food types and quantifying them by volume on a microgrid. we determined microhabitat preferences by surveying the substrates of slugs in the field. the overlap in substrate and food resources was greater between a. subfuscus and p. carolinianus than between the two native species. however, substrate choice was correlated with local substrate availability for p. carolinianus, suggesting flexibility in habitat use, and the slight overlap in food use between a. subfuscus and p. carolinianus may be low enough to minimize competition.",
            "contribution_ids": [
                "R52119"
            ]
        },
        {
            "instance_id": "R52143xR52126",
            "comparison_id": "R52143",
            "paper_id": "R52126",
            "text": "Physiological and morphological traits of exotic- invasive exotic- and native plant species in tallgrass prairie we compared 13 traits of invasive exotic, noninvasive exotic, and ecologically similar native species to determine if there are generalizable differences among these groups that relate to persistence and spread of exotic species in tallgrass prairie plant communities. when species were grouped as invasive (two species), noninvasive (five species), and native (six species), no differences were found for the suite of traits examined, likely because of the high variability within and between groups. however, when exotic species, regardless of invasiveness, were compared with the native species, specific leaf area was ca. 40% higher for the exotic species, a result that is consistent with that of other studies. this pattern was also observed for five of seven pairwise comparisons of exotic and native species with similar life history traits. in contrast, total end\u2010of\u2010season biomass was as much as three times higher for the native species in five of seven of the native\u2010exotic species pairs. for other traits, differences between exotic and native species were species\u2010specific and were generally more numerous for noninvasive than for invasive exotic species pair\u2010wise comparisons. thus, contrary to predictions, exotic species capable of successfully invading tallgrass prairie did not differ considerably from native species in most traits related to resource utilization and carbon gain. moreover, invasive exotic species, those capable of displacing native species and dominating a community, were not distinct for the observed traits from their native counterparts. these results indicate that other traits, such as the ability to respond to resource pulses or herbivory, may explain more effectively why certain invasive species are able to invade these communities aggressively.",
            "contribution_ids": [
                "R52127",
                "R52128"
            ]
        },
        {
            "instance_id": "R53407xR53405",
            "comparison_id": "R53407",
            "paper_id": "R53405",
            "text": "Plant invasions in Taiwan: Insights from the flora of casual and naturalized alien species data on floristic status, biological attributes, chronology and distribution of naturalized species have been shown to be a very powerful tool for discerning the patterns of plant invasions and species invasiveness. we analysed the newly compiled list of casual and naturalized plant species in taiwan (probably the only complete data set of this kind in east asia) and found that taiwan is relatively lightly invaded with only 8% of the flora being casual or naturalized. moreover, the index of casual and naturalized species per log area is also moderate, in striking contrast with many other island floras where contributions of naturalized species are much higher. casual and naturalized species have accumulated steadily and almost linearly over the past decades. fabaceae, asteraceae, and poaceae are the families with the most species. however, amaranthaceae, convolvulaceae, and onagraceae have the largest ratios of casual and naturalized species to their global numbers. ipomoea, solanum and crotalaria have the highest numbers of casual and naturalized species. about 60% of all genera with exotic species are new to taiwan. perennial herbs represent one third of the casual and naturalized flora, followed by annual herbs. about 60% of exotic species were probably introduced unintentionally onto the island; many species imported intentionally have ornamental, medicinal, or forage values. the field status of 50% of these species is unknown, but ornamentals represent noticeable proportions of naturalized species, while forage species represent a relatively larger proportion of casual species. species introduced for medicinal purposes seem to be less invasive. most of the casual and naturalized species of taiwan originated from the tropical americas, followed by asia and europe.",
            "contribution_ids": [
                "R53406"
            ]
        },
        {
            "instance_id": "R53407xR53295",
            "comparison_id": "R53407",
            "paper_id": "R53295",
            "text": "Establishment of introduced reptiles increases with the presence and richness of native congeners darwin proposed two contradictory hypotheses to explain the influence of congeners on the outcomes of invasion: the naturalization hypothesis, which predicts a negative relationship between the presence of congeners and invasion success, and the pre-adaptation hypothesis, which predicts a positive relationship between the presence of congeners and invasion success. studies testing these hypotheses have shown mixed support. we tested these hypotheses using the establishment success of non-native reptiles and congener presence/absence and richness across the globe. our results demonstrated support for the pre-adaptation hypothesis. we found that globally, both on islands and continents, establishment success was higher in the presence than in the absence of congeners and that establishment success increased with increasing congener richness. at the life form level, establishment success was higher for lizards, marginally higher for snakes, and not different for turtles in the presence of congeners; data were insufficient to test the hypotheses for crocodiles. there was no relationship between establishment success and congener richness for any life form. we suggest that we found support for the pre-adaptation hypothesis because, at the scale of our analysis, native congeners represent environmental conditions appropriate for the species rather than competition for niche space. our results imply that areas to target for early detection of non-native reptiles are those that host closely related species.",
            "contribution_ids": [
                "R53296"
            ]
        },
        {
            "instance_id": "R53407xR53276",
            "comparison_id": "R53407",
            "paper_id": "R53276",
            "text": "Learning from failures: testing broad taxonomic hypotheses about plant naturalization \"our understanding of broad taxonomic patterns of plant naturalizations is based entirely on observations of successful naturalizations. omission of the failures, however, can introduce bias by conflating the probabilities of introduction and naturalization. here, we use two comprehensive datasets of successful and failed plant naturalizations in new zealand and australia for a unique, flora-wide comparative test of several major invasion hypotheses. first, we show that some taxa are consistently more successful at naturalizing in these two countries, despite their environmental differences. broad climatic origins helped to explain some of the differences in success rates in the two countries. we further show that species with native relatives were generally more successful in both countries, contrary to darwin's naturalization hypothesis, but this effect was inconsistent among families across the two countries. finally, we show that contrary to studies based on successful naturalizations only, islands need not be inherently more invisible than continents.\"",
            "contribution_ids": [
                "R53277",
                "R56089"
            ]
        },
        {
            "instance_id": "R53407xR53355",
            "comparison_id": "R53407",
            "paper_id": "R53355",
            "text": "Validity of Darwin's naturalization hypothesis relates to the stages of invasion naturalization is the introduction and establishment of a nonnative species with sustainable populations in a novel environment. the success of nonnative species may be influenced by their relatedness to the native flora. darwin proposed that if a nonnative plant species is introduced into an environment without native congeners, the nonnative species will have a greater chance of becoming naturalized. to test darwin\u2019s naturalization hypothesis, we compiled a kentucky plant database consisting of 821 vascular plant species and subsequently selected species traits and distribution information to determine the effect of congeneric species and traits on the probability of successful naturalization and invasion. the predictors used include reproductive traits, growth form, abundance, habitat type, native congeners, and biogeographical origin. we fit three sets of generalized linear mixed models (glmms) with a binomial family and a logit link. backward selection based on minimizing the akaike information criterion (aic) was used in the analyses. our results from these three sets of models clearly indicate that the validity of darwin\u2019s hypothesis is invasion stage dependent. more specific, the naturalized and invasive models (predicting the probability of being naturalized and invasive respectively) did not support darwin\u2019s naturalization hypothesis. the number of native congeners had no effect on the likelihood that a particular species would naturalize and become invasive. our results suggest that darwin\u2019s naturalization hypothesis is more relevant during the early stage of establishment as demonstrated by the native model (predicting the probability of being native) and it becomes irrelevant during the late stages of invasion as indicated by the naturalized and invasive models. thus, it can be generalized that biotic interactions, especially competition, is a critical determinant of initial success for nonnative species in the recipient communities. once established, the fate of non-native species during the late stages of invasion may be more related to other factors such as biogeographic origin and habitat conditions. furthermore, we found reproductive traits such as flowering phenology and flower type are associated with invasion success. we also recognized contrasting traits between native and nonnative species, indicating niche differentiation between these two groups of species. niche overlapping was found as well among species regardless of the status of being native or otherwise. our study provides a novel approach to advance the understanding of phylogenetic relatedness between nonnative species and native flora by integrating traits and niche concepts at the regional scale.",
            "contribution_ids": [
                "R53356",
                "R53358"
            ]
        },
        {
            "instance_id": "R53407xR53350",
            "comparison_id": "R53407",
            "paper_id": "R53350",
            "text": "Phylogenetic isolation increases plant success despite increasing susceptibility to generalist herbivores aim\\u2002 theory suggests that introduced species that are phylogenetically distant from their recipient communities should be more successful than closely related introduced species because they can exploit open niches and escape enemies in their new range, i.e. darwin\u2019s naturalization hypothesis. alternatively, it has also been hypothesized that closely related invaders might be more successful than novel invaders because they are pre\u2010adapted to conditions in their new range; a paradox coined darwin\u2019s naturalization conundrum. to date, these hypotheses have been tested primarily at the regional scale, not within local plant communities where introduced species colonize, compete and encounter herbivores.",
            "contribution_ids": [
                "R53351",
                "R53353"
            ]
        },
        {
            "instance_id": "R53407xR53255",
            "comparison_id": "R53407",
            "paper_id": "R53255",
            "text": "Predictors of regional establishment success and spread of introduced non-indigenous vertebrates aim to provide the first analysis of predictors of both establishment and spread, both within and across taxa, for all vertebrate taxa within a region. we used florida, usa, as our study system because it has a well-documented history of introduction and invasion, and is a hotspot for biological invasions. location florida, usa. methods we analysed non-indigenous species (nis) data from peninsular florida \u2013 which included both successful and unsuccessful introductions from all vertebrate classes \u2013 to determine the best predictors of both establishment and spread for fish (65 species), herpetofauna (63 species), birds (71 species) and mammals (25 species). we used 10 variables proposed to be associated with the establishment and spread of nis: body mass, geographic origin, reproductive rate, diet generalism, native-range size, latitude of native range, number of nis present at date of introduction, presence of nis congeners, morphological proximity to other nis (in terms of body mass) and propagule pressure. a multimodel selection process was used with an information-theoretic approach to determine the best fit models for predicting establishment and spread of nis. we selected a priori plausible predictive models for establishment and spread. results large native-range size and small body mass best predicted establishment of non-indigenous herpetofauna. the presence of nis congeners had the largest positive effect on the establishment of non-indigenous fish. for mammals, the number of nis present at the time of introduction best explained establishment. no single model best explained bird establishment. for all taxa but birds, the number of nis present at time of introduction was included in at least one of the best-supported models for explaining spread.",
            "contribution_ids": [
                "R53256"
            ]
        },
        {
            "instance_id": "R53407xR53387",
            "comparison_id": "R53407",
            "paper_id": "R53387",
            "text": "Fish species introductions provide novel insights into the patterns and drivers of phylogenetic structure in freshwaters \" despite long-standing interest of terrestrial ecologists, freshwater ecosystems are a fertile, yet unappreciated, testing ground for applying community phylogenetics to uncover mechanisms of species assembly. we quantify phylogenetic clustering and overdispersion of native and non-native fishes of a large river basin in the american southwest to test for the mechanisms (environmental filtering versus competitive exclusion) and spatial scales influencing community structure. contrary to expectations, non-native species were phylogenetically clustered and related to natural environmental conditions, whereas native species were not phylogenetically structured, likely reflecting human-related changes to the basin. the species that are most invasive (in terms of ecological impacts) tended to be the most phylogenetically divergent from natives across watersheds, but not within watersheds, supporting the hypothesis that darwin's naturalization conundrum is driven by the spatial scale. phylogenetic distinctiveness may facilitate non-native establishment at regional scales, but environmental filtering restricts local membership to closely related species with physiological tolerances for current environments. by contrast, native species may have been phylogenetically clustered in historical times, but species loss from contemporary populations by anthropogenic activities has likely shaped the phylogenetic signal. our study implies that fundamental mechanisms of community assembly have changed, with fundamental consequences for the biogeography of both native and non-native species. \"",
            "contribution_ids": [
                "R53388"
            ]
        },
        {
            "instance_id": "R53407xR53360",
            "comparison_id": "R53407",
            "paper_id": "R53360",
            "text": "Introduction pathway and climate trump ecology and life history as predictors of establishment success in alien frogs and toads a major goal for ecology and evolution is to understand how abiotic and biotic factors shape patterns of biological diversity. here, we show that variation in establishment success of nonnative frogs and toads is primarily explained by variation in introduction pathways and climatic similarity between the native range and introduction locality, with minor contributions from phylogeny, species ecology, and life history. this finding contrasts with recent evidence that particular species characteristics promote evolutionary range expansion and reduce the probability of extinction in native populations of amphibians, emphasizing how different mechanisms may shape species distributions on different temporal and spatial scales. we suggest that contemporary changes in the distribution of amphibians will be primarily determined by human-mediated extinctions and movement of species within climatic envelopes, and less by species-typical traits.",
            "contribution_ids": [
                "R53361"
            ]
        },
        {
            "instance_id": "R53407xR53319",
            "comparison_id": "R53407",
            "paper_id": "R53319",
            "text": "Colonization plasticity of the boring bivalve Lithophaga aristata (Dillwyn- 1817) on the Southeastern Brazilian coast: considerations on its invasiveness potential lithophaga aristata is a boring bivalve native to the caribbean sea, first recorded in 2005 as an introduced species on the southeastern brazilian coast. the geographic distribution and density of l. aristata and of its native congeneric l. bisulcata were assessed in four areas of brazil (24 sites), additionally considering their relationship with types of substrate, depth and wave exposure. this study records the first occurrence of l. aristata in the sepetiba bay and also reports the species at five new localities in the arraial do cabo bay. lithophaga aristata is established in the four surveyed regions. at intertidal habitats, the exotic species only colonizes the infralittoral fringe but its density was not related to wave action. at subtidal habitats, the species colonizes natural and artificial substrates, from shallow (0.5m) to deep (5.0-7.0m) zones but no relationship between density and these evaluated factors was detected. broad geographical and ecological distributions and higher densities of this introduced species in relation to its native congeneric are suggested as contrary to darwin\u2019s naturalization hypothesis and instead indicate a high invasiveness potential.",
            "contribution_ids": [
                "R53320"
            ]
        },
        {
            "instance_id": "R53407xR53400",
            "comparison_id": "R53407",
            "paper_id": "R53400",
            "text": "The Roles of Climate- Phylogenetic Relatedness- Introduction Effort- and Reproductive Traits in the Establishment of Non-Native Reptiles and Amphibians abstract:\\u2002 we developed a method to predict the potential of non\u2010native reptiles and amphibians (herpetofauna) to establish populations. this method may inform efforts to prevent the introduction of invasive non\u2010native species. we used boosted regression trees to determine whether nine variables influence establishment success of introduced herpetofauna in california and florida. we used an independent data set to assess model performance. propagule pressure was the variable most strongly associated with establishment success. species with short juvenile periods and species with phylogenetically more distant relatives in regional biotas were more likely to establish than species that start breeding later and those that have close relatives. average climate match (the similarity of climate between native and non\u2010native range) and life form were also important. frogs and lizards were the taxonomic groups most likely to establish, whereas a much lower proportion of snakes and turtles established. we used results from our best model to compile a spreadsheet\u2010based model for easy use and interpretation. probability scores obtained from the spreadsheet model were strongly correlated with establishment success as were probabilities predicted for independent data by the boosted regression tree model. however, the error rate for predictions made with independent data was much higher than with cross validation using training data. this difference in predictive power does not preclude use of the model to assess the probability of establishment of herpetofauna because (1) the independent data had no information for two variables (meaning the full predictive capacity of the model could not be realized) and (2) the model structure is consistent with the recent literature on the primary determinants of establishment success for herpetofauna. it may still be difficult to predict the establishment probability of poorly studied taxa, but it is clear that non\u2010native species (especially lizards and frogs) that mature early and come from environments similar to that of the introduction region have the highest probability of establishment.",
            "contribution_ids": [
                "R53401",
                "R53403"
            ]
        },
        {
            "instance_id": "R53407xR53345",
            "comparison_id": "R53407",
            "paper_id": "R53345",
            "text": "A test of Darwin's naturalization hypothesis in the thistle tribe shows that close relatives make bad neighbors significance \\n invasive species negatively impact both natural ecosystems and human society and are notoriously difficult to control once established. thus, identifying potentially invasive taxa and preventing their dislocation is the most efficient management method. darwin\u2019s naturalization hypothesis, which predicts that the less closely related to native flora species are, the more likely they are to succeed as invaders, is tested here with an unprecedentedly thorough molecular phylogenetic approach, examining &gt;100,000 phylogenies of the weed-rich thistle tribe cardueae. branch lengths between taxa were used as measures of evolutionary relatedness. results show that invasive thistles are more closely related to natives than noninvasive introduced thistles, suggesting they share preadaptive traits with the natives that make them more likely to succeed as invaders.",
            "contribution_ids": [
                "R53346",
                "R53348"
            ]
        },
        {
            "instance_id": "R53407xR53372",
            "comparison_id": "R53407",
            "paper_id": "R53372",
            "text": "Invasiveness of alien plants in Brussels is related to their phylogenetic similarity to native species aim\\u2002 understanding the processes that drive invasion success of alien species has received considerable attention in current ecological research. from an evolutionary point of view, many studies have shown that the phylogenetic similarity between the invader species and the members of the native community may be an important aspect of invasiveness. in this study, using a coarse\u2010scale systematic sampling grid of 1\\u2003km2, we explore whether the occupancy frequency of two groups of alien species, archaeophytes and neophytes, in the urban angiosperm flora of brussels is influenced by their phylogenetic relatedness to native species.",
            "contribution_ids": [
                "R53373",
                "R53375"
            ]
        },
        {
            "instance_id": "R53407xR53377",
            "comparison_id": "R53407",
            "paper_id": "R53377",
            "text": "Testing Darwin's naturalization hypothesis in the Azores \"invasive species are a threat for ecosystems worldwide, especially oceanic islands. predicting the invasive potential of introduced species remains difficult, and only a few studies have found traits correlated to invasiveness. we produced a molecular phylogenetic dataset and an ecological trait database for the entire azorean flora and find that the phylogenetic nearest neighbour distance (pnnd), a measure of evolutionary relatedness, is significantly correlated with invasiveness. we show that introduced plant species are more likely to become invasive in the absence of closely related species in the native flora of the azores, verifying darwin's 'naturalization hypothesis'. in addition, we find that some ecological traits (especially life form and seed size) also have predictive power on invasive success in the azores. therefore, we suggest a combination of pnnd with ecological trait values as a universal predictor of invasiveness that takes into account characteristics of both introduced species and receiving ecosystem.\"",
            "contribution_ids": [
                "R53378",
                "R53380"
            ]
        },
        {
            "instance_id": "R53407xR53328",
            "comparison_id": "R53407",
            "paper_id": "R53328",
            "text": "Congener diversity- topographic heterogeneity and human-assisted dispersal predict spread rates of alien herpetofauna at a global scale \"understanding the factors that determine rates of range expansion is not only crucial for developing risk assessment schemes and management strategies for invasive species, but also provides important insight into the ability of species to disperse in response to climate change. however, there is little knowledge on why some invasions spread faster than others at large spatiotemporal scales. here, we examine the effects of human activities, species traits and characteristics of the invaded range on spread rates using a global sample of alien reptile and amphibian introductions. we show that spread rates vary remarkably among invaded locations within a species, and differ across biogeographical realms. spread rates are positively related to the richness of native congeneric species and human-assisted dispersal in the invaded range but are negatively correlated with topographic heterogeneity. our findings highlight the importance of environmental characteristics and human-assisted dispersal in developing robust frameworks for predicting species' range shifts.\"",
            "contribution_ids": [
                "R53329"
            ]
        },
        {
            "instance_id": "R53407xR53266",
            "comparison_id": "R53407",
            "paper_id": "R53266",
            "text": "Darwin's naturalization hypothesis: scale matters in coastal plant communities \"darwin proposed two seemingly contradictory hypotheses for a better understanding of biological invasions. strong relatedness of invaders to native communities as an indication of niche overlap could promote naturalization because of appropriate niche adaptation, but could also hamper naturalization because of negative interactions with native species ('darwin's naturalization hypothesis'). although these hypotheses provide clear and opposing predictions for expected patterns of species relatedness in invaded communities, so far no study has been able to clearly disentangle the underlying mechanisms. we hypothesize that conflicting past results are mainly due to the neglected role of spatial resolution of the community sampling. in this study, we corroborate both of darwin's expectations by using phylogenetic relatedness as a measure of niche overlap and by testing the effects of sampling resolution in highly invaded coastal plant communities. at spatial resolutions fine enough to detect signatures of biotic interactions, we find that most invaders are less related to their nearest relative in invaded plant communities than expected by chance (phylogenetic overdispersion). yet at coarser spatial resolutions, native assemblages become more invasible for closely-related species as a consequence of habitat filtering (phylogenetic clustering). recognition of the importance of the spatial resolution at which communities are studied allows apparently contrasting theoretical and empirical results to be reconciled. our study opens new perspectives on how to better detect, differentiate and understand the impact of negative biotic interactions and habitat filtering on the ability of invaders to establish in native communities.\"",
            "contribution_ids": [
                "R53267",
                "R53269"
            ]
        },
        {
            "instance_id": "R53407xR53271",
            "comparison_id": "R53407",
            "paper_id": "R53271",
            "text": "Darwin's naturalization hypothesis revisited in the origin of species, darwin (1859) drew attention to observations by alphonse de candolle (1855) that floras gain by naturalization far more species belonging to new genera than species belonging to native genera. darwin (1859, p. 86) goes on to give a specific example: \u201cin the last edition of dr. asa gray\u2019s \u2018manual of the flora of the united states\u2019 ... out of the 162 naturalised genera, no less than 100 genera are not there indigenous.\u201d darwin used these data to support his theory of intense competition between congeners, described only a few pages earlier: \u201cas the species of the same genus usually have, though by no means invariably, much similarity in habits and constitution, and always in structure, the struggle will generally be more severe between them\u201d (1859, p. 60). darwin\u2019s intriguing observations have recently attracted renewed interest, as comprehensive lists of naturalized plants have become available for various regions of the world. two studies (mack 1996; rejmanek 1996, 1998) have concluded that naturalized floras provide some support for darwin\u2019s hypothesis, but only one of these studies used statistical tests. analyses of additional floras are needed to test the generality of darwin\u2019s naturalization hypothesis. mack (1996) tabulated data from six regional floras within the united states and noted that naturalized species more often belong to alien genera than native genera, with the curious exception of one region (new york). in addition to the possibility of strong competition between native and introduced congeners, mack (1996) proposed that specialist native herbivores, or pathogens, may be",
            "contribution_ids": [
                "R53272",
                "R53274"
            ]
        },
        {
            "instance_id": "R53407xR53311",
            "comparison_id": "R53407",
            "paper_id": "R53311",
            "text": "Biotic interactions experienced by a new invader: effects of its close relatives at the community scale the success of nonindigenous species may be influenced by biotic interactions during the initial stages of invasion. here, we investigated whether a potential invader, solidago virgaurea l., would experience more damage by natural enemies in communities dominated by close relatives than those without them; interactions with mutualistic mycorrhizae might partially counteract these effects. we monitored damage experienced by s.\\xa0virgaurea planted into communities with native congeners and without close relatives. community type was crossed with a vegetation removal treatment to assess the combined effects of herbivory and competition on survival. we also evaluated growth of s.\\xa0virgaurea in a greenhouse experiment where seedlings were exposed to soil biota sampled from these communities and compared with sterile controls. overall, community type did not affect levels of herbivory or plant survival. removal of surrounding vegetation resulted in reduced damage and increased survival; these effects were largest in grass-dominated communities. soil sterilization reduced root growth and tended to reduce shoot growth, especially when compared with plants inoculated with biota collected near congeners. overall, our results suggest that the presence of close relatives is unlikely to make old-field communities more resistant to invasion by s.\\xa0virgaurea; instead, soil biota might facilitate growth in communities dominated by close relatives.",
            "contribution_ids": [
                "R53312"
            ]
        },
        {
            "instance_id": "R53407xR53314",
            "comparison_id": "R53407",
            "paper_id": "R53314",
            "text": "An experimental test of Darwin's naturalization hypothesis one of the oldest ideas in invasion biology, known as darwin\u2019s naturalization hypothesis, suggests that introduced species are more successful in communities in which their close relatives are absent. we conducted the first experimental test of this hypothesis in laboratory bacterial communities varying in phylogenetic relatedness between resident and invading species with and without a protist bacterivore. as predicted, invasion success increased with phylogenetic distance between the invading and the resident bacterial species in both the presence and the absence of protistan bacterivory. the frequency of successful invader establishment was best explained by average phylogenetic distance between the invader and all resident species, possibly indicating limitation by the availability of the unexploited niche (i.e., organic substances in the medium capable of supporting the invader growth); invader abundance was best explained by phylogenetic distance between the invader and its nearest resident relative, possibly indicating limitation by the availability of the unexploited optimal niche (i.e., the subset of organic substances supporting the best invader growth). these results were largely driven by one resident bacterium (a subspecies of serratia marcescens) posting the strongest resistance to the alien bacterium (another subspecies of s. marcescens). overall, our findings support phylogenetic relatedness as a useful predictor of species invasion success.",
            "contribution_ids": [
                "R53315",
                "R53317"
            ]
        },
        {
            "instance_id": "R54244xR54060",
            "comparison_id": "R54244",
            "paper_id": "R54060",
            "text": "Seedling defoliation, plant growth and flowering potential in native- and invasive-range Plantago lanceolata populations hanley me (2012). seedling defoliation, plant growth and flowering potential in native- and invasive-range plantago lanceolata populations. weed research52, 252\u2013259. \\n \\n \\n \\nsummary \\n \\nthe plastic response of weeds to new environmental conditions, in particular the likely relaxation of herbivore pressure, is considered vital for successful colonisation and spread. however, while variation in plant anti-herbivore resistance between native- and introduced-range populations is well studied, few authors have considered herbivore tolerance, especially at the seedling stage. this study examines variation in seedling tolerance in native (european) and introduced (north american) plantago lanceolata populations following cotyledon removal at 14\\xa0days old. subsequent effects on plant growth were quantified at 35\\xa0days, along with effects on flowering potential at maturity. cotyledon removal reduced early growth for all populations, with no variation between introduced- or native-range plants. although more variable, the effects of cotyledon loss on flowering potential were also unrelated to range. the likelihood that generalist seedling herbivores are common throughout north america may explain why no difference in seedling tolerance was apparent. however, increased flowering potential in plants from north american p.\\xa0lanceolata populations was observed. as increased flowering potential was not lost, even after severe cotyledon damage, the manifestation of phenotypic plasticity in weeds at maturity may nonetheless still be shaped by plasticity in the ability to tolerate herbivory during seedling establishment.",
            "contribution_ids": [
                "R54061"
            ]
        },
        {
            "instance_id": "R54244xR54014",
            "comparison_id": "R54244",
            "paper_id": "R54014",
            "text": "Native jewelweed, but not other native species, displays post-invasion trait divergence invasive exotic plants reduce the diversity of native communities by displacing native species. according to the coexistence theory, native plants are able to coexist with invaders only when their fitness is not significantly smaller than that of the exotics or when they occupy a different niche. it has therefore been hypothesized that the survival of some native species at invaded sites is due to post-invasion evolutionary changes in fitness and/or niche traits. \\n \\n \\n \\nin common garden experiments, we tested whether plants from invaded sites of two native species, impatiens noli-tangere and galeopsis speciosa, outperform conspecifics from non-invaded sites when grown in competition with the invader (impatiens parviflora). we further examined whether the expected superior performance of the plants from the invaded sites is due to changes in the plant size (fitness proxy) and/or changes in the germination phenology and phenotypic plasticity (niche proxies). \\n \\n \\n \\ninvasion history did not influence the performance of any native species when grown with the exotic competitor. in i. noli-tangere, however, we found significant trait divergence with regard to plant size, germination phenology and phenotypic plasticity. in the absence of a competitor, plants of i. noli-tangere from invaded sites were larger than plants from non-invaded sites. the former plants germinated earlier than inexperienced conspecifics or an exotic congener. invasion experience was also associated with increased phenotypic plasticity and an improved shade-avoidance syndrome. although these changes indicate fitness and niche differentiation of i. noli-tangere at invaded sites, future research should examine more closely the adaptive value of these changes and their genetic basis.",
            "contribution_ids": [
                "R54015"
            ]
        },
        {
            "instance_id": "R54244xR54190",
            "comparison_id": "R54244",
            "paper_id": "R54190",
            "text": "Phenotypic variability in Holcus lanatus L. in southern Chile: a strategy that enhances plant survival and pasture stability \\n\\nholcus lanatus l. can colonise a wide range of sites within the naturalised grassland of the humid dominion of chile. the objectives were to determine plant growth mechanisms and strategies that have allowed h. lanatus to colonise contrasting pastures and to determine the existence of ecotypes of h. lanatus in southern chile. plants of h. lanatus were collected from four geographic zones of southern chile and established in a randomised complete block design with four replicates. five newly emerging tillers were marked per plant and evaluated at the vegetative, pre-ear emergence, complete emerged inflorescence, end of flowering period, and mature seed stages. at each evaluation, one marked tiller was harvested per plant. the variables measured included lamina length and width, tiller height, length of the inflorescence, total number of leaves, and leaf, stem, and inflorescence mass. at each phenological stage, groups of accessions were statistically formed using cluster analysis. the grouping of accessions (cluster analysis) into statistically different groups (anova and canonical variate analysis) indicated the existence of different ecotypes. the phenotypic variation within each group of the accessions suggested that each group has its own phenotypic plasticity. it is concluded that the successful colonisation by h. lanatus has resulted from diversity within the species.\\n",
            "contribution_ids": [
                "R54191"
            ]
        },
        {
            "instance_id": "R54244xR54148",
            "comparison_id": "R54244",
            "paper_id": "R54148",
            "text": "Developmental plasticity of shell morphology of quagga mussels from shallow and deep-water habitats of the Great Lakes  summary \\n the invasive zebra mussel (dreissena polymorpha) has quickly colonized shallow-water habitats in the north american great lakes since the 1980s but the quagga mussel (dreissena bugensis) is becoming dominant in both shallow and deep-water habitats. while quagga mussel shell morphology differs between shallow and deep habitats, functional causes and consequences of such difference are unknown. we examined whether quagga mussel shell morphology could be induced by three environmental variables through developmental plasticity. we predicted that shallow-water conditions (high temperature, food quantity, water motion) would yield a morphotype typical of wild quagga mussels from shallow habitats, while deep-water conditions (low temperature, food quantity, water motion) would yield a morphotype present in deep habitats. we tested this prediction by examining shell morphology and growth rate of quagga mussels collected from shallow and deep habitats and reared under common-garden treatments that manipulated the three variables. shell morphology was quantified using the polar moment of inertia. of the variables tested, temperature had the greatest effect on shell morphology. higher temperature (\u223c18\u201320\u00b0c) yielded a morphotype typical of wild shallow mussels regardless of the levels of food quantity or water motion. in contrast, lower temperature (\u223c6\u20138\u00b0c) yielded a morphotype approaching that of wild deep mussels. if shell morphology has functional consequences in particular habitats, a plastic response might confer quagga mussels with a greater ability than zebra mussels to colonize a wider range of habitats within the great lakes.",
            "contribution_ids": [
                "R54149"
            ]
        },
        {
            "instance_id": "R54244xR54090",
            "comparison_id": "R54244",
            "paper_id": "R54090",
            "text": "Multiple common garden experiments suggest lack of local adaptation in an invasive ornamental plant aims adaptive evolution along geographic gradients of climatic conditions is suggested to facilitate the spread of invasive plant species, leading to clinal variation among populations in the introduced range. we investigated whether adaptation to climate is also involved in the invasive spread of an ornamental shrub, buddleja davidii, across western and central europe. methods we combined a common garden experiment, replicated in three climatically different central european regions, with reciprocal transplantation to quantify genetic differentiation in growth and reproductive traits of 20 invasive b. davidii populations. additionally, we compared compensatory regrowth among populations after clipping of stems to simulate mechanical damage.",
            "contribution_ids": [
                "R54091"
            ]
        },
        {
            "instance_id": "R54244xR54056",
            "comparison_id": "R54244",
            "paper_id": "R54056",
            "text": "Seasonal Photoperiods Alter Developmental Time and Mass of an Invasive Mosquito, Aedes albopictus (Diptera: Culicidae), Across Its North-South Range in the United States abstract the asian tiger mosquito, aedes albopictus (skuse), is perhaps the most successful invasive mosquito species in contemporary history. in the united states, ae. albopictus has spread from its introduction point in southern texas to as far north as new jersey (i.e., a span of \u224814\u00b0 latitude). this species experiences seasonal constraints in activity because of cold temperatures in winter in the northern united states, but is active year-round in the south. we performed a laboratory experiment to examine how life-history traits of ae. albopictus from four populations (new jersey [39.4\u00b0 n], virginia [38.6\u00b0 n], north carolina [35.8\u00b0 n], florida [27.6\u00b0 n]) responded to photoperiod conditions that mimic approaching winter in the north (short static daylength, short diminishing daylength) or relatively benign summer conditions in the south (long daylength), at low and high larval densities. individuals from northern locations were predicted to exhibit reduced development times and to emerge smaller as adults under short daylength, but be larger and take longer to develop under long daylength. life-history traits of southern populations were predicted to show less plasticity in response to daylength because of low probability of seasonal mortality in those areas. males and females responded strongly to photoperiod regardless of geographic location, being generally larger but taking longer to develop under the long daylength compared with short day lengths; adults of both sexes were smaller when reared at low larval densities. adults also differed in mass and development time among locations, although this effect was independent of density and photoperiod in females but interacted with density in males. differences between male and female mass and development times was greater in the long photoperiod suggesting differences between the sexes in their reaction to different photoperiods. this work suggests that ae. albopictus exhibits sex-specific phenotypic plasticity in life-history traits matching variation in important environmental variables.",
            "contribution_ids": [
                "R54057"
            ]
        },
        {
            "instance_id": "R54244xR54106",
            "comparison_id": "R54244",
            "paper_id": "R54106",
            "text": "High temperature tolerance and thermal plasticity in emerald ash borer Agrilus planipennis 1 the emerald ash borer agrilus planipennis (coleoptera: buprestidae) (eab), an invasive wood\u2010boring beetle, has recently caused significant losses of native ash (fraxinus spp.) trees in north america. movement of wood products has facilitated eab spread, and heat sanitation of wooden materials according to international standards for phytosanitary measures no. 15 (ispm 15) is used to prevent this. 2 in the present study, we assessed the thermal conditions experienced during a typical heat\u2010treatment at a facility using protocols for pallet wood treatment under policy pi\u201007, as implemented in canada. the basal high temperature tolerance of eab larvae and pupae was determined, and the observed heating rates were used to investigate whether the heat shock response and expression of heat shock proteins occurred in fourth\u2010instar larvae. 3 the temperature regime during heat treatment greatly exceeded the ispm 15 requirements of 56 \u00b0c for 30 min. emerald ash borer larvae were highly tolerant of elevated temperatures, with some instars surviving exposure to 53 \u00b0c without any heat pre\u2010treatments. high temperature survival was increased by either slow warming or pre\u2010exposure to elevated temperatures and a recovery regime that was accompanied by up\u2010regulated hsp70 expression under some of these conditions. 4 because eab is highly heat tolerant and exhibits a fully functional heat shock response, we conclude that greater survival than measured in vitro is possible under industry treatment conditions (with the larvae still embedded in the wood). we propose that the phenotypic plasticity of eab may lead to high temperature tolerance very close to conditions experienced in an ispm 15 standard treatment.",
            "contribution_ids": [
                "R54107"
            ]
        },
        {
            "instance_id": "R54244xR54032",
            "comparison_id": "R54244",
            "paper_id": "R54032",
            "text": "Morphological variation between non-native lake- and stream-dwelling pumpkinseed Lepomis gibbosusin the Iberian Peninsula the objective of this study was to test if morphological differences in pumpkinseed lepomis gibbosus found in their native range (eastern north america) that are linked to feeding regime, competition with other species, hydrodynamic forces and habitat were also found among stream- and lake- or reservoir-dwelling fish in iberian systems. the species has been introduced into these systems, expanding its range, and is presumably well adapted to freshwater iberian peninsula ecosystems. the results show a consistent pattern for size of lateral fins, with l. gibbosus that inhabit streams in the iberian peninsula having longer lateral fins than those inhabiting reservoirs or lakes. differences in fin placement, body depth and caudal peduncle dimensions do not differentiate populations of l. gibbosus from lentic and lotic water bodies and, therefore, are not consistent with functional expectations. lepomis gibbosus from lotic and lentic habitats also do not show a consistent pattern of internal morphological differentiation, probably due to the lack of lotic-lentic differences in prey type. overall, the univariate and multivariate analyses show that most of the external and internal morphological characters that vary among populations do not differentiate lotic from lentic iberian populations. the lack of expected differences may be a consequence of the high seasonal flow variation in mediterranean streams, and the resultant low- or no-flow conditions during periods of summer drought.",
            "contribution_ids": [
                "R54033"
            ]
        },
        {
            "instance_id": "R54244xR54192",
            "comparison_id": "R54244",
            "paper_id": "R54192",
            "text": "Differences in plasticity between invasive and native plants from a low resource environment 1 phenotypic plasticity is often cited as an important mechanism of plant invasion. however, few studies have evaluated the plasticity of a diverse set of traits among invasive and native species, particularly in low resource habitats, and none have examined the functional significance of these traits. 2 i explored trait plasticity in response to variation in light and nutrient availability in five phylogenetically related pairs of native and invasive species occurring in a nutrient\u2010poor habitat. in addition to the magnitude of trait plasticity, i assessed the correlation between 16 leaf\u2010 and plant\u2010level traits and plant performance, as measured by total plant biomass. because plasticity for morphological and physiological traits is thought to be limited in low resource environments (where native species usually display traits associated with resource conservation), i predicted that native and invasive species would display similar, low levels of trait plasticity. 3 across treatments, invasive and native species within pairs differed with respect to many of the traits measured; however, invasive species as a group did not show consistent patterns in the direction of trait values. relative to native species, invasive species displayed high plasticity in traits pertaining to biomass partitioning and leaf\u2010level nitrogen and light use, but only in response to nutrient availability. invasive and native species showed similar levels of resource\u2010use efficiency and there was no relationship between species plasticity and resource\u2010use efficiency across species. 4 traits associated with carbon fixation were strongly correlated with performance in invasive species while only a single resource conservation trait was strongly correlated with performance in multiple native species. several highly plastic traits were not strongly correlated with performance which underscores the difficulty in assessing the functional significance of resource conservation traits over short timescales and calls into question the relevance of simple, quantitative assessments of trait plasticity. 5 synthesis. my data support the idea that invasive species display high trait plasticity. the degree of plasticity observed here for species occurring in low resource systems corresponds with values observed in high resource systems, which contradicts the general paradigm that trait plasticity is constrained in low resource systems. several traits were positively correlated with plant performance suggesting that trait plasticity will influence plant fitness.",
            "contribution_ids": [
                "R54193"
            ]
        },
        {
            "instance_id": "R54244xR54040",
            "comparison_id": "R54244",
            "paper_id": "R54040",
            "text": "Architectural strategies of Rhamnus cathartica (Rhamnaceae) in relation to canopy openness while phenotypic plasticity is considered the major means that allows plant to cope with environmental heterogeneity, scant information is available on phenotypic plasticity of the whole-plant architecture in relation to ontogenic processes. we performed an architectural analysis to gain an understanding of the structural and ontogenic properties of common buckthorn ( rhamnus cathartica l., rhamnaceae) growing in the understory and under an open canopy. we found that ontogenic effects on growth need to be calibrated if a full description of phenotypic plasticity is to be obtained. our analysis pointed to three levels of organization (or nested structural units) in r.\\xa0cathartica. their modulation in relation to light conditions leads to the expression of two architectural strategies that involve sets of traits known to confer competitive advantage in their respective environments. in the understory, the plant develops a tree-like form. its strategy here is based on restricting investment in exploitation structures while promoting major vertical exploration and is probably key to species survival in the understory. under an open canopy, the second strategy leads the plant to adopt a shrub-like shape. it develops densely branched exploitation structures and flowers abundantly and rapidly. this strategy perfectly matches its aggressive behaviour observed in full sunlight. we propose, as hypotheses, that these two light-related strategies are implicated in the ability of r.\\xa0cathartica to outcompete the surrounding vegetation in a range of environmental conditions.",
            "contribution_ids": [
                "R54041"
            ]
        },
        {
            "instance_id": "R54244xR54062",
            "comparison_id": "R54244",
            "paper_id": "R54062",
            "text": "Shell morphology and relative growth variability of the invasive pearl oyster Pinctada radiata in coastal Tunisia \" the variability of shell morphology and relative growth of the invasive pearl oyster pinctada radiata was studied within and among ten populations from coastal tunisia using discriminant tests. therefore, 12 morphological characters were examined and 34 metric and weight ratios were defined. in addition to the classic morphological characters, populations were compared by the thickness of the nacreous layer. results of duncan's multiple comparison test showed that the most discriminative ratios were the width of nacreous layer of right valve to the inflation of shell, the hinge line length to the maximum width of shell and the nacre thickness to the maximum width of shell. the analysis of variance revealed an important inter-population morphological variability. both multidimensional scaling analysis and the squared mahalanobis distances ( d 2 ) of metric ratios divided tunisian p. radiata populations into four biogeographical groupings: the north coast (la marsa); harbours (hammamet, monastir and zarzis); the gulf of gab\u00e8s (sfax, kerkennah island, mahar\u00e8s, skhira and djerba) and the intertidal area (ajim). however, the kerkennah island population was discriminated by the squared mahalanobis distances ( d 2 ) of weight ratios in an isolated group suggesting particular trophic conditions in this area. the allometric study revealed high linear correlation between shell morphological characters and differences in allometric growth among p. radiata populations. unlike the morphological discrimination, allometric differentiation shows no clear geographical distinction. this study revealed that the pearl oyster p. radiata exhibited considerable phenotypic plasticity related to differences of environmental and/or ecological conditions along tunisian coasts and highlighted the discriminative character of the nacreous layer thickness parameter. \"",
            "contribution_ids": [
                "R54063"
            ]
        },
        {
            "instance_id": "R54244xR54174",
            "comparison_id": "R54244",
            "paper_id": "R54174",
            "text": "Growth, water relations, and stomatal development of Caragana korshinskii Kom. and Zygophyllum xanthoxylum (Bunge) Maxim. seedlings in response to water deficits abstract the selection and introduction of drought tolerant species is a common method of restoring degraded grasslands in arid environments. this study investigated the effects of water stress on growth, water relations, na+ and k+ accumulation, and stomatal development in the native plant species zygophyllum xanthoxylum (bunge) maxim., and an introduced species, caragana korshinskii kom., under three watering regimes. moderate drought significantly reduced pre\u2010dawn water potential, leaf relative water content, total biomass, total leaf area, above\u2010ground biomass, total number of leaves and specific leaf area, but it increased the root/total weight ratio (0.23 versus 0.33) in c. korshinskii. only severe drought significantly affected water status and growth in z. xanthoxylum. in any given watering regime, a significantly higher total biomass was observed in z. xanthoxylum (1.14 g) compared to c. korshinskii (0.19 g). moderate drought significantly increased na+ accumulation in all parts of z. xanthoxylum, e.g., moderate drought increased leaf na+ concentration from 1.14 to 2.03 g/100 g dw, however, there was no change in na+ (0.11 versus 0.12) in the leaf of c. korshinskii when subjected to moderate drought. stomatal density increased as water availability was reduced in both c. korshinskii and z. xanthoxylum, but there was no difference in stomatal index of either species. stomatal length and width, and pore width were significantly reduced by moderate water stress in z. xanthoxylum, but severe drought was required to produce a significant effect in c. korshinskii. these results indicated that c. korshinskii is more responsive to water stress and exhibits strong phenotypic plasticity especially in above\u2010ground/below\u2010ground biomass allocation. in contrast, z. xanthoxylum was more tolerant to water deficit, with a lower specific leaf area and a strong ability to maintain water status through osmotic adjustment and stomatal closure, thereby providing an effective strategy to cope with local extreme arid environments.",
            "contribution_ids": [
                "R54175"
            ]
        },
        {
            "instance_id": "R54244xR54162",
            "comparison_id": "R54244",
            "paper_id": "R54162",
            "text": "Trade-off between morphological convergence and opportunistic diet behavior in fish hybrid zone  abstract \\n \\n background \\n the invasive chondrostoma nasus nasus has colonized part of the distribution area of the protected endemic species chondrostoma toxostoma toxostoma . this hybrid zone is a complex system where multiple effects such as inter-species competition, bi-directional introgression, strong environmental pressure and so on are combined. why do sympatric chondrostoma fish present a unidirectional change in body shape? is this the result of inter-species interactions and/or a response to environmental effects or the result of trade-offs? studies focusing on the understanding of a trade-off between multiple parameters are still rare. although this has previously been done for cichlid species flock and for darwin finches, where mouth or beak morphology were coupled to diet and genetic identification, no similar studies have been done for a fish hybrid zone in a river. we tested the correlation between morphology (body and mouth morphology), diet (stable carbon and nitrogen isotopes) and genomic combinations in different allopatric and sympatric populations for a global data set of 1330 specimens. to separate the species interaction effect from the environmental effect in sympatry, we distinguished two data sets: the first one was obtained from a highly regulated part of the river and the second was obtained from specimens coming from the less regulated part. \\n \\n \\n results \\n the distribution of the hybrid combinations was different in the two part of the sympatric zone, whereas all the specimens presented similar overall changes in body shape and in mouth morphology. sympatric specimens were also characterized by a larger diet behavior variance than reference populations, characteristic of an opportunistic diet. no correlation was established between the body shape (or mouth deformation) and the stable isotope signature. \\n \\n \\n conclusion \\n the durance river is an untamed mediterranean river despite the presence of numerous dams that split the river from upstream to downstream. the sympatric effect on morphology and the large diet behavior range can be explained by a tendency toward an opportunistic behavior of the sympatric specimens. indeed, the similar response of the two species and their hybrids implied an adaptation that could be defined as an alternative trade-off that underline the importance of epigenetics mechanisms for potential success in a novel environment. \\n",
            "contribution_ids": [
                "R54163"
            ]
        },
        {
            "instance_id": "R54244xR54030",
            "comparison_id": "R54244",
            "paper_id": "R54030",
            "text": "Seedling traits, plasticity and local differentiation as strategies of invasive species of Impatiens in central Europe \"background and aims invasiveness of some alien plants is associated with their traits, plastic responses to environmental conditions and interpopulation differentiation. to obtain insights into the role of these processes in contributing to variation in performance, we compared congeneric species of impatiens (balsaminaceae) with different origin and invasion status that occur in central europe. methods native i. noli-tangere and three alien species (highly invasive i. glandulifera, less invasive i. parviflora and potentially invasive i. capensis) were studied and their responses to simulated canopy shading and different nutrient and moisture levels were determined in terms of survival and seedling traits. key results and conclusions impatiens glandulifera produced high biomass in all the treatments and the control, exhibiting the \u2018jack-and-master\u2019 strategy that makes it a strong competitor from germination onwards. the results suggest that plasticity and differentiation occurred in all the species tested and that along the continuum from plasticity to differentiation, the species at the plasticity end is the better invader. the most invasive species i. glandulifera appears to be highly plastic, whereas the other two less invasive species, i. parviflora and i. capensis, exhibited lower plasticity but rather strong population differentiation. the invasive impatiens species were taller and exhibited higher plasticity and differentiation than native i. noli-tangere. this suggests that even within one genus, the relative importance of the phenomena contributing to invasiveness appears to be species'specific.\"",
            "contribution_ids": [
                "R54031"
            ]
        },
        {
            "instance_id": "R54244xR54114",
            "comparison_id": "R54244",
            "paper_id": "R54114",
            "text": "Preadapted for invasiveness: do species traits or their plastic response to shading differ between invasive and non-invasive plant species in their native range? aim\\u2002 species capable of vigorous growth under a wide range of environmental conditions should have a higher chance of becoming invasive after introduction into new regions. high performance across environments can be achieved either by constitutively expressed traits that allow for high resource uptake under different environmental conditions or by adaptive plasticity of traits. here we test whether invasive and non\u2010invasive species differ in presumably adaptive plasticity.",
            "contribution_ids": [
                "R54115"
            ]
        },
        {
            "instance_id": "R54244xR54232",
            "comparison_id": "R54244",
            "paper_id": "R54232",
            "text": "Leaf ontogenetic dependence of light acclimation in invasive and native subtropical trees of different successional status in the bonin islands of the western pacific where the light environment is characterized by high fluctuations due to frequent typhoon disturbance, we hypothesized that the invasive success of bischofia javanica blume (invasive tree, mid-successional) may be attributable to a high acclimation capacity under fluctuating light availability. the physiological and morphological responses of b. javanica to both simulated canopy opening and closure were compared against three native species of different successional status: trema orientalis blume (pioneer), schima mertensiana (sieb. et zucc.) koidz (mid-successional) and elaeocarpus photiniaefolius hook.et arn (late-successional). the results revealed significant species-specific differences in the timing of physiological maturity and phenotypic plasticity in leaves developed under constant high and low light levels. for example, the photosynthetic capacity of t. orientalis reached a maximum in leaves that had just fully expanded when grown under constant high light (50% of full sun) whereas that of e. photiniaefolius leaves continued to increase until 50\\xa0d after full expansion. for leaves that had just reached full expansion, t. orientalis, having high photosynthetic plasticity between high and low light, exhibited low acclimation capacity under the changing light (from high to low or low to high light). in comparison with native species, b. javanica showed a higher degree of physiological and morphological acclimation following transfer to a new light condition in leaves of all age classes (i.e. before and after reaching full expansion). the high acclimation ability of b. javanica in response to changes in light availability may be a part of its pre-adaptations for invasiveness in the fluctuating environment of the bonin islands.",
            "contribution_ids": [
                "R54233"
            ]
        },
        {
            "instance_id": "R54244xR54110",
            "comparison_id": "R54244",
            "paper_id": "R54110",
            "text": "Relatedness predicts phenotypic plasticity in plants better than weediness background: weedy non-native species have long been predicted to be more phenotypically plastic than native species. question: are weedy non-native species more plastic than natives? organisms: fourteen perennial plant species: acer platanoides, acer saccharum, bromus inermis, bromus latiglumis, celastrus orbiculatus, celastrus scandens, elymus repens, elymus trachycaulus, plantago major, plantago rugelii, rosa multiflora, rosa palustris, solanum dulcamara, and solanum carolinense. field site: mesic old-field in dryden, ny (422749\u2033n, 762640\u2033w). methods: we grew seven pairs of native and non-native plant congeners in the field and tested their responses to reduced competition and the addition of fertilizer. we measured the plasticity of six traits related to growth and leaf palatability (total length, leaf dry mass, maximum relative growth rate, leaf toughness, trichome density, and specific leaf area). conclusions: weedy non-native species did not differ consistently from natives in their phenotypic plasticity. instead, relatedness was a better predictor of plasticity.",
            "contribution_ids": [
                "R54111"
            ]
        },
        {
            "instance_id": "R54244xR54054",
            "comparison_id": "R54244",
            "paper_id": "R54054",
            "text": "Phenotypic Plasticity in the Invasion of Crofton Weed (Eupatorium adenophorum) in China phenotypic plasticity and rapid evolution are two important strategies by which invasive species adapt to a wide range of environments and consequently are closely associated with plant invasion. to test their importance in invasion success of crofton weed, we examined the phenotypic response and genetic variation of the weed by conducting a field investigation, common garden experiments, and intersimple sequence repeat (issr) marker analysis on 16 populations in china. molecular markers revealed low genetic variation among and within the sampled populations. there were significant differences in leaf area (la), specific leaf area (sla), and seed number (sn) among field populations, and plasticity index (pi v ) for la, sla, and sn were 0.62, 0.46 and 0.85, respectively. regression analyses revealed a significant quadratic effect of latitude of population origin on la, sla, and sn based on field data but not on traits in the common garden experiments (greenhouse and open air). plants from different populations showed similar reaction norms across the two common gardens for functional traits. la, sla, aboveground biomass, plant height at harvest, first flowering day, and life span were higher in the greenhouse than in the open-air garden, whereas sn was lower. growth conditions (greenhouse vs. open air) and the interactions between growth condition and population origin significantly affect plant traits. the combined evidence suggests high phenotypic plasticity but low genetically based variation for functional traits of crofton weed in the invaded range. therefore, we suggest that phenotypic plasticity is the primary strategy for crofton weed as an aggressive invader that can adapt to diverse environments in china.",
            "contribution_ids": [
                "R54055"
            ]
        },
        {
            "instance_id": "R54244xR54222",
            "comparison_id": "R54244",
            "paper_id": "R54222",
            "text": "Adaptation vs. phenotypic plasticity in the success of a clonal invader the relative importance of plasticity vs. adaptation for the spread of invasive species has rarely been studied. we examined this question in a clonal population of invasive freshwater snails (potamopyrgus antipodarum) from the western united states by testing whether observed plasticity in life history traits conferred higher fitness across a range of temperatures. we raised isofemale lines from three populations from different climate regimes (high- and low-elevation rivers and an estuary) in a split-brood, common-garden design in three temperatures. we measured life history and growth traits and calculated population growth rate (as a measure of fitness) using an age-structured projection matrix model. we found a strong effect of temperature on all traits, but no evidence for divergence in the average level of traits among populations. levels of genetic variation and significant reaction norm divergence for life history traits suggested some role for adaptation. plasticity varied among traits and was lowest for size and reproductive traits compared to age-related traits and fitness. plasticity in fitness was intermediate, suggesting that invasive populations are not general-purpose genotypes with respect to the range of temperatures studied. thus, by considering plasticity in fitness and its component traits, we have shown that trait plasticity alone does not yield the same fitness across a relevant set of temperature conditions.",
            "contribution_ids": [
                "R54223"
            ]
        },
        {
            "instance_id": "R54244xR54224",
            "comparison_id": "R54244",
            "paper_id": "R54224",
            "text": "Phenotypic plasticity of an invasive acacia versus two native Mediterranean species the phenotypic plasticity and the competitive ability of the invasive acacia longifolia v. the indigenous mediterranean dune species halimium halimifolium and pinus pinea were evaluated. in particular, we explored the hypothesis that phenotypic plasticity in response to biotic and abiotic factors explains the observed differences in competitiveness between invasive and native species. the seedlings\u2019 ability to exploit different resource availabilities was examined in a two factorial experimental design of light and nutrient treatments by analysing 20 physiological and morphological traits. competitiveness was tested using an additive experimental design in combination with 15n-labelling experiments. light and nutrient availability had only minor effects on most physiological traits and differences between species were not significant. plasticity in response to changes in resource availability occurred in morphological and allocation traits, revealing a. longifolia to be a species of intermediate responsiveness. the major competitive advantage of a. longifolia was its constitutively high shoot elongation rate at most resource treatments and its effective nutrient acquisition. further, a. longifolia was found to be highly tolerant against competition from native species. in contrast to common expectations, the competition experiment indicated that a. longifolia expressed a constant allocation pattern and a phenotypic plasticity similar to that of the native species.",
            "contribution_ids": [
                "R54225"
            ]
        },
        {
            "instance_id": "R54244xR54228",
            "comparison_id": "R54244",
            "paper_id": "R54228",
            "text": "Predator-induced phenotypic plasticity in the exotic cladoceran Daphnia lumholtzi summary \\n \\n1. the exotic cladoceran daphnia lumholtzi has recently invaded freshwater systems throughout the united states. daphnia lumholtzi possesses extravagant head spines that are longer than those found on any other north american daphnia. these spines are effective at reducing predation from many of the predators that are native to newly invaded habitats; however, they are plastic both in nature and in laboratory cultures. the purpose of this experiment was to better understand what environmental cues induce and maintain these effective predator-deterrent spines. we conducted life-table experiments on individual d. lumholtzi grown in water conditioned with an invertebrate insect predator, chaoborus punctipennis, and water conditioned with a vertebrate fish predator, lepomis macrochirus. \\n \\n \\n \\n2. daphnia lumholtzi exhibited morphological plasticity in response to kairomones released by both predators. however, direct exposure to predator kairomones during postembryonic development did not induce long spines in d. lumholtzi. in contrast, neonates produced from individuals exposed to lepomis kairomones had significantly longer head and tail spines than neonates produced from control and chaoborus individuals. these results suggest that there may be a maternal, or pre-embryonic, effect of kairomone exposure on spine development in d. lumholtzi. \\n \\n \\n \\n3. independent of these morphological shifts, d. lumholtzi also exhibited plasticity in life history characteristics in response to predator kairomones. for example, d. lumholtzi exhibited delayed reproduction in response to chaoborus kairomones, and significantly more individuals produced resting eggs, or ephippia, in the presence of lepomis kairomones.",
            "contribution_ids": [
                "R54229"
            ]
        },
        {
            "instance_id": "R54244xR54236",
            "comparison_id": "R54244",
            "paper_id": "R54236",
            "text": "Induced defenses in response to an invading crab predator: An explanation of historical and geographic phenotypic change \\n the expression of defensive morphologies in prey often is correlated with predator abundance or diversity over a range of temporal and spatial scales. these patterns are assumed to reflect natural selection via differential predation on genetically determined, fixed phenotypes. phenotypic variation, however, also can reflect within-generation developmental responses to environmental cues (phenotypic plasticity). for example, water-borne effluents from predators can induce the production of defensive morphologies in many prey taxa. this phenomenon, however, has been examined only on narrow scales. here, we demonstrate adaptive phenotypic plasticity in prey from geographically separated populations that were reared in the presence of an introduced predator. marine snails exposed to predatory crab effluent in the field increased shell thickness rapidly compared with controls. induced changes were comparable to (\\n i \\n ) historical transitions in thickness previously attributed to selection by the invading predator and (\\n ii \\n ) present-day clinal variation predicted from water temperature differences. thus, predator-induced phenotypic plasticity may explain broad-scale geographic and temporal phenotypic variation. if inducible defenses are heritable, then selection on the reaction norm may influence coevolution between predator and prey. trade-offs may explain why inducible rather than constitutive defenses have evolved in several gastropod species.\\n",
            "contribution_ids": [
                "R54237"
            ]
        },
        {
            "instance_id": "R54244xR54172",
            "comparison_id": "R54244",
            "paper_id": "R54172",
            "text": "Understanding the consequences of seed dispersal in a heterogeneous environment  plant distributions are in part determined by environmental heterogeneity on both large (landscape) and small (several meters) spatial scales. plant populations can respond to environmental heterogeneity via genetic differentiation between large distinct patches, and via phenotypic plasticity in response to heterogeneity occurring at small scales relative to dispersal distance. as a result, the level of environmental heterogeneity experienced across generations, as determined by seed dispersal distance, may itself be under selection. selection could act to increase or decrease seed dispersal distance, depending on patterns of heterogeneity in environmental quality with distance from a maternal home site. serpentine soils, which impose harsh and variable abiotic stress on non-adapted plants, have been partially invaded by erodium cicutarium in northern california, usa. using nearby grassland sites characterized as either serpentine or non-serpentine, we collected seeds from dense patches of e. cicutarium on both soil types in spring 2004 and subsequently dispersed those seeds to one of four distances from their maternal home site (0, 0.5, 1, or 10 m). we examined distance-dependent patterns of variation in offspring lifetime fitness, conspecific density, soil availability, soil water content, and aboveground grass and forb biomass. anova revealed a distinct fitness peak when seeds were dispersed 0.5 m from their maternal home site on serpentine patches. in non-serpentine patches, fitness was reduced only for seeds placed back into the maternal home site. conspecific density was uniformly high within 1 m of a maternal home site on both soils, whereas soil water content and grass biomass were significantly heterogeneous among dispersal distances only on serpentine soils. structural equation modeling and multigroup analysis revealed significantly stronger direct and indirect effects linking abiotic and biotic variation to offspring performance on serpentine soils than on non-serpentine soils, indicating the potential for soil-specific selection on seed dispersal distance in this invasive species.",
            "contribution_ids": [
                "R54173"
            ]
        },
        {
            "instance_id": "R54244xR54070",
            "comparison_id": "R54244",
            "paper_id": "R54070",
            "text": "Phenotypic variation of an alien species in a new environment: the body size and diet of American mink over time and at local and continental scales introduced species must adapt their ecology, behaviour, and morphological traits to new conditions. the successful introduction and invasive potential of a species are related to its levels of phenotypic plasticity and genetic polymorphism. we analysed changes in the body mass and length of american mink (neovison vison) since its introduction into the warta mouth national park, western poland, in relation to diet composition and colonization progress from 1996 to 2004. mink body mass decreased significantly during the period of population establishment within the study area, with an average decrease of 13% from 1.36 to 1.18\\xa0kg in males and of 16% from 0.83 to 0.70\\xa0kg in females. diet composition varied seasonally and between consecutive years. the main prey items were mammals and fish in the cold season and birds and fish in the warm season. during the study period the proportion of mammals preyed upon increased in the cold season and decreased in the warm season. the proportion of birds preyed upon decreased over the study period, whereas the proportion of fish increased. following introduction, the strictly aquatic portion of mink diet (fish and frogs) increased over time, whereas the proportion of large prey (large birds, muskrats, and water voles) decreased. the average yearly proportion of large prey and average-sized prey in the mink diet was significantly correlated with the mean body masses of males and females. biogeographical variation in the body mass and length of mink was best explained by the percentage of large prey in the mink diet in both sexes, and by latitude for females. together these results demonstrate that american mink rapidly changed their body mass in relation to local conditions. this phenotypic variability may be underpinned by phenotypic plasticity and/or by adaptation of quantitative genetic variation. the potential to rapidly change phenotypic variation in this manner is an important factor determining the negative ecological impacts of invasive species.\\xa0\u00a9 2012 the linnean society of london, biological journal of the linnean society, 2012, 105, 681\u2013693.",
            "contribution_ids": [
                "R54071"
            ]
        },
        {
            "instance_id": "R54244xR54128",
            "comparison_id": "R54244",
            "paper_id": "R54128",
            "text": "Functional differences in response to drought in the invasive Taraxacum officinale from native and introduced alpine habitat ranges background: phenotypic plasticity and ecotypic differentiation have been suggested as the main mechanisms by which widely distributed species can colonise broad geographic areas with variable and stressful conditions. some invasive plant species are among the most widely distributed plants worldwide. plasticity and local adaptation could be the mechanisms for colonising new areas. aims: we addressed if taraxacum officinale from native (alps) and introduced (andes) stock responded similarly to drought treatment, in terms of photosynthesis, foliar angle, and flowering time. we also evaluated if ontogeny affected fitness and physiological responses to drought. methods: we carried out two common garden experiments with both seedlings and adults (f2) of t. officinale from its native and introduced ranges in order to evaluate their plasticity and ecotypic differentiation under a drought treatment. results: our data suggest that the functional response of t. officinale individuals from the introduced range to drought is the result of local adaptation rather than plasticity. in addition, the individuals from the native distribution range were more sensitive to drought than those from the introduced distribution ranges at both seedling and adult stages. conclusions: these results suggest that local adaptation may be a possible mechanism underlying the successful invasion of t. officinale in high mountain environments of the andes.",
            "contribution_ids": [
                "R54129"
            ]
        },
        {
            "instance_id": "R54244xR54066",
            "comparison_id": "R54244",
            "paper_id": "R54066",
            "text": "Germination patterns and implications for invasiveness in three Taraxacum (Asteraceae) species luo j & cardina j (2012). germination patterns and implications for invasiveness in three taraxacum (asteraceae) species. weed research\\xa052, 112\u2013121. \\n \\n \\n \\nsummary \\n \\nthe ability to germinate across different environments has been considered an important trait of invasive plant species that allows for establishment success in new habitats. using two alien congener species of asteraceae \u2013taraxacum officinale (invasive) and taraxacum laevigatum laevigatum (non-invasive) \u2013 we tested the hypothesis that invasive species germinate better than non-invasives under various conditions. the germination patterns of taraxacum brevicorniculatum, a contaminant found in seeds of the crop taraxacum kok-saghyz, were also investigated to evaluate its invasive potential. in four experiments, we germinated seeds along gradients of alternating temperature, constant temperature (with or without light), water potential and following accelerated ageing. neither higher nor lower germination per se explained invasion success for the taraxacum species tested here. at alternating temperature, the invasive t. officinale had higher germination than or similar to the non-invasive t.\\xa0laevigatum. contrary to predictions, t.\\xa0laevigatum exhibited higher germination than t.\\xa0officinale in environments of darkness, low water potential or after the seeds were exposed to an ageing process. these results suggested a complicated role of germination in the success of t.\\xa0officinale. taraxacum brevicorniculatum showed the highest germination among the three species in all environments. the invasive potential of this species is thus unclear and will probably depend on its performance at other life stages along environmental gradients.",
            "contribution_ids": [
                "R54067"
            ]
        },
        {
            "instance_id": "R54244xR54036",
            "comparison_id": "R54244",
            "paper_id": "R54036",
            "text": "Latitudinal Patterns in Phenotypic Plasticity and Fitness-Related Traits: Assessing the Climatic Variability Hypothesis (CVH) with an Invasive Plant Species phenotypic plasticity has been suggested as the main mechanism for species persistence under a global change scenario, and also as one of the main mechanisms that alien species use to tolerate and invade broad geographic areas. however, contrasting with this central role of phenotypic plasticity, standard models aimed to predict the effect of climatic change on species distributions do not allow for the inclusion of differences in plastic responses among populations. in this context, the climatic variability hypothesis (cvh), which states that higher thermal variability at higher latitudes should determine an increase in phenotypic plasticity with latitude, could be considered a timely and promising hypothesis. accordingly, in this study we evaluated, for the first time in a plant species (taraxacum officinale), the prediction of the cvh. specifically, we measured plastic responses at different environmental temperatures (5 and 20\u00b0c), in several ecophysiological and fitness-related traits for five populations distributed along a broad latitudinal gradient. overall, phenotypic plasticity increased with latitude for all six traits analyzed, and mean trait values increased with latitude at both experimental temperatures, the change was noticeably greater at 20\u00b0 than at 5\u00b0c. our results suggest that the positive relationship found between phenotypic plasticity and geographic latitude could have very deep implications on future species persistence and invasion processes under a scenario of climate change.",
            "contribution_ids": [
                "R54037"
            ]
        },
        {
            "instance_id": "R54244xR54194",
            "comparison_id": "R54244",
            "paper_id": "R54194",
            "text": "Major morphological changes in a Lake Victoria cichlid fish within two decades during the upsurge of the introduced predatory nile perch in lake victoria in the 1980s, the zooplanktivorous haplochromis (yssichromis) pyrrhocephalus nearly vanished. the species recovered coincident with the intense fishing of nile perch in the 1990s, when water clarity and dissolved oxygen levels had decreased dramatically due to increased eutrophication. in response to the hypoxic conditions, total gill surface in resurgent h. pyrrhocephalus increased by 64%. remarkably, head length, eye length, and head volume decreased in size, whereas cheek depth increased. reductions in eye size and depth of the rostral part of the musculus sternohyoideus, and reallocation of space between the opercular and suspensorial compartments of the head may have permitted accommodation of larger gills in a smaller head. by contrast, the musculus levator posterior, located dorsal to the gills, increased in depth. this probably reflects an adaptive response to the larger and tougher prey types in the diet of resurgent h. pyrrhocephalus. these striking morphological changes over a time span of only two decades could be the combined result of phenotypic plasticity and genetic change and may have fostered recovery of this species.",
            "contribution_ids": [
                "R54195"
            ]
        },
        {
            "instance_id": "R54244xR54112",
            "comparison_id": "R54244",
            "paper_id": "R54112",
            "text": "VARIATION IN PHENOTYPIC PLASTICITY AMONG NATIVE AND INVASIVE POPULATIONS OF ALLIARIA PETIOLATA alliaria petiolata is a eurasian biennial herb that is invasive in north america and for which phenotypic plasticity has been noted as a potentially important invasive trait. using four european and four north american populations, we explored variation among populations in the response of a suite of antioxidant, antiherbivore, and morphological traits to the availability of water and nutrients and to jasmonic acid treatment. multivariate analyses revealed substantial variation among populations in mean levels of these traits and in the response of this suite of traits to environmental variation, especially water availability. univariate analyses revealed variation in plasticity among populations in the expression of all of the traits measured to at least one of these environmental factors, with the exception of leaf length. there was no evidence for continentally distinct plasticity patterns, but there was ample evidence for variation in phenotypic plasticity among the populations within continents. this implies that a. petiolata has the potential to evolve distinct phenotypic plasticity patterns within populations but that invasive populations are no more plastic than native populations.",
            "contribution_ids": [
                "R54113"
            ]
        },
        {
            "instance_id": "R54244xR54144",
            "comparison_id": "R54244",
            "paper_id": "R54144",
            "text": "Evolution of dispersal traits along an invasion route in the wind-dispersed Senecio inaequidens (Asteraceae)  in introduced organisms, dispersal propensity is expected to increase during range expansion. this prediction is based on the assumption that phenotypic plasticity is low compared to genetic diversity, and an increase in dispersal can be counteracted by the allee effect. empirical evidence in support of these hypotheses is however lacking. the present study tested for evidence of differentiation in dispersal-related traits and the allee effect in the wind-dispersed invasive senecio inaequidens (asteraceae). we collected capitula from individuals in ten field populations, along an invasion route including the original introduction site in southern france. in addition, we conducted a common garden experiment from field-collected seeds and obtained capitula from individuals representing the same ten field populations. we analysed phenotypic variation in dispersal traits between field and common garden environments as a function of the distance between populations and the introduction site. our results revealed low levels of phenotypic differentiation among populations. however, significant clinal variation in dispersal traits was demonstrated in common garden plants representing the invasion route. in field populations, similar trends in dispersal-related traits and evidence of an allee effect were not detected. in part, our results supported expectations of increased dispersal capacity with range expansion, and emphasized the contribution of phenotypic plasticity under natural conditions.",
            "contribution_ids": [
                "R54145"
            ]
        },
        {
            "instance_id": "R54244xR54132",
            "comparison_id": "R54244",
            "paper_id": "R54132",
            "text": "Elevational distribution limits of non-native species: combining observational and experimental evidence \"background: in temperate mountains, most non-native plant species reach their distributional limit somewhere along the elevational gradient. however, it is unclear if growth limitations can explain upper range limits and whether phenotypic plasticity or genetic changes allow species to occupy a broad elevational gradient. aims: we investigated how non-native plant individuals from different elevations responded to growing season temperatures, which represented conditions at the core and margin of the elevational distributions of the species. methods: we recorded the occurrence of nine non-native species in the swiss alps and subsequently conducted a climate chamber experiment to assess growth rates of plants from different elevations under different temperature treatments. results: the elevational limit observed in the field was not related to the species' temperature response in the climate chamber experiment. almost all species showed a similar level of reduction in growth rates under lower temperatures independent of the upper elevational limit of the species' distribution. for two species we found indications for genetic differentiation among plants from different elevations. conclusions: we conclude that factors other than growing season temperatures, such as extreme events or winter mortality, might shape the elevational limit of non-native species, and that ecological filtering might select for genotypes that are phenotypically plastic.\"",
            "contribution_ids": [
                "R54133"
            ]
        },
        {
            "instance_id": "R54244xR54078",
            "comparison_id": "R54244",
            "paper_id": "R54078",
            "text": "Intra-population variability of life-history traits and growth during range expansion of the invasive round goby, Neogobius melanostomus fish can undergo changes in their life-history traits that correspond with local demographic conditions. under range expansion, a population of non-native fish might then be expected to exhibit a suite of life-history traits that differ between the edge and the centre of the population\u2019s geographic range. to test this hypothesis, life-history traits of an expanding population of round goby, neogobius melanostomus (pallas), in early and newly established sites in the trent river (ontario, canada) were compared in 2007 and 2008. round goby in the area of first introduction exhibited a significant decrease in age at maturity, increased length at age 1 and they increased in gsi from 2007 to 2008. while individuals at the edges of the range exhibited traits that promote population growth under low intraspecific density, yearly variability in life-history traits suggests that additional processes such as declining density and fluctuating food availability are influencing the reproductive strategy and growth of round goby during an invasion.",
            "contribution_ids": [
                "R54079"
            ]
        },
        {
            "instance_id": "R54244xR54130",
            "comparison_id": "R54244",
            "paper_id": "R54130",
            "text": "Morphological differentiation of introduced pikeperch (Sander lucioperca L., 1758) populations in Tunisian freshwaters summary \\n \\nin order to evaluate the phenotypic plasticity of introduced pikeperch populations in tunisia, the intra- and interpopulation differentiation was analysed using a biometric approach. thus, nine meristic counts and 23 morphological measurements were taken from 574 specimens collected from three dams and a hill lake. the univariate (anova) and multivariate analyses (pca and dfa) showed a low meristic variability between the pikeperch samples and a segregated pikeperch group from the sidi salem dam which displayed a high distance between mouth and pectoral fin and a high antedorsal distance. in addition, the korba hill lake population seemed to have more important values of total length, eye diameter, maximum body height and a higher distance between mouth and operculum than the other populations. however, the most accentuated segregation was found in the lebna sample where the individuals were characterized by high snout length, body thickness, pectoral fin length, maximum body height and distance between mouth and operculum. this study shows the existence of morphological differentiations between populations derived from a single gene pool that have been isolated in separated sites for several decades although in relatively similar environments.",
            "contribution_ids": [
                "R54131"
            ]
        },
        {
            "instance_id": "R54244xR54020",
            "comparison_id": "R54244",
            "paper_id": "R54020",
            "text": "Establishment of an Invasive Plant Species (Conium maculatum) in Contaminated Roadside Soil in Cook County, Illinois \"abstract interactions between environmental variables in anthropogenically disturbed environments and physiological traits of invasive species may help explain reasons for invasive species' establishment in new areas. here we analyze how soil contamination along roadsides may influence the establishment of conium maculatum (poison hemlock) in cook county, il, usa. we combine analyses that: (1) characterize the soil and measure concentrations of heavy metals and polycyclic aromatic hydrocarbons (pahs) where conium is growing; (2) assess the genetic diversity and structure of individuals among nine known populations; and (3) test for tolerance to heavy metals and evidence for local soil growth advantage with greenhouse establishment experiments. we found elevated levels of metals and pahs in the soil where conium was growing. specifically, arsenic (as), cadmium (cd), and lead (pb) were found at elevated levels relative to u.s. epa ecological contamination thresholds. in a greenhouse study we found that conium is more tolerant of soils containing heavy metals (as, cd, pb) than two native species. for the genetic analysis a total of 217 individuals (approximately 20\u201330 per population) were scored with 5 issr primers, yielding 114 variable loci. we found high levels of genetic diversity in all populations but little genetic structure or differentiation among populations. although conium shows a general tolerance to contamination, we found few significant associations between genetic diversity metrics and a suite of measured environmental and spatial parameters. soil contamination is not driving the peculiar spatial distribution of conium in cook county, but these findings indicate that conium is likely establishing in the chicago region partially due to its ability to tolerate high levels of metal contamination.\"",
            "contribution_ids": [
                "R54021"
            ]
        },
        {
            "instance_id": "R54244xR54050",
            "comparison_id": "R54244",
            "paper_id": "R54050",
            "text": "Common and rare plant species respond differently to fertilisation and competition, whether they are alien or native plant traits associated with alien invasiveness may also distinguish rare from common native species. to test this, we grew 23 native (9 common, 14 rare) and 18 alien (8 common, 10 rare) herbaceous species in switzerland from six plant families under nutrient-addition and competition treatments. alien and common species achieved greater biomass than native and rare species did overall respectively. across alien and native origins, common species increased total biomass more strongly in response to nutrient addition than rare species did and this difference was not confounded by habitat dissimilarities. there was a weak tendency for common species to survive competition better than rare species, which was also independent of origin. overall, our study suggests that common alien and native plant species are not fundamentally different in their responses to nutrient addition and competition.",
            "contribution_ids": [
                "R54051"
            ]
        },
        {
            "instance_id": "R54244xR54142",
            "comparison_id": "R54244",
            "paper_id": "R54142",
            "text": "Microhabitat analysis of the invasive exotic liana Lonicera japonica Thunb. abstract we documented microhabitat occurrence and growth of lonicera japonica to identify factors related to its invasion into a southern illinois shale barren. the barren was surveyed for l. japonica in june 2003, and the microhabitats of established l. japonica plants were compared to random points that sampled the range of available microhabitats in the barren. vine and leaf characters were used as measurements of plant growth. lonicera japonica occurred preferentially in areas of high litter cover and species richness, comparatively small trees, low par, low soil moisture and temperature, steep slopes, and shallow soils. plant growth varied among these microhabitats. among plots where l. japonica occurred, growth was related to soil and light conditions, and aspects of surrounding cover. overhead canopy cover was a common variable associated with nearly all measured growth traits. plasticity of traits to improve invader success can only affect the likelihood of invasion once constraints to establishment and persistence have been surmounted. therefore, understanding where l. japonica invasion occurs, and microhabitat interactions with plant growth are important for estimating invasion success.",
            "contribution_ids": [
                "R54143"
            ]
        },
        {
            "instance_id": "R54244xR54092",
            "comparison_id": "R54244",
            "paper_id": "R54092",
            "text": "Invasive Microstegium populations consistently outperform native range populations across diverse environments plant species introduced into novel ranges may become invasive due to evolutionary change, phenotypic plasticity, or other biotic or abiotic mechanisms. evolution of introduced populations could be the result of founder effects, drift, hybridization, or adaptation to local conditions, which could enhance the invasiveness of introduced species. however, understanding whether the success of invading populations is due to genetic differences between native and introduced populations may be obscured by origin x environment interactions. that is, studies conducted under a limited set of environmental conditions may show inconsistent results if native or introduced populations are differentially adapted to specific conditions. we tested for genetic differences between native and introduced populations, and for origin x environment interactions, between native (china) and introduced (u.s.) populations of the invasive annual grass microstegium vimineum (stiltgrass) across 22 common gardens spanning a wide range of habitats and environmental conditions. on average, introduced populations produced 46% greater biomass and had 7.4% greater survival, and outperformed native range populations in every common garden. however, we found no evidence that introduced microstegium exhibited greater phenotypic plasticity than native populations. biomass of microstegium was positively correlated with light and resident community richness and biomass across the common gardens. however, these relationships were equivalent for native and introduced populations, suggesting that the greater mean performance of introduced populations is not due to unequal responses to specific environmental parameters. our data on performance of invasive and native populations suggest that post-introduction evolutionary changes may have enhanced the invasive potential of this species. further, the ability of microstegium to survive and grow across the wide variety of environmental conditions demonstrates that few habitats are immune to invasion.",
            "contribution_ids": [
                "R54093"
            ]
        },
        {
            "instance_id": "R54244xR54134",
            "comparison_id": "R54244",
            "paper_id": "R54134",
            "text": "Thermal variability alters climatic stress resistance and plastic responses in a globally invasive pest, the Mediterranean fruit fly (Ceratitis capitata) climatic means with different degrees of variability (\u03b4) may change in the future and could significantly impact ectotherm species fitness. thus, there is an increased interest in understanding the effects of changes in means and variances of temperature on traits of climatic stress resistance. here, we examined short\u2010term (within\u2010generation) variation in mean temperature (23, 25, and 27\\u2003\u00b0c) at three levels of diel thermal fluctuations (\u03b4\\u2003=\\u20031, 3, or 5\\u2003\u00b0c) on an invasive pest insect, the mediterranean fruit fly, ceratitis capitata (wiedemann) (diptera: tephritidae). using the adult flies, we address the hypothesis that temperature variability may affect the climatic stress resistance over and above changes in mean temperature at constant variability levels. we scored the traits of high\u2010 and low\u2010thermal tolerance, high\u2010 and low\u2010temperature acute hardening ability, water balance, and egg production under benign conditions after exposure to each of the nine experimental scenarios. most importantly, results showed that temperature variance may have significant effects in addition to the changes in mean temperature for most traits scored. although typical acclimation responses were detected for most of the traits under low variance conditions, high variance scenarios dramatically altered the outcomes, with poorer climatic stress resistance detected in some, but not all, traits. these results suggest that large temperature fluctuations might limit plastic responses which in turn could reduce the insect fitness. increased mean temperatures in conjunction with increased temperature variability may therefore have stronger negative effects on this agricultural pest than elevated temperatures alone. the results of this study therefore have significant implications for understanding insect responses to climate change and suggest that analyses or simulations of only mean temperature variation may be inappropriate for predicting population\u2010level responses under future climate change scenarios despite their widespread use.",
            "contribution_ids": [
                "R54135"
            ]
        },
        {
            "instance_id": "R54244xR54196",
            "comparison_id": "R54244",
            "paper_id": "R54196",
            "text": "Increased fitness and plasticity of an invasive species in its introduced range: a study using Senecio pterophorus 1 when a plant species is introduced into a new range, it may differentiate genetically from the original populations in the home range. this genetic differentiation may influence the extent to which the invasion of the new range is successful. we tested this hypothesis by examining senecio pterophorus, a south african shrub that was introduced into ne spain about 40 years ago. we predicted that in the introduced range invasive populations would perform better and show greater plasticity than native populations. 2 individuals of s. pterophorus from four spanish (invasive) and four south african (native) populations were grown in catalonia, spain, in a common garden in which disturbance and water availability were manipulated. fitness traits and several ecophysiological parameters were measured. 3 the invasive populations of s. pterophorus survived better throughout the summer drought in a disturbed (unvegetated) environment than native south african populations. this success may be attributable to the lower specific leaf area (sla) and better water content regulation of the invasive populations in this treatment. 4 invasive populations displayed up to three times higher relative growth rate than native populations under conditions of disturbance and non\u2010limiting water availability. 5 the reproductive performance of the invasive populations was higher in all treatments except under the most stressful conditions (i.e. in non\u2010watered undisturbed plots), where no plant from either population flowered. 6 the results for leaf parameters and chlorophyll fluorescence measurements suggested that the greater fitness of the invasive populations could be attributed to more favourable ecophysiological responses. 7 synthesis. spanish invasive populations of s. pterophorus performed better in the presence of high levels of disturbance, and displayed higher plasticity of fitness traits in response to resource availability than native south african populations. our results suggest that genetic differentiation from source populations associated with founding may play a role in invasion success.",
            "contribution_ids": [
                "R54197"
            ]
        },
        {
            "instance_id": "R54244xR54074",
            "comparison_id": "R54244",
            "paper_id": "R54074",
            "text": "Phenotypic divergence of exotic fish populations is shaped by spatial proximity and habitat differences across an invaded landscape background: brown trout (salmo trutta) were introduced into, and subsequently colonized, a number of disparate watersheds on the island of newfoundland, canada (110,638 km 2 ), starting in 1883. questions: do environmental features of recently invaded habitats shape population-level phenotypic variability? are patterns of phenotypic variability suggestive of parallel adaptive divergence? and does the extent of phenotypic divergence increase as a function of distance between populations? hypotheses: populations that display similar phenotypes will inhabit similar environments. patterns in morphology, coloration, and growth in an invasive stream-dwelling fish should be consistent with adaptation, and populations closer to each other should be more similar than should populations that are farther apart. organism and study system: sixteen brown trout populations of probable common descent, inhabiting a gradient of environments. these populations include the most ancestral (\u223c130 years old) and most recently established (\u223c20 years old). analytical methods: we used multivariate statistical techniques to quantify morphological (e.g. body shape via geometric morphometrics and linear measurements of traits), meristic (e.g. counts of pigmentation spots), and growth traits from 1677 individuals. to account for ontogenetic and allometric effects on morphology, we conducted separate analyses on three distinct size/age classes. we used the bio-env routine and mantel tests to measure the correlation between phenotypic and habitat features. results: phenotypic similarity was significantly correlated with environmental similarity, especially in the larger size classes of fish. the extent to which these associations between phenotype and habitat result from parallel evolution, adaptive phenotypic plasticity, or historical founder effects is not known. observed patterns of body shape and fin sizes were generally consistent with predictions of adaptive trait patterns, but other traits showed less consistent patterns with habitat features. phenotypic differences increased as a function of straight-line distance (km) between watersheds and to a lesser extent fish dispersal distances, which suggests habitat has played a more significant role in shaping population phenotypes compared with founder effects.",
            "contribution_ids": [
                "R54075"
            ]
        },
        {
            "instance_id": "R54244xR54046",
            "comparison_id": "R54244",
            "paper_id": "R54046",
            "text": "Phenotypic Plasticity and Population Differentiation in an Ongoing Species Invasion the ability to succeed in diverse conditions is a key factor allowing introduced species to successfully invade and spread across new areas. two non-exclusive factors have been suggested to promote this ability: adaptive phenotypic plasticity of individuals, and the evolution of locally adapted populations in the new range. we investigated these individual and population-level factors in polygonum cespitosum, an asian annual that has recently become invasive in northeastern north america. we characterized individual fitness, life-history, and functional plasticity in response to two contrasting glasshouse habitat treatments (full sun/dry soil and understory shade/moist soil) in 165 genotypes sampled from nine geographically separate populations representing the range of light and soil moisture conditions the species inhabits in this region. polygonum cespitosum genotypes from these introduced-range populations expressed broadly similar plasticity patterns. in response to full sun, dry conditions, genotypes from all populations increased photosynthetic rate, water use efficiency, and allocation to root tissues, dramatically increasing reproductive fitness compared to phenotypes expressed in simulated understory shade. although there were subtle among-population differences in mean trait values as well as in the slope of plastic responses, these population differences did not reflect local adaptation to environmental conditions measured at the population sites of origin. instead, certain populations expressed higher fitness in both glasshouse habitat treatments. we also compared the introduced-range populations to a single population from the native asian range, and found that the native population had delayed phenology, limited functional plasticity, and lower fitness in both experimental environments compared with the introduced-range populations. our results indicate that the future spread of p. cespitosum in its introduced range will likely be fueled by populations consisting of individuals able to express high fitness across diverse light and moisture conditions, rather than by the evolution of locally specialized populations.",
            "contribution_ids": [
                "R54047"
            ]
        },
        {
            "instance_id": "R54244xR54210",
            "comparison_id": "R54244",
            "paper_id": "R54210",
            "text": "Contrasting plant physiological adaptation to climate in the native and introduced range of Hypericum perforatum \"abstract how introduced plants, which may be locally adapted to specific climatic conditions in their native range, cope with the new abiotic conditions that they encounter as exotics is not well understood. in particular, it is unclear what role plasticity versus adaptive evolution plays in enabling exotics to persist under new environmental circumstances in the introduced range. we determined the extent to which native and introduced populations of st. john's wort (hypericum perforatum) are genetically differentiated with respect to leaf-level morphological and physiological traits that allow plants to tolerate different climatic conditions. in common gardens in washington and spain, and in a greenhouse, we examined clinal variation in percent leaf nitrogen and carbon, leaf \u03b413c values (as an integrative measure of water use efficiency), specific leaf area (sla), root and shoot biomass, root/shoot ratio, total leaf area, and leaf area ratio (lar). as well, we determined whether native european h. perforatum experienced directional selection on leaf-level traits in the introduced range and we compared, across gardens, levels of plasticity in these traits. in field gardens in both washington and spain, native populations formed latitudinal clines in percent leaf n. in the greenhouse, native populations formed latitudinal clines in root and shoot biomass and total leaf area, and in the washington garden only, native populations also exhibited latitudinal clines in percent leaf c and leaf \u03b413c. traits that failed to show consistent latitudinal clines instead exhibited significant phenotypic plasticity. introduced st. john's wort populations also formed significant or marginally significant latitudinal clines in percent leaf n in washington and spain, percent leaf c in washington, and in root biomass and total leaf area in the greenhouse. in the washington common garden, there was strong directional selection among european populations for higher percent leaf n and leaf \u03b413c, but no selection on any other measured trait. the presence of convergent, genetically based latitudinal clines between native and introduced h. perforatum, together with previously published molecular data, suggest that native and exotic genotypes have independently adapted to a broad-scale variation in climate that varies with latitude.\"",
            "contribution_ids": [
                "R54211"
            ]
        },
        {
            "instance_id": "R54244xR54212",
            "comparison_id": "R54244",
            "paper_id": "R54212",
            "text": "Phenotypic plasticity of native vs. invasive purple loosestrife: A two-state multivariate approach the differences in phenotypic plasticity between invasive (north american) and native (german) provenances of the invasive plant lythrum salicaria (purple loosestrife) were examined using a multivariate reaction norm approach testing two important attributes of reaction norms described by multivariate vectors of phenotypic change: the magnitude and direction of mean trait differences between environments. data were collected for six life history traits from native and invasive plants using a split-plot design with experimentally manipulated water and nutrient levels. we found significant differences between native and invasive plants in multivariate phenotypic plasticity for comparisons between low and high water treatments within low nutrient levels, between low and high nutrient levels within high water treatments, and for comparisons that included both a water and nutrient level change. the significant genotype x environment (g x e) effects support the argument that invasiveness of purple loosestrife is closely associated with the interaction of high levels of soil nutrient and flooding water regime. our results indicate that native and invasive plants take different strategies for growth and reproduction; native plants flowered earlier and allocated more to flower production, while invasive plants exhibited an extended period of vegetative growth before flowering to increase height and allocation to clonal reproduction, which may contribute to increased fitness and invasiveness in subsequent years.",
            "contribution_ids": [
                "R54213"
            ]
        },
        {
            "instance_id": "R54244xR54234",
            "comparison_id": "R54244",
            "paper_id": "R54234",
            "text": "Can life-history traits predict the fate of introduced species? A case study on two cyprinid fish in southern France 1.\\u2002the ecological and economic costs of introduced species can be high. ecologists try to predict the probability of success and potential risk of the establishment of recently introduced species, given their biological characteristics. \\n \\n2.\\u2002in 1990 gudgeon, gobio gobio, were released in a drainage canal of the rhone delta of southern france. the asian topmouth gudgeon, pseudorasbora parva, was found for the first time in the same canal in 1993. those introductions offered a unique opportunity to compare in situ the fate of two closely related fish in the same habitat. \\n \\n3.\\u2002our major aims were to assess whether g. gobio was able to establish in what seemed an unlikely environment, to compare populations trends and life-history traits of both species and to assess whether we could explain or could have predicted our results, by considering their life-history strategies. \\n \\n4.\\u2002data show that both species have established in the canal and have spread. catches of p. parva have increased strongly and are now higher than those of g. gobio. \\n \\n5.\\u2002the two cyprinids have the same breeding season and comparable traits (such as short generation time, small body, high reproductive effort), so both could be classified as opportunists. the observed difference in their success (in terms of population growth and colonization rate) could be explained by the wider ecological and physiological tolerance of p. parva. \\n \\n6.\\u2002in conclusion, our field study seems to suggest that invasive vigour also results from the ability to tolerate environmental changes through phenotypic plasticity, rather than from particular life-history features pre-adapted to invasion. it thus remains difficult to define a good invader simply on the basis of its life-history features.",
            "contribution_ids": [
                "R54235"
            ]
        },
        {
            "instance_id": "R54244xR54186",
            "comparison_id": "R54244",
            "paper_id": "R54186",
            "text": "Establishment of parallel altitudinal clines in traits of native and introduced forbs due to altered ecological and evolutionary contexts, we might expect the responses of alien plants to environmental gradients, as revealed through patterns of trait variation, to differ from those of the same species in their native range. in particular, the spread of alien plant species along such gradients might be limited by their ability to establish clinal patterns of trait variation. we investigated trends in growth and reproductive traits in natural populations of eight invasive asteraceae forbs along altitudinal gradients in their native and introduced ranges (valais, switzerland, and wallowa mountains, oregon, usa). plants showed similar responses to altitude in both ranges, being generally smaller and having fewer inflorescences but larger seeds at higher altitudes. however, these trends were modified by region-specific effects that were independent of species status (native or introduced), suggesting that any differential performance of alien species in the introduced range cannot be interpreted without a fully reciprocal approach to test the basis of these differences. furthermore, we found differences in patterns of resource allocation to capitula among species in the native and the introduced areas. these suggest that the mechanisms underlying trait variation, for example, increasing seed size with altitude, might differ between ranges. the rapid establishment of clinal patterns of trait variation in the new range indicates that the need to respond to altitudinal gradients, possibly by local adaptation, has not limited the ability of these species to invade mountain regions. studies are now needed to test the underlying mechanisms of altitudinal clines in traits of alien species.",
            "contribution_ids": [
                "R54187"
            ]
        },
        {
            "instance_id": "R54244xR54140",
            "comparison_id": "R54244",
            "paper_id": "R54140",
            "text": "Phenotypic plasticity of thermal tolerance contributes to the invasion potential of Mediterranean fruit flies (Ceratitis capitata)  1. the invasion success of ceratitis capitata probably stems from physiological, morphological, and behavioural adaptations that enable them to survive in different habitats. however, it is generally poorly understood if variation in acute thermal tolerance and its phenotypic plasticity might be important in facilitating survival of c. capitata upon introduction to novel environments.",
            "contribution_ids": [
                "R54141"
            ]
        },
        {
            "instance_id": "R54867xR54767",
            "comparison_id": "R54867",
            "paper_id": "R54767",
            "text": "Predicting Richness of Native, Rare, and Exotic Plants in Response to Habitat and Disturbance Variables across a Variegated Landscape species richness of native, rare native, and exotic understorey plants was recorded at 120 sites in temperate grassy vegetation in new south wales. linear models were used to predict the effects of environment and disturbance on the richness of each of these groups. total native species and rare native species showed similar responses, with rich- ness declining on sites of increasing natural fertility of par- ent material as well as declining under conditions of water",
            "contribution_ids": [
                "R54768",
                "R54769"
            ]
        },
        {
            "instance_id": "R54867xR54786",
            "comparison_id": "R54867",
            "paper_id": "R54786",
            "text": "Pollution reduces native diversity and increases invader dominance in marine hard-substrate communities anthropogenic disturbance is considered a risk factor in the establishment of non\u2010indigenous species (nis); however, few studies have investigated the role of anthropogenic disturbance in facilitating the establishment and spread of nis in marine environments. a baseline survey of native and nis was undertaken in conjunction with a manipulative experiment to determine the effect that heavy metal pollution had on the diversity and invasibility of marine hard\u2010substrate assemblages. the study was repeated at two sites in each of two harbours in new south wales, australia. the survey sampled a total of 47 sessile invertebrate taxa, of which 15 (32%) were identified as native, 19 (40%) as nis, and 13 (28%) as cryptogenic. increasing pollution exposure decreased native species diversity at all study sites by between 33% and 50%. in contrast, there was no significant change in the numbers of nis. percentage cover was used as a measure of spatial dominance, with increased pollution exposure leading to increased nis dominance across all sites. at three of the four study sites, assemblages that had previously been dominated by natives changed to become either extensively dominated by nis or equally occupied by native and nis alike. no single native or nis was repeatedly responsible for the observed changes in native species diversity or nis dominance at all sites. rather, the observed effects of pollution were driven by a diverse range of taxa and species. these findings have important implications for both the way we assess pollution impacts, and for the management of nis. when monitoring the response of assemblages to pollution, it is not sufficient to simply assess changes in community diversity. rather, it is important to distinguish native from nis components since both are expected to respond differently. in order to successfully manage current nis, we first need to address levels of pollution within recipient systems in an effort to bolster the resilience of native communities to invasion.",
            "contribution_ids": [
                "R54787",
                "R54788",
                "R57319",
                "R57320"
            ]
        },
        {
            "instance_id": "R54867xR54819",
            "comparison_id": "R54867",
            "paper_id": "R54819",
            "text": "Distribution of an alien aquatic snail in relation to flow variability, human activities and water quality 1. disturbance and anthropogenic land use changes are usually considered to be key factors facilitating biological invasions. however, specific comparisons of invasion success between sites affected to different degrees by these factors are rare. 2. in this study we related the large-scale distribution of the invading new zealand mud snail ( potamopyrgus antipodarum ) in southern victorian streams, australia, to anthropogenic land use, flow variability, water quality and distance from the site to the sea along the stream channel. 3. the presence of p. antipodarum was positively related to an index of flow-driven disturbance, the coefficient of variability of mean daily flows for the year prior to the study. 4. furthermore, we found that the invader was more likely to occur at sites with multiple land uses in the catchment, in the forms of grazing, forestry and anthropogenic developments (e.g. towns and dams), compared with sites with low-impact activities in the catchment. however, this relationship was confounded by a higher likelihood of finding this snail in lowland sites close to the sea. 5. we conclude that p. antipodarum could potentially be found worldwide at sites with similar ecological characteristics. we hypothesise that its success as an invader may be related to an ability to quickly re-colonise denuded areas and that population abundances may respond to increased food resources. disturbances could facilitate this invader by creating spaces for colonisation (e.g. a possible consequence of floods) or changing resource levels (e.g. increased nutrient levels in streams with intense human land use in their catchments).",
            "contribution_ids": [
                "R54820",
                "R54821"
            ]
        },
        {
            "instance_id": "R54867xR54859",
            "comparison_id": "R54867",
            "paper_id": "R54859",
            "text": "Feral sheep on Socorro Island: facilitators of alien plant colonization and ecosystem decay the paper examines the role of feral sheep (ovis aries) in facilitating the naturalization of alien plants and degrading a formerly robust and stable ecosystem of socorro, an isolated oceanic island in the mexican pacific ocean. approximately half of the island is still sheep\u2010free. the other half has been widely overgrazed and transformed into savannah and prairie\u2010like open habitats that exhibit sheet and gully erosion and are covered by a mix of native and alien invasive vegetation today. vegetation transects in this moderately sheep\u2010impacted sector show that a significant number of native and endemic herb and shrub species exhibit sympatric distribution patterns with introduced plants. only one alien plant species has been recorded from any undisturbed and sheep\u2010free island sector so far.",
            "contribution_ids": [
                "R54860"
            ]
        },
        {
            "instance_id": "R54867xR54576",
            "comparison_id": "R54867",
            "paper_id": "R54576",
            "text": "Plant invasions along mountain roads: the altitudinal amplitude of alien Asteraceae forbs in their native and introduced ranges studying plant invasions along environmental gradients is a promising approach to dissect the relative importance of multiple interacting factors that affect the spread of a species in a new range. along altitudinal gradients, factors such as propagule pressure, climatic conditions and biotic interactions change simultaneously across rather small geographic scales. here we investigate the distribution of eight asteraceae forbs along mountain roads in both their native and introduced ranges in the valais (southern swiss alps) and the wallowa mountains (northeastern oregon, usa). we hypothesised that a lack of adaptation and more limiting propagule pressure at higher altitudes in the new range restricts the altitudinal distribution of aliens relative to the native range. however, all but one of the species reached the same or even a higher altitude in the new range. thus neither the need to adapt to changing climatic conditions nor lower propagule pressure at higher altitudes appears to have prevented the altitudinal spread of introduced populations. we found clear differences between regions in the relative occurrence of alien species in ruderal sites compared to roadsides, and in the degree of invasion away from the roadside, presumably reflecting differences in disturbance patterns between regions. whilst the upper altitudinal limits of these plant invasions are apparently climatically constrained, factors such as anthropogenic disturbance and competition with native vegetation appear to have greater influence than changing climatic conditions on the distribution of these alien species along altitudinal gradients.",
            "contribution_ids": [
                "R54577"
            ]
        },
        {
            "instance_id": "R54867xR54656",
            "comparison_id": "R54867",
            "paper_id": "R54656",
            "text": "Roads as conduits for exotic plant invasions in a semiarid landscape abstract: roads are believed to be a major contributing factor to the ongoing spread of exotic plants. we examined the effect of road improvement and environmental variables on exotic and native plant diversity in roadside verges and adjacent semiarid grassland, shrubland, and woodland communities of southern utah (\\u2003u.s.a.\\u2003). we measured the cover of exotic and native species in roadside verges and both the richness and cover of exotic and native species in adjacent interior communities (\\u200350 m beyond the edge of the road cut\\u2003) along 42 roads stratified by level of road improvement (\\u2003\\u2003paved, improved surface, graded, and four\u2010wheel\u2010drive track\\u2003). in roadside verges along paved roads, the cover of bromus tectorum was three times as great (\\u200327%\\u2003) as in verges along four\u2010wheel\u2010drive tracks (\\u2003\\u20039%\\u2003). the cover of five common exotic forb species tended to be lower in verges along four\u2010wheel\u2010drive tracks than in verges along more improved roads. the richness and cover of exotic species were both more than 50% greater, and the richness of native species was 30% lower, at interior sites adjacent to paved roads than at those adjacent to four\u2010wheel\u2010drive tracks. in addition, environmental variables relating to dominant vegetation, disturbance, and topography were significantly correlated with exotic and native species richness and cover. improved roads can act as conduits for the invasion of adjacent ecosystems by converting natural habitats to those highly vulnerable to invasion. however, variation in dominant vegetation, soil moisture, nutrient levels, soil depth, disturbance, and topography may render interior communities differentially susceptible to invasions originating from roadside verges. plant communities that are both physically invasible (\\u2003e.g., characterized by deep or fertile soils\\u2003) and disturbed appear most vulnerable. decision\u2010makers considering whether to build, improve, and maintain roads should take into account the potential spread of exotic plants.",
            "contribution_ids": [
                "R54657",
                "R54658"
            ]
        },
        {
            "instance_id": "R54867xR54675",
            "comparison_id": "R54867",
            "paper_id": "R54675",
            "text": "Land use intensification differentially benefits alien over native predators in agricultural landscape mosaics both anthropogenic habitat disturbance and the breadth of habitat use by alien species have been found to facilitate invasion into novel environments, and these factors have been hypothesized to be important within coccinellid communities specifically. in this study, we address two questions: (1) do alien species benefit more than native species from human\u2010disturbed habitats? (2) are alien species more generalized in their habitat use than natives within the invaded range or can their abundance patterns be explained by specialization on the most common habitats?",
            "contribution_ids": [
                "R54676"
            ]
        },
        {
            "instance_id": "R54867xR54803",
            "comparison_id": "R54867",
            "paper_id": "R54803",
            "text": "Relationship between productivity, and species and functional group diversity in grazed and non-grazed Pampas grassland most hypotheses addressing the effect of diversity on ecosystem function indicate the occurrence of higher process rates with increasing diversity, and only diverge in the shape of the function depending on their assumptions about the role of individual species and functional groups. contrarily to these predictions, we show that grazing of the flooding pampas grasslands increased species richness, but drastically reduced above ground net primary production, even when communities with similar initial biomass were compared. grazing increased species richness through the addition of a number of exotic forbs, without reducing the richness and cover of the native flora. since these forbs were essentially cool-season species, and also because their introduction has led to the displacement of warm-season grasses from dominant to subordinate positions in the community, grazing not only decreased productivity, but also shifted its seasonality towards the cool season. these results suggest that species diversity and/or richness alone are poor predictors of above-ground primary production. therefore, models that relate productivity to diversity should take into account the relative abundance and identity of species that are added or deleted by the specific disturbances that modify diversity.",
            "contribution_ids": [
                "R54804",
                "R54805"
            ]
        },
        {
            "instance_id": "R54867xR54770",
            "comparison_id": "R54867",
            "paper_id": "R54770",
            "text": "Disturbance-mediated competition and the spread of Phragmites australis in a coastal marsh in recent decades the grass phragmites australis has been aggressively in- vading coastal, tidal marshes of north america, and in many areas it is now considered a nuisance species. while p. australis has historically been restricted to the relatively benign upper border of brackish and salt marshes, it has been expanding seaward into more phys- iologically stressful regions. here we test a leading hypothesis that the spread of p. australis is due to anthropogenic modification of coastal marshes. we did a field experiment along natural borders between stands of p. australis and the other dominant grasses and rushes (i.e., matrix vegetation) in a brackish marsh in rhode island, usa. we applied a pulse disturbance in one year by removing or not removing neighboring matrix vegetation and adding three levels of nutrients (specifically nitrogen) in a factorial design, and then we monitored the aboveground performance of p. australis and the matrix vegetation. both disturbances increased the density, height, and biomass of shoots of p. australis, and the effects of fertilization were more pronounced where matrix vegetation was removed. clear- ing competing matrix vegetation also increased the distance that shoots expanded and their reproductive output, both indicators of the potential for p. australis to spread within and among local marshes. in contrast, the biomass of the matrix vegetation decreased with increasing severity of disturbance. disturbance increased the total aboveground production of plants in the marsh as matrix vegetation was displaced by p. australis. a greenhouse experiment showed that, with increasing nutrient levels, p. australis allocates proportionally more of its biomass to aboveground structures used for spread than to belowground struc- tures used for nutrient acquisition. therefore, disturbances that enrich nutrients or remove competitors promote the spread of p. australis by reducing belowground competition for nutrients between p. australis and the matrix vegetation, thus allowing p. australis, the largest plant in the marsh, to expand and displace the matrix vegetation. reducing nutrient load and maintaining buffers of matrix vegetation along the terrestrial-marsh ecotone will, therefore, be important methods of control for this nuisance species.",
            "contribution_ids": [
                "R54771"
            ]
        },
        {
            "instance_id": "R54867xR54659",
            "comparison_id": "R54867",
            "paper_id": "R54659",
            "text": "Testing life history correlates of invasiveness using congeneric plant species we used three congeneric annual thistles, which vary in their ability to invade california (usa) annual grasslands, to test whether invasiveness is related to differences in life history traits. we hypothesized that populations of these summer-flowering centaurea species must pass through a demographic gauntlet of survival and reproduction in order to persist and that the most invasive species (c. solstitialis) might possess unique life history characteristics. using the idea of a demographic gauntlet as a conceptual framework, we compared each congener in terms of (1) seed germination and seedling establishment, (2) survival of rosettes subjected to competition from annual grasses, (3) subsequent growth and flowering in adult plants, and (4) variation in breeding system. grazing and soil disturbance is thought to affect centaurea establishment, growth, and reproduction, so we also explored differences among congeners in their response to clipping and to different sizes of soil disturbance. \\n \\nwe found minimal differences among congeners in either seed germination responses or seedling establishment and survival. in contrast, differential growth responses of congeners to different sizes of canopy gaps led to large differences in adult size and fecundity. canopy-gap size and clipping affected the fecundity of each species, but the most invasive species (c. solstitialis) was unique in its strong positive response to combinations of clipping and canopy gaps. in addition, the phenology of c. solstitialis allows this species to extend its growing season into the summer\u2014a time when competition from winter annual vegetation for soil water is minimal. surprisingly, c. solstitialis was highly self-incompatible while the less invasive species were highly self-compatible. our results suggest that the invasiveness of c. solstitialis arises, in part, from its combined ability to persist in competition with annual grasses and its plastic growth and reproductive responses to open, disturbed habitat patches. \\n \\ncorresponding editor: d. p. c. peters.",
            "contribution_ids": [
                "R54660"
            ]
        },
        {
            "instance_id": "R54867xR54806",
            "comparison_id": "R54867",
            "paper_id": "R54806",
            "text": "Fire effects on plant diversity in serpentine vs. sandstone chaparral fire contributes to the maintenance of species diversity in many plant com- munities, but few studies have compared its impacts in similar communities that vary in such attributes as soils and productivity. we compared how a wildfire affected plant diversity in chaparral vegetation on serpentine and sandstone soils. we hypothesized that because biomass and cover are lower in serpentine chaparral, space and light are less limiting, and therefore postfire increases in plant species diversity would be lower than in sandstone chaparral. in 40 pairs of burned and unburned 250-m 2 plots, we measured changes in the plant community after a fire for three years. the diversity of native and exotic species increased more in response to fire in sandstone than serpentine chaparral, at both the local (plot) and regional (whole study) scales. in serpentine compared with sandstone chaparral, specialized fire-dependent species were less prevalent, mean fire severity was lower, mean time since last fire was longer, postfire shrub recruitment was lower, and regrowth of biomass was slower. within each chaparral type, the responses of diversity to fire were positively correlated with prefire shrub cover and with a number of measures of soil fertility. fire severity was negatively related to the postfire change in diversity in sandstone chaparral, and unimodally related to the postfire change in diversity in serpentine chaparral. our results suggest that the effects of fire on less productive plant communities like serpentine chaparral may be less pronounced, although longer lasting, than the effects of fire on similar but more productive communities.",
            "contribution_ids": [
                "R54807"
            ]
        },
        {
            "instance_id": "R54867xR54778",
            "comparison_id": "R54867",
            "paper_id": "R54778",
            "text": "Six years of plant community development after clearcut harvesting in western Washington what roles do ruderals and residuals play in early forest succession and how does repeated disturbance affect them? we examined this question by monitoring plant cover and composition on a productive site for 6\\xa0years after clearcutting and planting douglas-fir ( pseudotsuga menziesii (mirb.) franco). the replicated experiment included three treatments: vegetation control with five annual herbicide applications superimposed over two levels of slash removal (bole only or total tree plus most other wood) and an untreated control. three species groups were analyzed: native forest, native ruderals, and exotic ruderals. without vegetation control, the understory was rapidly invaded by exotic ruderals but was codominated by native and exotic ruderals by year 6. douglas-fir cover surpassed covers in the three species group covers at least 3\\xa0years sooner with herbicide treatments than without. species richness and coverage were lower for all species groups with vegetation control than without vegetation control. the effects of organic matter removal were much less than that of vegetation control. as predicted by the intermediate disturbance hypothesis, repeated vegetation control resulted in declining cover and richness; however, native forest species were surprisingly resilient, maintaining as much or more cover and richness as the ruderal groups.",
            "contribution_ids": [
                "R54779",
                "R54780"
            ]
        },
        {
            "instance_id": "R54867xR54849",
            "comparison_id": "R54867",
            "paper_id": "R54849",
            "text": "Alien Flora in Grasslands Adjacent to Road and Trail Corridors in Glacier National Park, Montana (U.S.A.) : alien plant species have rapidly invaded and successfully displaced native species in many grasslands of western north america. thus, the status of alien species in the nature reserve grasslands of this region warrants special attention. this study describes alien flora in nine fescue grassland study sites adjacent to three types of transportation corridors\u2014primary roads, secondary roads, and backcountry trails\u2014in glacier national park, montana (u.s.a.). parallel transects, placed at varying distances from the adjacent road or trail, were used to determine alien species richness and frequency at individual study sites. fifteen alien species were recorded, two eurasian grasses, phleum pratense and poa pratensis, being particularly common in most of the study sites. in sites adjacent to primary and secondary roads, alien species richness declined out to the most distant transect, suggesting that alien species are successfully invading grasslands from the roadside area. in study sites adjacent to backcountry trails, absence of a comparable decline and unexpectedly high levels of alien species richness 100 m from the trailside suggest that alien species have been introduced in off-trail areas. the results of this study imply that in spite of low levels of livestock grazing and other anthropogenic disturbances, fescue grasslands in nature reserves of this region are vulnerable to invasion by alien flora. given the prominent role that roadsides play in the establishment and dispersal of alien flora, road construction should be viewed from a biological, rather than an engineering, perspective. nature reserve man agers should establish effective roadside vegetation management programs that include monitoring, quickly treating keystone alien species upon their initial occurrence in nature reserves, and creating buffer zones on roadside leading to nature reserves. \\n \\n \\n \\nresumen: especies de plantas introducidas han invadido rapidamente y desplazado exitosamente especies nativas en praderas del oeste de america del norte. por lo tanto el estado de las especies introducidas en las reservas de pastizales naturales de esta region exige especial atencion. este estudio describe la flora introducida en nueve pastizales naturales de festuca, las areas de estudios son adyacentes a tres tipos decorredores de transporte\u2014caminos primarios, caminos secundarios y senderos remotos\u2014en el parque nacional \u201cglacier,\u201d montana (ee.uu). para determinar riqueza y frecuencia de especies introducidas, se trazaron transectas paralelas, localizadas a distancias variables del camino o sendero adyacente en las areas de estudio. se registraron quince especies introducidas. dos pastos eurasiaticos, phleum pratensis y poa pratensis, resultaron particularmente abuntes en la mayoria de las areas de estudio. en lugares adyacentes a caminos primarios y secundarios, la riqueza de especies introducidas disminuyo en la direccion de las transectas mas distantes, sugiriendo que las especies introducidas estan invadiendo exitosamente las praderas desde areas aledanas a caminos. en las areas de estudio adyacentes a senderos remotos no se encontro una disminucion comparable; inesperados altos niveles de riqueza de especies introducidas a 100 m de los senderos, sugieren que las especies foraneas han sido introducidas desde otras areas fuero de los senderos. los resultados de este estudio implican que a pesar de los bajos niveles de pastoreo y otras perturbaciones antropogenicas, los pastizales de festuca en las reservas naturales de esta region son vulnerables a la invasion de la flora introducida. dada el rol preponderante que juegan los caminos en el establecimiento y dispersion de la flora introducida, la construccion de rutas debe ser vista desde un punto de vista biologica, mas que desde una perspectiva meramente ingenieril. los administradores de reservas naturales deberian establecer programas efectivos de manejo de vegetacion en los bordes de los caminos. estos programas deberian incluir monitoreo, tratamiento rapido de especies introducidas y claves tan pronto como se detecten en las reservas naturales, y creacion de zonas de transicion en los caminos que conducen a las reservas naturales.",
            "contribution_ids": [
                "R54850"
            ]
        },
        {
            "instance_id": "R54867xR54652",
            "comparison_id": "R54867",
            "paper_id": "R54652",
            "text": "Plant and Small Vertebrate Composition and Diversity 36-39 Years After Root Plowing abstract root plowing is a common management practice to reduce woody vegetation and increase herbaceous forage for livestock on rangelands. our objective was to test the hypotheses that four decades after sites are root plowed they have 1) lower plant species diversity, less heterogeneity, greater percent canopy cover of exotic grasses; and 2) lower abundance and diversity of amphibians, reptiles, and small mammals, compared to sites that were not disturbed by root plowing. pairs of 4-ha sites were selected for sampling: in each pair of sites, one was root plowed in 1965 and another was not disturbed by root plowing (untreated). we estimated canopy cover of woody and herbaceous vegetation during summer 2003 and canopy cover of herbaceous vegetation during spring 2004. we trapped small mammals and herpetofauna in pitfall traps during late spring and summer 2001\u20132004. species diversity and richness of woody plants were less on root-plowed than on untreated sites; however, herbaceous plant and animal species did not differ greatly between treatments. evenness of woody vegetation was less on root-plowed sites, in part because woody legumes were more abundant. abundance of small mammals and herpetofauna varied with annual rainfall more than it varied with root plowing. although structural differences existed between vegetation communities, secondary succession of vegetation reestablishing after root plowing appears to be leading to convergence in plant and small animal species composition with untreated sites.",
            "contribution_ids": [
                "R54653"
            ]
        },
        {
            "instance_id": "R54867xR54855",
            "comparison_id": "R54867",
            "paper_id": "R54855",
            "text": "Roads Alter the Colonization Dynamics of a Keystone Herbivore in Neotropical Savannas roads can facilitate the establishment and spread of both native and exotic species. nevertheless, the precise mechanisms facilitating this expansion are rarely known. we tested the hypothesis that dirt roads are favorable landing and nest initiation sites for founding\u2010queens of the leaf\u2010cutter ant atta laevigata. for 2 yr, we compared the number of attempts to found new nests (colonization attempts) in dirt roads and the adjacent vegetation in a reserve of cerrado (tree\u2010dominated savanna) in southeastern brazil. the number of colonization attempts in roads was 5 to 10 times greater than in the adjacent vegetation. experimental transplants indicate that founding\u2010queens are more likely to establish a nest on bare soil than on soil covered with leaf\u2010litter, but the amount of litter covering the ground did not fully explain the preference of queens for dirt roads. queens that landed on roads were at higher risk of predation by beetles and ants than those that landed in the adjacent vegetation. nevertheless, greater predation in roads was not sufficient to offset the greater number of colonization attempts in this habitat. as a consequence, significantly more new colonies were established in roads than in the adjacent vegetation. our results suggest that disturbance caused by the opening of roads could result in an increased atta abundance in protected areas of the brazilian cerrado.",
            "contribution_ids": [
                "R54856"
            ]
        },
        {
            "instance_id": "R54867xR54715",
            "comparison_id": "R54867",
            "paper_id": "R54715",
            "text": "Human activity facilitates altitudinal expansion of exotic plants along a road in montane grassland, South Africa abstract question: do anthropogenic activities facilitate the distribution of exotic plants along steep altitudinal gradients? location: sani pass road, grassland biome, south africa. methods: on both sides of this road, presence and abundance of exotic plants was recorded in four 25-m long road-verge plots and in parallel 25 m \u00d7 2 m adjacent land plots, nested at five altitudinal levels: 1500, 1800, 2100, 2400 and 2700 m a.s.l. exotic community structure was analyzed using canonical correspondence analysis while a two-level nested generalized linear model was fitted for richness and cover of exotics. we tested the upper altitudinal limits for all exotics along this road for spatial clustering around four potential propagule sources using a t-test. results: community structure, richness and abundance of exotics were negatively correlated with altitude. greatest invasion by exotics was recorded for adjacent land at the 1500 m level. of the 45 exotics, 16 were found at higher altitudes than expected and observations were spatially clustered around potential propagule sources. conclusions: spatial clustering of upper altitudinal limits around human inhabited areas suggests that exotics originate from these areas, while exceeding expected altitudinal limits suggests that distribution ranges of exotics are presently underestimated. exotics are generally characterised by a high propagule pressure and/or persistent seedbanks, thus future tarring of the sani pass may result in an increase of exotic species richness and abundance. this would initially result from construction-related soil disturbance and subsequently from increased traffic, water run-off, and altered fire frequency. we suggest examples of management actions to prevent this. nomenclature: germishuizen & meyer (2003).",
            "contribution_ids": [
                "R54716"
            ]
        },
        {
            "instance_id": "R54867xR54824",
            "comparison_id": "R54867",
            "paper_id": "R54824",
            "text": "Pre-fire fuel reduction treatments influence plant communities and exotic species 9 years after a large wildfire questions: how did post-wildfire understorey plant community response, including exotic species response, differ between pre-fire treated areas that were less severely burned, and pre-fire untreated areas that were more severely burned? were these differences consistent through time? location: east-central arizona, southwestern us. methods: we used a multi-year data set from the 2002 rodeo\u2013chediski fire to detect post-fire trends in plant community response in burned ponderosa pine forests. within the burn perimeter, we examined the effects of pre-fire fuels treatments on post-fire vegetation by comparing paired treated and untreated sites on the apache-sitgreaves national forest. we sampled these paired sites in 2004, 2005 and 2011. results: there were significant differences in pre-fire treated and untreated plant communities by species composition and abundance in 2004 and 2005, but these communities were beginning to converge in 2011. total understorey plant cover was significantly higher in untreated areas for all 3 yr. plant cover generally increased between 2004 and 2005 and markedly decreased in 2011, with the exception of shrub cover, which steadily increased through time. the sharp decrease in forb and graminoid cover in 2011 is likely related to drought conditions since the fire. annual/biennial forb and graminoid cover decreased relative to perennial cover through time, consistent with the initial floristics hypothesis. exotic plant response was highly variable and not limited to the immediate post-fire, annual/biennial community. despite low overall exotic forb and graminoid cover for all years (<2.5%), several exotic species increased in frequency, and the relative proportion of exotic to native cover increased through time. conclusions: pre-treatment fuel reduction treatments helped maintain foundation overstorey species and associated native plant communities following this large wildfire. the overall low cover of exotic species on these sites supports other findings that the disturbance associated with high-severity fire does not always result in exotic species invasions. the increase in relative cover and frequency though time indicates that some species are proliferating, and continued monitoring is recommended. patterns of exotic species invasions after severe burning are not easily predicted, and are likely more dependent on site-specific factors such as propagules, weather patterns and management.",
            "contribution_ids": [
                "R54825"
            ]
        },
        {
            "instance_id": "R54867xR54841",
            "comparison_id": "R54867",
            "paper_id": "R54841",
            "text": "Lack of native species recovery following severe exotic disturbance in southern Californian shrublands summary \\n \\n1.\\u2002urban and agricultural activities are not part of natural disturbance regimes and may bear little resemblance to them. such disturbances are common in densely populated semi-arid shrub communities of the south-western us, yet successional studies in these regions have been limited primarily to natural successional change and the impact of human-induced changes on natural disturbance regimes. although these communities are resilient to recurrent and large-scale disturbance by fire, they are not necessarily well-adapted to recover from exotic disturbances. \\n \\n \\n \\n2.\\u2002this study investigated the effects of severe exotic disturbance (construction, heavy-vehicle activity, landfill operations, soil excavation and tillage) on shrub communities in southern california. these disturbances led to the conversion of indigenous shrublands to exotic annual communities with low native species richness. \\n \\n \\n \\n3.\\u2002nearly 60% of the cover on disturbed sites consisted of exotic annual species, while undisturbed sites were primarily covered by native shrub species (68%). annual species dominant on disturbed sites included erodium botrys, hypochaeris glabra, bromus spp., vulpia myuros and avena spp. \\n \\n \\n \\n4.\\u2002the cover of native species remained low on disturbed sites even 71\\xa0years after initial exotic disturbance ceased. native shrub seedlings were also very infrequent on disturbed sites, despite the presence of nearby seed sources. only two native shrubs, eriogonum fasciculatum and baccharis sarothroides, colonized some disturbed sites in large numbers. \\n \\n \\n \\n5.\\u2002although some disturbed sites had lower total soil nitrogen and percentage organic matter and higher ph than undisturbed sites, soil variables measured in this study were not sufficient to explain variations in species abundances on these sites. \\n \\n \\n \\n6.\\u2002non-native annual communities observed in this study did not recover to a predisturbed state within typical successional time (<\\xa025\\xa0years), supporting the hypothesis that altered stable states can occur if a community is pushed beyond its threshold of resilience.",
            "contribution_ids": [
                "R54842",
                "R54843"
            ]
        },
        {
            "instance_id": "R54867xR54661",
            "comparison_id": "R54867",
            "paper_id": "R54661",
            "text": "Invasibility and abiotic gradients: the positive correlation between native and exotic plant diversity we sampled the understory community in an old-growth, temperate forest to test alternative hypotheses explaining the establishment of exotic plants. we quantified the individual and net importance of distance from areas of human disturbance, native plant diversity, and environmental gradients in determining exotic plant establishment. distance from disturbed areas, both within and around the reserve, was not correlated to exotic species richness. numbers of native and exotic species were positively correlated at large (50 m 2 ) and small (10 m 2 ) plot sizes, a trend that persisted when relationships to environ- mental gradients were controlled statistically. both native and exotic species richness in- creased with soil ph and decreased along a gradient of increasing nitrate availability. exotic species were restricted to the upper portion of the ph gradient and had individualistic responses to the availability of soil resources. these results are inconsistent with both the diversity-resistance and resource-enrichment hypotheses for invasibility. environmental conditions favoring native species richness also favor exotic species richness, and com- petitive interactions with the native flora do not appear to limit the entry of additional species into the understory community at this site. it appears that exotic species with niche requirements poorly represented in the regional flora of native species may establish with relatively little resistance or consequence for native species richness.",
            "contribution_ids": [
                "R54662",
                "R57218"
            ]
        },
        {
            "instance_id": "R54867xR54699",
            "comparison_id": "R54867",
            "paper_id": "R54699",
            "text": "Effects of an intense prescribed fire on understory vegetation in a mixed conifer forest abstract huisinga, k. d., d. c. laughlin, p. z. ful\u00e9, j. d. springer, and c. m. mcglone (ecological restoration institute and school of forestry, northern arizona university, box 15017, flagstaff, az 86011). effects of an intense prescribed fire on understory vegetation in a mixed conifer forest. j. torrey bot. soc. 132: 590\u2013601. 2005.\u2014intense prescribed fire has been suggested as a possible method for forest restoration in mixed conifer forests. in 1993, a prescribed fire in a dense, never-harvested forest on the north rim of grand canyon national park escaped prescription and burned with greater intensity and severity than expected. we sampled this burned area and an adjacent unburned area to assess fire effects on understory species composition, diversity, and plant cover. the unburned area was sampled in 1998 and the burned area in 1999; 25% of the plots were resampled in 2001 to ensure that differences between sites were consistent and persistent, and not due to inter-annual climatic differences. species composition differed significantly between unburned and burned sites; eight species were identified as indicators of the unburned site and thirteen as indicators of the burned site. plant cover was nearly twice as great in the burned site than in the unburned site in the first years of measurement and was 4.6 times greater in the burned site in 2001. average and total species richness was greater in the burned site, explained mostly by higher numbers of native annual and biennial forbs. overstory canopy cover and duff depth were significantly lower in the burned site, and there were significant inverse relationships between these variables and plant species richness and plant cover. greater than 95% of the species in the post-fire community were native and exotic plant cover never exceeded 1%, in contrast with other northern arizona forests that were dominated by exotic species following high-severity fires. this difference is attributed to the minimal anthropogenic disturbance history (no logging, minimal grazing) of forests in the national park, and suggests that park managers may have more options than non-park managers to use intense fire as a tool for forest conservation and restoration.",
            "contribution_ids": [
                "R54700",
                "R54701"
            ]
        },
        {
            "instance_id": "R54867xR54761",
            "comparison_id": "R54867",
            "paper_id": "R54761",
            "text": "Scaling Disturbance Instead of Richness to Better Understand Anthropogenic Impacts on Biodiversity a primary impediment to understanding how species diversity and anthropogenic disturbance are related is that both diversity and disturbance can depend on the scales at which they are sampled. while the scale dependence of diversity estimation has received substantial attention, the scale dependence of disturbance estimation has been essentially overlooked. here, we break from conventional examination of the diversity-disturbance relationship by holding the area over which species richness is estimated constant and instead manipulating the area over which human disturbance is measured. in the boreal forest ecoregion of alberta, canada, we test the dependence of species richness on disturbance scale, the scale-dependence of the intermediate disturbance hypothesis, and the consistency of these patterns in native versus exotic species and among human disturbance types. we related field observed species richness in 1 ha surveys of 372 boreal vascular plant communities to remotely sensed measures of human disturbance extent at two survey scales: local (1 ha) and landscape (18 km2). supporting the intermediate disturbance hypothesis, species richness-disturbance relationships were quadratic at both local and landscape scales of disturbance measurement. this suggests the shape of richness-disturbance relationships is independent of the scale at which disturbance is assessed, despite that local diversity is influenced by disturbance at different scales by different mechanisms, such as direct removal of individuals (local) or indirect alteration of propagule supply (landscape). by contrast, predictions of species richness did depend on scale of disturbance measurement: with high local disturbance richness was double that under high landscape disturbance.",
            "contribution_ids": [
                "R54762"
            ]
        },
        {
            "instance_id": "R54867xR54789",
            "comparison_id": "R54867",
            "paper_id": "R54789",
            "text": "Conservation of the Grassy White Box Woodlands: Relative Contributions of Size and Disturbance to Floristic Composition and Diversity of Remnants before european settlement, grassy white box woodlands were the dominant vegetation in the east of the\\nwheat-sheep belt of south-eastern australia. tree clearing, cultivation and pasture improvement have led\\nto fragmentation of this once relatively continuous ecosystem, leaving a series of remnants which\\nthemselves have been modified by livestock grazing. little-modified remnants are extremely rare. we\\nexamined and compared the effects of fragmentation and disturbance on the understorey flora of\\nwoodland remnants, through a survey of remnants of varying size, grazing history and tree clearing. in\\naccordance with fragmentation theory, species richness generally increased with remnant size, and, for\\nlittle-grazed remnants, smaller remnants were more vulnerable to weed invasion. similarly, tree\\nclearing and grazing encouraged weed invasion and reduced native species richness. evidence for\\nincreased total species richness at intermediate grazing levels, as predicted by the intermediate\\ndisturbance hypothesis, was equivocal. remnant quality was more severely affected by grazing than by\\nremnant size. all little-grazed remnants had lower exotic species abundance and similar or higher native\\nspecies richness than grazed remnants, despite their extremely small sizes (&lt; 6 ha). further, small, littlegrazed\\nremnants maintained the general character of the pre-european woodland understorey, while\\ngrazing caused changes to the dominant species. although generally small, the little-grazed remnants\\nare the best representatives of the pre-european woodland understorey, and should be central to any\\nconservation plan for the woodlands. selected larger remnants are needed to complement these,\\nhowever, to increase the total area of woodland conserved, and, because most little-grazed remnants are\\ncleared, to represent the ecosystem in its original structural form. for the maintenance of native plant\\ndiversity and composition in little-grazed remnants, it is critical that livestock grazing continues to be\\nexcluded. for grazed remnants, maintenance of a site in its current state would allow continuation of\\npast management, while restoration to a pre-european condition would require management directed\\ntowards weed removal, and could take advantage of the difference noted in the predominant life-cycle\\nof native (perennial) versus exotic (annual or biennial) species.",
            "contribution_ids": [
                "R54790"
            ]
        },
        {
            "instance_id": "R54867xR54632",
            "comparison_id": "R54867",
            "paper_id": "R54632",
            "text": "Dalmatian toadflax (Linaria dalmatica) response to wildfire in a southwestern USA forest abstract severe wildfires often facilitate the spread of exotic invasive species, such as dalmatian toadflax (linaria dalmatica). we hypothesized that toadflax growth and reproduction would increase with increasing burn severity in a ponderosa pine (pinus ponderosa)-dominated forest. we measured toadflax density, cover, flowering stalks, and native species richness and cover on 327 plots for 3 y after a 2001 wildfire. toadflax stem density, cover, and flowering stalks increased in 2003, then decreased in 2004 in all burn severity classes, but remained higher than initial 2002 values. toadflax spread to previously uncolonized areas, though stem density decreased in unburned plots. transition matrices showed that more plots on moderately (73%) and severely (74%) burned areas classified as high toadflax density in 2002 remained high density in 2004. deterministic matrix modeling using 2002 to 2004 transition probabilities projected that the percentage of high-density plots would stabilize on moderately and severely burned sites at 41 and 61%, respectively. in contrast, 20-y rates of change (\u03bb) for unburned and low-severity burn sites were <1.0, and stabilizing at 2% for unburned plots and 19% for low-severity burn plots. post-wildfire conditions in high-severity burned areas favour increased density, cover, reproduction, and spread of dalmatian toadflax, while native species richness was reduced, suggesting that the invasive species would persist, at least in the short term, at the expense of natives. nomenclature: usda nrcs, 2007.",
            "contribution_ids": [
                "R54633",
                "R54634",
                "R54635"
            ]
        },
        {
            "instance_id": "R54867xR54729",
            "comparison_id": "R54867",
            "paper_id": "R54729",
            "text": "The short-term responses of small mammals to wildfire in semiarid mallee shrubland, Australia \\n\\ncontext. wildfire is a major driver of the structure and function of mallee eucalypt- and spinifex-dominated landscapes. understanding how fire influences the distribution of biota in these fire-prone environments is essential for effective ecological and conservation-based management.\\naims. we aimed to (1) determine the effects of an extensive wildfire (118\\u2009000\\u2009ha) on a small mammal community in the mallee shrublands of semiarid australia and (2) assess the hypothesis that the fire-response patterns of small mammals can be predicted by their life-history characteristics.\\nmethods. small-mammal surveys were undertaken concurrently at 26 sites: once before the fire and on four occasions following the fire (including 14 sites that remained unburnt). we documented changes in small-mammal occurrence before and after the fire, and compared burnt and unburnt sites. in addition, key components of vegetation structure were assessed at each site.\\nkey results. wildfire had a strong influence on vegetation structure and on the occurrence of small mammals. the mallee ningaui, ningaui yvonneae, a dasyurid marsupial, showed a marked decline in the immediate post-fire environment, corresponding with a reduction in hummock-grass cover in recently burnt vegetation. species richness of native small mammals was positively associated with unburnt vegetation, although some species showed no clear response to wildfire.\\nconclusions. our results are consistent with the contention that mammal responses to fire are associated with their known life-history traits. the species most strongly affected by wildfire, n. yvonneae, has the most specific habitat requirements and restricted life history of the small mammals in the study area. the only species positively associated with recently burnt vegetation, the introduced house mouse, mus domesticus, has a flexible life history and non-specialised resource requirements.\\nimplications. maintaining sources for recolonisation after large-scale wildfires will be vital to the conservation of native small mammals in mallee ecosystems.\\n",
            "contribution_ids": [
                "R54730"
            ]
        },
        {
            "instance_id": "R54867xR54736",
            "comparison_id": "R54867",
            "paper_id": "R54736",
            "text": "Species introductions, diversity and disturbances in marine macrophyte assemblages of the northwestern Mediterranean Sea in the process of species introduction, the traits that enable a species to establish and spread in a new habitat, and the habitat characteristics that determine the susceptibility to intro- duced species play a major role. among the habitat characteristics that render a habitat resistant or susceptible to introductions, species diversity and disturbance are believed to be the most important. it is generally assumed that high species richness renders a habitat resistant to introductions, while disturbances enhance their susceptibility. in the present study, these 2 hypotheses were tested on nw mediterranean shallow subtidal macrophyte assemblages. data collection was carried out in early summer 2002 on sub-horizontal rocky substrate at 9 sites along the french mediterranean coast, 4 undisturbed and 5 highly disturbed. disturbances include cargo, naval and passenger har- bours, and industrial and urban pollution. relationships between species richness (point diversity), disturbances and the number of introduced macrophytes were analysed. the following conclusions were drawn: (1) there is no relationship between species introductions, diversity and disturbance for the macrophyte assemblages; (2) multifactorial analyses only revealed the biogeographical relation- ships between the native flora of the sites.",
            "contribution_ids": [
                "R54737"
            ]
        },
        {
            "instance_id": "R54867xR54680",
            "comparison_id": "R54867",
            "paper_id": "R54680",
            "text": "Grassland invisibility and diversity: responses to nutrients, seed input, and disturbance the diversity and composition of a community are determined by a com- bination of local and regional processes. we conducted a field experiment to examine the impact of resource manipulations and seed addition on the invasibility and diversity of a low-productivity grassland. we manipulated resource levels both by a disturbance treatment that reduced adult plant cover in the spring of the first year and by addition of fertilizer every year. seeds of 46 native species, both resident and nonresident to the community, were added in spring of the first year to determine the effects of recruitment limitation from local (seed limitation) and regional (dispersal limitation) sources on local species richness. our results show that the unmanipulated community was not readily invasible. seed addition increased the species richness of unmanipulated plots, but this was primarily due to increased occurrence of resident species. nonresident species were only able to invade following a cover-reduction disturbance. cover reduction resulted in an increase in nitrogen availability in the first year, but had no measurable effect on light availability in any year. in contrast, fertilization created a persistent increase in nitrogen availability that increased plant cover or biomass and reduced light penetration to ground level. initially, fertilization had an overall positive effect on species richness, but by the third year, the effect was either negative or neutral. unlike cover reduction, fertilization had no observable effect on seedling recruitment or occurrence (number of plots) of invading resident or nonresident species. the results of our experiment demonstrate that, although resource fluctuations can increase the invasibility of this grass- land, the community response depends on the nature of the resource change.",
            "contribution_ids": [
                "R54681"
            ]
        },
        {
            "instance_id": "R54867xR54744",
            "comparison_id": "R54867",
            "paper_id": "R54744",
            "text": "Biogenic disturbance determines invasion success in a subtidal soft-sediment system \"theoretically, disturbance and diversity can influence the success of invasive colonists if (1) resource limitation is a prime determinant of invasion success and (2) disturbance and diversity affect the availability of required resources. however, resource limitation is not of overriding importance in all systems, as exemplified by marine soft sediments, one of earth's most widespread habitat types. here, we tested the disturbance-invasion hypothesis in a marine soft-sediment system by altering rates of biogenic disturbance and tracking the natural colonization of plots by invasive species. levels of sediment disturbance were controlled by manipulating densities of burrowing spatangoid urchins, the dominant biogenic sediment mixers in the system. colonization success by two invasive species (a gobiid fish and a semelid bivalve) was greatest in plots with sediment disturbance rates 9000 cm(3) x m(-2) x d(-1)). invasive colonization declined with increasing levels of sediment disturbance, counter to the disturbance-invasion hypothesis. increased sediment disturbance by the urchins also reduced the richness and diversity of native macrofauna (particularly small, sedentary, surface feeders), though there was no evidence of increased availability of resources with increased disturbance that would have facilitated invasive colonization: sediment food resources (chlorophyll a and organic matter content) did not increase, and space and access to overlying water were not limited (low invertebrate abundance). thus, our study revealed the importance of biogenic disturbance in promoting invasion resistance in a marine soft-sediment community, providing further evidence of the valuable role of bioturbation in soft-sediment systems (bioturbation also affects carbon processing, nutrient recycling, oxygen dynamics, benthic community structure, and so on.). bioturbation rates are influenced by the presence and abundance of large burrowing species (like spatangoid urchins). therefore, mass mortalities of large bioturbators could inflate invasion risk and alter other aspects of ecosystem performance in marine soft-sediment habitats.\"",
            "contribution_ids": [
                "R54745"
            ]
        },
        {
            "instance_id": "R54867xR54722",
            "comparison_id": "R54867",
            "paper_id": "R54722",
            "text": "Alien plant dynamics following fire in Mediterranean-climate California shrublands over 75 species of alien plants were recorded during the first five years after fire in southern california shrublands, most of which were european annuals. both cover and richness of aliens varied between years and plant association. alien cover was lowest in the first postfire year in all plant associations and remained low during succession in chaparral but increased in sage scrub. alien cover and richness were significantly correlated with year (time since disturbance) and with precipitation in both coastal and interior sage scrub associations. hypothesized factors determining alien dominance were tested with structural equation modeling. models that included nitrogen deposition and distance from the coast were not significant, but with those variables removed we obtained a significant model that gave an r 2 5 0.60 for the response variable of fifth year alien dominance. factors directly affecting alien dominance were (1) woody canopy closure and (2) alien seed banks. significant indirect effects were (3) fire intensity, (4) fire history, (5) prefire stand structure, (6) aridity, and (7) community type. according to this model the most critical factor in- fluencing aliens is the rapid return of the shrub and subshrub canopy. thus, in these communities a single functional type (woody plants) appears to the most critical element controlling alien invasion and persistence. fire history is an important indirect factor be- cause it affects both prefire stand structure and postfire alien seed banks. despite being fire-prone ecosystems, these shrublands are not adapted to fire per se, but rather to a particular fire regime. alterations in the fire regime produce a very different selective environment, and high fire frequency changes the selective regime to favor aliens. this study does not support the widely held belief that prescription burning is a viable man- agement practice for controlling alien species on semiarid landscapes.",
            "contribution_ids": [
                "R54723",
                "R54724"
            ]
        },
        {
            "instance_id": "R54867xR54725",
            "comparison_id": "R54867",
            "paper_id": "R54725",
            "text": "Fire and grazing impacts on plant diversity and alien plant invasions in the southern Sierra Nevada patterns of native and alien plant diversity in response to disturbance were examined along an elevational gradient in blue oak savanna, chaparral, and coniferous forests. total species richness, alien species richness, and alien cover declined with elevation, at scales from 1 to 1000 m2. we found no support for the hypothesis that community diversity inhibits alien invasion. at the 1-m2 point scale, where we would expect competitive interactions between the largely herbaceous flora to be most intense, alien species richness as well as alien cover increased with increasing native species richness in all communities. this suggests that aliens are limited not by the number of native competitors, but by resources that affect establishment of both natives and aliens. blue oak savannas were heavily dominated by alien species and consistently had more alien than native species at the 1-m2 scale. all of these aliens are annuals, and it is widely thought that they have displaced native bunchgrasses. if true, this...",
            "contribution_ids": [
                "R54726",
                "R54727",
                "R54728"
            ]
        },
        {
            "instance_id": "R54867xR54795",
            "comparison_id": "R54867",
            "paper_id": "R54795",
            "text": "Functional and performance comparisons of invasive Hieracium lepidulum and co-occurring species in New Zealand one of the key environmental factors affecting plant species abundance, including that of invasive exotics, is nutrient resource availability. plant functional response to nutrient availability, and what this tells us about plant interactions with associated species, may therefore give us clues about underlying processes related to plant abundance and invasion. patterns of abundance of hieracium lepidulum, a european herbaceous invader of subalpine new zealand, appear to be related to soil fertility/nutrient availability, however, abundance may be influenced by other factors including disturbance. in this study we compare h.\\xa0lepidulum and field co-occurring species for growth performance across artificial nutrient concentration gradients, for relative competitiveness and for response to disturbance, to construct a functional profile of the species. hieracium lepidulum was found to be significantly different in its functional response to nutrient concentration gradients. hieracium lepidulum had high relative growth rate, high yield and root plasticity in response to nutrient concentration dilution, relatively low absolute yield, low competitive yield and a positive response to clipping disturbance relative to other species. based on overall functional response to nutrient concentration gradients, compared with other species found at the same field sites, we hypothesize that h.\\xa0lepidulum invasion is not related to competitive domination. relatively low tolerance of nutrient dilution leads us to predict that h.\\xa0lepidulum is likely to be restricted from invading low fertility sites, including sites within alpine vegetation or where intact high biomass plant communities are found. positive response to clipping disturbance and relatively high nutrient requirement, despite poor competitive performance, leads us to predict that h.\\xa0lepidulum may respond to selective grazing disturbance of associated vegetation. these results are discussed in relation to published observations of h.\\xa0lepidulum in new zealand and possible tests for the hypotheses raised here.",
            "contribution_ids": [
                "R54796"
            ]
        },
        {
            "instance_id": "R54867xR54836",
            "comparison_id": "R54867",
            "paper_id": "R54836",
            "text": "How grazing and soil quality affect native and exotic plant diversity in rocky mountain grasslands we used multiscale plots to sample vascular plant diversity and soil characteristics in and adjacent to 26 long-term grazing exclosure sites in colorado, wyoming, montana, and south dakota, usa. the exclosures were 7\u201360 yr old (31.2 \u00b1 2.5 yr, mean \u00b1 1 se). plots were also randomly placed in the broader landscape in open rangeland in the same vegetation type at each site to assess spatial variation in grazed landscapes. consistent sampling in the nine national parks, wildlife refuges, and other management units yielded data from 78 1000-m2 plots and 780 1-m2 subplots. we hypothesized that native species richness would be lower in the exclosures than in grazed sites, due to competitive exclusion in the absence of grazing. we also hypothesized that grazed sites would have higher native and exotic species richness compared to ungrazed areas, due to disturbance (i.e., the intermediate-disturbance hypothesis) and the conventional wisdom that grazing may accelerate weed invasion. both hypotheses were soundly rej...",
            "contribution_ids": [
                "R54837",
                "R54838"
            ]
        },
        {
            "instance_id": "R54867xR54684",
            "comparison_id": "R54867",
            "paper_id": "R54684",
            "text": "Influence of fire and soil nutrients on native and non-native annuals at remnant vegetation edges in the Western Australian wheatbelt . the effect of fire on annual plants was examined in two vegetation types at remnant vegetation edges in the western australian wheatbelt. density and cover of non-native species were consistently greatest at the reserve edges, decreasing rapidly with increasing distance from reserve edge. numbers of native species showed little effect of distance from reserve edge. fire had no apparent effect on abundance of non-natives in allocasuarina shrubland but abundance of native plants increased. density of both non-native and native plants in acacia acuminata-eucalyptus loxophleba woodland decreased after fire. fewer non-native species were found in the shrubland than in the woodland in both unburnt and burnt areas, this difference being smallest between burnt areas. levels of soil phosphorus and nitrate were higher in burnt areas of both communities and ammonium also increased in the shrubland. levels of soil phosphorus and nitrate were higher at the reserve edge in the unburnt shrubland, but not in the woodland. there was a strong correlation between soil phosphorus levels and abundance of non-native species in the unburnt shrubland, but not after fire or in the woodland. removal of non-native plants in the burnt shrubland had a strong positive effect on total abundance of native plants, apparently due to increases in growth of smaller, suppressed native plants in response to decreased competition. two native species showed increased seed production in plots where non-native plants had been removed. there was a general indication that, in the short term, fire does not necessarily increase invasion of these communities by non-native species and could, therefore be a useful management tool in remnant vegetation, providing other disturbances are minimised.",
            "contribution_ids": [
                "R54685"
            ]
        },
        {
            "instance_id": "R54867xR54822",
            "comparison_id": "R54867",
            "paper_id": "R54822",
            "text": "Invasion, competitive dominance, and resource use by exotic and native California grassland species the dynamics of invasive species may depend on their abilities to compete for resources and exploit disturbances relative to the abilities of native species. we test this hypothesis and explore its implications for the restoration of native ecosystems in one of the most dramatic ecological invasions worldwide, the replacement of native perennial grasses by exotic annual grasses and forbs in 9.2 million hectares of california grasslands. the long-term persistence of these exotic annuals has been thought to imply that the exotics are superior competitors. however, seed-addition experiments in a southern california grassland revealed that native perennial species, which had lower requirements for deep soil water, soil nitrate, and light, were strong competitors, and they markedly depressed the abundance and fecundity of exotic annuals after overcoming recruitment limitations. native species reinvaded exotic grasslands across experimentally imposed nitrogen, water, and disturbance gradients. thus, exotic annuals are not superior competitors but rather may dominate because of prior disturbance and the low dispersal abilities and extreme current rarity of native perennials. if our results prove to be general, it may be feasible to restore native california grassland flora to at least parts of its former range.",
            "contribution_ids": [
                "R54823"
            ]
        },
        {
            "instance_id": "R54867xR54620",
            "comparison_id": "R54867",
            "paper_id": "R54620",
            "text": "A comparison of the urban flora of different phytoclimatic regions in Italy this study is a comparison of the spontaneous vascular flora of five italian cities: milan, ancona, rome, cagliari and palermo. the aims of the study are to test the hypothesis that urbanization results in uniformity of urban floras, and to evaluate the role of alien species in the flora of settlements located in different phytoclimatic regions. to obtain comparable data, ten plots of 1 ha, each representing typical urban habitats, were analysed in each city. the results indicate a low floristic similarity between the cities, while the strongest similarity appears within each city and between each city and the seminatural vegetation of the surrounding region. in the mediterranean settlements, even the most urbanized plots reflect the characters of the surrounding landscape and are rich in native species, while aliens are relatively few. these results differ from the reported uniformity and the high proportion of aliens which generally characterize urban floras elsewhere. to explain this trend the importance of apophytes (indigenous plants expanding into man-made habitats) is highlighted; several mediterranean species adapted to disturbance (i.e. grazing, trampling, and human activities) are pre-adapted to the urban environment. in addition, consideration is given to the minor role played by the \u2018urban heat island\u2019 in the mediterranean basin, and to the structure and history of several italian settlements, where ancient walls, ruins and archaeological sites in the periphery as well as in the historical centres act as conservative habitats and provide connection with seed-sources on the outskirts.",
            "contribution_ids": [
                "R54621"
            ]
        },
        {
            "instance_id": "R54867xR54801",
            "comparison_id": "R54867",
            "paper_id": "R54801",
            "text": "Herbaceous layer contrast and alien plant occurrence in utility corridors and riparian forests of the Allegheny High Plateau communities by alien plant species that can adversely affect community structure and function. to determine how corridor establishment influences riparian vegetation of the allegheny high plateau of northwestern pennsylvania, we compared the species composition and richness of the herbaceous layer (all vascular plants s 1 m tall) of utility corridors and adjacent headwater riparian forests, and tested the hypothesis that utility corridors serve as foci for the invasion of adjacent riparian forest by alien vascular plants. we contrasted plant species richness and vegetative cover, cover by growth form, species richness and cover of alien plants and cover of microhabitat components (open soil, rock, leaf litter, log, bryophyte) in utility corridors and adjacent riparian forest at 17 sites. cluster analysis revealed that herbaceous layer species assemblages in corridors and riparian forest were compositionally distinct. herbaceous layer cover and species richness were significantly (p s 0.05) greater in corridors than in riparian forest. fern, graminoid, and forb species co-dominated herbaceous layer cover in corridors; fern cover dominated riparian forests. cover of alien plants was significantly greater in corridors than in riparian forest. alien plant species richness and cover were significantly and positively correlated with open soil, floodplain width, and active channel width in corridors but were significantly and negatively correlated with litter cover in riparian forest. given that the majority of alien plant species we found in corridors were shade-intolerant and absent from riparian forests, we conclude that open utility corridors primarily serve as habitat refugia, rather than as invasion foci, for alien plant species in riparian forests of the allegheny high plateau.",
            "contribution_ids": [
                "R54802"
            ]
        },
        {
            "instance_id": "R54867xR54595",
            "comparison_id": "R54867",
            "paper_id": "R54595",
            "text": "Contingency of grassland restoration on year, site, and competition from introduced grasses semiarid ecosystems such as grasslands are characterized by high temporal variability in abiotic factors, which has led to suggestions that management actions may be more effective in some years than others. here we examine this hypothesis in the context of grassland restoration, which faces two major obstacles: the contingency of native grass establishment on unpredictable precipitation, and competition from introduced species. we established replicated restoration experiments over three years at two sites in the northern great plains in order to examine the extent to which the success of several restoration strategies varied between sites and among years. we worked in 50-yr-old stands of crested wheatgrass (agropyron cristatum), an introduced perennial grass that has been planted on >10 \u00d7 106 ha in western north america. establishment of native grasses was highly contingent on local conditions, varying fourfold among years and threefold between sites. survivorship also varied greatly and increased signi...",
            "contribution_ids": [
                "R54596"
            ]
        },
        {
            "instance_id": "R54867xR54709",
            "comparison_id": "R54867",
            "paper_id": "R54709",
            "text": "Epifaunal disturbance by periodic low levels of dissolved oxygen: native vs. invasive species response hypoxia is increasing in marine and estuarine systems worldwide, primarily due to anthropogenic causes. periodic hypoxia represents a pulse disturbance, with the potential to restruc- ture estuarine biotic communities. we chose the shallow, epifaunal community in the lower chesa- peake bay, virginia, usa, to test the hypothesis that low dissolved oxygen (do) (<4 mg l -1 ) affects community dynamics by reducing the cover of spatial dominants, creating space both for less domi- nant native species and for invasive species. settling panels were deployed at shallow depths in spring 2000 and 2001 at gloucester point, virginia, and were manipulated every 2 wk from late june to mid-august. manipulation involved exposing epifaunal communities to varying levels of do for up to 24 h followed by redeployment in the york river. exposure to low do affected both species com- position (presence or absence) and the abundance of the organisms present. community dominance shifted away from barnacles as level of hypoxia increased. barnacles were important spatial domi- nants which reduced species diversity when locally abundant. the cover of hydroides dianthus, a native serpulid polychaete, doubled when exposed to periodic hypoxia. increased h. dianthus cover may indicate whether a local region has experienced periodic, local do depletion and thus provide an indicator of poor water-quality conditions. in 2001, the combined cover of the invasive and crypto- genic species in this community, botryllus schlosseri (tunicate), molgula manhattensis (tunicate), ficopomatus enigmaticus (polychaete) and diadumene lineata (anemone), was highest on the plates exposed to moderately low do (2 mg l -1 < do < 4 mg l -1 ). all 4 of these species are now found world- wide and exhibit life histories well adapted for establishment in foreign habitats. low do events may enhance success of invasive species, which further stress marine and estuarine ecosystems.",
            "contribution_ids": [
                "R54710"
            ]
        },
        {
            "instance_id": "R54867xR54686",
            "comparison_id": "R54867",
            "paper_id": "R54686",
            "text": "Disturbance Facilitates Invasion: The Effects Are Stronger Abroad than at Home disturbance is one of the most important factors promoting exotic invasion. however, if disturbance per se is sufficient to explain exotic success, then \u201cinvasion\u201d abroad should not differ from \u201ccolonization\u201d at home. comparisons of the effects of disturbance on organisms in their native and introduced ranges are crucial to elucidate whether this is the case; however, such comparisons have not been conducted. we investigated the effects of disturbance on the success of eurasian native centaurea solstitialis in two invaded regions, california and argentina, and one native region, turkey, by conducting field experiments consisting of simulating different disturbances and adding locally collected c. solstitialis seeds. we also tested differences among c. solstitialis genotypes in these three regions and the effects of local soil microbes on c. solstitialis performance in greenhouse experiments. disturbance increased c. solstitialis abundance and performance far more in nonnative ranges than in the native range, but c. solstitialis biomass and fecundity were similar among populations from all regions grown under common conditions. eurasian soil microbes suppressed growth of c. solstitialis plants, while californian and argentinean soil biota did not. we suggest that escape from soil pathogens may contribute to the disproportionately powerful effect of disturbance in introduced regions.",
            "contribution_ids": [
                "R54687",
                "R54688"
            ]
        },
        {
            "instance_id": "R54867xR54711",
            "comparison_id": "R54867",
            "paper_id": "R54711",
            "text": "Dam invaders: impoundments facilitate biological invasions into freshwaters freshwater ecosystems are at the forefront of the global biodiversity crisis, with more declining and extinct species than in terrestrial or marine environments. hydrologic alterations and biological invasions represent two of the greatest threats to freshwater biota, yet the importance of linkages between these drivers of environmental change remains uncertain. here, we quantitatively test the hypothesis that impoundments facilitate the introduction and establishment of aquatic invasive species in lake ecosystems. by combining data on boating activity, water body physicochemistry, and geographical distribution of five nuisance invaders in the laurentian great lakes region, we show that non-indigenous species are 2.4 to 300 times more likely to occur in impoundments than in natural lakes, and that impoundments frequently support multiple invaders. furthermore, comparisons of the contemporary and historical landscapes revealed that impoundments enhance the invasion risk of natural lakes by increasing their...",
            "contribution_ids": [
                "R54712"
            ]
        },
        {
            "instance_id": "R54867xR54571",
            "comparison_id": "R54867",
            "paper_id": "R54571",
            "text": "Exotic and native vegetation establishment following channelization of a western Iberian river channelization is often a major cause of human impacts on river systems. it affects both hydrogeomorphic features and habitat characteristics and potentially impacts riverine flora and fauna. human-disturbed fluvial ecosystems also appear to be particularly vulnerable to exotic plant establishment. following a 12-year recovery period, the distribution, composition and cover of both exotic and native plant species were studied along a portuguese lowland river segment, which had been subjected to resectioning, straightening and two-stage bank reinforcement, and were compared with those of a nearby, less impacted segment. the species distribution was also related to environmental data. species richness and floristic composition in the channelized river segment were found to be similar to those at the more \u2018natural\u2019 river sites. floral differences were primarily consistent with the dominance of cover by certain species. however, there were significant differences in exotic and native species richness and cover between the \u2018natural\u2019 corridor and the channelized segment, which was more susceptible to invasion by exotic perennial taxa, such as eryngium pandanifolium, paspalum paspalodes, tradescantia fluminensis and acacia dealbata. factorial and canonical correspondence analyses revealed considerable patchiness in the distribution of species assemblages. the latter were associated with small differences in substrate composition and their own relative position across the banks and along the river segments in question. data was also subjected to an unweighted pair-group arithmetic average clustering, and the indicator value methodology was applied to selected cluster noda in order to obtain significant indicator species. copyright \u00a9 2001 john wiley & sons, ltd.",
            "contribution_ids": [
                "R54572",
                "R54573"
            ]
        },
        {
            "instance_id": "R54867xR54753",
            "comparison_id": "R54867",
            "paper_id": "R54753",
            "text": "Are invasive species the drivers or passengers of change in degraded ecosystems? \"few invaded ecosystems are free from habitat loss and disturbance, leading to uncertainty whether dominant invasive species are driving community change or are passengers along for the environmental ride. the ''driver'' model predicts that invaded communities are highly interactive, with subordinate native species being limited or ex- cluded by competition from the exotic dominants. the ''passenger'' model predicts that invaded communities are primarily structured by noninteractive factors (environmental change, dispersal limitation) that are less constraining on the exotics, which thus dominate. we tested these alternative hypotheses in an invaded, fragmented, and fire-suppressed oak savanna. we examined the impact of two invasive dominant perennial grasses on community structure using a reduction (mowing of aboveground biomass) and removal (weeding of above- and belowground biomass) experiment conducted at different seasons and soil depths. we examined the relative importance of competition vs. dispersal limitation with experimental seed additions. competition by the dominants limits the abundance and re- production of many native and exotic species based on their increased performance with removals and mowing. the treatments resulted in increased light availability and bare soil; soil moisture and n were unaffected. although competition was limiting for some, 36 of 79 species did not respond to the treatments or declined in the absence of grass cover. seed additions revealed that some subordinates are dispersal limited; competition alone was insufficient to explain their rarity even though it does exacerbate dispersal inefficiencies by lowering reproduction. while the net effects of the dominants were negative, their presence restricted woody plants, facilitated seedling survival with moderate disturbance (i.e., treatments applied in the fall), or was not the primary limiting factor for the occurrence of some species. finally, the species most functionally distinct from the dominants (forbs, woody plants) responded most significantly to the treatments. this suggests that relative abundance is determined more by trade-offs relating to environmental conditions (long- term fire suppression) than to traits relating to resource capture (which should most impact functionally similar species). this points toward the passenger model as the underlying cause of exotic dominance, although their combined effects (suppressive and facilitative) on community structure are substantial.\"",
            "contribution_ids": [
                "R54754"
            ]
        },
        {
            "instance_id": "R54867xR54808",
            "comparison_id": "R54867",
            "paper_id": "R54808",
            "text": "Resource availability and invasibility in an intertidal macroalgal assemblage \"the invasibility of a low intertidal macroalgal assemblage was experimentally tested from march 2003 to april 2004 at 1 locality in northern spain. it was hypothesised that a community becomes more susceptible to invasion when there is an increase in the amount of key resources. a bifactorial ('nutrient supply' and 'macroalgal biomass removed') orthogonal experiment was designed with 3 levels in each factor (high, medium and control). fertile plants of sargassum muticum (yendo) fensholt were transplanted to each plot to simulate the arrival of an invader. the invasibility of the assemblage was quantified in the pre- (density of recruits) and post-settlement (percentage cover, size and density of s. muticum at the end of the experiment) phases of s. muticum's life cycle. results supported the initial hypothesis. both space availability and nutrient enrichment facilitated the establishment and spread of s. muticum in the experimental plots. established s. muticum plants grew faster in enriched plots than in controls. furthermore, different successional assemblages played different roles in resisting invasion as s. muticum's life cycle pro- gressed. in the initial stage of the invasion, the bifurcaria bifurcata canopy inhibited recruitment by s. muticum, whereas understory species did not have a significant effect on invasion success. in contrast, an increased survivorship of s. muticum beneath the canopy of b. bifurcata was observed in those plots where s. muticum had successfully recruited. this study shows that the invasibility of this low intertidal assemblage is mediated by a complex interaction of several resources acting at different stages during s. muticum's invasion.\"",
            "contribution_ids": [
                "R54809",
                "R54810",
                "R54811"
            ]
        },
        {
            "instance_id": "R54867xR54799",
            "comparison_id": "R54867",
            "paper_id": "R54799",
            "text": "Relationship between fragmentation, degradation and native and exotic species richness in an Andean temperate forest of Chile impactos humanos tales como la fragmentacion y degradacion de bosques pueden tener fuertes efectos en las comunidades de especies vegetales nativas y exoticas. ademas, perturbaciones antropicas ocurren principalmente en menores altitudes produciendo mayores grados de fragmentacion y degradacion que en mayores altitudes. la invasion de plantas exoticas deberia ser mayor en bosques mas fragmentados o degradados y, por lo tanto, en menores altitudes dentro de un tipo de bosque o piso altitudinal. en cambio, la riqueza de especies nativas deberia ser negativamente afectada por la fragmentacion y degradacion, encontrandose mayor riqueza en mayores altitudes dentro de un tipo de bosque determinado. en este trabajo evaluamos estas hipotesis en un bosque templado andino de la region de la araucania, chile. registramos la composicion de plantas vasculares en doce fragmentos de diferente tamano, razon perimetro/area, altitud y degradacion antropica (cortas, incendios, fecas de ganado). en base a estas variables construimos un indice de fragmentacion y uno de degradacion para estos fragmentos. se analizaron las relaciones entre estas variables a traves de correlaciones de pearson. nuestros resultados sugieren que la fragmentacion y degradacion estan positivamente relacionadas y que ambos tipos de perturbacion ocurren en altitudes mas bajas del tipo de bosque estudiado. ademas, la fragmentacion y degradacion estan afectando en diferente forma a la riqueza de especies nativas y exoticas. la invasion se incremento como consecuencia tanto de fragmentacion como de degradacion, y como consecuencia del patron de distribucion altitudinal de estas perturbaciones, la invasion aparentemente ocurre principalmente en zonas bajas. en cambio, la riqueza de especies nativas fue negativamente afectada solo por la fragmentacion, y no se relaciono con la degradacion interna de los bosques ni con la altitud.",
            "contribution_ids": [
                "R54800"
            ]
        },
        {
            "instance_id": "R54867xR54844",
            "comparison_id": "R54867",
            "paper_id": "R54844",
            "text": "Effects of fragmentation and invasion on native ant communities in coastal southern California we investigated the roles of habitat fragmentation and the invasion of an exotic species on the structure of ground-foraging ant communities in 40 scrub habitat fragments in coastal southern california. in particular, we asked: how do fragment age, fragment size, amount of urban edge, percentage of native vegetation, degree of isolation, and the relative abundance of an exotic species, the argentine ant (linepithema humile) affect native ants? within these fragments, argentine ants were more abundant near developed edges and in areas dominated by exotic vegetation. the number of native ground-foraging ant species at any point declined from an average of >7 to <2 species in the presence of the argentine ant. among fragments, a stepwise multiple regression revealed that the abundance of argentine ants, the size of the fragment, and the number of years since it was isolated from larger continuous areas of scrub habitat best predict the number of remaining native ant species. the argentine ant was found in every fragment surveyed as well as around the edges of larger unfragmented areas. fragments had fewer native ant species than similar-sized plots within large unfragmented areas, and fragments with argentine ant-free refugia had more native ant species than those without refugia. the relative vulnerability of native ants to habitat fragmentation and the subsequent presence of argentine ants vary among species. the most sensitive species include army ants (neivamyrmex spp.) and harvester ants (genera messor and pogonomyrmex), both of which are important to ecosystem-level processes. our surveys suggest that the argentine ant is widespread in fragmented coastal scrub habitats in southern california and strongly affects native ant communities.",
            "contribution_ids": [
                "R54845",
                "R54846"
            ]
        },
        {
            "instance_id": "R54867xR54622",
            "comparison_id": "R54867",
            "paper_id": "R54622",
            "text": "Responses of exotic plant species to fires in Pinus ponderosa forests in northern Arizona . changes in disturbance due to fire regime in southwestern pinus ponderosa forests over the last century have led to dense forests that are threatened by widespread fire. it has been shown in other studies that a pulse of native, early-seral opportunistic species typically follow such disturbance events. with the growing importance of exotic plants in local flora, however, these exotics often fill this opportunistic role in recovery. we report the effects of fire severity on exotic plant species following three widespread fires of 1996 in northern arizona p. ponderosa forests. species richness and abundance of all vascular plant species, including exotics, were higher in burned than nearby unburned areas. exotic species were far more important, in terms of cover, where fire severity was highest. species present after wildfires include those of the pre-disturbed forest and new species that could not be predicted from above-ground flora of nearby unburned forests.",
            "contribution_ids": [
                "R54623",
                "R54624"
            ]
        },
        {
            "instance_id": "R54867xR54667",
            "comparison_id": "R54867",
            "paper_id": "R54667",
            "text": "Anthropogenic fires increase alien and native annual species in the Chilean coastal matorral aim\\u2002 we tested the hypothesis that anthropogenic fires favour the successful establishment of alien annual species to the detriment of natives in the chilean coastal matorral.",
            "contribution_ids": [
                "R54668"
            ]
        },
        {
            "instance_id": "R54867xR54609",
            "comparison_id": "R54867",
            "paper_id": "R54609",
            "text": "An experimental study of plant community invasibility a long\u2014term field experiment in limestone grassland near buxton (north derbyshire, united kingdom) was designed to identify plant attributes and vegetation characteristics conducive to successful invasion. plots containing crossed, continuous gradients of fertilizer addition and disturbance intensity were subjected to a single\u2014seed inoculum comprising a wide range of plant functional types and 54 species not originally present at the site. several disturbance treatments were applied; these included the creation of gaps of contrasting size and the mowing of the vegetation to different heights and at different times of the year. this paper analyzes the factors controlling the initial phase of the resulting invasions within the plots subject to gap creation. the susceptibility of the indigenous community to invasion was strongly related to the availability of bare ground created, but greatest success occurred where disturbance coincided with eutrophication. disturbance damage to the indigenous dominants (particularly festuca ovina) was an important determinant of seedling establishment by the sown invaders. large seed size was identified as an important characteristic allowing certain species to establish relatively evenly across the productivity\u2014disturbance matrix; smaller\u2014seeded species were more dependent on disturbance for establishment. successful and unsuccessful invaders were also distinguished to some extent by differences in germination requirements and present geographical distribution.",
            "contribution_ids": [
                "R54610"
            ]
        },
        {
            "instance_id": "R54867xR54746",
            "comparison_id": "R54867",
            "paper_id": "R54746",
            "text": "Establishment and Post-Hurricane Survival of the Non-Native Rio Grande Cichlid (Herichthys cyanoguttatus) in the Greater New Orleans Metropolitan Area abstract we conducted multiple surveys to determine the distribution of the non-native herichthys cyanoguttatus (rio grande cichlid) in the greater new orleans metropolitan area (gnoma). first, in 2003\u20132004, we trapped h. cyanoguttatus in lake pontchartrain (an oligohaline estuary) to determine if this freshwater species occurred in estuarine habitats. our goal was to test the prediction that h. cyanoguttatus used estuarine corridors to disperse. second, we sampled and compared 16 gnoma sites before and after the 2005 hurricanes to determine how h. cyanoguttatus populations responded. finally, we monitored h. cyanoguttatus populations monthly over two years (2006\u20132007) at six sites within the gnoma to determine if numbers continued to increase after the hurricanes. we confirmed that h. cyanoguttatus: 1) does occur in estuarine habitats (0 to 8 psu), 2) effectively survived the 2005 hurricanes, 3) has increased significantly from 2006 to 2007 at three of six gnoma sites, 4) is currently found more often in urban sites, and 5) persisted through the atypically cold winter of 2009/2010.",
            "contribution_ids": [
                "R54747",
                "R54748"
            ]
        },
        {
            "instance_id": "R54867xR54638",
            "comparison_id": "R54867",
            "paper_id": "R54638",
            "text": "Exotic invasive species in urban wetlands: environmental correlates and implications for wetland management summary 1. wetlands in urban regions are subjected to a wide variety of anthropogenic disturbances, many of which may promote invasions of exotic plant species. in order to devise management strategies, the influence of different aspects of the urban and natural environments on invasion and community structure must be understood. 2. the roles of soil variables, anthropogenic effects adjacent to and within the wetlands, and vegetation structure on exotic species occurrence within 21 forested wetlands in north-eastern new jersey, usa, were compared. the hypotheses were tested that different vegetation strata and different invasive species respond similarly to environmental factors, and that invasion increases with increasing direct human impact, hydrologic disturbance, adjacent residential land use and decreasing wetland area. canonical correspondence analyses, correlation and logistic regression analyses were used to examine invasion by individual species and overall site invasion, as measured by the absolute and relative number of exotic species in the site flora. 3. within each stratum, different sets of environmental factors separated exotic and native species. nutrients, soil clay content and ph, adjacent land use and canopy composition were the most frequently identified factors affecting species, but individual species showed highly individualistic responses to the sets of environmental variables, often responding in opposite ways to the same factor. 4. overall invasion increased with decreasing area but only when sites > 100 ha were included. unexpectedly, invasion decreased with increasing proportions of industrial/commercial adjacent land use. 5. the hypotheses were only partially supported; invasion does not increase in a simple way with increasing human presence and disturbance. 6. synthesis and applications . the results suggest that a suite of environmental conditions can be identified that are associated with invasion into urban wetlands, which can be widely used for assessment and management. however, a comprehensive ecosystem approach is needed that places the remediation of physical alterations from urbanization within a landscape context. specifically, sediment, inputs and hydrologic changes need to be related to adjoining urban land use and to the overlapping requirements of individual native and exotic species.",
            "contribution_ids": [
                "R54639"
            ]
        },
        {
            "instance_id": "R54867xR54627",
            "comparison_id": "R54867",
            "paper_id": "R54627",
            "text": "Variable effects of feral pig disturbances on native and exotic plants in a California grassland \"biological invasions are a global phenomenon that can accelerate disturbance regimes and facilitate colonization by other nonnative species. in a coastal grassland in northern california, we conducted a four-year exclosure experiment to assess the effects of soil disturbances by feral pigs (sus scrofa) on plant community composition and soil nitrogen availability. our results indicate that pig disturbances had substantial effects on the community, although many responses varied with plant functional group, geographic origin (native vs. exotic), and grassland type. (''short patches'' were dominated by annual grasses and forbs, whereas ''tall patches'' were dominated by perennial bunchgrasses.) soil disturbances by pigs increased the richness of exotic plant species by 29% and native taxa by 24%. although native perennial grasses were unaffected, disturbances reduced the bio- mass of exotic perennial grasses by 52% in tall patches and had no effect in short patches. pig disturbances led to a 69% decrease in biomass of exotic annual grasses in tall patches but caused a 62% increase in short patches. native, nongrass monocots exhibited the opposite biomass pattern as those seen for exotic annual grasses, with disturbance causing an 80% increase in tall patches and a 56% decrease in short patches. native forbs were unaffected by disturbance, whereas the biomass of exotic forbs increased by 79% with disturbance in tall patches and showed no response in short patches. in contrast to these vegetation results, we found no evidence that pig disturbances affected nitrogen mineral- ization rates or soil moisture availability. thus, we hypothesize that the observed vegetation changes were due to space clearing by pigs that provided greater opportunities for colo- nization and reduced intensity of competition, rather than changes in soil characteristics. in summary, although responses were variable, disturbances by feral pigs generally pro- moted the continued invasion of this coastal grassland by exotic plant taxa.\"",
            "contribution_ids": [
                "R54628",
                "R54629"
            ]
        },
        {
            "instance_id": "R55219xR54956",
            "comparison_id": "R55219",
            "paper_id": "R54956",
            "text": "The vulnerability of habitats to plant invasion: disentangling the roles of propagule pressure, time and sampling effort aim\\u2002 to quantify the vulnerability of habitats to invasion by alien plants having accounted for the effects of propagule pressure, time and sampling effort. \\n \\n \\n \\nlocation\\u2002 new zealand. \\n \\n \\n \\nmethods\\u2002 we used spatial, temporal and habitat information taken from 9297 herbarium records of 301 alien plant species to examine the vulnerability of 11 terrestrial habitats to plant invasions. a null model that randomized species records across habitats was used to account for variation in sampling effort and to derive a relative measure of invasion based either on all records for a species or only its first record. the relative level of invasion was related to the average distance of each habitat from the nearest conurbation, which was used as a proxy for propagule pressure. the habitat in which a species was first recorded was compared to the habitats encountered for all records of that species to determine whether the initial habitat could predict subsequent habitat occupancy. \\n \\n \\n \\nresults\\u2002 variation in sampling effort in space and time significantly masked the underlying vulnerability of habitats to plant invasions. distance from the nearest conurbation had little effect on the relative level of invasion in each habitat, but the number of first records of each species significantly declined with increasing distance. while urban, streamside and coastal habitats were over-represented as sites of initial invasion, there was no evidence of major invasion hotspots from which alien plants might subsequently spread. rather, the data suggest that certain habitats (especially roadsides) readily accumulate alien plants from other habitats. \\n \\n \\n \\nmain conclusions\\u2002 herbarium records combined with a suitable null model provide a powerful tool for assessing the relative vulnerability of habitats to plant invasion. the first records of alien plants tend to be found near conurbations, but this pattern disappears with subsequent spread. regardless of the habitat where a species was first recorded, ultimately most alien plants spread to roadside and sparse habitats. this information suggests that such habitats may be useful targets for weed surveillance and monitoring.",
            "contribution_ids": [
                "R54957"
            ]
        },
        {
            "instance_id": "R55219xR55013",
            "comparison_id": "R55219",
            "paper_id": "R55013",
            "text": "High predictability in introduction outcomes and the geographical range size of introduced Australian birds: a role for climate summary \\n \\n \\n1 \\nwe investigated factors hypothesized to influence introduction success and subsequent geographical range size in 52 species of bird that have been introduced to mainland australia. \\n \\n2 \\nthe 19 successful species had been introduced more times, at more sites and in greater overall numbers. relative to failed species, successfully introduced species also had a greater area of climatically suitable habitat available in australia, a larger overseas range size and were more likely to have been introduced successfully outside australia. after controlling for phylogeny these relationships held, except that with overseas range size and, in addition, larger-bodied species had a higher probability of introduction success. there was also a marked taxonomic bias: gamebirds had a much lower probability of success than other species. a model including five of these variables explained perfectly the patterns in introduction success across-species. \\n \\n3 \\nof the successful species, those with larger geographical ranges in australia had a greater area of climatically suitable habitat, traits associated with a faster population growth rate (small body size, short incubation period and more broods per season) and a larger overseas range size. the relationships between range size in australia, the extent of climatically suitable habitat and overseas range size held after controlling for phylogeny. \\n \\n4 \\nwe discuss the probable causes underlying these relationships and why, in retrospect, the outcome of bird introductions to australia are highly predictable.",
            "contribution_ids": [
                "R55014",
                "R56976"
            ]
        },
        {
            "instance_id": "R55219xR55088",
            "comparison_id": "R55219",
            "paper_id": "R55088",
            "text": "Effects of soil fungi, disturbance and propagule pressure on exotic plant recruitment and establishment at home and abroad \"biogeographic experiments that test how multiple interacting factors influence exotic plant abundance in their home and recipient communities are remarkably rare. we examined the effects of soil fungi, disturbance and propagule pressure on seed germination, seedling recruitment and adult plant establishment of the invasive centaurea stoebe in its native european and non\u2010native north american ranges. centaurea stoebe can establish virtual monocultures in parts of its non\u2010native range, but occurs at far lower abundances where it is native. we conducted parallel experiments at four european and four montana (usa) grassland sites with all factorial combinations of \u00b1 suppression of soil fungi, \u00b1disturbance and low versus high knapweed propagule pressure [100 or 300 knapweed seeds per 0.3 m \u00d7 0.3 m plot (1000 or 3000 per m2)]. we also measured germination in buried bags containing locally collected knapweed seeds that were either treated or not with fungicide. disturbance and propagule pressure increased knapweed recruitment and establishment, but did so similarly in both ranges. treating plots with fungicides had no effect on recruitment or establishment in either range. however, we found: (i) greater seedling recruitment and plant establishment in undisturbed plots in montana compared to undisturbed plots in europe and (ii) substantially greater germination of seeds in bags buried in montana compared to europe. also, across all treatments, total plant establishment was greater in montana than in europe. synthesis. our results highlight the importance of simultaneously examining processes that could influence invasion in both ranges. they indicate that under \u2018background\u2019 undisturbed conditions, knapweed recruits and establishes at greater abundance in montana than in europe. however, our results do not support the importance of soil fungi or local disturbances as mechanisms for knapweed's differential success in north america versus europe.\"",
            "contribution_ids": [
                "R55089"
            ]
        },
        {
            "instance_id": "R55219xR55097",
            "comparison_id": "R55219",
            "paper_id": "R55097",
            "text": "Effect of propagule pressure on the establishment and spread of the little fire ant Wasmannia auropunctata in a Gabonese oilfield we studied the effect of propagule pressure on the establishment and subsequent spread of the invasive little fire ant wasmannia auropunctata in a gabonese oilfield in lowland rain forest. oil well drilling, the major anthropogenic disturbance over the past 21 years in the area, was used as an indirect measure of propagule pressure. an analysis of 82 potential introductions at oil production platforms revealed that the probability of successful establishment significantly increased with the number of drilling events. specifically, the shape of the dose\u2013response establishment curve could be closely approximated by a poisson process with a 34% chance of infestation per well drilled. consistent with our knowledge of largely clonal reproduction by w. auropunctata, the shape of the establishment curve suggested that the ants were not substantially affected by allee effects, probably greatly contributing to this species\u2019 success as an invader. by contrast, the extent to which w. auropunctata spread beyond the point of initial introduction, and thus the extent of its damage to diversity of other ant species, was independent of propagule pressure. these results suggest that while establishment success depends on propagule pressure, other ecological or genetic factors may limit the extent of further spread. knowledge of the shape of the dose\u2013response establishment curve should prove useful in modelling the future spread of w. auropunctata and perhaps the spread of other clonal organisms.",
            "contribution_ids": [
                "R55098"
            ]
        },
        {
            "instance_id": "R55219xR54979",
            "comparison_id": "R55219",
            "paper_id": "R54979",
            "text": "Geographical variability in propagule pressure and climatic suitability explain the European distribution of two highly invasive crayfish we assess the relative contribution of human, biological and climatic factors in explaining the colonization success of two highly invasive freshwater decapods: the signal crayfish (pacifastacus leniusculus) and the red swamp crayfish (procambarus clarkii).",
            "contribution_ids": [
                "R54980"
            ]
        },
        {
            "instance_id": "R55219xR55081",
            "comparison_id": "R55219",
            "paper_id": "R55081",
            "text": "Invasive species profiling? Exploring the characteristics of non-native fishes across invasion stages in California \"summary \\n \\n1. the global spread of non-native species is a major concern for ecologists, particularly in regards to aquatic systems. predicting the characteristics of successful invaders has been a goal of invasion biology for decades. quantitative analysis of species characteristics may allow invasive species profiling and assist the development of risk assessment strategies. \\n \\n \\n \\n2. in the current analysis we developed a data base on fish invasions in catchments throughout california that distinguishes among the establishment, spread and integration stages of the invasion process, and separates social and biological factors related to invasion success. \\n \\n \\n \\n3. using akaike's information criteria (aic), logistic and multiple regression models, we show suites of biological variables, which are important in predicting establishment (parental care and physiological tolerance), spread (life span, distance from nearest native source and trophic status) and abundance (maximum size, physiological tolerance and distance from nearest native source). two variables indicating human interest in a species (propagule pressure and prior invasion success) are predictors of successful establishment and prior invasion success is a predictor of spread and integration. \\n \\n \\n \\n4. despite the idiosyncratic nature of the invasion process, our results suggest some assistance in the search for characteristics of fish species that successfully transition between invasion stages.\"",
            "contribution_ids": [
                "R55082"
            ]
        },
        {
            "instance_id": "R55219xR55117",
            "comparison_id": "R55219",
            "paper_id": "R55117",
            "text": "The comparative importance of species traits and introduction characteristics in tropical plant invasions aim\\u2002 we used alien plant species introduced to a botanic garden to investigate the relative importance of species traits (leaf traits, dispersal syndrome) and introduction characteristics (propagule pressure, residence time and distance to forest) in explaining establishment success in surrounding tropical forest. we also used invasion scores from a weed risk assessment protocol as an independent measure of invasion risk and assessed differences in variables between high\u2010 and low\u2010risk species.",
            "contribution_ids": [
                "R55118",
                "R55119"
            ]
        },
        {
            "instance_id": "R55219xR54958",
            "comparison_id": "R55219",
            "paper_id": "R54958",
            "text": "Quarantine arthropod invasions in Europe: the role of climate, hosts and propagule pressure to quantify the relative importance of propagule pressure, climate\u2010matching and host availability for the invasion of agricultural pest arthropods in europe and to forecast newly emerging pest species and european areas with the highest risk of arthropod invasion under current climate and a future climate scenario (a1f1).",
            "contribution_ids": [
                "R54959"
            ]
        },
        {
            "instance_id": "R55219xR55059",
            "comparison_id": "R55219",
            "paper_id": "R55059",
            "text": "Reproductive potential and seedling establishment of the invasive alien tree Schinus molle (Anacardiaceae) in South Africa schinus molle (peruvian pepper tree) was introduced to south africa more than 150\\xa0years ago and was widely planted, mainly along roads. only in the last two decades has the species become naturalized and invasive in some parts of its new range, notably in semi-arid savannas. research is being undertaken to predict its potential for further invasion in south africa. we studied production, dispersal and predation of seeds, seed banks, and seedling establishment in relation to land uses at three sites, namely ungrazed savanna once used as a military training ground; a savanna grazed by native game; and an ungrazed mine dump. we found that seed production and seed rain density of s. molle varied greatly between study sites, but was high at all sites (384\\xa0864\u20131\\xa0233\\xa0690 seeds per tree per year; 3877\u20139477 seeds per square metre per year). we found seeds dispersed to distances of up to 320\\xa0m from female trees, and most seeds were deposited within 50\\xa0m of putative source trees. annual seed rain density below canopies of acacia tortillis, the dominant native tree at all sites, was significantly lower in grazed savanna. the quality of seed rain was much reduced by endophagous predators. seed survival in the soil was low, with no survival recorded beyond 1\\xa0year. propagule pressure to drive the rate of recruitment: densities of seedlings and sapling densities were higher in ungrazed savanna and the ungrazed mine dump than in grazed savanna, as reflected by large numbers of young individuals, but adult\\xa0:\\xa0seedling ratios did not differ between savanna sites. frequent and abundant seed production, together with effective dispersal of viable s. molle seed by birds to suitable establishment sites below trees of other species to overcome predation effects, facilitates invasion. disturbance enhances invasion, probably by reducing competition from native plants.",
            "contribution_ids": [
                "R55060"
            ]
        },
        {
            "instance_id": "R55219xR55125",
            "comparison_id": "R55219",
            "paper_id": "R55125",
            "text": "Behavioural flexibility predicts invasion success in birds introduced to New Zealand a fundamental question in ecology is whether there are evolutionary characteristics of species that make some better than others at invading new communities. in birds, nesting habits, sexually selected traits, migration, clutch size and body mass have been suggested as important variables, but behavioural flexibility is another obvious trait that has received little attention. behavioural flexibility allows animals to respond more rapidly to environmental changes and can therefore be advantageous when invading novel habitats. behavioural flexibility is linked to relative brain size and, for foraging, has been operationalised as the number of innovations per taxon reported in the short note sections of ornithology journals. here, we use data on avian species introduced to new zealand and test the link between forebrain size, feeding innovation frequency and invasion success. relative brain size was, as expected, a significant predictor of introduction success, after removing the effect of introduction effort. species with relatively larger brains tended to be better invaders than species with smaller ones. introduction effort, migratory strategy and mode of juvenile development were also significant in the models. pair-wise comparisons of closely related species indicate that successful invaders also showed a higher frequency of foraging innovations in their region of origin. this study provides the first evidence in vertebrates of a general set of traits, behavioural flexibility, that can potentially favour invasion success.",
            "contribution_ids": [
                "R55126",
                "R57064"
            ]
        },
        {
            "instance_id": "R55219xR55057",
            "comparison_id": "R55219",
            "paper_id": "R55057",
            "text": "Role of propagule pressure in colonization success: disentangling the relative importance of demographic, genetic and habitat effects high propagule pressure is arguably the only consistent predictor of colonization success. more individuals enhance colonization success because they aid in overcoming demographic consequences of small population size (e.g. stochasticity and allee effects). the number of founders can also have direct genetic effects: with fewer individuals, more inbreeding and thus inbreeding depression will occur, whereas more individuals typically harbour greater genetic variation. thus, the demographic and genetic components of propagule pressure are interrelated, making it difficult to understand which mechanisms are most important in determining colonization success. we experimentally disentangled the demographic and genetic components of propagule pressure by manipulating the number of founders (fewer or more), and genetic background (inbred or outbred) of individuals released in a series of three complementary experiments. we used bemisia whiteflies and released them onto either their natal host (benign) or a novel host (challenging). our experiments revealed that having more founding individuals and those individuals being outbred both increased the number of adults produced, but that only genetic background consistently shaped net reproductive rate of experimental populations. environment was also important and interacted with propagule size to determine the number of adults produced. quality of the environment interacted also with genetic background to determine establishment success, with a more pronounced effect of inbreeding depression in harsh environments. this interaction did not hold for the net reproductive rate. these data show that the positive effect of propagule pressure on founding success can be driven as much by underlying genetic processes as by demographics. genetic effects can be immediate and have sizable effects on fitness.",
            "contribution_ids": [
                "R55058"
            ]
        },
        {
            "instance_id": "R55219xR55025",
            "comparison_id": "R55219",
            "paper_id": "R55025",
            "text": "Propagule Size and the Relative Success of Exotic Ungulate and Bird Introductions to New Zealand we investigated factors affecting the success of 14 species of ungulates introduced to new zealand around 1851\u20131926. the 11 successful species had a shorter maximum life span and were introduced in greater numbers than the three unsuccessful species. because introduction effort was confounded with other life\u2010history traits, we examined whether independent introductions of the same species were more likely to succeed when a greater number of individuals were introduced. for the six species with introductions that both succeeded and failed, successful introductions always involved an equal or greater number of individuals than unsuccessful introductions of the same species. for all independent introductions, there was a highly significant relationship between the number of individuals introduced and introduction success. when data for ungulate and bird introductions to new zealand were combined, a variable categorizing species as ungulate or bird was a highly significant predictor of introduction success, after variation in introduction effort was controlled. for a given number of individuals introduced, ungulates were much more likely to succeed than birds.",
            "contribution_ids": [
                "R55026",
                "R56979"
            ]
        },
        {
            "instance_id": "R55219xR55046",
            "comparison_id": "R55219",
            "paper_id": "R55046",
            "text": "Role of Propagule Size in the Success of Incipient Colonies of the Invasive Argentine Ant abstract: factors that contribute to the successful establishment of invasive species are often poorly understood. propagule size is considered a key determinant of establishment success, but experimental tests of its importance are rare. we used experimental colonies of the invasive argentine ant (\\u2003\\u2003linepithema humile) that differed both in worker and queen number to test how these attributes influence the survivorship and growth of incipient colonies. all propagules without workers experienced queen mortality, in contrast to only 6% of propagules with workers. in small propagules (10\u20131,000 workers), brood production increased with worker number but not queen number. in contrast, per capita measures of colony growth decreased with worker number over these colony sizes. in larger propagules (\\u20031,000\u201311,000 workers), brood production also increased with increasing worker number, but per capita brood production appeared independent of colony size. our results suggest that queens need workers to establish successfully but that propagules with as few as 10 workers can grow quickly. given the requirements for propagule success in argentine ants, it is not surprising how easily they spread via human commerce.",
            "contribution_ids": [
                "R55047"
            ]
        },
        {
            "instance_id": "R55219xR55092",
            "comparison_id": "R55219",
            "paper_id": "R55092",
            "text": "Inferring Process from Pattern in Plant Invasions: A Semimechanistic Model Incorporating Propagule Pressure and Environmental Factors propagule pressure is intuitively a key factor in biological invasions: increased availability of propagules increases the chances of establishment, persistence, naturalization, and invasion. the role of propagule pressure relative to disturbance and various environmental factors is, however, difficult to quantify. we explored the relative importance of factors driving invasions using detailed data on the distribution and percentage cover of alien tree species on south africa\u2019s agulhas plain (2,160 km2). classification trees based on geology, climate, land use, and topography adequately explained distribution but not abundance (canopy cover) of three widespread invasive species (acacia cyclops, acacia saligna, and pinus pinaster). a semimechanistic model was then developed to quantify the roles of propagule pressure and environmental heterogeneity in structuring invasion patterns. the intensity of propagule pressure (approximated by the distance from putative invasion foci) was a much better predictor of canopy cover than any environmental factor that was considered. the influence of environmental factors was then assessed on the residuals of the first model to determine how propagule pressure interacts with environmental factors. the mediating effect of environmental factors was species specific. models combining propagule pressure and environmental factors successfully predicted more than 70% of the variation in canopy cover for each species.",
            "contribution_ids": [
                "R55093"
            ]
        },
        {
            "instance_id": "R55219xR55072",
            "comparison_id": "R55219",
            "paper_id": "R55072",
            "text": "Planting history and propagule pressure as predictors of invasion by woody species in a temperate region abstract:\\u2002 we studied 28 alien tree species currently planted for forestry purposes in the czech republic to determine the probability of their escape from cultivation and naturalization. indicators of propagule pressure (number of administrative units in which a species is planted and total planting area) and time of introduction into cultivation were used as explanatory variables in multiple regression models. fourteen species escaped from cultivation, and 39% of the variance was explained by the number of planting units and the time of introduction, the latter being more important. species introduced early had a higher probability of escape than those introduced later, with more than 95% probability of escape for those introduced before 1801 and <5% for those introduced after 1892. probability of naturalization was more difficult to predict, and eight species were misclassified. a model omitting two species with the largest influence on the model yielded similar predictors of naturalization as did the probability of escape. both phases of invasion therefore appear to be driven by planting and introduction history in a similar way. our results demonstrate the importance of forestry for recruitment of invasive trees. six alien forestry trees, classified as invasive in the czech republic, are currently reported in nature reserves. in addition, forestry authorities want to increase the diversity of alien species and planting area in the country.",
            "contribution_ids": [
                "R55073"
            ]
        },
        {
            "instance_id": "R55219xR55050",
            "comparison_id": "R55219",
            "paper_id": "R55050",
            "text": "ECOLOGICAL RESISTANCE TO BIOLOGICAL INVASION OVERWHELMED BY PROPAGULE PRESSURE models and observational studies have sought patterns of predictability for invasion of natural areas by nonindigenous species, but with limited success. in a field experiment using forest understory plants, we jointly manipulated three hypothesized determinants of biological invasion outcome: resident diversity, physical disturbance and abiotic conditions, and propagule pressure. the foremost constraints on net habitat invasibility were the number of propagules that arrived at a site and naturally varying resident plant density. the physical environment (flooding regime) and the number of established resident species had negligible impact on habitat invasibility as compared to propagule pressure, despite manipulations that forced a significant reduction in resident richness, and a gradient in flooding from no flooding to annual flooding. this is the first experimental study to demonstrate the primacy of propagule pressure as a determinant of habitat invasibility in comparison with other candidate controlling factors.",
            "contribution_ids": [
                "R55051",
                "R55052",
                "R57386"
            ]
        },
        {
            "instance_id": "R55219xR54977",
            "comparison_id": "R55219",
            "paper_id": "R54977",
            "text": "Introduction history and species characteristics partly explain naturalization success of North American woody species in Europe 1 the search for general characteristics of invasive species has not been very successful yet. a reason for this could be that current invasion patterns are mainly reflecting the introduction history (i.e. time since introduction and propagule pressure) of the species. accurate data on the introduction history are, however, rare, particularly for introduced alien species that have not established. as a consequence, few studies that tested for the effects of species characteristics on invasiveness corrected for introduction history. 2 we tested whether the naturalization success of 582 north american woody species in europe, measured as the proportion of european geographic regions in which each species is established, can be explained by their introduction history. for 278 of these species we had data on characteristics related to growth form, life cycle, growth, fecundity and environmental tolerance. we tested whether naturalization success can be further explained by these characteristics. in addition, we tested whether the effects of species characteristics differ between growth forms. 3 both planting frequency in european gardens and time since introduction significantly increased naturalization success, but the effect of the latter was relatively weak. after correction for introduction history and taxonomy, six of the 26 species characteristics had significant effects on naturalization success. leaf retention and precipitation tolerance increased naturalization success. tree species were only 56% as likely to naturalize as non\u2010tree species (vines, shrubs and subshrubs), and the effect of planting frequency on naturalization success was much stronger for non\u2010trees than for trees. on the other hand, the naturalization success of trees, but not for non\u2010trees, increased with native range size, maximum plant height and seed spread rate. 4 synthesis. our results suggest that introduction history, particularly planting frequency, is an important determinant of current naturalization success of north american woody species (particularly of non\u2010trees) in europe. therefore, studies comparing naturalization success among species should correct for introduction history. species characteristics are also significant determinants of naturalization success, but their effects may differ between growth forms.",
            "contribution_ids": [
                "R54978"
            ]
        },
        {
            "instance_id": "R55219xR55002",
            "comparison_id": "R55219",
            "paper_id": "R55002",
            "text": "Factors explaining alien plant invasion success in a tropical ecosystem differ at each stage of invasion 1 understanding why some alien plant species become invasive when others fail is a fundamental goal in invasion ecology. we used detailed historical planting records of alien plant species introduced to amani botanical garden, tanzania and contemporary surveys of their invasion status to assess the relative ability of phylogeny, propagule pressure, residence time, plant traits and other factors to explain the success of alien plant species at different stages of the invasion process. 2 species with native ranges centred in the tropics and with larger seeds were more likely to regenerate, whereas naturalization success was explained by longer residence time, faster growth rate, fewer seeds per fruit, smaller seed mass and shade tolerance. 3 naturalized species spreading greater distances from original plantings tended to have more seeds per fruit, whereas species dispersed by canopy\u2010feeding animals and with native ranges centred on the tropics tended to have spread more widely in the botanical garden. species dispersed by canopy\u2010feeding animals and with greater seed mass were more likely to be established in closed forest. 4 phylogeny alone made a relatively minor contribution to the explanatory power of statistical models, but a greater proportion of variation in spread within the botanical garden and in forest establishment was explained by phylogeny alone than for other models. phylogeny jointly with variables also explained a greater proportion of variation in forest establishment than in other models. phylogenetic correction weakened the importance of dispersal syndrome in explaining compartmental spread, seed mass in the forest establishment model, and all factors except for growth rate and residence time in the naturalization model. 5 synthesis. this study demonstrates that it matters considerably how invasive species are defined when trying to understand the relative ability of multiple variables to explain invasion success. by disentangling different invasion stages and using relatively objective criteria to assess species status, this study highlights that relatively simple models can help to explain why some alien plants are able to naturalize, spread and even establish in closed tropical forests.",
            "contribution_ids": [
                "R55003",
                "R56968",
                "R56969"
            ]
        },
        {
            "instance_id": "R55219xR54996",
            "comparison_id": "R55219",
            "paper_id": "R54996",
            "text": "The demography of introduction pathways, propagule pressure and occurrences of non-native freshwater fish in England \"1.\\r\\nbiological invasion theory predicts that the introduction and establishment of non-native species is positively correlated with propagule pressure. releases of pet and aquarium fishes to inland waters has a long history; however, few studies have examined the demographic basis of their importation and incidence in the wild.\\r\\n\\r\\n2.\\r\\nfor the 1500 grid squares (10\u00d710\\u2009km) that make up england, data on human demographics (population density, numbers of pet shops, garden centres and fish farms), the numbers of non-native freshwater fishes (from consented licences) imported in those grid squares (i.e. propagule pressure), and the reported incidences (in a national database) of non-native fishes in the wild were used to examine spatial relationships between the occurrence of non-native fishes and the demographic factors associated with propagule pressure, as well as to test whether the demographic factors are statistically reliable predictors of the incidence of non-native fishes, and as such surrogate estimators of propagule pressure.\\r\\n\\r\\n3.\\r\\nprincipal coordinates of neighbour matrices analyses, used to generate spatially explicit models, and confirmatory factor analysis revealed that spatial distributions of non-native species in england were significantly related to human population density, garden centre density and fish farm density. human population density and the number of fish imports were identified as the best predictors of propagule pressure.\\r\\n\\r\\n4.\\r\\nhuman population density is an effective surrogate estimator of non-native fish propagule pressure and can be used to predict likely areas of non-native fish introductions. in conjunction with fish movements, where available, human population densities can be used to support biological invasion monitoring programmes across europe (and perhaps globally) and to inform management decisions as regards the prioritization of areas for the control of non-native fish introductions.\\r\\n\\r\\n\\r\\n\\r\\n\u00a9 crown copyright 2010. reproduced with the permission of her majesty's stationery office. published by john wiley & sons, ltd.\"",
            "contribution_ids": [
                "R54997"
            ]
        },
        {
            "instance_id": "R55219xR54987",
            "comparison_id": "R55219",
            "paper_id": "R54987",
            "text": "Hotspots of plant invasion predicted by propagule pressure and ecosystem characteristics aim\\u2002 biological invasions pose a major conservation threat and are occurring at an unprecedented rate. disproportionate levels of invasion across the landscape indicate that propagule pressure and ecosystem characteristics can mediate invasion success. however, most invasion predictions relate to species\u2019 characteristics (invasiveness) and habitat requirements. given myriad invaders and the inability to generalize from single\u2010species studies, more general predictions about invasion are required. we present a simple new method for characterizing and predicting landscape susceptibility to invasion that is not species\u2010specific.",
            "contribution_ids": [
                "R54988"
            ]
        },
        {
            "instance_id": "R55219xR55000",
            "comparison_id": "R55219",
            "paper_id": "R55000",
            "text": "Movement, colonization, and establishment success of a planthopper of prairie potholes, Delphacodes scolochloa (Hemiptera: Delphacidae) abstract 1.\\u2002movement, and particularly the colonisation of new habitat patches, remains one of the least known aspects of the life history and ecology of the vast majority of species. here, a series of experiments was conducted to rectify this problem with delphacodes scolochloa cronin & wilson, a wing\u2010dimorphic planthopper of the north american great plains.",
            "contribution_ids": [
                "R55001"
            ]
        },
        {
            "instance_id": "R55219xR55134",
            "comparison_id": "R55219",
            "paper_id": "R55134",
            "text": "The roles of climate, phylogenetic relatedness, introduction effort, and reproductive traits in the establishment of non-native reptiles and amphibians abstract:\\u2002 we developed a method to predict the potential of non\u2010native reptiles and amphibians (herpetofauna) to establish populations. this method may inform efforts to prevent the introduction of invasive non\u2010native species. we used boosted regression trees to determine whether nine variables influence establishment success of introduced herpetofauna in california and florida. we used an independent data set to assess model performance. propagule pressure was the variable most strongly associated with establishment success. species with short juvenile periods and species with phylogenetically more distant relatives in regional biotas were more likely to establish than species that start breeding later and those that have close relatives. average climate match (the similarity of climate between native and non\u2010native range) and life form were also important. frogs and lizards were the taxonomic groups most likely to establish, whereas a much lower proportion of snakes and turtles established. we used results from our best model to compile a spreadsheet\u2010based model for easy use and interpretation. probability scores obtained from the spreadsheet model were strongly correlated with establishment success as were probabilities predicted for independent data by the boosted regression tree model. however, the error rate for predictions made with independent data was much higher than with cross validation using training data. this difference in predictive power does not preclude use of the model to assess the probability of establishment of herpetofauna because (1) the independent data had no information for two variables (meaning the full predictive capacity of the model could not be realized) and (2) the model structure is consistent with the recent literature on the primary determinants of establishment success for herpetofauna. it may still be difficult to predict the establishment probability of poorly studied taxa, but it is clear that non\u2010native species (especially lizards and frogs) that mature early and come from environments similar to that of the introduction region have the highest probability of establishment.",
            "contribution_ids": [
                "R55135"
            ]
        },
        {
            "instance_id": "R55219xR55139",
            "comparison_id": "R55219",
            "paper_id": "R55139",
            "text": "Habitat, dispersal and propagule pressure control exotic plant infilling within an invaded range \"deep in the heart of a longstanding invasion, an exotic grass is still invading. range infilling potentially has the greatest impact on native communities and ecosystem processes, but receives much less attention than range expansion. \u2018snapshot' studies of invasive plant dispersal, habitat and propagule limitations cannot determine whether a landscape is saturated or whether a species is actively infilling empty patches. we investigate the mechanisms underlying invasive plant infilling by tracking the localized movement and expansion of microstegium vimineum populations from 2009 to 2011 at sites along a 100-km regional gradient in eastern u.s. deciduous forests. we find that infilling proceeds most rapidly where the invasive plants occur in warm, moist habitats adjacent to roads: under these conditions they produce copious seed, the dispersal distances of which increase exponentially with proximity to roadway. invasion then appears limited where conditions are generally dry and cool as propagule pressure tapers off. invasion also is limited in habitats >1 m from road corridors, where dispersal distances decline precipitously. in contrast to propagule and dispersal limitations, we find little evidence that infilling is habitat limited, meaning that as long as m. vimineum seeds are available and transported, the plant generally invades quite vigorously. our results suggest an invasive species continues to spread, in a stratified manner, within the invaded landscape long after first arriving. these dynamics conflict with traditional invasion models that emphasize an invasive edge with distinct boundaries. we find that propagule pressure and dispersal regulate infilling, providing the basis for projecting spread and landscape coverage, ecological effects and the efficacy of containment strategies.\"",
            "contribution_ids": [
                "R55140"
            ]
        },
        {
            "instance_id": "R55219xR55019",
            "comparison_id": "R55219",
            "paper_id": "R55019",
            "text": "The role of propagule pressure, genetic diversity and microsite availability for Senecio vernalis invasion genetic diversity is supposed to support the colonization success of expanding species, in particular in situations where microsite availability is constrained. addressing the role of genetic diversity in plant invasion experimentally requires its manipulation independent of propagule pressure. to assess the relative importance of these components for the invasion of senecio vernalis, we created propagule mixtures of four levels of genotype diversity by combining seeds across remote populations, across proximate populations, within single populations and within seed families. in a first container experiment with constant festuca rupicola density as matrix, genotype diversity was crossed with three levels of seed density. in a second experiment, we tested for effects of establishment limitation and genotype diversity by manipulating festuca densities. increasing genetic diversity had no effects on abundance and biomass of s. vernalis but positively affected the proportion of large individuals to small individuals. mixtures composed from proximate populations had a significantly higher proportion of large individuals than mixtures composed from within seed families only. high propagule pressure increased emergence and establishment of s. vernalis but had no effect on individual growth performance. establishment was favoured in containers with festuca, but performance of surviving seedlings was higher in open soil treatments. for s. vernalis invasion, we found a shift in driving factors from density dependence to effects of genetic diversity across life stages. while initial abundance was mostly linked to the amount of seed input, genetic diversity, in contrast, affected later stages of colonization probably via sampling effects and seemed to contribute to filtering the genotypes that finally grew up. in consequence, when disentangling the mechanistic relationships of genetic diversity, seed density and microsite limitation in colonization of invasive plants, a clear differentiation between initial emergence and subsequent survival to juvenile and adult stages is required.",
            "contribution_ids": [
                "R55020"
            ]
        },
        {
            "instance_id": "R55219xR55039",
            "comparison_id": "R55219",
            "paper_id": "R55039",
            "text": "The Influence of Numbers Released on the Outcome of Attempts to Introduce Exotic Bird Species to New Zealand 1. information on the approximate number of individuals released is available for 47 of the 133 exotic bird species introduced to new zealand in the late 19th and early 20th centuries. of these, 21 species had populations surviving in the wild in 1969-79. the long interval between introduction and assessment of outcome provides a rare opportunity to examine the factors correlated with successful establishment without the uncertainty of long-term population persistence associated with studies of short duration. 2. the probability of successful establishment was strongly influenced by the number of individuals released during the main period of introductions. eight-three per cent of species that had more than 100 individuals released within a 10-year period became established, compared with 21% of species that had less than 100 birds released. the relationship between the probability of establishment and number of birds released was similar to that found in a previous study of introductions of exotic birds to australia. 3. it was possible to look for a within-family influence on the success of introduction of the number of birds released in nine bird families. a positive influence was found within seven families and no effect in two families. this preponderance of families with a positive effect was statistically significant. 4. a significant effect of body weight on the probability of successful establishment was found, and negative effects of clutch size and latitude of origin. however, the statistical significance of these effects varied according to whether comparison was or was not restricted to within-family variation. after applying the bonferroni adjustment to significance levels, to allow for the large number of variables and factors being considered, only the effect of the number of birds released was statistically significant. 5. no significant effects on the probability of successful establishment were apparent for the mean date of release, the minimum number of years in which birds were released, the hemisphere of origin (northern or southern) and the size and diversity of latitudinal distribution of the natural geographical range.",
            "contribution_ids": [
                "R55040",
                "R56989"
            ]
        },
        {
            "instance_id": "R55219xR55114",
            "comparison_id": "R55219",
            "paper_id": "R55114",
            "text": "Propagule pressure hypothesis not supported by an 80-year experiment on woody species invasion ecological filters and availability of propagules play key roles structuring natural communities. propagule pressure has recently been suggested to be a fundamental factor explaining the success or failure of biological introductions. we tested this hypothesis with a remarkable data set on trees introduced to isla victoria, nahuel huapi national park, argentina. more than 130 species of woody plants, many known to be highly invasive elsewhere, were introduced to this island early in the 20th century, as part of an experiment to test their suitability as commercial forestry trees for this region. we obtained detailed data on three estimates of propagule pressure (number of introduced individuals, number of areas where introduced, and number of years during which the species was planted) for 18 exotic woody species. we matched these data with a survey of the species and number of individuals currently invading the island. none of the three estimates of propagule pressure predicted the current pattern of invasion. we suggest that other factors, such as biotic resistance, may be operating to determine the observed pattern of invasion, and that propagule pressure may play a relatively minor role in explaining at least some observed patterns of invasion success and failure.",
            "contribution_ids": [
                "R55115",
                "R55116"
            ]
        },
        {
            "instance_id": "R55219xR55061",
            "comparison_id": "R55219",
            "paper_id": "R55061",
            "text": "Determinants of vertebrate invasion success in Europe and North America \"species that are frequently introduced to an exotic range have a high potential of becoming invasive. besides propagule pressure, however, no other generally strong determinant of invasion success is known. although evidence has accumulated that human affiliates (domesticates, pets, human commensals) also have high invasion success, existing studies do not distinguish whether this success can be completely explained by or is partly independent of propagule pressure. here, we analyze both factors independently, propagule pressure and human affiliation. we also consider a third factor directly related to humans, hunting, and 17 traits on each species' population size and extent, diet, body size, and life history. our dataset includes all 2362 freshwater fish, mammals, and birds native to europe or north america. in contrast to most previous studies, we look at the complete invasion process consisting of (1) introduction, (2) establishment, and (3) spread. in this way, we not only consider which of the introduced species became invasive but also which species were introduced. of the 20 factors tested, propagule pressure and human affiliation were the two strongest determinants of invasion success across all taxa and steps. this was true for multivariate analyses that account for intercorrelations among variables as well as univariate analyses, suggesting that human affiliation influenced invasion success independently of propagule pressure. some factors affected the different steps of the invasion process antagonistically. for example, game species were much more likely to be introduced to an exotic continent than nonhunted species but tended to be less likely to establish themselves and spread. such antagonistic effects show the importance of considering the complete invasion process.\"",
            "contribution_ids": [
                "R55062",
                "R55063",
                "R57248"
            ]
        },
        {
            "instance_id": "R55219xR55146",
            "comparison_id": "R55219",
            "paper_id": "R55146",
            "text": "Propagule pressure drives establishment of introduced freshwater fish: quantitative evidence from an irrigation network propagule pressure is recognized as a fundamental driver of freshwater fish invasions, though few studies have quantified its role. natural experiments can be used to quantify the role of this factor relative to others in driving establishment success. an irrigation network in south africa takes water from an inter-basin water transfer (ibwt) scheme to supply multiple small irrigation ponds. we compared fish community composition upstream, within, and downstream of the irrigation network, to show that this system is a unidirectional dispersal network with a single immigration source. we then assessed the effect of propagule pressure and biological adaptation on the colonization success of nine fish species across 30 recipient ponds of varying age. establishing species received significantly more propagules at the source than did incidental species, while rates of establishment across the ponds displayed a saturation response to propagule pressure. this shows that propagule pressure is a significant driver of establishment overall. those species that did not establish were either extremely rare at the immigration source or lacked the reproductive adaptations to breed in the ponds. the ability of all nine species to arrive at some of the ponds illustrates how long-term continuous propagule pressure from ibwt infrastructure enables range expansion of fishes. the quantitative link between propagule pressure and success and rate of population establishment confirms the driving role of this factor in fish invasion ecology.",
            "contribution_ids": [
                "R55147"
            ]
        },
        {
            "instance_id": "R55219xR55068",
            "comparison_id": "R55219",
            "paper_id": "R55068",
            "text": "The role of propagule pressure in the invasion success of bluegill sunfish, Lepomis macrochirus, in Japan the bluegill sunfish, lepomis macrochirus, is a widespread exotic species in japan that is considered to have originated from 15 fish introduced from guttenberg, iowa, in 1960. here, the genetic and phenotypic traits of japanese populations were examined, together with 11 native populations of the usa using 10 microsatellite markers and six meristic traits. phylogenetic analysis reconfirmed a single origin of japanese populations, among which populations established in the 1960s were genetically close to guttenberg population, keeping high genetic diversity comparable to the ancestral population. in contrast, genetic diversity of later\u2010established populations significantly declined with genetic divergence from the ancestral population. among the 1960s established populations, that from lake biwa showed a significant isolation\u2010by\u2010distance pattern with surrounding populations in which genetic bottlenecks increased with geographical distance from lake biwa. although phenotypic divergence among populations was recognized in both neutral and adaptive traits, pst\u2013fst comparisons showed that it is independent of neutral genetic divergence. divergent selection was suggested in some populations from reservoirs with unstable habitats, while stabilizing selection was dominant. accordingly, many japanese populations of l. macrochirus appear to have derived from lake biwa population, expanding their distribution with population bottlenecks. despite low propagule pressure, the invasion success of l. macrochirus is probably because of its drastic population growth in lake biwa shortly after its introduction, together with artificial transplantations. it not only enabled the avoidance of a loss in genetic diversity but also formed a major gene pool that supported local adaptation with high phenotypic plasticity.",
            "contribution_ids": [
                "R55069"
            ]
        },
        {
            "instance_id": "R55219xR55021",
            "comparison_id": "R55219",
            "paper_id": "R55021",
            "text": "Assessing the Relative Importance of Disturbance, Herbivory, Diversity, and Propagule Pressure in Exotic Plant Invasion the current rate of invasive species introductions is unprecedented, and the dramatic impacts of exotic invasive plants on community and ecosystem properties have been well documented. despite the pressing management implications, the mechanisms that control exotic plant invasion remain poorly understood. several factors, such as disturbance, propagule pressure, species diversity, and herbivory, are widely believed to play a critical role in exotic plant invasions. however, few studies have examined the relative importance of these factors, and little is known about how propagule pressure interacts with various mechanisms of ecological resistance to determine invasion success. we quantified the relative importance of canopy disturbance, propagule pressure, species diversity, and herbivory in determining exotic plant invasion in 10 eastern hemlock forests in pennsylvania and new jersey (usa). use of a maximum-likelihood estimation framework and information theoretics allowed us to quantify the strength of evidence for alternative models of the influence of these factors on changes in exotic plant abundance. in addition, we developed models to determine the importance of interactions between ecosystem properties and propagule pressure. these analyses were conducted for three abundant, aggressive exotic species that represent a range of life histories: alliaria petiolata, berberis thunbergii, and microstegium vimineum. of the four hypothesized determinants of exotic plant invasion considered in this study, canopy disturbance and propagule pressure appear to be the most important predictors of a. petiolata, b. thunbergii, and m. vimineum invasion. herbivory was also found to be important in contributing to the invasion of some species. in addition, we found compelling evidence of an important interaction between propagule pressure and canopy disturbance. this is the first study to demonstrate the dominant role of the interaction between canopy disturbance and propagule pressure in determining forest invasibility relative to other potential controlling factors. the importance of the disturbance-propagule supply interaction, and its nonlinear functional form, has profound implications for the management of exotic plant species populations. improving our ability to predict exotic plant invasions will require enhanced understanding of the interaction between propagule pressure and ecological resistance mechanisms.",
            "contribution_ids": [
                "R55022",
                "R57204"
            ]
        },
        {
            "instance_id": "R55219xR55127",
            "comparison_id": "R55219",
            "paper_id": "R55127",
            "text": "Propagule pressure and climate contribute to the displacement of Linepithema humile by Pachycondyla chinensis identifying mechanisms governing the establishment and spread of invasive species is a fundamental challenge in invasion biology. because species invasions are frequently observed only after the species presents an environmental threat, research identifying the contributing agents to dispersal and subsequent spread are confined to retrograde observations. here, we use a combination of seasonal surveys and experimental approaches to test the relative importance of behavioral and abiotic factors in determining the local co-occurrence of two invasive ant species, the established argentine ant (linepithema humile mayr) and the newly invasive asian needle ant (pachycondyla chinensis emery). we show that the broader climatic envelope of p. chinensis enables it to establish earlier in the year than l. humile. we also demonstrate that increased p. chinensis propagule pressure during periods of l. humile scarcity contributes to successful p. chinensis early season establishment. furthermore, we show that, although l. humile is the numerically superior and behaviorally dominant species at baits, p. chinensis is currently displacing l. humile across the invaded landscape. by identifying the features promoting the displacement of one invasive ant by another we can better understand both early determinants in the invasion process and factors limiting colony expansion and survival.",
            "contribution_ids": [
                "R55128",
                "R56365",
                "R56780"
            ]
        },
        {
            "instance_id": "R55219xR55006",
            "comparison_id": "R55219",
            "paper_id": "R55006",
            "text": "Propagule pressure and persistence in experimental populations \\n average inoculum size and number of introductions are known to have positive effects on population persistence. however, whether these factors affect persistence independently or interact is unknown. we conducted a two-factor experiment in which 112 populations of parthenogenetic\\n daphnia magna \\n were maintained for 41 days to study effects of inoculum size and introduction frequency on: (i) population growth, (ii) population persistence and (iii) time-to-extinction. we found that the interaction of inoculum size and introduction frequency\u2014the immigration rate\u2014affected all three dependent variables, while population growth was additionally affected by introduction frequency. we conclude that for this system the most important aspect of propagule pressure is immigration rate, with relatively minor additional effects of introduction frequency and negligible effects of inoculum size.\\n",
            "contribution_ids": [
                "R55007",
                "R55008"
            ]
        },
        {
            "instance_id": "R56110xR56106",
            "comparison_id": "R56110",
            "paper_id": "R56106",
            "text": "Establishment success of introduced amphibians increases in the presence of congeneric species darwin\u2019s naturalization hypothesis predicts that the success of alien invaders will decrease with increasing taxonomic similarity to the native community. alternatively, shared traits between aliens and the native assemblage may preadapt aliens to their novel surroundings, thereby facilitating establishment (the preadaptation hypothesis). here we examine successful and failed introductions of amphibian species across the globe and find that the probability of successful establishment is higher when congeneric species are present at introduction locations and increases with increasing congener species richness. after accounting for positive effects of congeners, residence time, and propagule pressure, we also find that invader establishment success is higher on islands than on mainland areas and is higher in areas with abiotic conditions similar to the native range. these findings represent the first example in which the preadaptation hypothesis is supported in organisms other than plants and suggest that preadaptation has played a critical role in enabling introduced species to succeed in novel environments.",
            "contribution_ids": [
                "R56107"
            ]
        },
        {
            "instance_id": "R56110xR53276",
            "comparison_id": "R56110",
            "paper_id": "R53276",
            "text": "Learning from failures: testing broad taxonomic hypotheses about plant naturalization \"our understanding of broad taxonomic patterns of plant naturalizations is based entirely on observations of successful naturalizations. omission of the failures, however, can introduce bias by conflating the probabilities of introduction and naturalization. here, we use two comprehensive datasets of successful and failed plant naturalizations in new zealand and australia for a unique, flora-wide comparative test of several major invasion hypotheses. first, we show that some taxa are consistently more successful at naturalizing in these two countries, despite their environmental differences. broad climatic origins helped to explain some of the differences in success rates in the two countries. we further show that species with native relatives were generally more successful in both countries, contrary to darwin's naturalization hypothesis, but this effect was inconsistent among families across the two countries. finally, we show that contrary to studies based on successful naturalizations only, islands need not be inherently more invisible than continents.\"",
            "contribution_ids": [
                "R53277",
                "R56089"
            ]
        },
        {
            "instance_id": "R56110xR56096",
            "comparison_id": "R56110",
            "paper_id": "R56096",
            "text": "Across islands and continents, mammals are more successful invaders than birds many invasive species cause ecological or economic damage, and the fraction of introduced species that become invasive is an important determinant of the overall costs caused by invaders. according to the widely quoted tens rule, about 10% of all introduced species establish themselves and about 10% of these established species become invasive. global taxonomic differences in the fraction of species becoming invasive have not been described. in a global analysis of mammal and bird introductions, i show that both mammals and birds have a much higher invasion success than predicted by the tens rule, and that mammals have a significantly higher success than birds. averaged across islands and continents, 79% of mammals and 50% of birds introduced have established themselves and 63% of mammals and 34% of birds established have become invasive. my analysis also does not support the hypothesis that islands are more susceptible to invaders than continents, as i did not find a significant relationship between invasion success and the size of the island or continent to which the species were introduced. the data set used in this study has a number of limitations, e.g. information on propagule pressure was not available at this global scale, so understanding the mechanisms behind the observed patterns has to be postponed to future studies.",
            "contribution_ids": [
                "R56097",
                "R56994",
                "R56995"
            ]
        },
        {
            "instance_id": "R56110xR54984",
            "comparison_id": "R56110",
            "paper_id": "R54984",
            "text": "Global patterns of introduction effort and establishment success in birds theory suggests that introduction effort (propagule size or number) should be a key determinant of establishment success for exotic species. unfortunately, however, propagule pressure is not recorded for most introductions. studies must therefore either use proxies whose efficacy must be largely assumed, or ignore effort altogether. the results of such studies will be flawed if effort is not distributed at random with respect to other characteristics that are predicted to influence success. we use global data for more than 600 introduction events for birds to show that introduction effort is both the strongest correlate of introduction success, and correlated with a large number of variables previously thought to influence success. apart from effort, only habitat generalism relates to establishment success in birds.",
            "contribution_ids": [
                "R54985",
                "R54986",
                "R56086",
                "R57152"
            ]
        },
        {
            "instance_id": "R56110xR56092",
            "comparison_id": "R56110",
            "paper_id": "R56092",
            "text": "Global assessment of establishment success for amphibian and reptile invaders \\n\\ncontext\\naccording to the tens rule, 10% of introduced species establish themselves.\\n\\naims\\nwe tested this component of the tens rule for amphibians and reptiles globally, in europe and north america, where data are presumably of good quality, and on islands versus continents. we also tested whether there was a taxonomic difference in establishment success between amphibians and reptiles.\\n\\nmethods\\nwe examined data comprising 206 successful and 165 failed introduction records for 161 species of amphibians to 55 locations, and 560 successful and 641 failed introduction records for 469 species of reptiles to 116 locations around the world.\\n\\nkey results\\nglobally, establishment success was not different between amphibians (67%) and reptiles (62%). both means were well above the 10% value predicted by the tens rule. in europe and north america, establishment success was lower, although still higher than 10%. for reptiles, establishment success was higher on islands than on continents. our results question the tens rule and do not show taxonomic differences in establishment success.\\n\\nimplications\\nsimilar to studies on other taxa (birds and mammals), we found that establishment success was generally above 40%. this suggests that we should focus management on reducing the number of herptile species introduced because both reptiles and amphibians have a high likelihood of establishing. as data collection on invasions continue, testing establishment success in light of other factors, including propagule pressure, climate matching and taxonomic classifications, may provide additional insight into which species are most likely to establish in particular areas.\\n\\n",
            "contribution_ids": [
                "R56093"
            ]
        },
        {
            "instance_id": "R56110xR56084",
            "comparison_id": "R56110",
            "paper_id": "R56084",
            "text": "A comparative analysis of the relative success of introduced land birds on islands it has been suggested that more species have been successfully introduced to oceanic islands than to mainland regions. this suggestion has attracted considerable ecological interest and several theoretical mechanisms havebeen proposed. however, few data are available to test the hypotheses directly, and the pattern may simply result from many more species being transported to islands rather than mainland regions. here i test this idea using data for global land birds and present evidence that introductions to islands have a higher probability of success than those to mainland regions. this difference between island and mainland landforms is not consistent among either taxonomic families or biogeographic regions. instead, introduction attempts within the same biogeographic region have been significantly more successful than those that have occurred between two different biogeographic regions. subsequently, the proportion of introduction attempts that have occurred within a single biogeographic region is thus a significant predictor of the observed variability in introduction success. i also show that the correlates of successful island introductions are probably different to those of successful mainland introductions.",
            "contribution_ids": [
                "R56085"
            ]
        },
        {
            "instance_id": "R56110xR56078",
            "comparison_id": "R56110",
            "paper_id": "R56078",
            "text": "Global patterns in threats to vertebrates by biological invasions biological invasions as drivers of biodiversity loss have recently been challenged. fundamentally, we must know where species that are threatened by invasive alien species (ias) live, and the degree to which they are threatened. we report the first study linking 1372 vertebrates threatened by more than 200 ias from the completely revised global invasive species database. new maps of the vulnerability of threatened vertebrates to ias permit assessments of whether ias have a major influence on biodiversity, and if so, which taxonomic groups are threatened and where they are threatened. we found that centres of ias-threatened vertebrates are concentrated in the americas, india, indonesia, australia and new zealand. the areas in which ias-threatened species are located do not fully match the current hotspots of invasions, or the current hotspots of threatened species. the relative importance of biological invasions as drivers of biodiversity loss clearly varies across regions and taxa, and changes over time, with mammals from india, indonesia, australia and europe are increasingly being threatened by ias. the chytrid fungus primarily threatens amphibians, whereas invasive mammals primarily threaten other vertebrates. the differences in ias threats between regions and taxa can help efficiently target ias, which is essential for achieving the strategic plan 2020 of the convention on biological diversity.",
            "contribution_ids": [
                "R56079"
            ]
        },
        {
            "instance_id": "R56945xR56656",
            "comparison_id": "R56945",
            "paper_id": "R56656",
            "text": "Impact of alien plant invaders on pollination networks in two archipelagos mutualistic interactions between plants and animals promote integration of invasive species into native communities. in turn, the integrated invaders may alter existing patterns of mutualistic interactions. here we simultaneously map in detail effects of invaders on parameters describing the topology of both plant-pollinator (bi-modal) and plant-plant (uni-modal) networks. we focus on the invader opuntia spp., a cosmopolitan alien cactus. we compare two island systems: tenerife (canary islands) and menorca (balearic islands). opuntia was found to modify the number of links between plants and pollinators, and was integrated into the new communities via the most generalist pollinators, but did not affect the general network pattern. the plant uni-modal networks showed disassortative linkage, i.e. species with many links tended to connect to species with few links. thus, by linking to generalist natives, opuntia remained peripheral to network topology, and this is probably why native network properties were not affected at least in one of the islands. we conclude that the network analytical approach is indeed a valuable tool to evaluate the effect of invaders on native communities.",
            "contribution_ids": [
                "R56657"
            ]
        },
        {
            "instance_id": "R56945xR56648",
            "comparison_id": "R56945",
            "paper_id": "R56648",
            "text": "Implications of beaver Castor canadensis and trout introductions on native fish in the Cape Horn biosphere reserve, Chile abstract invasive species threaten global biodiversity, but multiple invasions make predicting the impacts difficult because of potential synergistic effects. we examined the impact of introduced beaver castor canadensis, brook trout salvelinus fontinalis, and rainbow trout oncorhynchus mykiss on native stream fishes in the cape horn biosphere reserve, chile. the combined effects of introduced species on the structure of the native freshwater fish community were quantified by electrofishing 28 stream reaches within four riparian habitat types (forest, grassland, shrubland, and beaver-affected habitat) in 23 watersheds and by measuring related habitat variables (water velocity, substrate type, depth, and the percentage of pools). three native stream fish species (puye galaxias maculatus [also known as inanga], aplochiton taeniatus, and a. zebra) were found along with brook trout and rainbow trout, but puye was the only native species that was common and widespread. the reaches affected by beaver impoundmen...",
            "contribution_ids": [
                "R56649"
            ]
        },
        {
            "instance_id": "R56945xR56867",
            "comparison_id": "R56945",
            "paper_id": "R56867",
            "text": "Comparisons of isotopic niche widths of some invasive and indigenous fauna in a South African river \"summary\\r\\n\\r\\nbiological invasions threaten ecosystem integrity and biodiversity, with numerous adverse implications for native flora and fauna. established populations of two notorious freshwater invaders, the snail tarebia granifera and the fish pterygoplichthys disjunctivus, have been reported on three continents and are frequently predicted to be in direct competition with native species for dietary resources.\\r\\nusing comparisons of species' isotopic niche widths and stable isotope community metrics, we investigated whether the diets of the invasive t.\\xa0granifera and p.\\xa0disjunctivus overlapped with those of native species in a highly invaded river. we also attempted to resolve diet composition for both species, providing some insight into the original pathway of invasion in the nseleni river, south africa.\\r\\nstable isotope metrics of the invasive species were similar to or consistently mid-range in comparison with their native counterparts, with the exception of markedly more uneven spread in isotopic space relative to indigenous species. dietary overlap between the invasive p.\\xa0disjunctivus and native fish was low, with the majority of shared food resources having overlaps of <0.26. the invasive t.\\xa0granifera showed effectively no overlap with the native planorbid snail. however, there was a high degree of overlap between the two invasive species (\u02dc0.86).\\r\\nbayesian mixing models indicated that detrital mangrove barringtonia racemosa leaves contributed the largest proportion to p.\\xa0disjunctivus diet (0.12\u20130.58), while the diet of t.\\xa0granifera was more variable with high proportions of detrital eichhornia crassipes (0.24\u20130.60) and azolla filiculoides (0.09\u20130.33) as well as detrital barringtonia racemosa leaves (0.00\u20130.30).\\r\\noverall, although the invasive t.\\xa0granifera and p.\\xa0disjunctivus were not in direct competition for dietary resources with native species in the nseleni river system, their spread in isotopic space suggests they are likely to restrict energy available to higher consumers in the food web. establishment of these invasive populations in the nseleni river is thus probably driven by access to resources unexploited or unavailable to native residents.\"",
            "contribution_ids": [
                "R56868"
            ]
        },
        {
            "instance_id": "R56945xR56915",
            "comparison_id": "R56945",
            "paper_id": "R56915",
            "text": "Positive plant and bird diversity response to experimental deer population reduction after decades of uncontrolled browsing during the 20th century, deer (family cervidae), both native and introduced populations, dramatically increased in abundance in many parts of the world and became seen as major threats to biodiversity in forest ecosystems. here, we evaluated the consequences that restoring top\u2010down herbivore population control has on plants and birds.",
            "contribution_ids": [
                "R56916"
            ]
        },
        {
            "instance_id": "R56945xR56555",
            "comparison_id": "R56945",
            "paper_id": "R56555",
            "text": "Exotic weed invasion increases the susceptibility of native plants to attack by a biocontrol herbivore landscape change has great, yet infrequently measured, potential to influence the susceptibility of natural systems to invasive species impacts. we quantified attack by an invasive biological control weevil (rhinocyllus conicus) on native thistles in relation to two types of landscape change: agricultural intensification and invasion by an exotic thistle, carduus nutans, the original target of biological control. weevil egg load was measured on native thistles in three landscape types: (1) agriculture dominated, (2) grassland dominated with exotic thistles, and, (3) grassland dominated without exotic thistles. we found no difference in egg load on native thistles within grassland landscapes without exotic thistles vs. within agricultural landscapes, suggesting that agricultural intensification per se does not influence levels of weevil attack. however, attack on the native cirsium undulatum increased significantly (three- to fivefold) with increasing exotic thistle density. within-patch exotic thistle density explained >50% of the variation in both the intensity and frequency of weevil attack. since r. conicus feeding dramatically reduces seed production, exotic thistles likely exert a negative indirect effect on native thistles. this study provides some of the first empirical evidence that invasion by an exotic plant can increase attack of native plants by shared insect herbivores.",
            "contribution_ids": [
                "R56556"
            ]
        },
        {
            "instance_id": "R56945xR56764",
            "comparison_id": "R56945",
            "paper_id": "R56764",
            "text": "Cane toads on cowpats: commercial livestock production facilitates toad invasion in tropical Australia habitat disturbance and the spread of invasive organisms are major threats to biodiversity, but the interactions between these two factors remain poorly understood in many systems. grazing activities may facilitate the spread of invasive cane toads (rhinella marina) through tropical australia by providing year-round access to otherwise-seasonal resources. we quantified the cane toad\u2019s use of cowpats (feces piles) in the field, and conducted experimental trials to assess the potential role of cowpats as sources of prey, water, and warmth for toads. our field surveys show that cane toads are found on or near cowpats more often than expected by chance. field-enclosure experiments show that cowpats facilitate toad feeding by providing access to dung beetles. cowpats also offer moist surfaces that can reduce dehydration rates of toads and are warmer than other nearby substrates. livestock grazing is the primary form of land use over vast areas of australia, and pastoral activities may have contributed substantially to the cane toad\u2019s successful invasion of that continent.",
            "contribution_ids": [
                "R56765"
            ]
        },
        {
            "instance_id": "R56945xR56559",
            "comparison_id": "R56945",
            "paper_id": "R56559",
            "text": "Exotic species replacement: shifting dominance of dreissenid mussels in the Soulanges Canal, upper St. Lawrence River, Canada abstract during the early 1990s, 2 eurasian macrofouling mollusks, the zebra mussel dreissena polymorpha and the quagga mussel d. bugensis, colonized the freshwater section of the st. lawrence river and decimated native mussel populations through competitive interference. for several years, zebra mussels dominated molluscan biomass in the river; however, quagga mussels have increased in abundance and are apparently displacing zebra mussels from the soulanges canal, west of the island of montreal. the ratio of quagga mussel biomass to zebra mussel biomass on the canal wall is correlated with depth, and quagga mussels constitute >99% of dreissenid biomass on bottom sediments. this dominance shift did not substantially affect the total dreissenid biomass, which has remained at 3 to 5 kg fresh mass /m2 on the canal walls for nearly a decade. the mechanism for this shift is unknown, but may be related to a greater bioenergetic efficiency for quaggas, which attained larger shell sizes than zebra mussels at all depths. similar events have occurred in the lower great lakes where zebra mussels once dominated littoral macroinvertebrate biomass, demonstrating that a well-established and prolific invader can be replaced by another introduced species without prior extinction.",
            "contribution_ids": [
                "R56560"
            ]
        },
        {
            "instance_id": "R56945xR56883",
            "comparison_id": "R56945",
            "paper_id": "R56883",
            "text": "The positive interaction between two nonindigenous species, Casuarina (Casuarina equisetifolia) and Acacia (Acacia mangium), in the tropical coastal zone of south China: stand dynamics and soil nutrients the role of mixed forests in tropical coastal south china is unclear due to a long history of afforestation with a casuarina (casuarina equisetifolia) monoculture. in this study, we determined how the stand dynamics and soil nutrients in monoculture stands of casuarina equisetifolia were influenced by acacia (acacia mangium), a fast-growing pioneer species, when the two tree species were combined in two initial proportions. we also compared the canopy conditions of mixed and monoculture stands of c. equisetifolia at the young stage. over a period of ten years, the density of stems was relatively low in c. equisetifolia \u00d7acacia mangium mixed stands compared to c. equisetifolia monoculture stands. by contrast, the aboveground biomass, understory diversity and soil nutrients were relatively high in c. equisetifolia \u00d7a. mangium mixed stands, particularly when the initial mixing proportion of a. mangium was greater. moreover, c. equisetifolia can protect a. mangium in the windy coastal environment by ensuring evenly distributed crown growth, intact canopy conditions, and high leaf area index (lai) during the young stage. in conclusion, the two species had a positive interaction in the mixed forests, which suggests that coastal conservation managers need to shift from their traditional focus on c. equisetifolia single-species afforestation to multi-tree species mixed afforestation.",
            "contribution_ids": [
                "R56884"
            ]
        },
        {
            "instance_id": "R56945xR56811",
            "comparison_id": "R56945",
            "paper_id": "R56811",
            "text": "Niche differentiation among invasive crayfish and their impacts on ecosystem structure and functioning \"1.many aquatic ecosystems sustain multiple invasive species and interactions among them have important implications for ecosystem structure and functioning. here, we examine interactions among two pairs of invasive crayfish species because of their close proximity and thus chance of sympatric populations in the near future within the thames catchment, u.k. (signal, pacifastacus leniusculus and virile crayfish, orconectes virilis within a river system; red swamp, procambarus clarkii and turkish crayfish, astacus leptodactylus found within a suite of ponds). we address two questions: do sympatric invasive crayfish occupy a smaller niche than their allopatric counterparts due to potential resource competition? and do interactions among invasive species amplify or mitigate one another's impacts on the ecosystem? 2.two fully factorial mesocosm experiments (one for each crayfish pair) were used to investigate crayfish diet and their impact on benthic invertebrate community structure, benthic algal standing stock and leaf litter decomposition rates in allopatric and sympatric populations, compared with a crayfish-free control. we used stable isotope analysis to examine crayfish diet in the mesocosms and in allopatric populations of each species in the thames catchment.\\xa03.isotopic niche width did not vary significantly between allopatric and sympatric populations of crayfish in the mesocosm experiments, and isotopic niche partitioning in all the wild populations suggests the invaders can coexist.\\xa04.all four species altered benthic invertebrate community structure but with differing functional effects, often mediated via trophic cascades. red swamp crayfish predation upon snails evidently promoted benthic algal standing stock via reduction in grazing pressure. however, a trophic cascade whereby the crayfish consumed native invertebrate shredders, causing a reduction in net leaf litter decomposition, was decoupled by red swamp and signal crayfish since they consumed leaf litter directly and thus moderated the cascade to a trickle when in sympatry with turkish or virile crayfish, respectively.\\xa05.benthic invertebrate predator abundance was significantly reduced by sympatric red swamp and turkish crayfish but not independently when in allopatry, indicating an amplified effect overall when in sympatry.\\xa06.our results suggest that the combined effect of multiple invasions on the ecosystem can reflect either an additive effect of their independent impacts or an amplified effect, which is greater than the sum of their independent impacts. a lack of general pattern in their effects makes any potential management strategy more complex.\"",
            "contribution_ids": [
                "R56812"
            ]
        },
        {
            "instance_id": "R56945xR56760",
            "comparison_id": "R56945",
            "paper_id": "R56760",
            "text": "Facilitation and competition among invasive plants: A field experiment with alligatorweed and water hyacinth ecosystems that are heavily invaded by an exotic species often contain abundant populations of other invasive species. this may reflect shared responses to a common factor, but may also reflect positive interactions among these exotic species. armand bayou (pasadena, tx) is one such ecosystem where multiple species of invasive aquatic plants are common. we used this system to investigate whether presence of one exotic species made subsequent invasions by other exotic species more likely, less likely, or if it had no effect. we performed an experiment in which we selectively removed exotic rooted and/or floating aquatic plant species and tracked subsequent colonization and growth of native and invasive species. this allowed us to quantify how presence or absence of one plant functional group influenced the likelihood of successful invasion by members of the other functional group. we found that presence of alligatorweed (rooted plant) decreased establishment of new water hyacinth (free-floating plant) patches but increased growth of hyacinth in established patches, with an overall net positive effect on success of water hyacinth. water hyacinth presence had no effect on establishment of alligatorweed but decreased growth of existing alligatorweed patches, with an overall net negative effect on success of alligatorweed. moreover, observational data showed positive correlations between hyacinth and alligatorweed with hyacinth, on average, more abundant. the negative effect of hyacinth on alligatorweed growth implies competition, not strong mutual facilitation (invasional meltdown), is occurring in this system. removal of hyacinth may increase alligatorweed invasion through release from competition. however, removal of alligatorweed may have more complex effects on hyacinth patch dynamics because there were strong opposing effects on establishment versus growth. the mix of positive and negative interactions between floating and rooted aquatic plants may influence local population dynamics of each group and thus overall invasion pressure in this watershed.",
            "contribution_ids": [
                "R56761"
            ]
        },
        {
            "instance_id": "R56945xR56577",
            "comparison_id": "R56945",
            "paper_id": "R56577",
            "text": "Functional diversity of mammalian predators and extinction in island birds the probability of a bird species going extinct on oceanic islands in the period since european colonization is predicted by the number of introduced predatory mammal species, but the exact mechanism driving this relationship is unknown. one possibility is that larger exotic predator communities include a wider array of predator functional types. these predator communities may target native bird species with a wider range of behavioral or life history characteristics. we explored the hypothesis that the functional diversity of the exotic predators drives bird species extinctions. we also tested how different combinations of functionally important traits of the predators explain variation in extinction probability. our results suggest a unique impact of each introduced mammal species on native bird populations, as opposed to a situation where predators exhibit functional redundancy. further, the impact of each additional predator may be facilitated by those already present, suggesting the possibility of \u201cinvasional meltdown.\u201d",
            "contribution_ids": [
                "R56578"
            ]
        },
        {
            "instance_id": "R56945xR56909",
            "comparison_id": "R56945",
            "paper_id": "R56909",
            "text": "Over-invasion in a freshwater ecosystem: newly introduced virile crayfish (Orconectes virilis) outcompete established invasive signal crayfish (Pacifastacus leniusculus) abstract biological invasions are a key threat to freshwater biodiversity, and identifying determinants of invasion success is a global conservation priority. the establishment of introduced species is predicted to be hindered by pre-existing, functionally similar invasive species. over a five-year period we, however, find that in the river lee (uk), recently introduced non-native virile crayfish (orconectes virilis) increased in range and abundance, despite the presence of established alien signal crayfish (pacifastacus leniusculus). in regions of sympatry, virile crayfish had a detrimental effect on signal crayfish abundance but not vice versa. competition experiments revealed that virile crayfish were more aggressive than signal crayfish and outcompeted them for shelter. together, these results provide early evidence for the potential over-invasion of signal crayfish by competitively dominant virile crayfish. based on our results and the limited distribution of virile crayfish in europe, we recommend that efforts to contain them within the lee catchment be implemented immediately.",
            "contribution_ids": [
                "R56910"
            ]
        },
        {
            "instance_id": "R56945xR56644",
            "comparison_id": "R56945",
            "paper_id": "R56644",
            "text": "Epiphytic macroinvertebrate communities on Eurasian watermilfoil (Myriophyllum spicatum) and native milfoils Myriophyllum sibericum and Myriophyllum alterniflorum in eastern North America aquatic macrophytes play an important role in the survival and proliferation of invertebrates in freshwater ecosystems. epiphytic invertebrate communities may be altered through the replacement of native macrophytes by exotic macrophytes, even when the macrophytes are close relatives and have similar morphology. we sampled an invasive exotic macrophyte, eurasian watermilfoil ( myriophyllum spicatum ), and native milfoils myriophyllum sibericum and myriophyllum alterniflorum in four bodies of water in southern quebec and upstate new york during the summer of 2005. within each waterbody, we compared the abundance, diversity, and community composition of epiphytic macroinvertebrates on exotic and native myriophyllum. in general, both m. sibericum and m. alterniflorum had higher invertebrate diversity and higher invertebrate biomass and supported more gastropods than the exotic m. spicatum. in late summer, invertebrate density tended to be higher on m. sibericum than on m. spicatum, but lower on m. alterniflorum than on m. spicatum. our results demonstrate that m. spicatum supports macroinvertebrate communities that may differ from those on structurally similar native macrophytes, although these differences vary across sites and sampling dates. thus, the replacement of native milfoils by m. spicatum may have indirect effects on aquatic food webs.",
            "contribution_ids": [
                "R56645"
            ]
        },
        {
            "instance_id": "R56945xR56569",
            "comparison_id": "R56945",
            "paper_id": "R56569",
            "text": "Recent biological invasion may hasten invasional meltdown by accelerating historical introductions biological invasions are rapidly producing planet-wide changes in biodiversity and ecosystem function. in coastal waters of the u.s., &gt;500 invaders have become established, and new introductions continue at an increasing rate. although most species have little impact on native communities, some initially benign introductions may occasionally turn into damaging invasions, although such introductions are rarely documented. here, i demonstrate that a recently introduced crab has resulted in the rapid spread and increase of an introduced bivalve that had been rare in the system for nearly 50 yr. this increase has occurred through the positive indirect effects of predation by the introduced crab on native bivalves. i used field and laboratory experiments to show that the mechanism is size-specific predation interacting with the different reproductive life histories of the native (protandrous hermaphrodite) and the introduced (dioecious) bivalves. these results suggest that positive interactions among the hundreds of introduced species that are accumulating in coastal systems could result in the rapid transformation of previously benign introductions into aggressively expanding invasions. even if future management efforts reduce the number of new introductions, given the large number of species already present, there is a high potential for positive interactions to produce many future management problems. given that invasional meltdown is now being documented in natural systems, i suggest that coastal systems may be closer to this threshold than currently believed.",
            "contribution_ids": [
                "R56570"
            ]
        },
        {
            "instance_id": "R56945xR56626",
            "comparison_id": "R56945",
            "paper_id": "R56626",
            "text": "Enemy release or invasional meltdown? Deer preference for exotic and native trees on Isla Victoria, Argentina \"how interactions between exotic species affect invasion impact is a fundamental issue on both theoretical and applied grounds. exotics can facilitate establishment and invasion of other exotics (invasional meltdown) or they can restrict them by re-establishing natural population control (as predicted by the enemy- release hypothesis). we studied forest invasion on an argentinean island where 43 species of pinaceae, including 60% of the world's recorded invasive pinaceae, were introduced c. 1920 but where few species are colonizing pristine areas. in this area two species of palearctic deer, natural enemies of most pinaceae, were introduced 80 years ago. expecting deer to help to control the exotics, we conducted a cafeteria experiment to assess deer preferences among the two dominant native species (a conifer, austrocedrus chilensis, and a broadleaf, nothofagus dombeyi) and two widely introduced exotic tree species (pseudotsuga menziesii and pinus ponderosa). deer browsed much more intensively on native species than on exotic conifers, in terms of number of individuals attacked and degree of browsing. deer preference for natives could potentially facilitate invasion by exotic pines. however, we hypothesize that the low rates of invasion currently observed can result at least partly from high densities of exotic deer, which, despite their preference for natives, can prevent establishment of both native and exotic trees. other factors, not mutually exclusive, could produce the observed pattern. our results underscore the difficulty of predicting how one introduced species will effect impact of another one.\"",
            "contribution_ids": [
                "R56627"
            ]
        },
        {
            "instance_id": "R56945xR56678",
            "comparison_id": "R56945",
            "paper_id": "R56678",
            "text": "Effects of introduced Canada geese (Branta canadensis) on native plant communities of the southern gulf islands, British Columbia abstract: \\n recent experiments suggest that introduced, non-migratory canada geese (branta canadensis) may be facilitating the spread of exotic grasses and decline of native plant species abundance on small islets in the georgia basin, british columbia, which otherwise harbour outstanding examples of threatened maritime meadow ecosystems. we examined this idea by testing if the presence of geese predicted the abundance of exotic grasses and native competitors at 2 spatial scales on 39 islands distributed throughout the southern gulf and san juan islands of canada and the united states, respectively. at the plot level, we found significant positive relationships between the percent cover of goose feces and exotic annual grasses. however, this trend was absent at the scale of whole islands. because rapid population expansion of introduced geese in the region only began in the 1980s, our results are consistent with the hypothesis that the deleterious effects of geese on the cover of exotic annual grasses have yet to proceed beyond the local scale, and that a window of opportunity now exists in which to implement management strategies to curtail this emerging threat to native ecosystems. research is now needed to test if the removal of geese results in the decline of exotic annual grasses.",
            "contribution_ids": [
                "R56679"
            ]
        },
        {
            "instance_id": "R56945xR56567",
            "comparison_id": "R56945",
            "paper_id": "R56567",
            "text": "Positive effects of a dominant invader on introduced and native mudflat species \"many introduced species have negative impacts on native species, but some develop positive interactions with both native species and other invaders. facilitation between invaders may lead to an overall acceleration in invasion success and impacts. mechanisms of facilitation include habitat alteration, or ecosystem engineering, and trophic interactions. in marine systems, only a handful of positive effects have been reported for invading species. in an unusual ne pacific marine assemblage dominated by 5 conspicuous invaders and 2 native species, we identified positive effects of the most abundant invader, the asian hornsnail batillaria attramentaria, on all other species. b. attramentaria reached densities >1400 m -2 , providing an average of 600 cm of hard substrate per m 2 on this mudflat. its shells were used as habitat almost exclusively by the introduced atlantic slipper shell crepidula convexa, the introduced asian anemone diadumene lineata, and 2 native hermit crabs pagurus hirsutiusculus and p. granosimanus. in addition, manipulative experiments showed that the abundance of the mudsnail nassarius fraterculus and percentage cover of the eelgrass zostera japonica, both introduced from the nw pacific, increased significantly in the presence of b. attramentaria. the most likely mechanisms for these facilitations are indirect grazing effects and bioturbation, respectively. since the precise arrival dates of all these invaders are unknown, the role of b. attramentaria's positive interactions in their initial invasion success is unknown. nevertheless, by providing habitat for 2 non-native epibionts and 2 native species, and by facilitating 2 other invaders, the non-native b. attramentaria enhances the level of invasion by all 6 species.\"",
            "contribution_ids": [
                "R56568"
            ]
        },
        {
            "instance_id": "R56945xR55127",
            "comparison_id": "R56945",
            "paper_id": "R55127",
            "text": "Propagule pressure and climate contribute to the displacement of Linepithema humile by Pachycondyla chinensis identifying mechanisms governing the establishment and spread of invasive species is a fundamental challenge in invasion biology. because species invasions are frequently observed only after the species presents an environmental threat, research identifying the contributing agents to dispersal and subsequent spread are confined to retrograde observations. here, we use a combination of seasonal surveys and experimental approaches to test the relative importance of behavioral and abiotic factors in determining the local co-occurrence of two invasive ant species, the established argentine ant (linepithema humile mayr) and the newly invasive asian needle ant (pachycondyla chinensis emery). we show that the broader climatic envelope of p. chinensis enables it to establish earlier in the year than l. humile. we also demonstrate that increased p. chinensis propagule pressure during periods of l. humile scarcity contributes to successful p. chinensis early season establishment. furthermore, we show that, although l. humile is the numerically superior and behaviorally dominant species at baits, p. chinensis is currently displacing l. humile across the invaded landscape. by identifying the features promoting the displacement of one invasive ant by another we can better understand both early determinants in the invasion process and factors limiting colony expansion and survival.",
            "contribution_ids": [
                "R55128",
                "R56365",
                "R56780"
            ]
        },
        {
            "instance_id": "R56945xR56793",
            "comparison_id": "R56945",
            "paper_id": "R56793",
            "text": "Assessing the potential to restore historic grazing ecosystems with tortoise ecological replacements the extinction of large herbivores, often keystone species, can dramatically modify plant communities and impose key biotic thresholds that may prevent an ecosystem returning to its previous state and threaten native biodiversity. a potentially innovative, yet controversial, landscape\u2010based long\u2010term restoration approach is to replace missing plant\u2010herbivore interactions with non\u2010native herbivores. aldabran giant (aldabrachelys gigantea) and madagascan radiated (astrochelys radiata) tortoises, taxonomically and functionally similar to the extinct mauritian giant tortoises (cylindraspis spp.), were introduced to round island, mauritius, in 2007 to control the non\u2010native plants that were threatening persistence of native species. we monitored the response of the plant community to tortoise grazing for 11 months in enclosures before the tortoises were released and, compared the cost of using tortoises as weeders with the cost of using manual labor. at the end of this period, plant biomass; vegetation height and cover; and adult, seedling, flower, and seed abundance were 3\u2013136 times greater in adjacent control plots than in the tortoise enclosures. after their release, the free\u2010roaming tortoises grazed on most non\u2010native plants and significantly reduced vegetation cover, height, and seed production, reflecting findings from the enclosure study. the tortoises generally did not eat native species, although they consumed those native species that increased in abundance following the eradication of mammalian herbivores. our results suggest that introduced non\u2010native tortoises are a more cost\u2010effective approach to control non\u2010native vegetation than manual weeding. numerous long\u2010term outcomes (e.g., change in species composition and soil seed bank) are possible following tortoise releases. monitoring and adaptive management are needed to ensure that the replacement herbivores promote the recovery of native plants.",
            "contribution_ids": [
                "R56794"
            ]
        },
        {
            "instance_id": "R56945xR56545",
            "comparison_id": "R56945",
            "paper_id": "R56545",
            "text": "Ecological traits of the amphipod invader Dikerogammarus villosus on a mesohabitat scale \"since 1995, dikerogammarus villosus sowinski, a ponto-caspian amphi- pod species, has been invading most of western europe' s hydrosystems. d. villosus geographic extension and quickly increasing population density has enabled it to become a major component of macrobenthic assemblages in recipient ecosystems. the ecological characteristics of d. villosus on a mesohabitat scale were investigated at a station in the moselle river. this amphipod is able to colonize a wide range of sub- stratum types, thus posing a threat to all freshwater ecosystems. rivers whose domi- nant substratum is cobbles and which have tree roots along the banks could harbour particularly high densities of d. villosus. a relationship exists between substratum par- ticle size and the length of the individuals, and spatial segregation according to length was shown. this allows the species to limit intra-specific competition between genera- tions while facilitating reproduction. a strong association exists between d. villosus and other ponto-caspian species, such as dreissena polymorpha and corophium cur- vispinum, in keeping with invasional meltdown theory. four taxa (coenagrionidae, calopteryx splendens, corophium curvispinum and gammarus pulex ) exhibited spa- tial niches that overlap significantly that of d. villosus. according to the predatory be- haviour of the newcomer, their populations may be severely impacted.\"",
            "contribution_ids": [
                "R56546"
            ]
        },
        {
            "instance_id": "R56945xR56638",
            "comparison_id": "R56945",
            "paper_id": "R56638",
            "text": "Positive interactions among plant species for pollinator service: assessing the 'magnet species' concept with invasive species plants with poorly attractive flowers or with little floral rewards may have inadequate pollinator service, which in turn reduces seed output. however, pollinator service of less attractive species could be enhanced when they are associated with species with highly attractive flowers (so called \u2018magnet-species\u2019). although several studies have reported the magnet species effect, few of them have evaluated whether this positive interaction result in an enhancement of the seed output for the beneficiary species. here, we compared pollinator visitation rates and seed output of the invasive annual species carduus pycnocephalus when grow associated with shrubs of the invasive lupinus arboreus and when grow alone, and hypothesized that l. arboreus acts as a magnet species for c. pycnocephalus. results showed that c. pycnocephalus individuals associated with l. arboreus had higher pollinator visitation rates and higher seed output than individuals growing alone. the higher visitation rates of c. pycnocephalus associated to l. arboreus were maintained after accounting for flower density, which consistently supports our hypothesis on the magnet species effect of l. arboreus. given that both species are invasives, the facilitated pollination and reproduction of c. pycnocephalus by l. arboreus could promote its naturalization in the community, suggesting a synergistic invasional process contributing to an \u2018invasional meltdown\u2019. the magnet effect of lupinus on carduus found in this study seems to be one the first examples of indirect facilitative interactions via increased pollination among invasive species.",
            "contribution_ids": [
                "R56639"
            ]
        },
        {
            "instance_id": "R56945xR56847",
            "comparison_id": "R56945",
            "paper_id": "R56847",
            "text": "Cascading ecological effects caused by the establishment of the emerald ash borer Agrilus planipennis (Coleoptera: Buprestidae) in European Russia emerald ash borer, agrilus planipennis, is a destructive invasive forest pest in north america and european russia. this pest species is rapidly spreading in european russia and is likely to arrive in other countries soon. the aim is to analyze the ecological consequences of the establishment of this pest in european russia and investigate (1) what other xylophagous beetles develop on trees affected by a. planipennis, (2) how common is the parasitoid of the emerald ash borer spathius polonicus (hymenoptera: braconidae: doryctinae) and what is the level of parasitism by this species, and (3) how susceptible is the native european ash species fraxinus excelsior to a. planipennis. a survey of approximately 1000 fraxinus pennsylvanica trees damaged by a. planipennis in 13 localities has shown that hylesinus varius (coleoptera: curculionidae: scolytinae), tetrops starkii (coleoptera: cerambycidae) and agrilus convexicollis (coleoptera: buprestidae) were common on these trees. spathius polonicus is frequently recorded. about 50 percent of late instar larvae of a. planipennis sampled were parasitized by s. polonicus. maps of the distributions of t. starkii, a. convexicollis and s. polonicus before and after the establishment of a. planipennis in european russia were compiled. it is hypothesized that these species, which are native to the west palaearctic, spread into central european russia after a. planipennis became established there. current observations confirm those of previous authors that native european ash fraxinus excelsior is susceptible to a. planipennis, increasing the threat posed by this pest. the establishment of a. planipennis has resulted in a cascade of ecological effects, such as outbreaks of other xylophagous beetles in a. planipennis-infested trees. it is likely that the propagation of s. polonicus will reduce the incidence of outbreaks of a. planipennis.",
            "contribution_ids": [
                "R56848"
            ]
        },
        {
            "instance_id": "R56945xR56803",
            "comparison_id": "R56945",
            "paper_id": "R56803",
            "text": "Experimental evidence for indirect facilitation among invasive plants facilitation among species may promote non\u2010native plant invasions through alteration of environmental conditions, enemies or mutualists. however, the role of non\u2010trophic indirect facilitation in invasions has rarely been examined. we used a long\u2010term field experiment to test for indirect facilitation by invasions of microstegium vimineum (stiltgrass) on a secondary invasion of alliaria petiolata (garlic mustard) by introducing alliaria seed into replicated plots previously invaded experimentally by microstegium. alliaria more readily colonized control plots without microstegium but produced almost seven times more biomass and nearly four times as many siliques per plant in microstegium\u2010invaded plots. improved performance of alliaria in microstegium\u2010invaded plots compared to control plots overwhelmed differences in total number of plants such that, on average, invaded plots contained 327% greater total alliaria biomass and 234% more total siliques compared to control plots. the facilitation of alliaria in microstegium\u2010invaded plots was associated with an 85% reduction in the biomass of resident species at the peak of the growing season and significantly greater light availability in microstegium\u2010invaded than control plots early in the growing season. synthesis. our results demonstrate that an initial plant invasion associated with suppression of resident species and increased resource availability can facilitate a secondary plant invasion. such positive interactions among species with similar habitat requirements, but offset phenologies, may exacerbate invasions and their impacts on native ecosystems.",
            "contribution_ids": [
                "R56804"
            ]
        },
        {
            "instance_id": "R56945xR56535",
            "comparison_id": "R56945",
            "paper_id": "R56535",
            "text": "Invasion of pollination networks on oceanic islands: importance of invader complexes and endemic super generalists abstract. the structure of pollination networks is described for two oceanic islands, the azorean flores and the mauritian ile aux aigrettes. at each island site, all interactions between endemic, non\u2010endemic native and introduced plants and pollinators were mapped. linkage level, i.e. number of species interactions per species, was significantly higher for endemic species than for non\u2010endemic native and introduced species. linkage levels of the two latter categories were similar. nine types of interaction may be recognized among endemic, non\u2010endemic native and introduced plants and pollinators. similar types had similar frequencies in the two networks. specifically, we looked for the presence of \u2018invader complexes\u2019 of mutualists, defined as groups of introduced species interacting more with each other than expected by chance and thus facilitating each other\u2019s establishment. on both islands, observed frequencies of interactions between native (endemic and non\u2010endemic) and introduced pollinators and plants differed from random. introduced pollinators and plants interacted less than expected by chance. thus, the data did not support the existence of invader complexes. instead, our study suggested that endemic super\u2010generalist species, i.e. pollinators or plant species with a very wide pollination niche, include new invaders in their set of food plants or pollinators and thereby improve establishment success of the invaders. reviewing other studies, super generalists seem to be a widespread island phenomenon, i.e. island pollination networks include one or a few species with a very high generalization level compared to co\u2010occurring species. low density of island species may lead to low interspecific competition, high abundance and ultimately wide niches and super generalization.",
            "contribution_ids": [
                "R56536"
            ]
        },
        {
            "instance_id": "R56945xR56927",
            "comparison_id": "R56945",
            "paper_id": "R56927",
            "text": "Species diversity, phenology, and temporal flight patterns of Hypothenemus Pygmy Borers (Coleoptera: Curculionidae: Scolytinae) in South Florida abstract hypothenemus are some of the most common and diverse bark beetles in natural as well as urban habitats, particularly in tropical and subtropical regions. despite their ecological success and ubiquitous presence, very little is known about the habits of this genus. this study aimed to understand species diversity and daily and seasonal trends in host-seeking flight patterns of hypothenemus in a suburban environment by systematic collections with ethanol baiting over a 15-mo period in south florida. a total of 481 specimens were collected and identified as eight species, most of them nonnative. hypothenemus formed the overwhelming majority of bark beetles (scolytinae) collected, confirming the dominance of the genus in urban environments. hypothenemus brunneus (hopkins) and hypothenemus seriatus (eichhoff) were most abundant, comprising 74% of the capture. rarefaction showed that the sample was sufficient to characterize the local diversity and composition. the seasonal pattern in hypothenemus capture was positively correlated to day-time temperature, not to season as in most temperate scolytinae. another significant observation in the community dynamics was the synchronized occurrence of two common species (h. birmanus and h. javanus), unrelated to season. hypothenemus were predominantly diurnal with a broad flight window. females flew as early as 11: 00 hours (edst), with peak flight occurring at 15: 00 hours, significantly earlier than flight patterns of most other scolytinae. surprisingly, male hypothenemus were frequently collected, despite their lack of functional wings. several potential explanations are discussed. this is the first study into the ecology of an entire community of the twig-feeding hypothenemus.",
            "contribution_ids": [
                "R56928"
            ]
        },
        {
            "instance_id": "R56945xR56939",
            "comparison_id": "R56945",
            "paper_id": "R56939",
            "text": "Foraging behavior interactions between two non-native social wasps, Vespula germanica and V. vulgaris (Hymenoptera: Vespidae): implications for invasion success? vespula vulgaris is an invasive scavenging social wasp that has very recently arrived in patagonia (argentina), a territory previously invaded \u2013 35 yrs earlier \u2013 by another wasp, vespula germanica. although v. vulgaris wasps possess features that could be instrumental in overcoming obstacles through several invasion stages, the presence of preestablished populations of v. germanica could affect their success. we studied the potential role played by v. germanica on the subsequent invasion process of v. vulgaris wasps in patagonia by focusing on the foraging interaction between both species. this is because food searching and exploitation are likely to overlap strongly among vespula wasps. we carried out choice tests where two types of baits were presented in a pairwise manner. we found experimental evidence supporting the hypothesis that v. germanica and v. vulgaris have an asymmetrical response to baits with stimuli simulating the presence of each other. v. germanica avoided baits with either visual or olfactory cues indicating the v. vulgaris presence. however, v. vulgaris showed no preference between baits with or lacking v. germanica stimuli. these results suggest that the presence of an established population of v. germanica may not contribute to added biotic resistance to v. vulgaris invasion.",
            "contribution_ids": [
                "R56940"
            ]
        },
        {
            "instance_id": "R56945xR56547",
            "comparison_id": "R56945",
            "paper_id": "R56547",
            "text": "Invasional 'meltdown' on an oceanic island islands can serve as model systems for understanding how biological invasions affect community structure and ecosystem function. here we show invasion by the alien crazy ant anoplolepis gracilipes causes a rapid, catastrophic shift in the rain forest ecosystem of a tropical oceanic island, affecting at least three trophic levels. in invaded areas, crazy ants extirpate the red land crab, the dominant endemic consumer on the forest floor. in doing so, crazy ants indirectly release seedling recruitment, enhance species richness of seedlings, and slow litter breakdown. in the forest canopy, new associations between this invasive ant and honeydew-secreting scale insects accelerate and diversify impacts. sustained high densities of foraging ants on canopy trees result in high population densities of hostgeneralist scale insects and growth of sooty moulds, leading to canopy dieback and even deaths of canopy trees. the indirect fallout from the displacement of a native keystone species by an ant invader, itself abetted by introduced/cryptogenic mutualists, produces synergism in impacts to precipitate invasional meltdown in this system.",
            "contribution_ids": [
                "R56548"
            ]
        },
        {
            "instance_id": "R56945xR56573",
            "comparison_id": "R56945",
            "paper_id": "R56573",
            "text": "Effects of Acer platanoides invasion on understory plant communities and tree regeneration in the northern Rocky Mountains quantitative studies are necessary to determine whether invasive plant species displace natives and reduce local biodiversity, or if they increase local biodiversity. here we describe the effects of invasion by norway maple acer platanoides on riparian plant communities and tree regeneration at two different scales (individual tree vs stand scales) in western montana, usa, using both descriptive and experimental approaches. the three stands differed in community composition with the stand most dominated by a. platanoides invasion being more compositionally homogenous, and less species rich (-67%), species even (-40%), and diverse ( -75%) than the two other stands. this sharp decrease in community richness and diversity of the highly invaded stand, relative to the other stands, corresponded with a 28-fold increase in a. platanoides seedlings and saplings. the dramatic difference between stand 1 vs 2 and 3 suggests that a. platanoides invasion is associated with a dramatic change in community composition and local loss of species diversity; however, other unaccounted for differences between stands may be the cause. these whole-stand correlations were corroborated by community patterns under individual a. platanoides trees in a stand with intermediate levels of patchy invasion. at the scale of individual a. platanoides canopies within a matrix of native trees, diversity and richness of species beneath solitary a. platanoides trees declined as the size of the trees increased. these decreases in native community properties corresponded with an increase in the density of a. platanoides seedlings. the effect of a. platanoides at the stand scale was more dramatic than at the individual canopy scale; however, at this smaller scale we only collected data from the stand with intermediate levels of invasion and not from the stand with high levels of invasion. transplant experiments with tree seedlings demonstrated that a. platanoides seedlings performed better when grown beneath conspecific canopies than under natives, but populus and pinus seedlings performed better when grown beneath populus canopies, the dominant native. our results indicate that a. platanoides trees suppress most native species, including the regeneration of the natural canopy dominants, but facilitate conspecifics in their understories.",
            "contribution_ids": [
                "R56574"
            ]
        },
        {
            "instance_id": "R56945xR56616",
            "comparison_id": "R56945",
            "paper_id": "R56616",
            "text": "Non-native habitat as home for non-native species: comparison of communities associated with invasive tubeworm and native oyster reefs \"introduction vectors for marine non-native species, such as oyster culture and boat foul- ing, often select for organisms dependent on hard substrates during some or all life stages. in soft- sediment estuaries, hard substrate is a limited resource, which can increase with the introduction of hard habitat-creating non-native species. positive interactions between non-native, habitat-creating species and non-native species utilizing such habitats could be a mechanism for enhanced invasion success. most previous studies on aquatic invasive habitat-creating species have demonstrated posi- tive responses in associated communities, but few have directly addressed responses of other non- native species. we explored the association of native and non-native species with invasive habitat- creating species by comparing communities associated with non-native, reef-building tubeworms ficopomatus enigmaticus and native oysters ostrea conchaphila in elkhorn slough, a central califor- nia estuary. non-native habitat supported greater densities of associated organisms\u2014primarily highly abundant non-native amphipods (e.g. monocorophium insidiosum, melita nitida), tanaid (sinelebus sp.), and tube-dwelling polychaetes (polydora spp.). detritivores were the most common trophic group, making up disproportionately more of the community associated with f. enigmaticus than was the case in the o. conchaphila community. analysis of similarity (anosim) showed that native species' community structure varied significantly among sites, but not between biogenic habi- tats. in contrast, non-natives varied with biogenic habitat type, but not with site. thus, reefs of the invasive tubeworm f. enigmaticus interact positively with other non-native species.\"",
            "contribution_ids": [
                "R56617"
            ]
        },
        {
            "instance_id": "R56945xR56789",
            "comparison_id": "R56945",
            "paper_id": "R56789",
            "text": "Exotic mammals disperse exotic fungi that promote invasion by exotic trees biological invasions are often complex phenomena because many factors influence their outcome. one key aspect is how non-natives interact with the local biota. interaction with local species may be especially important for exotic species that require an obligatory mutualist, such as pinaceae species that need ectomycorrhizal (em) fungi. em fungi and seeds of pinaceae disperse independently, so they may use different vectors. we studied the role of exotic mammals as dispersal agents of em fungi on isla victoria, argentina, where many pinaceae species have been introduced. only a few of these tree species have become invasive, and they are found in high densities only near plantations, partly because these pinaceae trees lack proper em fungi when their seeds land far from plantations. native mammals (a dwarf deer and rodents) are rare around plantations and do not appear to play a role in these invasions. with greenhouse experiments using animal feces as inoculum, plus observational and molecular studies, we found that wild boar and deer, both non-native, are dispersing em fungi. approximately 30% of the pinaceae seedlings growing with feces of wild boar and 15% of the seedlings growing with deer feces were colonized by non-native em fungi. seedlings growing in control pots were not colonized by em fungi. we found a low diversity of fungi colonizing the seedlings, with the hypogeous rhizopogon as the most abundant genus. wild boar, a recent introduction to the island, appear to be the main animal dispersing the fungi and may be playing a key role in facilitating the invasion of pine trees and even triggering their spread. these results show that interactions among non-natives help explain pine invasions in our study area.",
            "contribution_ids": [
                "R56790"
            ]
        },
        {
            "instance_id": "R57101xR55136",
            "comparison_id": "R57101",
            "paper_id": "R55136",
            "text": "Correlates of Introduction Success in Exotic New Zealand Birds whether or not a bird species will establish a new population after invasion of uncolonized habitat depends, from theory, on its life-history attributes and initial population size. data about initial population sizes are often unobtainable for natural and deliberate avian invasions. in new zealand, however, contemporary documentation of introduction efforts allowed us to systematically compare unsuccessful and successful invaders without bias. we obtained data for 79 species involved in 496 introduction events and used the present-day status of each species as the dependent variable in fitting multiple logistic regression models. we found that introduction efforts for species that migrated within their endemic ranges were significantly less likely to be successful than those for nonmigratory species with similar introduction efforts. initial population size, measured as number of releases and as the minimum number of propagules liberated in new zealand, significantly increased the probability of translocation success. a null model showed that species released more times had a higher probability per release of successful establishment. among 36 species for which data were available, successful invaders had significantly higher natality/mortality ratios. successful invaders were also liberated at significantly more sites. invasion of new zealand by exotic birds was therefore primarily related to management, an outcome that has implications for conservation biology.",
            "contribution_ids": [
                "R55137",
                "R55138",
                "R57074"
            ]
        },
        {
            "instance_id": "R57101xR55002",
            "comparison_id": "R57101",
            "paper_id": "R55002",
            "text": "Factors explaining alien plant invasion success in a tropical ecosystem differ at each stage of invasion 1 understanding why some alien plant species become invasive when others fail is a fundamental goal in invasion ecology. we used detailed historical planting records of alien plant species introduced to amani botanical garden, tanzania and contemporary surveys of their invasion status to assess the relative ability of phylogeny, propagule pressure, residence time, plant traits and other factors to explain the success of alien plant species at different stages of the invasion process. 2 species with native ranges centred in the tropics and with larger seeds were more likely to regenerate, whereas naturalization success was explained by longer residence time, faster growth rate, fewer seeds per fruit, smaller seed mass and shade tolerance. 3 naturalized species spreading greater distances from original plantings tended to have more seeds per fruit, whereas species dispersed by canopy\u2010feeding animals and with native ranges centred on the tropics tended to have spread more widely in the botanical garden. species dispersed by canopy\u2010feeding animals and with greater seed mass were more likely to be established in closed forest. 4 phylogeny alone made a relatively minor contribution to the explanatory power of statistical models, but a greater proportion of variation in spread within the botanical garden and in forest establishment was explained by phylogeny alone than for other models. phylogeny jointly with variables also explained a greater proportion of variation in forest establishment than in other models. phylogenetic correction weakened the importance of dispersal syndrome in explaining compartmental spread, seed mass in the forest establishment model, and all factors except for growth rate and residence time in the naturalization model. 5 synthesis. this study demonstrates that it matters considerably how invasive species are defined when trying to understand the relative ability of multiple variables to explain invasion success. by disentangling different invasion stages and using relatively objective criteria to assess species status, this study highlights that relatively simple models can help to explain why some alien plants are able to naturalize, spread and even establish in closed tropical forests.",
            "contribution_ids": [
                "R55003",
                "R56968",
                "R56969"
            ]
        },
        {
            "instance_id": "R57101xR55025",
            "comparison_id": "R57101",
            "paper_id": "R55025",
            "text": "Propagule Size and the Relative Success of Exotic Ungulate and Bird Introductions to New Zealand we investigated factors affecting the success of 14 species of ungulates introduced to new zealand around 1851\u20131926. the 11 successful species had a shorter maximum life span and were introduced in greater numbers than the three unsuccessful species. because introduction effort was confounded with other life\u2010history traits, we examined whether independent introductions of the same species were more likely to succeed when a greater number of individuals were introduced. for the six species with introductions that both succeeded and failed, successful introductions always involved an equal or greater number of individuals than unsuccessful introductions of the same species. for all independent introductions, there was a highly significant relationship between the number of individuals introduced and introduction success. when data for ungulate and bird introductions to new zealand were combined, a variable categorizing species as ungulate or bird was a highly significant predictor of introduction success, after variation in introduction effort was controlled. for a given number of individuals introduced, ungulates were much more likely to succeed than birds.",
            "contribution_ids": [
                "R55026",
                "R56979"
            ]
        },
        {
            "instance_id": "R57101xR55011",
            "comparison_id": "R57101",
            "paper_id": "R55011",
            "text": "The role of competition and introduction effort in the success of passeriform birds introduced to New Zealand the finding that passeriform birds introduced to the islands of hawaii and saint helena were more likely to successfully invade when fewer other introduced species were present has been interpreted as strong support for the hypothesis that interspecific competition influences invasion success. i tested whether invasions were more likely to succeed when fewer species were present using the records of passeriform birds introduced to four acclimatization districts in new zealand. i also tested whether introduction effort, measured as the number of introductions and the total number of birds released, could predict invasion outcomes, a result previously established for all birds introduced to new zealand. i found patterns consistent with both competition and introduction effort as explanations for invasion success. however, data supporting the two explanations were confounded such that the greater success of invaders arriving when fewer other species were present could have been due to a causal relationship between invasion success and introduction effort. hence, without data on introduction effort, previous studies may have overestimated the degree to which the number of potential competitors could independently explain invasion outcomes and may therefore have overstated the importance of competition in structuring introduced avian assemblages. furthermore, i suggest that a second pattern in avian invasion success previously attributed to competition, the morphological overdispersion of successful invaders, could also arise as an artifact of variation in introduction effort.",
            "contribution_ids": [
                "R55012",
                "R56975"
            ]
        },
        {
            "instance_id": "R57101xR57061",
            "comparison_id": "R57101",
            "paper_id": "R57061",
            "text": "Patterns of extinction in the introduced Hawaiian avifauna: a reexamination of the role of competition among introduced passeriform and columbiform birds of the six major hawaiian islands, some species (including most of those introduced early) may have an intrinsically high probability of successful invasion, whereas others (including many of those introduced from 1900 through 1936) may be intrinsically less likely to succeed. this hypothesis accords well with the observation that, of the 41 species introduced on more than one of the hawaiian islands, all but four either succeeded everywhere they were introduced or failed everywhere they were introduced, no matter what other species or how many other species were present. other hypotheses, including competitive ones, are possible. however, most other patterns that have been claimed to support the hypothesis that competitive interactions have been key to which species survived are ambiguous. we propose that the following patterns are true: (1) extinction rate as a function of number of species present (s) is not better fit by addition of an s2 term. (2) bill-length differences between pairs of species that invaded together may tend to be less for pairs in which at least one species became extinct, but the result is easily changed by use of one reasonable set of conventions rather than another. in any event, the relationship of bill-length differences to resource overlap has not been established for these species. (3) surviving forest passeriforms on oahu may be overdispersed in morphological space, although the species pool used to construct the space may not have been the correct one. (4) densities of surviving species on species-poor islands have not been shown to exceed those on species-rich islands.",
            "contribution_ids": [
                "R57062"
            ]
        },
        {
            "instance_id": "R57101xR56984",
            "comparison_id": "R57101",
            "paper_id": "R56984",
            "text": "Introduction pathways and establishment rates of invasive aquatic species in Europe species invasion is one of the leading mechanisms of global environmental change, particularly in freshwater ecosystems. we used the food and agriculture organization\\'s database of invasive aquatic species to study invasion rates and to analyze invasion pathways within europe. of the 123 aquatic species introduced into six contrasting european countries, the average percentage established is 63%, well above the 5%\\x9620% suggested by williamson\\'s \"tens\" rule. the introduction and establishment transitions are independent of each other, and species that became widely established did so because their introduction was attempted in many countries, not because of a better establishment capability. the most frequently introduced aquatic species in europe are freshwater fishes. we describe clear introduction pathways of aquatic species into europe and three types of country are observed: \"recipient and donor\" (large, midlatitude european countries, such as france, the united kingdom, and germany, that give and receive the most introductions), \"recipient\" (most countries, but particularly southern countries, which give few species but receive many), and \"neither recipient nor donor\" (only two countries). a path analysis showed that the numbers of species given and received are mediated by the size (area) of the country and population density, but not gross domestic product per capita.",
            "contribution_ids": [
                "R56985"
            ]
        },
        {
            "instance_id": "R57101xR57075",
            "comparison_id": "R57101",
            "paper_id": "R57075",
            "text": "How well do we understand the impacts of alien species on ecosystem services? A pan-European, cross-taxa assessment recent comprehensive data provided through the daisie project (www.europe-aliens.org) have facilitated the development of the first pan-european assessment of the impacts of alien plants, vertebrates, and invertebrates \u2013 in terrestrial, freshwater, and marine environments \u2013 on ecosystem services. there are 1094 species with documented ecological impacts and 1347 with economic impacts. the two taxonomic groups with the most species causing impacts are terrestrial invertebrates and terrestrial plants. the north sea is the maritime region that suffers the most impacts. across taxa and regions, ecological and economic impacts are highly correlated. terrestrial invertebrates create greater economic impacts than ecological impacts, while the reverse is true for terrestrial plants. alien species from all taxonomic groups affect \u201csupporting\u201d, \u201cprovisioning\u201d, \u201cregulating\u201d, and \u201ccultural\u201d services and interfere with human well-being. terrestrial vertebrates are responsible for the greatest range of impacts, and these are widely distributed across europe. here, we present a review of the financial costs, as the first step toward calculating an estimate of the economic consequences of alien species in europe.",
            "contribution_ids": [
                "R57076",
                "R57077",
                "R57078",
                "R57079",
                "R57080"
            ]
        },
        {
            "instance_id": "R57101xR57088",
            "comparison_id": "R57101",
            "paper_id": "R57088",
            "text": "The analysis and modelling of British invasions the scope programme on the ecology of biological invasions addresses three questions: what are the factors that determine whether a species will become an invader or not? what are the site properties which determine whether an ecological system will be relatively prone to or resistant to invasion? how should management systems be developed to best advantage, given the knowledge gained by attempting to answer the first two questions? the answers that have been offered to these questions earlier, and during the course of the programme, are reviewed. the consensus is that, although certain habitat and biological features increase the probability of invasion and establishment, these features are neither necessary nor sufficient, and that the prediction of invasion is not yet feasible. these points are illustrated by examples and generalizations from a survey of british invaders. the probability that an established invader will be a pest in britain seems to be around 10% . mathematical modelling may help in understanding and, later, in predicting invasions. models indicate that establishment may be more critical than spread, and that a successful invader will spread at a constant linear speed. models and data suggest that both an accelerating rate of spread and occasional major jumps can be expected; consequently, efforts to eliminate an invader at an early stage will be the most effective.",
            "contribution_ids": [
                "R57089",
                "R57090",
                "R57091"
            ]
        },
        {
            "instance_id": "R57101xR57057",
            "comparison_id": "R57101",
            "paper_id": "R57057",
            "text": "Predicting the Australian weed status of southern African plants a method of predicting weed status was developed for southern african plants naturalized in australia, based upon information on extra-australian weed status, distribution and taxonomy. weed status in australia was associated with being geographically widespread in southern africa, being found in a wide range of climates in southern africa, being described as a weed or targeted by herbicides in southern africa, with early introduction and establishment in australia, and with weediness in regions other than southern africa. multiple logistic regressions were used to identify the variables that best predicted weed status. the best fitting regressions were for weeds present for a long time in australia (more than 140 years). they utilized three variables, namely weed status, climatic range in southern africa and the existence of congeneric weeds in southern africa. the highest level of variation explained (43%) was obtained for agricultural weeds using a single variable, weed status in southern africa. being recorded as a weed in australia was related to climatic range and the existence of congeneric weeds in southern africa (40% of variation explained). no variables were suitable predictors of non-agricultural (environmental) weeds. the regressions were used to predict future weed status of plants either not introduced or recently arrived in australia. recently-arrived species which were predicted to become weeds are acacia karroo hayne (mimosaceae), arctotis venustra t. norl. (asteraceae), sisymbrium thellungii o.e. schulz (brassicaceae) and solanum retroflexum dun. (solanaceae). twenty species not yet arrived in australia were predicted to have a high likelihood of becoming weeds. analysis of the residuals of the regressions indicated two long-established species which might prove to be good targets for biological control: mesembryanthemum crystallinum l. (aizoaceae) and watsonia meriana (l.) mill. (iridaceae).",
            "contribution_ids": [
                "R57058"
            ]
        },
        {
            "instance_id": "R57101xR55125",
            "comparison_id": "R57101",
            "paper_id": "R55125",
            "text": "Behavioural flexibility predicts invasion success in birds introduced to New Zealand a fundamental question in ecology is whether there are evolutionary characteristics of species that make some better than others at invading new communities. in birds, nesting habits, sexually selected traits, migration, clutch size and body mass have been suggested as important variables, but behavioural flexibility is another obvious trait that has received little attention. behavioural flexibility allows animals to respond more rapidly to environmental changes and can therefore be advantageous when invading novel habitats. behavioural flexibility is linked to relative brain size and, for foraging, has been operationalised as the number of innovations per taxon reported in the short note sections of ornithology journals. here, we use data on avian species introduced to new zealand and test the link between forebrain size, feeding innovation frequency and invasion success. relative brain size was, as expected, a significant predictor of introduction success, after removing the effect of introduction effort. species with relatively larger brains tended to be better invaders than species with smaller ones. introduction effort, migratory strategy and mode of juvenile development were also significant in the models. pair-wise comparisons of closely related species indicate that successful invaders also showed a higher frequency of foraging innovations in their region of origin. this study provides the first evidence in vertebrates of a general set of traits, behavioural flexibility, that can potentially favour invasion success.",
            "contribution_ids": [
                "R55126",
                "R57064"
            ]
        },
        {
            "instance_id": "R57101xR56972",
            "comparison_id": "R57101",
            "paper_id": "R56972",
            "text": "Parental investment and fecundity, but not brain size, are associated with establishment success in introduced fishes summary \\n \\n1 \\nclassical theory predicts that colonizing ability should increase with fecundity. additionally, it has recently been shown that successful establishment of birds was correlated with relative brain size, which was suggested as possibly universal among vertebrates. \\n \\n2 \\ni conducted a comparative study of establishment success in global fish introductions, controlling for regional geographic differences, to test these hypothesized correlates. \\n \\n3 \\nin 133 introductions of 17 fish species, establishment success was negatively associated with fecundity while there was no evidence for an effect of relative brain size. in analysis of partially overlapping data, there was no evidence of a correlation between relative brain size and establishment rate across 39 species. \\n \\n4 \\none explanation for the negative association with fecundity is that parental investment might be more important to establishment than fecundity. in 126 introductions of 14 species, reproductive behaviours associated with parental investment were significantly associated with establishment success. these results suggest that the correlation between brain size and establishment success is not universal.",
            "contribution_ids": [
                "R56973"
            ]
        },
        {
            "instance_id": "R57101xR55013",
            "comparison_id": "R57101",
            "paper_id": "R55013",
            "text": "High predictability in introduction outcomes and the geographical range size of introduced Australian birds: a role for climate summary \\n \\n \\n1 \\nwe investigated factors hypothesized to influence introduction success and subsequent geographical range size in 52 species of bird that have been introduced to mainland australia. \\n \\n2 \\nthe 19 successful species had been introduced more times, at more sites and in greater overall numbers. relative to failed species, successfully introduced species also had a greater area of climatically suitable habitat available in australia, a larger overseas range size and were more likely to have been introduced successfully outside australia. after controlling for phylogeny these relationships held, except that with overseas range size and, in addition, larger-bodied species had a higher probability of introduction success. there was also a marked taxonomic bias: gamebirds had a much lower probability of success than other species. a model including five of these variables explained perfectly the patterns in introduction success across-species. \\n \\n3 \\nof the successful species, those with larger geographical ranges in australia had a greater area of climatically suitable habitat, traits associated with a faster population growth rate (small body size, short incubation period and more broods per season) and a larger overseas range size. the relationships between range size in australia, the extent of climatically suitable habitat and overseas range size held after controlling for phylogeny. \\n \\n4 \\nwe discuss the probable causes underlying these relationships and why, in retrospect, the outcome of bird introductions to australia are highly predictable.",
            "contribution_ids": [
                "R55014",
                "R56976"
            ]
        },
        {
            "instance_id": "R57101xR57048",
            "comparison_id": "R57101",
            "paper_id": "R57048",
            "text": "Predicting the number of ecologically harmful exotic species in an aquatic system most introduced species apparently have little impact on native biodiversity, but the proliferation of human vectors that transport species worldwide increases the probability of a region being affected by high\u2010impact invaders \u2013 i.e. those that cause severe declines in native species populations. our study determined whether the number of high\u2010impact invaders can be predicted from the total number of invaders in an area, after controlling for species\u2013area effects. these two variables are positively correlated in a set of 16 invaded freshwater and marine systems from around the world. the relationship is a simple linear function; there is no evidence of synergistic or antagonistic effects of invaders across systems. a similar relationship is found for introduced freshwater fishes across 149 regions. in both data sets, high\u2010impact invaders comprise approximately 10% of the total number of invaders. although the mechanism driving this correlation is likely a sampling effect, it is not simply the proportional sampling of a constant number of repeat\u2010offenders; in most cases, an invader is not reported to have strong impacts on native species in the majority of regions it invades. these findings link vector activity and the negative impacts of introduced species on biodiversity, and thus justify management efforts to reduce invasion rates even where numerous invasions have already occurred.",
            "contribution_ids": [
                "R57049",
                "R57050"
            ]
        },
        {
            "instance_id": "R57101xR56965",
            "comparison_id": "R57101",
            "paper_id": "R56965",
            "text": "Mistakes in the analysis of exotic species establishment: source pool designation and correlates of introduction success among parrots (Aves: Psittaciformes) of the world aim\\u2002 to evaluate the effect of mis\u2010specifying the correct comparison of species pools in the study of species characteristics associated with the biological introduction of exotic species.",
            "contribution_ids": [
                "R56966",
                "R56967"
            ]
        },
        {
            "instance_id": "R57101xR56102",
            "comparison_id": "R57101",
            "paper_id": "R56102",
            "text": "Are islands more susceptible to be invaded than continents? Birds say no island communities are generally viewed as being more susceptible to invasion than those of mainland areas, yet empirical evidence is almost lacking. a species-by-species examination of introduced birds in two independent island-mainland comparisons is not consistent with this hypothesis. in the new zealand-mainland australia comparison, 16 species were successful in both regions, 19 always failed and only eight had mixed outcomes. mixed results were observed less often than expected by chance, and in only 5 cases was the relationship in the predicted direction. this result is not biased by differences in introduction effort because, within species, the number of individuals released in new zealand did not differ significantly from those released in mainland australia. a similar result emerged in the hawaiian islands-mainland usa comparison: among the 35 species considered, 15 were successful in both regions, seven always failed and 13 had mixed outcomes. in this occasion, the results fit well to those expected by chance, and in only seven cases was the relationship in the direction predicted. i therefore conclude that, if true, the view that islands are less resistant than continents to invasions is far from universal.",
            "contribution_ids": [
                "R56103",
                "R57063"
            ]
        },
        {
            "instance_id": "R57101xR57092",
            "comparison_id": "R57101",
            "paper_id": "R57092",
            "text": "The varying success of invaders . ........ ... .. . . ....... ..... . ......... . ---------- . .... ........ .... . .... . ..... . ------------. ........ .... . ... ..... . . .. . .... . . ... . . .. . ........ .. . . ... . ..... .. . . .... .... .... ... ..... . . . .... .. . .. ... . . . . .. .. ...... . ....... ... ... . ... .. . . . . . .... ....... .... ......... ... ........ ........ ...",
            "contribution_ids": [
                "R57093",
                "R57094",
                "R57095",
                "R57096"
            ]
        },
        {
            "instance_id": "R57101xR57065",
            "comparison_id": "R57101",
            "paper_id": "R57065",
            "text": "Globalisation in marine ecosystems: the story of non-indigenous marine species across European seas the introduction of non-indigenous species (nis) across the major european seas is a dynamic non-stop process. up to september 2004, 851 nis (the majority being zoobenthic organ- isms) have been reported in european marine and brackish waters, the majority during the 1960s and 1970s. the mediterranean is by far the major recipient of exotic species with an average of one introduction every 4 wk over the past 5 yr. of the 25 species recorded in 2004, 23 were reported in the mediterranean and only two in the baltic. the most updated patterns and trends in the rate, mode of introduction and establishment success of introductions were examined, revealing a process similar to introductions in other parts of the world, but with the uniqueness of migrants through the suez canal into the mediterranean (lessepsian or erythrean migration). shipping appears to be the major vector of introduction (excluding the lessepsian migration). aquaculture is also an important vector with target species outnumbered by those introduced unintentionally. more than half of immigrants have been estab- lished in at least one regional sea. however, for a significant part of the introductions both the establishment success and mode of introduction remain unknown. finally, comparing trends across taxa and seas is not as accurate as could have been wished because there are differences in the spatial and taxonomic effort in the study of nis. these differences lead to the conclusion that the number of nis remains an underestimate, calling for continuous updating and systematic research.",
            "contribution_ids": [
                "R57066"
            ]
        },
        {
            "instance_id": "R57101xR55039",
            "comparison_id": "R57101",
            "paper_id": "R55039",
            "text": "The Influence of Numbers Released on the Outcome of Attempts to Introduce Exotic Bird Species to New Zealand 1. information on the approximate number of individuals released is available for 47 of the 133 exotic bird species introduced to new zealand in the late 19th and early 20th centuries. of these, 21 species had populations surviving in the wild in 1969-79. the long interval between introduction and assessment of outcome provides a rare opportunity to examine the factors correlated with successful establishment without the uncertainty of long-term population persistence associated with studies of short duration. 2. the probability of successful establishment was strongly influenced by the number of individuals released during the main period of introductions. eight-three per cent of species that had more than 100 individuals released within a 10-year period became established, compared with 21% of species that had less than 100 birds released. the relationship between the probability of establishment and number of birds released was similar to that found in a previous study of introductions of exotic birds to australia. 3. it was possible to look for a within-family influence on the success of introduction of the number of birds released in nine bird families. a positive influence was found within seven families and no effect in two families. this preponderance of families with a positive effect was statistically significant. 4. a significant effect of body weight on the probability of successful establishment was found, and negative effects of clutch size and latitude of origin. however, the statistical significance of these effects varied according to whether comparison was or was not restricted to within-family variation. after applying the bonferroni adjustment to significance levels, to allow for the large number of variables and factors being considered, only the effect of the number of birds released was statistically significant. 5. no significant effects on the probability of successful establishment were apparent for the mean date of release, the minimum number of years in which birds were released, the hemisphere of origin (northern or southern) and the size and diversity of latitudinal distribution of the natural geographical range.",
            "contribution_ids": [
                "R55040",
                "R56989"
            ]
        },
        {
            "instance_id": "R57101xR57020",
            "comparison_id": "R57101",
            "paper_id": "R57020",
            "text": "Differentiating successful and failed molluscan invaders in estuarine ecosystems abstract: despite mounting evidence of invasive species\u2019 impacts on the environment and society,our ability to predict invasion establishment, spread, and impact are inadequate. efforts to explainand predict invasion outcomes have been limited primarily to terrestrial and freshwater ecosystems.invasions are also common in coastal marine ecosystems, yet to date predictive marine invasion mod-els are absent. here we present a model based on biological attributes associated with invasion suc-cess (establishment) of marine molluscs that compares successful and failed invasions from a groupof 93 species introduced to san francisco bay (sfb) in association with commercial oyster transfersfrom eastern north america (ca. 1869 to 1940). a multiple logistic regression model correctly classi-fied 83% of successful and 80% of failed invaders according to their source region abundance at thetime of oyster transfers, tolerance of low salinity, and developmental mode. we tested the generalityof the sfb invasion model by applying it to 3 coastal locations (2 in north america and 1 in europe)that received oyster transfers from the same source and during the same time as sfb. the model cor-rectly predicted 100, 75, and 86% of successful invaders in these locations, indicating that abun-dance, environmental tolerance (ability to withstand low salinity), and developmental mode not onlyexplain patterns of invasion success in sfb, but more importantly, predict invasion success in geo-graphically disparate marine ecosystems. finally, we demonstrate that the proportion of marine mol-luscs that succeeded in the latter stages of invasion (i.e. that establish self-sustaining populations,spread and become pests) is much greater than has been previously predicted or shown for otheranimals and plants.key words: invasion \u00b7 bivalve \u00b7 gastropod \u00b7 mollusc \u00b7 marine \u00b7 oyster \u00b7 vector \u00b7 risk assessment",
            "contribution_ids": [
                "R57021",
                "R57022",
                "R57023"
            ]
        },
        {
            "instance_id": "R57101xR56970",
            "comparison_id": "R57101",
            "paper_id": "R56970",
            "text": "Sexual plumage differences and the outcome of game bird (Aves: Galliformes) introductions on oceanic islands galliformes, after passeriformes, is the group of birds that has been most introduced to oceanic islands. among passeriformes, whether the species\u2019 plumage is sexually monochromatic or dichromatic, along with other factors such as introduction effort and interspecific competition, has been identified as a factor that limits introduction success. in this study, we tested the hypothesis that sexually dichromatic plumage reduces the probability of success for 51 species from 26 genera of game birds that were introduced onto 12 oceanic islands. analyses revealed no significant differences in probability of introduction success between monochromatic and dichromatic species at either the generic or specific levels. we also found no significant difference between these two groups in size of native geographic range, wing length or humanintroduction effort. our results do not support the hypothesis that sexually dichromatic plumage (probably a response to sexual selection) predicts introduction outcomes of game birds as has been reported for passerine birds. these findings suggest that passerine and non-passerine birds differ fundamentally in terms of factors that could influence introduction outcome, and should therefore be evaluated separately as opposed to lumping these two groups as \u2018land birds\u2019.",
            "contribution_ids": [
                "R56971"
            ]
        },
        {
            "instance_id": "R57101xR57072",
            "comparison_id": "R57101",
            "paper_id": "R57072",
            "text": "Environmental and economic impact assessment of alien and invasive fish species in Europe using the generic impact scoring system invasions by alien species are one of the major threats to the native environment. there are multifold attempts to counter alien species, but limited resources for mitigation or eradication programmes makes prioritisation indispensable. we used the generic impact scoring system to assess the impact of alien fish species in europe. it prioritises species, but also offers the possibility to compare the impact of alien invasive species between different taxonomic groups. for alien fish in europe, we compiled a list of 40 established species. by literature research, we assessed the environmental impact (through herbivory, predation, competition, disease transmission, hybridisation and ecosystem alteration) and economic impact (on agriculture, animal production, forestry, human infrastructure, human health and human social life) of each species. the goldfish/gibel complex carassius auratus/c.\\xa0gibelio scored the highest impact points, followed by the grass carp ctenopharyngodon idella and the topmouth gudgeon pseudorasbora parva. according to our analyses, alien fish species have the strongest impact on the environment through predation, followed by competition with native species. besides negatively affecting animal production (mainly in aquaculture), alien fish have no pronounced economic impact. at the species level, c.\\xa0auratus/c.\\xa0gibelio show similar impact scores to the worst alien mammals in europe. this study indicates that the generic impact scoring system is useful to investigate the impact of alien fish, also allowing cross-taxa comparisons. our results are therefore of major relevance for stakeholders and decision-makers involved in management and eradication of alien fish species.",
            "contribution_ids": [
                "R57073"
            ]
        },
        {
            "instance_id": "R57101xR57016",
            "comparison_id": "R57101",
            "paper_id": "R57016",
            "text": "Determinants for the successful establishment of exotic ants in New Zealand biological invasions can dramatically alter ecosystems. an ability to predict the establishment success for exotic species is important for biosecurity and conservation purposes. i examine the exotic new zealand ant fauna for characteristics that predict or determine an exotic species\u2019 ability to establish. quarantine records show interceptions of 66 ant species: 17 of which have established, 43 have failed to establish, whereas nests of another six are periodically observed but have failed to establish permanently (called \u2018ephemeral\u2019 establishment). mean temperature at the highest latitude and interception variables were the only factors significantly different between established, failed or ephemeral groups. aspects of life history, such as competitive behaviour and morphology, were not different between groups. however, in a stepwise discriminant analysis, small size was a key factor influencing establishment success. interception rate and climate were also secondarily important. the resulting classification table predicted establishment success with 71% accuracy. because not all exotic species are represented in quarantine records, a further discriminant model is described without interception data. though with less accuracy (65%) than the full model, it still correctly predicted the success or failure of four species not used in the previous analysis. techniques for improving the prediction accuracy are discussed. predicting which species will establish in a new area appears an achievable goal, which will be a valuable tool for conservation biology.",
            "contribution_ids": [
                "R57017"
            ]
        },
        {
            "instance_id": "R57101xR57018",
            "comparison_id": "R57101",
            "paper_id": "R57018",
            "text": "Sexual selection and the risk of extinction of introduced birds on oceanic islands we test the hypothesis that response to sexual selection increases the risk of extinction by examining the fate of plumage-monomorphic versus plumage-dimorphic bird species introduced to the tropical islands of oahu and tahiti. we assume that plumage dimorphism is a response to sexual selection and we assume that the males of plumage-dimorphic species experience stronger sexual selection pressures than males of monomorphic species. on oahu, the extinction rate for dimorphic species, 59%, is significantly greater than for monomorphic species, 23%. on tahiti, only 7% of the introduced dimorphic species have persisted compared to 22% for the introduced monomorphic species. for the combined oahu and tahiti data sets, addition of plumage-by-fate interaction significantly improves the fit of the log-linear model, fate+island+plumage+(fate-by-island)+(island-by-plumage). to control for phylogenetic constraint, a logistic regression model is analyzed using a data subset consisting of only the two best represented families, fringillidae and passeridae. here, plumage and the plumage-by-family interaction are significant. plumage is significantly associated with increased risk of extinction for passerids but insignificantly associated for fringillids. thus, the hypothesis that response to sexual selection increases the risk of extinction is supported for passerids and for the data set as a whole. the probability of extinction was correlated with the number of species already introduced. thus, species that have responded to sexual selection may be poorer interspecific competitors when their communities contain many other species.",
            "contribution_ids": [
                "R57019"
            ]
        },
        {
            "instance_id": "R57101xR56098",
            "comparison_id": "R57101",
            "paper_id": "R56098",
            "text": "Establishment success across convergent Mediterranean ecosystems: an analysis of bird introductions abstract:\\u2002 concern over the impact of invaders on biodiversity and on the functioning of ecosystems has generated a rising tide of comparative analyses aiming to unveil the factors that shape the success of introduced species across different regions. one limitation of these studies is that they often compare geographically rather than ecologically defined regions. we propose an approach that can help address this limitation: comparison of invasions across convergent ecosystems that share similar climates. we compared avian invasions in five convergent mediterranean climate systems around the globe. based on a database of 180 introductions representing 121 avian species, we found that the proportion of bird species successfully established was high in all mediterranean systems (more than 40% for all five regions). species differed in their likelihood to become established, although success was not higher for those originating from mediterranean systems than for those from nonmediterranean regions. controlling for this taxonomic effect with generalized linear mixed models, species introduced into mediterranean islands did not show higher establishment success than those introduced to the mainland. susceptibility to avian invaders, however, differed substantially among the different mediterranean regions. the probability that a species will become established was highest in the mediterranean basin and lowest in mediterranean australia and the south african cape. our results suggest that many of the birds recently introduced into mediterranean systems, and especially into the mediterranean basin, have a high potential to establish self\u2010sustaining populations. this finding has important implications for conservation in these biologically diverse hotspots.",
            "contribution_ids": [
                "R56099",
                "R56999"
            ]
        },
        {
            "instance_id": "R57501xR57209",
            "comparison_id": "R57501",
            "paper_id": "R57209",
            "text": "Invasibility and compositional stability in a grassland community: relationships to diversity and extrinsic factors we present results from an ongoing field study conducted in kansas grassland to examine correlates of invasibility and community stability along a natural gradient of plant diversity. invasibility was evaluated by sowing seeds of 34 plant species into 40 experimental plots and then measuring colonization success after two growing seasons. compositional stability, defined as resistance to change in species relative abundances over two growing seasons and in response to experimental disturbance, was measured in a separate set of 40 plots. we found that community susceptibility to invasion was greatest in high diversity microsites within this grassland. multiple regression analyses suggested that the positive correlation between invasibility and plant diversity was due to the direct influences of the extrinsic factors that contribute to spatial variation in diversity (soil disturbances; light availability), not to any direct impact of diversity. in addition, we found that compositional stability in response to disturbance was greatest within low diversity microsites and was strongly related to the dominance (evenness) component of diversity.",
            "contribution_ids": [
                "R57210"
            ]
        },
        {
            "instance_id": "R57501xR54786",
            "comparison_id": "R57501",
            "paper_id": "R54786",
            "text": "Pollution reduces native diversity and increases invader dominance in marine hard-substrate communities anthropogenic disturbance is considered a risk factor in the establishment of non\u2010indigenous species (nis); however, few studies have investigated the role of anthropogenic disturbance in facilitating the establishment and spread of nis in marine environments. a baseline survey of native and nis was undertaken in conjunction with a manipulative experiment to determine the effect that heavy metal pollution had on the diversity and invasibility of marine hard\u2010substrate assemblages. the study was repeated at two sites in each of two harbours in new south wales, australia. the survey sampled a total of 47 sessile invertebrate taxa, of which 15 (32%) were identified as native, 19 (40%) as nis, and 13 (28%) as cryptogenic. increasing pollution exposure decreased native species diversity at all study sites by between 33% and 50%. in contrast, there was no significant change in the numbers of nis. percentage cover was used as a measure of spatial dominance, with increased pollution exposure leading to increased nis dominance across all sites. at three of the four study sites, assemblages that had previously been dominated by natives changed to become either extensively dominated by nis or equally occupied by native and nis alike. no single native or nis was repeatedly responsible for the observed changes in native species diversity or nis dominance at all sites. rather, the observed effects of pollution were driven by a diverse range of taxa and species. these findings have important implications for both the way we assess pollution impacts, and for the management of nis. when monitoring the response of assemblages to pollution, it is not sufficient to simply assess changes in community diversity. rather, it is important to distinguish native from nis components since both are expected to respond differently. in order to successfully manage current nis, we first need to address levels of pollution within recipient systems in an effort to bolster the resilience of native communities to invasion.",
            "contribution_ids": [
                "R54787",
                "R54788",
                "R57319",
                "R57320"
            ]
        },
        {
            "instance_id": "R57501xR57382",
            "comparison_id": "R57501",
            "paper_id": "R57382",
            "text": "Weed numbers in New Zealand's forest and scrub reserves \"new zealand's protected natural areas are being increasingly threatened by weeds as the natural landscape is fragmented and surrounding land use intensifies. to assist in designing management to reduce the threat, we attempted to determine the most important reserve characteristics influencing the presence of problem weeds in forest and scrub reserves. data on 15 reserve characteristics were derived from surveys of 234 reserves. from correlation analysis, analysis of variance and consideration of several multivariate models, it appears that the most important characteristics influencing the number of problem weeds in reserves are proximity to towns, distance from roads and railway lines, human use, reserve shape, and habitat diversity. these factors reflect principally increased proximity to source of propagules associated with intensifying land use, including urbanisation. reserves with the most weeds are narrow remnants on fertile soils with clearings and a history of modification, and those close to towns or sites of high human activity. if these reserves are to continue to protect natural values, they will require regular attention to prevent the establishment of further weeds. accidental spread of weeds and disturbance in reserves should be minimised.\"",
            "contribution_ids": [
                "R57383"
            ]
        },
        {
            "instance_id": "R57501xR57292",
            "comparison_id": "R57501",
            "paper_id": "R57292",
            "text": "The distribution and habitat associations of non-native plant species in urban riparian habitats questions: 1. what are the distribution and habitat associations of non-native (neophyte) species in riparian zones? 2. are there significant differences, in terms of plant species diversity, composition, habitat condition and species attributes, between plant communities where non-natives are present or abundant and those where non-natives are absent or infrequent? 3. are the observed differences generic to non-natives or do individual non-native species differ in their vegetation associations? location: west midlands conurbation (wmc), uk. methods: 56 sites were located randomly on four rivers across the wmc. ten 2 m \u00d7 2 m quadrats were placed within 15 m of the river to sample vegetation within the floodplain at each site. all vascular plants were recorded along with site information such as surrounding land use and habitat types. results: non-native species were found in many vegetation types and on all rivers in the wmc. there were higher numbers of non-natives on more degraded, human-modified rivers. more non-native species were found in woodland, scrub and tall herb habitats than in grasslands. we distinguish two types of communities with non-natives. in communities colonized following disturbance, in comparison to quadrats containing no non-native species, those with non-natives had higher species diversity and more forbs, annuals and shortlived monocarpic perennials. native species in quadrats containing non-natives were characteristic of conditions of higher fertility and ph, had a larger specific leaf area and were less stress tolerant or competitive. in later successional communities dominated by particular non-natives, native diversity declined with increasing cover of non-natives. associated native species were characteristic of low light conditions. conclusions: communities containing non-natives can be associated with particular types of native species. extrinsic factors (disturbance, eutrophication) affected both native and non-native species. in disturbed riparian habitats the key determinant of diversity is dominance by competitive invasive species regardless of their native or non-native origin.",
            "contribution_ids": [
                "R57293"
            ]
        },
        {
            "instance_id": "R57501xR52138",
            "comparison_id": "R57501",
            "paper_id": "R52138",
            "text": "The role of diversity and functional traits of species in community invasibility \"the invasion of exotic species into assemblages of native plants is a pervasive and widespread phenomenon. many theoretical and observational studies suggest that diverse communities are more resistant to invasion by exotic species than less diverse ones. however, experimental results do not always support such a relationship. therefore, the hypothesis of diversity-community invasibility is still a focus of controversy in the field of invasion ecology. in this study, we established and manipulated communities with different species diversity and different species functional groups (16 species belong to c3, c4, forbs and legumes, respectively) to test elton's hypothesis and other relevant hypotheses by studying the process of invasion. alligator weed (alternanthera philoxeroides) was chosen as the invader. we found that the correlation between the decrement of extractable soil nitrogen and biomass of alligator weed was not significant, and that species diversity, independent of functional groups diversity, did not show a significant correlation with invasibility. however, the communities with higher functional groups diversity significantly reduced the biomass of alligator weed by decreasing its resource opportunity. functional traits of species also influenced the success of the invasion. alternanthera sessilis, in the same morphological and functional group as alligator weed, was significantly resistant to alligator weed invasion. because community invasibility is influenced by many factors and interactions among them, the pattern and mechanisms of community invasibility are likely to be far subtler than we found in this study. more careful manipulated experiments coupled with theoretical modeling studies are essential steps to a more profound understanding of community invasibility.\"",
            "contribution_ids": [
                "R52139",
                "R57396"
            ]
        },
        {
            "instance_id": "R57501xR57111",
            "comparison_id": "R57501",
            "paper_id": "R57111",
            "text": "Environmental and biotic correlates to lionfish invasion success in Bahamian coral reefs lionfish (pterois volitans), venomous predators from the indo-pacific, are recent invaders of the caribbean basin and southeastern coast of north america. quantification of invasive lionfish abundances, along with potentially important physical and biological environmental characteristics, permitted inferences about the invasion process of reefs on the island of san salvador in the bahamas. environmental wave-exposure had a large influence on lionfish abundance, which was more than 20 and 120 times greater for density and biomass respectively at sheltered sites as compared with wave-exposed environments. our measurements of topographic complexity of the reefs revealed that lionfish abundance was not driven by habitat rugosity. lionfish abundance was not negatively affected by the abundance of large native predators (or large native groupers) and was also unrelated to the abundance of medium prey fishes (total length of 5\u201310 cm). these relationships suggest that (1) higher-energy environments may impose intrinsic resistance against lionfish invasion, (2) habitat complexity may not facilitate the lionfish invasion process, (3) predation or competition by native fishes may not provide biotic resistance against lionfish invasion, and (4) abundant prey fish might not facilitate lionfish invasion success. the relatively low biomass of large grouper on this island could explain our failure to detect suppression of lionfish abundance and we encourage continuing the preservation and restoration of potential lionfish predators in the caribbean. in addition, energetic environments might exert direct or indirect resistance to the lionfish proliferation, providing native fish populations with essential refuges.",
            "contribution_ids": [
                "R57112"
            ]
        },
        {
            "instance_id": "R57501xR52106",
            "comparison_id": "R57501",
            "paper_id": "R52106",
            "text": "Functional composition controls invasion success in a California serpentine grassland 1. recent debates about the role of biotic resistance in controlling invasion success have focused on effects of species richness. however, functional composition could be a stronger control: species already in the community with similar functional traits to those of the invaders should have the greatest competitive effect on invaders. still, experiments assessing effects of functional similarity have found contradictory results.",
            "contribution_ids": [
                "R52107",
                "R52108",
                "R57237"
            ]
        },
        {
            "instance_id": "R57501xR57214",
            "comparison_id": "R57501",
            "paper_id": "R57214",
            "text": "Plant community diversity and composition provide little resistance to Juniperus encroachment widespread encroachment of the fire-intolerant species juniperus virginiana l. into north american grasslands and savannahs where fire has largely been removed has prompted the need to identify mechanisms driving j. virginiana encroachment. we tested whether encroachment success of j. virginiana is related to plant species diversity and composi- tion across three plant communities. we predicted j. virginiana encroachment success would (i) decrease with increasing diversity, and (ii)j.virginiana encroachment success would be unrelated to species composition. we simulated encroachment by planting j. virginiana seedlings in tallgrass prairie, old-field grassland, and upland oak forest. we used j. virginiana survival and growth as an index of encroachment success and evaluated success as a function of plant community traits (i.e., species richness, species diversity, and species composition). our results indicated that j. virginiana encroachment suc- cess increased with increasing plant richness and diversity. moreover, growth and survival of j. virginiana seedlings was associated with plant species composition only in the old-field grassland and upland oak forest. these results suggest that greater plant species richness and diversity provide little resistance to j. virginiana encroachment, and the results suggest resource availability and other biotic or abiotic factors are determinants of j. virginiana encroachment success.",
            "contribution_ids": [
                "R57215"
            ]
        },
        {
            "instance_id": "R57501xR57384",
            "comparison_id": "R57501",
            "paper_id": "R57384",
            "text": "Biotic resistance to invader establishment of a southern Appalachian plant community is determined by environmental conditions summary 1 tests of the relationship between resident plant species richness and habitat invasibility have yielded variable results. i investigated the roles of experimental manipulation of understorey species richness and overstorey characteristics in resistance to invader establishment in a floodplain forest in south-western virginia, usa. 2 i manipulated resident species richness in experimental plots along a flooding gradient, keeping plot densities at their original levels, and quantified the overstorey characteristics of each plot. 3 after manipulating the communities, i transplanted 10 randomly chosen invaders from widespread native and non-native forest species into the experimental plots. success of an invasion was measured by survival and growth of the invader. 4 native and non-native invader establishment trends were influenced by different aspects of the biotic community and these relationships depended on the site of invasion. the most significant influence on non-native invader survival in this system of streamside and upper terrace plots was the overstorey composition. non-native species survival in the flooded plots after 2 years was significantly positively related to proximity to larger trees. however, light levels did not fully explain the overstorey effect and were unrelated to native survivorship. the effects of understorey richness on survivorship depended on the origin of the invaders and the sites they were transplanted into. additionally, native species growth was significantly affected by understorey plot richness. 5 the direction and strength of interactions with both the overstorey (for non-native invaders) and understorey richness (for natives and non-natives) changed with the site of invasion and associated environmental conditions. rather than supporting the hypothesis of biotic resistance to non-native invasion, my results suggest that native invaders experienced increased competition with the native understorey plants in the more benign upland habitat and facilitation in the stressful riparian zone.",
            "contribution_ids": [
                "R57385"
            ]
        },
        {
            "instance_id": "R57501xR55021",
            "comparison_id": "R57501",
            "paper_id": "R55021",
            "text": "Assessing the Relative Importance of Disturbance, Herbivory, Diversity, and Propagule Pressure in Exotic Plant Invasion the current rate of invasive species introductions is unprecedented, and the dramatic impacts of exotic invasive plants on community and ecosystem properties have been well documented. despite the pressing management implications, the mechanisms that control exotic plant invasion remain poorly understood. several factors, such as disturbance, propagule pressure, species diversity, and herbivory, are widely believed to play a critical role in exotic plant invasions. however, few studies have examined the relative importance of these factors, and little is known about how propagule pressure interacts with various mechanisms of ecological resistance to determine invasion success. we quantified the relative importance of canopy disturbance, propagule pressure, species diversity, and herbivory in determining exotic plant invasion in 10 eastern hemlock forests in pennsylvania and new jersey (usa). use of a maximum-likelihood estimation framework and information theoretics allowed us to quantify the strength of evidence for alternative models of the influence of these factors on changes in exotic plant abundance. in addition, we developed models to determine the importance of interactions between ecosystem properties and propagule pressure. these analyses were conducted for three abundant, aggressive exotic species that represent a range of life histories: alliaria petiolata, berberis thunbergii, and microstegium vimineum. of the four hypothesized determinants of exotic plant invasion considered in this study, canopy disturbance and propagule pressure appear to be the most important predictors of a. petiolata, b. thunbergii, and m. vimineum invasion. herbivory was also found to be important in contributing to the invasion of some species. in addition, we found compelling evidence of an important interaction between propagule pressure and canopy disturbance. this is the first study to demonstrate the dominant role of the interaction between canopy disturbance and propagule pressure in determining forest invasibility relative to other potential controlling factors. the importance of the disturbance-propagule supply interaction, and its nonlinear functional form, has profound implications for the management of exotic plant species populations. improving our ability to predict exotic plant invasions will require enhanced understanding of the interaction between propagule pressure and ecological resistance mechanisms.",
            "contribution_ids": [
                "R55022",
                "R57204"
            ]
        },
        {
            "instance_id": "R57501xR57128",
            "comparison_id": "R57501",
            "paper_id": "R57128",
            "text": "How does Reynoutria invasion fit the various theories of invasibility? abstract questions: 1. how does species richness of recipient communities affect reynoutria invasion? 2. how does reynoutria invasion change host community structure? 3. are there any differences in habitat preferences among three closely related reynoutria taxa? 4. how does the genetic structure of reynoutria populations change along the course of a river? location: river jizera basin, north bohemia, czech republic. methods: nine 0.25 km2 plots were chosen along the river. within each plot all main habitat types were determined and sampled using the braun-blanquet scale to determine the invasibility of various communities. the patches invaded by reynoutria taxa and surrounding reynoutria-free vegetation in the same habitat type were sampled as relev\u00e9 pairs to compare the composition of invaded and non-invaded vegetation. in addition, to characterize the genetic structure of reynoutria populations along the river, 30 samples from different clones were collected. results and conclusions: 1. the species richness of communities has no influence on the success of reynoutria invasion in the area studied. the combination of environmental conditions and propagule spread is more important to the invasion success than the number of species in the host community. 2. reynoutria invasion greatly reduces species diversity. 3. r. japonica invaded more habitat types than r. sachalinensis and r. \u00d7 bohemica. the hybrid r. \u00d7 bohemica outcompetes the parental taxa at sites where both taxa co-occur. 4. isozyme analysis revealed phenotype variability in the hybrid in contrast to the parental taxa. different hybrid phenotypes are distributed randomly on the middle and lower reaches of the river jizera; one of them dominates and the other three occur occasionally. this pattern supports the hypothesis that sexual reproduction occasionally occurs within reynoutria taxa. nomenclature: ehrendorfer (1973).",
            "contribution_ids": [
                "R57129"
            ]
        },
        {
            "instance_id": "R57501xR57245",
            "comparison_id": "R57501",
            "paper_id": "R57245",
            "text": "Filling in the gaps: modelling native species richness and invasions using spatially incomplete data detailed knowledge of patterns of native species richness, an important component of biodiversity, and non\u2010native species invasions is often lacking even though this knowledge is essential to conservation efforts. however, we cannot afford to wait for complete information on the distribution and abundance of native and harmful invasive species. using information from counties well surveyed for plants across the usa, we developed models to fill data gaps in poorly surveyed areas by estimating the density (number of species km\u22122) of native and non\u2010native plant species. here, we show that native plant species density is non\u2010random, predictable, and is the best predictor of non\u2010native plant species density. we found that eastern agricultural sites and coastal areas are among the most invaded in terms of non\u2010native plant species densities, and that the central usa appears to have the greatest ratio of non\u2010native to native species. these large\u2010scale models could also be applied to smaller spatial scales or other taxa to set priorities for conservation and invasion mitigation, prevention, and control efforts.",
            "contribution_ids": [
                "R57246"
            ]
        },
        {
            "instance_id": "R57501xR57369",
            "comparison_id": "R57501",
            "paper_id": "R57369",
            "text": "Scale and plant invasions: a theory of biotic acceptance we examined the relationship between native and alien plant species richness, cover, and estimated biomass at multiple spatial scales. the large dataset included 7051 1-m subplots, 1443 10-m subplots, and 727 100-m subplots, nested in 727 1000-m plots in 37 natural vegetation types in seven states in the central united states. we found that native and alien species richness (averaged across the vegetation types) increased significantly with plot area. furthermore, the relationship between native and alien species richness became increasingly positive and significant from the plant neighbourhood scale (1-m) to the 10-m, 100-m, and the 1000-m scale where over 80% of the vegetation types had positive slopes between native and alien species richness. both native and alien plant species may be responding to increased resource availability and/or habitat heterogeneity with increased area. we found significant positive relationships between the coefficient of variation of native cover in 1-m subplots in a vegetation type (i.e. a measure of habitat heterogeneity), and both the relative cover and relative biomass of alien plant species. at the 1000-m scale, we did find weak negative relationships between native species richness and the cover, biomass, and relative cover of alien plant species. however, we found very strong positive relationships between alien species richness and the cover, relative cover, and relative biomass of alien species at regional scales. these results, along with many other field studies in natural ecosystems, show that the dominant general pattern in invasion ecology at multiple spatial scales is one of \u201cbiotic acceptance\u201d where natural ecosystems tend to accommodate the establishment and coexistence of introduced species despite the presence and abundance of native species.",
            "contribution_ids": [
                "R57370"
            ]
        },
        {
            "instance_id": "R57501xR57265",
            "comparison_id": "R57501",
            "paper_id": "R57265",
            "text": "Species diversity and biological invasions: relating local process to community pattern in a california riparian system, the most diverse natural assemblages are the most invaded by exotic plants. a direct in situ manipulation of local diversity and a seed addition experiment showed that these patterns emerge despite the intrinsic negative effects of diversity on invasions. the results suggest that species loss at small scales may reduce invasion resistance. at community-wide scales, the overwhelming effects of ecological factors spatially covarying with diversity, such as propagule supply, make the most diverse communities most likely to be invaded.",
            "contribution_ids": [
                "R57266",
                "R57267"
            ]
        },
        {
            "instance_id": "R57501xR57296",
            "comparison_id": "R57501",
            "paper_id": "R57296",
            "text": "Species evenness and invasion resistance of experimental grassland communities concern for biodiversity loss coupled with the accelerated rate of biological invasions has provoked much interest in assessing how native plant species diversity affects invasibility. although experimental studies extensively document the effects of species richness on invader performance, the role of species evenness in such studies is rarely examined. species evenness warrants more attention because the relative abundances of species can account for substantially more of the variance in plant community diversity and tend to change more rapidly and more frequently in response to disturbances than the absolute numbers of species. in this study, we experimentally manipulated species evenness within native prairie grassland mesocosms. we assessed how evenness affected primary productivity, light availability and the resistance of native communities to invasion. the primary productivity of native communities increased significantly with species evenness, and this increase in productivity was accompanied by significant decreases in light availability. however, evenness had no effect on native community resistance to invasion by three common exotic invasive species. in this study, niche complementarity provides a potential mechanism for the effects of evenness on productivity and light availability, but these effects apparently were not strong enough to alter the invasibility of the experimental communities. our results suggest that species evenness enhances community productivity but provides no benefit to invasion resistance in otherwise functionally diverse communities.",
            "contribution_ids": [
                "R57297"
            ]
        },
        {
            "instance_id": "R57501xR57268",
            "comparison_id": "R57501",
            "paper_id": "R57268",
            "text": "Local interactions, dispersal, and native and exotic plant diversity along a California stream although the species pool, dispersal, and local interactions all influence species diversity, their relative importance is debated. i examined their importance in controlling the number of native and exotic plant species occupying tussocks formed by the sedge carex nudata along a california stream. of particular interest were the factors underlying a downstream increase in plant diversity and biological invasions. i conducted seed addition experiments and manipulated local diversity and cover to evaluate the degree to which tussocks saturate with species, and to examine the roles of local competitive processes, abiotic factors, and seed supply in controlling the system-wide patterns. seeds of three native and three exotic plants sown onto experimentally assembled tussock communities less successfully established on tussocks with a greater richness of resident plants. nonetheless, even the most diverse tussocks were somewhat colonized, suggesting that tussocks are not completely saturated with species. similarly, in an experiment where i sowed seeds onto natural tussocks along the river, colonization increased two- to three-fold when i removed the resident species. even on intact tussocks, however, seed addition increased diversity, indicating that the tussock assemblages are seed limited. colonization success on cleared and uncleared tussocks increased downstream from km 0 to km 3 of the study site, but showed no trends from km 3 to km 8. this suggests that while abiotic and biotic features of the tussocks may control the increase in diversity and invasions from km 0 to km 3, similar increases from km 3 to km 8 are more likely explained by potential downstream increases in seed supply. the effective water dispersal of seed mimics and prevailingly downstream winds indicated that dispersal most likely occurs in a downstream direction. these results suggest that resident species diversity, competitive interactions, and seed supply similarly influence the colonization of native and exotic species.",
            "contribution_ids": [
                "R57269"
            ]
        },
        {
            "instance_id": "R57501xR57290",
            "comparison_id": "R57501",
            "paper_id": "R57290",
            "text": "Effects of native species diversity and resource additions on invader impact theory and empirical work have demonstrated that diverse communities can inhibit invasion. yet, it is unclear how diversity influences invader impact, how impact varies among exotics, and what the relative importance of diversity is versus extrinsic factors that themselves can influence invasion. to address these issues, we established plant assemblages that varied in native species and functional richness and crossed this gradient in diversity with resource (water) addition. identical assemblages were either uninvaded or invaded with one of three exotic forbs: spotted knapweed (centaurea maculosa), dalmatian toadflax (linaria dalmatica), or sulfur cinquefoil (potentilla recta). to determine impacts, we measured the effects of exotics on native biomass and, for spotted knapweed, on soil moisture and nitrogen levels. assemblages with high species richness were less invaded and less impacted than less diverse assemblages. impact scaled with exotic biomass; spotted knapweed had the largest impact on native biomass compared with the other exotics. although invasion depressed native biomass, the net result was to increase total community yield. water addition increased invasibility (for knapweed only) but had no effect on invader impact. together, these results suggest that diversity inhibits invasion and reduces impact more than resource additions facilitate invasion or impact.",
            "contribution_ids": [
                "R57291"
            ]
        },
        {
            "instance_id": "R57501xR57157",
            "comparison_id": "R57501",
            "paper_id": "R57157",
            "text": "Human-related processes drive the richness of exotic birds in Europe \\n both human-related and natural factors can affect the establishment and distribution of exotic species. understanding the relative role of the different factors has important scientific and applied implications. here, we examined the relative effect of human-related and natural factors in determining the richness of exotic bird species established across europe. using hierarchical partitioning, which controls for covariation among factors, we show that the most important factor is the human-related community-level propagule pressure (the number of exotic species introduced), which is often not included in invasion studies due to the lack of information for this early stage in the invasion process. another, though less important, factor was the human footprint (an index that includes human population size, land use and infrastructure). biotic and abiotic factors of the environment were of minor importance in shaping the number of established birds when tested at a european extent using 50\u00d750\\u200akm\\n 2 \\n grid squares. we provide, to our knowledge, the first map of the distribution of exotic bird richness in europe. the richest hotspot of established exotic birds is located in southeastern england, followed by areas in belgium and the netherlands. community-level propagule pressure remains the major factor shaping the distribution of exotic birds also when tested for the uk separately. thus, studies examining the patterns of establishment should aim at collecting the crucial and hard-to-find information on community-level propagule pressure or develop reliable surrogates for estimating this factor. allowing future introductions of exotic birds into europe should be reconsidered carefully, as the number of introduced species is basically the main factor that determines the number established.\\n",
            "contribution_ids": [
                "R57158"
            ]
        },
        {
            "instance_id": "R57501xR54661",
            "comparison_id": "R57501",
            "paper_id": "R54661",
            "text": "Invasibility and abiotic gradients: the positive correlation between native and exotic plant diversity we sampled the understory community in an old-growth, temperate forest to test alternative hypotheses explaining the establishment of exotic plants. we quantified the individual and net importance of distance from areas of human disturbance, native plant diversity, and environmental gradients in determining exotic plant establishment. distance from disturbed areas, both within and around the reserve, was not correlated to exotic species richness. numbers of native and exotic species were positively correlated at large (50 m 2 ) and small (10 m 2 ) plot sizes, a trend that persisted when relationships to environ- mental gradients were controlled statistically. both native and exotic species richness in- creased with soil ph and decreased along a gradient of increasing nitrate availability. exotic species were restricted to the upper portion of the ph gradient and had individualistic responses to the availability of soil resources. these results are inconsistent with both the diversity-resistance and resource-enrichment hypotheses for invasibility. environmental conditions favoring native species richness also favor exotic species richness, and com- petitive interactions with the native flora do not appear to limit the entry of additional species into the understory community at this site. it appears that exotic species with niche requirements poorly represented in the regional flora of native species may establish with relatively little resistance or consequence for native species richness.",
            "contribution_ids": [
                "R54662",
                "R57218"
            ]
        },
        {
            "instance_id": "R57501xR57197",
            "comparison_id": "R57501",
            "paper_id": "R57197",
            "text": "Invasibility of experimental grassland communities: the role of earthworms, plant functional group identity and seed size invasions of natural communities by non-indigenous species threaten native biodiversity and are currently rated as one of the most important global-scale environmental problems. the mechanisms that make communities resistant to invasions and drive the establishment success of seedlings are essential both for management and for understanding community assembly and structure. especially in grasslands, anecic earthworms are known to function as ecosystem engineers, however, their direct effects on plant community composition and on the invasibility of plant communities via plant seed burial, ingestion and digestion are poorly understood. in a greenhouse experiment we investigated the impact of lumbricus terrestris, plant functional group identity and seed size of plant invader species and plant functional group of the established plant community on the number and biomass of plant invaders. we set up 120 microcosms comprising four plant community treatments, two earthworm treatments and three plant invader treatments containing three seed size classes. earthworm performance was influenced by an interaction between plant functional group identity of the established plant community and that of invader species. the established plant community and invader seed size affected the number of invader plants significantly, while invader biomass was only affected by the established community. since earthworm effects on the number and biomass of invader plants varied with seed size and plant functional group identity they probably play a key role in seedling establishment and plant community composition. seeds and germinating seedlings in earthworm burrows may significantly contribute to earthworm nutrition, but this deserves further attention. lumbricus terrestris likely behaves like a \u2018farmer\u2019 by collecting plant seeds which cannot directly be swallowed or digested. presumably, these seeds are left in middens and become eatable after partial microbial decay. increased earthworm numbers in more diverse plant communities likely contribute to the positive relationship between plant species diversity and resistance against invaders.",
            "contribution_ids": [
                "R57198"
            ]
        },
        {
            "instance_id": "R57501xR57307",
            "comparison_id": "R57501",
            "paper_id": "R57307",
            "text": "Plant diversity increases resistance to invasion in the absence of covarying extrinsic factors \"biological invasion is a widespread, but poorly understood phenomenon. elton's hypothesis, supported by theory, experiment, and anecdotal evidence, suggests that an important determinant of invasion success is resident biodiversity, arguing that high diversity increases the competitive environment of communities and makes them more difficult to invade. observational studies of plant invasions, however, find little support for this hypothesis and argue strongly against it. lack of control of extrinsic factors (e.g., disturbance, climate, or soil fertility) that covary with biodiversity and invasion in observational studies makes it difficult to determine if their findings truly refute elton's hypothesis. we examined performance of crepis tectorum (an invasive, annual composite weed) in experimental prairie grassland plots and greenhouse plant assemblages in which resident species richness was directly manipulated. under these conditions, unlike observational studies, no covarying extrinsic factors could interfere with interpreting results, we found a strong inverse association between resident diversity and invader performance as predicted by elton's hypothesis. higher resident diversity increased crowding, decreased available light, and decreased available nutrients all of which increased the competitive environment of diverse plant assemblages and reduced c. tectorum success, examination of individual resident species impacts on c. tectorum performance demonstrated that this diversity effect was not due to the sampling effect. these results suggest that both elton's hypothesis and its competitive mechanism may operate in nature, but covarying extrinsic factors may obscure the negative impact of diversity on invader success.\"",
            "contribution_ids": [
                "R57308"
            ]
        },
        {
            "instance_id": "R57501xR57273",
            "comparison_id": "R57501",
            "paper_id": "R57273",
            "text": "Phalaris arundinacea seedling establishment: effects of canopy complexity in fen, mesocosm, and restoration experiments phalaris arundinacea l. (reed canary grass) is a major invader of wetlands in temperate north america; it creates monotypic stands and displaces native vegetation. in this study, the effect of plant canopies on the establishment of p. arundinacea from seed in a fen, fen-like mesocosms, and a fen restoration site was assessed. in wingra fen, canopies that were more resistant to p. arundinacea establishment had more species (eight or nine versus four to six species) and higher cover of aster firmus. in mesocosms planted with glyceria striata plus 1, 6, or 15 native species, all canopies closed rapidly and prevented p. arundinacea establishment from seed, regardless of the density of the matrix species or the number of added species. only after gaps were created in the canopy was p. arundinacea able to establish seedlings; then, the 15-species treatment reduced establishment to 48% of that for single-species canopies. a similar experiment in the restoration site produced less cover of native plants, and p. a...",
            "contribution_ids": [
                "R57274"
            ]
        },
        {
            "instance_id": "R57501xR57277",
            "comparison_id": "R57501",
            "paper_id": "R57277",
            "text": "Functional group dominance and identity effects influence the magnitude of grassland invasion variation in functional community composition is expected to influence the extent of exotic species invasions. yet, whether resident functional groups control invasion through their relative biomass (mass ratio hypothesis) or by traits other than biomass (identity hypothesis) remains poorly understood. we performed a 6\u2010year experiment to determine the effects of removing different functional groups on exotic species biomass in a flooding pampa grassland, argentina. functional groups were defined by life\u2010form (grasses or forbs), phenology (winter or summer) and origin (native or exotic). removal of each functional group was compared against the removal of an equivalent amount of random biomass. exotic group responses were monitored over 4 years of continuous removals, and after 2 years of recovery without manipulations. removal of dominant native summer grasses caused the greatest impact on exotic species and overall community composition. native summer\u2010grass removal significantly increased exotic grass (120%) and forb (730%) biomass beyond the level (46% and 180%, respectively) expected from deleting a similar amount of biomass at random. exotic annual grasses showed only a transient increase, whereas exotic forb invasion persisted even after 2 years without removals. removing subordinate, native or exotic winter grasses, and rare native forbs significantly promoted exotic forbs, but to the same level (300%) as random biomass removals. total grass removal increased exotic forbs to half the extent expected from adding the effects of single grass group removals. dispersal limitation and harsh abiotic conditions may constrain exotic forb spread into such heavily grass\u2010depleted patches. synthesis. the impact of losing a functional group on the magnitude and persistence of invasion reflected its relative contribution to community biomass. identity attributes other than biomass (e.g. phenological niche) further enhanced the biotic control that dominant native grasses exerted on established exotic species. our findings highlight the community legacies of past disturbances to dominant functional groups.",
            "contribution_ids": [
                "R57278"
            ]
        },
        {
            "instance_id": "R57501xR55050",
            "comparison_id": "R57501",
            "paper_id": "R55050",
            "text": "ECOLOGICAL RESISTANCE TO BIOLOGICAL INVASION OVERWHELMED BY PROPAGULE PRESSURE models and observational studies have sought patterns of predictability for invasion of natural areas by nonindigenous species, but with limited success. in a field experiment using forest understory plants, we jointly manipulated three hypothesized determinants of biological invasion outcome: resident diversity, physical disturbance and abiotic conditions, and propagule pressure. the foremost constraints on net habitat invasibility were the number of propagules that arrived at a site and naturally varying resident plant density. the physical environment (flooding regime) and the number of established resident species had negligible impact on habitat invasibility as compared to propagule pressure, despite manipulations that forced a significant reduction in resident richness, and a gradient in flooding from no flooding to annual flooding. this is the first experimental study to demonstrate the primacy of propagule pressure as a determinant of habitat invasibility in comparison with other candidate controlling factors.",
            "contribution_ids": [
                "R55051",
                "R55052",
                "R57386"
            ]
        },
        {
            "instance_id": "R57501xR57284",
            "comparison_id": "R57501",
            "paper_id": "R57284",
            "text": "Scale dependent relationships between native plant diversity and the invasion of croftonweed (Eupatorium adenophorum) in southwest China abstract croftonweed is an invasive plant in southwest china. we examined the relationships between its invasion patterns and native plant diversity at different spatio-temporal scales. at the 25 m2 scale, invasion success was negatively correlated with native plant diversity, indicating that resource availability might be the dominant factor regulating community invasibility. at the 400-m2 scale, both negative and positive relationships were detected, possibly identifying a spatial scale threshold where extrinsic environmental factors became more important to community invasibility. at the vegetation province scale, variations in physical environment outweighed the importance of intrinsic biotic factors and positive relationships between diversity and invader success were found. native plant diversity also inhibited croftonweed over the course of community succession and at the early stages of invasion at local spatial scales. however, the changing relationship might be an artifact of sampling at different spatial scales. nomenclature:\\u2003croftonweed, eupatorium adenophorum sprengel eupad.",
            "contribution_ids": [
                "R57285"
            ]
        },
        {
            "instance_id": "R57501xR57175",
            "comparison_id": "R57501",
            "paper_id": "R57175",
            "text": "Native communities determine the identity of exotic invaders even at scales at which communities are unsaturated aim\\u2002 to determine why some communities are more invasible than others and how this depends on spatial scale. our previous work in serpentine ecosystems showed that native and exotic diversity are negatively correlated at small scales, but became positively correlated at larger scales. we hypothesized that this pattern was the result of classic niche partitioning at small scales where the environment is homogeneous, and a shift to the dominance of coexistence mechanisms that depend on spatial heterogeneity in the environment at large scales.",
            "contribution_ids": [
                "R57176"
            ]
        },
        {
            "instance_id": "R57501xR57207",
            "comparison_id": "R57501",
            "paper_id": "R57207",
            "text": "Diversity and biomass of native macrophytes are negatively related to dominance of an invasive Poaceae in Brazilian sub-tropical streams \" besides exacerbated exploitation, pollution, flow alteration and habitats degradation, freshwater biodiversity is also threatened by biological invasions. this paper addresses how native aquatic macrophyte communities are affected by the non-native species urochloa arrecta, a current successful invader in brazilian freshwater systems. we compared the native macrophytes colonizing patches dominated and non-dominated by this invader species. we surveyed eight streams in northwest paran\u00e1 state (brazil). in each stream, we recorded native macrophytes' richness and biomass in sites where u. arrecta was dominant and in sites where it was not dominant or absent. no native species were found in seven, out of the eight investigated sites where u. arrecta was dominant. thus, we found higher native species richness, shannon index and native biomass values in sites without dominance of u. arrecta than in sites dominated by this invader. although difficult to conclude about causes of such differences, we infer that the elevated biomass production by this grass might be the primary reason for alterations in invaded environments and for the consequent impacts on macrophytes' native communities. however, biotic resistance offered by native richer sites could be an alternative explanation for our results. to mitigate potential impacts and to prevent future environmental perturbations, we propose mechanical removal of the invasive species and maintenance or restoration of riparian vegetation, for freshwater ecosystems have vital importance for the maintenance of ecological services and biodiversity and should be preserved. \"",
            "contribution_ids": [
                "R57208"
            ]
        },
        {
            "instance_id": "R57501xR57256",
            "comparison_id": "R57501",
            "paper_id": "R57256",
            "text": "Opposite relationships between invasibility and native species richness at patch versus landscape scales of native species. in 1 m 2 patches, native cover was positively associated with native richness and thus cover-related competition was a likely mechanism by which richness influenced r. cathartica . at the landscape scale (comparing the aggregate stand-scale metrics among the 17 stands), native cover and richness were still positively related, but had opposite relationships with r. cathartica cover. r. cathartica cover was positively related to species richness and negatively related to native species cover. the observed switch at different scales from a positive to a negative relationship between r. cathartica cover and native richness supported the hypothesized scale dependence of these relations. propagule pressure, which we estimated by measuring the size of nearby mature r. cathartica shrubs, had a large positive effect on r. cathartica seedling cover at the landscape scale. these results suggest that landscape patterns of invasion may be best understood in light of the combination of many factors including native diversity, native cover, and propagule pressure.",
            "contribution_ids": [
                "R57257"
            ]
        },
        {
            "instance_id": "R57501xR54984",
            "comparison_id": "R57501",
            "paper_id": "R54984",
            "text": "Global patterns of introduction effort and establishment success in birds theory suggests that introduction effort (propagule size or number) should be a key determinant of establishment success for exotic species. unfortunately, however, propagule pressure is not recorded for most introductions. studies must therefore either use proxies whose efficacy must be largely assumed, or ignore effort altogether. the results of such studies will be flawed if effort is not distributed at random with respect to other characteristics that are predicted to influence success. we use global data for more than 600 introduction events for birds to show that introduction effort is both the strongest correlate of introduction success, and correlated with a large number of variables previously thought to influence success. apart from effort, only habitat generalism relates to establishment success in birds.",
            "contribution_ids": [
                "R54985",
                "R54986",
                "R56086",
                "R57152"
            ]
        },
        {
            "instance_id": "R57501xR57321",
            "comparison_id": "R57501",
            "paper_id": "R57321",
            "text": "Biotic acceptance in introduced amphibians and reptiles in Europe and North America aim \\n \\nthe biotic resistance hypothesis argues that complex plant and animal communities are more resistant to invasion than simpler communities. conversely, the biotic acceptance hypothesis states that non-native and native species richness are positively related. most tests of these hypotheses at continental scales, typically conducted on plants, have found support for biotic acceptance. we tested these hypotheses on both amphibians and reptiles across europe and north america. \\n \\n \\n \\nlocation \\n \\ncontinental countries in europe and states/provinces in north america. \\n \\n \\n \\nmethods \\n \\nwe used multiple linear regression models to determine which factors predicted successful establishment of amphibians and reptiles in europe and north america, and additional models to determine which factors predicted native species richness. \\n \\n \\n \\nresults \\n \\nsuccessful establishment of amphibians and reptiles in europe and reptiles in north america was positively related to native species richness. we found higher numbers of successful amphibian species in europe than in north america. potential evapotranspiration (pet) was positively related to non-native species richness for amphibians and reptiles in europe and reptiles in north america. pet was also the primary factor determining native species richness for both amphibians and reptiles in europe and north america. \\n \\n \\n \\nmain conclusions \\n \\nwe found support for the biotic acceptance hypothesis for amphibians and reptiles in europe and reptiles in north america, suggesting that the presence of native amphibian and reptile species generally indicates good habitat for non-native species. our data suggest that the greater number of established amphibians per native amphibians in europe than in north america might be explained by more introductions in europe or climate-matching of the invaders. areas with high native species richness should be the focus of control and management efforts, especially considering that non-native species located in areas with a high number of natives can have a large impact on biological diversity.",
            "contribution_ids": [
                "R57322"
            ]
        },
        {
            "instance_id": "R57501xR57309",
            "comparison_id": "R57501",
            "paper_id": "R57309",
            "text": "Weak vs. strong invaders of natural plant communities: Assessing invasibility and impact in response to the profound threat of exotic species to natural systems, much attention has been focused on the biotic resistance hypothesis, which predicts that diverse communities should better resist invasions. while studies of natural communities generally refute this hypothesis, reporting positive relationships between native species diversity and invasibility, some local-scale studies have instead obtained negative relationships. most treatments of the topic have failed to recognize that all exotic invaders do not behave alike: while \u201cweak\u201d invaders become minor components of communities, \u201cstrong\u201d invaders become community dominants at the expense of native species. at the same time, the specific impacts of strong invaders on communities are poorly documented yet critical to understanding implications of diversity loss. with these shortfalls in mind, we examined local-scale relationships between native and exotic plant taxa in bunchgrass communities of western montana, usa. we found that measures of...",
            "contribution_ids": [
                "R57310"
            ]
        },
        {
            "instance_id": "R57501xR52120",
            "comparison_id": "R57501",
            "paper_id": "R52120",
            "text": "Plant functional group diversity as a mechanism for invasion resistance a commonly cited mechanism for invasion resistance is more complete resource use by diverse plant assemblages with maximum niche complementarity. we investigated the invasion resistance of several plant functional groups against the nonindigenous forb spotted knapweed (centaurea maculosa). the study consisted of a factorial combination of seven functional group removals (groups singularly or in combination) and two c. maculosa treatments (addition vs. no addition) applied in a randomized complete block design replicated four times at each of two sites. we quantified aboveground plant material nutrient concentration and uptake (concentration \u00d7 biomass) by indigenous functional groups: grasses, shallow\u2010rooted forbs, deep\u2010rooted forbs, spikemoss, and the nonindigenous invader c. maculosa. in 2001, c. maculosa density depended upon which functional groups were removed. the highest c. maculosa densities occurred where all vegetation or all forbs were removed. centaurea maculosa densities were the lowest in plots where nothing, shallow\u2010rooted forbs, deep\u2010rooted forbs, grasses, or spikemoss were removed. functional group biomass was also collected and analyzed for nitrogen, phosphorus, potassium, and sulphur. based on covariate analyses, postremoval indigenous plot biomass did not relate to invasion by c. maculosa. analysis of variance indicated that c. maculosa tissue nutrient percentage and net nutrient uptake were most similar to indigenous forb functional groups. our study suggests that establishing and maintaining a diversity of plant functional groups within the plant community enhances resistance to invasion. indigenous plants of functionally similar groups as an invader may be particularly important in invasion resistance.",
            "contribution_ids": [
                "R52121",
                "R57323"
            ]
        },
        {
            "instance_id": "R57501xR57367",
            "comparison_id": "R57501",
            "paper_id": "R57367",
            "text": "Exotic plant species invade hot spots of native plant diversity some theories and experimental studies suggest that areas of low plant spe- cies richness may be invaded more easily than areas of high plant species richness. we gathered nested-scale vegetation data on plant species richness, foliar cover, and frequency from 200 1-m 2 subplots (20 1000-m 2 modified-whittaker plots) in the colorado rockies (usa), and 160 1-m 2 subplots (16 1000-m 2 plots) in the central grasslands in colorado, wyoming, south dakota, and minnesota (usa) to test the generality of this paradigm. at the 1-m 2 scale, the paradigm was supported in four prairie types in the central grasslands, where exotic species richness declined with increasing plant species richness and cover. at the 1-m 2 scale, five forest and meadow vegetation types in the colorado rockies contradicted the paradigm; exotic species richness increased with native-plant species richness and foliar cover. at the 1000-m 2 plot scale (among vegetation types), 83% of the variance in exotic species richness in the central grasslands was explained by the total percentage of nitrogen in the soil and the cover of native plant species. in the colorado rockies, 69% of the variance in exotic species richness in 1000-m 2 plots was explained by the number of native plant species and the total percentage of soil carbon. at landscape and biome scales, exotic species primarily invaded areas of high species richness in the four central grasslands sites and in the five colorado rockies vegetation types. for the nine vegetation types in both biomes, exotic species cover was positively correlated with mean foliar cover, mean soil percentage n, and the total number of exotic species. these patterns of invasibility depend on spatial scale, biome and vegetation type, spatial autocorrelation effects, availability of resources, and species-specific responses to grazing and other disturbances. we conclude that: (1) sites high in herbaceous foliar cover and soil fertility, and hot spots of plant diversity (and biodiversity), are invasible in many landscapes; and (2) this pattern may be more closely related to the degree resources are available in native plant communities, independent of species richness. exotic plant in- vasions in rare habitats and distinctive plant communities pose a significant challenge to land managers and conservation biologists.",
            "contribution_ids": [
                "R57368"
            ]
        },
        {
            "instance_id": "R57501xR57378",
            "comparison_id": "R57501",
            "paper_id": "R57378",
            "text": "Continental rain forest fragments in Singapore resist invasion by exotic plants abstract aim\\u2002 in general, the plant communities of oceanic islands suffer more from exotic plant invasions than their continental equivalents. at least part of this difference may be contributed by differences in non\u2010biological factors, such as the antiquity and intensity of human impacts and the absence of internal barriers to dispersal, rather than differences in inherent invasibility. we tested the resistance of species\u2010rich continental rain forests to plant invasion on a small, continental island that has been subject to prolonged and intensive human impact.",
            "contribution_ids": [
                "R57379"
            ]
        },
        {
            "instance_id": "R57501xR57261",
            "comparison_id": "R57501",
            "paper_id": "R57261",
            "text": "Invasibility of plankton food webs along a trophic state gradient biological invasions are becoming more common, yet the majority of introduced exotic species fail to establish viable populations in new environments. current ecological research suggests that invasion success may be determined by properties of the native ecosystem, such as the supply rate of limiting nutrients (i.e. trophic state). we examined how trophic state influences invasion success by introducing an exotic zooplankter, daphnia lumholtzi into native plankton communities in a series of experimental mesocosms exposed to a strong nutrient gradient. we predicted that the attributes of nutrient-enriched communities would increase the likelihood of a successful invasion attempt by d. lumholtzi. contrary to our original predictions, we found that d. lumholtzi was often absent from mesocosms that developed under high nutrient supply rates. instead, the presence of d. lumholtzi was associated with systems that had low nutrients, low zooplankton biomass, and high zooplankton species diversity. using generalized estimating equations (gee) and multivariate species data, we found that the presence-absence of d. lumholtzi could be explained by variations in zooplankton community structure, which was itself strongly influenced by nutrient supply rate. we argue that the apparent invasion success of d. lumholtzi was inhibited by the dominance of another cladoceran species, chydorus sphaericus. these results suggest that the interaction between trophic state and species identity influenced the invasion success of introduced d. lumholtzi.",
            "contribution_ids": [
                "R57262"
            ]
        },
        {
            "instance_id": "R57501xR55061",
            "comparison_id": "R57501",
            "paper_id": "R55061",
            "text": "Determinants of vertebrate invasion success in Europe and North America \"species that are frequently introduced to an exotic range have a high potential of becoming invasive. besides propagule pressure, however, no other generally strong determinant of invasion success is known. although evidence has accumulated that human affiliates (domesticates, pets, human commensals) also have high invasion success, existing studies do not distinguish whether this success can be completely explained by or is partly independent of propagule pressure. here, we analyze both factors independently, propagule pressure and human affiliation. we also consider a third factor directly related to humans, hunting, and 17 traits on each species' population size and extent, diet, body size, and life history. our dataset includes all 2362 freshwater fish, mammals, and birds native to europe or north america. in contrast to most previous studies, we look at the complete invasion process consisting of (1) introduction, (2) establishment, and (3) spread. in this way, we not only consider which of the introduced species became invasive but also which species were introduced. of the 20 factors tested, propagule pressure and human affiliation were the two strongest determinants of invasion success across all taxa and steps. this was true for multivariate analyses that account for intercorrelations among variables as well as univariate analyses, suggesting that human affiliation influenced invasion success independently of propagule pressure. some factors affected the different steps of the invasion process antagonistically. for example, game species were much more likely to be introduced to an exotic continent than nonhunted species but tended to be less likely to establish themselves and spread. such antagonistic effects show the importance of considering the complete invasion process.\"",
            "contribution_ids": [
                "R55062",
                "R55063",
                "R57248"
            ]
        },
        {
            "instance_id": "R57501xR57187",
            "comparison_id": "R57501",
            "paper_id": "R57187",
            "text": "Diversity of locust gut bacteria protects against pathogen invasion diversity-invasibility relationships were explored in the novel context of the colonization resistance provided by gut bacteria of the desert locust schistocerca gregaria against pathogenic bacteria. germ-free insects were associated with various combinations of one to three species of locust gut bacteria and then fed an inoculum of the pathogenic bacterium serratia marcescens. there was a significant negative relationship between the resulting density of serratia marcescens and the number of symbiotic gut bacterial species present. likewise there was a significant inverse relationship between community diversity and the proportion of locusts that harboured serratia. host mortality was not negatively correlated with resistance to gut-invasion by serratia marcescens, although there were significantly more deaths among pathogen fed germ-free insects than tri-associated gnotobiotes. the outcome is consistent with the predictions of community ecology theory that species-rich communities are more resistant to invasion than species-poor communities.",
            "contribution_ids": [
                "R57188"
            ]
        },
        {
            "instance_id": "R57501xR57109",
            "comparison_id": "R57501",
            "paper_id": "R57109",
            "text": "The abiotic and biotic factors limiting establishment of predatory fishes at their expanding northern range boundaries in Ontario, Canada there is a poor understanding of the importance of biotic interactions in determining species distributions with climate change. theory from invasion biology suggests that the success of species introductions outside of their historical ranges may be either positively (biotic acceptance) or negatively (biotic resistance) related to native biodiversity. using data on fish community composition from two survey periods separated by approximately 28 years during which climate was warming, we examined the factors influencing the establishment of three predatory centrarchids: smallmouth bass (micropterus dolomieu), largemouth bass (m. salmoides), and rock bass (ambloplites rupestris) in lakes at their expanding northern range boundaries in ontario. variance partitioning demonstrated that, at a regional scale, abiotic factors play a stronger role in determining the establishment of these species than biotic factors. pairing lakes within watersheds where each species had established with lakes sharing similar abiotic conditions where the species had not established revealed both positive and negative relationships between the establishment of centrarchids and the historical presence of other predatory species. the establishment of these species near their northern range boundaries is primarily determined by abiotic factors at a regional scale; however, biotic factors become important at the lake\u2010to\u2010lake scale. studies of exotic species invasions have previously highlighted how spatial scale mediates the importance of abiotic vs. biotic factors on species establishment. our study demonstrates how concepts from invasion biology can inform our understanding of the factors controlling species distributions with changing climate.",
            "contribution_ids": [
                "R57110"
            ]
        },
        {
            "instance_id": "R57501xR52122",
            "comparison_id": "R57501",
            "paper_id": "R52122",
            "text": "Grassland invader responses to realistic changes in native species richness the importance of species richness for repelling exotic plant invasions varies from ecosystem to ecosystem. thus, in order to prioritize conservation objectives, it is critical to identify those ecosystems where decreasing richness will most greatly magnify invasion risks. our goal was to determine if invasion risks greatly increase in response to common reductions in grassland species richness. we imposed treatments that mimic management-induced reductions in grassland species richness (i.e., removal of shallow- and/or deep-rooted forbs and/or grasses and/or cryptogam layers). then we introduced and monitored the performance of a notorious invasive species (i.e., centaurea maculosa). we found that, on a per-gram-of-biomass basis, each resident plant group similarly suppressed invader growth. hence, with respect to preventing c. maculosa invasions, maintaining overall productivity is probably more important than maintaining the productivity of particular plant groups or species. but at the sites we studied, all plant groups may be needed to maintain overall productivity because removing forbs decreased overall productivity in two of three years. alternatively, removing forbs increased productivity in another year, and this led us to posit that removing forbs may inflate the temporal productivity variance as opposed to greatly affecting time-averaged productivity. in either case, overall productivity responses to single plant group removals were inconsistent and fairly modest, and only when all plant groups were removed did c. maculosa growth increase substantially over a no-removal treatment. as such, it seems that intense disturbances (e.g., prolonged drought, overgrazing) that deplete multiple plant groups may often be a prerequisite for c. maculosa invasion.",
            "contribution_ids": [
                "R52123",
                "R57340"
            ]
        },
        {
            "instance_id": "R57501xR57241",
            "comparison_id": "R57501",
            "paper_id": "R57241",
            "text": "Tree species diversity reduces the invasibility of maritime pine stands by the bast scale, Matsucoccus feytaudi (Homoptera: Margarodidae) \"species-rich plant communities may be more resistant to invasive herbivores because of reduced host-plant accessibility and increased natural enemy diversity and abundance. we tested these hypotheses in corsica, a mediterra- nean island recently invaded by the maritime pine bast scale, matsucoccus feytaudi duc., which causes widespread tree mortality in pinus pinaster ait. the endemic matsucoccus pini green infests corsican pine, pinus nigra laricio poiret, where it is controlled by the native predatory bug elatophilus nigricornis zetterstedt. as revealed by kairomone trap- ping, e. nigricornis was most abundant in pure corsican pine in areas not yet colonized by m. feytaudi, and in pure maritime pine its density decreased with the distance from the nearest corsican pine forest. the abundance of m. feytaudi was compared in five pairs of pure maritime pine and mixed maritime and corsican pine stands. it was consistently higher in pure than in mixed maritime pine stands, whereas e. nigricornis showed the opposite pattern, and relative differences were correlated with the proportion of corsican pine in the mixture. the predation by e. nigricornis was manipulated in pure maritime pine stands using synthetic attractants of the predator. matsucoccus feytaudi density was significantly reduced in maritime pines baited with kairomone dispensers. resume : les communautes vegetales riches en especes seraient plus resistantes aux invasions d'herbivores en limitant l'accessibilite aux plantes hotes et en favorisant les ennemis naturels generalistes. nous avons teste ces hypotheses en corse, une ile mediterraneenne recemment envahie par la cochenille du pin maritime matsucoccus feytaudi duc., une espece qui provoque une mortalite generalisee du pin maritime (pinus pinaster ait.). l'espece endemique matsucoccus pini green, sur pin laricio (pinus nigra laricio poiret), est controlee par la punaise predatrice elatophilus nigricornis zetterstedt. utilisant le piegeage kairomonal, nous avons montre que, hors de la zone envahie par m. feytaudi, l'abondance de e. nigricornis est maximale dans les peuplements purs de pin laricio. dans les peuplements de pin ma- ritime, elle decroit avec leur distance au plus proche pin laricio. les densites de m. feytaudi ont ete comparees dans cinq paires de peuplements purs de pin maritime ou melanges avec du pin laricio. elles sont significativement plus ele- vees dans les peuplements purs de pin maritime alors que e. nigricornis montre une distribution inverse. ces differen- ces entre peuplements purs et mixtes sont correlees a la proportion de pin laricio dans les melanges. en attirant e. nigricornis a l'aide de kairomones dans des peuplements purs de pin maritime, une reduction significative du taux d'accroissement des populations de m. feytaudi a ete observee.\"",
            "contribution_ids": [
                "R57242"
            ]
        },
        {
            "instance_id": "R57501xR57303",
            "comparison_id": "R57501",
            "paper_id": "R57303",
            "text": "Native macrophyte density and richness affect the invasiveness of a tropical Poaceae species the role of the native species richness and density in ecosystem invasibility is a matter of concern for both ecologists and managers. we tested the hypothesis that the invasiveness of urochloa arrecta (non-native in the neotropics) is negatively affected by the species richness and abundance of native aquatic macrophytes in freshwater ecosystems. we first created four levels of macrophyte richness in a greenhouse (richness experiment), and we then manipulated the densities of the same native species in a second experiment (density experiment). when the native macrophytes were adults, fragments of u. arrecta were added, and their growth was assessed. our results from the richness experiment corroborated the hypothesis of a negative relationship between the native species richness and the growth of u. arrecta, as measured by sprout length and root biomass. however, the resistance to invasion was not attributed to the presence of a particular native species with a greater competitive ability. in the density experiment, u. arrecta growth decreased significantly with an increased density of all five of the native species. density strongly affected the performance of the poaceae in a negative manner, suggesting that patches that are densely colonized by native macrophytes and less subject to disturbances will be more resistant to invasion than those that are poorly colonized and more commonly subjected to disturbances. our density experiment also showed that some species exhibit a higher competitive ability than others (sampling effect). although native richness and abundance clearly limit the colonization and establishment of u. arrecta, these factors cannot completely prevent the invasion of aquatic ecosystems by this poaceae species.",
            "contribution_ids": [
                "R57304"
            ]
        },
        {
            "instance_id": "R57501xR57401",
            "comparison_id": "R57501",
            "paper_id": "R57401",
            "text": "Realistic species losses disproportionately reduce grassland resistance to biological invaders consequences of progressive biodiversity declines depend on the functional roles of individual species and the order in which species are lost. most studies of the biodiversity\u2013ecosystem functioning relation tackle only the first of these factors. we used observed variation in grassland diversity to design an experimental test of how realistic species losses affect invasion resistance. because entire plant functional groups disappeared faster than expected by chance, resistance declined dramatically with progressive species losses. realistic biodiversity losses, even of rare species, can thus affect ecosystem processes far more than indicated by randomized-loss experiments.",
            "contribution_ids": [
                "R57402"
            ]
        },
        {
            "instance_id": "R57501xR57326",
            "comparison_id": "R57501",
            "paper_id": "R57326",
            "text": "Plant community diversity and invasibility by exotics: invasion of Mediterranean old fields by Conyza bonariensis and Conyza canadensis a series of communities were established in situ to differentiate the effects of species richness, functional richness and functional group identity on invasibility of mediterranean annual old fields. we monitored the demographic and vegetative parameters of two exotic annuals introduced as seedlings, conyza bonariensis and c. canadensis. community species richness and functional composition determined resistance to invasion by conyza.conyza bonariensis biomass decreased with increasing species richness. legumes increased the biomass and consequently the net fecundity of both conyza, while survival was favoured by asteraceae. communities with fewer asteraceae and grasses increased the reproductive effort of c. bonariensis. a separate glasshouse experiment using the same species mixes revealed that establishment of conyza decreased with increasing species richness or when grasses were present. patterns of conyza performance are interpreted in the light of measurements of ecosystem functional parameters, making it possible to formulate hypotheses about mechanisms limiting community invasibility.",
            "contribution_ids": [
                "R57327"
            ]
        },
        {
            "instance_id": "R57501xR57179",
            "comparison_id": "R57501",
            "paper_id": "R57179",
            "text": "Spatial heterogeneity explains the scale dependence of the native-exotic diversity relationship while small-scale studies show that more diverse native communities are less invasible by exotics, studies at large spatial scales often find positive correlations between native and exotic diversity. this large-scale pattern is thought to arise because landscapes with favorable conditions for native species also have favorable conditions for exotic species. from theory, we proposed an alternative hypothesis: the positive relationship at large scales is driven by spatial heterogeneity in species composition, which is driven by spatial heterogeneity in the environment. landscapes with more spatial heterogeneity in the environment can sustain more native and more exotic species, leading to a positive correlation of native and exotic diversity at large scales. in a nested data set for grassland plants, we detected negative relationships between native and exotic diversity at small spatial scales and positive relationships at large spatial scales. supporting our hypothesis, the positive relationships between native and exotic diversity at large scales were driven by positive relationships between native and exotic beta diversity. further, both native and exotic diversity were positively correlated with spatial heterogeneity in abiotic conditions (variance of soil depth, soil nitrogen, and aspect) but were uncorrelated with average abiotic conditions, supporting the spatial-heterogeneity hypothesis but not the favorable-conditions",
            "contribution_ids": [
                "R57180"
            ]
        },
        {
            "instance_id": "R57501xR56996",
            "comparison_id": "R57501",
            "paper_id": "R56996",
            "text": "Invasion success of vertebrates in Europe and North America \\n species become invasive if they (\\n i \\n ) are introduced to a new range, (\\n ii \\n ) establish themselves, and (\\n iii \\n ) spread. to address the global problems caused by invasive species, several studies investigated steps\\n ii \\n and\\n iii \\n of this invasion process. however, only one previous study looked at step\\n i \\n and examined the proportion of species that have been introduced beyond their native range. we extend this research by investigating all three steps for all freshwater fish, mammals, and birds native to europe or north america. a higher proportion of european species entered north america than vice versa. however, the introduction rate from europe to north america peaked in the late 19th century, whereas it is still rising in the other direction. there is no clear difference in invasion success between the two directions, so neither the imperialism dogma (that eurasian species are exceptionally successful invaders) is supported, nor is the contradictory hypothesis that north america offers more biotic resistance to invaders than europe because of its less disturbed and richer biota. our results do not support the tens rule either: that \u224810% of all introduced species establish themselves and that \u224810% of established species spread. we find a success of \u224850% at each step. in comparison, only \u22485% of native vertebrates were introduced in either direction. these figures show that, once a vertebrate is introduced, it has a high potential to become invasive. thus, it is crucial to minimize the number of species introductions to effectively control invasive vertebrates.\\n",
            "contribution_ids": [
                "R56997",
                "R56998",
                "R57249"
            ]
        },
        {
            "instance_id": "R57501xR57315",
            "comparison_id": "R57501",
            "paper_id": "R57315",
            "text": "Effects of Native Herbs and Light on Garlic Mustard (Alliaria petiolata) Invasion \"abstract the degree to which invasive species drive or respond to environmental change has important implications for conservation and invasion management. often characterized as a driver of change in north american woodlands, the invasive herb garlic mustard may instead respond to declines in native plant cover and diversity. we tested effects of native herb cover, richness, and light availability on garlic mustard invasion in a minnesota oak woodland. we planted 50 garlic mustard seeds into plots previously planted with 0 to 10 native herb species. we measured garlic mustard seedling establishment, survival to rosette and adult stages, and average (per plant) and total (per plot) biomass and silique production. with the use of structural equation models, we analyzed direct, indirect, and net effects of native cover, richness, and light on successive garlic mustard life stages. native plant cover had a significant negative effect on all life stages. species richness had a significant positive effect on native cover, resulting in indirect negative effects on all garlic mustard stages, and net negative effects on adult numbers, total biomass, and silique production. light had a strong negative effect on garlic mustard seedling establishment and a positive effect on native herb cover, resulting in significant negative net effects on garlic mustard rosette and adult numbers. however, light's net effect on total garlic mustard biomass and silique production was positive; reproductive output was high even in low-light/high-cover conditions. combined effects of cover, richness, and light suggest that native herbs provide biotic resistance to invasion by responding to increased light availability and suppressing garlic mustard responses, although this resistance may be overwhelmed by high propagule pressure. garlic mustard invasion may occur, in part, in response to native plant decline. restoring native herbs and controlling garlic mustard seed production may effectively reduce garlic mustard spread and restore woodland diversity. nomenclature: garlic mustard [alliaria petiolata (m. bieb.) cavara & grande]. management implications: observations of native herb decline and garlic mustard spread are often presented as evidence of garlic mustard's impacts on woodland plant communities. alternative explanations include native plants affect garlic mustard invasion, both garlic mustard and native plants influence each other, or neither interact directly but are instead responding in opposite directions to other environmental pressures. understanding the relationship between garlic mustard and native plants can inform invasion control and woodland management. to test the hypothesis that garlic mustard invades in response to declining herb richness and cover, we planted garlic mustard seeds into experimental native herb communities across a range of light levels and analyzed garlic mustard seedling establishment, survival to rosette and adult stages, and biomass and seed capsule (silique) production. we found that native cover strongly suppressed garlic mustard at every life stage. higher herb species richness produced greater percent cover and thus contributed indirectly to invasion resistance. garlic mustard demonstrated a flexible response to light: fewer garlic mustard seedlings established in high light plots, but these individuals were highly productive in the second year, whereas in low-light plots, garlic mustard plants were more numerous but less productive. managing woodland light levels alone is therefore unlikely to prevent garlic mustard invasion. woodlands with high resource availability and minimal native herb cover may be most vulnerable to invasion. restoration of woodland herbaceous communities may play an important role in reducing invasibility, especially following management activities that reduce canopy cover and increase light availability at the forest floor. however, identifying and controlling drivers of native plant decline (e.g., white-tailed deer herbivory and earthworm invasion) may be necessary to restore native herb communities to densities sufficient to suppress garlic mustard. additionally, garlic mustard's substantial seed production, even in competitive conditions, suggests that propagule pressure may potentially overwhelm biotic resistance to invasion. a comprehensive management strategy that focuses on herb restoration, minimizing environmental stressors, and reducing propagule pressure via targeted control of second-year garlic mustard plants may be most effective at increasing woodland resistance to invasion.\"",
            "contribution_ids": [
                "R57316"
            ]
        },
        {
            "instance_id": "R57501xR57332",
            "comparison_id": "R57501",
            "paper_id": "R57332",
            "text": "Invasion by Heracleum mantegazzianum in different habitats in the Czech Republic . heracleum mantegazzianum, a tall forb from the western caucasus invaded several different habitats in the czech republic. the relation between invasion success and type of recipient habitat was studied in the slavkovsku les hilly ridge, czech republic. the vegetation of 14 habitat types occurring in an area of ca. 25 km2 was analysed using phytosociological releves, and the invasion success of heracleum (in terms of number of localities, area covered and proportion of available area occupied) was recorded separately in each of them. site conditions were expressed indirectly using ellenberg indicator values. the hypothesis tested was that heracleum spreads in the majority of vegetation types regardless of the properties of the recipient vegetation. \\n \\n \\n \\ncommunity invasibility appeared to be affected by site conditions and the composition of the recipient vegetation. the species is not found in acidic habitats. disturbed habitats with good possibilities of dispersal for heracleum seeds are more easily invaded. communities with a higher proportion of phanerophytes and of species with cs (competitive/stresstolerating) strategy were more resistant to invasion. the invasion success was bigger in sites with increased possibilities of spread for heracleum diaspores. communities invaded by heracleum had a lower species diversity and a higher indicator value for nitrogen than not-invaded stands. it appears that species contributing to community resistance against invasion of heracleum, or capable of persisting in heracleum-invaded stands, have similar ecological requirements but a different life strategy to the invader.",
            "contribution_ids": [
                "R57333"
            ]
        },
        {
            "instance_id": "R57501xR57139",
            "comparison_id": "R57501",
            "paper_id": "R57139",
            "text": "Landscape-scale patterns of biological invasions in shoreline plant communities little is known about the patterns and dynamics of exotic species invasions at landscape to regional spatial scales. we quantified the presence (identity, abundance, and richness) and characteristics of native and exotic species in estuarine strandline plant communities at 24 sites in narragansett bay, rhode island, usa. our results do not support several fundamental predictions of invasion biology. established exotics (79 of 147 recorded plant species) were nearly indistinguishable from the native plant species (i.e. in terms of growth form, taxonomic grouping, and patterns of spatial distribution and abundance) and essentially represent a random sub-set of the current regional species pool. the cover and richness of exotic species varied substantially among quadrats and sites but were not strongly related to any site-level physical characteristics thought to affect invasibility (i.e. the physical disturbance regime, legal status, neighboring habitat type, and substrate characteristics). native and exotic cover or richness were not negatively related within most sites. across sites, native and exotic richness were positively correlated and exotic cover was unrelated to native richness. the colonization and spread of exotics does not appear to have been substantially reduced at sites with high native diversity. furthermore, despite the fact that the rhode island strandline system is one of the most highly-invaded natural plant communities described to date, exotic species, both individually and as a group, currently appear to pose little threat to native plant diversity. our findings are concordant with most recent, large-scale investigations that do not support the theoretical foundation of invasion biology and generally contradict small-scale experimental work.",
            "contribution_ids": [
                "R57140"
            ]
        },
        {
            "instance_id": "R57501xR57373",
            "comparison_id": "R57501",
            "paper_id": "R57373",
            "text": "The rich get richer: patterns of plant invasions in the United States observations from islands, small-scale experiments, and mathematical models have generally supported the paradigm that habitats of low plant diversity are more vulnerable to plant invasions than areas of high plant diversity. we summarize two independent data sets to show exactly the opposite pattern at multiple spatial scales. more significant, and alarming, is that hotspots of native plant diversity have been far more heavily invaded than areas of low plant diversity in most parts of the united states when considered at larger spatial scales. our findings suggest that we cannot expect such hotspots to repel invasions, and that the threat of invasion is significant and predictably greatest in these areas.",
            "contribution_ids": [
                "R57374"
            ]
        },
        {
            "instance_id": "R57501xR57263",
            "comparison_id": "R57501",
            "paper_id": "R57263",
            "text": "Fish invasions in the world's river systems: When natural processes are blurred by human activities \"because species invasions are a principal driver of the human-induced biodiversity crisis, the identification of the major determinants of global invasions is a prerequisite for adopting sound conservation policies. three major hypotheses, which are not necessarily mutually exclusive, have been proposed to explain the establishment of non-native species: the \u201chuman activity\u201d hypothesis, which argues that human activities facilitate the establishment of non-native species by disturbing natural landscapes and by increasing propagule pressure; the \u201cbiotic resistance\u201d hypothesis, predicting that species-rich communities will readily impede the establishment of non-native species; and the \u201cbiotic acceptance\u201d hypothesis, predicting that environmentally suitable habitats for native species are also suitable for non-native species. we tested these hypotheses and report here a global map of fish invasions (i.e., the number of non-native fish species established per river basin) using an original worldwide dataset of freshwater fish occurrences, environmental variables, and human activity indicators for 1,055 river basins covering more than 80% of earth's surface. first, we identified six major invasion hotspots where non-native species represent more than a quarter of the total number of species. according to the world conservation union, these areas are also characterised by the highest proportion of threatened fish species. second, we show that the human activity indicators account for most of the global variation in non-native species richness, which is highly consistent with the \u201chuman activity\u201d hypothesis. in contrast, our results do not provide support for either the \u201cbiotic acceptance\u201d or the \u201cbiotic resistance\u201d hypothesis. we show that the biogeography of fish invasions matches the geography of human impact at the global scale, which means that natural processes are blurred by human activities in driving fish invasions in the world's river systems. in view of our findings, we fear massive invasions in developing countries with a growing economy as already experienced in developed countries. anticipating such potential biodiversity threats should therefore be a priority.\"",
            "contribution_ids": [
                "R57264"
            ]
        },
        {
            "instance_id": "R57501xR57205",
            "comparison_id": "R57501",
            "paper_id": "R57205",
            "text": "The rich generally get richer, but there are exceptions: Correlations between species richness of native plant species and alien weeds in Mexico \"studies on the resistance of communities to plant invasions at different spatial scales have yielded contradictory results that have been attributed to scale\u2010dependent factors. some of these studies argue either for or against elton's notion of biotic resistance against invasions through diversity. we studied the correlation between alien weeds and native species, dividing the latter group into weedy and non\u2010weedy species, integrating various factors that influence diversity into an analysis on the scale of the federal states of mexico. the resulting multiple\u2010regression models for native and alien weed species are robust (adjusted r2 = 0.87 and r2 = 0.69, respectively) and show a strong partial correlation of the number of weed species (native and alien) with the number of non\u2010weed native species. these results agree with studies showing a positive correlation between the number of native and alien species on larger scales. both models also include human population density as an important predictor variable, but this is more important for alien weeds (\u03b2 = 0.62) than for native weeds (\u03b2 = 0.32). in the regression model for native weed species richness, the non\u2010cultivated (fallow) area (\u03b2 = 0.24) correlated positively with native weed richness. in the model for alien weed species richness, the native weed species richness was an important variable (\u03b2 = \u22120.51), showing a negative partial correlation (rpart = \u22120.4). this result is consistent with elton's biotic resistance hypothesis, suggesting that biotic resistance is scale independent but that this may be masked by other factors that influence the diversity of both weeds and non\u2010weeds.\"",
            "contribution_ids": [
                "R57206"
            ]
        },
        {
            "instance_id": "R58002xR57717",
            "comparison_id": "R58002",
            "paper_id": "R57717",
            "text": "Use of the introduced bivalve, Musculista senhousia, by generalist parasites of native New Zealand bivalves abstract introduced species are often thought to do well because of an escape from natural enemies. however, once established, they can acquire a modest assemblage of enemies, including parasites, in their new range. here we quantified prevalence and effects of infection with copepods (family myicolidae) and pea crabs (pinnotheres novaezelandiae), in three mussel species, the non\u2010native musculista senhousia, and two native mussels, perna canaliculus and xenostrobus pulex, at bucklands beach, auckland, new zealand. copepod prevalence was highest in x. pulex (17.9%), whereas pea crab prevalence was highest in p. canaliculus (33.6%). both parasites infected m. senhousia, but at a much lower prevalence. dry tissue weight was significantly lower in p. canaliculus infected with pea crabs. in addition, we experimentally investigated host species selection by pea crabs. in an experimental apparatus, pea crabs showed a significant attraction to p. canaliculus, but not so for x. pulex or m. senhousia. when the mussels were presented in combination, pea crabs showed a weak attraction for x. pulex. pea crab attraction to m. senhousia was not significant. it appears that the introduced m. senhousia largely escapes the detrimental effects of infection with either parasite species compared with native mussels occurring in sympatry.",
            "contribution_ids": [
                "R57718",
                "R57719"
            ]
        },
        {
            "instance_id": "R58002xR57652",
            "comparison_id": "R58002",
            "paper_id": "R57652",
            "text": "Limited grazing pressure by native herbivores on the invasive seaweed Caulerpa taxifolia in a temperate Australian estuary \\n\\ncaulerpa taxifolia is an invasive alga threatening biodiversity in invaded regions. its proliferation in recipient communities will be due to several factors including limited grazing effects by native herbivores. however, little is known about grazing pressure exerted by native herbivores on c. taxifolia relative to native macrophytes or its attractiveness to them as habitat. the present study determined which herbivores co-occurred with invasive c. taxifolia in a temperate australian estuary and documented their abundance, relative grazing effects, habitat preference and survivorship on c. taxifolia compared with native macrophytes. four herbivores co-occurred with c. taxifolia and their densities were often low or zero at the sites studied. feeding experiments showed that compared with c. taxifolia: the fish, girella tricuspidata, preferred ulva sp.; the sea-hare, aplysia dactylomela, preferred laurencia sp.; whereas the mesograzers, cymadusa setosa and platynereis dumerilii antipoda, both consumed cystoseira trinodus and sargassum sp. at higher rates. the two mesograzers also showed strong habitat preference for c. trinodus and sargassum sp. cymadusa setosa had poor survivorship on caulerpa taxifolia whereas p. dumerilii antipoda had 100% survivorship on c. taxifolia after 41 days. we consider that the low diversity and abundance of native herbivores, their weak grazing pressure on c. taxifolia and its low attractiveness as habitat may facilitate further local spread in this estuary, and potentially in other invaded locations.\\n",
            "contribution_ids": [
                "R57653"
            ]
        },
        {
            "instance_id": "R58002xR57607",
            "comparison_id": "R58002",
            "paper_id": "R57607",
            "text": "Herbivores and the success of exotic plants: a phylogenetically controlled experiment in a field experiment with 30 locally occurring old-field plant species grown in a common garden, we found that non-native plants suffer levels of attack (leaf herbivory) equal to or greater than levels suffered by congeneric native plants. this phylogenetically controlled analysis is in striking contrast to the recent findings from surveys of exotic organisms, and suggests that even if enemy release does accompany the invasion process, this may not be an important mechanism of invasion, particularly for plants with close relatives in the recipient flora.",
            "contribution_ids": [
                "R57608"
            ]
        },
        {
            "instance_id": "R58002xR57787",
            "comparison_id": "R58002",
            "paper_id": "R57787",
            "text": "Low prevalence of haemosporidian parasites in the introduced house sparrow (Passer domesticus) in Brazil abstract species that are introduced to novel environments can lose their native pathogens and parasites during the process of introduction. the escape from the negative effects associated with these natural enemies is commonly employed as an explanation for the success and expansion of invasive species, which is termed the enemy release hypothesis (erh). in this study, nested pcr techniques and microscopy were used to determine the prevalence and intensity (respectively) of plasmodium spp. and haemoproteus spp. in introduced house sparrows and native urban birds of central brazil. generalized linear mixed models were fitted by laplace approximation considering a binomial error distribution and logit link function. location and species were considered as random effects and species categorization (native or non-indigenous) as fixed effects. we found that native birds from brazil presented significantly higher parasite prevalence in accordance with the erh. we also compared our data with the literature, and found that house sparrows native to europe exhibited significantly higher parasite prevalence than introduced house sparrows from brazil, which also supports the erh. therefore, it is possible that house sparrows from brazil might have experienced a parasitic release during the process of introduction, which might also be related to a demographic release (e.g. release from the negative effects of parasites on host population dynamics).",
            "contribution_ids": [
                "R57788"
            ]
        },
        {
            "instance_id": "R58002xR57656",
            "comparison_id": "R58002",
            "paper_id": "R57656",
            "text": "Prevalence and evolutionary relationships of haematozoan parasites in native versus introduced populations of common myna Acridotheres tristis the success of introduced species is frequently explained by their escape from natural enemies in the introduced region. we tested the enemy release hypothesis with respect to two well studied blood parasite genera (plasmodium and haemoproteus) in native and six introduced populations of the common myna acridotheres tristis. not all comparisons of introduced populations to the native population were consistent with expectations of the enemy release hypothesis. native populations show greater overall parasite prevalence than introduced populations, but the lower prevalence in introduced populations is driven by low prevalence in two populations on oceanic islands (fiji and hawaii). when these are excluded, prevalence does not differ significantly. we found a similar number of parasite lineages in native populations compared to all introduced populations. although there is some evidence that common mynas may have carried parasite lineages from native to introduced locations, and also that introduced populations may have become infected with novel parasite lineages, it may be difficult to differentiate between parasites that are native and introduced, because malarial parasite lineages often do not show regional or host specificity.",
            "contribution_ids": [
                "R57657"
            ]
        },
        {
            "instance_id": "R58002xR57889",
            "comparison_id": "R58002",
            "paper_id": "R57889",
            "text": "Biogeographic comparisons of herbivore attack, growth and impact of Japanese knotweed between Japan and France to shed light on the process of how exotic species become invasive, it is necessary to study them both in their native and non\u2010native ranges. our intent was to measure differences in herbivory, plant growth and the impact on other species in fallopia japonica in its native and non\u2010native ranges. we performed a cross\u2010range full descriptive, field study in japan (native range) and france (non\u2010native range). we assessed dna ploidy levels, the presence of phytophagous enemies, the amount of leaf damage, several growth parameters and the co\u2010occurrence of fallopia japonica with other plant species of herbaceous communities. invasive fallopia japonica plants were all octoploid, a ploidy level we did not encounter in the native range, where plants were all tetraploid. octoploids in france harboured far less phytophagous enemies, suffered much lower levels of herbivory, grew larger and had a much stronger impact on plant communities than tetraploid conspecifics in the native range in japan. our data confirm that fallopia japonica performs better \u2013 plant vigour and dominance in the herbaceous community \u2013 in its non\u2010native than its native range. because we could not find octoploids in the native range, we cannot separate the effects of differences in ploidy from other biogeographic factors. to go further, common garden experiments would now be needed to disentangle the proper role of each factor, taking into account the ploidy levels of plants in their native and non\u2010native ranges. synthesis. as the process by which invasive plants successfully invade ecosystems in their non\u2010native range is probably multifactorial in most cases, examining several components \u2013 plant growth, herbivory load, impact on recipient systems \u2013 of plant invasions through biogeographic comparisons is important. our study contributes towards filling this gap in the research, and it is hoped that this method will spread in invasion ecology, making such an approach more common.",
            "contribution_ids": [
                "R57890",
                "R57891"
            ]
        },
        {
            "instance_id": "R58002xR53282",
            "comparison_id": "R58002",
            "paper_id": "R53282",
            "text": "Enemy damage of exotic plant species is similar to that of natives and increases with productivity in their colonized ranges, exotic plants may be released from some of the herbivores or pathogens of their home ranges but these can be replaced by novel enemies. it is of basic and practical interest to understand which characteristics of invaded communities control accumulation of the new pests. key questions are whether enemy load on exotic species is smaller than on native competitors as suggested by the enemy release hypothesis (erh) and whether this difference is most pronounced in resource\u2010rich habitats as predicted by the resource\u2013enemy release hypothesis (r\u2010erh). in 72 populations of 12 exotic invasive species, we scored all visible above\u2010ground damage morphotypes caused by herbivores and fungal pathogens. in addition, we quantified levels of leaf herbivory and fruit damage. we then assessed whether variation in damage diversity and levels was explained by habitat fertility, by relatedness between exotic species and the native community or rather by native species diversity. in a second part of the study, we also tested the erh and the r\u2010erh by comparing damage of plants in 28 pairs of co\u2010occurring native and exotic populations, representing nine congeneric pairs of native and exotic species. in the first part of the study, diversity of damage morphotypes and damage levels of exotic populations were greater in resource\u2010rich habitats. co\u2010occurrence of closely related, native species in the community significantly increased the probability of fruit damage. herbivory on exotics was less likely in communities with high phylogenetic diversity. in the second part of the study, exotic and native congeneric populations incurred similar damage diversity and levels, irrespective of whether they co\u2010occurred in nutrient\u2010poor or nutrient\u2010rich habitats. synthesis. we identified habitat productivity as a major community factor affecting accumulation of enemy damage by exotic populations. similar damage levels in exotic and native congeneric populations, even in species pairs from fertile habitats, suggest that the enemy release hypothesis or the r\u2010erh cannot always explain the invasiveness of introduced species.",
            "contribution_ids": [
                "R53283",
                "R53285",
                "R57876"
            ]
        },
        {
            "instance_id": "R58002xR57994",
            "comparison_id": "R58002",
            "paper_id": "R57994",
            "text": "Can enemy release explain the invasion success of the diploid Leucanthemum vulgare in North America? abstract enemy release is a commonly accepted mechanism to explain plant invasions. both the diploid leucanthemum vulgare and the morphologically very similar tetraploid leucanthemum ircutianum have been introduced into north america. to verify which species is more prevalent in north america we sampled 98 leucanthemum populations and determined their ploidy level. although polyploidy has repeatedly been proposed to be associated with increased invasiveness in plants, only two of the populations surveyed in north america were the tetraploid l. ircutianum . we tested the enemy release hypothesis by first comparing 20 populations of l. vulgare and 27 populations of l. ircutianum in their native range in europe, and then comparing the european l. vulgare populations with 31 l. vulgare populations sampled in north america. characteristics of the site and associated vegetation, plant performance and invertebrate herbivory were recorded. in europe, plant height and density of the two species were similar but l. vulgare produced more flower heads than l. ircutianum . leucanthemum vulgare in north america was 17\\xa0% taller, produced twice as many flower heads and grew much denser compared to l. vulgare in europe. attack rates by root- and leaf-feeding herbivores on l. vulgare in europe (34 and 75\\xa0%) was comparable to that on l. ircutianum (26 and 71\\xa0%) but higher than that on l. vulgare in north america (10 and 3\\xa0%). however, herbivore load and leaf damage were low in europe. cover and height of the co-occurring vegetation was higher in l. vulgare populations in the native than in the introduced range, suggesting that a shift in plant competition may more easily explain the invasion success of l. vulgare than escape from herbivory.",
            "contribution_ids": [
                "R57995"
            ]
        },
        {
            "instance_id": "R58002xR57820",
            "comparison_id": "R58002",
            "paper_id": "R57820",
            "text": "Island invasion by a threatened tree species: evidence for natural enemy release of mahogany (Swietenia macrophylla) on Dominica, Lesser Antilles despite its appeal to explain plant invasions, the enemy release hypothesis (erh) remains largely unexplored for tropical forest trees. even scarcer are erh studies conducted on the same host species at both the community and biogeographical scale, irrespective of the system or plant life form. in cabrits national park, dominica, we observed patterns consistent with enemy release of two introduced, congeneric mahogany species, swietenia macrophylla and s. mahagoni, planted almost 50 years ago. swietenia populations at cabrits have reproduced, with s. macrophylla juveniles established in and out of plantation areas at densities much higher than observed in its native range. swietenia macrophylla juveniles also experienced significantly lower leaf-level herbivory (\u223c3.0%) than nine co-occurring species native to dominica (8.4\u201321.8%), and far lower than conspecific herbivory observed in its native range (11%\u201343%, on average). these complimentary findings at multiple scales support erh, and confirm that swietenia has naturalized at cabrits. however, swietenia abundance was positively correlated with native plant diversity at the seedling stage, and only marginally negatively correlated with native plant abundance for stems \u22651-cm dbh. taken together, these descriptive patterns point to relaxed enemy pressure from specialized enemies, specifically the defoliator steniscadia poliophaea and the shoot-borer hypsipyla grandella, as a leading explanation for the enhanced recruitment of swietenia trees documented at cabrits.",
            "contribution_ids": [
                "R57821",
                "R57822"
            ]
        },
        {
            "instance_id": "R58002xR57912",
            "comparison_id": "R58002",
            "paper_id": "R57912",
            "text": "Parasites and genetic diversity in an invasive bumblebee biological invasions are facilitated by the global transportation of species and climate change. given that invasions may cause ecological and economic damage and pose a major threat to biodiversity, understanding the mechanisms behind invasion success is essential. both the release of non-native populations from natural enemies, such as parasites, and the genetic diversity of these populations may play key roles in their invasion success. we investigated the roles of parasite communities, through enemy release and parasite acquisition, and genetic diversity in the invasion success of the non-native bumblebee, bombus hypnorum, in the united kingdom. the invasive b. hypnorum had higher parasite prevalence than most, or all native congeners for two high-impact parasites, probably due to higher susceptibility and parasite acquisition. consequently parasites had a higher impact on b. hypnorum queens\u2019 survival and colony-founding success than on native species. bombus hypnorum also had lower functional genetic diversity at the sex-determining locus than native species. higher parasite prevalence and lower genetic diversity have not prevented the rapid invasion of the united kingdom by b. hypnorum. these data may inform our understanding of similar invasions by commercial bumblebees around the world. this study suggests that concerns about parasite impacts on the small founding populations common to re-introduction and translocation programs may be less important than currently believed.",
            "contribution_ids": [
                "R57913"
            ]
        },
        {
            "instance_id": "R58002xR57950",
            "comparison_id": "R58002",
            "paper_id": "R57950",
            "text": "Phytophagous Insects on Native and Non-Native Host Plants: Combining the Community Approach and the Biogeographical Approach during the past centuries, humans have introduced many plant species in areas where they do not naturally occur. some of these species establish populations and in some cases become invasive, causing economic and ecological damage. which factors determine the success of non-native plants is still incompletely understood, but the absence of natural enemies in the invaded area (enemy release hypothesis; erh) is one of the most popular explanations. one of the predictions of the erh, a reduced herbivore load on non-native plants compared with native ones, has been repeatedly tested. however, many studies have either used a community approach (sampling from native and non-native species in the same community) or a biogeographical approach (sampling from the same plant species in areas where it is native and where it is non-native). either method can sometimes lead to inconclusive results. to resolve this, we here add to the small number of studies that combine both approaches. we do so in a single study of insect herbivory on 47 woody plant species (trees, shrubs, and vines) in the netherlands and japan. we find higher herbivore diversity, higher herbivore load and more herbivory on native plants than on non-native plants, generating support for the enemy release hypothesis.",
            "contribution_ids": [
                "R57951",
                "R57952",
                "R57953",
                "R57954"
            ]
        },
        {
            "instance_id": "R58002xR57720",
            "comparison_id": "R58002",
            "paper_id": "R57720",
            "text": "Herbivores, but not other insects, are scarce on alien plants \"abstract\\xa0 understanding how the landscape-scale replacement of indigenous plants with alien plants influences ecosystem structure and functioning is critical in a world characterized by increasing biotic homogenization. an important step in this process is to assess the impact on invertebrate communities. here we analyse insect species richness and abundance in sweep collections from indigenous and alien (australasian) woody plant species in south africa's western cape. we use phylogenetically relevant comparisons and compare one indigenous with three australasian alien trees within each of fabaceae: mimosoideae, myrtaceae, and proteaceae: grevilleoideae. although some of the alien species analysed had remarkably high abundances of herbivores, even when intentionally introduced biological control agents are discounted, overall, herbivorous insect assemblages from alien plants were slightly less abundant and less diverse compared with those from indigenous plants \u2013 in accordance with predictions from the enemy release hypothesis. however, there were no clear differences in other insect feeding guilds. we conclude that insect assemblages from alien plants are generally quite diverse, and significant differences between these and assemblages from indigenous plants are only evident for herbivorous insects.\"",
            "contribution_ids": [
                "R57721"
            ]
        },
        {
            "instance_id": "R58002xR57982",
            "comparison_id": "R58002",
            "paper_id": "R57982",
            "text": "Comparison of parasite diversity in native panopeid mud crabs and the invasive Asian shore crab in estuaries of northeast North America numerous non-indigenous species (nis) have successfully established in new locales, where they can have large impacts on community and ecosystem structure. a loss of natural enemies, such as parasites, is one mechanism proposed to contribute to that success. while several studies have shown nis are initially less parasitized than native conspecifics, fewer studies have investigated whether parasite richness changes over time. moreover, evaluating the role that parasites have in invaded communities requires not only an understanding of the parasite diversity of nis but also the species with which they interact; yet parasite diversity in native species may be inadequately quantified. in our study, we examined parasite taxonomic richness, infection prevalence, and infection intensity in the invasive asian shore crab hemigrapsus sanguineus de haan, 1835 and two native mud crabs (panopeus herbstii milne-edwards, 1834 and eurypanopeus depressus smith, 1869) in estuarine and coastal communities along the east coast of the usa. we also examined reproductive tissue allocation (i.e., the proportion of gonad weight to total body weight) in all three crabs to explore possible differences in infected versus uninfected crabs. we found three parasite taxa infecting h. sanguineus and four taxa infecting mud crabs, including a rhizocephalan castrator (loxothylacus panopaei) parasitizing e. depressus. moreover, we documented a significant negative relationship between parasite escape and time for h. sanguineus, including a new 2015 record of a native microphallid trematode. altogether, there was no significant difference in taxonomic richness among the crab species. across parasite taxa, h. sanguineus demonstrated significantly lower infection prevalence compared to p. herbstii; yet a multivariate analysis of taxa-specific prevalence demonstrated no significant differences among crabs. finally, infected p. herbstii had the highest proportion of gonad weight to total body weight. our study finds some evidence for lower infection prevalence in the non-native versus the native hosts. however, we also demonstrate that parasite escape can lessen with time. our work has implications for the understanding of the potential influence parasites may have on the future success of nis in introduced regions.",
            "contribution_ids": [
                "R57983"
            ]
        },
        {
            "instance_id": "R58002xR57992",
            "comparison_id": "R58002",
            "paper_id": "R57992",
            "text": "Incorporation of an invasive plant into a native insect herbivore food web the integration of invasive species into native food webs represent multifarious dynamics of ecological and evolutionary processes. we document incorporation of prunus serotina (black cherry) into native insect food webs. we find that p. serotina harbours a herbivore community less dense but more diverse than its native relative, p. padus (bird cherry), with similar proportions of specialists and generalists. while herbivory on p. padus remained stable over the past century, that on p. serotina gradually doubled. we show that p. serotina may have evolved changes in investment in cyanogenic glycosides compared with its native range. in the leaf beetle gonioctena quinquepunctata , recently shifted from native sorbus aucuparia to p. serotina , we find divergent host preferences on sorbus - versus prunus -derived populations, and weak host-specific differentiation among 380 individuals genotyped for 119 snp loci. we conclude that evolutionary processes may generate a specialized herbivore community on an invasive plant, allowing prognoses of reduced invasiveness over time. on the basis of the results presented here, we would like to caution that manual control might have the adverse effect of a slowing down of processes of adaptation, and a delay in the decline of the invasive character of p. serotina .",
            "contribution_ids": [
                "R57993"
            ]
        },
        {
            "instance_id": "R58002xR57920",
            "comparison_id": "R58002",
            "paper_id": "R57920",
            "text": "Invasive plants escape from suppressive soil biota at regional scales a prominent hypothesis for plant invasions is escape from the inhibitory effects of soil biota. although the strength of these inhibitory effects, measured as soil feedbacks, has been assessed between natives and exotics in non\u2010native ranges, few studies have compared the strength of plant\u2013soil feedbacks for exotic species in soils from non\u2010native versus native ranges. we examined whether 6 perennial european forb species that are widespread invaders in north american grasslands (centaurea stoebe, euphorbia esula, hypericum perforatum, linaria vulgaris, potentilla recta and leucanthemum vulgare) experienced different suppressive effects of soil biota collected from 21 sites across both ranges. four of the six species tested exhibited substantially reduced shoot biomass in \u2018live\u2019 versus sterile soil from europe. in contrast, north american soils produced no significant feedbacks on any of the invasive species tested indicating a broad scale escape from the inhibitory effects of soil biota. negative feedbacks generated by european soil varied idiosyncratically among sites and species. since this variation did not correspond with the presence of the target species at field sites, it suggests that negative feedbacks can be generated from soil biota that are widely distributed in native ranges in the absence of density\u2010dependent effects. synthesis. our results show that for some invasives, native soils have strong suppressive potential, whereas this is not the case in soils from across the introduced range. differences in regional\u2010scale evolutionary history among plants and soil biota could ultimately help explain why some exotics are able to occur at higher abundance in the introduced versus native range.",
            "contribution_ids": [
                "R57921"
            ]
        },
        {
            "instance_id": "R58002xR57872",
            "comparison_id": "R58002",
            "paper_id": "R57872",
            "text": "Arthropod Communities on Native and Nonnative Early Successional Plants abstract \\n early successional ruderal plants in north america include numerous native and nonnative species, and both are abundant in disturbed areas. the increasing presence of nonnative plants may negatively impact a critical component of food web function if these species support fewer or a less diverse arthropod fauna than the native plant species that they displace. we compared arthropod communities on six species of common early successional native plants and six species of nonnative plants, planted in replicated native and nonnative plots in a farm field. samples were taken twice each year for 2 yr. in most arthropod samples, total biomass and abundance were substantially higher on the native plants than on the nonnative plants. native plants produced as much as five times more total arthropod biomass and up to seven times more species per 100 g of dry leaf biomass than nonnative plants. both herbivores and natural enemies (predators and parasitoids) predominated on native plants when analyzed separately. in addition, species richness was about three times greater on native than on nonnative plants, with 83 species of insects collected exclusively from native plants, and only eight species present only on nonnatives. these results support a growing body of evidence suggesting that nonnative plants support fewer arthropods than native plants, and therefore contribute to reduced food resources for higher trophic levels.",
            "contribution_ids": [
                "R57873"
            ]
        },
        {
            "instance_id": "R58002xR57755",
            "comparison_id": "R58002",
            "paper_id": "R57755",
            "text": "Release from foliar and floral fungal pathogen species does not explain the geographic spread of naturalized North American plants in Europe 1 during the last centuries many alien species have established and spread in new regions, where some of them cause large ecological and economic problems. as one of the main explanations of the spread of alien species, the enemy\u2010release hypothesis is widely accepted and frequently serves as justification for biological control. 2 we used a global fungus\u2013plant host distribution data set for 140 north american plant species naturalized in europe to test whether alien plants are generally released from foliar and floral pathogens, whether they are mainly released from pathogens that are rare in the native range, and whether geographic spread of the north american plant species in europe is associated with release from fungal pathogens. 3 we show that the 140 north american plant species naturalized in europe were released from 58% of their foliar and floral fungal pathogen species. however, when we also consider fungal pathogens of the native north american host range that in europe so far have only been reported on other plant species, the estimated release is reduced to 10.3%. moreover, in europe north american plants have mainly escaped their rare, pathogens, of which the impact is restricted to few populations. most importantly and directly opposing the enemy\u2010release hypothesis, geographic spread of the alien plants in europe was negatively associated with their release from fungal pathogens. 4 synthesis. north american plants may have escaped particular fungal species that control them in their native range, but based on total loads of fungal species, release from foliar and floral fungal pathogens does not explain the geographic spread of north american plant species in europe. to test whether enemy release is the major driver of plant invasiveness, we urgently require more studies comparing release of invasive and non\u2010invasive alien species from enemies of different guilds, and studies that assess the actual impact of the enemies.",
            "contribution_ids": [
                "R57756"
            ]
        },
        {
            "instance_id": "R58002xR57654",
            "comparison_id": "R58002",
            "paper_id": "R57654",
            "text": "Phytophagous insects of giant hogweed Heracleum mantegazzianum (Apiaceae) in invaded areas of Europe and in its native area of the Caucasus giant hogweed, heracleum mantegazzianum (apiaceae), was introduced from the caucasus into western europe more than 150 years ago and later became an invasive weed which created major problems for european authorities. phytophagous insects were collected in the native range of the giant hogweed (caucasus) and were compared to those found on plants in the invaded parts of europe. the list of herbivores was compiled from surveys of 27 localities in nine countries during two seasons. in addition, litera- ture records for herbivores were analysed for a total of 16 heracleum species. we recorded a total of 265 herbivorous insects on heracleum species and we analysed them to describe the herbivore assemblages, locate vacant niches, and identify the most host- specific herbivores on h. mantegazzianum. when combining our investigations with similar studies of herbivores on other invasive weeds, all studies show a higher proportion of specialist herbivores in the native habitats compared to the invaded areas, supporting the \"enemy release hypothesis\" (erh). when analysing the relative size of the niches (measured as plant organ biomass), we found less herbivore species per biomass on the stem and roots, and more on the leaves (fig. 5). most herbivores were polyphagous gener- alists, some were found to be oligophagous (feeding within the same family of host plants) and a few had only heracleum species as host plants (monophagous). none were known to feed exclusively on h. mantegazzianum. the oligophagous herbivores were restricted to a few taxonomic groups, especially within the hemiptera, and were particularly abundant on this weed.",
            "contribution_ids": [
                "R57655"
            ]
        },
        {
            "instance_id": "R58002xR57918",
            "comparison_id": "R58002",
            "paper_id": "R57918",
            "text": "Determining the origin of invasions and demonstrating a lack of enemy release from microsporidian pathogens in common wasps (Vespula vulgaris) \"understanding the role of enemy release in biological invasions requires an assessment of the invader's home range, the number of invasion events and enemy prevalence. the common wasp (vespula vulgaris) is a widespread invader. we sought to determine the eurasian origin of this wasp and examined world\u2010wide populations for microsporidian pathogen infections to investigate enemy release.\"",
            "contribution_ids": [
                "R57919"
            ]
        },
        {
            "instance_id": "R58002xR57722",
            "comparison_id": "R58002",
            "paper_id": "R57722",
            "text": "Novel host associations and habitats for Senecio-specialist herbivorous insects in Auckland we studied the genusand species-specialist monophagous herbivorous insects of senecio (asteraceae) in auckland, new zealand. with the exception of the widespread s. hispidulus, the eight native senecio species in mainland auckland (two endemic) are typically uncommon and restricted to less modified conservation land. however, 11 naturalised senecio have established and are often widespread in urban and rural habitats. three endemic senecio-specialist herbivores \u2013 nyctemera annulata, patagoniodes farnaria, and tephritis fascigera \u2013 formed novel host associations with naturalised senecio species and spread into modified landscapes. host associations for these species were not related to whether senecio species are naturalised or native. however, the abundances of patagonoides farnaria and tephritis fascigera were significantly higher in wildland habitats than rural or urban habitats, and wildland senecio were on average 1.4 times more likely to experience >5% folivory than urban conspecifics. ___________________________________________________________________________________________________________________________________",
            "contribution_ids": [
                "R57723",
                "R57724"
            ]
        },
        {
            "instance_id": "R58002xR57973",
            "comparison_id": "R58002",
            "paper_id": "R57973",
            "text": "Evidence for enemy release and increased seed production and size for two invasive Australian acacias invasive plants are hypothesized to have higher fitness in introduced areas due to their release from pathogens and herbivores and the relocation of resources to reproduction. however, few studies have tested this hypothesis in native and introduced regions. a biogeographical approach is fundamental to understanding the mechanisms involved in plant invasions and to detect rapid evolutionary changes in the introduced area. reproduction was assessed in native and introduced ranges of two invasive australian woody legumes, acacia dealbata and a. longifolia. seed production, pre\u2010dispersal seed predation, seed and elaiosome size and seedling size were assessed in 7\u201310 populations from both ranges, taking into account the effect of differences in climate. there was a significantly higher percentage of fully developed seeds per pod, a lower proportion of aborted seeds and the absence of pre\u2010dispersal predation in the introduced range for both acacia species. acacia longifolia produced more seeds per pod in the invaded range, whereas a. dealbata produced more seeds per tree in the invaded range. seeds were bigger in the invaded range for both species, and elaiosome: seed ratio was smaller for a. longifolia in the invaded range. seedlings were also larger in the invaded range, suggesting that the increase in seed size results into greater offspring growth. there were no differences in the climatic conditions of sites occupied by a. longifolia in both regions. minimum temperature was higher in portuguese a. dealbata populations, but this difference did not explain the increase in seed production and seed size in the introduced range. it did have, however, a positive effect on the number of pods per tree. synthesis. acacia dealbata and a. longifolia escape pre\u2010dispersal predation in the introduced range and display a higher production of fully developed seeds per fruit and bigger seeds. these differences may explain the invasion of both species because they result in an increased seedling growth and the production of abundant soil seedbanks in the introduced area.",
            "contribution_ids": [
                "R57974"
            ]
        },
        {
            "instance_id": "R58002xR57648",
            "comparison_id": "R58002",
            "paper_id": "R57648",
            "text": "Biogeographical comparison of the arthropod herbivore communities associated with Lepidium draba in its native, expanded and introduced ranges aim\\u2002 to examine the composition and structure of the arthropod community on the invasive weed lepidium draba in its native, expanded and introduced ranges, in order to elucidate the lack of a biotic constraint that may facilitate invasion.",
            "contribution_ids": [
                "R57649",
                "R57650",
                "R57651"
            ]
        },
        {
            "instance_id": "R58002xR57620",
            "comparison_id": "R58002",
            "paper_id": "R57620",
            "text": "Herbivory, disease, recruitment limitation, and success of alien and native tree species the enemies hypothesis predicts that alien plants have a competitive ad- vantage over native plants because they are often introduced with few herbivores or diseases. to investigate this hypothesis, we transplanted seedlings of the invasive alien tree, sapium sebiferum (chinese tallow tree) and an ecologically similar native tree, celtis laevigata (hackberry), into mesic forest, floodplain forest, and coastal prairie sites in east texas and manipulated foliar fungal diseases and insect herbivores with fungicidal and insecticidal sprays. as predicted by the enemies hypothesis, insect herbivores caused significantly greater damage to untreated celtis seedlings than to untreated sapium seedlings. however, contrary to predictions, suppression of insect herbivores caused significantly greater in- creases in survivorship and growth of sapium seedlings compared to celtis seedlings. regressions suggested that sapium seedlings compensate for damage in the first year but that this greatly increases the risk of mortality in subsequent years. fungal diseases had no effects on seedling survival or growth. the recruitment limitation hypothesis predicts that the local abundance of a species will depend more on local seed input than on com- petitive ability at that location. to investigate this hypothesis, we added seeds of celtis and sapium on and off of artificial soil disturbances at all three sites. adding seeds increased the density of celtis seedlings and sometimes sapium seedlings, with soil disturbance only affecting density of celtis. together the results of these experiments suggest that the success of sapium may depend on high rates of seed input into these ecosystems and high growth potential, as well as performance advantages of seedlings caused by low rates of herbivory.",
            "contribution_ids": [
                "R57621",
                "R57622"
            ]
        },
        {
            "instance_id": "R58002xR57632",
            "comparison_id": "R58002",
            "paper_id": "R57632",
            "text": "Enemy release? An experiment with congeneric plant pairs and diverse above- and belowground enemies \"several hypotheses proposed to explain the success of introduced species focus on altered interspecific interactions. one of the most prominent, the enemy release hypothesis, posits that invading species benefit compared to their native counterparts if they lose their herbivores and pathogens during the invasion process. we previously reported on a common garden experiment (from 2002) in which we compared levels of herbivory between 30 taxonomically paired native and introduced old-field plants. in this phyloge- netically controlled comparison, herbivore damage tended to be higher on introduced than on native plants. this striking pattern, the opposite of current theory, prompted us to further investigate herbivory and several other interspecific interactions in a series of linked ex- periments with the same set of species. here we show that, in these new experiments, introduced plants, on average, received less insect herbivory and were subject to half the negative soil microbial feedback compared to natives; attack by fungal and viral pathogens also tended to be reduced on introduced plants compared to natives. although plant traits (foliar c:n, toughness, and water content) suggested that introduced species should be less resistant to generalist consumers, they were not consistently more heavily attacked. finally, we used meta-analysis to combine data from this study with results from our previous work to show that escape generally was inconsistent among guilds of enemies: there were few instances in which escape from multiple guilds occurred for a taxonomic pair, and more cases in which the patterns of escape from different enemies canceled out. our examination of multiple interspecific interactions demonstrates that escape from one guild of enemies does not necessarily imply escape from other guilds. because the effects of each guild are likely to vary through space and time, the net effect of all enemies is also likely to be variable. the net effect of these interactions may create ''invasion opportunity windows'': times when introduced species make advances in native communities.\"",
            "contribution_ids": [
                "R57633",
                "R57634"
            ]
        },
        {
            "instance_id": "R58002xR57700",
            "comparison_id": "R58002",
            "paper_id": "R57700",
            "text": "The invasive shrub Buddleja davidii performs better in its introduced range it is commonly assumed that invasive plants grow more vigorously in their introduced than in their native range, which is then attributed to release from natural enemies or to microevolutionary changes, or both. however, few studies have tested this assumption by comparing the performance of invasive species in their native vs. introduced ranges. here, we studied abundance, growth, reproduction, and herbivory in 10 native chinese and 10 invasive german populations of the invasive shrub buddleja davidii (scrophulariaceae; butterfly bush). we found strong evidence for increased plant vigour in the introduced range: plants in invasive populations were significantly taller and had thicker stems, larger inflorescences, and heavier seeds than plants in native populations. these differences in plant performance could not be explained by a more benign climate in the introduced range. since leaf herbivory was substantially reduced in invasive populations, our data rather suggest that escape from natural enemies, associated with increased plant growth and reproduction, contributes to the invasion success of b. davidii in central europe.",
            "contribution_ids": [
                "R57701"
            ]
        },
        {
            "instance_id": "R58002xR57662",
            "comparison_id": "R58002",
            "paper_id": "R57662",
            "text": "Insect herbivore faunal diversity among invasive, non-invasive and native Eugenia species: Implications for the enemy release hypothesis abstract the enemy release hypothesis (erh) frequently has been invoked to explain the naturalization and spread of introduced species. one ramification of the erh is that invasive plants sustain less herbivore pressure than do native species. empirical studies testing the erh have mostly involved two-way comparisons between invasive introduced plants and their native counterparts in the invaded region. testing the erh would be more meaningful if such studies also included introduced non-invasive species because introduced plants, regardless of their abundance or impact, may support a reduced insect herbivore fauna and experience less damage. in this study, we employed a three-way comparison, in which we compared herbivore faunas among native, introduced invasive, and introduced non-invasive plants in the genus eugenia (myrtaceae) which all co-occur in south florida. we observed a total of 25 insect species in 12 families and 6 orders feeding on the six species of eugenia. of these insect species, the majority were native (72%), polyphagous (64%), and ectophagous (68%). we found that invasive introduced eugenia has a similar level of herbivore richness as both the native and the non-invasive introduced eugenia. however, the numbers and percentages of oligophagous insect species were greatest on the native eugenia, but they were not different between the invasive and non-invasive introduced eugenia. one oligophagous endophagous insect has likely shifted from the native to the invasive, but none to the non-invasive eugenia. in summary, the invasive eugenia encountered equal, if not greater, herbivore pressure than the non-invasive eugenia, including from oligophagous and endophagous herbivores. our data only provided limited support to the erh. we would not have been able to draw this conclusion without inclusion of the non-invasive eugenia species in the study.",
            "contribution_ids": [
                "R57663",
                "R57664",
                "R57665",
                "R57666"
            ]
        },
        {
            "instance_id": "R58002xR57988",
            "comparison_id": "R58002",
            "paper_id": "R57988",
            "text": "Alien and native plant establishment in grassland communities is more strongly affected by disturbance than above- and below-ground enemies understanding the factors that drive commonness and rarity of plant species and whether these factors differ for alien and native species are key questions in ecology. if a species is to become common in a community, incoming propagules must first be able to establish. the latter could be determined by competition with resident plants, the impacts of herbivores and soil biota, or a combination of these factors. we aimed to tease apart the roles that these factors play in determining establishment success in grassland communities of 10 alien and 10 native plant species that are either common or rare in germany, and from four families. in a two\u2010year multisite field experiment, we assessed the establishment success of seeds and seedlings separately, under all factorial combinations of low vs. high disturbance (mowing vs mowing and tilling of the upper soil layer), suppression or not of pathogens (biocide application) and, for seedlings only, reduction or not of herbivores (net\u2010cages). native species showed greater establishment success than alien species across all treatments, regardless of their commonness. moreover, establishment success of all species was positively affected by disturbance. aliens showed lower establishment success in undisturbed sites with biocide application. release of the undisturbed resident community from pathogens by biocide application might explain this lower establishment success of aliens. these findings were consistent for establishment from either seeds or seedlings, although less significantly so for seedlings, suggesting a more important role of pathogens in very early stages of establishment after germination. herbivore exclusion did play a limited role in seedling establishment success. synthesis: in conclusion, we found that less disturbed grassland communities exhibited strong biotic resistance to establishment success of species, whether alien or native. however, we also found evidence that alien species may benefit weakly from soilborne enemy release, but that this advantage over native species is lost when the latter are also released by biocide application. thus, disturbance was the major driver for plant species establishment success and effects of pathogens on alien plant establishment may only play a minor role.",
            "contribution_ids": [
                "R57989"
            ]
        },
        {
            "instance_id": "R58002xR57614",
            "comparison_id": "R58002",
            "paper_id": "R57614",
            "text": "Herbivorous arthropod community of an alien weed Solanum carolinense L. herbivorous arthropod fauna of the horse nettle solanum carolinense l., an alien solanaceous herb of north american origin, was characterized by surveying arthropod communities in the fields and comparing them with the original community compiled from published data to infer the impact of herbivores on the weed in the introduced region. field surveys were carried out in the central part of mainland japan for five years including an intensive regular survey in 1992. thirty-nine arthropod species were found feeding on the weed. the leaf, stem, flower and fruit of the weed were infested by the herbivores. the comparison of characteristics of the arthropod community with those of the community in the usa indicated that more sapsuckers and less chewers were on the weed in japan than in the usa. the community in japan was composed of high proportions of polyphages and exophages compared to that in the usa. eighty-seven percent of the species are known to be pests of agricultural crops. low species diversity of the community was also suggested. the depauperated herbivore community, in terms of feeding habit and niche on s. carolinense, suggested that the weed partly escaped from herbivory in its reproductive parts. the regular population census, however, indicated that a dominant coccinellid beetle, epilachna vigintioctopunctata, caused a noticeable damage on the leaves of the weed.",
            "contribution_ids": [
                "R57615"
            ]
        },
        {
            "instance_id": "R58002xR57986",
            "comparison_id": "R58002",
            "paper_id": "R57986",
            "text": "Herbivory and the success of Ligustrum lucidum: evidence from a comparison between native and novel ranges \\n\\ninvasive plant species may benefit from a reduction in herbivory in their introduced range. the reduced herbivory may cause a reallocation of resources from defence to fitness. here, we evaluated leaf herbivory of an invasive tree species (ligustrum lucidum aiton) in its native and novel ranges, and determined the potential changes in leaf traits that may be associated with the patterns of herbivory. we measured forest structure, damage by herbivores and leaf traits in novel and native ranges, and on the basis of the literature, we identified the common natural herbivores of l. lucidum. we also performed an experiment offering leaves from both ranges to a generalist herbivore (spodoptera frugiperda). l. lucidum was more abundant and experienced significantly less foliar damage in the novel than in the native range, in spite of the occurrence of several natural herbivores. the reduced lignin content and lower lignin\\u2009:\\u2009n ratio in novel leaves, together with the higher herbivore preference for leaves of this origin in the laboratory experiment, indicated lower herbivore resistance in novel than in native populations. the reduced damage by herbivores is not the only factor explaining invasion success, but it may be an important cause that enhances the invasiveness of l. lucidum.\\n",
            "contribution_ids": [
                "R57987"
            ]
        },
        {
            "instance_id": "R58002xR57612",
            "comparison_id": "R58002",
            "paper_id": "R57612",
            "text": "Diversity and abundance patterns of phytophagous insect communities on alien and native host plants in the Brassicaceae the herbivore load (abundance and species richness of herbivores) on alien plants is supposed to be one of the keys to understand the invasiveness of species. we investigate the phytophagous insect communities on cabbage plants (brassicaceae) in europe. we compare the communities of endophagous and ectophagous insects as well as of coleoptera and lepidoptera on native and alien cabbage plant species. contrary to many other reports, we found no differences in the herbivore load between native and alien hosts. the majority of insect species attacked alien as well as native hosts. across insect species, there was no difference in the patterns of host range on native and on alien hosts. likewise the similarity of insect communities across pairs of host species was not different between natives and aliens. we conclude that the general similarity in the community patterns between native and alien cabbage plant species are due to the chemical characteristics of this plant family. all cabbage plants share glucosinolates. this may facilitate host switches from natives to aliens. hence the presence of native congeners may influence invasiveness of alien plants.",
            "contribution_ids": [
                "R57613"
            ]
        },
        {
            "instance_id": "R58002xR57840",
            "comparison_id": "R58002",
            "paper_id": "R57840",
            "text": "Parasites and invasions: a biogeographic examination of parasites and hosts in native and introduced ranges aim\\u2002 to use a comparative approach to understand parasite demographic patterns in native versus introduced populations, evaluating the potential roles of host invasion history and parasite life history.",
            "contribution_ids": [
                "R57841"
            ]
        },
        {
            "instance_id": "R58002xR57996",
            "comparison_id": "R58002",
            "paper_id": "R57996",
            "text": "A Comparison of Herbivore Damage on Three Invasive Plants and Their Native Congeners: Implications for the Enemy Release Hypothesis abstract\\u2003 one explanation for the success of exotic plants in their introduced habitats is that, upon arriving to a new continent, plants escaped their native herbivores or pathogens, resulting in less damage and lower abundance of enemies than closely related native species (enemy release hypothesis). we tested whether the three exotic plant species, rubus phoenicolasius (wineberry), fallopia japonica (japanese knotweed), and persicaria perfoliata (mile-a-minute weed), suffered less herbivory or pathogen attack than native species by comparing leaf damage and invertebrate herbivore abundance and diversity on the invasive species and their native congeners. fallopia japonica and r. phoenicolasius received less leaf damage than their native congeners, and f. japonica also contained a lower diversity and abundance of invertebrate herbivores. if the observed decrease in damage experienced by these two plant species contributes to increased fitness, then escape from enemies may provide at least a partial explanation for their invasiveness. however, p. perfoliata actually received greater leaf damage than its native congener. rhinoncomimus latipes, a weevil previously introduced in the united states as a biological control for p. perfoliata, accounted for the greatest abundance of insects collected from p. perfoliata. therefore, it is likely that the biocontrol r. latipes was responsible for the greater damage on p. perfoliata, suggesting this insect may be effective at controlling p. perfoliata populations if its growth and reproduction is affected by the increased herbivore damage.",
            "contribution_ids": [
                "R68056",
                "R57997"
            ]
        },
        {
            "instance_id": "R58002xR57693",
            "comparison_id": "R58002",
            "paper_id": "R57693",
            "text": "Tolerance to herbivory, and not resistance, may explain differential success of invasive, naturalized, and native North American temperate vines numerous hypotheses suggest that natural enemies can influence the dynamics of biological invasions. here, we use a group of 12 related native, invasive, and naturalized vines to test the relative importance of resistance and tolerance to herbivory in promoting biological invasions. in a field experiment in long island, new york, we excluded mammal and insect herbivores and examined plant growth and foliar damage over two growing seasons. this novel approach allowed us to compare the relative damage from mammal and insect herbivores and whether damage rates were related to invasion. in a greenhouse experiment, we simulated herbivory through clipping and measured growth response. after two seasons of excluding herbivores, there was no difference in relative growth rates among invasive, naturalized, and native woody vines, and all vines were susceptible to damage from mammal and insect herbivores. thus, differential attack by herbivores and plant resistance to herbivory did not explain invasion success of these species. in the field, where damage rates were high, none of the vines were able to fully compensate for damage from mammals. however, in the greenhouse, we found that invasive vines were more tolerant of simulated herbivory than native and naturalized relatives. our results indicate that invasive vines are not escaping herbivory in the novel range, rather they are persisting despite high rates of herbivore damage in the field. while most studies of invasive plants and natural enemies have focused on resistance, this work suggests that tolerance may also play a large role in facilitating invasions.",
            "contribution_ids": [
                "R57694",
                "R57695",
                "R57696",
                "R57697"
            ]
        },
        {
            "instance_id": "R58002xR57637",
            "comparison_id": "R58002",
            "paper_id": "R57637",
            "text": "Herbivory, time since introduction and the invasiveness of exotic plants 1 we tested the enemy release hypothesis for invasiveness using field surveys of herbivory on 39 exotic and 30 native plant species growing in natural areas near ottawa, canada, and found that exotics suffered less herbivory than natives. 2 for the 39 introduced species, we also tested relationships between herbivory, invasiveness and time since introduction to north america. highly invasive plants had significantly less herbivory than plants ranked as less invasive. recently arrived plants also tended to be more invasive; however, there was no relationship between time since introduction and herbivory. 3 release from herbivory may be key to the success of highly aggressive invaders. low herbivory may also indicate that a plant possesses potent defensive chemicals that are novel to north america, which may confer resistance to pathogens or enable allelopathy in addition to deterring herbivorous insects.",
            "contribution_ids": [
                "R57638"
            ]
        },
        {
            "instance_id": "R58002xR57924",
            "comparison_id": "R58002",
            "paper_id": "R57924",
            "text": "Macroparasite Fauna of Alien Grey Squirrels (Sciurus carolinensis): Composition, Variability and Implications for Native Species introduced hosts populations may benefit of an \"enemy release\" through impoverishment of parasite communities made of both few imported species and few acquired local ones. moreover, closely related competing native hosts can be affected by acquiring introduced taxa (spillover) and by increased transmission risk of native parasites (spillback). we determined the macroparasite fauna of invasive grey squirrels (sciurus carolinensis) in italy to detect any diversity loss, introduction of novel parasites or acquisition of local ones, and analysed variation in parasite burdens to identify factors that may increase transmission risk for native red squirrels (s. vulgaris). based on 277 grey squirrels sampled from 7 populations characterised by different time scales in introduction events, we identified 7 gastro-intestinal helminths and 4 parasite arthropods. parasite richness is lower than in grey squirrel\\'s native range and independent from introduction time lags. the most common parasites are nearctic nematodes strongyloides robustus (prevalence: 56.6%) and trichostrongylus calcaratus (6.5%), red squirrel flea ceratophyllus sciurorum (26.0%) and holarctic sucking louse neohaematopinus sciuri (17.7%). all other parasites are european or cosmopolitan species with prevalence below 5%. s. robustus abundance is positively affected by host density and body mass, c. sciurorum abundance increases with host density and varies with seasons. overall, we show that grey squirrels in italy may benefit of an enemy release, and both spillback and spillover processes towards native red squirrels may occur.",
            "contribution_ids": [
                "R57925"
            ]
        },
        {
            "instance_id": "R58002xR57761",
            "comparison_id": "R58002",
            "paper_id": "R57761",
            "text": "Community structure of insect herbivores on introduced and native Solidago plants in Japan we compared community composition, density, and species richness of herbivorous insects on the introduced plant solidago altissima l. (asteraceae) and the related native species solidago virgaurea l. in japan. we found large differences in community composition on the two solidago species. five hemipteran sap feeders were found only on s. altissima. two of them, the aphid uroleucon nigrotuberculatum olive (hemiptera: aphididae) and the scale insect parasaissetia nigra nietner (hemiptera: coccidae), were exotic species, accounting for 62% of the total individuals on s. altissima. these exotic sap feeders mostly determined the difference of community composition on the two plant species. in contrast, the herbivore community on s. virgaurea consisted predominately of five native insects: two lepidopteran leaf chewers and three dipteran leaf miners. overall species richness did not differ between the plants because the increased species richness of sap feeders was offset by the decreased richness of leaf chewers and leaf miners on s. altissima. the overall density of herbivorous insects was higher on s. altissima than on s. virgaurea, because of the high density of the two exotic sap feeding species on s. altissima. we discuss the importance of analyzing community composition in terms of feeding guilds of insect herbivores for understanding how communities of insect herbivores are organized on introduced plants in novel habitats.",
            "contribution_ids": [
                "R57762"
            ]
        },
        {
            "instance_id": "R58002xR57907",
            "comparison_id": "R58002",
            "paper_id": "R57907",
            "text": "Little evidence for release from herbivores as a driver of plant invasiveness from a multi-species herbivore-removal experiment enemy release is frequently posed as a main driver of invasiveness of alien species. however, an experimental multi-species test examining performance and herbivory of invasive alien, non-invasive alien and native plant species in the presence and absence of natural enemies is lacking. in a common garden experiment in switzerland, we manipulated exposure of seven alien invasive, eight alien non-invasive and fourteen native species from six taxonomic groups to natural enemies (invertebrate herbivores), by applying a pesticide treatment under two different nutrient levels. we assessed biomass production, herbivore damage and the major herbivore taxa on plants. across all species, plants gained significantly greater biomass under pesticide treatment. however, invasive, non-invasive and native species did not differ in their biomass response to pesticide treatment at either nutrient level. the proportion of leaves damaged on invasive species was significantly lower compared to native species, but not when compared to non-invasive species. however, the difference was lost when plant size was accounted for. there were no differences between invasive, non-invasive and native species in herbivore abundance. our study offers little support for invertebrate herbivore release as a driver of plant invasiveness, but suggests that future enemy release studies should account for differences in plant size among species.",
            "contribution_ids": [
                "R57908",
                "R57909",
                "R57910",
                "R57911"
            ]
        },
        {
            "instance_id": "R58002xR57968",
            "comparison_id": "R58002",
            "paper_id": "R57968",
            "text": "Pollinators and predators at home and away: do they determine invasion success for Australian Acacia in New Zealand? interactions with pollinators and pre\u2010dispersal seed predators are important determinants of reproductive output and could influence the success of plant species introduced to areas outside their native range. we identified the role of these interactions in determining reproductive output and invasion outcomes for species of australian acacia introduced to new zealand.",
            "contribution_ids": [
                "R57969",
                "R57970"
            ]
        },
        {
            "instance_id": "R58002xR57740",
            "comparison_id": "R58002",
            "paper_id": "R57740",
            "text": "Acceleration of Exotic Plant Invasion in a Forested Ecosystem by a Generalist Herbivore abstract:\\u2002 the successful invasion of exotic plants is often attributed to the absence of coevolved enemies in the introduced range (i.e., the enemy release hypothesis). nevertheless, several components of this hypothesis, including the role of generalist herbivores, remain relatively unexplored. we used repeated censuses of exclosures and paired controls to investigate the role of a generalist herbivore, white\u2010tailed deer (odocoileus virginianus), in the invasion of 3 exotic plant species (microstegium vimineum, alliaria petiolata, and berberis thunbergii) in eastern hemlock (tsuga canadensis) forests in new jersey and pennsylvania (u.s.a.). this work was conducted in 10 eastern hemlock (t. canadensis) forests that spanned gradients in deer density and in the severity of canopy disturbance caused by an introduced insect pest, the hemlock woolly adelgid (adelges tsugae). we used maximum likelihood estimation and information theoretics to quantify the strength of evidence for alternative models of the influence of deer density and its interaction with the severity of canopy disturbance on exotic plant abundance. our results were consistent with the enemy release hypothesis in that exotic plants gained a competitive advantage in the presence of generalist herbivores in the introduced range. the abundance of all 3 exotic plants increased significantly more in the control plots than in the paired exclosures. for all species, the inclusion of canopy disturbance parameters resulted in models with substantially greater support than the deer density only models. our results suggest that white\u2010tailed deer herbivory can accelerate the invasion of exotic plants and that canopy disturbance can interact with herbivory to magnify the impact. in addition, our results provide compelling evidence of nonlinear relationships between deer density and the impact of herbivory on exotic species abundance. these findings highlight the important role of herbivore density in determining impacts on plant abundance and provide evidence of the operation of multiple mechanisms in exotic plant invasion.",
            "contribution_ids": [
                "R57741"
            ]
        },
        {
            "instance_id": "R58002xR57763",
            "comparison_id": "R58002",
            "paper_id": "R57763",
            "text": "Entomofauna of the introduced Chinese Tallow Tree abstract entomofauna in monospecific stands of the introduced chinese tallow tree (sapium sebiferum) and native mixed woodlands was sampled in 1982 along the texas coast and compared to samples of arthropods from an earlier study of native coastal prairie and from a study of arthropods in s. sebiferum in 2004. species diversity, richness, and abundance were highest in prairie, and were higher in mixed woodland than in s. sebiferum. nonmetric multidimensional scaling distinguished orders and families of arthropods, and families of herbivores in s. sebiferum from mixed woodland and coastal prairie. taxonomic similarity between s. sebiferum and mixed woodland was 51%. fauna from s. sebiferum in 2001 was more similar to mixed woodland than to samples from s. sebiferum collected in 1982. these results indicate that the entomofauna in s. sebiferum originated from mixed prairie and that, with time, these faunas became more similar. species richness and abundance of herbivores was lower in s. sebiferum, but proportion of total species in all trophic groups, except herbivores, was higher in s. sebiferum than mixed woodland. low concentration of tannin in leaves of s. sebiferum did not explain low loss of leaves to herbivores. lower abundance of herbivores on introduced species of plants fits the enemy release hypothesis, and low concentration of defense compounds in the face of low number of herbivores fits the evolution of increased competitive ability hypothesis.",
            "contribution_ids": [
                "R57764"
            ]
        },
        {
            "instance_id": "R58002xR57853",
            "comparison_id": "R58002",
            "paper_id": "R57853",
            "text": "Invading from the garden? A comparison of leaf herbivory for exotic and native plants in natural and ornamental settings abstract\\u2002 the enemies release hypothesis proposes that exotic species can become invasive by escaping from predators and parasites in their novel environment. agrawal et al. (enemy release? an experiment with congeneric plant pairs and diverse above\u2010 and below\u2010ground enemies. ecology, 86, 2979\u20132989) proposed that areas or times in which damage to introduced species is low provide opportunities for the invasion of native habitat. we tested whether ornamental settings may provide areas with low levels of herbivory for trees and shrubs, potentially facilitating invasion success. first, we compared levels of leaf herbivory among native and exotic species in ornamental and natural settings in cincinnati, ohio, united states. in the second study, we compared levels of herbivory for invasive and noninvasive exotic species between natural and ornamental settings. we found lower levels of leaf damage for exotic species than for native species; however, we found no differences in the amount of leaf damage suffered in ornamental or natural settings. our results do not provide any evidence that ornamental settings afford additional release from herbivory for exotic plant species.",
            "contribution_ids": [
                "R57854",
                "R57855"
            ]
        },
        {
            "instance_id": "R58002xR57914",
            "comparison_id": "R58002",
            "paper_id": "R57914",
            "text": "High water-use efficiency and growth contribute to success of non-native Erodium cicutarium in a Sonoran Desert winter annual community erodium cicutarium, an invasive plant, has recently increased in abundance in the sonoran desert. we tested hypotheses for its success, and found no evidence for a release from natural enemies. instead, e. cicutarium was able to achieve higher growth rates while controlling leaf-level water loss, allowing it to out-compete natives.",
            "contribution_ids": [
                "R57915"
            ]
        },
        {
            "instance_id": "R6755xR6531",
            "comparison_id": "R6755",
            "paper_id": "R6531",
            "text": "Using Semantics for Interactive Visual Analysis of Linked Open Data providing easy to use methods for visual analysis of linked data is often hindered by the complexity of semantic technologies. on the other hand, semantic information inherent to linked data provides opportunities to support the user in interactively analysing the data. this paper provides a demonstration of an interactive, web-based visualisation tool, the \"vis wizard\", which makes use of semantics to simplify the process of setting up visualisations, transforming the data and, most importantly, interactively analysing multiple datasets using brushing and linking methods.",
            "contribution_ids": [
                "R25690",
                "R6532"
            ]
        },
        {
            "instance_id": "R6755xR6523",
            "comparison_id": "R6755",
            "paper_id": "R6523",
            "text": "Towards a Linked-Data based Visualization Wizard datasets published in the lod cloud are recommended to follow some best practice in order to be 4-5 stars linked data compliant. they can often be consumed and accessed by different means such as api access, bulk download or as linked data fragments, but most of the time, a sparql endpoint is also provided. while the lod cloud keeps growing, having a quick glimpse of those datasets is getting harder and there is a need to develop new methods enabling to detect automatically what an arbitrary dataset is about and to recommend visualizations for data samples. we consider that \"a visualization is worth a million triples\", and in this paper, we propose a novel approach that mines the content of datasets and automatically generates visualizations. our approach is directly based on the usage of sparql queries that will detect the important categories of a dataset and that will specifically consider the properties used by the objects which have been interlinked via owl:sameas links. we then propose to associate type of visualization for those categories. we have implemented this approach into a so-called linked data vizualization wizard (ldvizwiz).",
            "contribution_ids": [
                "R6524"
            ]
        },
        {
            "instance_id": "R6755xR6511",
            "comparison_id": "R6755",
            "paper_id": "R6511",
            "text": "SemLens: visual analysis of semantic data with scatter plots and semantic lenses querying the semantic web and analyzing the query results are often complex tasks that can be greatly facilitated by visual interfaces. a major challenge in the design of these interfaces is to provide intuitive and efficient interaction support without limiting too much the analytical degrees of freedom. this paper introduces semlens, a visual tool that combines scatter plots and semantic lenses to overcome this challenge and to allow for a simple yet powerful analysis of rdf data. the scatter plots provide a global overview on an object collection and support the visual discovery of correlations and patterns in the data. the semantic lenses add dimensions for local analysis of subsets of the objects. a demo accessing dbpedia data is used for illustration.",
            "contribution_ids": [
                "R25676",
                "R6512"
            ]
        },
        {
            "instance_id": "R6756xR6457",
            "comparison_id": "R6756",
            "paper_id": "R6457",
            "text": "Using Hierarchical Edge Bundles to visualize complex ontologies in GLOW \"in the past decade, much effort has been put into the visual representation of ontologies. however, present visualization strategies are not equipped to handle complex ontologies with many relations, leading to visual clutter and inefficient use of space. in this paper, we propose glow, a method for ontology visualization based on hierarchical edge bundles. hierarchical edge bundles is a new visually attractive technique for displaying relations in hierarchical data, such as concept structures formed by 'subclass-of' and 'type-of' relations. we have developed a visualization library based on owl api, as well as a plug-in for prot\u00e9g\u00e9, a well-known ontology editor. the displayed adjacency relations can be selected from an ontology using a set of common configurations, allowing for intuitive discovery of information. our evaluation demonstrates that the glow visualization provides better visual clarity, and displays relations and complex ontologies better than the existing prot\u00e9g\u00e9 visualization plug-in jambalaya.\"",
            "contribution_ids": [
                "R25717",
                "R6458"
            ]
        },
        {
            "instance_id": "R6756xR6429",
            "comparison_id": "R6756",
            "paper_id": "R6429",
            "text": "Using Clusters in RDF Visualization clustered graph visualization techniques are an easy to understand way of hiding complex parts of a visualized graph when they are not needed by the user. when visualizing rdf, there are several situations where such clusters are defined in a very natural way. using this techniques, we can give the user optional access to some detailed information without unnecessarily occupying space in the basic view of the data. this paper describes algorithms for clustered visualization used in the trisolda rdf visualizer. most notable is the newly added clustered navigation technique.",
            "contribution_ids": [
                "R25708",
                "R6430"
            ]
        },
        {
            "instance_id": "R6756xR6417",
            "comparison_id": "R6756",
            "paper_id": "R6417",
            "text": "RDF data exploration and visualization we present paged graph visualization (pgv), a new semi-autonomous tool for rdf data exploration and visualization. pgv consists of two main components: a) the \"pgv explorer\" and b) the \"rdf pager\" module utilizing brahms, our high per-formance main-memory rdf storage system. unlike existing graph visualization techniques which attempt to display the entire graph and then filter out irrelevant data, pgv begins with a small graph and provides the tools to incrementally explore and visualize relevant data of very large rdf ontologies. we implemented several techniques to visualize and explore hot spots in the graph, i.e. nodes with large numbers of immediate neighbors. in response to the user-controlled, semantics-driven direction of the exploration, the pgv explorer obtains the necessary sub-graphs from the rdf pager and enables their incremental visualization leaving the previously laid out sub-graphs intact. we outline the problem of visualizing large rdf data sets, discuss our interface and its implementation, and through a controlled experiment we show the benefits of pgv.",
            "contribution_ids": [
                "R25704",
                "R6418"
            ]
        },
        {
            "instance_id": "R6756xR25720",
            "comparison_id": "R6756",
            "paper_id": "R25720",
            "text": "A Visual Summary for Linked Open Data sources in this paper we propose lodex, a tool that produces a representative summary of a linked open data (lod) source starting from scratch, thus supporting users in exploring and understanding the contents of a dataset. the tool takes in input the url of a sparql endpoint and launches a set of predefined sparql queries, from the results of the queries it generates a visual summary of the source. the summary reports statistical and structural information of the lod dataset and it can be browsed to focus on particular classes or to explore their properties and their use. lodex was tested on the 137 public sparql endpoints contained in data hub (formerly ckan), one of the main open data catalogues. the statistical and structural information extraction was successfully performed on 107 sources, among these the most significant ones are included in the online version of the tool.",
            "contribution_ids": [
                "R25721",
                "R6470"
            ]
        },
        {
            "instance_id": "R6756xR6461",
            "comparison_id": "R6756",
            "paper_id": "R6461",
            "text": "LodLive, exploring the web of data lodlive project, http://en.lodlive.it/, provides a demonstration of the use of linked data standard (rdf, sparql) to browse rdf resources. the application aims to spread linked data principles with a simple and friendly interface and reusable techniques. in this report we present an overview of the potential of lodlive, mentioning tools and methodologies that were used to create it.",
            "contribution_ids": [
                "R25718",
                "R6462"
            ]
        },
        {
            "instance_id": "R6756xR6409",
            "comparison_id": "R6756",
            "paper_id": "R6409",
            "text": "A tool for visualization and editing of OWL ontologies in an effort to optimize visualization and editing of owl ontologies we have developed growl-a browser and visual editor for owl that accurately visualizes the underlying dl semantics of owl ontologies while avoiding the difficulties of the verbose owl syntax. in this paper, we discuss growl visualization model and the essential visualization techniques implemented in growl.",
            "contribution_ids": [
                "R6410"
            ]
        },
        {
            "instance_id": "R6756xR6477",
            "comparison_id": "R6756",
            "paper_id": "R6477",
            "text": "graphVizdb: A Scalable Platform for Interactive Large Graph Visualization. we present a novel platform for the interactive visualization of very large graphs. the platform enables the user to interact with the visualized graph in a way that is very similar to the exploration of maps at multiple levels. our approach involves an offline preprocessing phase that builds the layout of the graph by assigning coordinates to its nodes with respect to a euclidean plane. the respective points are indexed with a spatial data structure, i.e., an r-tree, and stored in a database. multiple abstraction layers of the graph based on various criteria are also created offline, and they are indexed similarly so that the user can explore the dataset at different levels of granularity, depending on her particular needs. then, our system translates user operations into simple and very efficient spatial operations (i.e., window queries) in the backend. this technique allows for a fine-grained access to very large graphs with extremely low latency and memory requirements and without compromising the functionality of the tool. our web-based prototype supports three main operations: (1) interactive navigation, (2) multi-level exploration, and (3) keyword search on the graph metadata.",
            "contribution_ids": [
                "R6478"
            ]
        },
        {
            "instance_id": "R6756xR6433",
            "comparison_id": "R6756",
            "paper_id": "R6433",
            "text": "Visualizing large-scale RDF data using Subsets, Summaries, and Sampling in Oracle the paper addresses the problem of visualizing large scale rdf data via a 3-s approach, namely, by using, 1) subsets: to present only relevant data for visualisation; both static and dynamic subsets can be specified, 2) summaries: to capture the essence of rdf data being viewed; summarized data can be expanded on demand thereby allowing users to create hybrid (summary-detail) fisheye views of rdf data, and 3) sampling: to further optimize visualization of large-scale data where a representative sample suffices. the visualization scheme works with both asserted and inferred triples (generated using rdf(s) and owl semantics). this scheme is implemented in oracle by developing a plug-in for the cytoscape graph visualization tool, which uses functions defined in a oracle pl/sql package, to provide fast and optimized access to oracle semantic store containing rdf data. interactive visualization of a synthesized rdf data set (lubm 1 million triples), two native rdf datasets (wikipedia 47 million triples and uniprot 700 million triples), and an owl ontology (eclassowl with a large class hierarchy including over 25,000 owl classes, 5,000 properties, and 400,000 class-properties) demonstrates the effectiveness of our visualization scheme.",
            "contribution_ids": [
                "R25709",
                "R6434"
            ]
        },
        {
            "instance_id": "R6757xR6380",
            "comparison_id": "R6757",
            "paper_id": "R6380",
            "text": "Cross-Lingual Question Answering Using Common Semantic Space with the advent of big data concept, a lot of attention has been paid to structuring and giving semantic to this data. knowledge bases like dbpedia play an important role to achieve this goal. question answering systems are common approach to address expressivity and usability of information extraction from knowledge bases. recent researches focused only on monolingual qa systems while cross-lingual setting has still so many barriers. in this paper we introduce a new cross-lingual approach using a unified semantic space among languages. after keyword extraction, entity linking and answer type detection, we use cross lingual semantic similarity to extract the answer from knowledge base via relation selection and type matching. we have evaluated our approach on persian and spanish which are typologically different languages. our experiments are on dbpedia. the results are promising for both languages.",
            "contribution_ids": [
                "R6381"
            ]
        },
        {
            "instance_id": "R6757xR6300",
            "comparison_id": "R6757",
            "paper_id": "R6300",
            "text": "Question answering over biomedical linked data with Grammatical Framework the blending of linked data with ontologies leverages the access to data. gfmed introduces grammars for a controlled natural language targeted towards biomedical linked data and the corresponding controlled sparql language. the grammars are described in grammatical framework and introduce linguistic and sparql phrases mostly about drugs, diseases and relationships between them. the semantic and linguistic chunks correspond to description logic constructors. problems and solutions for querying biomedical linked data with romanian, besides english, are also considered in the context of gf.",
            "contribution_ids": [
                "R6301"
            ]
        },
        {
            "instance_id": "R6757xR6401",
            "comparison_id": "R6757",
            "paper_id": "R6401",
            "text": "Natural language questions for the web of data the linked data initiative comprises structured databases in the semantic-web data model rdf. exploring this heterogeneous data by structured query languages is tedious and error-prone even for skilled users. to ease the task, this paper presents a methodology for translating natural language questions into structured sparql queries over linked-data sources. \\n \\nour method is based on an integer linear program to solve several disambiguation tasks jointly: the segmentation of questions into phrases; the mapping of phrases to semantic entities, classes, and relations; and the construction of sparql triple patterns. our solution harnesses the rich type system provided by knowledge bases in the web of linked data, to constrain our semantic-coherence objective function. we present experiments on both the question translation and the resulting query answering.",
            "contribution_ids": [
                "R6402"
            ]
        },
        {
            "instance_id": "R6757xR6350",
            "comparison_id": "R6757",
            "paper_id": "R6350",
            "text": "Description of the POMELO System for the Task 2 of QALD-2014 in this paper, we present the pomelo system developed for participating in the task 2 of the qald-4 challenge. for translating natural language questions in sparql queries we exploit natural language processing methods, semantic resources and rdf triples description. we designed a four-step method which pre-processes the question, performs an abstraction of the question, then builds a representation of the sparql query and finally generates the query. the system was ranked second out of three participating systems. it achieves good performance with 0.85 f-measure on the set of 25 test questions.",
            "contribution_ids": [
                "R6351"
            ]
        },
        {
            "instance_id": "R6757xR6353",
            "comparison_id": "R6757",
            "paper_id": "R6353",
            "text": "PowerAqua: Supporting users in querying and exploring the Semantic Web with the continued growth of online semantic information, the processes of searching and managing this massive scale and heterogeneous content have become increasingly challenging. in this work, we present poweraqua, an ontologybased question answering system that is able to answer queries by locating and integrating information, which can be distributed across heterogeneous semantic resources. we provide a complete overview of the system including: the research challenges that it addresses, its architecture, the evaluations that have been conducted to test it, and an in-depth discussion showing how poweraqua effectively supports users in querying and exploring semantic web content.",
            "contribution_ids": [
                "R6354"
            ]
        },
        {
            "instance_id": "R6757xR6313",
            "comparison_id": "R6757",
            "paper_id": "R6313",
            "text": "Natural language queries over heterogeneous linked data graphs the demand to access large amounts of heterogeneous structured data is emerging as a trend for many users and applications. however, the effort involved in querying heterogeneous and distributed third-party databases can create major barriers for data consumers. at the core of this problem is the semantic gap between the way users express their information needs and the representation of the data. this work aims to provide a natural language interface and an associated semantic index to support an increased level of vocabulary independency for queries over linked data/semantic web datasets, using a distributional-compositional semantics approach. distributional semantics focuses on the automatic construction of a semantic model based on the statistical distribution of co-occurring words in large-scale texts. the proposed query model targets the following features: (i) a principled semantic approximation approach with low adaptation effort (independent from manually created resources such as ontologies, thesauri or dictionaries), (ii) comprehensive semantic matching supported by the inclusion of large volumes of distributional (unstructured) commonsense knowledge into the semantic approximation process and (iii) expressive natural language queries. the approach is evaluated using natural language queries on an open domain dataset and achieved avg. recall=0.81, mean avg. precision=0.62 and mean reciprocal rank=0.49.",
            "contribution_ids": [
                "R6314"
            ]
        },
        {
            "instance_id": "R6757xR6316",
            "comparison_id": "R6757",
            "paper_id": "R6316",
            "text": "A HMM-based approach to question answering against linked data in this paper, we present a qa system enabling nl questions against linked data, designed and adopted by the tor vergata university ai group in the qald-3 evaluation. the system integrates lexical semantic modeling and statistical inference within a complex architecture that decomposes the nl interpretation task into a cascade of three different stages: (1) the selection of key ontological information from the question (i.e. predicate, arguments and properties), (2) the location of such salient information in the ontology through the joint disambiguation of the different candidates and (3) the compilation of the final sparql query. this architecture characterizes a novel approach for the task and exploits a graphical model (i.e. an hidden markov model) to select the proper ontological triples according to the graph nature of rdf. in particular, for each query an hmm model is produced whose viterbi solution is the comprehensive joint disambiguation across the sentence elements. the combination of these approaches achieved interesting results in the qald competition. the rtv is in fact within the group of participants performing slightly below the best system, but with smaller requirements and on significantly poorer input information.",
            "contribution_ids": [
                "R6317"
            ]
        },
        {
            "instance_id": "R68535xR67866",
            "comparison_id": "R68535",
            "paper_id": "R67866",
            "text": "Emergent constraints on transient climate response  (TCR) and equilibrium climate sensitivity\u00c2\u00a0(ECS) from historical warming in CMIP5 and CMIP6 models abstract. climate sensitivity to co2 remains the key uncertainty in projections of future climate change. transient climate response\\xa0(tcr) is the metric of temperature sensitivity that is most relevant to warming in the next few decades and contributes the biggest uncertainty to estimates of the carbon budgets consistent with the paris targets. equilibrium climate sensitivity\\xa0(ecs) is vital for understanding longer-term climate change and stabilisation targets. in the ipcc 5th assessment report (ar5), the stated \u201clikely\u201d ranges (16\\u2009%\u201384\\u2009% confidence) of tcr (1.0\u20132.5\\u2009k) and ecs (1.5\u20134.5\\u2009k) were broadly consistent with the ensemble of cmip5 earth system models\\xa0(esms) available at the time. however, many of the latest cmip6 esms have larger climate sensitivities, with 5\\xa0of 34\\xa0models having tcr values above 2.5\\u2009k and an ensemble mean tcr of 2.0\u00b10.4\\u2009k. even starker, 12\\xa0of 34\\xa0models have an ecs value above 4.5\\u2009k. on the face of it, these latest esm results suggest that the ipcc likely ranges may need revising upwards, which would cast further doubt on the feasibility of the paris targets. here we show that rather than increasing the uncertainty in climate sensitivity, the cmip6 models help to constrain the likely range of tcr to 1.3\u20132.1\\u2009k, with a central estimate of 1.68\\u2009k. we reach this conclusion through an emergent constraint approach which relates the value of tcr linearly to the global warming from 1975\\xa0onwards. this is a period when the signal-to-noise ratio of the net radiative forcing increases strongly, so that uncertainties in aerosol forcing become progressively less problematic. we find a consistent emergent constraint on tcr when we apply the same method to cmip5 models. our constraints on tcr are in good agreement with other recent studies which analysed cmip ensembles. the relationship between ecs and the post-1975 warming trend is less direct and also non-linear. however, we are able to derive a likely range of ecs of 1.9\u20133.4\\u2009k from the cmip6 models by assuming an underlying emergent relationship based on a two-box energy balance model. despite some methodological differences; this is consistent with a previously published ecs constraint derived from warming trends in cmip5 models to\\xa02005. our results seem to be part of a growing consensus amongst studies that have applied the emergent constraint approach to different model ensembles and to different aspects of the record of global warming.\\n",
            "contribution_ids": [
                "R67870",
                "R67880",
                "R68044",
                "R68045",
                "R68050",
                "R68052",
                "R68055",
                "R68059",
                "R68062",
                "R68065",
                "R68072",
                "R68078",
                "R68081",
                "R68084",
                "R68085",
                "R68090",
                "R68093",
                "R68096",
                "R68099",
                "R68102",
                "R68106",
                "R68110",
                "R68111",
                "R68116",
                "R68066",
                "R68075"
            ]
        },
        {
            "instance_id": "R68871xR23436",
            "comparison_id": "R68871",
            "paper_id": "R23436",
            "text": "Climate Simulations Using MRI-AGCM3.2 with 20-km Grid a new version of the atmospheric general circulation model of the meteorological research institute (mri), with a horizontal grid size of about 20 km, has been developed. the previous version of the 20-km model, mriagcm3.1, which was developed from an operational numerical weather-prediction model, provided information on possible climate change induced by global warming, including future changes in tropical cyclones, the east asian monsoon, extreme events, and blockings. for the new version, mri-agcm3.2, we have introduced various new parameterization schemes that improve the model climate. using the new model, we performed a present-day climate experiment using observed sea surface temperature. the model shows improvements in simulating heavy monthly-mean precipitation around the tropical western pacific, the global distribution of tropical cyclones, the seasonal march of east asian summer monsoon, and blockings in the pacific. improvements in the model climatologies were confirmed numerically using skill scores (e.g., taylor\u2019s skill score).",
            "contribution_ids": [
                "R23437"
            ]
        },
        {
            "instance_id": "R68871xR23326",
            "comparison_id": "R68871",
            "paper_id": "R23326",
            "text": "GFDL\u00e2\u0080\u0099s ESM2 Global Coupled Climate\u00e2\u0080\u0093Carbon Earth System Models. Part I: Physical Formulation and Baseline Simulation Characteristics abstract \\n the physical climate formulation and simulation characteristics of two new global coupled carbon\u2013climate earth system models, esm2m and esm2g, are described. these models demonstrate similar climate fidelity as the geophysical fluid dynamics laboratory\u2019s previous climate model version 2.1 (cm2.1) while incorporating explicit and consistent carbon dynamics. the two models differ exclusively in the physical ocean component; esm2m uses modular ocean model version 4p1 with vertical pressure layers while esm2g uses generalized ocean layer dynamics with a bulk mixed layer and interior isopycnal layers. differences in the ocean mean state include the thermocline depth being relatively deep in esm2m and relatively shallow in esm2g compared to observations. the crucial role of ocean dynamics on climate variability is highlighted in el ni\u00f1o\u2013southern oscillation being overly strong in esm2m and overly weak in esm2g relative to observations. thus, while esm2g might better represent climate changes relating to total heat content variability given its lack of long-term drift, gyre circulation, and ventilation in the north pacific, tropical atlantic, and indian oceans, and depth structure in the overturning and abyssal flows, esm2m might better represent climate changes relating to surface circulation given its superior surface temperature, salinity, and height patterns, tropical pacific circulation and variability, and southern ocean dynamics. the overall assessment is that neither model is fundamentally superior to the other, and that both models achieve sufficient fidelity to allow meaningful climate and earth system modeling applications. this affords the ability to assess the role of ocean configuration on earth system interactions in the context of two state-of-the-art coupled carbon\u2013climate models.",
            "contribution_ids": [
                "R23327"
            ]
        },
        {
            "instance_id": "R68871xR23260",
            "comparison_id": "R68871",
            "paper_id": "R23260",
            "text": "The NCEP Climate Forecast System Reanalysis \"the ncep climate forecast system reanalysis (cfsr) was completed for the 31-yr period from 1979 to 2009, in january 2010. the cfsr was designed and executed as a global, high-resolution coupled atmosphere\u2013ocean\u2013land surface\u2013sea ice system to provide the best estimate of the state of these coupled domains over this period. the current cfsr will be extended as an operational, real-time product into the future. new features of the cfsr include 1) coupling of the atmosphere and ocean during the generation of the 6-h guess field, 2) an interactive sea ice model, and 3) assimilation of satellite radiances by the gridpoint statistical interpolation (gsi) scheme over the entire period. the cfsr global atmosphere resolution is ~38 km (t382) with 64 levels extending from the surface to 0.26 hpa. the global ocean's latitudinal spacing is 0.25\u00b0 at the equator, extending to a global 0.5\u00b0 beyond the tropics, with 40 levels to a depth of 4737 m. the global land surface model has four soil levels and the global sea ice m...\"",
            "contribution_ids": [
                "R23261"
            ]
        },
        {
            "instance_id": "R68871xR23368",
            "comparison_id": "R68871",
            "paper_id": "R23368",
            "text": "Present-Day Atmospheric Simulations Using GISS ModelE: Comparison to In Situ, Satellite, and Reanalysis Data abstract \\n a full description of the modele version of the goddard institute for space studies (giss) atmospheric general circulation model (gcm) and results are presented for present-day climate simulations (ca. 1979). this version is a complete rewrite of previous models incorporating numerous improvements in basic physics, the stratospheric circulation, and forcing fields. notable changes include the following: the model top is now above the stratopause, the number of vertical layers has increased, a new cloud microphysical scheme is used, vegetation biophysics now incorporates a sensitivity to humidity, atmospheric turbulence is calculated over the whole column, and new land snow and lake schemes are introduced. the performance of the model using three configurations with different horizontal and vertical resolutions is compared to quality-controlled in situ data, remotely sensed and reanalysis products. overall, significant improvements over previous models are seen, particularly in upper-atmosphere temperatures and winds, cloud heights, precipitation, and sea level pressure. data\u2013model comparisons continue, however, to highlight persistent problems in the marine stratocumulus regions.",
            "contribution_ids": [
                "R23369"
            ]
        },
        {
            "instance_id": "R68871xR23273",
            "comparison_id": "R68871",
            "paper_id": "R23273",
            "text": "The ACCESS coupled model: description, control climate and evaluation 4oasis3.2\u20135 coupling framework. the primary goal of the access-cm development is to provide the australian climate community with a new generation fully coupled climate model for climate research, and to participate in phase five of the coupled model inter-comparison project (cmip5). this paper describes the access-cm framework and components, and presents the control climates from two versions of the access-cm, access1.0 and access1.3, together with some fields from the 20 th century historical experiments, as part of model evaluation. while sharing the same ocean sea-ice model (except different setups for a few parameters), access1.0 and access1.3 differ from each other in their atmospheric and land surface components: the former is configured with the uk met office hadgem2 (r1.1) atmospheric physics and the met office surface exchange scheme land surface model version 2, and the latter with atmospheric physics similar to the uk met office global atmosphere 1.0 includ ing modifications performed at cawcr and the csiro community atmosphere biosphere land exchange land surface model version 1.8. the global average annual mean surface air temperature across the 500-year preindustrial control integrations show a warming drift of 0.35 \u00b0c in access1.0 and 0.04 \u00b0c in access1.3. the overall skills of access-cm in simulating a set of key climatic fields both globally and over australia significantly surpass those from the preceding csiro mk3.5 model delivered to the previous coupled model inter-comparison. however, access-cm, like other cmip5 models, has deficiencies in various as pects, and these are also discussed.",
            "contribution_ids": [
                "R23274"
            ]
        },
        {
            "instance_id": "R68871xR23287",
            "comparison_id": "R68871",
            "paper_id": "R23287",
            "text": "A Modified Dynamic Framework for the Atmospheric Spectral Model and Its Application abstract \\n this paper describes a dynamic framework for an atmospheric general circulation spectral model in which a reference stratified atmospheric temperature and a reference surface pressure are introduced into the governing equations so as to improve the calculation of the pressure gradient force and gradients of surface pressure and temperature. the vertical profile of the reference atmospheric temperature approximately corresponds to that of the u.s. midlatitude standard atmosphere within the troposphere and stratosphere, and the reference surface pressure is a function of surface terrain geopotential and is close to the observed mean surface pressure. prognostic variables for the temperature and surface pressure are replaced by their perturbations from the prescribed references. the numerical algorithms of the explicit time difference scheme for vorticity and the semi-implicit time difference scheme for divergence, perturbation temperature, and perturbation surface pressure equation are given in detail. the modified numerical framework is implemented in the community atmosphere model version 3 (cam3) developed at the national center for atmospheric research (ncar) to test its validation and impact on simulated climate. both the original and the modified models are run with the same spectral resolution (t42), the same physical parameterizations, and the same boundary conditions corresponding to the observed monthly mean sea surface temperature and sea ice concentration from 1971 to 2000. this permits one to evaluate the performance of the new dynamic framework compared to the commonly used one. results show that there is a general improvement for the simulated climate at regional and global scales, especially for temperature and wind.",
            "contribution_ids": [
                "R23288"
            ]
        },
        {
            "instance_id": "R6947xR6736",
            "comparison_id": "R6947",
            "paper_id": "R6736",
            "text": "Towards Unsupervised Learning of Temporal Relations between Events automatic extraction of temporal relations between event pairs is an important task for several natural language processing applications such as question answering, information extraction, and summarization. since most existing methods are supervised and require large corpora, which for many languages do not exist, we have concentrated our efforts to reduce the need for annotated data as much as possible. this paper presents two different algorithms towards this goal. the first algorithm is a weakly supervised machine learning approach for classification of temporal relations between events. in the first stage, the algorithm learns a general classifier from an annotated corpus. then, inspired by the hypothesis of \"one type of temporal relation per discourse\\'\\', it extracts useful information from a cluster of topically related documents. we show that by combining the global information of such a cluster with local decisions of a general classifier, a bootstrapping cross-document classifier can be built to extract temporal relations between events. our experiments show that without any additional annotated data, the accuracy of the proposed algorithm is higher than that of several previous successful systems. the second proposed method for temporal relation extraction is based on the expectation maximization (em) algorithm. within em, we used different techniques such as a greedy best-first search and integer linear programming for temporal inconsistency removal. we think that the experimental results of our em based algorithm, as a first step toward a fully unsupervised temporal relation extraction method, is encouraging.",
            "contribution_ids": [
                "R6737"
            ]
        },
        {
            "instance_id": "R6947xR6705",
            "comparison_id": "R6947",
            "paper_id": "R6705",
            "text": "TIARA: A Visual Exploratory Text Analytic System in this paper, we present a novel exploratory visual analytic system called tiara (text insight via automated responsive analytics), which combines text analytics and interactive visualization to help users explore and analyze large collections of text. given a collection of documents, tiara first uses topic analysis techniques to summarize the documents into a set of topics, each of which is represented by a set of keywords. in addition to extracting topics, tiara derives time-sensitive keywords to depict the content evolution of each topic over time. to help users understand the topic-based summarization results, tiara employs several interactive text visualization techniques to explain the summarization results and seamlessly link such results to the original text. we have applied tiara to several real-world applications, including email summarization and patient record analysis. to measure the effectiveness of tiara, we have conducted several experiments. our experimental results and initial user feedback suggest that tiara is effective in aiding users in their exploratory text analytic tasks.",
            "contribution_ids": [
                "R6706"
            ]
        },
        {
            "instance_id": "R6947xR6722",
            "comparison_id": "R6947",
            "paper_id": "R6722",
            "text": "Framework for Abstractive Summarization using Text-to-Text Generation we propose a new, ambitious framework for abstractive summarization, which aims at selecting the content of a summary not from sentences, but from an abstract representation of the source documents. this abstract representation relies on the concept of information items (init), which we define as the smallest element of coherent information in a text or a sentence. our framework differs from previous abstractive summarization models in requiring a semantic analysis of the text. we present a first attempt made at developing a system from this framework, along with evaluation results for it from tac 2010. we also present related work, both from within and outside of the automatic summarization domain.",
            "contribution_ids": [
                "R6723"
            ]
        },
        {
            "instance_id": "R6947xR6733",
            "comparison_id": "R6947",
            "paper_id": "R6733",
            "text": "A Statistical Approach for Automatic Text Summarization by Extraction automatic document summarization is a highly interdisciplinary research area related with computer science as well as cognitive psychology. this summarization is to compress an original document into a summarized version by extracting almost all of the essential concepts with text mining techniques. this research focuses on developing a statistical automatic text summarization approach, kmixture probabilistic model, to enhancing the quality of summaries. ksrs employs the k-mixture probabilistic model to establish term weights in a statistical sense, and further identifies the term relationships to derive the semantic relationship significance (srs) of nouns. sentences are ranked and extracted based on their semantic relationship significance values. the objective of this research is thus to propose a statistical approach to text summarization. we propose a k-mixture semantic relationship significance (ksrs) approach to enhancing the quality of document summary results. the k-mixture probabilistic model is used to determine the term weights. term relationships are then investigated to develop the semantic relationship of nouns that manifests sentence semantics. sentences with significant semantic relationship, nouns are extracted to form the summary accordingly.",
            "contribution_ids": [
                "R6734"
            ]
        },
        {
            "instance_id": "R6947xR6747",
            "comparison_id": "R6947",
            "paper_id": "R6747",
            "text": "Automatic Keyword Extraction for Text Summarization in e-Newspapers \"summarization is the process of reducing a text document to create a summary that retains the most important points of the original document. extractive summarizers work on the given text to extract sentences that best convey the message hidden in the text. most extractive summarization techniques revolve around the concept of finding keywords and extracting sentences that have more keywords than the rest. keyword extraction usually is done by extracting relevant words having a higher frequency than others, with stress on important ones'. manual extraction or annotation of keywords is a tedious process brimming with errors involving lots of manual effort and time. in this paper, we proposed an algorithm to extract keyword automatically for text summarization in e-newspaper datasets. the proposed algorithm is compared with the experimental result of articles having the similar title in four different e-newspapers to check the similarity and consistency in summarized results.\"",
            "contribution_ids": [
                "R6748"
            ]
        },
        {
            "instance_id": "R6947xR6709",
            "comparison_id": "R6947",
            "paper_id": "R6709",
            "text": "Towards recency ranking in web search in web search, recency ranking refers to ranking documents by relevance which takes freshness into account. in this paper, we propose a retrieval system which automatically detects and responds to recency sensitive queries. the system detects recency sensitive queries using a high precision classifier. the system responds to recency sensitive queries by using a machine learned ranking model trained for such queries. we use multiple recency features to provide temporal evidence which effectively represents document recency. furthermore, we propose several training methodologies important for training recency sensitive rankers. finally, we develop new evaluation metrics for recency sensitive queries. our experiments demonstrate the efficacy of the proposed approaches.",
            "contribution_ids": [
                "R6710"
            ]
        },
        {
            "instance_id": "R6947xR6725",
            "comparison_id": "R6947",
            "paper_id": "R6725",
            "text": "Using NMF-based text summarization to improve supervised and unsupervised classification this paper presents a new generic text summarization method using non-negative matrix factorization (nmf) to estimate sentence relevance. proposed sentence relevance estimation is based on normalization of nmf topic space and further weighting of each topic using sentences representation in topic space. the proposed method shows better summarization quality and performance than state of the art methods on duc 2002 standard dataset. in addition, we study how this method can improve the performance of supervised and unsupervised text classification tasks. in our experiments with reuters-21578 and classic4 benchmark datasets we apply developed text summarization method as a preprocessing step for further multi-label classification and clustering. as a result, the quality of classification and clustering has been significantly improved.",
            "contribution_ids": [
                "R6726"
            ]
        },
        {
            "instance_id": "R6947xR6712",
            "comparison_id": "R6947",
            "paper_id": "R6712",
            "text": "Understanding Text Corpora with Multiple Facets text visualization becomes an increasingly more important research topic as the need to understand massive-scale textual information is proven to be imperative for many people and businesses. however, it is still very challenging to design effective visual metaphors to represent large corpora of text due to the unstructured and high-dimensional nature of text. in this paper, we propose a data model that can be used to represent most of the text corpora. such a data model contains four basic types of facets: time, category, content (unstructured), and structured facet. to understand the corpus with such a data model, we develop a hybrid visualization by combining the trend graph with tag-clouds. we encode the four types of data facets with four separate visual dimensions. to help people discover evolutionary and correlation patterns, we also develop several visual interaction methods that allow people to interactively analyze text by one or more facets. finally, we present two case studies to demonstrate the effectiveness of our solution in support of multi-faceted visual analysis of text corpora.",
            "contribution_ids": [
                "R6713"
            ]
        },
        {
            "instance_id": "R6947xR6743",
            "comparison_id": "R6947",
            "paper_id": "R6743",
            "text": "UWN: A Large Multilingual Lexical Knowledge Base we present uwn, a large multilingual lexical knowledge base that describes the meanings and relationships of words in over 200 languages. this paper explains how link prediction, information integration and taxonomy induction methods have been used to build uwn based on wordnet and extend it with millions of named entities from wikipedia. we additionally introduce extensions to cover lexical relationships, frame-semantic knowledge, and language data. an online interface provides human access to the data, while a software api enables applications to look up over 16 million words and names.",
            "contribution_ids": [
                "R6744"
            ]
        },
        {
            "instance_id": "R6948xR6567",
            "comparison_id": "R6948",
            "paper_id": "R6567",
            "text": "Automated text summarization and the SUMMARIST system this paper consists of three parts: a preliminary typology of summaries in general; a description of the current and planned modules and performance of the summarist automated multilingual text summarization system being built sat isi, and a discussion of three methods to evaluate summaries.",
            "contribution_ids": [
                "R6568"
            ]
        },
        {
            "instance_id": "R6948xR6593",
            "comparison_id": "R6948",
            "paper_id": "R6593",
            "text": "NewsInEssence: A System For Domain-Independent, Real-Time News Clustering and Multi-Document Summarization newsinessence is a system for finding, visualizing and summarizing a topic-based cluster of news stories. in the generic scenario for newsinessence, a user selects a single news story from a news web site. our system then searches other live sources of news for other stories related to the same event and produces summaries of a subset of the stories that it finds, according to parameters specified by the user.",
            "contribution_ids": [
                "R6594"
            ]
        },
        {
            "instance_id": "R6948xR6582",
            "comparison_id": "R6948",
            "paper_id": "R6582",
            "text": "Information Fusion in the Context of Multi-Document Summarization we present a method to automatically generate a concise summary by identifying and synthesizing similar elements across related text from a set of multiple documents. our approach is unique in its usage of language generation to reformulate the wording of the summary.",
            "contribution_ids": [
                "R6583"
            ]
        },
        {
            "instance_id": "R6948xR6571",
            "comparison_id": "R6948",
            "paper_id": "R6571",
            "text": "Trainable, scalable summarization using robust NLP and machine learning we describe a trainable and scalable summarization system which utilizes features derived from information retrieval, information extraction, and nlp techniques and on-line resources. the system combines these features using a trainable feature combiner learned from summary examples through a machine learning algorithm. we demonstrate system scalability by reporting results on the best combination of summarization features for different document sources. we also present preliminary results from a task-based evaluation on summarization output usability.",
            "contribution_ids": [
                "R6572"
            ]
        },
        {
            "instance_id": "R6948xR6614",
            "comparison_id": "R6948",
            "paper_id": "R6614",
            "text": "Generating Indicative-Informative Summaries with SumUM \" we present and evaluate sumum, a text summarization system that takes a raw technical text as input and produces an indicative informative summary. the indicative part of the summary identifies the topics of the document, and the informative part elaborates on some of these topics according to the reader's interest. sumum motivates the topics, describes entities, and defines concepts. it is a first step for exploring the issue of dynamic summarization. this is accomplished through a process of shallow syntactic and semantic analysis, concept identification, and text regeneration. our method was developed through the study of a corpus of abstracts written by professional abstractors. relying on human judgment, we have evaluated indicativeness, informativeness, and text acceptability of the automatic summaries. the results thus far indicate good performance when compared with other summarization technologies. \"",
            "contribution_ids": [
                "R6615"
            ]
        },
        {
            "instance_id": "R6948xR6599",
            "comparison_id": "R6948",
            "paper_id": "R6599",
            "text": "Automated multi-document summarization in NeATS this paper describes the multi-document text summarization system neats. using a simple algorithm, neats was among the top two performers of the duc-01 evaluation.",
            "contribution_ids": [
                "R6600"
            ]
        },
        {
            "instance_id": "R6948xR6578",
            "comparison_id": "R6948",
            "paper_id": "R6578",
            "text": "Discourse Trees Are Good Indicators of Importance in Text researchers in computational linguistics have long speculated that the nuclei of the rhetorical structure tree of a text form an adequate \\\\summary\" of the text for which that tree was built. however, to my knowledge, there has been no experiment to connrm how valid this speculation really is. in this paper, i describe a psycholinguistic experiment that shows that the concepts of discourse structure and nuclearity can be used eeectively in text summarization. more precisely, i show that there is a strong correlation between the nuclei of the discourse structure of a text and what readers perceive to be the most important units in that text. in addition, i propose and evaluate the quality of an automatic, discourse-based summa-rization system that implements the methods that were validated by the psycholinguistic experiment. the evaluation indicates that although the system does not match yet the results that would be obtained if discourse trees had been built manually, it still signiicantly outperforms both a baseline algorithm and microsoft\\'s ooce97 summarizer. 1 motivation traditionally, previous approaches to automatic text summarization have assumed that the salient parts of a text can be determined by applying one or more of the following assumptions: important sentences in a text contain words that are used frequently (luhn 1958; edmundson 1968); important sentences contain words that are used in the title and section headings (edmundson 1968); important sentences are located at the beginning or end of paragraphs (baxendale 1958); important sentences are located at positions in a text that are genre dependent, and these positions can be determined automatically, through training important sentences use bonus words such as \\\\greatest\" and \\\\signiicant\" or indicator phrases such as \\\\the main aim of this paper\" and \\\\the purpose of this article\", while unimportant sentences use stigma words such as \\\\hardly\" and \\\\im-possible\" important sentences and concepts are the highest connected entities in elaborate semantic struc-important and unimportant sentences are derivable from a discourse representation of the text (sparck jones 1993b; ono, sumita, & miike 1994). in determining the words that occur most frequently in a text or the sentences that use words that occur in the headings of sections, computers are accurate tools. therefore, in testing the validity of using these indicators for determining the most important units in a text, it is adequate to compare the direct output of a summarization program that implements the assump-tion(s) under scrutiny with a human-made \u2026",
            "contribution_ids": [
                "R6579"
            ]
        },
        {
            "instance_id": "R69680xR69609",
            "comparison_id": "R69680",
            "paper_id": "R69609",
            "text": "Towards a knowledge graph based speech interface applications which use human speech as an input require a speech interface with high recognition accuracy. the words or phrases in the recognised text are annotated with a machine-understandable meaning and linked to knowledge graphs for further processing by the target application. these semantic annotations of recognised words can be represented as a subject-predicate-object triples which collectively form a graph often referred to as a knowledge graph. this type of knowledge representation facilitates to use speech interfaces with any spoken input application, since the information is represented in logical, semantic form, retrieving and storing can be followed using any web standard query languages. in this work, we develop a methodology for linking speech input to knowledge graphs and study the impact of recognition errors in the overall process. we show that for a corpus with lower wer, the annotation and linking of entities to the dbpedia knowledge graph is considerable. dbpedia spotlight, a tool to interlink text documents with the linked open data is used to link the speech recognition output to the dbpedia knowledge graph. such a knowledge-based speech recognition interface is useful for applications such as question answering or spoken dialog systems.",
            "contribution_ids": [
                "R69610"
            ]
        },
        {
            "instance_id": "R69680xR69604",
            "comparison_id": "R69680",
            "paper_id": "R69604",
            "text": "Learning knowledge graphs for question answering through conversational dialog we describe how a question-answering system can learn about its domain from conversational dialogs. our system learns to relate concepts in science questions to propositions in a fact corpus, stores new concepts and relations in a knowledge graph (kg), and uses the graph to solve questions. we are the first to acquire knowledge for question-answering from open, natural language dialogs without a fixed ontology or domain model that predetermines what users can say. our relation-based strategies complete more successful dialogs than a query expansion baseline, our taskdriven relations are more effective for solving science questions than relations from general knowledge sources, and our method is practical enough to generalize to other domains.",
            "contribution_ids": [
                "R69605"
            ]
        },
        {
            "instance_id": "R69680xR69648",
            "comparison_id": "R69680",
            "paper_id": "R69648",
            "text": "Knowledge engineering tools for reasoning with scientific observations and interpretations: a neural connectivity use case \" abstract \\n \\n background \\n we address the goal of curating observations from published experiments in a generalizable form; reasoning over these observations to generate interpretations and then querying this interpreted knowledge to supply the supporting evidence. we present web-application software as part of the 'bioscholar' project (r01-gm083871) that fully instantiates this process for a well-defined domain: using tract-tracing experiments to study the neural connectivity of the rat brain. \\n \\n \\n results \\n the main contribution of this work is to provide the first instantiation of a knowledge representation for experimental observations called 'knowledge engineering from experimental design' (kefed) based on experimental variables and their interdependencies. the software has three parts: (a) the kefed model editor - a design editor for creating kefed models by drawing a flow diagram of an experimental protocol; (b) the kefed data interface - a spreadsheet-like tool that permits users to enter experimental data pertaining to a specific model; (c) a 'neural connection matrix' interface that presents neural connectivity as a table of ordinal connection strengths representing the interpretations of tract-tracing data. this tool also allows the user to view experimental evidence pertaining to a specific connection. bioscholar is built in flex 3.5. it uses persevere (a nosql database) as a flexible data store and powerloom \u00ae (a mature first order logic reasoning system) to execute queries using spatial reasoning over the bams neuroanatomical ontology. \\n \\n \\n conclusions \\n we first introduce the kefed approach as a general approach and describe its possible role as a way of introducing structured reasoning into models of argumentation within new models of scientific publication. we then describe the design and implementation of our example application: the bioscholar software. this is presented as a possible biocuration interface and supplementary reasoning toolkit for a larger, more specialized bioinformatics system: the brain architecture management system (bams). \\n \"",
            "contribution_ids": [
                "R69649"
            ]
        },
        {
            "instance_id": "R69680xR69653",
            "comparison_id": "R69680",
            "paper_id": "R69653",
            "text": "Using taxonomies to facilitate the analysis of the association rules the data mining process enables the end users to analyze, understand and use the extracted knowledge in an intelligent system or to support in the decision-making processes. however, many algorithms used in the process encounter large quantities of patterns, complicating the analysis of the patterns. this fact occurs with association rules, a data mining technique that tries to identify intrinsic patterns in large data sets. a method that can help the analysis of the association rules is the use of taxonomies in the step of post-processing knowledge. in this paper, the gart algorithm is proposed, which uses taxonomies to generalize association rules, and the rulee-gar computational module, that enables the analysis of the generalized rules.",
            "contribution_ids": [
                "R69654"
            ]
        },
        {
            "instance_id": "R69680xR69657",
            "comparison_id": "R69680",
            "paper_id": "R69657",
            "text": "Knowledge-based interactive postmining of association rules using ontologies in data mining, the usefulness of association rules is strongly limited by the huge amount of delivered rules. to overcome this drawback, several methods were proposed in the literature such as itemset concise representations, redundancy reduction, and postprocessing. however, being generally based on statistical information, most of these methods do not guarantee that the extracted rules are interesting for the user. thus, it is crucial to help the decision-maker with an efficient postprocessing step in order to reduce the number of rules. this paper proposes a new interactive approach to prune and filter discovered rules. first, we propose to use ontologies in order to improve the integration of user knowledge in the postprocessing task. second, we propose the rule schema formalism extending the specification language proposed by liu et al. for user expectations. furthermore, an interactive framework is designed to assist the user throughout the analyzing task. applying our new approach over voluminous sets of rules, we were able, by integrating domain expert knowledge in the postprocessing step, to reduce the number of rules to several dozens or less. moreover, the quality of the filtered rules was validated by the domain expert at various points in the interactive process.",
            "contribution_ids": [
                "R69658"
            ]
        },
        {
            "instance_id": "R69680xR69633",
            "comparison_id": "R69680",
            "paper_id": "R69633",
            "text": "Learning heterogeneous knowledge base embeddings for explainable recommendation providing model-generated explanations in recommender systems is important to user experience. state-of-the-art recommendation algorithms\u2014especially the collaborative filtering (cf)- based approaches with shallow or deep models\u2014usually work with various unstructured information sources for recommendation, such as textual reviews, visual images, and various implicit or explicit feedbacks. though structured knowledge bases were considered in content-based approaches, they have been largely ignored recently due to the availability of vast amounts of data and the learning power of many complex models. however, structured knowledge bases exhibit unique advantages in personalized recommendation systems. when the explicit knowledge about users and items is considered for recommendation, the system could provide highly customized recommendations based on users\u2019 historical behaviors and the knowledge is helpful for providing informed explanations regarding the recommended items. a great challenge for using knowledge bases for recommendation is how to integrate large-scale structured and unstructured data, while taking advantage of collaborative filtering for highly accurate performance. recent achievements in knowledge-base embedding (kbe) sheds light on this problem, which makes it possible to learn user and item representations while preserving the structure of their relationship with external knowledge for explanation. in this work, we propose to explain knowledge-base embeddings for explainable recommendation. specifically, we propose a knowledge-base representation learning framework to embed heterogeneous entities for recommendation, and based on the embedded knowledge base, a soft matching algorithm is proposed to generate personalized explanations for the recommended items. experimental results on real-world e-commerce datasets verified the superior recommendation performance and the explainability power of our approach compared with state-of-the-art baselines.",
            "contribution_ids": [
                "R69634"
            ]
        },
        {
            "instance_id": "R69680xR69665",
            "comparison_id": "R69680",
            "paper_id": "R69665",
            "text": "Interpreting data mining results with linked data for learning analytics: motivation, case study and direction \"learning analytics by nature relies on computational information processing activities intended to extract from raw data some interesting aspects that can be used to obtain insights into the behaviours of learners, the design of learning experiences, etc. there is a large variety of computational techniques that can be employed, all with interesting properties, but it is the interpretation of their results that really forms the core of the analytics process. in this paper, we look at a specific data mining method, namely sequential pattern extraction, and we demonstrate an approach that exploits available linked open data for this interpretation task. indeed, we show through a case study relying on data about students' enrolment in course modules how linked data can be used to provide a variety of additional dimensions through which the results of the data mining method can be explored, providing, at interpretation time, new input into the analytics process.\"",
            "contribution_ids": [
                "R69666"
            ]
        },
        {
            "instance_id": "R69680xR69678",
            "comparison_id": "R69680",
            "paper_id": "R69678",
            "text": "Logical rule induction and theory learning using neural theorem proving a hallmark of human cognition is the ability to continually acquire and distill observations of the world into meaningful, predictive theories. in this paper we present a new mechanism for logical theory acquisition which takes a set of observed facts and learns to extract from them a set of logical rules and a small set of core facts which together entail the observations. our approach is neuro-symbolic in the sense that the rule pred- icates and core facts are given dense vector representations. the rules are applied to the core facts using a soft unification procedure to infer additional facts. after k steps of forward inference, the consequences are compared to the initial observations and the rules and core facts are then encouraged towards representations that more faithfully generate the observations through inference. our approach is based on a novel neural forward-chaining differentiable rule induction network. the rules are interpretable and learned compositionally from their predicates, which may be invented. we demonstrate the efficacy of our approach on a variety of ilp rule induction and domain theory learning datasets.",
            "contribution_ids": [
                "R69679"
            ]
        },
        {
            "instance_id": "R69680xR69663",
            "comparison_id": "R69680",
            "paper_id": "R69663",
            "text": "Semantic text mining with linked data linked data is an open data space that emerges from the publication and interlinking of structured data on the web using the semantic web technologies. how to utilize this wealth of data is currently a focused research theme of the semantic web community. in this paper, we aim to utilize linked data to generate semantic annotations for frequent patterns extracted from textual documents. first, we extract semantic relations from textual documents and merge them into a set of semantic graphs. then, we apply a frequent subgraph discovery algorithm on the set of graphs to generate frequent patterns. finally, we annotate the discovered patterns using linked data. our approach can be applied in such domains as terrorist network analysis and biological network analysis. the efficacy of our approach is demonstrated through an empirical experiment that discovers and validates relationships between political figures from large number of news on the web.",
            "contribution_ids": [
                "R69664"
            ]
        },
        {
            "instance_id": "R69680xR69543",
            "comparison_id": "R69680",
            "paper_id": "R69543",
            "text": "How a general-purpose common- sense ontology can improve performance of learning-based image retrieval the knowledge representation community has built general-purpose ontologies which contain large amounts of commonsense knowledge over relevant aspects of the world, including useful visual information, e.g.: \"a ball is used by a football player\", \"a tennis player is located at a tennis court\". current state-of-the-art approaches for visual recognition do not exploit these rule-based knowledge sources. instead, they learn recognition models directly from training examples. in this paper, we study how general-purpose ontologies\u2014specifically, mit\\'s conceptnet ontology\u2014can improve the performance of state-of-the-art vision systems. as a testbed, we tackle the problem of sentence-based image retrieval. our retrieval approach incorporates knowledge from conceptnet on top of a large pool of object detectors derived from a deep learning technique. in our experiments, we show that conceptnet can improve performance on a common benchmark dataset. key to our performance is the use of the espgame dataset to select visually relevant relations from conceptnet. consequently, a main conclusion of this work is that general-purpose commonsense ontologies improve performance on visual reasoning tasks when properly filtered to select meaningful visual relations.",
            "contribution_ids": [
                "R69544"
            ]
        },
        {
            "instance_id": "R69680xR69673",
            "comparison_id": "R69680",
            "paper_id": "R69673",
            "text": "Using linked data to interpret tables vast amounts of information is available in structured forms like spreadsheets, database relations, and tables found in documents and on the web. we describe an approach that uses linked data to interpret such tables and associate their components with nodes in a reference linked data collection. our proposed framework assigns a class (i.e. type) to table columns, links table cells to entities, and inferred relations between columns to properties. the resulting interpretation can be used to annotate tables, confirm existing facts in the linked data collection, and propose new facts to be added. our implemented prototype uses dbpedia as the linked data collection and wikitology for background knowledge. we evaluated its performance using a collection of tables from google squared, wikipedia and the web.",
            "contribution_ids": [
                "R69674"
            ]
        },
        {
            "instance_id": "R69680xR69635",
            "comparison_id": "R69680",
            "paper_id": "R69635",
            "text": "Knowledge-aware autoencoders for explainable recommender systems recommender systems have been widely used to help users in finding what they are looking for thus tackling the information overload problem. after several years of research and industrial findings looking after better algorithms to improve accuracy and diversity metrics, explanation services for recommendation are gaining momentum as a tool to provide a human-understandable feedback to results computed, in most of the cases, by black-box machine learning techniques. as a matter of fact, explanations may guarantee users satisfaction, trust, and loyalty in a system. in this paper, we evaluate how different information encoded in a knowledge graph are perceived by users when they are adopted to show them an explanation. more precisely, we compare how the use of categorical information, factual one or a mixture of them both in building explanations, affect explanatory criteria for a recommender system. experimental results are validated through an a/b testing platform which uses a recommendation engine based on a semantics-aware autoencoder to build users profiles which are in turn exploited to compute recommendation lists and to provide an explanation.",
            "contribution_ids": [
                "R69636"
            ]
        },
        {
            "instance_id": "R69680xR69607",
            "comparison_id": "R69680",
            "paper_id": "R69607",
            "text": "Knowledge-based conversational agents and virtual story telling we describe an architecture for building speech-enabled conversational agents, deployed as self-contained web services, with ability to provide inference processing on very large knowledge bases and its application to voice enabled chatbots in a virtual storytelling environment. the architecture integrates inference engines, natural language pattern matching components and story-specific information extraction from rdf/xml files. our web interface is dynamically generated by server side agents supporting multi-modal interface components (speech and animation). prolog refactorings of the wordnet lexical knowledge base, framenet and the open mind common sense knowledge repository are combined with internet meta-search to provide high-quality knowledge sources to our conversational agents. an example of conversational agent with speech capabilities is deployed on the web at http://logic.csci.unt.edu:8080/wordnet_agent/frame.html. the agent is also accessible for live multi-user text-based chat, through a yahoo instant messenger protocol adaptor, from wired or wireless devices, as the jinni_agent yahoo im \"handle\".",
            "contribution_ids": [
                "R69608"
            ]
        },
        {
            "instance_id": "R69680xR69587",
            "comparison_id": "R69680",
            "paper_id": "R69587",
            "text": "Answering science exam questions using query reformulation with background knowledge open-domain question answering (qa) is an important problem in ai and nlp that is emerging as a bellwether for progress on the generalizability of ai methods and techniques. much of the progress in open-domain qa systems has been realized through advances in information retrieval methods and corpus construction. in this paper, we focus on the recently introduced arc challenge dataset, which contains 2,590 multiple choice questions authored for grade-school science exams. these questions are selected to be the most challenging for current qa systems, and current state of the art performance is only slightly better than random chance. we present a system that reformulates a given question into queries that are used to retrieve supporting text from a large corpus of science-related text. our rewriter is able to incorporate background knowledge from conceptnet and -- in tandem with a generic textual entailment system trained on scitail that identifies support in the retrieved results -- outperforms several strong baselines on the end-to-end qa task despite only being trained to identify essential terms in the original source question. we use a generalizable decision methodology over the retrieved evidence and answer candidates to select the best answer. by combining query reformulation, background knowledge, and textual entailment our system is able to outperform several strong baselines on the arc dataset.",
            "contribution_ids": [
                "R69588"
            ]
        },
        {
            "instance_id": "R69680xR69637",
            "comparison_id": "R69680",
            "paper_id": "R69637",
            "text": "Improving sequential recommendation with knowledge-enhanced memory networks with the revival of neural networks, many studies try to adapt powerful sequential neural models, \u0131e recurrent neural networks (rnn), to sequential recommendation. rnn-based networks encode historical interaction records into a hidden state vector. although the state vector is able to encode sequential dependency, it still has limited representation power in capturing complicated user preference. it is difficult to capture fine-grained user preference from the interaction sequence. furthermore, the latent vector representation is usually hard to understand and explain. to address these issues, in this paper, we propose a novel knowledge enhanced sequential recommender. our model integrates the rnn-based networks with key-value memory network (kv-mn). we further incorporate knowledge base (kb) information to enhance the semantic representation of kv-mn. rnn-based models are good at capturing sequential user preference, while knowledge-enhanced kv-mns are good at capturing attribute-level user preference. by using a hybrid of rnns and kv-mns, it is expected to be endowed with both benefits from these two components. the sequential preference representation together with the attribute-level preference representation are combined as the final representation of user preference. with the incorporation of kb information, our model is also highly interpretable. to our knowledge, it is the first time that sequential recommender is integrated with external memories by leveraging large-scale kb information.",
            "contribution_ids": [
                "R69638"
            ]
        },
        {
            "instance_id": "R69680xR69562",
            "comparison_id": "R69680",
            "paper_id": "R69562",
            "text": "The more you know: Using knowledge graphs for image classification one characteristic that sets humans apart from modern learning-based computer vision algorithms is the ability to acquire knowledge about the world and use that knowledge to reason about the visual world. humans can learn about the characteristics of objects and the relationships that occur between them to learn a large variety of visual concepts, often with few examples. this paper investigates the use of structured prior knowledge in the form of knowledge graphs and shows that using this knowledge improves performance on image classification. we build on recent work on end-to-end learning on graphs, introducing the graph search neural network as a way of efficiently incorporating large knowledge graphs into a vision classification pipeline. we show in a number of experiments that our method outperforms standard neural network baselines for multi-label classification.",
            "contribution_ids": [
                "R69563"
            ]
        },
        {
            "instance_id": "R69680xR69601",
            "comparison_id": "R69680",
            "paper_id": "R69601",
            "text": "Out of the box: Reasoning with graph convolution nets for factual visual question answering \"accurately answering a question about a given image requires combining observations with general knowledge. while this is effortless for humans, reasoning with general knowledge remains an algorithmic challenge. to advance research in this direction a novel `fact-based' visual question answering (fvqa) task has been introduced recently along with a large set of curated facts which link two entities, i.e., two possible answers, via a relation. given a question-image pair, deep network techniques have been employed to successively reduce the large set of facts until one of the two entities of the final remaining fact is predicted as the answer. we observe that a successive process which considers one fact at a time to form a local decision is sub-optimal. instead, we develop an entity graph and use a graph convolutional network to `reason' about the correct answer by jointly considering all entities. we show on the challenging fvqa dataset that this leads to an improvement in accuracy of around 7% compared to the state of the art.\"",
            "contribution_ids": [
                "R69602"
            ]
        },
        {
            "instance_id": "R69680xR69621",
            "comparison_id": "R69680",
            "paper_id": "R69621",
            "text": "Interaction Embeddings for Prediction and Explanation in Knowledge Graphs \"knowledge graph embedding aims to learn distributed representations for entities and relations, and is proven to be effective in many applications. crossover interactions -- bi-directional effects between entities and relations --- help select related information when predicting a new triple, but haven't been formally discussed before. in this paper, we propose crosse, a novel knowledge graph embedding which explicitly simulates crossover interactions. it not only learns one general embedding for each entity and relation as most previous methods do, but also generates multiple triple specific embeddings for both of them, named interaction embeddings. we evaluate embeddings on typical link prediction tasks and find that crosse achieves state-of-the-art results on complex and more challenging datasets. furthermore, we evaluate embeddings from a new perspective -- giving explanations for predicted triples, which is important for real applications. in this work, an explanation for a triple is regarded as a reliable closed-path between the head and the tail entity. compared to other baselines, we show experimentally that crosse, benefiting from interaction embeddings, is more capable of generating reliable explanations to support its predictions.\"",
            "contribution_ids": [
                "R69622"
            ]
        },
        {
            "instance_id": "R69680xR69611",
            "comparison_id": "R69680",
            "paper_id": "R69611",
            "text": "Algorithmic transparency of conversational agents a lack of algorithmic transparency is a major barrier to the adoption of artificial intelligence technologies within contexts which require high risk and high consequence decision making. in this paper we present a framework for providing transparency of algorithmic processes. we include important considerations not identified in research to date for the high risk and high consequence context of defence intelligence analysis. to demonstrate the core concepts of our framework we explore an example application (a conversational agent for knowledge exploration) which demonstrates shared human-machine reasoning in a critical decision making scenario. we include new findings from interviews with a small number of analysts and recommendations for future \\nresearch.",
            "contribution_ids": [
                "R69612"
            ]
        },
        {
            "instance_id": "R69680xR69560",
            "comparison_id": "R69680",
            "paper_id": "R69560",
            "text": "A symbolic approach for explaining errors in image classification tasks machine learning algorithms, despite their increasing success in handling object recognition tasks, still seldom perform without error. often the process of understanding why the algorithm has fail ...",
            "contribution_ids": [
                "R69561"
            ]
        },
        {
            "instance_id": "R69680xR69667",
            "comparison_id": "R69680",
            "paper_id": "R69667",
            "text": "Linked data and online classifications to organise mined patterns in patient data in this paper, we investigate the use of web data resources in medicine, especially through medical classifications made available using the principles of linked data, to support the interpretation of patterns mined from patient care trajectories. interpreting such patterns is naturally a challenge for an analyst, as it requires going through large amounts of results and access to sufficient background knowledge. we employ linked data, especially as exposed through the bioportal system, to create a navigation structure within the patterns obtained form sequential pattern mining. we show how this approach provides a flexible way to explore data about trajectories of diagnoses and treatments according to different medical classifications.",
            "contribution_ids": [
                "R69668"
            ]
        },
        {
            "instance_id": "R69680xR69597",
            "comparison_id": "R69680",
            "paper_id": "R69597",
            "text": "Fvqa: Fact-based visual question answering visual question answering (vqa) has attracted much attention in both computer vision and natural language processing communities, not least because it offers insight into the relationships between two important sources of information. current datasets, and the models built upon them, have focused on questions which are answerable by direct analysis of the question and image alone. the set of such questions that require no external information to answer is interesting, but very limited. it excludes questions which require common sense, or basic factual knowledge to answer, for example. here we introduce fvqa (fact-based vqa), a vqa dataset which requires, and supports, much deeper reasoning. fvqa primarily contains questions that require external information to answer. we thus extend a conventional visual question answering dataset, which contains image-question-answer triplets, through additional image-question-answer-supporting fact tuples. each supporting-fact is represented as a structural triplet, such as . we evaluate several baseline models on the fvqa dataset, and describe a novel model which is capable of reasoning about an image on the basis of supporting-facts.",
            "contribution_ids": [
                "R69598"
            ]
        },
        {
            "instance_id": "R69680xR69572",
            "comparison_id": "R69680",
            "paper_id": "R69572",
            "text": "Linking imagenet-wordnet synsets with wikidata the linkage of imagenet wordnet synsets to wikidata items will leverage deep learning algorithm with access to a rich multilingual knowledge graph. here i will describe our on-going efforts in linking the two resources and issues faced in matching the wikidata and wordnet knowledge graphs. i show an example on how the linkage can be used in a deep learning setting with real-time image classification and labeling in a non-english language and discuss what opportunities lies ahead.",
            "contribution_ids": [
                "R69573"
            ]
        },
        {
            "instance_id": "R70287xR70021",
            "comparison_id": "R70287",
            "paper_id": "R70021",
            "text": "Discovery, Synthesis, And Structure-Based Optimization of a Series ofN-(tert-Butyl)-2-(N-arylamido)-2-(pyridin-3-yl) Acetamides (ML188) as Potent Noncovalent Small Molecule Inhibitors of the Severe Acute Respiratory Syndrome Coronavirus (SARS-CoV) 3CL Protease \"a high-throughput screen of the nih molecular libraries sample collection and subsequent optimization of a lead dipeptide-like series of severe acute respiratory syndrome (sars) main protease (3clpro) inhibitors led to the identification of probe compound ml188 (16-(r), (r)-n-(4-(tert-butyl)phenyl)-n-(2-(tert-butylamino)-2-oxo-1-(pyridin-3-yl)ethyl)furan-2-carboxamide, pubchem cid: 46897844). unlike the majority of reported coronavirus 3clpro inhibitors that act via covalent modification of the enzyme, 16-(r) is a noncovalent sars-cov 3clpro inhibitor with moderate mw and good enzyme and antiviral inhibitory activity. a multicomponent ugi reaction was utilized to rapidly explore structure-activity relationships within s(1'), s(1), and s(2) enzyme binding pockets. the x-ray structure of sars-cov 3clpro bound with 16-(r) was instrumental in guiding subsequent rounds of chemistry optimization. 16-(r) provides an excellent starting point for the further design and refinement of 3clpro inhibitors that act by a noncovalent mechanism of action.\"",
            "contribution_ids": [
                "R70022",
                "R70040"
            ]
        },
        {
            "instance_id": "R70287xR51373",
            "comparison_id": "R70287",
            "paper_id": "R51373",
            "text": "Identification of antiviral drug candidates against SARS-CoV-2 from FDA-approved drugs abstract covid-19 is an emerging infectious disease and was recently declared as a pandemic by who. currently, there is no vaccine or therapeutic available for this disease. drug repositioning represents the only feasible option to address this global challenge and a panel of 48 fda-approved drugs that have been pre-selected by an assay of sars-cov was screened to identify potential antiviral drug candidates against sars-cov-2 infection. we found a total of 24 drugs which exhibited antiviral efficacy (0.1 \u03bcm &lt; ic 50 &lt; 10 \u03bcm) against sars-cov-2. in particular, two fda-approved drugs - niclosamide and ciclesonide \u2013 were notable in some respects. these drugs will be tested in an appropriate animal model for their antiviral activities. in near future, these already fda-approved drugs could be further developed following clinical trials in order to provide additional therapeutic options for patients with covid-19.",
            "contribution_ids": [
                "R51374",
                "R51399"
            ]
        },
        {
            "instance_id": "R70287xR51252",
            "comparison_id": "R70287",
            "paper_id": "R51252",
            "text": "Identification of inhibitors of SARS-CoV-2 in-vitro cellular toxicity in human (Caco-2) cells using a large scale drug repurposing collection abstract \\n to identify possible candidates for progression towards clinical studies against sars-cov-2, we screened a well-defined collection of 5632 compounds including 3488 compounds which have undergone clinical investigations (marketed drugs, phases 1 -3, and withdrawn) across 600 indications. compounds were screened for their inhibition of viral induced cytotoxicity using the human epithelial colorectal adenocarcinoma cell line caco-2 and a sars-cov-2 isolate. the primary screen of 5632 compounds gave 271 hits. a total of 64 compounds with ic50 &lt;20 \u00b5m were identified, including 19 compounds with ic50 &lt; 1 \u00b5m. of this confirmed hit population, 90% have not yet been previously reported as active against sars-cov-2 in-vitro cell assays. some 37 of the actives are launched drugs, 19 are in phases 1-3 and 10 pre-clinical. several inhibitors were associated with modulation of host pathways including kinase signaling p53 activation, ubiquitin pathways and pde activity modulation, with long chain acyl transferases were effective viral inhibitors.",
            "contribution_ids": [
                "R51254"
            ]
        },
        {
            "instance_id": "R70287xR70068",
            "comparison_id": "R70287",
            "paper_id": "R70068",
            "text": "Identification of potential treatments for COVID-19 through artificial intelligence-enabled phenomic analysis of human cells infected with SARS-CoV-2 abstract to identify potential therapeutic stop-gaps for sars-cov-2, we evaluated a library of 1,670 approved and reference compounds in an unbiased, cellular image-based screen for their ability to suppress the broad impacts of the sars-cov-2 virus on phenomic profiles of human renal cortical epithelial cells using deep learning. in our assay, remdesivir is the only antiviral tested with strong efficacy, neither chloroquine nor hydroxychloroquine have any beneficial effect in this human cell model, and a small number of compounds not currently being pursued clinically for sars-cov-2 have efficacy. we observed weak but beneficial class effects of \u03b2-blockers, mtor/pi3k inhibitors and vitamin d analogues and a mild amplification of the viral phenotype with \u03b2-agonists.",
            "contribution_ids": [
                "R70069"
            ]
        },
        {
            "instance_id": "R70287xR70125",
            "comparison_id": "R70287",
            "paper_id": "R70125",
            "text": "Structure-Based Design, Synthesis, and Biological Evaluation of a Series of Novel and Reversible Inhibitors for the Severe Acute Respiratory Syndrome\u00e2\u0088\u0092Coronavirus Papain-Like Protease we describe here the design, synthesis, molecular modeling, and biological evaluation of a series of small molecule, nonpeptide inhibitors of sars-cov plpro. our initial lead compound was identified via high-throughput screening of a diverse chemical library. we subsequently carried out structure-activity relationship studies and optimized the lead structure to potent inhibitors that have shown antiviral activity against sars-cov infected vero e6 cells. upon the basis of the x-ray crystal structure of inhibitor 24-bound to sars-cov plpro, a drug design template was created. our structure-based modification led to the design of a more potent inhibitor, 2 (enzyme ic(50) = 0.46 microm; antiviral ec(50) = 6 microm). interestingly, its methylamine derivative, 49, displayed good enzyme inhibitory potency (ic(50) = 1.3 microm) and the most potent sars antiviral activity (ec(50) = 5.2 microm) in the series. we have carried out computational docking studies and generated a predictive 3d-qsar model for sars-cov plpro inhibitors.",
            "contribution_ids": [
                "R70126"
            ]
        },
        {
            "instance_id": "R70584xR70546",
            "comparison_id": "R70584",
            "paper_id": "R70546",
            "text": "Machine Learning Models for Analysis of Vital Signs Dynamics: A Case for Sepsis Onset Prediction objective . achieving accurate prediction of sepsis detection moment based on bedside monitor data in the intensive care unit (icu). a good clinical outcome is more probable when onset is suspected and treated on time, thus early insight of sepsis onset may save lives and reduce costs. methodology . we present a novel approach for feature extraction, which focuses on the hypothesis that unstable patients are more prone to develop sepsis during icu stay. these features are used in machine learning algorithms to provide a prediction of a patient\u2019s likelihood to develop sepsis during icu stay, hours before it is diagnosed. results . five machine learning algorithms were implemented using r software packages. the algorithms were trained and tested with a set of 4 features which represent the variability in vital signs. these algorithms aimed to calculate a patient\u2019s probability to become septic within the next 4 hours, based on recordings from the last 8 hours. the best area under the curve (auc) was achieved with support vector machine (svm) with radial basis function, which was 88.38%. conclusions . the high level of predictive accuracy along with the simplicity and availability of input variables present great potential if applied in icus. variability of a patient\u2019s vital signs proves to be a good indicator of one\u2019s chance to become septic during icu stay.",
            "contribution_ids": [
                "R70547",
                "R70573"
            ]
        },
        {
            "instance_id": "R70584xR70556",
            "comparison_id": "R70584",
            "paper_id": "R70556",
            "text": "Detecting pathogen exposure during the non-symptomatic incubation period using physiological data abstract early pathogen exposure detection allows better patient care and faster implementation of public health measures (patient isolation, contact tracing). existing exposure detection most frequently relies on overt clinical symptoms, namely fever, during the infectious prodromal period. we have developed a robust machine learning based method to better detect asymptomatic states during the incubation period using subtle, sub-clinical physiological markers. starting with high-resolution physiological waveform data from non-human primate studies of viral (ebola, marburg, lassa, and nipah viruses) and bacterial ( y. pestis ) exposure, we processed the data to reduce short-term variability and normalize diurnal variations, then provided these to a supervised random forest classification algorithm and post-classifier declaration logic step to reduce false alarms. in most subjects detection is achieved well before the onset of fever; subject cross-validation across exposure studies (varying viruses, exposure routes, animal species, and target dose) lead to 51h mean early detection (at 0.93 area under the receiver-operating characteristic curve [aucroc]). evaluating the algorithm against entirely independent datasets for lassa, nipah, and y. pestis exposures un-used in algorithm training and development yields a mean 51h early warning time (at aucroc=0.95). we discuss which physiological indicators are most informative for early detection and options for extending this capability to limited datasets such as those available from wearable, non-invasive, ecg-based sensors.",
            "contribution_ids": [
                "R70557",
                "R70578"
            ]
        },
        {
            "instance_id": "R70584xR70560",
            "comparison_id": "R70584",
            "paper_id": "R70560",
            "text": "Physiological monitoring for critically ill patients: testing a predictive model for the early detection of sepsis \u2022 objective to assess the predictive value for the early detection of sepsis of the physiological monitoring parameters currently recommended by the surviving sepsis campaign. \u2022 methods the project impact data set was used to assess whether the physiological parameters of heart rate, mean arterial pressure, body temperature, and respiratory rate can be used to distinguish between critically ill adult patients with and without sepsis in the first 24 hours of admission to an intensive care unit. \u2022 results all predictor variables used in the analyses differed significantly between patients with sepsis and patients without sepsis. however, only 2 of the predictor variables, mean arterial pressure and high temperature, were independently associated with sepsis. in addition, the temperature mean for hypothermia was significantly lower in patients without sepsis. the odds ratio for having sepsis was 2.126 for patients with a temperature of 38\u00b0c or higher, 3.874 for patients with a mean arterial blood pressure of less than 70 mm hg, and 4.63 times greater for patients who had both of these conditions. \u2022 conclusions the results support the use of some of the guidelines of the surviving sepsis campaign. however, the lowest mean temperature was significantly less for patients without sepsis than for patients with sepsis, a finding that calls into question the clinical usefulness of using hypothermia as an early predictor of sepsis. alone the group of variables used is not sufficient for discriminating between critically ill patients with and without sepsis.",
            "contribution_ids": [
                "R70561",
                "R70580"
            ]
        },
        {
            "instance_id": "R70584xR70548",
            "comparison_id": "R70584",
            "paper_id": "R70548",
            "text": "Machine-Learning-Based Laboratory Developed Test for the Diagnosis of Sepsis in High-Risk Patients sepsis, a dysregulated host response to infection, is a major health burden in terms of both mortality and cost. the difficulties clinicians face in diagnosing sepsis, alongside the insufficiencies of diagnostic biomarkers, motivate the present study. this work develops a machine-learning-based sepsis diagnostic for a high-risk patient group, using a geographically and institutionally diverse collection of nearly 500,000 patient health records. using only a minimal set of clinical variables, our diagnostics outperform common severity scoring systems and sepsis biomarkers and benefit from being available immediately upon ordering.",
            "contribution_ids": [
                "R70549",
                "R70574"
            ]
        },
        {
            "instance_id": "R70584xR70562",
            "comparison_id": "R70584",
            "paper_id": "R70562",
            "text": "Predictive models for severe sepsis in adult ICU patients intensive care unit (icu) patients have significant morbidity and mortality, often from complications that arise during the hospital stay. severe sepsis is one of the leading causes of death among these patients. predictive models have the potential to allow for earlier detection of severe sepsis and ultimately earlier intervention. however, current methods for identifying and predicting severe sepsis are biased and inadequate. the goal of this work is to identify a new framework for the prediction of severe sepsis and identify early predictors utilizing clinical laboratory values and vital signs collected in adult icu patients. we explore models with logistic regression (lr), support vector machines (svm), and logistic model trees (lmt) utilizing vital signs, laboratory values, or a combination of vital and laboratory values. when applied to a retrospective cohort of icu patients, the svm model using laboratory and vital signs as predictors identified 339 (65%) of the 3,446 patients as developing severe sepsis correctly. based on this new framework and developed models, we provide a recommendation for the use in clinical decision support in icu and non-icu environments.",
            "contribution_ids": [
                "R70563",
                "R70581"
            ]
        },
        {
            "instance_id": "R70605xR70595",
            "comparison_id": "R70605",
            "paper_id": "R70595",
            "text": "A Generalizable, Data-Driven Approach to Predict Daily Risk of Clostridium difficile Infection at Two Large Academic Health Centers objective an estimated 293,300 healthcare-associated cases of clostridium difficile infection (cdi) occur annually in the united states. to date, research has focused on developing risk prediction models for cdi that work well across institutions. however, this one-size-fits-all approach ignores important hospital-specific factors. we focus on a generalizable method for building facility-specific models. we demonstrate the applicability of the approach using electronic health records (ehr) from the university of michigan hospitals (um) and the massachusetts general hospital (mgh). methods we utilized ehr data from 191,014 adult admissions to um and 65,718 adult admissions to mgh. we extracted patient demographics, admission details, patient history, and daily hospitalization details, resulting in 4,836 features from patients at um and 1,837 from patients at mgh. we used l2 regularized logistic regression to learn the models, and we measured the discriminative performance of the models on held-out data from each hospital. results using the um and mgh test data, the models achieved area under the receiver operating characteristic curve (auroc) values of 0.82 (95% confidence interval [ci], 0.80\u20130.84) and 0.75 ( 95% ci, 0.73\u20130.78), respectively. some predictive factors were shared between the 2 models, but many of the top predictive factors differed between facilities. conclusion a data-driven approach to building models for estimating daily patient risk for cdi was used to build institution-specific models at 2 large hospitals with different patient populations and ehr systems. in contrast to traditional approaches that focus on developing models that apply across hospitals, our generalizable approach yields risk-stratification models tailored to an institution. these hospital-specific models allow for earlier and more accurate identification of high-risk patients and better targeting of infection prevention strategies. infect control hosp epidemiol 2018;39:425\u2013433",
            "contribution_ids": [
                "R70596"
            ]
        },
        {
            "instance_id": "R70605xR70593",
            "comparison_id": "R70605",
            "paper_id": "R70593",
            "text": "A Multi-Center Prospective Derivation and Validation of a Clinical Prediction Tool for Severe Clostridium difficile Infection background and aims prediction of severe clinical outcomes in clostridium difficile infection (cdi) is important to inform management decisions for optimum patient care. currently, treatment recommendations for cdi vary based on disease severity but validated methods to predict severe disease are lacking. the aim of the study was to derive and validate a clinical prediction tool for severe outcomes in cdi. methods a cohort totaling 638 patients with cdi was prospectively studied at three tertiary care clinical sites (boston, dublin and houston). the clinical prediction rule (cpr) was developed by multivariate logistic regression analysis using the boston cohort and the performance of this model was then evaluated in the combined houston and dublin cohorts. results the cpr included the following three binary variables: age \u2265 65 years, peak serum creatinine \u22652 mg/dl and peak peripheral blood leukocyte count of \u226520,000 cells/\u03bcl. the clostridium difficile severity score (cdss) correctly classified 76.5% (95% ci: 70.87-81.31) and 72.5% (95% ci: 67.52-76.91) of patients in the derivation and validation cohorts, respectively. in the validation cohort, cdss scores of 0, 1, 2 or 3 were associated with severe clinical outcomes of cdi in 4.7%, 13.8%, 33.3% and 40.0% of cases respectively. conclusions we prospectively derived and validated a clinical prediction rule for severe cdi that is simple, reliable and accurate and can be used to identify high-risk patients most likely to benefit from measures to prevent complications of cdi.",
            "contribution_ids": [
                "R70594"
            ]
        },
        {
            "instance_id": "R70605xR70585",
            "comparison_id": "R70605",
            "paper_id": "R70585",
            "text": "Development and validation of a Clostridium difficile infection risk prediction model \"objective. to develop and validate a risk prediction model that could identify patients at high risk for clostridium difficile infection (cdi) before they develop disease. design and setting. retrospective cohort study in a tertiary care medical center. patients. patients admitted to the hospital for at least 48 hours during the calendar year 2003. methods. data were collected electronically from the hospital's medical informatics database and analyzed with logistic regression to determine variables that best predicted patients' risk for development of cdi. model discrimination and calibration were calculated. the model was bootstrapped 500 times to validate the predictive accuracy. a receiver operating characteristic curve was calculated to evaluate potential risk cutoffs. results. a total of 35,350 admitted patients, including 329 with cdi, were studied. variables in the risk prediction model were age, cdi pressure, times admitted to hospital in the previous 60 days, modified acute physiology score, days of treatment with high-risk antibiotics, whether albumin level was low, admission to an intensive care unit, and receipt of laxatives, gastric acid suppressors, or antimotility drugs. the calibration and discrimination of the model were very good to excellent (c index, 0.88; brier score, 0.009). conclusions. the cdi risk prediction model performed well. further study is needed to determine whether it could be used in a clinical setting to prevent cdi-associated outcomes and reduce costs.\"",
            "contribution_ids": [
                "R70586"
            ]
        },
        {
            "instance_id": "R70605xR70587",
            "comparison_id": "R70605",
            "paper_id": "R70587",
            "text": "Prediction of Recurrent Clostridium Difficile Infection Using Comprehensive Electronic Medical Records in an Integrated Healthcare Delivery System background predicting recurrent clostridium difficile infection (rcdi) remains difficult. methods. we employed a retrospective cohort design. granular electronic medical record (emr) data had been collected from patients hospitalized at 21 kaiser permanente northern california hospitals. the derivation dataset (2007\u20132013) included data from 9,386 patients who experienced incident cdi (icdi) and 1,311 who experienced their first cdi recurrences (rcdi). the validation dataset (2014) included data from 1,865 patients who experienced incident cdi and 144 who experienced rcdi. using multiple techniques, including machine learning, we evaluated more than 150 potential predictors. our final analyses evaluated 3 models with varying degrees of complexity and 1 previously published model. results despite having a large multicenter cohort and access to granular emr data (eg, vital signs, and laboratory test results), none of the models discriminated well (c statistics, 0.591\u20130.605), had good calibration, or had good explanatory power. conclusions our ability to predict rcdi remains limited. given currently available emr technology, improvements in prediction will require incorporating new variables because currently available data elements lack adequate explanatory power. infect control hosp epidemiol 2017;38:1196\u20131203",
            "contribution_ids": [
                "R70588"
            ]
        },
        {
            "instance_id": "R70630xR70614",
            "comparison_id": "R70630",
            "paper_id": "R70614",
            "text": "Maximizing Interpretability and Cost-Effectiveness of Surgical Site Infection (SSI) Predictive Models Using Feature-Specific Regularized Logistic Regression on Preoperative Temporal Data this study describes a novel approach to solve the surgical site infection (ssi) classification problem. feature engineering has traditionally been one of the most important steps in solving complex classification problems, especially in cases with temporal data. the described novel approach is based on abstraction of temporal data recorded in three temporal windows. maximum likelihood l1-norm (lasso) regularization was used in penalized logistic regression to predict the onset of surgical site infection occurrence based on available patient blood testing results up to the day of surgery. prior knowledge of predictors (blood tests) was integrated in the modelling by introduction of penalty factors depending on blood test prices and an early stopping parameter limiting the maximum number of selected features used in predictive modelling. finally, solutions resulting in higher interpretability and cost-effectiveness were demonstrated. using repeated holdout cross-validation, the baseline c-reactive protein (crp) classifier achieved a mean auc of 0.801, whereas our best full lasso model achieved a mean auc of 0.956. best model testing results were achieved for full lasso model with maximum number of features limited at 20 features with an auc of 0.967. presented models showed the potential to not only support domain experts in their decision making but could also prove invaluable for improvement in prediction of ssi occurrence, which may even help setting new guidelines in the field of preoperative ssi prevention and surveillance.",
            "contribution_ids": [
                "R70615"
            ]
        },
        {
            "instance_id": "R70630xR70624",
            "comparison_id": "R70630",
            "paper_id": "R70624",
            "text": "Predictive Modeling of Surgical Site Infections Using Sparse Laboratory Data as part of a data mining competition, a training and test set of laboratory test data about patients with and without surgical site infection (ssi) were provided. the task was to develop predictive models with training set and identify patients with ssi in the no label test set. lab test results are vital resources that guide healthcare providers make decisions about all aspects of surgical patient management. many machine learning models were developed after pre-processing and imputing the lab tests data and only the top performing methods are discussed. overall, random forest algorithms performed better than support vector machine and logistic regression. using a set of 74 lab tests, with rf, there were only 4 false positives in the training set and predicted 35 out of 50 ssi patients in the test set (accuracy 0.86, sensitivity 0.68, and specificity 0.91). optimal ways to address healthcare data quality concerns and imputation methods as well as newer generalizable algorithms need to be explored further to decipher new associations and knowledge among laboratory biomarkers and ssi.",
            "contribution_ids": [
                "R70625"
            ]
        },
        {
            "instance_id": "R70630xR70608",
            "comparison_id": "R70630",
            "paper_id": "R70608",
            "text": "Automated Detection of Postoperative Surgical Site Infections Using Supervised Methods with Electronic Health Record Data the national surgical quality improvement project (nsqip) is widely recognized as \u201cthe best in the nation\u201d surgical quality improvement resource in the united states. in particular, it rigorously defines postoperative morbidity outcomes, including surgical adverse events occurring within 30 days of surgery. due to its manual yet expensive construction process, the nsqip registry is of exceptionally high quality, but its high cost remains a significant bottleneck to nsqip\u2019s wider dissemination. in this work, we propose an automated surgical adverse events detection tool, aimed at accelerating the process of extracting postoperative outcomes from medical charts. as a prototype system, we combined local ehr data with the nsqip gold standard outcomes and developed machine learned models to retrospectively detect surgical site infections (ssi), a particular family of adverse events that nsqip extracts. the built models have high specificity (from 0.788 to 0.988) as well as very high negative predictive values (>0.98), reliably eliminating the vast majority of patients without ssi, thereby significantly reducing the nsqip extractors\u2019 burden.",
            "contribution_ids": [
                "R70609"
            ]
        },
        {
            "instance_id": "R70630xR70626",
            "comparison_id": "R70630",
            "paper_id": "R70626",
            "text": "Data-driven Temporal Prediction of Surgical Site Infection analysis of data from electronic health records (ehr) presents unique challenges, in particular regarding nonuniform temporal resolution of longitudinal variables. a considerable amount of patient information is available in the ehr - including blood tests that are performed routinely during inpatient follow-up. these data are useful for the design of advanced machine learning-based methods and prediction models. using a matched cohort of patients undergoing gastrointestinal surgery (101 cases and 904 controls), we built a prediction model for post-operative surgical site infections (ssis) using gaussian process (gp) regression, time warping and imputation methods to manage the sparsity of the data source, and support vector machines for classification. for most blood tests, wider confidence intervals after imputation were obtained in patients with ssi. predictive performance with individual blood tests was maintained or improved by joint model prediction, and non-linear classifiers performed consistently better than linear models.",
            "contribution_ids": [
                "R70627"
            ]
        },
        {
            "instance_id": "R70630xR70618",
            "comparison_id": "R70630",
            "paper_id": "R70618",
            "text": "A diagnostic algorithm for the surveillance of deep surgical site infections after colorectal surgery abstract objective: surveillance of surgical site infections (ssis) is important for infection control and is usually performed through retrospective manual chart review. the aim of this study was to develop an algorithm for the surveillance of deep ssis based on clinical variables to enhance efficiency of surveillance. design: retrospective cohort study (2012\u20132015). setting: a dutch teaching hospital. participants: we included all consecutive patients who underwent colorectal surgery excluding those with contaminated wounds at the time of surgery. all patients were evaluated for deep ssis through manual chart review, using the centers for disease control and prevention (cdc) criteria as the reference standard. analysis: we used logistic regression modeling to identify predictors that contributed to the estimation of diagnostic probability. bootstrapping was applied to increase generalizability, followed by assessment of statistical performance and clinical implications. results: in total, 1,606 patients were included, of whom 129 (8.0%) acquired a deep ssi. the final model included postoperative length of stay, wound class, readmission, reoperation, and 30-day mortality. the model achieved 68.7% specificity and 98.5% sensitivity and an area under the receiver operator characteristic (roc) curve (auc) of 0.950 (95% ci, 0.932\u20130.969). positive and negative predictive values were 21.5% and 99.8%, respectively. applying the algorithm resulted in a 63.4% reduction in the number of records requiring full manual review (from 1,606 to 590). conclusions: this 5-parameter model identified 98.5% of patients with a deep ssi. the model can be used to develop semiautomatic surveillance of deep ssis after colorectal surgery, which may further improve efficiency and quality of ssi surveillance.",
            "contribution_ids": [
                "R70619"
            ]
        },
        {
            "instance_id": "R70632xR70585",
            "comparison_id": "R70632",
            "paper_id": "R70585",
            "text": "Development and validation of a Clostridium difficile infection risk prediction model \"objective. to develop and validate a risk prediction model that could identify patients at high risk for clostridium difficile infection (cdi) before they develop disease. design and setting. retrospective cohort study in a tertiary care medical center. patients. patients admitted to the hospital for at least 48 hours during the calendar year 2003. methods. data were collected electronically from the hospital's medical informatics database and analyzed with logistic regression to determine variables that best predicted patients' risk for development of cdi. model discrimination and calibration were calculated. the model was bootstrapped 500 times to validate the predictive accuracy. a receiver operating characteristic curve was calculated to evaluate potential risk cutoffs. results. a total of 35,350 admitted patients, including 329 with cdi, were studied. variables in the risk prediction model were age, cdi pressure, times admitted to hospital in the previous 60 days, modified acute physiology score, days of treatment with high-risk antibiotics, whether albumin level was low, admission to an intensive care unit, and receipt of laxatives, gastric acid suppressors, or antimotility drugs. the calibration and discrimination of the model were very good to excellent (c index, 0.88; brier score, 0.009). conclusions. the cdi risk prediction model performed well. further study is needed to determine whether it could be used in a clinical setting to prevent cdi-associated outcomes and reduce costs.\"",
            "contribution_ids": [
                "R70586"
            ]
        },
        {
            "instance_id": "R70632xR70595",
            "comparison_id": "R70632",
            "paper_id": "R70595",
            "text": "A Generalizable, Data-Driven Approach to Predict Daily Risk of Clostridium difficile Infection at Two Large Academic Health Centers objective an estimated 293,300 healthcare-associated cases of clostridium difficile infection (cdi) occur annually in the united states. to date, research has focused on developing risk prediction models for cdi that work well across institutions. however, this one-size-fits-all approach ignores important hospital-specific factors. we focus on a generalizable method for building facility-specific models. we demonstrate the applicability of the approach using electronic health records (ehr) from the university of michigan hospitals (um) and the massachusetts general hospital (mgh). methods we utilized ehr data from 191,014 adult admissions to um and 65,718 adult admissions to mgh. we extracted patient demographics, admission details, patient history, and daily hospitalization details, resulting in 4,836 features from patients at um and 1,837 from patients at mgh. we used l2 regularized logistic regression to learn the models, and we measured the discriminative performance of the models on held-out data from each hospital. results using the um and mgh test data, the models achieved area under the receiver operating characteristic curve (auroc) values of 0.82 (95% confidence interval [ci], 0.80\u20130.84) and 0.75 ( 95% ci, 0.73\u20130.78), respectively. some predictive factors were shared between the 2 models, but many of the top predictive factors differed between facilities. conclusion a data-driven approach to building models for estimating daily patient risk for cdi was used to build institution-specific models at 2 large hospitals with different patient populations and ehr systems. in contrast to traditional approaches that focus on developing models that apply across hospitals, our generalizable approach yields risk-stratification models tailored to an institution. these hospital-specific models allow for earlier and more accurate identification of high-risk patients and better targeting of infection prevention strategies. infect control hosp epidemiol 2018;39:425\u2013433",
            "contribution_ids": [
                "R70596"
            ]
        },
        {
            "instance_id": "R70632xR70587",
            "comparison_id": "R70632",
            "paper_id": "R70587",
            "text": "Prediction of Recurrent Clostridium Difficile Infection Using Comprehensive Electronic Medical Records in an Integrated Healthcare Delivery System background predicting recurrent clostridium difficile infection (rcdi) remains difficult. methods. we employed a retrospective cohort design. granular electronic medical record (emr) data had been collected from patients hospitalized at 21 kaiser permanente northern california hospitals. the derivation dataset (2007\u20132013) included data from 9,386 patients who experienced incident cdi (icdi) and 1,311 who experienced their first cdi recurrences (rcdi). the validation dataset (2014) included data from 1,865 patients who experienced incident cdi and 144 who experienced rcdi. using multiple techniques, including machine learning, we evaluated more than 150 potential predictors. our final analyses evaluated 3 models with varying degrees of complexity and 1 previously published model. results despite having a large multicenter cohort and access to granular emr data (eg, vital signs, and laboratory test results), none of the models discriminated well (c statistics, 0.591\u20130.605), had good calibration, or had good explanatory power. conclusions our ability to predict rcdi remains limited. given currently available emr technology, improvements in prediction will require incorporating new variables because currently available data elements lack adequate explanatory power. infect control hosp epidemiol 2017;38:1196\u20131203",
            "contribution_ids": [
                "R70588"
            ]
        },
        {
            "instance_id": "R70632xR70593",
            "comparison_id": "R70632",
            "paper_id": "R70593",
            "text": "A Multi-Center Prospective Derivation and Validation of a Clinical Prediction Tool for Severe Clostridium difficile Infection background and aims prediction of severe clinical outcomes in clostridium difficile infection (cdi) is important to inform management decisions for optimum patient care. currently, treatment recommendations for cdi vary based on disease severity but validated methods to predict severe disease are lacking. the aim of the study was to derive and validate a clinical prediction tool for severe outcomes in cdi. methods a cohort totaling 638 patients with cdi was prospectively studied at three tertiary care clinical sites (boston, dublin and houston). the clinical prediction rule (cpr) was developed by multivariate logistic regression analysis using the boston cohort and the performance of this model was then evaluated in the combined houston and dublin cohorts. results the cpr included the following three binary variables: age \u2265 65 years, peak serum creatinine \u22652 mg/dl and peak peripheral blood leukocyte count of \u226520,000 cells/\u03bcl. the clostridium difficile severity score (cdss) correctly classified 76.5% (95% ci: 70.87-81.31) and 72.5% (95% ci: 67.52-76.91) of patients in the derivation and validation cohorts, respectively. in the validation cohort, cdss scores of 0, 1, 2 or 3 were associated with severe clinical outcomes of cdi in 4.7%, 13.8%, 33.3% and 40.0% of cases respectively. conclusions we prospectively derived and validated a clinical prediction rule for severe cdi that is simple, reliable and accurate and can be used to identify high-risk patients most likely to benefit from measures to prevent complications of cdi.",
            "contribution_ids": [
                "R70594"
            ]
        },
        {
            "instance_id": "R70633xR70595",
            "comparison_id": "R70633",
            "paper_id": "R70595",
            "text": "A Generalizable, Data-Driven Approach to Predict Daily Risk of Clostridium difficile Infection at Two Large Academic Health Centers objective an estimated 293,300 healthcare-associated cases of clostridium difficile infection (cdi) occur annually in the united states. to date, research has focused on developing risk prediction models for cdi that work well across institutions. however, this one-size-fits-all approach ignores important hospital-specific factors. we focus on a generalizable method for building facility-specific models. we demonstrate the applicability of the approach using electronic health records (ehr) from the university of michigan hospitals (um) and the massachusetts general hospital (mgh). methods we utilized ehr data from 191,014 adult admissions to um and 65,718 adult admissions to mgh. we extracted patient demographics, admission details, patient history, and daily hospitalization details, resulting in 4,836 features from patients at um and 1,837 from patients at mgh. we used l2 regularized logistic regression to learn the models, and we measured the discriminative performance of the models on held-out data from each hospital. results using the um and mgh test data, the models achieved area under the receiver operating characteristic curve (auroc) values of 0.82 (95% confidence interval [ci], 0.80\u20130.84) and 0.75 ( 95% ci, 0.73\u20130.78), respectively. some predictive factors were shared between the 2 models, but many of the top predictive factors differed between facilities. conclusion a data-driven approach to building models for estimating daily patient risk for cdi was used to build institution-specific models at 2 large hospitals with different patient populations and ehr systems. in contrast to traditional approaches that focus on developing models that apply across hospitals, our generalizable approach yields risk-stratification models tailored to an institution. these hospital-specific models allow for earlier and more accurate identification of high-risk patients and better targeting of infection prevention strategies. infect control hosp epidemiol 2018;39:425\u2013433",
            "contribution_ids": [
                "R70596"
            ]
        },
        {
            "instance_id": "R70633xR70593",
            "comparison_id": "R70633",
            "paper_id": "R70593",
            "text": "A Multi-Center Prospective Derivation and Validation of a Clinical Prediction Tool for Severe Clostridium difficile Infection background and aims prediction of severe clinical outcomes in clostridium difficile infection (cdi) is important to inform management decisions for optimum patient care. currently, treatment recommendations for cdi vary based on disease severity but validated methods to predict severe disease are lacking. the aim of the study was to derive and validate a clinical prediction tool for severe outcomes in cdi. methods a cohort totaling 638 patients with cdi was prospectively studied at three tertiary care clinical sites (boston, dublin and houston). the clinical prediction rule (cpr) was developed by multivariate logistic regression analysis using the boston cohort and the performance of this model was then evaluated in the combined houston and dublin cohorts. results the cpr included the following three binary variables: age \u2265 65 years, peak serum creatinine \u22652 mg/dl and peak peripheral blood leukocyte count of \u226520,000 cells/\u03bcl. the clostridium difficile severity score (cdss) correctly classified 76.5% (95% ci: 70.87-81.31) and 72.5% (95% ci: 67.52-76.91) of patients in the derivation and validation cohorts, respectively. in the validation cohort, cdss scores of 0, 1, 2 or 3 were associated with severe clinical outcomes of cdi in 4.7%, 13.8%, 33.3% and 40.0% of cases respectively. conclusions we prospectively derived and validated a clinical prediction rule for severe cdi that is simple, reliable and accurate and can be used to identify high-risk patients most likely to benefit from measures to prevent complications of cdi.",
            "contribution_ids": [
                "R70594"
            ]
        },
        {
            "instance_id": "R70633xR70603",
            "comparison_id": "R70633",
            "paper_id": "R70603",
            "text": "Learning Data-Driven Patient Risk Stratification Models for Clostridium difficile abstract \\n background. \\u2003although many risk factors are well known, clostridium difficile infection (cdi) continues to be a significant problem throughout the world. the purpose of this study was to develop and validate a data-driven, hospital-specific risk stratification procedure for estimating the probability that an inpatient will test positive for c difficile. \\n methods. \\u2003we consider electronic medical record (emr) data from patients admitted for \u226524 hours to a large urban hospital in the u.s. between april 2011 and april 2013. predictive models were constructed using l2-regularized logistic regression and data from the first year. the number of observational variables considered varied from a small set of well known risk factors readily available to a physician to over 10 000 variables automatically extracted from the emr. each model was evaluated on holdout admission data from the following year. a total of 34 846 admissions with 372 cases of cdi was used to train the model. \\n results. \\u2003applied to the separate validation set of 34 722 admissions with 355 cases of cdi, the model that made use of the additional emr data yielded an area under the receiver operating characteristic curve (auroc) of 0.81 (95% confidence interval [ci], .79\u2013.83), and it significantly outperformed the model that considered only the small set of known clinical risk factors, auroc of 0.71 (95% ci, .69\u2013.75). \\n conclusions. \\u2003automated risk stratification of patients based on the contents of their emrs can be used to accurately ide.jpegy a high-risk population of patients. the proposed method holds promise for enabling the selective allocation of interventions aimed at reducing the rate of cdi.",
            "contribution_ids": [
                "R70604"
            ]
        },
        {
            "instance_id": "R70633xR70591",
            "comparison_id": "R70633",
            "paper_id": "R70591",
            "text": "Improving Risk Prediction of Clostridium Difficile Infection Using Temporal Event-Pairs clostridium difficile infection (cdi) is a contagious healthcare-associated infection that imposes a significant burden on the healthcare system. in 2011 alone, half a million patients suffered from cdi in the united states, 29,000 dying within 30 days of diagnosis. determining which hospital patients are at risk for developing cdi is critical to helping healthcare workers take timely measures to prevent or detect and treat this infection. we improve the state of the art of cdi risk prediction by designing an ensemble logistic regression classifier that given partial patient visit histories, outputs the risk of patients acquiring cdi during their current hospital visit. the novelty of our approach lies in the representation of each patient visit as a collection of co-occurring and chronologically ordered pairs of events. this choice is motivated by our hypothesis that cdi risk is influenced not just by individual events (e.g., being prescribed a first generation cephalosporin antibiotic), but by the temporal ordering of individual events (e.g., antibiotic prescription followed by transfer to a certain hospital unit). while this choice explodes the number of features, we use a randomized greedy feature selection algorithm followed by bic minimization to reduce the dimensionality of the feature space, while retaining the most relevant features. we apply our approach to a rich dataset from the university of iowa hospitals and clinics (uihc), curated from diverse sources, consisting of 200,000 visits (30,000 per year, 2006-2011) involving 125,000 unique patients, 2 million diagnoses, 8 million prescriptions, 400,000 room transfers spanning a hospital with 700 patient rooms and 200 units. our approach to classification produces better risk predictions (auc) than existing risk estimators for cdi, even when trained just on data available at patient admission. it also identifies novel risk factors for cdi that are combinations of co-occurring and chronologically ordered events.",
            "contribution_ids": [
                "R70592"
            ]
        },
        {
            "instance_id": "R70640xR70624",
            "comparison_id": "R70640",
            "paper_id": "R70624",
            "text": "Predictive Modeling of Surgical Site Infections Using Sparse Laboratory Data as part of a data mining competition, a training and test set of laboratory test data about patients with and without surgical site infection (ssi) were provided. the task was to develop predictive models with training set and identify patients with ssi in the no label test set. lab test results are vital resources that guide healthcare providers make decisions about all aspects of surgical patient management. many machine learning models were developed after pre-processing and imputing the lab tests data and only the top performing methods are discussed. overall, random forest algorithms performed better than support vector machine and logistic regression. using a set of 74 lab tests, with rf, there were only 4 false positives in the training set and predicted 35 out of 50 ssi patients in the test set (accuracy 0.86, sensitivity 0.68, and specificity 0.91). optimal ways to address healthcare data quality concerns and imputation methods as well as newer generalizable algorithms need to be explored further to decipher new associations and knowledge among laboratory biomarkers and ssi.",
            "contribution_ids": [
                "R70625"
            ]
        },
        {
            "instance_id": "R70640xR70628",
            "comparison_id": "R70640",
            "paper_id": "R70628",
            "text": "Classification of postoperative surgical site infections from blood measurements with missing data using recurrent neural networks clinical measurements that can be represented as time series constitute an important fraction of the electronic health records and are often both uncertain and incomplete. recurrent neural networks are a special class of neural networks that are particularly suitable to process time series data but, in their original formulation, cannot explicitly deal with missing data. in this paper, we explore imputation strategies for handling missing values in classifiers based on recurrent neural network (rnn) and apply a recently proposed recurrent architecture, the gated recurrent unit with decay, specifically designed to handle missing data. we focus on the problem of detecting surgical site infection in patients by analyzing time series of their blood sample measurements and we compare the results obtained with different rnn-based classifiers.",
            "contribution_ids": [
                "R70629"
            ]
        },
        {
            "instance_id": "R70640xR70626",
            "comparison_id": "R70640",
            "paper_id": "R70626",
            "text": "Data-driven Temporal Prediction of Surgical Site Infection analysis of data from electronic health records (ehr) presents unique challenges, in particular regarding nonuniform temporal resolution of longitudinal variables. a considerable amount of patient information is available in the ehr - including blood tests that are performed routinely during inpatient follow-up. these data are useful for the design of advanced machine learning-based methods and prediction models. using a matched cohort of patients undergoing gastrointestinal surgery (101 cases and 904 controls), we built a prediction model for post-operative surgical site infections (ssis) using gaussian process (gp) regression, time warping and imputation methods to manage the sparsity of the data source, and support vector machines for classification. for most blood tests, wider confidence intervals after imputation were obtained in patients with ssi. predictive performance with individual blood tests was maintained or improved by joint model prediction, and non-linear classifiers performed consistently better than linear models.",
            "contribution_ids": [
                "R70627"
            ]
        },
        {
            "instance_id": "R70640xR70614",
            "comparison_id": "R70640",
            "paper_id": "R70614",
            "text": "Maximizing Interpretability and Cost-Effectiveness of Surgical Site Infection (SSI) Predictive Models Using Feature-Specific Regularized Logistic Regression on Preoperative Temporal Data this study describes a novel approach to solve the surgical site infection (ssi) classification problem. feature engineering has traditionally been one of the most important steps in solving complex classification problems, especially in cases with temporal data. the described novel approach is based on abstraction of temporal data recorded in three temporal windows. maximum likelihood l1-norm (lasso) regularization was used in penalized logistic regression to predict the onset of surgical site infection occurrence based on available patient blood testing results up to the day of surgery. prior knowledge of predictors (blood tests) was integrated in the modelling by introduction of penalty factors depending on blood test prices and an early stopping parameter limiting the maximum number of selected features used in predictive modelling. finally, solutions resulting in higher interpretability and cost-effectiveness were demonstrated. using repeated holdout cross-validation, the baseline c-reactive protein (crp) classifier achieved a mean auc of 0.801, whereas our best full lasso model achieved a mean auc of 0.956. best model testing results were achieved for full lasso model with maximum number of features limited at 20 features with an auc of 0.967. presented models showed the potential to not only support domain experts in their decision making but could also prove invaluable for improvement in prediction of ssi occurrence, which may even help setting new guidelines in the field of preoperative ssi prevention and surveillance.",
            "contribution_ids": [
                "R70615"
            ]
        },
        {
            "instance_id": "R70640xR70618",
            "comparison_id": "R70640",
            "paper_id": "R70618",
            "text": "A diagnostic algorithm for the surveillance of deep surgical site infections after colorectal surgery abstract objective: surveillance of surgical site infections (ssis) is important for infection control and is usually performed through retrospective manual chart review. the aim of this study was to develop an algorithm for the surveillance of deep ssis based on clinical variables to enhance efficiency of surveillance. design: retrospective cohort study (2012\u20132015). setting: a dutch teaching hospital. participants: we included all consecutive patients who underwent colorectal surgery excluding those with contaminated wounds at the time of surgery. all patients were evaluated for deep ssis through manual chart review, using the centers for disease control and prevention (cdc) criteria as the reference standard. analysis: we used logistic regression modeling to identify predictors that contributed to the estimation of diagnostic probability. bootstrapping was applied to increase generalizability, followed by assessment of statistical performance and clinical implications. results: in total, 1,606 patients were included, of whom 129 (8.0%) acquired a deep ssi. the final model included postoperative length of stay, wound class, readmission, reoperation, and 30-day mortality. the model achieved 68.7% specificity and 98.5% sensitivity and an area under the receiver operator characteristic (roc) curve (auc) of 0.950 (95% ci, 0.932\u20130.969). positive and negative predictive values were 21.5% and 99.8%, respectively. applying the algorithm resulted in a 63.4% reduction in the number of records requiring full manual review (from 1,606 to 590). conclusions: this 5-parameter model identified 98.5% of patients with a deep ssi. the model can be used to develop semiautomatic surveillance of deep ssis after colorectal surgery, which may further improve efficiency and quality of ssi surveillance.",
            "contribution_ids": [
                "R70619"
            ]
        },
        {
            "instance_id": "R70642xR70562",
            "comparison_id": "R70642",
            "paper_id": "R70562",
            "text": "Predictive models for severe sepsis in adult ICU patients intensive care unit (icu) patients have significant morbidity and mortality, often from complications that arise during the hospital stay. severe sepsis is one of the leading causes of death among these patients. predictive models have the potential to allow for earlier detection of severe sepsis and ultimately earlier intervention. however, current methods for identifying and predicting severe sepsis are biased and inadequate. the goal of this work is to identify a new framework for the prediction of severe sepsis and identify early predictors utilizing clinical laboratory values and vital signs collected in adult icu patients. we explore models with logistic regression (lr), support vector machines (svm), and logistic model trees (lmt) utilizing vital signs, laboratory values, or a combination of vital and laboratory values. when applied to a retrospective cohort of icu patients, the svm model using laboratory and vital signs as predictors identified 339 (65%) of the 3,446 patients as developing severe sepsis correctly. based on this new framework and developed models, we provide a recommendation for the use in clinical decision support in icu and non-icu environments.",
            "contribution_ids": [
                "R70563",
                "R70581"
            ]
        },
        {
            "instance_id": "R70642xR70564",
            "comparison_id": "R70642",
            "paper_id": "R70564",
            "text": "A Bayesian network for early diagnosis of sepsis patients: a basis for a clinical decision support system sepsis is a severe medical condition caused by an inordinate immune response to an infection. early detection of sepsis symptoms is important to prevent the progression into the more severe stages of the disease, which kills one in four it effects. electronic medical records of 1492 patients containing 233 cases of sepsis were used in a clustering analysis to identify features that are indicative of sepsis and can be further used for training a bayesian inference network. the bayesian network was constructed using the systemic inflammatory response syndrome criteria, mean arterial pressure, and lactate levels for sepsis patients. the resulting network reveals a clear correlation between lactate levels and sepsis. furthermore, it was shown that lactate levels may be predicative of the sirs criteria. in this light, bayesian networks of sepsis patients hold the promise of providing a clinical decision support system in the future.",
            "contribution_ids": [
                "R70565",
                "R70582"
            ]
        },
        {
            "instance_id": "R70642xR70560",
            "comparison_id": "R70642",
            "paper_id": "R70560",
            "text": "Physiological monitoring for critically ill patients: testing a predictive model for the early detection of sepsis \u2022 objective to assess the predictive value for the early detection of sepsis of the physiological monitoring parameters currently recommended by the surviving sepsis campaign. \u2022 methods the project impact data set was used to assess whether the physiological parameters of heart rate, mean arterial pressure, body temperature, and respiratory rate can be used to distinguish between critically ill adult patients with and without sepsis in the first 24 hours of admission to an intensive care unit. \u2022 results all predictor variables used in the analyses differed significantly between patients with sepsis and patients without sepsis. however, only 2 of the predictor variables, mean arterial pressure and high temperature, were independently associated with sepsis. in addition, the temperature mean for hypothermia was significantly lower in patients without sepsis. the odds ratio for having sepsis was 2.126 for patients with a temperature of 38\u00b0c or higher, 3.874 for patients with a mean arterial blood pressure of less than 70 mm hg, and 4.63 times greater for patients who had both of these conditions. \u2022 conclusions the results support the use of some of the guidelines of the surviving sepsis campaign. however, the lowest mean temperature was significantly less for patients without sepsis than for patients with sepsis, a finding that calls into question the clinical usefulness of using hypothermia as an early predictor of sepsis. alone the group of variables used is not sufficient for discriminating between critically ill patients with and without sepsis.",
            "contribution_ids": [
                "R70561",
                "R70580"
            ]
        },
        {
            "instance_id": "R70642xR70548",
            "comparison_id": "R70642",
            "paper_id": "R70548",
            "text": "Machine-Learning-Based Laboratory Developed Test for the Diagnosis of Sepsis in High-Risk Patients sepsis, a dysregulated host response to infection, is a major health burden in terms of both mortality and cost. the difficulties clinicians face in diagnosing sepsis, alongside the insufficiencies of diagnostic biomarkers, motivate the present study. this work develops a machine-learning-based sepsis diagnostic for a high-risk patient group, using a geographically and institutionally diverse collection of nearly 500,000 patient health records. using only a minimal set of clinical variables, our diagnostics outperform common severity scoring systems and sepsis biomarkers and benefit from being available immediately upon ordering.",
            "contribution_ids": [
                "R70549",
                "R70574"
            ]
        },
        {
            "instance_id": "R70642xR70556",
            "comparison_id": "R70642",
            "paper_id": "R70556",
            "text": "Detecting pathogen exposure during the non-symptomatic incubation period using physiological data abstract early pathogen exposure detection allows better patient care and faster implementation of public health measures (patient isolation, contact tracing). existing exposure detection most frequently relies on overt clinical symptoms, namely fever, during the infectious prodromal period. we have developed a robust machine learning based method to better detect asymptomatic states during the incubation period using subtle, sub-clinical physiological markers. starting with high-resolution physiological waveform data from non-human primate studies of viral (ebola, marburg, lassa, and nipah viruses) and bacterial ( y. pestis ) exposure, we processed the data to reduce short-term variability and normalize diurnal variations, then provided these to a supervised random forest classification algorithm and post-classifier declaration logic step to reduce false alarms. in most subjects detection is achieved well before the onset of fever; subject cross-validation across exposure studies (varying viruses, exposure routes, animal species, and target dose) lead to 51h mean early detection (at 0.93 area under the receiver-operating characteristic curve [aucroc]). evaluating the algorithm against entirely independent datasets for lassa, nipah, and y. pestis exposures un-used in algorithm training and development yields a mean 51h early warning time (at aucroc=0.95). we discuss which physiological indicators are most informative for early detection and options for extending this capability to limited datasets such as those available from wearable, non-invasive, ecg-based sensors.",
            "contribution_ids": [
                "R70557",
                "R70578"
            ]
        },
        {
            "instance_id": "R76783xR76770",
            "comparison_id": "R76783",
            "paper_id": "R76770",
            "text": "Knowledge Graphs in Manufacturing and Production: A Systematic Literature Review knowledge graphs in manufacturing and production aim to make production lines more efficient and flexible with higher quality output. this makes knowledge graphs attractive for companies to reach industry 4.0 goals. however, existing research in the field is quite preliminary, and more research effort on analyzing how knowledge graphs can be applied in the field of manufacturing and production is needed. therefore, we have conducted a systematic literature review as an attempt to characterize the state-of-the-art in this field, i.e., by identifying existing research and by identifying gaps and opportunities for further research. we have focused on finding the primary studies in the existing literature, which were classified and analyzed according to four criteria: bibliometric key facts, research type facets, knowledge graph characteristics, and application scenarios. besides, an evaluation of the primary studies has also been carried out to gain deeper insights in terms of methodology, empirical evidence, and relevance. as a result, we can offer a complete picture of the domain, which includes such interesting aspects as the fact that knowledge fusion is currently the main use case for knowledge graphs, that empirical research and industrial application are still missing to a large extent, that graph embeddings are not fully exploited, and that technical literature is fast-growing but still seems to be far from its peak.",
            "contribution_ids": [
                "R76772"
            ]
        },
        {
            "instance_id": "R76783xR76779",
            "comparison_id": "R76783",
            "paper_id": "R76779",
            "text": "Knowledge Graphs: New Directions for Knowledge Representation on the Semantic Web the increasingly pervasive nature of the web, expanding to devices and things in everyday \\nlife, along with new trends in artificial intelligence call for new paradigms and a new look on \\nknowledge representation and processing at scale for the semantic web. the emerging, but still \\nto be concretely shaped concept of \"knowledge graphs\" provides an excellent unifying metaphor \\nfor this current status of semantic web research. more than two decades of semantic web \\nresearch provides a solid basis and a promising technology and standards stack to interlink data, \\nontologies and knowledge on the web. however, neither are applications for knowledge graphs \\nas such limited to linked open data, nor are instantiations of knowledge graphs in enterprises \\n\u2013 while often inspired by \u2013 limited to the core semantic web stack. this report documents the \\nprogram and the outcomes of dagstuhl seminar 18371 \"knowledge graphs: new directions for \\nknowledge representation on the semantic web\", where a group of experts from academia and \\nindustry discussed fundamental questions around these topics for a week in early september 2018, \\nincluding the following: what are knowledge graphs? which applications do we see to emerge? \\nwhich open research questions still need be addressed and which technology gaps still need to \\nbe closed?",
            "contribution_ids": [
                "R76780"
            ]
        },
        {
            "instance_id": "R76783xR76758",
            "comparison_id": "R76783",
            "paper_id": "R76758",
            "text": "Relational Representation Learning for Dynamic (Knowledge) Graphs: A Survey graphs arise naturally in many real-world applications including social networks, recommender systems, ontologies, biology, and computational finance. traditionally, machine learning models for graphs have been mostly designed for static graphs. however, many applications involve evolving graphs. this introduces important challenges for learning and inference since nodes, attributes, and edges change over time. in this survey, we review the recent advances in representation learning for dynamic graphs, including dynamic knowledge graphs. we describe existing models from an encoder-decoder perspective, categorize these encoders and decoders based on the techniques they employ, and analyze the approaches in each category. we also review several prominent applications and widely used datasets, and highlight directions for future research.",
            "contribution_ids": [
                "R76760"
            ]
        },
        {
            "instance_id": "R76783xR76746",
            "comparison_id": "R76783",
            "paper_id": "R76746",
            "text": "Knowledge Graph Embedding: A Survey of Approaches and Applications knowledge graph (kg) embedding is to embed components of a kg including entities and relations into continuous vector spaces, so as to simplify the manipulation while preserving the inherent structure of the kg. it can benefit a variety of downstream tasks such as kg completion and relation extraction, and hence has quickly gained massive attention. in this article, we provide a systematic review of existing techniques, including not only the state-of-the-arts but also those with latest trends. particularly, we make the review based on the type of information used in the embedding task. techniques that conduct embedding using only facts observed in the kg are first introduced. we describe the overall framework, specific model design, typical training procedures, as well as pros and cons of such techniques. after that, we discuss techniques that further incorporate additional information besides facts. we focus specifically on the use of entity types, relation paths, textual descriptions, and logical rules. finally, we briefly introduce how kg embedding can be applied to and benefit a wide variety of downstream tasks such as kg completion, relation extraction, question answering, and so forth.",
            "contribution_ids": [
                "R76748"
            ]
        },
        {
            "instance_id": "R76785xR76746",
            "comparison_id": "R76785",
            "paper_id": "R76746",
            "text": "Knowledge Graph Embedding: A Survey of Approaches and Applications knowledge graph (kg) embedding is to embed components of a kg including entities and relations into continuous vector spaces, so as to simplify the manipulation while preserving the inherent structure of the kg. it can benefit a variety of downstream tasks such as kg completion and relation extraction, and hence has quickly gained massive attention. in this article, we provide a systematic review of existing techniques, including not only the state-of-the-arts but also those with latest trends. particularly, we make the review based on the type of information used in the embedding task. techniques that conduct embedding using only facts observed in the kg are first introduced. we describe the overall framework, specific model design, typical training procedures, as well as pros and cons of such techniques. after that, we discuss techniques that further incorporate additional information besides facts. we focus specifically on the use of entity types, relation paths, textual descriptions, and logical rules. finally, we briefly introduce how kg embedding can be applied to and benefit a wide variety of downstream tasks such as kg completion, relation extraction, question answering, and so forth.",
            "contribution_ids": [
                "R76748"
            ]
        },
        {
            "instance_id": "R76785xR76770",
            "comparison_id": "R76785",
            "paper_id": "R76770",
            "text": "Knowledge Graphs in Manufacturing and Production: A Systematic Literature Review knowledge graphs in manufacturing and production aim to make production lines more efficient and flexible with higher quality output. this makes knowledge graphs attractive for companies to reach industry 4.0 goals. however, existing research in the field is quite preliminary, and more research effort on analyzing how knowledge graphs can be applied in the field of manufacturing and production is needed. therefore, we have conducted a systematic literature review as an attempt to characterize the state-of-the-art in this field, i.e., by identifying existing research and by identifying gaps and opportunities for further research. we have focused on finding the primary studies in the existing literature, which were classified and analyzed according to four criteria: bibliometric key facts, research type facets, knowledge graph characteristics, and application scenarios. besides, an evaluation of the primary studies has also been carried out to gain deeper insights in terms of methodology, empirical evidence, and relevance. as a result, we can offer a complete picture of the domain, which includes such interesting aspects as the fact that knowledge fusion is currently the main use case for knowledge graphs, that empirical research and industrial application are still missing to a large extent, that graph embeddings are not fully exploited, and that technical literature is fast-growing but still seems to be far from its peak.",
            "contribution_ids": [
                "R76772"
            ]
        },
        {
            "instance_id": "R76785xR76779",
            "comparison_id": "R76785",
            "paper_id": "R76779",
            "text": "Knowledge Graphs: New Directions for Knowledge Representation on the Semantic Web the increasingly pervasive nature of the web, expanding to devices and things in everyday \\nlife, along with new trends in artificial intelligence call for new paradigms and a new look on \\nknowledge representation and processing at scale for the semantic web. the emerging, but still \\nto be concretely shaped concept of \"knowledge graphs\" provides an excellent unifying metaphor \\nfor this current status of semantic web research. more than two decades of semantic web \\nresearch provides a solid basis and a promising technology and standards stack to interlink data, \\nontologies and knowledge on the web. however, neither are applications for knowledge graphs \\nas such limited to linked open data, nor are instantiations of knowledge graphs in enterprises \\n\u2013 while often inspired by \u2013 limited to the core semantic web stack. this report documents the \\nprogram and the outcomes of dagstuhl seminar 18371 \"knowledge graphs: new directions for \\nknowledge representation on the semantic web\", where a group of experts from academia and \\nindustry discussed fundamental questions around these topics for a week in early september 2018, \\nincluding the following: what are knowledge graphs? which applications do we see to emerge? \\nwhich open research questions still need be addressed and which technology gaps still need to \\nbe closed?",
            "contribution_ids": [
                "R76780"
            ]
        },
        {
            "instance_id": "R76785xR76758",
            "comparison_id": "R76785",
            "paper_id": "R76758",
            "text": "Relational Representation Learning for Dynamic (Knowledge) Graphs: A Survey graphs arise naturally in many real-world applications including social networks, recommender systems, ontologies, biology, and computational finance. traditionally, machine learning models for graphs have been mostly designed for static graphs. however, many applications involve evolving graphs. this introduces important challenges for learning and inference since nodes, attributes, and edges change over time. in this survey, we review the recent advances in representation learning for dynamic graphs, including dynamic knowledge graphs. we describe existing models from an encoder-decoder perspective, categorize these encoders and decoders based on the techniques they employ, and analyze the approaches in each category. we also review several prominent applications and widely used datasets, and highlight directions for future research.",
            "contribution_ids": [
                "R76760"
            ]
        },
        {
            "instance_id": "R77162xR75942",
            "comparison_id": "R77162",
            "paper_id": "R75942",
            "text": "Parental well-being in times of Covid-19 in Germany abstract we examine the effects of covid-19 and related restrictions on individuals with dependent children in germany. we specifically focus on the role of day care center and school closures, which may be regarded as a \u201cdisruptive exogenous shock\u201d to family life. we make use of a novel representative survey of parental well-being collected in may and june 2020 in germany, when schools and day care centers were closed but while other measures had been relaxed and new infections were low. in our descriptive analysis, we compare well-being during this period with a pre-crisis period for different groups. in a difference-in-differences design, we compare the change for individuals with children to the change for individuals without children, accounting for unrelated trends as well as potential survey mode and context effects. we find that the crisis lowered the relative well-being of individuals with children, especially for individuals with young children, for women, and for persons with lower secondary schooling qualifications. our results suggest that public policy measures taken to contain covid-19 can have large effects on family well-being, with implications for child development and parental labor market outcomes.",
            "contribution_ids": [
                "R75945",
                "R77076",
                "R77077",
                "R77081",
                "R77082"
            ]
        },
        {
            "instance_id": "R77162xR76559",
            "comparison_id": "R77162",
            "paper_id": "R76559",
            "text": "Socioeconomic status and well-being during COVID-19: A resource-based examination. \"the authors assess levels and within-person changes in psychological well-being (i.e., depressive symptoms and life satisfaction) from before to during the covid-19 pandemic for individuals in the united states, in general and by socioeconomic status (ses). the data is from 2 surveys of 1,143 adults from rand corporation's nationally representative american life panel, the first administered between april-june, 2019 and the second during the initial peak of the pandemic in the united states in april, 2020. depressive symptoms during the pandemic were higher than population norms before the pandemic. depressive symptoms increased from before to during covid-19 and life satisfaction decreased. individuals with higher education experienced a greater increase in depressive symptoms and a greater decrease in life satisfaction from before to during covid-19 in comparison to those with lower education. supplemental analysis illustrates that income had a curvilinear relationship with changes in well-being, such that individuals at the highest levels of income experienced a greater decrease in life satisfaction from before to during covid-19 than individuals with lower levels of income. we draw on conservation of resources theory and the theory of fundamental social causes to examine four key mechanisms (perceived financial resources, perceived control, interpersonal resources, and covid-19-related knowledge/news consumption) underlying the relationship between ses and well-being during covid-19. these resources explained changes in well-being for the sample as a whole but did not provide insight into why individuals of higher education experienced a greater decline in well-being from before to during covid-19. (psycinfo database record (c) 2020 apa, all rights reserved).\"",
            "contribution_ids": [
                "R76566"
            ]
        },
        {
            "instance_id": "R77162xR75946",
            "comparison_id": "R77162",
            "paper_id": "R75946",
            "text": "Who is most affected by the Corona crisis? An analysis of changes in stress and well-being in Switzerland abstract this study analyses the consequences of the covid-19 crisis on stress and well-being in switzerland. in particular, we assess whether vulnerable groups in terms of social isolation, increased workload and limited socioeconomic resources are affected more than others. using longitudinal data from the swiss household panel, including a specific covid-19 study, we estimate change score models to predict changes in perceived stress and life satisfaction at the end of the semi-lockdown in comparison to before the crisis. we find no general change in life satisfaction and a small decrease in stress. yet, in line with our expectations, more vulnerable groups in terms of social isolation (young adults, covid-19 risk group members, individuals without a partner), workload (women) and socioeconomic resources (unemployed and those who experienced a deteriorating financial situation) reported a decrease in life satisfaction. stress levels decreased most strongly among high earners, workers on short-time work and the highly educated.",
            "contribution_ids": [
                "R75948",
                "R77084",
                "R77086"
            ]
        },
        {
            "instance_id": "R77162xR76575",
            "comparison_id": "R77162",
            "paper_id": "R76575",
            "text": "The gender gap in mental well-being during the Covid-19 outbreak: evidence from the UK \"we document a decline in mental well-being after the onset of the covid-19 pandemic in the uk. this decline is twice as large for women as for men. we seek to explain this gender gap by exploring gender differences in: family and caring responsibilities; financial and work situation; social engagement; health situation, and health behaviours, including exercise. differences in family and caring responsibilities play some role, but the bulk of the gap is explained by social factors. women reported more close friends before the pandemic than men, and increased loneliness after the pandemic's onset. other factors are similarly distributed across genders and so play little role. finally, we document larger declines in well-being for the young, of both genders, than the old.\"",
            "contribution_ids": [
                "R76576",
                "R77075"
            ]
        },
        {
            "instance_id": "R77162xR76554",
            "comparison_id": "R77162",
            "paper_id": "R76554",
            "text": "The COVID-19 pandemic and subjective well-being: longitudinal evidence on satisfaction with work and family \"abstract this paper provides a timely evaluation of whether the main covid-19 lockdown policies \u2013 remote work, short-time work and closure of schools and childcare \u2013 have an immediate effect on the german population in terms of changes in satisfaction with work and family life. relying on individual level panel data collected before and during the lockdown, we examine (1) how family satisfaction and work satisfaction of individuals have changed over the lockdown period, and (2) how lockdown-driven changes in the labour market situation (i.e. working remotely and being sent on short-time work) have affected satisfactions. we apply first-difference regressions for mothers, fathers, and persons without children. our results show a general decrease in family satisfaction. we also find an overall decline in work satisfaction which is most pronounced for mothers and those without children who have to switch to short-time work. in contrast, fathers' well-being is less affected negatively and their family satisfaction even increased after changing to short-time work. we conclude that while the lockdown circumstances generally have a negative effect on the satisfaction with work and family of individuals in germany, effects differ between childless persons, mothers, and fathers with the latter being least negatively affected.\"",
            "contribution_ids": [
                "R76558",
                "R77087"
            ]
        },
        {
            "instance_id": "R77220xR76542",
            "comparison_id": "R77220",
            "paper_id": "R76542",
            "text": "Up and About: Older Adults\u00e2\u0080\u0099 Well-being During the COVID-19 Pandemic in a Swedish Longitudinal Study abstract \\n \\n objectives \\n to investigate early effects of the covid-19 pandemic related to (a) levels of worry, risk perception, and social distancing; (b) longitudinal effects on well-being; and (c) effects of worry, risk perception, and social distancing on well-being. \\n \\n \\n methods \\n we analyzed annual changes in four aspects of well-being over 5 years (2015\u20132020): life satisfaction, financial satisfaction, self-rated health, and loneliness in a subsample (n = 1,071, aged 65\u201371) from a larger survey of swedish older adults. the 2020 wave, collected march 26\u2013april 2, included measures of worry, risk perception, and social distancing in response to covid-19. \\n \\n \\n results \\n (a) in relation to covid-19: 44.9% worried about health, 69.5% about societal consequences, 25.1% about financial consequences; 86.4% perceived a high societal risk, 42.3% a high risk of infection, and 71.2% reported high levels of social distancing. (b) well-being remained stable (life satisfaction and loneliness) or even increased (self-rated health and financial satisfaction) in 2020 compared to previous years. (c) more worry about health and financial consequences was related to lower scores in all four well-being measures. higher societal worry and more social distancing were related to higher well-being. \\n \\n \\n discussion \\n in the early stage of the pandemic, swedish older adults on average rated their well-being as high as, or even higher than, previous years. however, those who worried more reported lower well-being. our findings speak to the resilience, but also heterogeneity, among older adults during the pandemic. further research, on a broad range of health factors and long-term psychological consequences, is needed. \\n",
            "contribution_ids": [
                "R76545"
            ]
        },
        {
            "instance_id": "R77220xR76554",
            "comparison_id": "R77220",
            "paper_id": "R76554",
            "text": "The COVID-19 pandemic and subjective well-being: longitudinal evidence on satisfaction with work and family \"abstract this paper provides a timely evaluation of whether the main covid-19 lockdown policies \u2013 remote work, short-time work and closure of schools and childcare \u2013 have an immediate effect on the german population in terms of changes in satisfaction with work and family life. relying on individual level panel data collected before and during the lockdown, we examine (1) how family satisfaction and work satisfaction of individuals have changed over the lockdown period, and (2) how lockdown-driven changes in the labour market situation (i.e. working remotely and being sent on short-time work) have affected satisfactions. we apply first-difference regressions for mothers, fathers, and persons without children. our results show a general decrease in family satisfaction. we also find an overall decline in work satisfaction which is most pronounced for mothers and those without children who have to switch to short-time work. in contrast, fathers' well-being is less affected negatively and their family satisfaction even increased after changing to short-time work. we conclude that while the lockdown circumstances generally have a negative effect on the satisfaction with work and family of individuals in germany, effects differ between childless persons, mothers, and fathers with the latter being least negatively affected.\"",
            "contribution_ids": [
                "R76558",
                "R77087"
            ]
        },
        {
            "instance_id": "R77220xR75942",
            "comparison_id": "R77220",
            "paper_id": "R75942",
            "text": "Parental well-being in times of Covid-19 in Germany abstract we examine the effects of covid-19 and related restrictions on individuals with dependent children in germany. we specifically focus on the role of day care center and school closures, which may be regarded as a \u201cdisruptive exogenous shock\u201d to family life. we make use of a novel representative survey of parental well-being collected in may and june 2020 in germany, when schools and day care centers were closed but while other measures had been relaxed and new infections were low. in our descriptive analysis, we compare well-being during this period with a pre-crisis period for different groups. in a difference-in-differences design, we compare the change for individuals with children to the change for individuals without children, accounting for unrelated trends as well as potential survey mode and context effects. we find that the crisis lowered the relative well-being of individuals with children, especially for individuals with young children, for women, and for persons with lower secondary schooling qualifications. our results suggest that public policy measures taken to contain covid-19 can have large effects on family well-being, with implications for child development and parental labor market outcomes.",
            "contribution_ids": [
                "R75945",
                "R77076",
                "R77077",
                "R77081",
                "R77082"
            ]
        },
        {
            "instance_id": "R77220xR77070",
            "comparison_id": "R77220",
            "paper_id": "R77070",
            "text": "The Impact of the Coronavirus Lockdown on Mental Health: Evidence from the US the coronavirus outbreak has caused significant disruptions to people\u2019s lives. we document the impact of state-wide stay-at-home orders on mental health using real time survey data in the us. the lockdown measures lowered mental health by 0.085 standard deviations. this large negative effect is entirely driven by women. as a result of the lockdown measures, the existing gender gap in mental health has increased by 66%. the negative effect on women\u2019s mental health cannot be explained by an increase in financial worries or childcare responsibilities.",
            "contribution_ids": [
                "R77071",
                "R77072",
                "R77073"
            ]
        },
        {
            "instance_id": "R77220xR76567",
            "comparison_id": "R77220",
            "paper_id": "R76567",
            "text": "Individual differences and changes in subjective wellbeing during the early stages of the COVID-19 pandemic. \"the covid-19 pandemic has considerably impacted many people's lives. this study examined changes in subjective wellbeing between december 2019 and may 2020 and how stress appraisals and coping strategies relate to individual differences and changes in subjective wellbeing during the early stages of the pandemic. data were collected at 4 time points from 979 individuals in germany. results showed that, on average, life satisfaction, positive affect, and negative affect did not change significantly between december 2019 and march 2020 but decreased between march and may 2020. across the latter timespan, individual differences in life satisfaction were positively related to controllability appraisals, active coping, and positive reframing, and negatively related to threat and centrality appraisals and planning. positive affect was positively related to challenge and controllable-by-self appraisals, active coping, using emotional support, and religion, and negatively related to threat appraisal and humor. negative affect was positively related to threat and centrality appraisals, denial, substance use, and self-blame, and negatively related to controllability appraisals and emotional support. contrary to expectations, the effects of stress appraisals and coping strategies on changes in subjective wellbeing were small and mostly nonsignificant. these findings imply that the covid-19 pandemic represents not only a major medical and economic crisis, but also has a psychological dimension, as it can be associated with declines in key facets of people's subjective wellbeing. psychological practitioners should address potential declines in subjective wellbeing with their clients and attempt to enhance clients' general capability to use functional stress appraisals and effective coping strategies. (psycinfo database record (c) 2020 apa, all rights reserved).\"",
            "contribution_ids": [
                "R76571"
            ]
        },
        {
            "instance_id": "R78492xR76554",
            "comparison_id": "R78492",
            "paper_id": "R76554",
            "text": "The COVID-19 pandemic and subjective well-being: longitudinal evidence on satisfaction with work and family \"abstract this paper provides a timely evaluation of whether the main covid-19 lockdown policies \u2013 remote work, short-time work and closure of schools and childcare \u2013 have an immediate effect on the german population in terms of changes in satisfaction with work and family life. relying on individual level panel data collected before and during the lockdown, we examine (1) how family satisfaction and work satisfaction of individuals have changed over the lockdown period, and (2) how lockdown-driven changes in the labour market situation (i.e. working remotely and being sent on short-time work) have affected satisfactions. we apply first-difference regressions for mothers, fathers, and persons without children. our results show a general decrease in family satisfaction. we also find an overall decline in work satisfaction which is most pronounced for mothers and those without children who have to switch to short-time work. in contrast, fathers' well-being is less affected negatively and their family satisfaction even increased after changing to short-time work. we conclude that while the lockdown circumstances generally have a negative effect on the satisfaction with work and family of individuals in germany, effects differ between childless persons, mothers, and fathers with the latter being least negatively affected.\"",
            "contribution_ids": [
                "R76558",
                "R77087"
            ]
        },
        {
            "instance_id": "R78492xR77070",
            "comparison_id": "R78492",
            "paper_id": "R77070",
            "text": "The Impact of the Coronavirus Lockdown on Mental Health: Evidence from the US the coronavirus outbreak has caused significant disruptions to people\u2019s lives. we document the impact of state-wide stay-at-home orders on mental health using real time survey data in the us. the lockdown measures lowered mental health by 0.085 standard deviations. this large negative effect is entirely driven by women. as a result of the lockdown measures, the existing gender gap in mental health has increased by 66%. the negative effect on women\u2019s mental health cannot be explained by an increase in financial worries or childcare responsibilities.",
            "contribution_ids": [
                "R77071",
                "R77072",
                "R77073"
            ]
        },
        {
            "instance_id": "R78492xR75942",
            "comparison_id": "R78492",
            "paper_id": "R75942",
            "text": "Parental well-being in times of Covid-19 in Germany abstract we examine the effects of covid-19 and related restrictions on individuals with dependent children in germany. we specifically focus on the role of day care center and school closures, which may be regarded as a \u201cdisruptive exogenous shock\u201d to family life. we make use of a novel representative survey of parental well-being collected in may and june 2020 in germany, when schools and day care centers were closed but while other measures had been relaxed and new infections were low. in our descriptive analysis, we compare well-being during this period with a pre-crisis period for different groups. in a difference-in-differences design, we compare the change for individuals with children to the change for individuals without children, accounting for unrelated trends as well as potential survey mode and context effects. we find that the crisis lowered the relative well-being of individuals with children, especially for individuals with young children, for women, and for persons with lower secondary schooling qualifications. our results suggest that public policy measures taken to contain covid-19 can have large effects on family well-being, with implications for child development and parental labor market outcomes.",
            "contribution_ids": [
                "R75945",
                "R77076",
                "R77077",
                "R77081",
                "R77082"
            ]
        },
        {
            "instance_id": "R78492xR76542",
            "comparison_id": "R78492",
            "paper_id": "R76542",
            "text": "Up and About: Older Adults\u00e2\u0080\u0099 Well-being During the COVID-19 Pandemic in a Swedish Longitudinal Study abstract \\n \\n objectives \\n to investigate early effects of the covid-19 pandemic related to (a) levels of worry, risk perception, and social distancing; (b) longitudinal effects on well-being; and (c) effects of worry, risk perception, and social distancing on well-being. \\n \\n \\n methods \\n we analyzed annual changes in four aspects of well-being over 5 years (2015\u20132020): life satisfaction, financial satisfaction, self-rated health, and loneliness in a subsample (n = 1,071, aged 65\u201371) from a larger survey of swedish older adults. the 2020 wave, collected march 26\u2013april 2, included measures of worry, risk perception, and social distancing in response to covid-19. \\n \\n \\n results \\n (a) in relation to covid-19: 44.9% worried about health, 69.5% about societal consequences, 25.1% about financial consequences; 86.4% perceived a high societal risk, 42.3% a high risk of infection, and 71.2% reported high levels of social distancing. (b) well-being remained stable (life satisfaction and loneliness) or even increased (self-rated health and financial satisfaction) in 2020 compared to previous years. (c) more worry about health and financial consequences was related to lower scores in all four well-being measures. higher societal worry and more social distancing were related to higher well-being. \\n \\n \\n discussion \\n in the early stage of the pandemic, swedish older adults on average rated their well-being as high as, or even higher than, previous years. however, those who worried more reported lower well-being. our findings speak to the resilience, but also heterogeneity, among older adults during the pandemic. further research, on a broad range of health factors and long-term psychological consequences, is needed. \\n",
            "contribution_ids": [
                "R76545"
            ]
        },
        {
            "instance_id": "R78492xR76559",
            "comparison_id": "R78492",
            "paper_id": "R76559",
            "text": "Socioeconomic status and well-being during COVID-19: A resource-based examination. \"the authors assess levels and within-person changes in psychological well-being (i.e., depressive symptoms and life satisfaction) from before to during the covid-19 pandemic for individuals in the united states, in general and by socioeconomic status (ses). the data is from 2 surveys of 1,143 adults from rand corporation's nationally representative american life panel, the first administered between april-june, 2019 and the second during the initial peak of the pandemic in the united states in april, 2020. depressive symptoms during the pandemic were higher than population norms before the pandemic. depressive symptoms increased from before to during covid-19 and life satisfaction decreased. individuals with higher education experienced a greater increase in depressive symptoms and a greater decrease in life satisfaction from before to during covid-19 in comparison to those with lower education. supplemental analysis illustrates that income had a curvilinear relationship with changes in well-being, such that individuals at the highest levels of income experienced a greater decrease in life satisfaction from before to during covid-19 than individuals with lower levels of income. we draw on conservation of resources theory and the theory of fundamental social causes to examine four key mechanisms (perceived financial resources, perceived control, interpersonal resources, and covid-19-related knowledge/news consumption) underlying the relationship between ses and well-being during covid-19. these resources explained changes in well-being for the sample as a whole but did not provide insight into why individuals of higher education experienced a greater decline in well-being from before to during covid-19. (psycinfo database record (c) 2020 apa, all rights reserved).\"",
            "contribution_ids": [
                "R76566"
            ]
        },
        {
            "instance_id": "R8342xR8312",
            "comparison_id": "R8342",
            "paper_id": "R8312",
            "text": "The Publishing Workflow Ontology (PWO) . in this paper we introduce the publishing work\ufb02ow ontology ( pwo ), i.e., an owl 2 dl ontology for the description of work\ufb02ows that is particularly suitable for formalising typical publishing processes such as the publication of articles in journals. we support the presentation with a discussion of all the ontology design patterns that have been reused for modelling the main characteristics of publishing work\ufb02ows. in addition, we present two possible application of pwo in the publishing and legislative domains.",
            "contribution_ids": [
                "R8313"
            ]
        },
        {
            "instance_id": "R8342xR8301",
            "comparison_id": "R8342",
            "paper_id": "R8301",
            "text": "The Document Components Ontology (DoCO) the availability in machine-readable form of descriptions of the structure of documents, as well as of the document\\ndiscourse (e.g. the scientific discourse within scholarly articles), is crucial for facilitating semantic publishing and the overall\\ncomprehension of documents by both users and machines. in this paper we introduce doco, the document components ontology,\\nan owl 2 dl ontology that provides a general-purpose structured vocabulary of document elements to describe both structural and\\nrhetorical document components in rdf. in addition to describing the formal description of the ontology, this paper showcases its\\nutility in practice in a variety of our own applications and other activities of the semantic publishing community that rely on doco\\nto annotate and retrieve document components of scholarly articles.",
            "contribution_ids": [
                "R8302"
            ]
        }
    ]
}