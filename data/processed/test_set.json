{
    "instances": [
        {
            "instance_id": "R108358xR108135",
            "comparison_id": "R108358",
            "paper_id": "R108135",
            "text": "Mapping of hydrothermally altered rocks by the EO-1 Hyperion sensor, Northern Danakil Depression, Eritrea \"an eo\u20101 hyperion scene was used to identify and map hydrothermally altered rocks and a precambrian metamorphic sequence at and around the alid volcanic dome, at the northern danakil depression, eritrea. mapping was coupled with laboratory analyses, including reflectance measurements, x\u2010ray diffraction, and petrographic examination of selected rock samples. thematic maps were compiled from the dataset, which was carefully pre\u2010processed to evaluate and to correct interferences in the data. despite the difficulties, lithological mapping using narrow spectral bands proved possible. a spectral signature attributed to ammonium was detected in the laboratory measurements of hydrothermally altered rocks from alid. this was expressed as spectral absorption clues in the atmospherically corrected cube, at the known hydrothermally altered areas. the existence of ammonium in hydrothermally altered rocks within the alid dome has been confirmed by previous studies. spectral information of endmember's mineralogy found in the area (e.g. dolomite) enables a surface mineral map to be produced that stands in good agreement with the known geology along the overpass. these maps are the first hyperspectral overview of the surface mineralogy in this arid terrain and may be used as a base for future studies of remote areas such as the danakil.\"",
            "contribution_ids": [
                "R108136"
            ]
        },
        {
            "instance_id": "R108358xR108144",
            "comparison_id": "R108358",
            "paper_id": "R108144",
            "text": "Mapping of Alteration Zones in Mineral Rich Belt of South-East Rajasthan Using Remote Sensing Techniques remote sensing techniques have emerged as an asset for various geological studies. satellite images obtained by different sensors contain plenty of information related to the terrain. digital image processing further helps in customized ways for the prospecting of minerals. in this study, an attempt has been made to map the hydrothermally altered zones using multispectral and hyperspectral datasets of south east rajasthan. advanced spaceborne thermal emission and reflection radiometer (aster) and hyperion (level1r) dataset have been processed to generate different band ratio composites (brcs). for this study, aster derived brcs were generated to delineate the alteration zones, gossans, abundant clays and host rocks. aster and hyperion images were further processed to extract mineral end members and classified mineral maps have been produced using spectral angle mapper (sam) method. results were validated with the geological map of the area which shows positive agreement with the image processing outputs. thus, this study concludes that the band ratios and image processing in combination play significant role in demarcation of alteration zones which may provide pathfinders for mineral prospecting studies. keywords\u2014advanced space-borne thermal emission and reflection radiometer, aster, hyperion, band ratios, alteration zones, spectral angle mapper.",
            "contribution_ids": [
                "R108145"
            ]
        },
        {
            "instance_id": "R109612xR109396",
            "comparison_id": "R109612",
            "paper_id": "R109396",
            "text": "No nitrogen fixation in the Bay of Bengal? \" abstract. the bay of bengal (bob) has long stood as a biogeochemical enigma, with\\nsubsurface waters containing extremely low, but persistent, concentrations\\nof oxygen in the nanomolar range which \u2013 for some, yet unconstrained, reason \u2013\\nare prevented from becoming anoxic. one reason for this may be the low\\nproductivity of the bob waters due to nutrient limitation and the resulting\\nlack of respiration of organic material at intermediate waters. thus, the\\nparameters determining primary production are key in understanding what\\nprevents the bob from developing anoxia. primary productivity in the sunlit\\nsurface layers of tropical oceans is mostly limited by the supply of\\nreactive nitrogen through upwelling, riverine flux, atmospheric deposition,\\nand biological dinitrogen (n2) fixation. in the bob, a stable\\nstratification limits nutrient supply via upwelling in the open waters, and\\nriverine or atmospheric fluxes have been shown to support only less than one-quarter of the nitrogen for primary production. this leaves a large\\nuncertainty for most of the bob's nitrogen input, suggesting a potential\\nrole of n2 fixation in those waters. here, we present a survey of n2 fixation and carbon fixation in the bob\\nduring the winter monsoon season. we detected a community of n2 fixers\\ncomparable to other oxygen minimum zone (omz) regions, with only a few\\ncyanobacterial clades and a broad diversity of non-phototrophic n2\\nfixers present throughout the water column (samples collected between 10\\nand 560\\u2009m water depth). while similar communities of n2 fixers were\\nshown to actively fix n2 in other omzs, n2 fixation rates were\\nbelow the detection limit in our samples covering the water column between\\nthe deep chlorophyll maximum and the omz. consistent with this, no n2\\nfixation signal was visible in \u03b415n signatures. we suggest that\\nthe absence of n2 fixation may be a consequence of a micronutrient\\nlimitation or of an o2 sensitivity of the omz diazotrophs in the bob.\\nexploring how the onset of n2 fixation by cyanobacteria compared to\\nnon-phototrophic n2 fixers would impact on omz o2 concentrations,\\na simple model exercise was carried out. we observed that both photic-zone-based and omz-based n2 fixation are very sensitive to even\\nminimal changes in water column stratification, with stronger mixing\\nincreasing organic matter production and export, which can exhaust\\nremaining o2 traces in the bob.\\n \"",
            "contribution_ids": [
                "R109397",
                "R109581",
                "R109596",
                "R138402"
            ]
        },
        {
            "instance_id": "R109612xR109573",
            "comparison_id": "R109612",
            "paper_id": "R109573",
            "text": "N2 Fixation in the Eastern Arabian Sea: Probable Role of Heterotrophic Diazotrophs biogeochemical implications of global imbalance between the rates of marine dinitrogen (n2) fixation and denitrification have spurred us to understand the former process in the arabian sea, which contributes considerably to the global nitrogen budget. heterotrophic bacteria have gained recent appreciation for their major role in marine n budget by fixing a significant amount of n2. accordingly, we hypothesize a probable role of heterotrophic diazotrophs from the 15n2 enriched isotope labelling dark incubations that witnessed rates comparable to the light incubations in the eastern arabian sea during spring 2010. maximum areal rates (8 mmol n m-2 d-1) were the highest ever observed anywhere in world oceans. our results suggest that the eastern arabian sea gains ~92% of its new nitrogen through n2 fixation. our results are consistent with the observations made in the same region in preceding year, i.e., during the spring of 2009.",
            "contribution_ids": [
                "R109574",
                "R109591",
                "R138494"
            ]
        },
        {
            "instance_id": "R109904xR109860",
            "comparison_id": "R109904",
            "paper_id": "R109860",
            "text": "Applying weighted PageRank to author citation networks this article aims to identify whether different weighted pagerank algorithms can be applied to author citation networks to measure the popularity and prestige of a scholar from a citation perspective. information retrieval (ir) was selected as a test field and data from 1956\u20132008 were collected from web of science. weighted pagerank with citation and publication as weighted vectors were calculated on author citation networks. the results indicate that both popularity rank and prestige rank were highly correlated with the weighted pagerank. principal component analysis was conducted to detect relationships among these different measures. for capturing prize winners within the ir field, prestige rank outperformed all the other measures. \u00a9 2011 wiley periodicals, inc.",
            "contribution_ids": [
                "R109862"
            ]
        },
        {
            "instance_id": "R109904xR109894",
            "comparison_id": "R109904",
            "paper_id": "R109894",
            "text": "A Hybrid Approach Toward Research Paper Recommendation Using Centrality Measures and Author Ranking the volume of research articles in digital repositories is increasing. this spectacular growth of repositories makes it rather difficult for researchers to obtain related research papers in response to their queries. the problem becomes worse when a researcher with insufficient knowledge of searching research articles uses these repositories. in the traditional recommendation approaches, the results of the query miss many high-quality papers, in the related work section, which are either published recently or have low citation count. to overcome this problem, there needs to be a solution which considers not only structural relationships between the papers but also inspects the quality of authors publishing those articles. many research paper recommendation approaches have been implemented which includes collaborative filtering-based, content-based, and citation analysis-based techniques. the collaborative filtering-based approaches primarily use paper-citation matrix for recommendations, whereas the content-based approaches only consider the content of the paper. the citation analysis considers the structure of the network and focuses on papers citing or cited by the paper of interest. it is therefore very difficult for a recommender system to recommend high-quality papers without a hybrid approach that incorporates multiple features, such as citation information and author information. the proposed method creates a multilevel citation and relationship network of authors in which the citation network uses the structural relationship between the papers to extract significant papers, and authors\u2019 collaboration network finds key authors from those papers. the papers selected by this hybrid approach are then recommended to the user. the results have shown that our proposed method performs exceedingly well as compared with the state-of-the-art existing systems, such as google scholar and multilevel simultaneous citation network.",
            "contribution_ids": [
                "R109899"
            ]
        },
        {
            "instance_id": "R111045xR110913",
            "comparison_id": "R111045",
            "paper_id": "R110913",
            "text": "Multinuclear Lanthanide-Implanted Tetrameric Dawson-Type Phosphotungstates with Switchable Luminescence Behaviors Induced by Fast Photochromism a series of benzoate-decorated lanthanide (ln)-containing tetrameric dawson-type phosphotungstates [n(ch3)4]6h20[{(p2w17o61)ln(h2o)3ln(c6h5coo)(h2o)6]}{[(p2w17o61)ln(h2o)3}]2cl2\u00b798h2o [ln = sm (1), eu (2), and gd (3)] were made using a facile one-step assembly strategy and characterized by several techniques. notably, the ln-containing tetrameric dawson-type polyoxoanions [{(p2w17o61)ln(h2o)3ln(c6h5coo)(h2o)6]}{[(p2w17o61)ln(h2o)3}]224- are all established by four monolacunary dawson-type [p2w17o61]10- segments, encapsulating a ln3+ ion with two benzoates coordinating to the ln3+ ions. 1-3 exhibit reversible photochromism, which can change from intrinsic white to blue for 6 min upon uv irradiation, and their colors gradually recover for 30 h in the dark. the solid-state photoluminescence spectra of 1 and 2 display characteristic emissions of ln components based on 4f-4f transitions. time-resolved emission spectra of 1 and 2 were also measured to authenticate the energy transfer from the phosphotungstate and organic chromophores to eu3+. in particular, 1 shows an effectively switchable luminescence behavior induced by its fast photochromism.",
            "contribution_ids": [
                "R110916"
            ]
        },
        {
            "instance_id": "R111045xR110993",
            "comparison_id": "R111045",
            "paper_id": "R110993",
            "text": "Anilido-oxazoline-ligated rare-earth metal complexes: synthesis, characterization and highly cis-1,4-selective polymerization of isoprene anilido-oxazoline-ligated rare-earth metal complexes show strong fluorescence emissions and good catalytic performance on isoprene polymerization with high cis -1,4-selectivity.",
            "contribution_ids": [
                "R110998"
            ]
        },
        {
            "instance_id": "R112387xR78371",
            "comparison_id": "R112387",
            "paper_id": "R78371",
            "text": "Automatic Classification of Non-Functional Requirements from Augmented App User Reviews \"context: the leading app distribution platforms, apple app store, google play, and windows phone store, have over 4 million apps. research shows that user reviews contain abundant useful information which may help developers to improve their apps. extracting and considering non-functional requirements (nfrs), which describe a set of quality attributes wanted for an app and are hidden in user reviews, can help developers to deliver a product which meets users' expectations. objective: developers need to be aware of the nfrs from massive user reviews during software maintenance and evolution. automatic user reviews classification based on an nfr standard provides a feasible way to achieve this goal. method: in this paper, user reviews were automatically classified into four types of nfrs (reliability, usability, portability, and performance), functional requirements (frs), and others. we combined four classification techniques bow, tf-idf, chi2, and aur-bow (proposed in this work) with three machine learning algorithms naive bayes, j48, and bagging to classify user reviews. we conducted experiments to compare the f-measures of the classification results through all the combinations of the techniques and algorithms. results: we found that the combination of aur-bow with bagging achieves the best result (a precision of 71.4%, a recall of 72.3%, and an f-measure of 71.8%) among all the combinations. conclusion: our finding shows that augmented user reviews can lead to better classification results, and the machine learning algorithm bagging is more suitable for nfrs classification from user reviews than na\u00efve bayes and j48.\"",
            "contribution_ids": [
                "R78373"
            ]
        },
        {
            "instance_id": "R112387xR78432",
            "comparison_id": "R112387",
            "paper_id": "R78432",
            "text": "Software Feature Request Detection in Issue Tracking Systems communication about requirements is often handled in issue tracking systems, especially in a distributed setting. as issue tracking systems also contain bug reports or programming tasks, the software feature requests of the users are often difficult to identify. this paper investigates natural language processing and machine learning features to detect software feature requests in natural language data of issue tracking systems. it compares traditional linguistic machine learning features, such as \"bag of words\", with more advanced features, such as subject-action-object, and evaluates combinations of machine learning features derived from the natural language and features taken from the issue tracking system meta-data. our investigation shows that some combinations of machine learning features derived from natural language and the issue tracking system meta-data outperform traditional approaches. we show that issues or data fields (e.g. descriptions or comments), which contain software feature requests, can be identified reasonably well, but hardly the exact sentence. finally, we show that the choice of machine learning algorithms should depend on the goal, e.g. maximization of the detection rate or balance between detection rate and precision. in addition, the paper contributes a double coded gold standard and an open-source implementation to further pursue this topic.",
            "contribution_ids": [
                "R198935",
                "R78434"
            ]
        },
        {
            "instance_id": "R112387xR108208",
            "comparison_id": "R112387",
            "paper_id": "R108208",
            "text": "Facilitating developer-user interactions with mobile app review digests \"as users are interacting with a large of mobile apps under various usage contexts, user involvements in an app design process has become a critical issue. despite this fact, existing apps or app store platforms only provide a limited form of user involvements such as posting app reviews and sending email reports. while building a unified platform for facilitating user involvements with various apps is our ultimate goal, we present our preliminary work on handling developers' information overload attributed to a large number of app comments. to address this issue, we first perform a simple content analysis on app reviews from the developer's standpoint. we then propose an algorithm that automatically identifies informative reviews reflecting user involvements. the preliminary evaluation results document the efficiency of our algorithm.\"",
            "contribution_ids": [
                "R108210"
            ]
        },
        {
            "instance_id": "R112387xR112033",
            "comparison_id": "R112387",
            "paper_id": "R112033",
            "text": "Listening to the Crowd for the Release Planning of Mobile Apps the market for mobile apps is getting bigger and bigger, and it is expected to be worth over 100 billion dollars in 2020. to have a chance to succeed in such a competitive environment, developers need to build and maintain high-quality apps, continuously astonishing their users with the coolest new features. mobile app marketplaces allow users to release reviews. despite reviews are aimed at recommending apps among users, they also contain precious information for developers, reporting bugs and suggesting new features. to exploit such a source of information, developers are supposed to manually read user reviews, something not doable when hundreds of them are collected per day. to help developers dealing with such a task, we developed clap (crowd listener for release planning), a web application able to (i) categorize user reviews based on the information they carry out, (ii) cluster together related reviews, and (iii) prioritize the clusters of reviews to be implemented when planning the subsequent app release. we evaluated all the steps behind clap, showing its high accuracy in categorizing and clustering reviews and the meaningfulness of the recommended prioritizations. also, given the availability of clap as a working tool, we assessed its applicability in industrial environments.",
            "contribution_ids": [
                "R112040"
            ]
        },
        {
            "instance_id": "R112387xR112044",
            "comparison_id": "R112387",
            "paper_id": "R112044",
            "text": "Can app changelogs improve requirements classification from app reviews?: an exploratory study [background] recent research on mining app reviews for software evolution indicated that the elicitation and analysis of user requirements can benefit from supplementing user reviews by data from other sources. however, only a few studies reported results of leveraging app changelogs together with app reviews. [aims] motivated by those findings, this exploratory experimental study looks into the role of app changelogs in the classification of requirements derived from app reviews. we aim at understanding if the use of app changelogs can lead to more accurate identification and classification of functional and non-functional requirements from app reviews. we also want to know which classification technique works better in this context. [method] we did a case study on the effect of app changelogs on automatic classification of app reviews. specifically, manual labeling, text preprocessing, and four supervised machine learning algorithms were applied to a series of experiments, varying in the number of app changelogs in the experimental data. [results] we compared the accuracy of requirements classification from app reviews, by training the four classifiers with varying combinations of app reviews and changelogs. among the four algorithms, na\u00efve bayes was found to be more accurate for categorizing app reviews. [conclusions] the results show that official app changelogs did not contribute to more accurate identification and classification of requirements from app reviews. in addition, na\u00efve bayes seems to be more suitable for our further research on this topic.",
            "contribution_ids": [
                "R112046"
            ]
        },
        {
            "instance_id": "R114155xR76123",
            "comparison_id": "R114155",
            "paper_id": "R76123",
            "text": "Crowdsourcing to elicit requirements for MyERP application crowdsourcing is an emerging method to collect requirements for software systems. applications seeking global acceptance need to meet the expectations of a wide range of users. collecting requirements and arriving at consensus with a wide range of users is difficult using traditional method of requirements elicitation. this paper presents crowdsourcing based approach for german medium-size software company myerp that might help the company to get access to requirements from non-german customers. we present the tasks involved in the proposed solution that would help the company meet the goal of eliciting requirements at a fast pace with non-german customers.",
            "contribution_ids": [
                "R76125"
            ]
        },
        {
            "instance_id": "R114155xR111441",
            "comparison_id": "R114155",
            "paper_id": "R111441",
            "text": "Crowd Out the Competition myerp is a fictional developer of an enterprise resource planning (erp) system. driven by the competition, they face the challenge of losing market share if they fail to de-ploy a software as a service (saas) erp system to the european market quickly, but with high quality product. this also means that the requirements engineering (re) activities will have to be performed efficiently and provide solid results. an additional problem they face is that their (potential) stakeholders are phys-ically distributed, it makes sense to consider them a \"crowd\". this competition paper suggests a crowd-based re approach that first identifies the crowd, then collects and analyzes their feedback to derive wishes and needs, and validate the results through prototyping. for this, techniques are introduced that have so far been rarely employed within re, but more \"traditional\" re techniques, will also be integrated and/or adapted to attain the best possible result in the case of myerp.",
            "contribution_ids": [
                "R111443"
            ]
        },
        {
            "instance_id": "R114155xR112407",
            "comparison_id": "R114155",
            "paper_id": "R112407",
            "text": "Which Feature is Unusable? Detecting Usability and User Experience Issues from User Reviews \"usability and user experience (uux) strongly affect software quality and success. user reviews allow software users to report uux issues. however, this information can be difficult to access due to the varying quality of the reviews, its large numbers and unstructured nature. in this work we propose an approach to automatically detect the uux strengths and issues of software features according to user reviews. we use a collocation algorithm for extracting the features, lexical sentiment analysis for uncovering users' satisfaction about a particular feature and machine learning for detecting the specific uux issues affecting the software application. additionally, we present two visualizations of the results. an initial evaluation of the approach against human judgement obtained mixed results.\"",
            "contribution_ids": [
                "R112409"
            ]
        },
        {
            "instance_id": "R114155xR112434",
            "comparison_id": "R114155",
            "paper_id": "R112434",
            "text": "Users \u00e2\u0080\u0094 The Hidden Software Product Quality Experts?: A Study on How App Users Report Quality Aspects in Online Reviews [context and motivation] research on eliciting requirements from a large number of online reviews using automated means has focused on functional aspects. assuring the quality of an app is vital for its success. this is why user feedback concerning quality issues should be considered as well [question/problem] but to what extent do online reviews of apps address quality characteristics? and how much potential is there to extract such knowledge through automation? [principal ideas/results] by tagging online reviews, we found that users mainly write about \"usability\" and \"reliability\", but the majority of statements are on a subcharacteristic level, most notably regarding \"operability\", \"adaptability\", \"fault tolerance\", and \"interoperability\". a set of 16 language patterns regarding \"usability\" correctly identified 1,528 statements from a large dataset far more efficiently than our manual analysis of a small subset. [contribution] we found that statements can especially be derived from online reviews about qualities by which users are directly affected, although with some ambiguity. language patterns can identify statements about qualities with high precision, though the recall is modest at this time. nevertheless, our results have shown that online reviews are an unused big data source for quality requirements.",
            "contribution_ids": [
                "R195568",
                "R112436"
            ]
        },
        {
            "instance_id": "R114155xR113008",
            "comparison_id": "R114155",
            "paper_id": "R113008",
            "text": "Canary: Extracting Requirements-Related Information from Online Discussions online discussions about software applications generate a large amount of requirements-related information. this information can potentially be usefully applied in requirements engineering; however currently, there are few systematic approaches for extracting such information. to address this gap, we propose canary, an approach for extracting and querying requirements-related information in online discussions. the highlight of our approach is a high-level query language that combines aspects of both requirements and discussion in online forums. we give the semantics of the query language in terms of relational databases and sql. we demonstrate the usefulness of the language using examples on real data extracted from online discussions. our approach relies on human annotations of online discussions. we highlight the subtleties involved in interpreting the content in online discussions and the assumptions and choices we made to effectively address them. we demonstrate the feasibility of generating high-quality annotations by obtaining them from lay amazon mechanical turk users.",
            "contribution_ids": [
                "R195498",
                "R113010"
            ]
        },
        {
            "instance_id": "R114155xR113030",
            "comparison_id": "R114155",
            "paper_id": "R113030",
            "text": "Conceptualising, extracting and analysing requirements arguments in users' forums: The CrowdRE\u00e2\u0080\u0090Arg framework \"due to the pervasive use of online forums and social media, users' feedback are more accessible today and can be used within a requirements engineering context. however, such information is often fragmented, with multiple perspectives from multiple parties involved during on\u2010going interactions. in this paper, the authors propose a crowd\u2010based requirements engineering approach by argumentation (crowdre\u2010arg). the framework is based on the analysis of the textual conversations found in user forums, identification of features, issues and the arguments that are in favour or opposing a given requirements statement. the analysis is to generate an argumentation model of the involved user statements, retrieve the conflicting\u2010viewpoints, reason about the winning\u2010arguments and present that to systems analysts to make informed\u2010requirements decisions. for this purpose, the authors adopted a bipolar argumentation framework and a coalition\u2010based meta\u2010argumentation framework as well as user voting techniques. the crowdre\u2010arg approach and its algorithms are illustrated through two sample conversations threads taken from the reddit forum. additionally, the authors devised algorithms that can identify conflict\u2010free features or issues based on their supporting and attacking arguments. the authors tested these machine learning algorithms on a set of 3,051 user comments, preprocessed using the content analysis technique. the results show that the proposed algorithms correctly and efficiently identify conflict\u2010free features and issues along with their winning arguments.\"",
            "contribution_ids": [
                "R113033"
            ]
        },
        {
            "instance_id": "R114155xR113173",
            "comparison_id": "R114155",
            "paper_id": "R113173",
            "text": "Software Feature Request Detection in Issue Tracking Systems communication about requirements is often handled in issue tracking systems, especially in a distributed setting. as issue tracking systems also contain bug reports or programming tasks, the software feature requests of the users are often difficult to identify. this paper investigates natural language processing and machine learning features to detect software feature requests in natural language data of issue tracking systems. it compares traditional linguistic machine learning features, such as \"bag of words\", with more advanced features, such as subject-action-object, and evaluates combinations of machine learning features derived from the natural language and features taken from the issue tracking system meta-data. our investigation shows that some combinations of machine learning features derived from natural language and the issue tracking system meta-data outperform traditional approaches. we show that issues or data fields (e.g. descriptions or comments), which contain software feature requests, can be identified reasonably well, but hardly the exact sentence. finally, we show that the choice of machine learning algorithms should depend on the goal, e.g. maximization of the detection rate or balance between detection rate and precision. in addition, the paper contributes a double coded gold standard and an open-source implementation to further pursue this topic.",
            "contribution_ids": [
                "R113175"
            ]
        },
        {
            "instance_id": "R114155xR113204",
            "comparison_id": "R114155",
            "paper_id": "R113204",
            "text": "Mining Android App Descriptions for Permission Requirements Recommendation \"during the development or maintenance of an android app, the app developer needs to determine the app's security and privacy requirements such as permission requirements. permission requirements include two folds. first, what permissions (i.e., access to sensitive resources, e.g., location or contact list) the app needs to request. second, how to explain the reason of permission usages to users. in this paper, we focus on the multiple challenges that developers face when creating permission-usage explanations. we propose a novel framework, clap, that mines potential explanations from the descriptions of similar apps. clap leverages information retrieval and text summarization techniques to find frequent permission usages. we evaluate clap on a large dataset containing 1.4 million android apps. the evaluation results outperform existing state-of-the-art approaches, showing great promise of clap as a tool for assisting developers and permission requirements discovery.\"",
            "contribution_ids": [
                "R195127",
                "R113206"
            ]
        },
        {
            "instance_id": "R12250xR12231",
            "comparison_id": "R12250",
            "paper_id": "R12231",
            "text": "Novel coronavirus 2019-nCoV: early estimation of epidemiological parameters and epidemic predictions abstract since first identified, the epidemic scale of the recently emerged novel coronavirus (2019-ncov) in wuhan, china, has increased rapidly, with cases arising across china and other countries and regions. using a transmission model, we estimate a basic reproductive number of 3.11 (95%ci, 2.39\u20134.13); 58\u201376% of transmissions must be prevented to stop increasing; wuhan case ascertainment of 5.0% (3.6\u20137.4); 21022 (11090\u201333490) total infections in wuhan 1 to 22 january. changes to previous version case data updated to include 22 jan 2020; we did not use cases reported after this period as cases were reported at the province level hereafter, and large-scale control interventions were initiated on 23 jan 2020; improved likelihood function, better accounting for first 41 confirmed cases, and now using all infections (rather than just cases detected) in wuhan for prediction of infection in international travellers; improved characterization of uncertainty in parameters, and calculation of epidemic trajectory confidence intervals using a more statistically rigorous method; extended range of latent period in sensitivity analysis to reflect reports of up to 6 day incubation period in household clusters; removed travel restriction analysis, as different modelling approaches (e.g. stochastic transmission, rather than deterministic transmission) are more appropriate to such analyses.",
            "contribution_ids": [
                "R12232"
            ]
        },
        {
            "instance_id": "R12251xR36138",
            "comparison_id": "R12251",
            "paper_id": "R36138",
            "text": "Estimating the generation interval for COVID-19 based on symptom onset data abstract background estimating key infectious disease parameters from the covid-19 outbreak is quintessential for modelling studies and guiding intervention strategies. whereas different estimates for the incubation period distribution and the serial interval distribution have been reported, estimates of the generation interval for covid-19 have not been provided. methods we used outbreak data from clusters in singapore and tianjin, china to estimate the generation interval from symptom onset data while acknowledging uncertainty about the incubation period distribution and the underlying transmission network. from those estimates we obtained the proportions pre-symptomatic transmission and reproduction numbers. results the mean generation interval was 5.20 (95%ci 3.78-6.78) days for singapore and 3.95 (95%ci 3.01-4.91) days for tianjin, china when relying on a previously reported incubation period with mean 5.2 and sd 2.8 days. the proportion of pre-symptomatic transmission was 48% (95%ci 32-67%) for singapore and 62% (95%ci 50-76%) for tianjin, china. estimates of the reproduction number based on the generation interval distribution were slightly higher than those based on the serial interval distribution. conclusions estimating generation and serial interval distributions from outbreak data requires careful investigation of the underlying transmission network. detailed contact tracing information is essential for correctly estimating these quantities.",
            "contribution_ids": [
                "R36139",
                "R36140",
                "R36141",
                "R36142"
            ]
        },
        {
            "instance_id": "R12251xR37008",
            "comparison_id": "R12251",
            "paper_id": "R37008",
            "text": "Estimation of the Transmission Risk of the 2019-nCoV and Its Implication for Public Health Interventions since the emergence of the first cases in wuhan, china, the novel coronavirus (2019-ncov) infection has been quickly spreading out to other provinces and neighboring countries. estimation of the basic reproduction number by means of mathematical modeling can be helpful for determining the potential and severity of an outbreak and providing critical information for identifying the type of disease interventions and intensity. a deterministic compartmental model was devised based on the clinical progression of the disease, epidemiological status of the individuals, and intervention measures. the estimations based on likelihood and model analysis show that the control reproduction number may be as high as 6.47 (95% ci 5.71\u20137.23). sensitivity analyses show that interventions, such as intensive contact tracing followed by quarantine and isolation, can effectively reduce the control reproduction number and transmission risk, with the effect of travel restriction adopted by wuhan on 2019-ncov infection in beijing being almost equivalent to increasing quarantine by a 100 thousand baseline value. it is essential to assess how the expensive, resource-intensive measures implemented by the chinese authorities can contribute to the prevention and control of the 2019-ncov infection, and how long they should be maintained. under the most restrictive measures, the outbreak is expected to peak within two weeks (since 23 january 2020) with a significant low peak value. with travel restriction (no imported exposed individuals to beijing), the number of infected individuals in seven days will decrease by 91.14% in beijing, compared with the scenario of no travel restriction.",
            "contribution_ids": [
                "R37009"
            ]
        },
        {
            "instance_id": "R137469xR137380",
            "comparison_id": "R137469",
            "paper_id": "R137380",
            "text": "Deposition of a TMDSO-Based Film by a Non-Equilibrium Atmospheric Pressure DC Plasma Jet: Deposition of a TMDSO-Based Film\u00e2\u0080\u00a6 this work deals with the deposition of thin films using an atmospheric pressure direct current nitrogen plasma jet with tetramethyldisiloxane as precursor. the effect of o-2 flow and plasma discharge power on film deposition rate and film chemical characteristics is investigated in detail by surface profilometry, fourier transform infrared spectroscopy, and x-ray photoelectron spectroscopy. it is found that a higher deposition rate is obtained at higher oxygen flow rates and higher discharge powers. increasing discharge power shows a certain amount of capability to transfer low oxygen content bonds to high oxygen content bonds. organic films can be deposited in a pure nitrogen atmosphere. the film chemical composition can be tuned to a more inorganic structure by admixture of o-2 leading to an increase in sio4 units at high oxygen flow rates.",
            "contribution_ids": [
                "R137382"
            ]
        },
        {
            "instance_id": "R137469xR137398",
            "comparison_id": "R137469",
            "paper_id": "R137398",
            "text": "Transitions Between and Control of Guided and Branching Streamers in DC Nanosecond Pulsed Excited Plasma Jets plasma bullets are ionization fronts created in atmospheric-pressure plasma jets. the propagation behavior of those bullets is, in the literature, explained by the formation of an interface between the inert gas and the ambient air created by the gas flow of the plasma jet, which guides these discharges in the formed gas channel. in this paper, we examine this ionization phenomenon in uniform gases at atmospheric pressure where this interface between two gases is not present. by changing electrical parameters and adding admixtures such as oxygen, nitrogen, and air to the gas flow, the conditions for which plasma bullets are present are investigated. nanosecond time-resolved images have been taken with an iccd camera to observe the propagation behavior of these discharges. it is argued that the inhomogeneous spatial concentration of metastable atoms and ions, due to the laminar gas flow and the operation frequency of the discharge in the range of a few kilohertz, is responsible for the guidance of the ionization fronts. furthermore, conditions have been observed at where the branching of the discharge is stable and reproducible over time in the case of a helium plasma by adding admixtures of oxygen. possible mechanisms for this phenomenon are discussed.",
            "contribution_ids": [
                "R137400"
            ]
        },
        {
            "instance_id": "R137469xR137410",
            "comparison_id": "R137469",
            "paper_id": "R137410",
            "text": "A brush-shaped air plasma jet operated in glow discharge mode at atmospheric pressure using ambient air as working gas, a direct-current plasma jet is developed to generate a brush-shaped plasma plume with fairly large volume. although a direct-current power supply is used, the discharge shows a pulsed characteristic. based on the voltage-current curve and fast photography, the brush-shaped plume, like the gliding arc plasma, is in fact a temporal superposition of a moving discharge filament in an arched shape. during it moves away from the nozzle, the discharge evolves from a low-current arc into a normal glow in one discharge cycle. the emission profile is explained qualitatively based on the dynamics of the plasma brush.",
            "contribution_ids": [
                "R137412"
            ]
        },
        {
            "instance_id": "R137469xR137416",
            "comparison_id": "R137469",
            "paper_id": "R137416",
            "text": "Flux of OH and O radicals onto a surface by an atmospheric-pressure helium plasma jet measured by laser-induced fluorescence the atmospheric-pressure helium plasma jet is of emerging interest as a cutting-edge biomedical device for cancer treatment, wound healing and sterilization. reactive oxygen species such as oh and o radicals are considered to be major factors in the application of biological plasma. in this study, density distribution, temporal behaviour and flux of oh and o radicals on a surface are measured using laser-induced fluorescence. a helium plasma jet is generated by applying pulsed high voltage of 8 kv with 10 khz using a quartz tube with an inner diameter of 4 mm. to evaluate the relation between the surface condition and active species production, three surfaces are used: dry, wet and rat skin. when the helium flow rate is 1.5 l min\u22121, radial distribution of oh density on the rat skin surface shows a maximum density of 1.2 \u00d7 1013 cm\u22123 at the centre of the plasma-mediated area, while o atom density shows a maximum of 1.0 \u00d7 1015 cm\u22123 at 2.0 mm radius from the centre of the plasma-mediated area. their densities in the effluent of the plasma jet are almost constant during the intervals of the discharge pulses because their lifetimes are longer than the pulse interval. their density distribution depends on the helium flow rate and the surface humidity. with these results, oh and o production mechanisms in the plasma jet and their flux onto the surface are discussed.",
            "contribution_ids": [
                "R137418"
            ]
        },
        {
            "instance_id": "R137469xR137422",
            "comparison_id": "R137469",
            "paper_id": "R137422",
            "text": "Phase-resolved measurement of electric charge deposited by an atmospheric pressure plasma jet on a dielectric surface the surface charge distribution deposited by the effluent of a dielectric barrier discharge driven atmospheric pressure plasma jet on a dielectric surface has been studied. for the first time, the deposition of charge was observed phase resolved. it takes place in either one or two events in each half cycle of the driving voltage. the charge transfer could also be detected in the electrode current of the jet. the periodic change of surface charge polarity has been found to correspond well with the appearance of ionized channels left behind by guided streamers (bullets) that have been identified in similar experimental situations. the distribution of negative surface charge turned out to be significantly broader than for positive charge. with increasing distance of the jet nozzle from the target surface, the charge transfer decreases until finally the effluent loses contact and the charge transfer stops.",
            "contribution_ids": [
                "R137424"
            ]
        },
        {
            "instance_id": "R137469xR137429",
            "comparison_id": "R137469",
            "paper_id": "R137429",
            "text": "Plasma Processes and Plasma Sources in Medicine the use of plasma for healthcare can be dated back as far as the middle of the 19th century. only the development of room temperature atmospheric pressure plasma sources in the past decade, however, has opened the new and fast growing interdisciplinary research field of plasma medicine. three main topics can be distinguished: plasma treated implants, plasma decontamination, and plasmas in medical therapy. understanding of the plasma sources and the plasma processes involved is still incomplete. with the aim of a more fundamental insight we investigate plasmas in a) functionalization of implants with antimicrobial as well as cell attachment enhancing surfaces b) atmospheric pressure plasmas (apps) in inactivation of bacteria, decontamination of bottles and food products, as well as medical equipment and c) apps in medical therapy and their effects on cell viability as a means to finding a plasma \u201cdosage\u201d. the possibilities of an application focused designing of plasma sources will be emphasized. on the example of feed gas humidity and its significant influence the importance of determining and controlling unobvious or hidden parameter is demonstrated (\u00a9 2012 wiley\u2010vch verlag gmbh & co. kgaa, weinheim)",
            "contribution_ids": [
                "R137431"
            ]
        },
        {
            "instance_id": "R137469xR137453",
            "comparison_id": "R137469",
            "paper_id": "R137453",
            "text": "Integrated Microwave Atmospheric Plasma Source (IMAPlaS): thermal and spectroscopic properties and antimicrobial effect onB. atrophaeusspores the integrated microwave atmospheric plasma source (imaplas) operating with a microwave resonator at 2.45 ghz driven by a solid-state transistor oscillator generates a core plasma of high temperature (t > 1000 k), therefore producing reactive species such as no very effectively. the effluent of the plasma source is much colder, which enables direct treatment of thermolabile materials or even living tissue. in this study the source was operated with argon, helium and nitrogen with gas flow rates between 0.3 and 1.0 slm. depending on working gas and distance, axial gas temperatures between 30 and 250 \u00b0c were determined in front of the nozzle. reactive species were identified by emission spectroscopy in the spectral range from vacuum ultraviolet to near infrared. the irradiance in the ultraviolet range was also measured. using b. atrophaeus spores to test antimicrobial efficiency, we determined log10-reduction rates of up to a factor of 4.",
            "contribution_ids": [
                "R137455"
            ]
        },
        {
            "instance_id": "R137469xR137456",
            "comparison_id": "R137469",
            "paper_id": "R137456",
            "text": "The antibacterial activity of a microwave argon plasma jet at atmospheric pressure relies mainly on UV-C radiations the main bactericidal sources produced by a microwave induced cold argon plasma jet in open air are identified and their relative proportion in the biocide efficiency of the jet is assessed on planktonic gram-negative bacteria (wild-type strains and deletion mutants of escherichia coli) diluted in water. in these conditions ultraviolet light (uv) most probably in the uv-c region of the electromagnetic spectrum, is responsible for 86.7 \u00b1 3.2% of the observed bactericidal efficiency of the jet whereas hydrogen peroxide represents 9.9 \u00b1 5.5% of it. the exposition level of the bacteria to uv-c radiations is estimated at 20 mj cm\u22122 using a specific photodiode and the influence of the initial bacteria concentration on the apparent antibacterial efficiency of the jet is highlighted.",
            "contribution_ids": [
                "R137458"
            ]
        },
        {
            "instance_id": "R138127xR137522",
            "comparison_id": "R138127",
            "paper_id": "R137522",
            "text": "Paclitaxel-loaded poly(D,L-lactide-co-glycolide) nanoparticles for radiotherapy in hypoxic human tumor cells in vitro radioresistant hypoxic cells may contribute to the failure of radiation therapy in controlling certain tumors. some studies have suggested the radiosensitizing effect of paclitaxel. the poly(d,l-lactide-co-glycolide)(plga) nanoparticles containing paclitaxel were prepared by o/w emulsification-solvent evaporation method. the physicochemical characteristics of the nanoparticles (i.e. encapsulation efficiency, particle size distribution, morphology, in vitro release) were studied. the morphology of the two human tumor cell lines: a carcinoma cervicis (hela) and a hepatoma (hepg2), treated with paclitaxel-loaded nanoparticles was photomicrographed. flow cytometry was used to quantify the number of the tumor cells held in the g2/m phase of the cell cycle. the cellular uptake of nanoparticles was evaluated by transmission electronic microscopy. cell viability was determined by the ability of single cell to form colonies in vitro. the prepared nanoparticles were spherical in shape with size between 200nm and 800nm. the encapsulation efficiency was 85.5\uff05. the release behaviour of paclitaxel from the nanoparticles exhibited a biphasic pattern characterised by a fast initial release during the first 24 h, followed by a slower and continuous release. co-culture of the two tumor cell lines with paclitaxel-loaded nanoparticles demonstrated that the cell morphology was changed and the released paclitaxel retained its bioactivity to block cells in the g2/m phase. the cellular uptake of nanoparticles was observed. the free paclitaxel and paclitaxel-loaded nanoparticles effectively sensitized hypoxic hela and hepg2 cells to radiation. under this experimental condition, the radiosensitization of paclitaxel-loaded nanoparticles was more significant than that of free paclitaxel.keywords: paclitaxel\uff1bdrug delivery\uff1bnanoparticle\uff1bradiotherapy\uff1bhypoxia\uff1bhuman tumor cells\uff1bcellular uptake",
            "contribution_ids": [
                "R137524"
            ]
        },
        {
            "instance_id": "R139050xR138725",
            "comparison_id": "R139050",
            "paper_id": "R138725",
            "text": "Using deep autoencoders to identify abnormal brain structural patterns in neuropsychiatric disorders: A large\u00e2\u0080\u0090scale multi\u00e2\u0080\u0090sample study machine learning is becoming an increasingly popular approach for investigating spatially distributed and subtle neuroanatomical alterations in brain\u2010based disorders. however, some machine learning models have been criticized for requiring a large number of cases in each experimental group, and for resembling a \u201cblack box\u201d that provides little or no insight into the nature of the data. in this article, we propose an alternative conceptual and practical approach for investigating brain\u2010based disorders which aim to overcome these limitations. we used an artificial neural network known as \u201cdeep autoencoder\u201d to create a normative model using structural magnetic resonance imaging data from 1,113 healthy people. we then used this model to estimate total and regional neuroanatomical deviation in individual patients with schizophrenia and autism spectrum disorder using two independent data sets (n =\\u2009263). we report that the model was able to generate different values of total neuroanatomical deviation for each disease under investigation relative to their control group (p <\\u2009.005). furthermore, the model revealed distinct patterns of neuroanatomical deviations for the two diseases, consistent with the existing neuroimaging literature. we conclude that the deep autoencoder provides a flexible and promising framework for assessing total and regional neuroanatomical deviations in neuropsychiatric populations.",
            "contribution_ids": [
                "R138728"
            ]
        },
        {
            "instance_id": "R139050xR138729",
            "comparison_id": "R139050",
            "paper_id": "R138729",
            "text": "fMRIPrep: a robust preprocessing pipeline for functional MRI preprocessing of functional mri (fmri) involves numerous steps to clean and standardize data before statistical analysis. generally, researchers create ad hoc preprocessing workflows for each new dataset, building upon a large inventory of tools available for each step. the complexity of these workflows has snowballed with rapid advances in mr data acquisition and image processing techniques. we introduce fmriprep , an analysis-agnostic tool that addresses the challenge of robust and reproducible preprocessing for task-based and resting fmri data. fmriprep automatically adapts a best-in-breed workflow to the idiosyncrasies of virtually any dataset, ensuring high-quality preprocessing with no manual intervention. by introducing visual assessment checkpoints into an iterative integration framework for software-testing, we show that fmriprep robustly produces high-quality results on a diverse fmri data collection comprising participants from 54 different studies in the openfmri repository. we review the distinctive features of fmriprep in a qualitative comparison to other preprocessing workflows. we demonstrate that fmriprep achieves higher spatial accuracy as it introduces less uncontrolled spatial smoothness than commonly used preprocessing tools. fmriprep has the potential to transform fmri research by equipping neuroscientists with a high-quality, robust, easy-to-use and transparent preprocessing workflow which can help ensure the validity of inference and the interpretability of their results.",
            "contribution_ids": [
                "R138740"
            ]
        },
        {
            "instance_id": "R139050xR138776",
            "comparison_id": "R139050",
            "paper_id": "R138776",
            "text": "Applying deep neural networks to unstructured text notes in electronic medical records for phenotyping youth depression background we report a study of machine learning applied to the phenotyping of psychiatric diagnosis for research recruitment in youth depression, conducted with 861 labelled electronic medical records (emrs) documents. a model was built that could accurately identify individuals who were suitable candidates for a study on youth depression. objective our objective was a model to identify individuals who meet inclusion criteria as well as unsuitable patients who would require exclusion. methods our methods included applying a system that coded the emr documents by removing personally identifying information, using two psychiatrists who labelled a set of emr documents (from which the 861 came), using a brute force search and training a deep neural network for this task. findings according to a cross-validation evaluation, we describe a model that had a specificity of 97% and a sensitivity of 45% and a second model with a specificity of 53% and a sensitivity of 89%. we combined these two models into a third one (sensitivity 93.5%; specificity 68%; positive predictive value (precision) 77%) to generate a list of most suitable candidates in support of research recruitment. conclusion our efforts are meant to demonstrate the potential for this type of approach for patient recruitment purposes but it should be noted that a larger sample size is required to build a truly reliable recommendation system. clinical implications future efforts will employ alternate neural network algorithms available and other machine learning methods.",
            "contribution_ids": [
                "R138778"
            ]
        },
        {
            "instance_id": "R139050xR138807",
            "comparison_id": "R139050",
            "paper_id": "R138807",
            "text": "DeepBipolar: Identifying genomic mutations for bipolar disorder via deep learning bipolar disorder, also known as manic depression, is a brain disorder that affects the brain structure of a patient. it results in extreme mood swings, severe states of depression, and overexcitement simultaneously. it is estimated that roughly 3% of the population of the united states (about 5.3 million adults) suffers from bipolar disorder. recent research efforts like the twin studies have demonstrated a high heritability factor for the disorder, making genomics a viable alternative for detecting and treating bipolar disorder, in addition to the conventional lengthy and costly postsymptom clinical diagnosis. motivated by this study, leveraging several emerging deep learning algorithms, we design an end\u2010to\u2010end deep learning architecture (called deepbipolar) to predict bipolar disorder based on limited genomic data. deepbipolar adopts the deep convolutional neural network (dcnn) architecture that automatically extracts features from genotype information to predict the bipolar phenotype. we participated in the critical assessment of genome interpretation (cagi) bipolar disorder challenge and deepbipolar was considered the most successful by the independent assessor. in this work, we thoroughly evaluate the performance of deepbipolar and analyze the type of signals we believe could have affected the classifier in distinguishing the case samples from the control set.",
            "contribution_ids": [
                "R138810"
            ]
        },
        {
            "instance_id": "R139050xR138865",
            "comparison_id": "R139050",
            "paper_id": "R138865",
            "text": "Detection of mood disorder using speech emotion profiles and LSTM \"in mood disorder diagnosis, bipolar disorder (bd) patients are often misdiagnosed as unipolar depression (ud) on initial presentation. it is crucial to establish an accurate distinction between bd and ud to make a correct and early diagnosis, leading to improvements in treatment and course of illness. to deal with this misdiagnosis problem, in this study, we experimented on eliciting subjects' emotions by watching six eliciting emotional video clips. after watching each video clips, their speech responses were collected when they were interviewing with a clinician. in mood disorder detection, speech emotions play an import role to detect manic or depressive symptoms. therefore, speech emotion profiles (ep) are obtained by using the support vector machine (svm) which are built via speech features adapted from selected databases using a denoising autoencoder-based method. finally, a long short-term memory (lstm) recurrent neural network is employed to characterize the temporal information of the eps with respect to six emotional videos. comparative experiments clearly show the promising advantage and efficacy of the lstm-based approach for mood disorder detection.\"",
            "contribution_ids": [
                "R138867"
            ]
        },
        {
            "instance_id": "R139050xR138951",
            "comparison_id": "R139050",
            "paper_id": "R138951",
            "text": "Human Behaviour-Based Automatic Depression Analysis Using Hand-Crafted Statistics and Deep Learned Spectral Features depression is a serious mental disorder that affects millions of people all over the world. traditional clinical diagnosis methods are subjective, complicated and need extensive participation of experts. audio-visual automatic depression analysis systems predominantly base their predictions on very brief sequential segments, sometimes as little as one frame. such data contains much redundant information, causes a high computational load, and negatively affects the detection accuracy. final decision making at the sequence level is then based on the fusion of frame or segment level predictions. however, this approach loses longer term behavioural correlations, as the behaviours themselves are abstracted away by the frame-level predictions. we propose to on the one hand use automatically detected human behaviour primitives such as gaze directions, facial action units (au), etc. as low-dimensional multi-channel time series data, which can then be used to create two sequence descriptors. the first calculates the sequence-level statistics of the behaviour primitives and the second casts the problem as a convolutional neural network problem operating on a spectral representation of the multichannel behaviour signals. the results of depression detection (binary classification) and severity estimation (regression) experiments conducted on the avec 2016 daic-woz database show that both methods achieved significant improvement compared to the previous state of the art in terms of the depression severity estimation.",
            "contribution_ids": [
                "R138953"
            ]
        },
        {
            "instance_id": "R139050xR138661",
            "comparison_id": "R139050",
            "paper_id": "R138661",
            "text": "Clinical data Neuroimage data effective discrimination of attention deficit hyperactivity disorder (adhd) using imaging and functional biomarkers would have fundamental influence on public health. in usual, the discrimination is based on the standards of american psychiatric association. in this paper, we modified one of the deep learning method on structure and parameters according to the properties of adhd data, to discriminate adhd on the unique public dataset of adhd-200. we predicted the subjects as control, combined, inattentive or hyperactive through their frequency features. the results achieved improvement greatly compared to the performance released by the competition. besides, the imbalance in datasets of deep learning model influenced the results of classification. as far as we know, it is the first time that the deep learning method has been used for the discrimination of adhd with fmri data.",
            "contribution_ids": [
                "R138663"
            ]
        },
        {
            "instance_id": "R139050xR138702",
            "comparison_id": "R139050",
            "paper_id": "R138702",
            "text": "3D CNN Based Automatic Diagnosis of Attention Deficit Hyperactivity Disorder Using Functional and Structural MRI attention deficit hyperactivity disorder (adhd) is one of the most common mental-health disorders. as a neurodevelopment disorder, neuroimaging technologies, such as magnetic resonance imaging (mri), coupled with machine learning algorithms, are being increasingly explored as biomarkers in adhd. among various machine learning methods, deep learning has demonstrated excellent performance on many imaging tasks. with the availability of publically-available, large neuroimaging data sets for training purposes, deep learning-based automatic diagnosis of psychiatric disorders can become feasible. in this paper, we develop a deep learning-based adhd classification method via 3-d convolutional neural networks (cnns) applied to mri scans. since deep neural networks may utilize millions of parameters, even the large number of mri samples in pooled data sets is still relatively limited if one is to learn discriminative features from the raw data. instead, here we propose to first extract meaningful 3-d low-level features from functional mri (fmri) and structural mri (smri) data. furthermore, inspired by radiologists\u2019 typical approach for examining brain images, we design a 3-d cnn model to investigate the local spatial patterns of mri features. finally, we discover that brain functional and structural information are complementary, and design a multi-modality cnn architecture to combine fmri and smri features. evaluations on the hold-out testing data of the adhd-200 global competition shows that the proposed multi-modality 3-d cnn approach achieves the state-of-the-art accuracy of 69.15% and outperforms reported classifiers in the literature, even with fewer training samples. we suggest that multi-modality classification will be a promising direction to find potential neuroimaging biomarkers of neurodevelopment disorders.",
            "contribution_ids": [
                "R138705"
            ]
        },
        {
            "instance_id": "R139050xR138876",
            "comparison_id": "R139050",
            "paper_id": "R138876",
            "text": "Mood disorder identification using deep bottleneck features of elicited speech in the diagnosis of mental health disorder, a large portion of the bipolar disorder (bd) patients is likely to be misdiagnosed as unipolar depression (ud) on initial presentation. as speech is the most natural way to express emotion, this work focuses on tracking emotion profile of elicited speech for short-term mood disorder identification. in this work, the deep scattering spectrum (dss) and low level descriptors (llds) of the elicited speech signals are extracted as the speech features. the hierarchical spectral clustering (hsc) algorithm is employed to adapt the emotion database to the mood disorder database to alleviate the data bias problem. the denoising autoencoder is then used to extract the bottleneck features of dss and llds for better representation. based on the bottleneck features, a long short term memory (lstm) is applied to generate the time-varying emotion profile sequence. finally, given the emotion profile sequence, the hmm-based identification and verification model is used to determine mood disorder. this work collected the elicited emotional speech data from 15 bds, 15 uds and 15 healthy controls for system training and evaluation. five-fold cross validation was employed for evaluation. experimental results show that the system using the bottleneck feature achieved an identification accuracy of 73.33%, improving by 8.89%, compared to that without bottleneck features. furthermore, the system with verification mechanism, improving by 4.44%, outperformed that without verification.",
            "contribution_ids": [
                "R138878"
            ]
        },
        {
            "instance_id": "R139050xR138969",
            "comparison_id": "R139050",
            "paper_id": "R138969",
            "text": "Artificial Intelligent System for Automatic Depression Level Analysis Through Visual and Vocal Expressions a human being\u2019s cognitive system can be simulated by artificial intelligent systems. machines and robots equipped with cognitive capability can automatically recognize a humans mental state through their gestures and facial expressions. in this paper, an artificial intelligent system is proposed to monitor depression. it can predict the scales of beck depression inventory ii (bdi-ii) from vocal and visual expressions. first, different visual features are extracted from facial expression images. deep learning method is utilized to extract key visual features from the facial expression frames. second, spectral low-level descriptors and mel-frequency cepstral coefficients features are extracted from short audio segments to capture the vocal expressions. third, feature dynamic history histogram (fdhh) is proposed to capture the temporal movement on the feature space. finally, these fdhh and audio features are fused using regression techniques for the prediction of the bdi-ii scales. the proposed method has been tested on the public audio/visual emotion challenges 2014 dataset as it is tuned to be more focused on the study of depression. the results outperform all the other existing methods on the same dataset.",
            "contribution_ids": [
                "R138972"
            ]
        },
        {
            "instance_id": "R139050xR138984",
            "comparison_id": "R139050",
            "paper_id": "R138984",
            "text": "Cell-Coupled Long Short-Term Memory With $L$ -Skip Fusion Mechanism for Mood Disorder Detection Through Elicited Audiovisual Features in early stages, patients with bipolar disorder are often diagnosed as having unipolar depression in mood disorder diagnosis. because the long-term monitoring is limited by the delayed detection of mood disorder, an accurate and one-time diagnosis is desirable to avoid delay in appropriate treatment due to misdiagnosis. in this paper, an elicitation-based approach is proposed for realizing a one-time diagnosis by using responses elicited from patients by having them watch six emotion-eliciting videos. after watching each video clip, the conversations, including patient facial expressions and speech responses, between the participant and the clinician conducting the interview were recorded. next, the hierarchical spectral clustering algorithm was employed to adapt the facial expression and speech response features by using the extended cohn\u2013kanade and enterface databases. a denoizing autoencoder was further applied to extract the bottleneck features of the adapted data. then, the facial and speech bottleneck features were input into support vector machines to obtain speech emotion profiles (eps) and the modulation spectrum (ms) of the facial action unit sequence for each elicited response. finally, a cell-coupled long short-term memory (lstm) network with an $l$ -skip fusion mechanism was proposed to model the temporal information of all elicited responses and to loosely fuse the eps and the ms for conducting mood disorder detection. the experimental results revealed that the cell-coupled lstm with the $l$ -skip fusion mechanism has promising advantages and efficacy for mood disorder detection.",
            "contribution_ids": [
                "R138988"
            ]
        },
        {
            "instance_id": "R139050xR138992",
            "comparison_id": "R139050",
            "paper_id": "R138992",
            "text": "User-level psychological stress detection from social media using deep neural network \"it is of significant importance to detect and manage stress before it turns into severe problems. however, existing stress detection methods usually rely on psychological scales or physiological devices, making the detection complicated and costly. in this paper, we explore to automatically detect individuals' psychological stress via social media. employing real online micro-blog data, we first investigate the correlations between users' stress and their tweeting content, social engagement and behavior patterns. then we define two types of stress-related attributes: 1) low-level content attributes from a single tweet, including text, images and social interactions; 2) user-scope statistical attributes through their weekly micro-blog postings, leveraging information of tweeting time, tweeting types and linguistic styles. to combine content attributes with statistical attributes, we further design a convolutional neural network (cnn) with cross autoencoders to generate user-scope content attributes from low-level content attributes. finally, we propose a deep neural network (dnn) model to incorporate the two types of user-scope attributes to detect users' psychological stress. we test the trained model on four different datasets from major micro-blog platforms including sina weibo, tencent weibo and twitter. experimental results show that the proposed model is effective and efficient on detecting psychological stress from micro-blog data. we believe our model would be useful in developing stress detection tools for mental health agencies and individuals.\"",
            "contribution_ids": [
                "R138994"
            ]
        },
        {
            "instance_id": "R139050xR138998",
            "comparison_id": "R139050",
            "paper_id": "R138998",
            "text": "Psychological stress detection from cross-media microblog data using Deep Sparse Neural Network \"long-term stress may lead to many severe physical and mental problems. traditional psychological stress detection usually relies on the active individual participation, which makes the detection labor-consuming, time-costing and hysteretic. with the rapid development of social networks, people become more and more willing to share moods via microblog platforms. in this paper, we propose an automatic stress detection method from cross-media microblog data. we construct a three-level framework to formulate the problem. we first obtain a set of low-level features from the tweets. then we define and extract middle-level representations based on psychological and art theories: linguistic attributes from tweets' texts, visual attributes from tweets' images, and social attributes from tweets' comments, retweets and favorites. finally, a deep sparse neural network is designed to learn the stress categories incorporating the cross-media attributes. experiment results show that the proposed method is effective and efficient on detecting psychological stress from microblog data.\"",
            "contribution_ids": [
                "R139000"
            ]
        },
        {
            "instance_id": "R139190xR139077",
            "comparison_id": "R139190",
            "paper_id": "R139077",
            "text": "Spatially resolved diagnostics on a microscale atmospheric pressure plasma jet despite enormous potential for technological applications, fundamentals of stable non-equilibrium micro-plasmas at ambient pressure are still only partly understood. micro-plasma jets are one sub-group of these plasma sources. for an understanding it is particularly important to analyse transport phenomena of energy and particles within and between the core and effluent of the discharge. the complexity of the problem requires the combination and correlation of various highly sophisticated diagnostics yielding different information with an extremely high temporal and spatial resolution. a specially designed rf microscale atmospheric pressure plasma jet (\u03bc-appj) provides excellent access for optical diagnostics to the discharge volume and the effluent region. this allows detailed investigations of the discharge dynamics and energy transport mechanisms from the discharge to the effluent. here we present examples for diagnostics applicable to different regions and combine the results. the diagnostics applied are optical emission spectroscopy (oes) in the visible and ultraviolet and two-photon absorption laser-induced fluorescence spectroscopy. by the latter spatially resolved absolutely calibrated density maps of atomic oxygen have been determined for the effluent. oes yields an insight into energy transport mechanisms from the core into the effluent. the first results of spatially and phase-resolved oes measurements of the discharge dynamics of the core are presented.",
            "contribution_ids": [
                "R139169"
            ]
        },
        {
            "instance_id": "R139190xR139080",
            "comparison_id": "R139190",
            "paper_id": "R139080",
            "text": "Diagnostics on an atmospheric pressure plasma jet the atmospheric pressure plasma jet (appj) is a homogeneous non-equilibrium discharge at ambient pressure. it operates with a noble base gas and a percentage-volume admixture of a molecular gas. applications of the discharge are mainly based on reactive species in the effluent. the effluent region of a discharge operated in helium with an oxygen admixture has been investigated. the optical emission from atomic oxygen decreases with distance from the discharge but can still be observed several centimetres in the effluent. ground state atomic oxygen, measured using absolutely calibrated two-photon laser induced fluorescence spectroscopy, shows a similar behaviour. detailed understanding of energy transport mechanisms requires investigations of the discharge volume and the effluent region. an atmospheric pressure plasma jet has been designed providing excellent diagnostics access and a simple geometry ideally suited for modelling and simulation. laser spectroscopy and optical emission spectroscopy can be applied in the discharge volume and the effluent region.",
            "contribution_ids": [
                "R139170"
            ]
        },
        {
            "instance_id": "R139190xR139086",
            "comparison_id": "R139190",
            "paper_id": "R139086",
            "text": "Generation of atomic oxygen in the effluent of an atmospheric pressure plasma jet \"the planar 13.56\\u2009mhz rf-excited low temperature atmospheric pressure plasma jet (appj) investigated in this study is operated with helium feed gas and a small molecular oxygen admixture. the effluent leaving the discharge through the jet's nozzle contains very few charged particles and a high reactive oxygen species' density. as its main reactive radical, essential for numerous applications, the ground state atomic oxygen density in the appj's effluent is measured spatially resolved with two-photon absorption laser induced fluorescence spectroscopy. the atomic oxygen density at the nozzle reaches a value of \u223c1016\\u2009cm\u22123. even at several centimetres distance still 1% of this initial atomic oxygen density can be detected. optical emission spectroscopy (oes) reveals the presence of short living excited oxygen atoms up to 10\\u2009cm distance from the jet's nozzle. the measured high ground state atomic oxygen density and the unaccounted for presence of excited atomic oxygen require further investigations on a possible energy transfer from the appj's discharge region into the effluent: energetic vacuum ultraviolet radiation, measured by oes down to 110\\u2009nm, reaches far into the effluent where it is presumed to be responsible for the generation of atomic oxygen.4 this study forms part of: s reuter 2007 formation mechanisms of atomic oxygen in an atmospheric pressure plasma jet characterised by spectroscopic methods dissertation duisburg-essen university and was presented at the 59th gaseous electronics conference (gec) (columbus, oh).\"",
            "contribution_ids": [
                "R139172"
            ]
        },
        {
            "instance_id": "R139190xR139089",
            "comparison_id": "R139190",
            "paper_id": "R139089",
            "text": "The dynamics of radio-frequency driven atmospheric pressure plasma jets the complex dynamics of radio-frequency driven atmospheric pressure plasma jets is investigated using various optical diagnostic techniques and numerical simulations. absolute number densities of ground state atomic oxygen radicals in the plasma effluent are measured by two-photon absorption laser induced fluorescence spectroscopy (talif). spatial profiles are compared with (vacuum) ultra-violet radiation from excited states of atomic oxygen and molecular oxygen, respectively. the excitation and ionization dynamics in the plasma core are dominated by electron impact and observed by space and phase resolved optical emission spectroscopy (proes). the electron dynamics is governed through the motion of the plasma boundary sheaths in front of the electrodes as illustrated in numerical simulations using a hybrid code based on fluid equations and kinetic treatment of electrons.",
            "contribution_ids": [
                "R139173"
            ]
        },
        {
            "instance_id": "R139190xR139106",
            "comparison_id": "R139190",
            "paper_id": "R139106",
            "text": "Concepts and characteristics of the \u00e2\u0080\u0098COST Reference Microplasma Jet\u00e2\u0080\u0099 biomedical applications of non-equilibrium atmospheric pressure plasmas have attracted intense interest in the past few years. many plasma sources of diverse design have been proposed for these applications, but the relationship between source characteristics and application performance is not well-understood, and indeed many sources are poorly characterized. this circumstance is an impediment to progress in application development. a reference source with well-understood and highly reproducible characteristics may be an important tool in this context. researchers around the world should be able to compare the characteristics of their own sources and also their results with this device. in this paper, we describe such a reference source, developed from the simple and robust micro-scaled atmospheric pressure plasma jet (\u03bc-appj) concept. this development occurred under the auspices of cost action mp1101 \u2018biomedical applications of atmospheric pressure plasmas\u2019. gas contamination and power measurement are shown to be major causes of irreproducible results in earlier source designs. these problems are resolved in the reference source by refinement of the mechanical and electrical design and by specifying an operating protocol. these measures are shown to be absolutely necessary for reproducible operation. they include the integration of current and voltage probes into the jet. the usual combination of matching unit and power supply is replaced by an integrated lc power coupling circuit and a 5\\u2009w single frequency generator. the design specification and operating protocol for the reference source are being made freely available.",
            "contribution_ids": [
                "R139179"
            ]
        },
        {
            "instance_id": "R139190xR139118",
            "comparison_id": "R139190",
            "paper_id": "R139118",
            "text": "Determination of NO densities in a surface dielectric barrier discharge using optical emission spectroscopy a new computationally assisted diagnostic to measure no densities in atmospheric-pressure microplasmas by optical emission spectroscopy (oes) is developed and validated against absorption spectroscopy in a volume dielectric barrier discharge (dbd). the oes method is then applied to a twin surface dbd operated in n 2 to measure the no density as a function of the o 2 admixture ( 0.1%\u2013 1%). the underlying rate equation model reveals that no ( a 2 \u03c3 + ) is primarily excited by reactions of the ground state no ( x 2 \u03c0 ) with metastables n 2 ( a 3 \u03c3 u + ).a new computationally assisted diagnostic to measure no densities in atmospheric-pressure microplasmas by optical emission spectroscopy (oes) is developed and validated against absorption spectroscopy in a volume dielectric barrier discharge (dbd). the oes method is then applied to a twin surface dbd operated in n 2 to measure the no density as a function of the o 2 admixture ( 0.1%\u2013 1%). the underlying rate equation model reveals that no ( a 2 \u03c3 + ) is primarily excited by reactions of the ground state no ( x 2 \u03c0 ) with metastables n 2 ( a 3 \u03c3 u + ).",
            "contribution_ids": [
                "R139183"
            ]
        },
        {
            "instance_id": "R139190xR139135",
            "comparison_id": "R139190",
            "paper_id": "R139135",
            "text": "2D spatially resolved O atom density profiles in an atmospheric pressure plasma jet: from the active plasma volume to the effluent abstract \\n two-dimensional spatially resolved absolute atomic oxygen densities are measured within an atmospheric pressure micro plasma jet and in its effluent. the plasma is operated in helium with an admixture of 0.5% of oxygen at 13.56\\u2009mhz and with a power of 1\\u2009w. absolute atomic oxygen densities are obtained using two photon absorption laser induced fluorescence spectroscopy. the results are interpreted based on measurements of the electron dynamics by phase resolved optical emission spectroscopy in combination with a simple model that balances the production of atomic oxygen with its losses due to chemical reactions and diffusion. within the discharge, the atomic oxygen density builds up with a rise time of 600 \u00b5 s along the gas flow and reaches a plateau of 8\\u2009\u00d7 10 15 \\u2009cm \u22123 . in the effluent, the density decays exponentially with a decay time of 180 \u00b5 s (corresponding to a decay length of 3\\u2009mm at a gas flow of 1.0\\u2009slm). it is found that both, the species formation behavior and the maximum distance between the jet nozzle and substrates for possible oxygen treatments of surfaces can be controlled by adjusting the gas flow.",
            "contribution_ids": [
                "R139189"
            ]
        },
        {
            "instance_id": "R139526xR139469",
            "comparison_id": "R139526",
            "paper_id": "R139469",
            "text": "PENYELESAIAN MULTI-OBJECTIVE FLEXIBLE JOB SHOP SCHEDULING PROBLEM  MENGGUNAKAN  HYBRID ALGORITMA IMUN flexible job shop scheduling problem (fjssp) is one of scheduling problems with specification: there is a job to be done in a certain order, each job contains a number of operations and each operation is processed on a machine of some available machine. the purpose of this paper is to solve multi-objective flexible job shop scheduling problem with minimizing the makespan, the biggest workload and the total workload of all machines. because of complexity these problem, a integrated approach immune algorithm (ia) and simulated annealing (sa) algorithm are combined to solve the multi-objective fjssp. a clonal selection is a strategy for generating new antibody based on selecting the antibody for reproduction. sa is used as a local search search algorithm for enhancing the local ability with certain probability to avoid becoming trapped in a local optimum. the simulation result have proved that this hybrid immune algorithm is an efficient and effective approach to solve the multi-objective fjssp",
            "contribution_ids": [
                "R139471"
            ]
        },
        {
            "instance_id": "R139526xR139522",
            "comparison_id": "R139526",
            "paper_id": "R139522",
            "text": "Multisystem Optimization for an Integrated Production Scheduling with Resource Saving Problem in Textile Printing and Dyeing resource saving has become an integral aspect of manufacturing in industry 4.0. this paper proposes a multisystem optimization (mso) algorithm, inspired by implicit parallelism of heuristic methods, to solve an integrated production scheduling with resource saving problem in textile printing and dyeing. first, a real-world integrated production scheduling with resource saving is formulated as a multisystem optimization problem. then, the mso algorithm is proposed to solve multisystem optimization problems that consist of several coupled subsystems, and each of the subsystems may contain multiple objectives and multiple constraints. the proposed mso algorithm is composed of within-subsystem evolution and cross-subsystem migration operators, and the former is to optimize each subsystem by excellent evolution operators and the later is to complete information sharing between multiple subsystems, to accelerate the global optimization of the whole system. performance is tested on a set of multisystem benchmark functions and compared with improved nsga-ii and multiobjective multifactorial evolutionary algorithm (mo-mfea). simulation results show that the mso algorithm is better than compared algorithms for the benchmark functions studied in this paper. finally, the mso algorithm is successfully applied to the proposed integrated production scheduling with resource saving problem, and the results show that mso is a promising algorithm for the studied problem.",
            "contribution_ids": [
                "R139525"
            ]
        },
        {
            "instance_id": "R139567xR139297",
            "comparison_id": "R139567",
            "paper_id": "R139297",
            "text": "What's going on in my city?: recommender systems and electronic participatory budgeting in this paper, we present electronic participatory budgeting (epb) as a novel application domain for recommender systems. on public data from the epb platforms of three major us cities - cambridge, miami and new york city-, we evaluate various methods that exploit heterogeneous sources and models of user preferences to provide personalized recommendations of citizen proposals. we show that depending on characteristics of the cities and their participatory processes, particular methods are more effective than others for each city. this result, together with open issues identified in the paper, call for further research in the area.",
            "contribution_ids": [
                "R139299"
            ]
        },
        {
            "instance_id": "R139567xR138297",
            "comparison_id": "R139567",
            "paper_id": "R138297",
            "text": "A Multi-Agent System for the management of E-Government Services this paper aims at studying the exploitation of intelligent agents for supporting citizens to access e-government services. to this purpose, it proposes a multi-agent system capable of suggesting to the users the most interesting services for them; specifically, these suggestions are computed by taking into account both their exigencies/preferences and the capabilities of the devices they are currently exploiting. the paper first describes the proposed system and, then, reports various experimental results. finally, it presents a comparison between our system and other related ones already presented in the literature.",
            "contribution_ids": [
                "R138299"
            ]
        },
        {
            "instance_id": "R139642xR139605",
            "comparison_id": "R139642",
            "paper_id": "R139605",
            "text": "Device modeling of perovskite solar cells based on structural similarity with thin film inorganic semiconductor solar cells device modeling of ch3nh3pbi3\u2212xcl3 perovskite-based solar cells was performed. the perovskite solar cells employ a similar structure with inorganic semiconductor solar cells, such as cu(in,ga)se2, and the exciton in the perovskite is wannier-type. we, therefore, applied one-dimensional device simulator widely used in the cu(in,ga)se2 solar cells. a high open-circuit voltage of 1.0\\u2009v reported experimentally was successfully reproduced in the simulation, and also other solar cell parameters well consistent with real devices were obtained. in addition, the effect of carrier diffusion length of the absorber and interface defect densities at front and back sides and the optimum thickness of the absorber were analyzed. the results revealed that the diffusion length experimentally reported is long enough for high efficiency, and the defect density at the front interface is critical for high efficiency. also, the optimum absorber thickness well consistent with the thickness range of real devices was derived.",
            "contribution_ids": [
                "R139607"
            ]
        },
        {
            "instance_id": "R139642xR139614",
            "comparison_id": "R139642",
            "paper_id": "R139614",
            "text": "Highly Efficient and Stable Sn-Rich Perovskite Solar Cells by Introducing Bromine compositional engineering of recently arising methylammonium (ma) lead (pb) halide based perovskites is an essential approach for finding better perovskite compositions to resolve still remaining issues of toxic pb, long-term instability, etc. in this work, we carried out crystallographic, morphological, optical, and photovoltaic characterization of compositional masn0.6pb0.4i3-xbrx by gradually introducing bromine (br) into parental pb-sn binary perovskite (masn0.6pb0.4i3) to elucidate its function in sn-rich (sn:pb = 6:4) perovskites. we found significant advances in crystallinity and dense coverage of the perovskite films by inserting the br into sn-rich perovskite lattice. furthermore, light-intensity-dependent open circuit voltage (voc) measurement revealed much suppressed trap-assisted recombination for a proper br-added (x = 0.4) device. these contributed to attaining the unprecedented power conversion efficiency of 12.1% and voc of 0.78 v, which are, to the best of our knowledge, the highest performance in the sn-rich (\u226560%) perovskite solar cells reported so far. in addition, impressive enhancement of photocurrent-output stability and little hysteresis were found, which paves the way for the development of environmentally benign (pb reduction), stable monolithic tandem cells using the developed low band gap (1.24-1.26 ev) masn0.6pb0.4i3-xbrx with suggested composition (x = 0.2-0.4).",
            "contribution_ids": [
                "R139617"
            ]
        },
        {
            "instance_id": "R139642xR139634",
            "comparison_id": "R139642",
            "paper_id": "R139634",
            "text": "Highly Reproducible Sn-Based Hybrid Perovskite Solar Cells with 9% Efficiency the low power conversion efficiency (pce) of tin\u2010based hybrid perovskite solar cells (hpscs) is mainly attributed to the high background carrier density due to a high density of intrinsic defects such as sn vacancies and oxidized species (sn4+) that characterize sn\u2010based hpscs. herein, this study reports on the successful reduction of the background carrier density by more than one order of magnitude by depositing near\u2010single\u2010crystalline formamidinium tin iodide (fasni3) films with the orthorhombic a\u2010axis in the out\u2010of\u2010plane direction. using these highly crystalline films, obtained by mixing a very small amount (0.08 m) of layered (2d) sn perovskite with 0.92 m (3d) fasni3, for the first time a pce as high as 9.0% in a planar p\u2013i\u2013n device structure is achieved. these devices display negligible hysteresis and light soaking, as they benefit from very low trap\u2010assisted recombination, low shunt losses, and more efficient charge collection. this represents a 50% improvement in pce compared to the best reference cell based on a pure fasni3 film using snf2 as a reducing agent. moreover, the 2d/3d\u2010based hpscs show considerable improved stability due to the enhanced robustness of the perovskite film compared to the reference cell.",
            "contribution_ids": [
                "R139637"
            ]
        },
        {
            "instance_id": "R139972xR139938",
            "comparison_id": "R139972",
            "paper_id": "R139938",
            "text": "Micromachined accelerometer with no proof mass this paper describes a revolutionary micromachined accelerometer which is simple, reliable, and inexpensive to make. the operating principle of this accelerometer is based on free-convection heat transfer of a tiny hot air bubble in an enclosed chamber. an experimental device has demonstrated a 0.6 milli-g sensitivity which can theoretically be extended to sub-micro-g level.",
            "contribution_ids": [
                "R139940"
            ]
        },
        {
            "instance_id": "R139972xR139963",
            "comparison_id": "R139972",
            "paper_id": "R139963",
            "text": "Theoretical Modeling, Numerical Simulations and Experimental Study of Micro Thermal Convective Accelerometers we present a one-dimensional (1d) theoretical model for the design analysis of a micro thermal convective accelerometer (mtca). systematical design analysis was conducted on the sensor performance covering the sensor output, sensitivity, and power consumption. the sensor output was further normalized as a function of normalized input acceleration in terms of rayleigh number r $_{\\\\mathrm {a}}$ (the product of grashof number g $_{\\\\mathrm {r}}$ and prandtl number p $_{\\\\mathrm {r}}$ ) for different fluids. a critical rayleigh number ( r a c = 3,000) is founded, for the first time, to determine the boundary between the linear and nonlinear response regime of mtca. based on the proposed 1d model, key parameters, including the location of the detectors, sensor length, thin film thickness, cavity height, heater temperature, and fluid types, were optimized to improve sensor performance. accordingly, a cmos compatible mtca was designed and fabricated based on the theoretical analysis, which showed a high sensitivity of 1,289 mv/g. therefore, this efficient 1d model, one million times faster than cfd simulation, can be a promising tool for the system-level cmos mems design.",
            "contribution_ids": [
                "R139968"
            ]
        },
        {
            "instance_id": "R140131xR74705",
            "comparison_id": "R140131",
            "paper_id": "R74705",
            "text": "Smart Cities and Cultural Heritage \u00e2\u0080\u0093 A Review of Developments and Future Opportunities soja & kanai (2006) use the terms \u201cglobal city region\u201d to refer to \u201ca new metropolitan form characterised by sprawling polycentric networks of urban centres \u2026\u201d such networks are becoming \\nidentified with both the potential and the reality of \u2018smart\u2019 city infrastructures of connected transportation, financial, energy, health, information and cultural systems.",
            "contribution_ids": [
                "R74706",
                "R74710"
            ]
        },
        {
            "instance_id": "R140131xR139975",
            "comparison_id": "R140131",
            "paper_id": "R139975",
            "text": "CULTURAL HERITAGE IN SMART CITY ENVIRONMENTS: THE UPDATE abstract. in 2017 we published a seminal research study in the international archives of the photogrammetry, remote sensing &amp;amp; spatial information sciences about how smart city tools, solutions and applications underpinned historical and cultural heritage of cities at that time (angelidou et al. 2017). we now return to investigate the progress that has been made during the past three years, and specifically whether the weak substantiation of cultural heritage in smart city strategies that we observed in 2017 has been improved. the newest literature suggests that smart cities should capitalize on local strengths and give prominence to local culture and traditions and provides a handful of solutions to this end. however, a more thorough examination of what has been actually implemented reveals a (still) rather immature approach. the smart city cases that were selected for the purposes of this research include tarragona (spain), budapest (hungary) and karlsruhe (germany). for each one we collected information regarding the overarching structure of the initiative, the positioning of cultural heritage and the inclusion of heritage-related smart city applications. we then performed a comparative analysis based on a simplified version of the digital strategy canvas. our findings suggest that a rich cultural heritage and a broader strategic focus on touristic branding and promotion are key ingredients of smart city development in this domain; this is a commonality of all the investigated cities. moreover, three different strategy architectures emerge, representing the different interplays among the smart city, cultural heritage and sustainable urban development. we conclude that a new generation of smart city initiatives is emerging, in which cultural heritage is of increasing importance. this generation tends to associate cultural heritage with social and cultural values, liveability and sustainable urban development.\\n",
            "contribution_ids": [
                "R139978"
            ]
        },
        {
            "instance_id": "R140131xR140106",
            "comparison_id": "R140131",
            "paper_id": "R140106",
            "text": "Smart Cities in Europe \"urban performance currently depends not only on a city's endowment of hard infrastructure (physical capital), but also, and increasingly so, on the availability and quality of knowledge communication and social infrastructure (human and social capital). the latter form of capital is decisive for urban competitiveness. against this background, the concept of the \u201csmart city\u201d has recently been introduced as a strategic device to encompass modern urban production factors in a common framework and, in particular, to highlight the importance of information and communication technologies (icts) in the last 20 years for enhancing the competitive profile of a city. the present paper aims to shed light on the often elusive definition of the concept of the \u201csmart city.\u201d we provide a focused and operational definition of this construct and present consistent evidence on the geography of smart cities in the eu27. our statistical and graphical analyses exploit in depth, for the first time to our knowledge, the most recent version of the urban audit data set in order to analyze the factors determining the performance of smart cities. we find that the presence of a creative class, the quality of and dedicated attention to the urban environment, the level of education, and the accessibility to and use of icts for public administration are all positively correlated with urban wealth. this result prompts the formulation of a new strategic agenda for european cities that will allow them to achieve sustainable urban development and a better urban landscape.\"",
            "contribution_ids": [
                "R140108"
            ]
        },
        {
            "instance_id": "R140348xR140132",
            "comparison_id": "R140348",
            "paper_id": "R140132",
            "text": "DeepWalk: online learning of social representations \"we present deepwalk, a novel approach for learning latent representations of vertices in a network. these latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models. deepwalk generalizes recent advancements in language modeling and unsupervised feature learning (or deep learning) from sequences of words to graphs. deepwalk uses local information obtained from truncated random walks to learn latent representations by treating walks as the equivalent of sentences. we demonstrate deepwalk's latent representations on several multi-label network classification tasks for social networks such as blogcatalog, flickr, and youtube. our results show that deepwalk outperforms challenging baselines which are allowed a global view of the network, especially in the presence of missing information. deepwalk's representations can provide f1 scores up to 10% higher than competing methods when labeled data is sparse. in some experiments, deepwalk's representations are able to outperform all baseline methods while using 60% less training data. deepwalk is also scalable. it is an online learning algorithm which builds useful incremental results, and is trivially parallelizable. these qualities make it suitable for a broad class of real world applications such as network classification, and anomaly detection.\"",
            "contribution_ids": [
                "R140134"
            ]
        },
        {
            "instance_id": "R140348xR140159",
            "comparison_id": "R140348",
            "paper_id": "R140159",
            "text": "LogicENN: A Neural Based Knowledge Graphs Embedding Model with Logical Rules knowledge graph embedding models have gained significant attention in ai research. the aim of knowledge graph embedding is to embed the graphs into a vector space in which the structure of the graph is preserved. recent works have shown that the inclusion of background knowledge, such as logical rules, can improve the performance of embeddings in downstream machine learning tasks. however, so far, most existing models do not allow the inclusion of rules. we address the challenge of including rules and present a new neural based embedding model (logicenn). we prove that logicenn can learn every ground truth of encoded rules in a knowledge graph. to the best of our knowledge, this has not been proved so far for the neural based family of embedding models. moreover, we derive formulae for the inclusion of various rules, including (anti-)symmetric, inverse, irreflexive and transitive, implication, composition, equivalence, and negation. our formulation allows avoiding grounding for implication and equivalence relations. our experiments show that logicenn outperforms the existing models in link prediction.",
            "contribution_ids": [
                "R140160"
            ]
        },
        {
            "instance_id": "R140348xR140164",
            "comparison_id": "R140348",
            "paper_id": "R140164",
            "text": "OPA2Vec: combining formal and informal content of biomedical ontologies to improve similarity-based prediction motivation\\nontologies are widely used in biology for data annotation, integration and analysis. in addition to formally structured axioms, ontologies contain meta-data in the form of annotation axioms which provide valuable pieces of information that characterize ontology classes. annotation axioms commonly used in ontologies include class labels, descriptions or synonyms. despite being a rich source of semantic information, the ontology meta-data are generally unexploited by ontology-based analysis methods such as semantic similarity measures.\\n\\n\\nresults\\nwe propose a novel method, opa2vec, to generate vector representations of biological entities in ontologies by combining formal ontology axioms and annotation axioms from the ontology meta-data. we apply a word2vec model that has been pre-trained on either a corpus or abstracts or full-text articles to produce feature vectors from our collected data. we validate our method in two different ways: first, we use the obtained vector representations of proteins in a similarity measure to predict protein-protein interaction on two different datasets. second, we evaluate our method on predicting gene-disease associations based on phenotype similarity by generating vector representations of genes and diseases using a phenotype ontology, and applying the obtained vectors to predict gene-disease associations using mouse model phenotypes. we demonstrate that opa2vec significantly outperforms existing methods for predicting gene-disease associations. using evidence from mouse models, we apply opa2vec to identify candidate genes for several thousand rare and orphan diseases. opa2vec can be used to produce vector representations of any biomedical entity given any type of biomedical ontology.\\n\\n\\navailability and implementation\\nhttps://github.com/bio-ontology-research-group/opa2vec.\\n\\n\\nsupplementary information\\nsupplementary data are available at bioinformatics online.",
            "contribution_ids": [
                "R140167"
            ]
        },
        {
            "instance_id": "R140348xR140171",
            "comparison_id": "R140348",
            "paper_id": "R140171",
            "text": "On2vec: Embedding-based relation prediction for ontology population populating ontology graphs represents a long-standing problem for the semantic web community. recent advances in translation-based graph embedding methods for populating instance-level knowledge graphs lead to promising new approaching for the ontology population problem. however, unlike instance-level graphs, the majority of relation facts in ontology graphs come with comprehensive semantic relations, which often include the properties of transitivity and symmetry, as well as hierarchical relations. these comprehensive relations are often too complex for existing graph embedding methods, and direct application of such methods is not feasible. hence, we propose on2vec, a novel translation-based graph embedding method for ontology population. on2vec integrates two model components that effectively characterize comprehensive relation facts in ontology graphs. the first is the component-specific model that encodes concepts and relations into low-dimensional embedding spaces without a loss of relational properties; the second is the hierarchy model that performs focused learning of hierarchical relation facts. experiments on several well-known ontology graphs demonstrate the promising capabilities of on2vec in predicting and verifying new relation facts. these promising results also make possible significant improvements in related methods.",
            "contribution_ids": [
                "R140173"
            ]
        },
        {
            "instance_id": "R140543xR139324",
            "comparison_id": "R140543",
            "paper_id": "R139324",
            "text": "Graphene Nanomesh As Highly Sensitive Chemiresistor Gas Sensor graphene is a one atom thick carbon allotrope with all surface atoms that has attracted significant attention as a promising material as the conduction channel of a field-effect transistor and chemical field-effect transistor sensors. however, the zero bandgap of semimetal graphene still limits its application for these devices. in this work, ethanol-chemical vapor deposition (cvd) of a grown p-type semiconducting large-area monolayer graphene film was patterned into a nanomesh by the combination of nanosphere lithography and reactive ion etching and evaluated as a field-effect transistor and chemiresistor gas sensors. the resulting neck-width of the synthesized nanomesh was about \u223c20 nm and was comprised of the gap between polystyrene (ps) spheres that was formed during the reactive ion etching (rie) process. the neck-width and the periodicities of the graphene nanomesh (gnm) could be easily controlled depending on the duration/power of the rie and the size of the ps nanospheres. the fabricated gnm transistor device exhibited promising electronic properties featuring a high drive current and an i(on)/i(off) ratio of about 6, significantly higher than its film counterpart. similarly, when applied as a chemiresistor gas sensor at room temperature, the graphene nanomesh sensor showed excellent sensitivity toward no(2) and nh(3), significantly higher than their film counterparts. the ethanol-based graphene nanomesh sensors exhibited sensitivities of about 4.32%/ppm in no(2) and 0.71%/ppm in nh(3) with limits of detection of 15 and 160 ppb, respectively. our demonstrated studies on controlling the neck width of the nanomesh would lead to further improvement of graphene-based transistors and sensors.",
            "contribution_ids": [
                "R139326",
                "R140513"
            ]
        },
        {
            "instance_id": "R140543xR139343",
            "comparison_id": "R140543",
            "paper_id": "R139343",
            "text": "Exfoliated black phosphorus gas sensing properties at room temperature room temperature gas sensing properties of chemically exfoliated black phosphorus (bp) to oxidizing (no2, co2) and reducing (nh3, h2, co) gases in a dry air carrier have been reported. to study the gas sensing properties of bp, chemically exfoliated bp flakes have been drop casted on si3n4 substrates provided with pt comb-type interdigitated electrodes in n2 atmosphere. scanning electron microscopy and x-ray photoelectron spectroscopy characterizations show respectively the occurrence of a mixed structure, composed of bp coarse aggregates dispersed on bp exfoliated few layer flakes bridging the electrodes, and a clear 2p doublet belonging to bp, which excludes the occurrence of surface oxidation. room temperature electrical tests in dry air show a p-type response of multilayer bp with measured detection limits of 20 ppb and 10 ppm to no2 and nh3 respectively. no response to co and co2 has been detected, while a slight but steady sensitivity to h2 has been recorded. the reported results confirm, on an experimental basis, what was previously theoretically predicted, demonstrating the promising sensing properties of exfoliated bp.",
            "contribution_ids": [
                "R139345",
                "R140503"
            ]
        },
        {
            "instance_id": "R140543xR140539",
            "comparison_id": "R140543",
            "paper_id": "R140539",
            "text": "Porous ZnO Polygonal Nanoflakes: Synthesis, Use in High-Sensitivity NO2 Gas Sensor, and Proposed Mechanism of Gas Sensing unique porous zno polygonal nanoflakes were synthesized by the microwave hydrothermal method. the structural properties of the products were investigated by using x-ray diffraction, scanning electron microscopy, transmission electron microscopy (tem), and high-resolution tem techniques. in situ diffuse reflectance infrared fourier transform spectroscopy technique was employed to investigate the mechanism of no2 sensing. free nitrate ions, nitrate ions, and nitrite anions were the main adsorbed species. n2o was formed via no\u2013 and n2o2\u2013 that were stemmed from no. comparative tests for gas sensing between gas sensors based on the as-prepared porous zno nanoflakes and purchased zno nanoparticles clearly showed that the former exhibited more excellent no2 sensing performances. photoluminescence and x-ray photoelectron spectroscopy spectra further proved that the intensities of donors (oxygen vacancy (vo) and/or zinc interstitial (zni)) and surface oxygen species (o2\u2013 and o2), which were involved in the mechani...",
            "contribution_ids": [
                "R140541"
            ]
        },
        {
            "instance_id": "R141156xR141119",
            "comparison_id": "R141156",
            "paper_id": "R141119",
            "text": "High-isolation CPW MEMS shunt switches-part 1: modeling  this paper, the first of two parts, presents an electromagnetic model for membrane microelectromechanical systems (mems) shunt switches for microwave/millimeter-wave applications. the up-state capacitance can be accurately modeled using three-dimensional static solvers, and full-wave solvers are used to predict the current distribution and inductance of the switch. the loss in the up-state position is equivalent to the coplanar waveguide line loss and is 0.01-0.02 db at 10-30 ghz for a 2-/spl mu/m-thick au mems shunt switch. it is seen that the capacitance, inductance, and series resistance can be accurately extracted from dc-40 ghz s-parameter measurements. it is also shown that dramatic increase in the down-state isolation (20/sup +/ db) can be achieved with the choice of the correct lc series resonant frequency of the switch. in part 2 of this paper, the equivalent capacitor-inductor-resistor model is used in the design of tuned high isolation switches at 10 and 30 ghz.",
            "contribution_ids": [
                "R141121"
            ]
        },
        {
            "instance_id": "R141156xR141136",
            "comparison_id": "R141156",
            "paper_id": "R141136",
            "text": "A zipper RF MEMS tunable capacitor with interdigitated RF and actuation electrodes this paper presents a new rf mems tunable capacitor based on the zipper principle and with interdigitated rf and actuation electrodes. the electrode configuration prevents dielectric charging under high actuation voltages. it also increases the capacitance ratio and the tunable analog range. the effect of the residual stress on the capacitance tunability is also investigated. two devices with different interdigital rf and actuation electrodes are fabricated on an alumina substrate and result in a capacitance ratio around 3.0 (cmin = 70\u201390 ff, cmax = 240\u2013270 ff) and with a q > 100 at 3 ghz. this design can be used in wideband tunable filters and matching networks.",
            "contribution_ids": [
                "R141138"
            ]
        },
        {
            "instance_id": "R141156xR141150",
            "comparison_id": "R141156",
            "paper_id": "R141150",
            "text": "Investigation of Charge Injection and Relaxation in Multilayer Dielectric Stacks for Capacitive RF MEMS Switch Application this paper proposes a new approach to the problem of irreversible stiction of capacitive radio frequency (rf) microelectromechanical (mems) switch attributed to the dielectric charging. we investigate how charge accumulates in multi- and single-layer dielectric structures for a capacitive rf mems switch using metal-insulator-semiconductor (mis) capacitor structure. two multidielectric-layers are structured, which are sio2+si3n4 and sio2+si3n4+sio2 stack films. meanwhile, si3n4 single-layer dielectric structure is also fabricated for comparison. in the experiments, the space charges are first injected into the dielectric layers by stressing mis devices with a dc bias; then the injected charge kinetics are monitored by capacitance-voltage measurement before and after charge injection. we found that the polarity of charge accumulated in the dielectric is strongly influenced by the dielectric structure. when the metal electrode is positively biased, a negative charge accumulates in the single and triple-layer devices, while a positive charge accumulates in the double-layer devices. furthermore, the experiment results also show that the lowest charge accumulation can be achieved using double-layer dielectric structure even though the fastest relaxation process takes place in triple-layer dielectric structure.",
            "contribution_ids": [
                "R141152"
            ]
        },
        {
            "instance_id": "R141425xR141401",
            "comparison_id": "R141425",
            "paper_id": "R141401",
            "text": "Application of camelid heavy-chain variable domains (VHHs) in prevention and treatment of bacterial and viral infections abstract camelid heavy-chain variable domains (vhhs) are the smallest, intact, antigen-binding units to occur in nature. vhhs possess high degrees of solubility and robustness enabling generation of multivalent constructs with increased avidity \u2013 characteristics that mark their superiority to other antibody fragments and monoclonal antibodies. capable of effectively binding to molecular targets inaccessible to classical immunotherapeutic agents and easily produced in microbial culture, vhhs are considered promising tools for pharmaceutical biotechnology. with the aim to demonstrate the perspective and potential of vhhs for the development of prophylactic and therapeutic drugs to target diseases caused by bacterial and viral infections, this review article will initially describe the structural features that underlie the unique properties of vhhs and explain the methods currently used for the selection and recombinant production of pathogen-specific vhhs, and then thoroughly summarize the experimental findings of five distinct studies that employed vhhs as inhibitors of host\u2013pathogen interactions or neutralizers of infectious agents. past and recent studies suggest the potential of camelid heavy-chain variable domains as a novel modality of immunotherapeutic drugs and a promising alternative to monoclonal antibodies. vhhs demonstrate the ability to interfere with bacterial pathogenesis by preventing adhesion to host tissue and sequestering disease-causing bacterial toxins. to protect from viral infections, vhhs may be employed as inhibitors of viral entry by binding to viral coat proteins or blocking interactions with cell-surface receptors. the implementation of vhhs as immunotherapeutic agents for infectious diseases is of considerable potential and set to contribute to public health in the near future.",
            "contribution_ids": [
                "R141402"
            ]
        },
        {
            "instance_id": "R141425xR141413",
            "comparison_id": "R141425",
            "paper_id": "R141413",
            "text": "Novel coronavirus-like particles targeting cells lining the respiratory tract virus like particles (vlps) produced by the expression of viral structural proteins can serve as versatile nanovectors or potential vaccine candidates. in this study we describe for the first time the generation of hcov-nl63 vlps using baculovirus system. major structural proteins of hcov-nl63 have been expressed in tagged or native form, and their assembly to form vlps was evaluated. additionally, a novel procedure for chromatography purification of hcov-nl63 vlps was developed. interestingly, we show that these nanoparticles may deliver cargo and selectively transduce cells expressing the ace2 protein such as ciliated cells of the respiratory tract. production of a specific delivery vector is a major challenge for research concerning targeting molecules. the obtained results show that hcov-nl63 vlps may be efficiently produced, purified, modified and serve as a delivery platform. this study constitutes an important basis for further development of a promising viral vector displaying narrow tissue tropism.",
            "contribution_ids": [
                "R141414"
            ]
        },
        {
            "instance_id": "R141425xR141415",
            "comparison_id": "R141425",
            "paper_id": "R141415",
            "text": "Development of Label-Free Colorimetric Assay for MERS-CoV Using Gold Nanoparticles worldwide outbreaks of infectious diseases necessitate the development of rapid and accurate diagnostic methods. colorimetric assays are a representative tool to simply identify the target molecules in specimens through color changes of an indicator (e.g., nanosized metallic particle, and dye molecules). the detection method is used to confirm the presence of biomarkers visually and measure absorbance of the colored compounds at a specific wavelength. in this study, we propose a colorimetric assay based on an extended form of double-stranded dna (dsdna) self-assembly shielded gold nanoparticles (aunps) under positive electrolyte (e.g., 0.1 m mgcl2) for detection of middle east respiratory syndrome coronavirus (mers-cov). this platform is able to verify the existence of viral molecules through a localized surface plasmon resonance (lspr) shift and color changes of aunps in the uv\u2013vis wavelength range. we designed a pair of thiol-modified probes at either the 5\u2032 end or 3\u2032 end to organize complementary base pairs with upstream of the e protein gene (upe) and open reading frames (orf) 1a on mers-cov. the dsdna of the target and probes forms a disulfide-induced long self-assembled complex, which protects aunps from salt-induced aggregation and transition of optical properties. this colorimetric assay could discriminate down to 1 pmol/\u03bcl of 30 bp mers-cov and further be adapted for convenient on-site detection of other infectious diseases, especially in resource-limited settings.",
            "contribution_ids": [
                "R141416"
            ]
        },
        {
            "instance_id": "R141425xR141419",
            "comparison_id": "R141425",
            "paper_id": "R141419",
            "text": "Identification of sialic acid-binding function for the Middle East respiratory syndrome coronavirus spike glycoprotein significance \\n middle east respiratory syndrome coronavirus (mers-cov) recurrently infects humans from its dromedary camel reservoir, causing severe respiratory disease with an \u223c35% fatality rate. the virus binds to the dipeptidyl peptidase 4 (dpp4) entry receptor on respiratory epithelial cells via its spike protein. we here report that the mers-cov spike protein selectively binds to sialic acid (sia) and demonstrate that cell-surface sialoglycoconjugates can serve as an attachment factor. our observations warrant further research into the role of sia binding in the virus\u2019s host and tissue tropism and transmission, which may be influenced by the observed sia-binding fine specificity and by differences in sialoglycomes among host species.",
            "contribution_ids": [
                "R141420"
            ]
        },
        {
            "instance_id": "R141593xR141444",
            "comparison_id": "R141593",
            "paper_id": "R141444",
            "text": "Low-kfilms modification under EUV and VUV radiation modification of ultra-low-k films by extreme ultraviolet (euv) and vacuum ultraviolet (vuv) emission with 13.5, 58.4, 106, 147 and 193 nm wavelengths and fluences up to 6 \u00d7 1018 photons cm\u22122 is studied experimentally and theoretically to reveal the damage mechanism and the most \u2018damaging\u2019 spectral region. organosilicate glass (osg) and organic low-k films with k-values of 1.8\u20132.5 and porosity of 24\u201351% are used in these experiments. the si\u2013ch3 bonds depletion is used as a criterion of vuv damage of osg low-k films. it is shown that the low-k damage is described by two fundamental parameters: photoabsorption (pa) cross-section \u03c3pa and effective quantum yield \u03c6 of si\u2013ch3 photodissociation. the obtained \u03c3pa and \u03c6 values demonstrate that the effect of wavelength is defined by light absorption spectra, which in osg materials is similar to fused silica. this is the reason why vuv light in the range of \u223c58\u2013106 nm having the highest pa cross-sections causes strong si\u2013ch3 depletion only in the top part of the films (\u223c50\u2013100 nm). the deepest damage is observed after exposure to 147 nm vuv light since this emission is located at the edge of si\u2013o absorption, has the smallest pa cross-section and provides extensive si\u2013ch3 depletion over the whole film thickness. the effective quantum yield slowly increases with the increasing porosity but starts to grow quickly when the porosity exceeds the critical threshold located close to a porosity of \u223c50%. the high degree of pore interconnectivity of these films allows easy movement of the detached methyl radicals. the obtained results have a fundamental character and can be used for prediction of ulk material damage under vuv light with different wavelengths.",
            "contribution_ids": [
                "R141584",
                "R141771"
            ]
        },
        {
            "instance_id": "R141593xR141460",
            "comparison_id": "R141593",
            "paper_id": "R141460",
            "text": "An In Situ Comparison between VUV Photon and Ion Energy Fluxes to Polymer Surfaces Immersed in an RF Plasma absolutely calibrated vacuum ultraviolet (vuv) spectroscopy has been used to determine the energy fluxes of vuv photons at an electrically floating substrate in a low-pressure 13.56-mhz radiofrequency plasma reactor used for polymer surface treatments. these fluxes have been compared with the positive ion flux that was reported in an earlier study. at the typical operating parameters of 10-mtorr pressure and 10-w power, the total vuv energy flux is 2.2 mw cm-2, compared with a value of 3.3 mw cm-2 from the ions. with increasing power (from 0.5 to 12 w), both the ion and vuv energy fluxes increase monotonically. however, as the pressure increases, (1\u2212100 mtorr), the ion energy flux declines, while the vuv component increases. at discharge powers of 10 w, and pressures greater than 25 mtorr, the greater part of the energy flux to the surface is from the vuv photons. these measurements are used to determine which of the plasma components, vuv or ions, will be most effective in the treatment of polystyrene su...",
            "contribution_ids": [
                "R141592",
                "R141779"
            ]
        },
        {
            "instance_id": "R141593xR141532",
            "comparison_id": "R141593",
            "paper_id": "R141532",
            "text": "VUV Spectral Irradiance Measurements in H\n                    2\n                    /He/Ar Microwave Plasmas and Comparison with Solar Data microwave plasmas with h2 and h2/rare gas mixtures are convenient sources of vuv radiation for laboratory simulations of astrophysical media. we recently undertook an extensive study to characterize microwave plasmas in an h2/he gas mixture in order to optimize a vuv solar simulator over the 115\u2013170 nm spectral range. in this paper, we extend our investigation to the effect of the addition of ar into h2/he plasma on the vuv spectral irradiance. our study combines various optical diagnostics such as a vuv spectrometer and optical emission spectroscopy. quantitative measurements of the spectral irradiance and photons flux in different mixtures are accomplished using a combination of vuv spectrometry and chemical actinometry. results show that the ar addition into h2/he plasma largely affects the predominant emissions of the hydrogen ly\u03b1 line (121.6 nm) and h2 (b\u03c3u\u2013x \u03c3g) band (150\u2013170 nm). while a microwave plasma with 1.4% h2/he is required to mimic the entire vuv solar spectrum in the 115\u2013170 nm range, the combination with 1.28% h2/35% ar/he is the best alternative to obtain a quasi-monochromatic spectrum with emission dominated by the ly\u03b1 line. the maximum of the spectral irradiance is significantly higher in the ternary mixtures compared to the binary mixture of 1.4% h2/he. further ar increase yielded lower spectral irradiance and absolute photon fluxes. our measured spectral irradiances are compared to vuv solar data in the 115\u2013170 nm range, emphasizing the use of microwave plasmas in astrophysical studies and laboratory simulations of planetary atmospheres.",
            "contribution_ids": [
                "R141577",
                "R141764"
            ]
        },
        {
            "instance_id": "R141593xR108936",
            "comparison_id": "R141593",
            "paper_id": "R108936",
            "text": "Absolute vacuum ultraviolet flux in inductively coupled plasmas and chemical modifications of 193 nm photoresist vacuum ultraviolet (vuv) photons in plasma processing systems are known to alter surface chemistry and may damage gate dielectrics and photoresist. we characterize absolute vuv fluxes to surfaces exposed in an inductively coupled argon plasma, 1\u201350 mtorr, 25\u2013400 w, using a calibrated vuv spectrometer. we also demonstrate an alternative method to estimate vuv fluence in an inductively coupled plasma (icp) reactor using a chemical dosimeter-type monitor. we illustrate the technique with argon icp and xenon lamp exposure experiments, comparing direct vuv measurements with measured chemical changes in 193 nm photoresist-covered si wafers following vuv exposure.",
            "contribution_ids": [
                "R141590",
                "R141777"
            ]
        },
        {
            "instance_id": "R141699xR141621",
            "comparison_id": "R141699",
            "paper_id": "R141621",
            "text": "Probing the highly efficient room temperature ammonia gas sensing properties of a luminescent ZnO nanowire array prepared via an AAO-assisted template route a highly ordered luminescent zno nanowire array was synthesized which has excellent sensitivity and fast response to nh 3 gas.",
            "contribution_ids": [
                "R141623"
            ]
        },
        {
            "instance_id": "R141699xR141631",
            "comparison_id": "R141699",
            "paper_id": "R141631",
            "text": "Rice Husk Templated Mesoporous ZnO Nanostructures for Ethanol Sensing at Room Temperature mesoporous zinc oxide nanostructures are successfully synthesized via the sol-gel route by using a rice husk as the template for ethanol sensing at room temperature. the structure and morphology of the nanostructures are characterized by x-ray diffraction, scanning electron microscopy (sem), transmission electron microscopy (tem), and nitrogen adsorption\u2013desorption analyses. the mechanism for the growth of zinc oxide nanostructures over the biotemplate is proposed. sem and tem observations also reveal the formation of spherical zinc oxide nanoparticles over the interwoven fibrous network. multiple sized pores having pore diameter ranging from 10\u201340 nm is also evidenced from the pore size distribution plot. the larger surface area and porous nature of the material lead to high sensitivity (40.93% for 300 ppm of ethanol), quick response (42 s) and recovery (40 s) towards ethanol at 300 k. the porous nature of the interwoven fibre-like network affords mass transportation of ethanol vapor, which results in faster surface accessibility, and hence it acts as a potential candidate for ethanol sensing at room temperature.",
            "contribution_ids": [
                "R141633"
            ]
        },
        {
            "instance_id": "R141752xR141205",
            "comparison_id": "R141752",
            "paper_id": "R141205",
            "text": "Governance Infrastructures in 2020 a governance infrastructure is the collection of technologies and systems, people, policies, practices, and relationships that interact to support governing activities. information technology, especially communication and computational technologies, continues to augment society\u2019s ability to organize, interact, and govern. as we think about the future of governance, this article challenges us to move beyond questions of how to best manage government institutions to how to design smart governance systems with the appropriate incentives and rules to harness and coordinate the enthusiasm and capabilities of those governed. this article anticipates how the interaction of technology and society can be leveraged to mindfully design an interaction-defined, participation-based governance infrastructure to return power to the people while increasing accountability. supporting examples of such governance approaches already exist and are regularly emerging in distributed organizations, online communities, nonprofits, and governments.",
            "contribution_ids": [
                "R141207",
                "R142079"
            ]
        },
        {
            "instance_id": "R141752xR141214",
            "comparison_id": "R141752",
            "paper_id": "R141214",
            "text": "Conceptualizing smart city with dimensions of technology, people, and institutions this conceptual paper discusses how we can consider a particular city as a smart one, drawing on recent practices to make cities smart. a set of the common multidimensional components underlying the smart city concept and the core factors for a successful smart city initiative is identified by exploring current working definitions of smart city and a diversity of various conceptual relatives similar to smart city. the paper offers strategic principles aligning to the three main dimensions (technology, people, and institutions) of smart city: integration of infrastructures and technology-mediated services, social learning for strengthening human infrastructure, and governance for institutional improvement and citizen engagement.",
            "contribution_ids": [
                "R141216",
                "R142076"
            ]
        },
        {
            "instance_id": "R141752xR141250",
            "comparison_id": "R141752",
            "paper_id": "R141250",
            "text": "Aspirations and Realizations: The Smart City of Seattle smart city initiatives have been launched on every continent. that notwithstanding the concept of \u201csmart city\u201d has remained ambiguous. we systematically interviewed officials of an acclaimed smart city (seattle) and explicitly asked the officials for their own definitions of \u201csmart city,\u201d which we then compared to the respective projects run by that city. while the definitions given by the practitioners were found different from those in the literature, the smart city projects lived up and matched the practitioner definitions to a high degree. we document the projects and their expected and realized benefits, which illustrate where a leading city government is headed in terms of smart government. however, \u201csmart city\u201d initiatives in local government might be only a steppingstone in making the greater urban space a \u201csmart city,\u201d which appears to be a more challenging undertaking.",
            "contribution_ids": [
                "R141252",
                "R141757",
                "R142064"
            ]
        },
        {
            "instance_id": "R141780xR141661",
            "comparison_id": "R141780",
            "paper_id": "R141661",
            "text": "Fluorescent N-Doped Carbon Dots as in Vitro and in Vivo Nanothermometer the fluorescent n-doped carbon dots (n-cds) obtained from c3n4 emit strong blue fluorescence, which is stable with different ionic strengths and time. the fluorescence intensity of n-cds decreases with the temperature increasing, while it can recover to the initial one with the temperature decreasing. it is an accurate linear response of fluorescence intensity to temperature, which may be attributed to the synergistic effect of abundant oxygen-containing functional groups and hydrogen bonds. further experiments also demonstrate that n-cds can serve as effective in vitro and in vivo fluorescence-based nanothermometer.",
            "contribution_ids": [
                "R141663"
            ]
        },
        {
            "instance_id": "R141780xR141708",
            "comparison_id": "R141780",
            "paper_id": "R141708",
            "text": "N,S co-doped carbon dots as a stable bio-imaging probe for detection of intracellular temperature and tetracycline n,s-cds display an unambiguous bioimaging ability in the detection of intracellular temperature and tetracycline with satisfactory results.",
            "contribution_ids": [
                "R141713"
            ]
        },
        {
            "instance_id": "R142850xR142837",
            "comparison_id": "R142850",
            "paper_id": "R142837",
            "text": "New Method for Delivering a Hydrophobic Drug for Photodynamic Therapy Using Pure Nanocrystal Form of the Drug a carrier-free method for delivery of a hydrophobic drug in its pure form, using nanocrystals (nanosized crystals), is proposed. to demonstrate this technique, nanocrystals of a hydrophobic photosensitizing anticancer drug, 2-devinyl-2-(1-hexyloxyethyl)pyropheophorbide (hpph), have been synthesized using the reprecipitation method. the resulting drug nanocrystals were monodispersed and stable in aqueous dispersion, without the necessity of an additional stabilizer (surfactant). as shown by confocal microscopy, these pure drug nanocrystals were taken up by the cancer cells with high avidity. though the fluorescence and photodynamic activity of the drug were substantially quenched in the form of nanocrystals in aqueous suspension, both these characteristics were recovered under in vitro and in vivo conditions. this recovery of drug activity and fluorescence is possibly due to the interaction of nanocrystals with serum albumin, resulting in conversion of the drug nanocrystals into the molecular form. this was confirmed by demonstrating similar recovery in presence of fetal bovine serum (fbs) or bovine serum albumin (bsa). under similar treatment conditions, the hpph in nanocrystal form or in 1% tween-80/water formulation showed comparable in vitro and in vivo efficacy.",
            "contribution_ids": [
                "R142839"
            ]
        },
        {
            "instance_id": "R144121xR143919",
            "comparison_id": "R144121",
            "paper_id": "R143919",
            "text": "Enabling Folksonomies for Knowledge Extraction: A Semantic Grounding Approach folksonomies emerge as the result of the free tagging activity of a large number of users over a variety of resources. they can be considered as valuable sources from which it is possible to obtain emerging vocabularies that can be leveraged in knowledge extraction tasks. however, when it comes to understanding the meaning of tags in folksonomies, several problems mainly related to the appearance of synonymous and ambiguous tags arise, specifically in the context of multilinguality. the authors aim to turn folksonomies into knowledge structures where tag meanings are identified, and relations between them are asserted. for such purpose, they use dbpedia as a general knowledge base from which they leverage its multilingual capabilities.",
            "contribution_ids": [
                "R143921"
            ]
        },
        {
            "instance_id": "R144512xR144378",
            "comparison_id": "R144512",
            "paper_id": "R144378",
            "text": "In vivo biodistribution of venlafaxine-PLGA nanoparticles for brain delivery: plain vs. functionalized nanoparticles abstract background: actually, no drugs provide therapeutic benefit to approximately one-third of depressed patients. depression is predicted to become the first global disease by 2030. so, new therapeutic interventions are imperative. research design and methods: venlafaxine-loaded poly(lactic-co-glycolic acid) (plga) nanoparticles (nps) were surface functionalized with two ligands against transferrin receptor to enhance access to brain. an in vitro blood\u2013brain barrier model using hcmec/d3 cell line was developed to evaluate permeability. in vivo biodistribution studies were performed using c57/bl6 mice. particles were administered intranasal and main organs were analyzed. results: particles were obtained as a lyophilized powder easily to re-suspend. internalization and permeability studies showed the following cell association sequence: tfrp-nps>tf-nps>plain nps. permeability studies also showed that encapsulated vlf was not affected by p-gp pump efflux increasing its concentration in the basolateral side after 24 h. in vivo studies showed that 25% of plain nps reach the brain after 30 min of one intranasal administration while less than 5% of functionalized nps get the target. conclusions: plain nps showed the highest ability to reach the brain vs. functionalized nps after 30 min by intranasal administration. we suggest plain nps probably travel via direct nose-to-brian route whereas functionalized nps reach the brain by receptor-mediated endocytosis.",
            "contribution_ids": [
                "R144381",
                "R144382"
            ]
        },
        {
            "instance_id": "R144512xR144478",
            "comparison_id": "R144512",
            "paper_id": "R144478",
            "text": "Co-delivery of doxorubicin and siRNA for glioma therapy by a brain targeting system: angiopep-2-modified poly(lactic-co-glycolic acid) nanoparticles abstract it is very challenging to treat brain cancer because of the blood\u2013brain barrier (bbb) restricting therapeutic drug or gene to access the brain. in this research project, angiopep-2 (ang) was used as a brain-targeted peptide for preparing multifunctional ang-modified poly(lactic-co-glycolic acid) (plga) nanoparticles (nps), which encapsulated both doxorubicin (dox) and epidermal growth factor receptor (egfr) sirna, designated as ang/plga/dox/sirna. this system could efficiently deliver dox and sirna into u87mg cells leading to significant cell inhibition, apoptosis and egfr silencing in vitro. it demonstrated that this drug system was capable of penetrating the bbb in vivo, resulting in more drugs accumulation in the brain. the animal study using the brain orthotopic u87mg glioma xenograft model indicated that the ang-targeted co-delivery of dox and egfr sirna resulted in not only the prolongation of the life span of the glioma-bearing mice but also an obvious cell apoptosis in glioma tissue.",
            "contribution_ids": [
                "R144480"
            ]
        },
        {
            "instance_id": "R145685xR145174",
            "comparison_id": "R145685",
            "paper_id": "R145174",
            "text": "Theory of Line Broadening in Multiplet Spectra \"a theory of line broadening in the impect approximation is developed which includes the case of overlapping lines. it is assumed that the collisions which give rise to the broadening do not cause transitions between states with different principal quantam numbers. the theory was worked out in detail in two cases: (1) the broadening arises only from perturbations of the upper state with arbitrary splitting of the substates. this approximation may be used if the perturbations of the lower state are relatively unimportant (e.g.. the higher series members of the balmer lines), and is exact if the perturbations do not affect the lower state as in the case of the ground stute of hydrogen perturbed by electron collisions; (2) complete degeneracy of the initial and final states. this approximation is also valid on the far wing of the line if there is splitting, i.e.. for frequencies large compared to thc splitting, and is a generalization of anderson's theory. the formal theory is worked out by two different methods. the method of calculation for nearly degenerate initial and final states with splitting is indicated. method i is particularly suited for calculating the wing distribution while method ii is more suitable formore\\xa0\u00bb finding tbe intensity distribution at the line center for overlapping lines. the line profile is made up of a sum of dispersion profiles and asymmetric terms whicb arise from interferences when the transition operator is not diagonal. the shift and half-width parameters are found from the roots of a secular equation and depend on the splitting as well as the density. temperature. and the character of the perturbation. (auth)\u00ab\\xa0less\"",
            "contribution_ids": [
                "R145225"
            ]
        },
        {
            "instance_id": "R145685xR145180",
            "comparison_id": "R145685",
            "paper_id": "R145180",
            "text": "Stark Broadening of Neutral Helium Lines in a Plasma \"the frequency distributions of spectral lines of nonhydrogenic atoms broadened by local fields of both electrons and ions in a plasma are calculated in the classical path approximation. the electron collisions are treated by an impact theory which takes into account deviations from adiabaticity. for the ion effects, the adiabatic approximation can be used to describe the time-dependent wave functions. the various approximations employed were examined for self-consistency, and an accuracy of about 20% in the resulting line profiles is expected. good agreement with wulff's experimental helium line profiles was obtained while there are large deviations from the adiabatic theory, especially for the line shifts. asymptotic distributions for the line wings are given for astrophysical applications. here the ion effects can be as important as the electron effects and lead to large asymmetries, but near the line core electrons usually dominate. numerical results are tabulated for 24 neutral helium lines with principal quantum numbers up to five.\"",
            "contribution_ids": [
                "R145227"
            ]
        },
        {
            "instance_id": "R145685xR145210",
            "comparison_id": "R145685",
            "paper_id": "R145210",
            "text": "Stark broadening of the B III2s\u00e2\u0088\u00922plines we present a quantum-mechanical calculation of stark linewidths from electron-ion collisions for the 2s{sub 1/2}-2p{sub 1/2,3/2}, {lambda}=2066 and 2067 {angstrom}, resonance transitions in biii. the results confirm previous quantum-mechanical r-matrix calculations, but contradict recent measurements and semiclassical and some semiempirical calculations. the differences between the calculations can be attributed to the dominance of small l partial waves in the electron-atom scattering, while the large stark widths inferred from the measurements would be substantially reduced if allowance is made for hydrodynamic turbulence from high-reynolds-number flows and the associated doppler broadening. {copyright} {ital 1997} {ital the american physical society}",
            "contribution_ids": [
                "R145238"
            ]
        },
        {
            "instance_id": "R145685xR145213",
            "comparison_id": "R145685",
            "paper_id": "R145213",
            "text": "Electron impact broadening of spectral lines in Be-like ions: quantum calculations we present in this paper quantum mechanical calculations for the electron impact stark linewidths of the 2s3s\u20132s3p transitions for the four beryllium-like ions from n iv to ne vii. calculations are made in the frame of the impact approximation and intermediate coupling, taking into account fine-structure effects. a comparison between our calculations, experimental and other theoretical results, shows a good agreement. this is the first time that such a good agreement is found between quantum and experimental linewidths of highly charged ions.",
            "contribution_ids": [
                "R145239"
            ]
        },
        {
            "instance_id": "R145950xR142709",
            "comparison_id": "R145950",
            "paper_id": "R142709",
            "text": "Unified IoT ontology to enable interoperability and federation of testbeds \"after a thorough analysis of existing internet of things (iot) related ontologies, in this paper we propose a solution that aims to achieve semantic interoperability among heterogeneous testbeds. our model is framed within the eu h2020's fiesta-iot project, that aims to seamlessly support the federation of testbeds through the usage of semantic-based technologies. our proposed model (ontology) takes inspiration from the well-known noy et al. methodology for reusing and interconnecting existing ontologies. to build the ontology, we leverage a number of core concepts from various mainstream ontologies and taxonomies, such as semantic sensor network (ssn), m3-lite (a lite version of m3 and also an outcome of this study), wgs84, iot-lite, time, and dul. in addition, we also introduce a set of tools that aims to help external testbeds adapt their respective datasets to the developed ontology.\"",
            "contribution_ids": [
                "R142711",
                "R142852",
                "R144804"
            ]
        },
        {
            "instance_id": "R146458xR146051",
            "comparison_id": "R146458",
            "paper_id": "R146051",
            "text": "Innovation Management in the Context of Smart Cities Digital Transformation the paper introduces important aspects of doctoral research concerning innovation management in the context of business management challenges posed by digital transformation. the research was conducted as part of the research centre of business administration in the bucharest university of economic studies, romania. the study aims to identify and display key components of innovation management \u2013 with a primary focus on topics spurred by the recent wave of digital evolution. against this background, the issue of smart city solutions makes for an interesting case \u2013 firstly, because it affects a large number of people and businesses around the globe and secondly, the complexity of the topic forces companies to pursue different innovation management approaches to successfully manage its associated challenges as well as opportunities. the paper consists of an overview on the existing literature and a concise outline of our research. both researches from professional associations as well as recognized publishers were considered. furthermore, market data were gathered and processed. more than 50 publications were analyzed to better understand trends in digital transformation and its impact on innovation management. our research revealed that in the light of the fundamental challenges posed by digitization, companies are required to take a structured approach towards their innovation management options. in the context of smart city solutions, the adoption of the \u201c4i solutions model\u201d enables businesses to choose the strategic option suitable to their individual case. concisely, this framework includes four different approaches ranging from initiating groundwork innovation internally to establishing partnerships with selected external parties.",
            "contribution_ids": [
                "R146053"
            ]
        },
        {
            "instance_id": "R146458xR146090",
            "comparison_id": "R146458",
            "paper_id": "R146090",
            "text": "Internet of Things, legal and regulatory framework in digital transformation from smart to intelligent cities \"digital transformation from \u201csmart\u201d to \u201cintelligent city\u201d is based on new information technologies and knowledge, as well as on organizational and security processes. the authors of this paper will present the legal and regulatory framework and challenges of internet of things in development of smart cities on the way to become intelligent cities. the special contribution of the paper will be an overview of new legal and regulatory framework general data protection regulation (gdpr) which is of great importance for european union legal and regulation framework and bringing novelties in citizen's privacy and protection of personal data.\"",
            "contribution_ids": [
                "R146092"
            ]
        },
        {
            "instance_id": "R146458xR146157",
            "comparison_id": "R146458",
            "paper_id": "R146157",
            "text": "The digital transformation and smart data analytics: An overview of enabling developments and application areas the digital transformation enables new business models and enhanced business processes by utilizing available data for analytics, prediction, and decision support. we give an overview of the enabling developments for the digital transformation, the areas of application, and concrete use case examples. we summarize our findings in a framework for the digital transformation and discuss the potential for new and adapted business models.",
            "contribution_ids": [
                "R146159"
            ]
        },
        {
            "instance_id": "R146851xR145085",
            "comparison_id": "R146851",
            "paper_id": "R145085",
            "text": "Developing open source, self-contained disease surveillance software applications for use in resource-limited settings abstract background emerging public health threats often originate in resource-limited countries. in recognition of this fact, the world health organization issued revised international health regulations in 2005, which call for significantly increased reporting and response capabilities for all signatory nations. electronic biosurveillance systems can improve the timeliness of public health data collection, aid in the early detection of and response to disease outbreaks, and enhance situational awareness. methods as components of its suite for automated global biosurveillance (sages) program, the johns hopkins university applied physics laboratory developed two open-source, electronic biosurveillance systems for use in resource-limited settings. openessence provides web-based data entry, analysis, and reporting. essence desktop edition provides similar capabilities for settings without internet access. both systems may be configured to collect data using locally available cell phone technologies. results essence desktop edition has been deployed for two years in the republic of the philippines. local health clinics have rapidly adopted the new technology to provide daily reporting, thus eliminating the two-to-three week data lag of the previous paper-based system. conclusions openessence and essence desktop edition are two open-source software products with the capability of significantly improving disease surveillance in a wide range of resource-limited settings. these products, and other emerging surveillance technologies, can assist resource-limited countries compliance with the revised international health regulations.",
            "contribution_ids": [
                "R145087",
                "R145088",
                "R145089"
            ]
        },
        {
            "instance_id": "R146851xR145318",
            "comparison_id": "R146851",
            "paper_id": "R145318",
            "text": "Electronic Surveillance System for the Early Notification of Community-Based Epidemics (ESSENCE): Overview, Components, and Public Health Applications \\n background \\n the electronic surveillance system for the early notification of community-based epidemics (essence) is a secure web-based tool that enables health care practitioners to monitor health indicators of public health importance for the detection and tracking of disease outbreaks, consequences of severe weather, and other events of concern. the essence concept began in an internally funded project at the johns hopkins university applied physics laboratory, advanced with funding from the state of maryland, and broadened in 1999 as a collaboration with the walter reed army institute for research. versions of the system have been further developed by johns hopkins university applied physics laboratory in multiple military and civilian programs for the timely detection and tracking of health threats. \\n \\n \\n objective \\n this study aims to describe the components and development of a biosurveillance system increasingly coordinating all-hazards health surveillance and infectious disease monitoring among large and small health departments, to list the key features and lessons learned in the growth of this system, and to describe the range of initiatives and accomplishments of local epidemiologists using it. \\n \\n \\n methods \\n the features of essence include spatial and temporal statistical alerting, custom querying, user-defined alert notifications, geographical mapping, remote data capture, and event communications. to expedite visualization, configurable and interactive modes of data stratification and filtering, graphical and tabular customization, user preference management, and sharing features allow users to query data and view geographic representations, time series and data details pages, and reports. these features allow essence users to gather and organize the resulting wealth of information into a coherent view of population health status and communicate findings among users. \\n \\n \\n results \\n the resulting broad utility, applicability, and adaptability of this system led to the adoption of essence by the centers for disease control and prevention, numerous state and local health departments, and the department of defense, both nationally and globally. the open-source version of suite for automated global electronic biosurveillance is available for global, resource-limited settings. resourceful users of the us national syndromic surveillance program essence have applied it to the surveillance of infectious diseases, severe weather and natural disaster events, mass gatherings, chronic diseases and mental health, and injury and substance abuse. \\n \\n \\n conclusions \\n with emerging high-consequence communicable diseases and other health conditions, the continued user requirement\u2013driven enhancements of essence demonstrate an adaptable disease surveillance capability focused on the everyday needs of public health. the challenge of a live system for widely distributed users with multiple different data sources and high throughput requirements has driven a novel, evolving architecture design. \\n",
            "contribution_ids": [
                "R145327"
            ]
        },
        {
            "instance_id": "R146851xR145901",
            "comparison_id": "R146851",
            "paper_id": "R145901",
            "text": "Evaluating the electronic tuberculosis register surveillance system in Eden District, Western Cape, South Africa, 2015 abstract background: tuberculosis (tb) surveillance data are crucial to the effectiveness of national tb control programs. in south africa, few surveillance system evaluations have been undertaken to provide a rigorous assessment of the platform from which the national and district health systems draws data to inform programs and policies. objective: evaluate the attributes of eden district\u2019s tb surveillance system, western cape province, south africa. methods: data quality, sensitivity and positive predictive value were assessed using secondary data from 40,033 tb cases entered in eden district\u2019s etr.net from 2007 to 2013, and 79 purposively selected tb blue cards (tbcs), a medical patient file and source document for data entered into etr.net. simplicity, flexibility, acceptability, stability and usefulness of the etr.net were assessed qualitatively through interviews with tb nurses, information health officers, sub-district and district coordinators involved in the tb surveillance. results: tb surveillance system stakeholders report that eden district\u2019s etr.net system was simple, acceptable, flexible and stable, and achieves its objective of informing tb control program, policies and activities. data were less complete in the etr.net (66\u2013100%) than in the tbcs (76\u2013100%), and concordant for most variables except pre-treatment smear results, antiretroviral therapy (art) and treatment outcome. the sensitivity of recorded variables in etr.net was 98% for gender, 97% for patient category, 93% for art, 92% for treatment outcome and 90% for pre-treatment smear grading. conclusions: our results reveal that the system provides useful information to guide tb control program activities in eden district. however, urgent attention is needed to address gaps in clinical recording on the tbc and data capturing into the etr.net system. we recommend continuous training and support of tb personnel involved with tb care, management and surveillance on tb data recording into the tbcs and etr.net as well as the implementation of a well-structured quality control and assurance system.",
            "contribution_ids": [
                "R145904",
                "R145914",
                "R145915"
            ]
        },
        {
            "instance_id": "R146851xR146256",
            "comparison_id": "R146851",
            "paper_id": "R146256",
            "text": "Improving national surveillance of Lyme neuroborreliosis in Denmark through electronic reporting of specific antibody index testing from 2010 to 2012 our aim was to evaluate the results of automated surveillance of lyme neuroborreliosis (lnb) in denmark using the national microbiology database (miba), and to describe the epidemiology of laboratory-confirmed lnb at a national level. miba-based surveillance includes electronic transfer of laboratory results, in contrast to the statutory surveillance based on manually processed notifications. antibody index (ai) testing is the recommend laboratory test to support the diagnosis of lnb in denmark. in the period from 2010 to 2012, 217 clinical cases of lnb were notified to the statutory surveillance system, while 533 cases were reported ai positive by the miba system. thirty-five unconfirmed cases (29 ai-negative and 6 not tested) were notified, but not captured by miba. using miba, the number of reported cases was increased almost 2.5 times. furthermore, the reporting was timelier (median lag time: 6 vs 58 days). average annual incidence of ai-confirmed lnb in denmark was 3.2/100,000 population and incidences stratified by municipality ranged from none to above 10/100,000. this is the first study reporting nationwide incidence of lnb using objective laboratory criteria. laboratory-based surveillance with electronic data-transfer was more accurate, complete and timely compared to the surveillance based on manually processed notifications. we propose using ai test results for lnb surveillance instead of clinical reporting.\\n",
            "contribution_ids": [
                "R146258"
            ]
        },
        {
            "instance_id": "R147040xR145554",
            "comparison_id": "R147040",
            "paper_id": "R145554",
            "text": "Identifying the Main Mosquito Species in China Based on DNA Barcoding mosquitoes are insects of the diptera, nematocera, and culicidae families, some species of which are important disease vectors. identifying mosquito species based on morphological characteristics is difficult, particularly the identification of specimens collected in the field as part of disease surveillance programs. because of this difficulty, we constructed dna barcodes of the cytochrome c oxidase subunit 1, the coi gene, for the more common mosquito species in china, including the major disease vectors. a total of 404 mosquito specimens were collected and assigned to 15 genera and 122 species and subspecies on the basis of morphological characteristics. individuals of the same species grouped closely together in a neighborhood-joining tree based on coi sequence similarity, regardless of collection site. coi gene sequence divergence was approximately 30 times higher for species in the same genus than for members of the same species. divergence in over 98% of congeneric species ranged from 2.3% to 21.8%, whereas divergence in conspecific individuals ranged from 0% to 1.67%. cryptic species may be common and a few pseudogenes were detected.",
            "contribution_ids": [
                "R145555",
                "R155680"
            ]
        },
        {
            "instance_id": "R148381xR148267",
            "comparison_id": "R148381",
            "paper_id": "R148267",
            "text": "Enhanced delivery of etoposide across the blood\u00e2\u0080\u0093brain barrier to restrain brain tumor growth using melanotransferrin antibody- and tamoxifen-conjugated solid lipid nanoparticles abstract melanotransferrin antibody (ma) and tamoxifen (tx) were conjugated on etoposide (etp)-entrapped solid lipid nanoparticles (etp-slns) to target the blood\u2013brain barrier (bbb) and glioblastom multiforme (gbm). ma- and tx-conjugated etp-slns (ma\u2013tx\u2013etp\u2013slns) were used to infiltrate the bbb comprising a monolayer of human astrocyte-regulated human brain-microvascular endothelial cells (hbmecs) and to restrain the proliferation of malignant u87mg cells. tx-grafted etp-slns (tx\u2013etp\u2013slns) significantly enhanced the bbb permeability coefficient for etp and raised the fluorescent intensity of calcein-am when compared with etp-slns. in addition, surface ma could increase the bbb permeability coefficient for etp about twofold. the viability of hbmecs was higher than 86%, suggesting a high biocompatibility of ma\u2013tx\u2013etp-slns. moreover, the efficiency in antiproliferation against u87mg cells was in the order of ma\u2013tx\u2013etp-slns\\u2009\\u2009>\\u2009\\u2009tx\u2013etp-slns\\u2009\\u2009>\\u2009\\u2009etp-slns\\u2009\\u2009>\\u2009\\u2009slns. the capability of ma\u2013tx\u2013etp-slns to target hbmecs and u87mg cells during internalization was verified by immunochemical staining of expressed melanotransferrin. ma\u2013tx\u2013etp-slns can be a potent pharmacotherapy to deliver etp across the bbb to gbm.",
            "contribution_ids": [
                "R148269"
            ]
        },
        {
            "instance_id": "R148381xR148289",
            "comparison_id": "R148381",
            "paper_id": "R148289",
            "text": "Vincristine and temozolomide combined chemotherapy for the treatment of glioma: a comparison of solid lipid nanoparticles and nanostructured lipid carriers for dual drugs delivery abstract context: glioma is a common malignant brain tumor originating in the central nervous system. efficient delivery of therapeutic agents to the cells and tissues is a difficult challenge. co-delivery of anticancer drugs into the cancer cells or tissues by multifunctional nanocarriers may provide a new paradigm in cancer treatment. objective: in this study, solid lipid nanoparticles (slns) and nanostructured lipid carriers (nlcs) were constructed for co-delivery of vincristine (vcr) and temozolomide (tmz) to develop the synergetic therapeutic action of the two drugs. the antitumor effects of these two systems were compared to provide a better choice for gliomatosis cerebri treatment. methods: vcr- and tmz-loaded slns (vt-slns) and nlcs (vt-nlcs) were formulated. their particle size, zeta potential, drug encapsulation efficiency (ee) and drug loading capacity were evaluated. the single tmz-loaded slns and nlcs were also prepared as contrast. anti-tumor efficacies of the two kinds of carriers were evaluated on u87 malignant glioma cells and mice bearing malignant glioma model. results: significantly better glioma inhibition was observed on nlcs formulations than slns, and dual drugs displayed the highest antitumor efficacy in vivo and in vitro than all the other formulations used. conclusion: vt-nlcs can deliver vcr and tmz into u87mg cells more efficiently, and inhibition efficacy is higher than vt-slns. this dual drugs-loaded nlcs could be an outstanding drug delivery system to achieve excellent therapeutic efficiency for the treatment of malignant gliomatosis cerebri.",
            "contribution_ids": [
                "R148291",
                "R148292"
            ]
        },
        {
            "instance_id": "R150058xR145757",
            "comparison_id": "R150058",
            "paper_id": "R145757",
            "text": "SemEval-2018 Task 7: Semantic Relation Extraction and Classification in Scientific Papers this paper describes the first task on semantic relation extraction and classification in scientific paper abstracts at semeval 2018. the challenge focuses on domain-specific semantic relations and includes three different subtasks. the subtasks were designed so as to compare and quantify the effect of different pre-processing steps on the relation classification results. we expect the task to be relevant for a broad range of researchers working on extracting specialized knowledge from domain corpora, for example but not limited to scientific or bio-medical information extraction. the task attracted a total of 32 participants, with 158 submissions across different scenarios.",
            "contribution_ids": [
                "R145759",
                "R145770",
                "R145773"
            ]
        },
        {
            "instance_id": "R150058xR146853",
            "comparison_id": "R150058",
            "paper_id": "R146853",
            "text": "SciREX: A Challenge Dataset for Document-Level Information Extraction extracting information from full documents is an important problem in many domains, but most previous work focus on identifying relationships within a sentence or a paragraph. it is challenging to create a large-scale information extraction (ie) dataset at the document level since it requires an understanding of the whole document to annotate entities and their document-level relationships that usually span beyond sentences or even sections. in this paper, we introduce scirex, a document level ie dataset that encompasses multiple ie tasks, including salient entity identification and document level n-ary relation identification from scientific articles. we annotate our dataset by integrating automatic and human annotations, leveraging existing scientific knowledge resources. we develop a neural model as a strong baseline that extends previous state-of-the-art ie models to document-level ie. analyzing the model performance shows a significant gap between human performance and current baselines, inviting the community to use our dataset as a challenge to develop document-level ie models. our data and code are publicly available at https://github.com/allenai/scirex .",
            "contribution_ids": [
                "R146855"
            ]
        },
        {
            "instance_id": "R150058xR147638",
            "comparison_id": "R150058",
            "paper_id": "R147638",
            "text": "Identifying used methods and datasets in scientific publications although it has become common to assess publications and researchers by means of their citation count (e.g., using the h-index), measuring the impact of scientific methods and datasets (e.g., using an \u201ch-index for datasets\u201d) has been performed only to a limited extent. this is not surprising because the usage information of methods and datasets is typically not explicitly provided by the authors, but hidden in a publication\u2019s text. in this paper, we propose an approach to identifying methods and datasets in texts that have actually been used by the authors. our approach first recognizes datasets and methods in the text by means of a domain-specific named entity recognition method with minimal human interaction. it then classifies these mentions into used vs. non-used based on the textual contexts. the obtained labels are aggregated on the document level and integrated into the microsoft academic knowledge graph modeling publications\u2019 metadata. in experiments based on the microsoft academic graph, we show that both method and dataset mentions can be identified and correctly classified with respect to their usage to a high degree. overall, our approach facilitates method and dataset recommendation, enhanced paper recommendation, and scientific impact quantification. it can be extended in such a way that it can identify mentions of any entity type (e.g., task).",
            "contribution_ids": [
                "R147640"
            ]
        },
        {
            "instance_id": "R150058xR69282",
            "comparison_id": "R150058",
            "paper_id": "R69282",
            "text": "SemEval 2017 Task 10: ScienceIE - Extracting Keyphrases and Relations from Scientific Publications we describe the semeval task of extracting keyphrases and relations between them from scientific documents, which is crucial for understanding which publications describe which processes, tasks and materials. although this was a new task, we had a total of 26 submissions across 3 evaluation scenarios. we expect the task and the findings reported in this paper to be relevant for researchers working on understanding scientific content, as well as the broader knowledge base population and information extraction communities.",
            "contribution_ids": [
                "R69283"
            ]
        },
        {
            "instance_id": "R150570xR147545",
            "comparison_id": "R150570",
            "paper_id": "R147545",
            "text": "GENIA corpus--a semantically annotated corpus for bio-textmining motivation\\nnatural language processing (nlp) methods are regarded as being useful to raise the potential of text mining from biological literature. the lack of an extensively annotated corpus of this literature, however, causes a major bottleneck for applying nlp techniques. genia corpus is being developed to provide reference materials to let nlp techniques work for bio-textmining.\\n\\n\\nresults\\ngenia corpus version 3.0 consisting of 2000 medline abstracts has been released with more than 400,000 words and almost 100,000 annotations for biological terms.",
            "contribution_ids": [
                "R147547"
            ]
        },
        {
            "instance_id": "R150570xR148549",
            "comparison_id": "R150570",
            "paper_id": "R148549",
            "text": "Medmentions: a large biomedical corpus annotated with UMLS concepts this paper presents the formal release of {\\\\em medmentions}, a new manually annotated resource for the recognition of biomedical concepts. what distinguishes medmentions from other annotated biomedical corpora is its size (over 4,000 abstracts and over 350,000 linked mentions), as well as the size of the concept ontology (over 3 million concepts from umls 2017) and its broad coverage of biomedical disciplines. in addition to the full corpus, a sub-corpus of medmentions is also presented, comprising annotations for a subset of umls 2017 targeted towards document retrieval. to encourage research in biomedical named entity recognition and linking, data splits for training and testing are included in the release, and a baseline model and its metrics for entity linking are also described.",
            "contribution_ids": [
                "R148551"
            ]
        },
        {
            "instance_id": "R151435xR151352",
            "comparison_id": "R151435",
            "paper_id": "R151352",
            "text": "Enzymatic glucose biosensor based on ZnO nanorod array grown by hydrothermal decomposition we report herein a glucose biosensor based on glucose oxidase (gox) immobilized on zno nanorod array grown by hydrothermal decomposition. in a phosphate buffer solution with a ph value of 7.4, negatively charged gox was immobilized on positively charged zno nanorods through electrostatic interaction. at an applied potential of +0.8v versus ag\u2215agcl reference electrode, zno nanorods based biosensor presented a high and reproducible sensitivity of 23.1\u03bcacm\u22122mm\u22121 with a response time of less than 5s. the biosensor shows a linear range from 0.01to3.45mm and an experiment limit of detection of 0.01mm. an apparent michaelis-menten constant of 2.9mm shows a high affinity between glucose and gox immobilized on zno nanorods.",
            "contribution_ids": [
                "R151354"
            ]
        },
        {
            "instance_id": "R151435xR151376",
            "comparison_id": "R151435",
            "paper_id": "R151376",
            "text": "ZnO/Cu Nanocomposite: A Platform for Direct Electrochemistry of Enzymes and Biosensing Applications unique structured nanomaterials can facilitate the direct electron transfer between redox proteins and the electrodes. here, in situ directed growth on an electrode of a zno/cu nanocomposite was prepared by a simple corrosion approach, which enables robust mechanical adhesion and electrical contact between the nanostructured zno and the electrodes. this is great help to realize the direct electron transfer between the electrode surface and the redox protein. sem images demonstrate that the morphology of the zno/cu nanocomposite has a large specific surface area, which is favorable to immobilize the biomolecules and construct biosensors. using glucose oxidase (gox) as a model, this zno/cu nanocomposite is employed for immobilization of gox and the construction of the glucose biosensor. direct electron transfer of gox is achieved at zno/cu nanocomposite with a high heterogeneous electron transfer rate constant of 0.67 \u00b1 0.06 s(-1). such zno/cu nanocomposite provides a good matrix for direct electrochemistry of enzymes and mediator-free enzymatic biosensors.",
            "contribution_ids": [
                "R151378"
            ]
        },
        {
            "instance_id": "R152186xR151947",
            "comparison_id": "R152186",
            "paper_id": "R151947",
            "text": "Evidence of lasing on the Balmer-\u00ce\u00b1 line of OVIII in an ablative capillary discharge in a low-inductance ablative discharge through a capillary made of polyacetal (pom), lasing on the balmer-\u03b1 line of oviii at 10.24 nm is identified. in line with previous studies of lasing on cvi ions, it is argued to be the consequence of charge exchange collisions after a m=0 instability. lasing in both cases occurred at about the same time after beginning of the discharge, although lasing on the balmer-\u03b1 line of oviii was less frequently observed, i.e., in approximately one out of ten discharges. lasing on the cvi ion was seen in one out of three discharges. this is probably due to the need of reaching higher electron temperatures to completely strip oxygen ions simultaneously in the hot constrictions (necks) of the plasma instability.",
            "contribution_ids": [
                "R151949"
            ]
        },
        {
            "instance_id": "R152186xR152081",
            "comparison_id": "R152186",
            "paper_id": "R152081",
            "text": "Soft-x-ray amplification in a capillary discharge soft-x-ray amplification in the c vi balmer \\\\ensuremath{\\\\alpha} transition is observed in a capillary discharge. the capillary is made of polyethylene with a bore diameter of 1.2 mm. a hot and dense carbon plasma which is formed on the capillary axis region expands radially and collides with the wall where it undergoes a rapid cooling and subsequent recombination. the amplification takes place in this cool (${\\\\mathit{t}}_{\\\\mathit{e}}$\\\\ensuremath{\\\\sim}13 ev) plasma region, according to space-resolved spectral data obtained using a 2-m grazing incidence spectrograph. the gain coefficient is measured to be 2.8 ${\\\\mathrm{cm}}^{\\\\mathrm{\\\\ensuremath{-}}1}$.",
            "contribution_ids": [
                "R152083"
            ]
        },
        {
            "instance_id": "R152186xR152133",
            "comparison_id": "R152186",
            "paper_id": "R152133",
            "text": "High-power-density capillary discharge plasma columns for shorter wavelength discharge-pumped soft-x-ray lasers we report the generation of plasma columns in gas-filled capillary channels using discharge excitation powers that exceed those of previous studies by one to two orders of magnitude. current pulses up to 200 ka and 10-90 % rise time of about 10 ns (current increase rate equivalent to 1.5 x 10(13) a/s) were utilized to excite plasmas in 3.3 and 4 mm diameter channels. time resolved soft-x-ray spectra and pinhole images of the plasma were obtained. the experimental data and its comparison with model computations suggest that dense argon plasma columns 300 mum in diameter with electron temperatures >250 ev have been obtained. these characteristics make these plasmas of interest for extending discharge-pumped lasers to shorter wavelengths.",
            "contribution_ids": [
                "R152135"
            ]
        },
        {
            "instance_id": "R152282xR149037",
            "comparison_id": "R152282",
            "paper_id": "R149037",
            "text": "The Competent Boundary Spanner inter-organizational frameworks of intervention dominate the resolution of complex societal problems facing the uk and many other countries. strategic alliances, joint working arrangements, networks, partnerships and many other forms of collaboration across sectoral and organizational boundaries currently proliferate across the policy landscape. however, the discourse is positioned at an institutional and organizational level, and comparatively little attention is accorded to the pivotal role of individual actors in the management of inter-organizational relationships. this paper attempts to redress this balance by focusing on the skills, competencies and behaviour of boundary spanners. a critical review of the relevant literature, both from an institutional and relational perspective, is undertaken. this is complemented by some new empirical research that involves an engagement with groups of particular types of boundary spanner using a combination of surveys and in-depth interviews. finally, a discussion makes connections between the existing literature and the research findings and offers suggestions for future areas of enquiry.",
            "contribution_ids": [
                "R149039"
            ]
        },
        {
            "instance_id": "R152282xR149072",
            "comparison_id": "R152282",
            "paper_id": "R149072",
            "text": "Defining the Role of the Smart-City Manager: An Analysis of Responsibilities and Skills abstract increasing social problems are challenging public administrations to adopt new strategies in order to create smarter cities. with regard to this, some cities have created a dedicated organizational unit focused on planning and implementation of smart city (sc) projects, led by an sc manager. however, the sc manager\u2019s responsibilities and curricula remain overlooked. the objective of this paper is to theoretically explore the role of the sc manager in municipalities and to analyze their main responsibilities and skills. based on an empirical questionnaire administered to public managers and politicians, a responsibility index (ri) is defined to identify the domains under the responsibility of the newly-established role of sc manager. the questionnaire is also an opportunity for understanding the main competencies and skills required through a factor analysis and qualitative investigation of the responses.",
            "contribution_ids": [
                "R149074"
            ]
        },
        {
            "instance_id": "R152282xR149075",
            "comparison_id": "R152282",
            "paper_id": "R149075",
            "text": "Required competencies in public administration study programs in the evaluation of undergraduate and graduate study programs, there is an important issue about which competencies must be acquired by graduates. this study tested the importance of competencies in public administration study programs in the light of expectations of employers in slovenian public administration. the aim of the research was to find out how various competencies acquired in higher education (undergraduate and graduate study in public administration) are evaluated by employers in public administration. on the basis of analysis of findings of similar research projects, the competencies contained in programs by renowned universities and competencies defined for the work positions, a set of discipline-specific competencies (61) were designed. research was conducted in 2015 and involved 343 respondents. a qualitative research method (survey) was used to collect the data which were then analyzed with the spss statistical program and microsoft excel. the results show that the competencies related to ethics and ethical behavior were evaluated as the most important; generic competencies are better assessed than specific ones and on average the competencies received a higher assessment for graduates (compare to undergraduates) positions",
            "contribution_ids": [
                "R149077"
            ]
        },
        {
            "instance_id": "R152282xR149078",
            "comparison_id": "R152282",
            "paper_id": "R149078",
            "text": "Administrative Skills and Degrees: The \u00e2\u0080\u009cBest Place\u00e2\u0080\u009d Debate Rages On abstract what should human service administration students learn? where is the best place for them to receive their education? nonprofit administrators, government agency managers, social work professors and public administration educators exhibit considerable agreement regarding what should be taught but little agreement regarding which degree is best. thus, the widespread debate concerning the best degree for non-profit administrators will rage on, with most practitioners preferring the mba and mpa degrees at the top level and academics believing that \u201ctheir\u201d degree is best. despite the disagreement, the msw degree is perceived well at the entry and middle levels of management.",
            "contribution_ids": [
                "R149080"
            ]
        },
        {
            "instance_id": "R152282xR149207",
            "comparison_id": "R152282",
            "paper_id": "R149207",
            "text": "Changing competencies for human resource management: examining e-government scorecard and Federal Human Capital Survey evidence \"as of this writing, effective human capital management is one of the key provisions of the president's management agenda (pma), which is committed to improving management processes on the us federal level to achieve results. while us federal organisations have made significant strides in improving human capital management, a connected component of the pma, e-government, lags behind for several large federal organisations. the connection between human capital management and e-government is a recent one. this manuscript seeks to investigate the connection between these two key components of the president's management agenda to answer the question: 'how are human resource management competencies evolving to reflect changing technology and knowledge management needs?' using data from the president's management scorecard (between 2002 and 2006), and two federal human capital surveys (2004, 2006), this manuscript gives special attention to the association between leading and lagging federal e-government agencies and it and knowledge competence.\"",
            "contribution_ids": [
                "R149209"
            ]
        },
        {
            "instance_id": "R152282xR149211",
            "comparison_id": "R152282",
            "paper_id": "R149211",
            "text": "Identifying government chief information officer education and training needs: the case of Saudi Arabia this paper identifies education and training needs of government chief information officers (gcio) in the kingdom of saudi arabia (ksa). it aims to provide foundation that would assist the ksa national e-government program (yesser) in identifying and prioritizing initiatives oriented towards building the capacity of gcios. based on the results of a survey conducted among gcios and highest it officials of 30 government agencies and the results of four semi-structured interviews, the paper identifies the knowledge areas and skills that should be developed by gcio educational programs, the stages of public sector ict in which gcios are most involved, the preferred delivery modes for the training, the preferred institutions for hosting gcios education and training programs, and the prerequisites for those who should participate in gcio educational programs. in addition to the policy recommendations for the ksa government, the main contribution of the paper is the validation of a methodology that can be applied by any government for designing capacity-building programs for their it leaders.",
            "contribution_ids": [
                "R149213"
            ]
        },
        {
            "instance_id": "R152282xR149221",
            "comparison_id": "R152282",
            "paper_id": "R149221",
            "text": "Conceptualizing Electronic Governance Education responding to the issues of complexity, relevance, cost and risk of electronic governance (egov), we witness a specialization of the roles responsible for egov development and operation, professionalizationof the personnel playing such roles, and utilization of the egov services and information to fulfill citizen needs. in order to build competencies required by such(managerial, professional, technician and user) roles, education becomes a key success factor, and a growing variety of egov learning opportunities emerges. however, lacking conceptual underpinnings for ego education, the discovery, analysis and integration of such opportunities is difficult. to address this need, the paper develops a theoretical construct for ego education, applies six measures to this construct: who-- learners, why -- roles, what -- competencies, how --programs, where -- schools, and when -- prerequisites, and validates it through a landscaping exercise focusing on egov university programs.",
            "contribution_ids": [
                "R149223"
            ]
        },
        {
            "instance_id": "R152282xR149726",
            "comparison_id": "R152282",
            "paper_id": "R149726",
            "text": "Competency Frameworks in The Belgian Governments: Causes, Construction and Contents the belgian federal government and the belgian flemish government have picked up competency management as a multifaceted tool to suit their own visions of organizational change rather than simply responding to a new management trend in the private sector. both governments have used it to foster both vertical and horizontal integration in their fragmented administrations, and to deal with problems of recruitment and retention of qualified personnel. the analysis presented here also reveals that the seemingly uniform use of \u2018competency speak\u2019 hides multiple dimensions that provide several solutions to different organizational problems. at the same time, the cases examined demonstrate how the new tools both serve and disconcert the diverse bureau-political interests of top civil servants, trade unions and human resource management units. in addition, we examine how the new tools break with at least two traditional features of the highly formal and rigid career systems and the relatively low status of officials in the belgian administrations.",
            "contribution_ids": [
                "R149728"
            ]
        },
        {
            "instance_id": "R152282xR149740",
            "comparison_id": "R152282",
            "paper_id": "R149740",
            "text": "Requisite competencies for government Chief Information Officer in Sri Lanka \"developed countries such as usa, australia and eu have technology savvy executives in certain government sector organizations performing the cio\u2019s role. these countries have managed to improve their government sector delivery of services to citizens leveraging on it/is. however, in sri lanka there is very low recognition for the role of a cio in government sector organizations and even in private sector organizations. \\ndifferent cios may be equipped with their own set of different skills. however, it is undoubtedly important for cios to acquire the particularly necessary set of skills, knowledge and experience that would enable them to act as catalysts in strategically and efficiently using it to improve their organization's service delivery. \\nconsidering the above facts, the authors did an empirical research study based on an extensive literature review. the research goals were to, (1) evaluate the set of competencies required of sri lankan cios and, (2) provide an understanding of the way the cio role should be formulated, such that it will have an impact on the strategy of sri lankan organizations. it is envisioned that the recommendations of this study will provide the necessary information to it directors and senior executives in government organizations to develop the competencies required to enable them to effectively function as cios.\"",
            "contribution_ids": [
                "R149742"
            ]
        },
        {
            "instance_id": "R152282xR149772",
            "comparison_id": "R152282",
            "paper_id": "R149772",
            "text": "The Skill Set of the Successful Collaborator in this article, the authors focus on members of the u.s. senior executive service who choose collaboration as a management strategy to increase performance and, in particular, their views of the skill set of a successful collaborator. based on the current literature on collaboration and networks, these executives might be expected to identify strategic thinking and strategic management as the most important skills. contrary to expectations, the federal executives most frequently mentioned individual attributes and interpersonal skills as essential for successful collaboration, followed by group process skills, strategic leadership skills, and substantive/technical expertise. the article provides empirical substantiation of the previous literature, with one major difference: the strong reporting of the importance of individual attributes by federal executives (much more than previously reported by other scholars in the field). strategic leadership skills, strategic management skills, and technical skills matter, but they are not the most important factors behind successful collaborations, according to federal executives.",
            "contribution_ids": [
                "R149774"
            ]
        },
        {
            "instance_id": "R154289xR147129",
            "comparison_id": "R154289",
            "paper_id": "R147129",
            "text": "A Hierarchical Attention Retrieval Model for Healthcare Question Answering the growth of the web in recent years has resulted in the development of various online platforms that provide healthcare information services. these platforms contain an enormous amount of information, which could be beneficial for a large number of people. however, navigating through such knowledgebases to answer specific queries of healthcare consumers is a challenging task. a majority of such queries might be non-factoid in nature, and hence, traditional keyword-based retrieval models do not work well for such cases. furthermore, in many scenarios, it might be desirable to get a short answer that sufficiently answers the query, instead of a long document with only a small amount of useful information. in this paper, we propose a neural network model for ranking documents for question answering in the healthcare domain. the proposed model uses a deep attention mechanism at word, sentence, and document levels, for efficient retrieval for both factoid and non-factoid queries, on documents of varied lengths. specifically, the word-level cross-attention allows the model to identify words that might be most relevant for a query, and the hierarchical attention at sentence and document levels allows it to do effective retrieval on both long and short documents. we also construct a new large-scale healthcare question-answering dataset, which we use to evaluate our model. experimental evaluation results against several state-of-the-art baselines show that our model outperforms the existing retrieval techniques.",
            "contribution_ids": [
                "R147131"
            ]
        },
        {
            "instance_id": "R154289xR147992",
            "comparison_id": "R154289",
            "paper_id": "R147992",
            "text": "Large-scale semantic parsing via schema matching and lexicon extension supervised training procedures for semantic parsers produce high-quality semantic parsers, but they have difficulty scaling to large databases because of the sheer number of logical constants for which they must see labeled training data. we present a technique for developing semantic parsers for large databases based on a reduction to standard supervised training algorithms, schema matching, and pattern learning. leveraging techniques from each of these areas, we develop a semantic parser for freebase that is capable of parsing questions with an f1 that improves by 0.42 over a purely-supervised learning algorithm.",
            "contribution_ids": [
                "R147994"
            ]
        },
        {
            "instance_id": "R155101xR154337",
            "comparison_id": "R155101",
            "paper_id": "R154337",
            "text": "High-Repetition-Rate Grazing-Incidence Pumped X-Ray Laser Operating at 18.9\u00c2\u00a0nm we have demonstrated a 10 hz ni-like mo x-ray laser operating at 18.9 nm with 150 mj total pump energy by employing a novel pumping scheme. the grazing-incidence scheme is described, where a picosecond pulse is incident at a grazing angle to a mo plasma column produced by a slab target irradiated by a 200 ps laser pulse. this scheme uses refraction of the short pulse at a predetermined electron density to increase absorption to pump a specific gain region. the higher coupling efficiency inherent to this scheme allows a reduction in the pump energy where 70 mj long pulse energy and 80 mj short pulse energy are sufficient to produce lasing at a 10 hz repetition rate. under these conditions and by optimizing the delay between the pulses, we achieve strong amplification and close to saturation for 4 mm long targets.",
            "contribution_ids": [
                "R154338"
            ]
        },
        {
            "instance_id": "R155101xR154961",
            "comparison_id": "R155101",
            "paper_id": "R154961",
            "text": "High-average-power, 100-Hz-repetition-rate, tabletop soft-x-ray lasers at sub-15-nm wavelengths efficient excitation of dense plasma columns at 100-hz repetition rate using a tailored pump pulse profile produced a tabletop soft-x-ray laser average power of 0.1 mw at = 13.9 nm and 20 w at = 11.9 nm from transitions of ni-like ag and ni-like sn, respectively. lasing on several other transitions with wavelengths between 10.9 and 14.7 nm was also obtained using 0.9-j pump pulses of 5-ps duration from a compact diode-pumped chirped pulse amplification yb:yag laser. hydrodynamic and atomic plasma simulations show that the pump pulse profile, consisting of a nanosecond ramp followed by two peaks of picosecond duration, creates a plasma with an increased density of ni-like ions at the time of peak temperature that results in a larger gain coefficient over a temporally and spatially enlarged space leading to a threefold increase in the soft-x-ray laser output pulse energy. the high average power of these compact soft-x-ray lasers will enable applications requiring high photon flux. these results open the path to milliwatt-average-power tabletop soft-x-ray lasers.",
            "contribution_ids": [
                "R154962"
            ]
        },
        {
            "instance_id": "R155101xR155047",
            "comparison_id": "R155101",
            "paper_id": "R155047",
            "text": "Compact gain-saturated x-ray lasers down to 685\u00e2\u0080\u0089\u00e2\u0080\u0089nm and amplification down to 585\u00e2\u0080\u0089\u00e2\u0080\u0089nm plasma-based x-ray lasers allow single-shot nano-scale imaging and other experiments requiring a large number of photons per pulse to be conducted in compact facilities. however, compact repetitively fired gain-saturated x-ray lasers have been limited to wavelengths above \u03bb=8.85\\u2009\\u2009nm. here we extend their range to \u03bb=6.85\\u2009\\u2009nm by transient traveling wave excitation of ni-like gd ions in a plasma created with an optimized pre-pulse followed by rapid heating with an intense sub-picosecond pump pulse. isoelectronic scaling also produced strong lasing at 6.67\\xa0nm and 6.11\\xa0nm in ni-like tb and amplification at 6.41\\xa0nm and 5.85\\xa0nm in ni-like dy. this scaling to shorter wavelengths was obtained by progressively increasing the pump pulse grazing incidence angle to access increased plasma densities. we experimentally demonstrate that the optimum grazing incidence angle increases linearly with atomic number from 17\\xa0deg for z=42 (mo) to 43\\xa0deg for z=66 (dy). the results will enable applications of sub-7\\xa0nm lasers at compact facilities.",
            "contribution_ids": [
                "R155050"
            ]
        },
        {
            "instance_id": "R155621xR151517",
            "comparison_id": "R155621",
            "paper_id": "R151517",
            "text": "Cyclodextrins in eye drop formulations: enhanced topical delivery of corticosteroids to the eye: Acta\n Ophthalmologica\n Scandinavica\n 2002 \"cyclodextrins are cylindrical oligosaccharides with a lipophilic central cavity and hydrophilic outer surface. they can form water-soluble complexes with lipophilic drugs, which 'hide' in the cavity. cyclodextrins can be used to form aqueous eye drop solutions with lipophilic drugs, such as steroids and some carbonic anhydrase inhibitors. the cyclodextrins increase the water solubility of the drug, enhance drug absorption into the eye, improve aqueous stability and reduce local irritation. cyclodextrins are useful excipients in eye drop formulations of various drugs, including steroids of any kind, carbonic anhydrase inhibitors, pilocarpine, cyclosporins, etc. their use in ophthalmology has already begun and is likely to expand the selection of drugs available as eye drops. in this paper we review the properties of cyclodextrins and their application in eye drop formulations, of which their use in the formulation of dexamethasone eye drops is an example. cyclodextrins have been used to formulate eye drops containing corticosteroids, such as dexamethasone, with levels of concentration and ocular absorption which, according to human and animal studies, are many times those seen with presently available formulations. cyclodextrin-based dexamethasone eye drops are well tolerated in the eye and seem to provide a higher degree of bioavailability and clinical efficiency than the steroid eye drop formulations presently available. such formulations offer the possibility of once per day application of corticosteroid eye drops after eye surgery, and more intensive topical steroid treatment in severe inflammation. while cyclodextrins have been known for more than a century, their use in ophthalmology is just starting. cyclodextrins are useful excipients in eye drop formulations for a variety of lipophilic drugs. they will facilitate eye drop formulations for drugs that otherwise might not be available for topical use, while improving absorption and stability and decreasing local irritation.\"",
            "contribution_ids": [
                "R151519"
            ]
        },
        {
            "instance_id": "R155621xR151616",
            "comparison_id": "R155621",
            "paper_id": "R151616",
            "text": "Influence of Hydroxypropyl \u00ce\u00b2-Cyclodextrin on the Corneal Permeation of Pilocarpine abstract the influence of hydroxypropyl \u03b2-cyclodextrin (hp\u03b2cd) on the corneal permeation of pilocarpine nitrate was investigated by an in vitro permeability study using isolated rabbit cornea. pupillary-response pattern to pilocarpine nitrate with and without hp\u03b2cd was examined in rabbit eye. corneal permeation of pilocarpine nitrate was found to be four times higher after adding hp\u03b2cd into the formulation. the reduction of pupil diameter (miosis) by pilocarpine nitrate was significantly increased as a result of hp\u03b2cd addition into the simple aqueous solution of the active substance. the highest miotic response was obtained with the formulation prepared in a vehicle of carbopol\u00ae 940. it is suggested that ocular bioavailability of pilocarpine nitrate could be improved by the addition of hp\u03b2cd.",
            "contribution_ids": [
                "R151618"
            ]
        },
        {
            "instance_id": "R155621xR151628",
            "comparison_id": "R155621",
            "paper_id": "R151628",
            "text": "Improvement of Nasal Bioavailability of Luteinizing Hormone-Releasing Hormone Agonist, Buserelin, by Cyclodextrin Derivatives in Rats the effects of chemically modified cyclodextrins on the nasal absorption of buserelin, an agonist of luteinizing hormone-releasing hormone, were investigated in anesthetized rats. of the cyclodextrins tested, dimethyl-beta-cyclodextrin (dm-beta-cyd) was the most effective in improving the rate and extent of the nasal bioavailability of buserelin. fluorescence spectroscopic studies indicated that the cyclodextrins formed inclusion complexes with buserelin, which may reduce the diffusibility of buserelin across the nasal epithelium and may participate in the protection of the peptide against enzymatic degradation in the nasal mucosa. additionally, the cyclodextrins increased the permeability of the nasal mucosa, which was the primary determinant based on the multiple regression analysis of the nasal absorption enhancement of buserelin. scanning electron microscopic observations revealed that dm-beta-cyd induced no remarkable changes in the surface morphology of the nasal mucosa at a minimal concentration necessary to achieve substantial absorption enhancement. the present results suggest that dm-beta-cyd could improve the nasal bioavailability of buserelin and is well-tolerated by the nasal mucosa of the rat.",
            "contribution_ids": [
                "R151630"
            ]
        },
        {
            "instance_id": "R155621xR155590",
            "comparison_id": "R155621",
            "paper_id": "R155590",
            "text": "The Effect of Cyclodextrins on the In Vitro and In Vivo Properties of Insulin-Loaded Poly (D,L-Lactic-Co-Glycolic Acid) Microspheres: EFFECT OF CYCLODEXTRINS ON MICROSPHERES in this work we describe the development and characterization of a new formulation of insulin (ins). insulin was complexed with cyclodextrins (cd) in order to improve its solubility and stability being available as a dry powder, after encapsulation into poly (d,l-lactic-co-glycolic acid) (plga) microspheres. the complex ins : cd was encapsulated into microspheres in order to obtain particles with an average diameter between 2 and 6 microm. this system was able to induce significant reduction of the plasma glucose level in two rodent models, normal mice and diabetic rats, after intratracheal administration.",
            "contribution_ids": [
                "R155592"
            ]
        },
        {
            "instance_id": "R157074xR157039",
            "comparison_id": "R157074",
            "paper_id": "R157039",
            "text": "DNA barcode library for European Gelechiidae (Lepidoptera) suggests greatly underestimated species diversity for the first time, a nearly complete barcode library for european gelechiidae is provided. dna barcode sequences (coi gene \u2013 cytochrome c oxidase 1) from 751 out of 865 nominal species, belonging to 105 genera, were successfully recovered. a total of 741 species represented by specimens with sequences \u2265 500bp and an additional ten species represented by specimens with shorter sequences were used to produce 53 nj trees. intraspecific barcode divergence averaged only 0.54% whereas distance to the nearest-neighbour species averaged 5.58%. of these, 710 species possessed unique dna barcodes, but 31 species could not be reliably discriminated because of barcode sharing or partial barcode overlap. species discrimination based on the barcode index system (bin) was successful for 668 out of 723 species which clustered from minimum one to maximum 22 unique bins. fifty-five species shared a bin with up to four species and identification from dna barcode data is uncertain. finally, 65 clusters with a unique bin remained unidentified to species level. these putative taxa, as well as 114 nominal species with more than one bin, suggest the presence of considerable cryptic diversity, cases which should be examined in future revisionary studies.",
            "contribution_ids": [
                "R157043"
            ]
        },
        {
            "instance_id": "R157326xR156333",
            "comparison_id": "R157326",
            "paper_id": "R156333",
            "text": "Demonstration of a Soft X-Ray Amplifier we report observations of amplified spontaneous emission at soft x-ray wavelengths. an optical laser ionized thin foils of selenium to produce a population inversion of the $2{p}^{5}3p$ and $2{p}^{5}3s$ levels of the neonlike ion. using three time-resolved, spectroscopic measurements we demonstrated gain-length products up to 6.5 and gain coefficients of 5.5\\\\ifmmode\\\\pm\\\\else\\\\textpm\\\\fi{}1.0 ${\\\\mathrm{cm}}^{\\\\ensuremath{-}1}$ for the $j=2 \\\\mathrm{to} 1$ lines at 206.3 and 209.6 \\\\aa{}. we also observed considerable amplification for the same transitions in yttrium at 155.0 and 157.1 \\\\aa{}.",
            "contribution_ids": [
                "R156334"
            ]
        },
        {
            "instance_id": "R157326xR156663",
            "comparison_id": "R157326",
            "paper_id": "R156663",
            "text": "Short wavelength x\u00e2\u0080\u0090ray laser research at the Lawrence Livermore National Laboratory laboratory x\u2010ray lasers are currently being studied by researchers worldwide. this paper reviews some of the recent work carried out at lawrence livermore national laboratory. laser action has been demonstrated at wavelengths as short as 35.6 a while saturation of the small signal gain has been observed with longer wavelength schemes. some of the most successful schemes to date have been collisionally pumped x\u2010ray lasers that use the thermal electron distribution within a laser\u2010produced plasma to excite electrons from closed shells in neon\u2010 and nickel\u2010like ions to metastable levels in the next shell. attempts to quantify and improve the longitudinal and transverse coherence of collisionally pumped x\u2010ray lasers are motivated by the desire to produce sources for specific applications. toward this goal there is a large effort underway to enhance the power output of the ni\u2010like ta x\u2010ray laser at 44.83 a as a source for x\u2010ray imaging of live cells. improving the efficiency of x\u2010ray lasers in order to produce s...",
            "contribution_ids": [
                "R156665"
            ]
        },
        {
            "instance_id": "R157326xR156908",
            "comparison_id": "R157326",
            "paper_id": "R156908",
            "text": "Saturated and Short Pulse Duration X-Ray Lasers the basis of a model of the relationship between gain and output laser intensity is reviewed and the measurement of the duration of x\u2010ray lasing with a streak camera with 700 fs temporal resolution is described. combined with a temporal smearing due to the spectrometer employed, we have measured x\u2010ray laser pulse durations for ni\u2010like silver at 13.9 nm and ne\u2010like nickel at 23.1 nm with a total time resolution of 1.1 ps. an extension of the model is shown to consistently relate the measured x\u2010ray laser pulse duration to estimates of the gain duration obtained by temporally resolving resonance line emission from states near in energy to the upper lasing level.",
            "contribution_ids": [
                "R156910"
            ]
        },
        {
            "instance_id": "R160742xR160723",
            "comparison_id": "R160742",
            "paper_id": "R160723",
            "text": "Ocean carbon cycling in the Indian Ocean: 1. Spatiotemporal variability of inorganic carbon and air-sea CO2gas exchange: INDIAN OCEAN CARBON CYCLE, 1 the spatiotemporal variability of upper ocean inorganic carbon parameters and air\u2010sea co2 exchange in the indian ocean was examined using inorganic carbon data collected as part of the world ocean circulation experiment (woce) cruises in 1995. multiple linear regression methods were used to interpolate and extrapolate the temporally and geographically limited inorganic carbon data set to the entire indian ocean basin using other climatological hydrographic and biogeochemical data. the spatiotemporal distributions of total carbon dioxide (tco2), alkalinity, and seawater pco2 were evaluated for the indian ocean and regions of interest including the arabian sea, bay of bengal, and 10\u00b0n\u201335\u00b0s zones. the indian ocean was a net source of co2 to the atmosphere, and a net sea\u2010to\u2010air co2 flux of +237 \u00b1 132 tg c yr\u22121 (+0.24 pg c yr\u22121) was estimated. regionally, the arabian sea, bay of bengal, and 10\u00b0n\u201310\u00b0s zones were perennial sources of co2 to the atmosphere. in the 10\u00b0s\u201335\u00b0s zone, the co2 sink or source status of the surface ocean shifts seasonally, although the region is a net oceanic sink of atmospheric co2.",
            "contribution_ids": [
                "R160724"
            ]
        },
        {
            "instance_id": "R160742xR160733",
            "comparison_id": "R160742",
            "paper_id": "R160733",
            "text": "Environmental controls on the seasonal carbon dioxide fluxes in the northeastern Indian Ocean total carbon dioxide (tco 2) and computations of partial pressure of carbon dioxide (pco 2) had been examined in northerneastern region of indian ocean. it exhibit seasonal and spatial variability. north-south gradients in the pco 2 levels were closely related to gradients in salinity caused by fresh water discharge received from rivers. eddies observed in this region helped to elevate the nutrients availability and the biological controls by increasing the productivity. these phenomena elevated the carbon dioxide draw down during the fair seasons. seasonal fluxes estimated from local wind speed and air-sea carbon dioxide difference indicate that during southwest monsoon, the northeastern indian ocean acts as a strong sink of carbon dioxide (-20.04 mmol m \u20132 d -1 ). also during fall intermonsoon the area acts as a weak sink of carbon dioxide (-4.69 mmol m \u20132 d -1 ). during winter monsoon, this region behaves as a weak carbon dioxide source with an average sea to air flux of 4.77 mmol m -2 d -1 . in the northern region, salinity levels in the surface level are high during winter compared to the other two seasons. northeastern indian ocean shows significant intraseasonal variability in carbon dioxide fluxes that are mediated by eddies which provide carbon dioxide and nutrients from the subsurface waters to the mixed layer.",
            "contribution_ids": [
                "R160734"
            ]
        },
        {
            "instance_id": "R160847xR160810",
            "comparison_id": "R160847",
            "paper_id": "R160810",
            "text": "Influence of Process and Formulation Parameters on Dissolution and Stability Characteristics of Kollidon\u00c2\u00ae VA 64 Hot-Melt Extrudates the objective of the present study was to investigate the effects of processing variables and formulation factors on the characteristics of hot-melt extrudates containing a copolymer (kollidon\u00ae va 64). nifedipine was used as a model drug in all of the extrudates. differential scanning calorimetry (dsc) was utilized on the physical mixtures and melts of varying drug\u2013polymer concentrations to study their miscibility. the drug\u2013polymer binary mixtures were studied for powder flow, drug release, and physical and chemical stabilities. the effects of moisture absorption on the content uniformity of the extrudates were also studied. processing the materials at lower barrel temperatures (115\u2013135\u00b0c) and higher screw speeds (50\u2013100\\xa0rpm) exhibited higher post-processing drug content (~99\u2013100%). dsc and x-ray diffraction studies confirmed that melt extrusion of drug\u2013polymer mixtures led to the formation of solid dispersions. interestingly, the extrusion process also enhanced the powder flow characteristics, which occurred irrespective of the drug load (up to 40% w/w). moreover, the content uniformity of the extrudates, unlike the physical mixtures, was not sensitive to the amount of moisture absorbed. the extrusion conditions did not influence drug release from the extrudates; however, release was greatly affected by the drug loading. additionally, the drug release from the physical mixture of nifedipine\u2013kollidon\u00ae va 64 was significantly different when compared to the corresponding extrudates (f2\\u2009=\\u200936.70). the extrudates exhibited both physical and chemical stabilities throughout the period of study. overall, hot-melt extrusion technology in combination with kollidon\u00ae va 64 produced extrudates capable of higher drug loading, with enhanced flow characteristics, and excellent stability.",
            "contribution_ids": [
                "R160812"
            ]
        },
        {
            "instance_id": "R160847xR160844",
            "comparison_id": "R160847",
            "paper_id": "R160844",
            "text": "Solid-state characterization of Felodipine\u00e2\u0080\u0093Soluplus amorphous solid dispersions abstract the aim of the current study is to develop amorphous solid dispersion (sd) via hot melt extrusion technology to improve the solubility of a water-insoluble compound, felodipine (fel). the solubility was dramatically increased by preparation of amorphous sds via hot-melt extrusion with an amphiphilic polymer, soluplus\u00ae (sol). fel was found to be miscible with sol by calculating the solubility parameters. the solubility of fel within sol was determined to be in the range of 6.2\u20139.9% (w/w). various techniques were applied to characterize the solid-state properties of the amorphous sds. these included fourier transform infrared spectrometry spectroscopy and raman spectroscopy to detect the formation of hydrogen bonding between the drug and the polymer. scanning electron microscopy was performed to study the morphology of the sds. among all the hot-melt extrudates, fel was found to be molecularly dispersed within the polymer matrix for the extrudates containing 10% drug, while few small crystals were detected in the 30 and 50% extrudates. in conclusion, solubility of fel was enhanced while a homogeneous sd was achieved for 10% drug loading.",
            "contribution_ids": [
                "R160846"
            ]
        },
        {
            "instance_id": "R161728xR160274",
            "comparison_id": "R161728",
            "paper_id": "R160274",
            "text": "Smart City Digital Twin\u00e2\u0080\u0093Enabled Energy Management: Toward Real-Time Urban Building Energy Benchmarking abstractto meet energy-reduction goals, cities are challenged with assessing building energy performance and prioritizing efficiency upgrades across existing buildings. although current top-down bu...",
            "contribution_ids": [
                "R160277"
            ]
        },
        {
            "instance_id": "R161728xR160331",
            "comparison_id": "R161728",
            "paper_id": "R160331",
            "text": "An Architecture for Blockchain over Edge-enabled IoT for Smart Circular Cities \"circular economy is a novel economic model, where every 'asset' is not wasted but reused and upscaled. the internet of things-iot paradigm can underpin the transition to a circular economy by enabling fine-grained and continuous asset tracking. however, there are issues related to security and privacy of iot devices that generate and handle sensitive and personal data. the use of blockchain technology provides an answer to this issue, however, its application raises issues related to the highly-constrained nature of these networks. in this paper, edge computing is presented as a solution to this issue, providing a way in which blockchain and edge computing can be used together to address the constrained nature of iot. furthermore, we present the challenges that this combination poses and the opportunities that it brings. we propose an architecture that decreases the iot devices requirements for memory capacity and increases the overall performance. we also discuss the architecture design and the challenges that it has, comparing it to the traditional blockchain architecture as well as an edge computing architecture for mobile blockchain. the paper closes with a discussion and future extensions of our work are presented, as well.\"",
            "contribution_ids": [
                "R160333"
            ]
        },
        {
            "instance_id": "R161728xR160374",
            "comparison_id": "R161728",
            "paper_id": "R160374",
            "text": "A Digital Twin Paradigm: Vehicle-to-Cloud Based Advanced Driver Assistance Systems digital twin, an emerging representation of cyberphysical systems, has attracted increasing attentions very recently. it opens the way to real-time monitoring and synchronization of real-world activities with the virtual counterparts. in this study, we develop a digital twin paradigm using an advanced driver assistance system (adas) for connected vehicles. by leveraging vehicle-to-cloud (v2c) communication, on-board devices can upload the data to the server through cellular network. the server creates a virtual world based on the received data, processes them with the proposed models, and sends them back to the connected vehicles. drivers can benefit from this v2c based adas, even if all computations are conducted on the cloud. the cooperative ramp merging case study is conducted, and the field implementation results show the proposed digital twin framework can benefit the transportation systems regarding mobility and environmental sustainability with acceptable communication delays and packet losses.",
            "contribution_ids": [
                "R160376"
            ]
        },
        {
            "instance_id": "R161728xR160384",
            "comparison_id": "R161728",
            "paper_id": "R160384",
            "text": "A Digital Twin-based Privacy Enhancement Mechanism for the Automotive Industry this paper discusses a digital twin demonstrator for privacy enhancement in the automotive industry. here, the digital twin demonstrator is presented as a method for the design and implementation of privacy enhancement mechanisms, and is used to detect privacy concerns and minimize breaches and associated risks to which smart car drivers can be exposed through connected infotainment applications and services. the digital twin-based privacy enhancement demonstrator is designed to simulate variety of conditions that can occur in the smart car ecosystem. we firstly identify the core stakeholders (actors) in the smart car ecosystem, their roles and exposure to privacy vulnerabilities and associated risks. secondly, we identify assets that consume and generate sensitive privacy data in smart cars, their functionalities, and relevant privacy concerns and risks. thirdly, we design an infrastructure for collecting (i) real-time sensor data from smart cars and their assets, and (ii) environmental data, road and traffic data, generated through operational driving lifecycle. in order to ensure compliance of the collected data with privacy policies and regulations, e.g. with gdpr requirements for enforcement of the data subject\u2019s rights, we design methods for the digital twin-based privacy enhancement demonstrator that are based on behavioural analytics informed by gdpr. we also perform data anonymization to minimize privacy risks and enable actions such as sending an automatic informed consent to the stakeholders.",
            "contribution_ids": [
                "R160386"
            ]
        },
        {
            "instance_id": "R161728xR160390",
            "comparison_id": "R161728",
            "paper_id": "R160390",
            "text": "Collaborative city digital twin for the COVID-19 pandemic: A federated learning solution \"in this work, we propose a collaborative city digital twin based on fl, a novel paradigm that allowing multiple city dt to share the local strategy and status in a timely manner. in particular, an fl central server manages the local updates of multiple collaborators (city dt), provides a global model which is trained in multiple iterations at different city dt systems, until the model gains the correlations between various response plan and infection trend. that means, a collaborative city dt paradigm based on fl techniques can obtain knowledge and patterns from multiple dts, and eventually establish a `global view' for city crisis management. meanwhile, it also helps to improve each city digital twin selves by consolidating other dt's respective data without violating privacy rules. to validate the proposed solution, we take covid-19 pandemic as a case study. the experimental results on the real dataset with various response plan validate our proposed solution and demonstrate the superior performance.\"",
            "contribution_ids": [
                "R160392"
            ]
        },
        {
            "instance_id": "R161728xR160395",
            "comparison_id": "R161728",
            "paper_id": "R160395",
            "text": "Building and exploiting a Digital Twin for the management of drinking water distribution networks abstract digital twins (dts) are starting to be exploited to improve the management of water distribution systems (wdss) and, in the future, they will be crucial for decision making. in this paper, the authors propose several requirements that a dt of a water distribution system should accomplish. developing a dt is a challenge, and a continuous process of adjustments and learning is required. due to the advantages of having a dt of the wds always available, during the last years a strategy to build and maintain a dt of the water distribution network of valencia (spain) and its metropolitan area (1.6 million inhabitants) was developed. this is one of the first dts built of a water utility, being currently in operation. the great benefits of their use in the daily operation of the system ensure that they will begin to be usual in the most advanced smart cities.",
            "contribution_ids": [
                "R160398"
            ]
        },
        {
            "instance_id": "R161728xR160402",
            "comparison_id": "R161728",
            "paper_id": "R160402",
            "text": "BIM and IoT: A Synopsis from GIS Perspective abstract. internet-of-things (iot) focuses on enabling communication between all devices, things that are existent in real life or that are virtual. building information models (bims) and building information modelling is a hype that has been the buzzword of the construction industry for last 15 years. bims emerged as a result of a push by the software companies, to tackle the problems of inefficient information exchange between different software and to enable true interoperability. in bim approach most up-to-date an accurate models of a building are stored in shared central databases during the design and the construction of a project and at post-construction stages. gis based city monitoring / city management applications require the fusion of information acquired from multiple resources, bims, city models and sensors. this paper focuses on providing a method for facilitating the gis based fusion of information residing in digital building \u201cmodels\u201d and information acquired from the city objects i.e. \u201cthings\u201d. once this information fusion is accomplished, many fields ranging from emergency response, urban surveillance, urban monitoring to smart buildings will have potential benefits.\\n",
            "contribution_ids": [
                "R160404"
            ]
        },
        {
            "instance_id": "R161729xR159456",
            "comparison_id": "R161729",
            "paper_id": "R159456",
            "text": "Geospatial Artificial Intelligence: Potentials of Machine Learning for 3D Point Clouds and Geospatial Digital Twins abstract artificial intelligence (ai) is changing fundamentally the way how it solutions are implemented and operated across all application domains, including the geospatial domain. this contribution outlines ai-based techniques for 3d point clouds and geospatial digital twins as generic components of geospatial ai. first, we briefly reflect on the term \u201cai\u201d and outline technology developments needed to apply ai to it solutions, seen from a software engineering perspective. next, we characterize 3d point clouds as key category of geodata and their role for creating the basis for geospatial digital twins; we explain the feasibility of machine learning (ml) and deep learning (dl) approaches for 3d point clouds. in particular, we argue that 3d point clouds can be seen as a corpus with similar properties as natural language corpora and formulate a \u201cnaturalness hypothesis\u201d for 3d point clouds. in the main part, we introduce a workflow for interpreting 3d point clouds based on ml/dl approaches that derive domain-specific and application-specific semantics for 3d point clouds without having to create explicit spatial 3d models or explicit rule sets. finally, examples are shown how ml/dl enables us to efficiently build and maintain base data for geospatial digital twins such as virtual 3d city models, indoor models, or building information models.",
            "contribution_ids": [
                "R159458"
            ]
        },
        {
            "instance_id": "R161729xR160217",
            "comparison_id": "R161729",
            "paper_id": "R160217",
            "text": "Methodological Framework for Digital Transition and Performance Assessment of Smart Cities the ultimate goal of smart cities is to improve citizens\u2019 quality of life in a scenario where technological solutions challenge urban governance. however, the knowledge and framework for data use for smart cities remain relatively unknown. the actual translation of city problems into diverse actions requires specific methodologies to guide digital transitions of cities and to assess to what extent the smart cities\u2019 initiatives pursue sustainable development goals. this paper proposes a methodological framework for digital modelling of cities allowing assessment of their performance and supporting decision making. the city model adopts the concept of digital twin as a powerful tool for discussion between stakeholders, as well as citizens to find the smartest solutions and get valuable insight after their deployment. the methodological framework is presented as a set of digital twin concept, stages of digital twinning and implementation strategy. furthermore, the most common city information models, suitable for implementation of digital twins are summarized.",
            "contribution_ids": [
                "R160219"
            ]
        },
        {
            "instance_id": "R161729xR160256",
            "comparison_id": "R161729",
            "paper_id": "R160256",
            "text": "Devising a Game Theoretic Approach to Enable Smart City Digital Twin Analytics despite investments in advancing information and communications technology (ict)-integrated infrastructure systems toward becoming smarter cities, cities often face a large gap between smart sustainable supply and demand. here, we review the core concepts of ict-integrated infrastructure systems as they pertain to developing smart and sustainable cities, and describe how a game theoretic-based digital twin of a city can enable more visibility and insight into the successful implementation of such systems. this study is a foundational step toward enabling participation of all city stakeholders (i.e., government, industry, and citizens) in the decision making process and the creation of smart sustainable cities. engaging city stakeholders in such a manner allows for collective participation in changes, which can enable continuous adaptation toward more sustaining growth and prosperity. 1. smart sustainable cities 1.1. urbanization, growth of supply and demand, and urge for efficiency between 1950 and 2018, the world\u2019s urban population have grown from 751 to more than 4.2 billion. projections anticipate that, by 2050, they will constitute nearly 70% of the world population [1]. in the united states, currently the most urbanized region in the world, this percentage is expected to increase to",
            "contribution_ids": [
                "R160258"
            ]
        },
        {
            "instance_id": "R162329xR162021",
            "comparison_id": "R162329",
            "paper_id": "R162021",
            "text": "Sub-38 nm resolution tabletop microscopy with 13 nm wavelength laser light we have acquired images with a spatial resolution better than 38 nm by using a tabletop microscope that combines 13 nm wavelength light from a high-brightness tabletop laser and fresnel zone plate optics. these results open a gateway to the development of compact and widely available extreme-ultraviolet imaging tools capable of inspecting samples in a variety of environments with a 15-20 nm spatial resolution and a picosecond time resolution.",
            "contribution_ids": [
                "R162023"
            ]
        },
        {
            "instance_id": "R162329xR162104",
            "comparison_id": "R162329",
            "paper_id": "R162104",
            "text": "Single-shot soft-x-ray digital holographic microscopy with an adjustable field of view and magnification single-shot digital holographic microscopy with an adjustable field of view and magnification was demonstrated by using a tabletop 32.8 nm soft-x-ray laser. the holographic images were reconstructed with a two-dimensional fast-fourier-transform algorithm, and a new configuration of imaging was developed to overcome the pixel-size limit of the recording device without reducing the effective na. the image of an atomic-force-microscope cantilever was reconstructed with a lateral resolution of 480 nm, and the phase contrast image of a 20 nm carbon mesh foil demonstrated that profiles of sample thickness can be reconstructed with few-nanometers uncertainty. the ultrashort x-ray pulse duration combined with single-shot capability offers great advantage for flash imaging of delicate samples.",
            "contribution_ids": [
                "R162106"
            ]
        },
        {
            "instance_id": "R162329xR162244",
            "comparison_id": "R162329",
            "paper_id": "R162244",
            "text": "Single-shot soft x-ray laser linewidth measurement using a grating interferometer the linewidth of a 14.7 nm wavelength ni-like pd soft x-ray laser was measured in a single shot using a soft x-ray diffraction grating interferometer. the instrument uses the time delay introduced by the gratings across the beam to measure the temporal coherence. the spectral linewidth of the 4d1s0-4p1p1 ni-like pd lasing line was measured to be \u03b4\u03bb/\u03bb=3\u00d710(-5) from the fourier transform of the fringe visibility. this single shot linewidth measurement technique provides a rapid and accurate way to determine the temporal coherence of soft x-ray lasers that can contribute to the development of femtosecond plasma-based soft x-ray lasers.",
            "contribution_ids": [
                "R162245"
            ]
        },
        {
            "instance_id": "R162329xR162271",
            "comparison_id": "R162329",
            "paper_id": "R162271",
            "text": "Tabletop single-shot extreme ultraviolet Fourier transform holography of an extended object we demonstrate single and multi-shot fourier transform holography with the use of a tabletop extreme ultraviolet laser. the reference wave was produced by a fresnel zone plate with a central opening that allowed the incident beam to illuminate the sample directly. the high reference wave intensity allows for larger objects to be imaged compared to mask-based lensless fourier transform holography techniques. we obtain a spatial resolution of 169 nm from a single laser pulse and a resolution of 128 nm from an accumulation of 20 laser pulses for an object ~11x11\u03bcm(2) in size. this experiment utilized a tabletop extreme ultraviolet laser that produces a highly coherent ~1.2 ns laser pulse at 46.9 nm wavelength.",
            "contribution_ids": [
                "R162273"
            ]
        },
        {
            "instance_id": "R162574xR162457",
            "comparison_id": "R162574",
            "paper_id": "R162457",
            "text": "Overview of the CHEMDNER patents task a considerable effort has been made to extract biological and chemical entities, as well as their relationships, from the scientific literature, either manually through traditional literature curation or by using information extraction and text mining technologies. medicinal chemistry patents contain a wealth of information, for instance to uncover potential biomarkers that might play a role in cancer treatment and prognosis. however, current biomedical annotation databases do not cover such information, partly due to limitations of publicly available biomedical patent mining software. as part of the biocreative v chemdner patents track, we present the results of the first named entity recognition (ner) assignment carried out to detect mentions of chemical compounds and genes/proteins in running patent text. more specifically, this task aimed to evaluate the performance of automatic name recognition strategies capable of isolating chemical names and gene and gene product mentions from surrounding text within patent titles and abstracts. a total of 22 unique teams submitted results for at least one of the three chemdner subtasks. the first subtask, called the cemp (chemical entity mention in patents) task, focused on the detection of chemical named entity mentions in patents, requesting teams to return the start and end indices corresponding to all the chemical entities found in a given record. a total of 21 teams submitted 93 runs, for this subtask. the top performing team reached an f-measure of 0.89 with a precision of 0.87 and a recall of 0.91. the cpd (chemical passage detection) task required the classification of patent titles and abstracts whether they do or do not contain chemical compound mentions. nine teams returned predictions for this task (40 runs). the top run in terms of matthew\u2019s correlation coefficient (mcc) had a score of 0.88, the highest sensitivity ? corresponding author",
            "contribution_ids": [
                "R162459",
                "R171956",
                "R171968",
                "R171966"
            ]
        },
        {
            "instance_id": "R163742xR163725",
            "comparison_id": "R163742",
            "paper_id": "R163725",
            "text": "RDoC Task at BioNLP-OST 2019 bionlp open shared tasks (bionlp-ost) is an international competition organized to facilitate development and sharing of computational tasks of biomedical text mining and solutions to them. for bionlp-ost 2019, we introduced a new mental health informatics task called \u201crdoc task\u201d, which is composed of two subtasks: information retrieval and sentence extraction through national institutes of mental health\u2019s research domain criteria framework. five and four teams around the world participated in the two tasks, respectively. according to the performance on the two tasks, we observe that there is room for improvement for text mining on brain research and mental illness.",
            "contribution_ids": [
                "R163727"
            ]
        },
        {
            "instance_id": "R164231xR164050",
            "comparison_id": "R164231",
            "paper_id": "R164050",
            "text": "Static Relations: a Piece in the Biomedical Information Extraction Puzzle \"we propose a static relation extraction task to complement biomedical information extraction approaches. we argue that static relations such as part-whole are implicitly involved in many common extraction settings, define a task setting making them explicit, and discuss their integration into previously proposed tasks and extraction methods. we further identify a specific static relation extraction task motivated by the bionlp'09 shared task on event extraction, introduce an annotated corpus for the task, and demonstrate the feasibility of the task by experiments showing that the defined relations can be reliably extracted. the task setting and corpus can serve to support several forms of domain information extraction.\"",
            "contribution_ids": [
                "R164052"
            ]
        },
        {
            "instance_id": "R164231xR163865",
            "comparison_id": "R164231",
            "paper_id": "R163865",
            "text": "Part-of-Speech Annotation of Biology Research Abstracts a part-of-speech (pos) tagged corpus was built on research abstracts in biomedical domain with the penn treebank scheme. as consistent annotation was difficult without domain-specific knowledge we made use of the existing term annotation of the genia corpus. a list of frequent terms annotated in the genia corpus was compiled and the pos of each constituent of those terms were determined with assistance from domain specialists. the pos of the terms in the list are pre-assigned, then a tagger assigns pos to remaining words preserving the pre-assigned pos, whose results are corrected by human annotators. we also modified the ptb scheme slightly. an inter-annotator agreement tested on new 50 abstracts was 98.5%. a pos tagger trained with the annotated abstracts was tested against a gold-standard set made from the interannotator agreement. the untrained tagger had the accuracy of 83.0%. trained with 2000 annotated abstracts the accuracy rose to 98.2%. the 2000 annotated abstracts are publicly available.",
            "contribution_ids": [
                "R163867"
            ]
        },
        {
            "instance_id": "R166240xR163050",
            "comparison_id": "R166240",
            "paper_id": "R163050",
            "text": "Named Entity Recognition in Wikipedia \"named entity recognition (ner) is used in many domains beyond the newswire text that comprises current gold-standard corpora. recent work has used wikipedia's link structure to automatically generate near gold-standard annotations. until now, these resources have only been evaluated on newswire corpora or themselves. \\n \\nwe present the first ner evaluation on a wikipedia gold standard (wg) corpus. our analysis of cross-corpus performance on wg shows that wikipedia text may be a harder ner domain than newswire. we find that an automatic annotation of wikipedia has high agreement with wg and, when used as training data, outperforms newswire models by up to 7.7%.\"",
            "contribution_ids": [
                "R163052"
            ]
        },
        {
            "instance_id": "R166240xR163109",
            "comparison_id": "R166240",
            "paper_id": "R163109",
            "text": "WiNER: A Wikipedia Annotated Corpus for Named Entity Recognition we revisit the idea of mining wikipedia in order to generate named-entity annotations. we propose a new methodology that we applied to english wikipedia to build winer, a large, high quality, annotated corpus. we evaluate its usefulness on 6 ner tasks, comparing 4 popular state-of-the art approaches. we show that lstm-crf is the approach that benefits the most from our corpus. we report impressive gains with this model when using a small portion of winer on top of the conll training material. last, we propose a simple but efficient method for exploiting the full range of winer, leading to further improvements.",
            "contribution_ids": [
                "R163111"
            ]
        },
        {
            "instance_id": "R166240xR166178",
            "comparison_id": "R166240",
            "paper_id": "R166178",
            "text": "Exploiting Wikipedia as external knowledge for named entity recognition we explore the use of wikipedia as external knowledge to improve named entity recognition (ner). our method retrieves the corresponding wikipedia entry for each candidate word sequence and extracts a category label from the first sentence of the entry, which can be thought of as a definition part. these category labels are used as features in a crf-based ne tagger. we demonstrate using the conll 2003 dataset that the wikipedia category labels extracted by such a simple method actually improve the accuracy of ner.",
            "contribution_ids": [
                "R166180"
            ]
        },
        {
            "instance_id": "R172155xR171842",
            "comparison_id": "R172155",
            "paper_id": "R171842",
            "text": "BC4GO: a full-text corpus for the BioCreative IV GO task gene function curation via gene ontology (go) annotation is a common task among model organism database groups. owing to its manual nature, this task is considered one of the bottlenecks in literature curation. there have been many previous attempts at automatic identification of go terms and supporting information from full text. however, few systems have delivered an accuracy that is comparable with humans. one recognized challenge in developing such systems is the lack of marked sentence-level evidence text that provides the basis for making go annotations. we aim to create a corpus that includes the go evidence text along with the three core elements of go annotations: (i) a gene or gene product, (ii) a go term and (iii) a go evidence code. to ensure our results are consistent with real-life go data, we recruited eight professional go curators and asked them to follow their routine go annotation protocols. our annotators marked up more than 5000 text passages in 200 articles for 1356 distinct go terms. for evidence sentence selection, the inter-annotator agreement (iaa) results are 9.3% (strict) and 42.7% (relaxed) in f1-measures. for go term selection, the iaas are 47% (strict) and 62.9% (hierarchical). our corpus analysis further shows that abstracts contain \u223c10% of relevant evidence sentences and 30% distinct go terms, while the results/experiment section has nearly 60% relevant sentences and >70% go terms. further, of those evidence sentences found in abstracts, less than one-third contain enough experimental detail to fulfill the three core criteria of a go annotation. this result demonstrates the need of using full-text articles for text mining go annotations. through its use at the biocreative iv go (bc4go) task, we expect our corpus to become a valuable resource for the bionlp research community. database url: http://www.biocreative.org/resources/corpora/bc-iv-go-task-corpus/.",
            "contribution_ids": [
                "R171844",
                "R171845"
            ]
        },
        {
            "instance_id": "R182358xR182107",
            "comparison_id": "R182358",
            "paper_id": "R182107",
            "text": "Multi-Task Learning for Calorie Prediction on a Novel Large-Scale Recipe Dataset Enriched with Nutritional Information a rapidly growing amount of content posted online, such as food recipes, opens doors to new exciting applications at the intersection of vision and language. in this work, we aim to estimate the calorie amount of a meal directly from an image by learning from recipes people have published on the internet, thus skipping time-consuming manual data annotation. since there are few large-scale publicly available datasets captured in unconstrained environments, we propose the pic2kcal benchmark comprising 308 000 images from over 70 000 recipes including photographs, ingredients, and instructions. to obtain nutritional information of the ingredients and automatically determine the ground-truth calorie value, we match the items in the recipes with structured information from a food item database. we evaluate various neural networks for regression of the calorie quantity and extend them with the multi-task paradigm. our learning procedure combines the calorie estimation with prediction of proteins, carbohydrates, and fat amounts as well as a multi-label ingredient classification. our experiments demonstrate clear benefits of multi-task learning for calorie estimation, surpassing the single-task calorie regression by 9.9%. to encourage further research on this task, we make the code for generating the dataset and the models publicly available.",
            "contribution_ids": [
                "R182109",
                "R182111",
                "R182130",
                "R182145",
                "R182156",
                "R182171",
                "R182172",
                "R182174",
                "R182175",
                "R182176",
                "R182178",
                "R182179",
                "R182181",
                "R182182",
                "R182183",
                "R182185",
                "R182186",
                "R182187",
                "R182188",
                "R182189"
            ]
        },
        {
            "instance_id": "R182358xR182316",
            "comparison_id": "R182358",
            "paper_id": "R182316",
            "text": "Automatic Chinese food identification and quantity estimation computer-aided food identification and quantity estimation have caught more attention in recent years because of the growing concern of our health. the identification problem is usually defined as an image categorization or classification problem and several researches have been proposed. in this paper, we address the issues of feature descriptors in the food identification problem and introduce a preliminary approach for the quantity estimation using depth information. sparse coding is utilized in the sift and local binary pattern feature descriptors, and these features combined with gabor and color features are used to represent food items. a multi-label svm classifier is trained for each feature, and these classifiers are combined with multi-class adaboost algorithm. for evaluation, 50 categories of worldwide food are used, and each category contains 100 photographs from different sources, such as manually taken or from internet web albums. an overall accuracy of 68.3% is achieved, and success at top-n candidates achieved 80.6%, 84.8%, and 90.9% accuracy accordingly when n equals 2, 3, and 5, thus making mobile application practical. the experimental results show that the proposed methods greatly improve the performance of original sift and lbp feature descriptors. on the other hand, for quantity estimation using depth information, a straight forward method is proposed for certain food, while transparent food ingredients such as pure water and cooked rice are temporarily excluded.",
            "contribution_ids": [
                "R182318"
            ]
        },
        {
            "instance_id": "R182358xR182352",
            "comparison_id": "R182358",
            "paper_id": "R182352",
            "text": "Real-Time Mobile Food Recognition System \"we propose a mobile food recognition system the poses of which are estimating calorie and nutritious of foods and recording a user's eating habits. since all the processes on image recognition performed on a smart-phone, the system does not need to send images to a server and runs on an ordinary smartphone in a real-time way. to recognize food items, a user draws bounding boxes by touching the screen first, and then the system starts food item recognition within the indicated bounding boxes. to recognize them more accurately, we segment each food item region by grubcut, extract a color histogram and surf-based bag-of-features, and finally classify it into one of the fifty food categories with linear svm and fast 2 kernel. in addition, the system estimates the direction of food regions where the higher svm output score is expected to be obtained, show it as an arrow on the screen in order to ask a user to move a smartphone camera. this recognition process is performed repeatedly about once a second. we implemented this system as an android smartphone application so as to use multiple cpu cores effectively for real-time recognition. in the experiments, we have achieved the 81.55% classification rate for the top 5 category candidates when the ground-truth bounding boxes are given. in addition, we obtained positive evaluation by user study compared to the food recording system without object recognition.\"",
            "contribution_ids": [
                "R182354"
            ]
        },
        {
            "instance_id": "R184018xR182127",
            "comparison_id": "R184018",
            "paper_id": "R182127",
            "text": "Crop diversity is associated with higher child diet diversity in Ethiopia, particularly among low-income households, but not in Vietnam abstract objectives: to examine associations of household crop diversity with school-aged child dietary diversity in vietnam and ethiopia and mechanisms underlying these associations. design: we created a child diet diversity score (dds) using data on seven food groups consumed in the last 24 h. generalised estimating equations were used to model associations of household-level crop diversity, measured as a count of crop species richness (csr) and of plant crop nutritional functional richness (cnfr), with dds. we examined effect modification by household wealth and subsistence orientation, and mediation by the farm\u2019s market orientation. setting: two survey years of longitudinal data from the young lives cohort. participants: children (aged 5 years in 2006 and 8 years in 2009) from rural farming households in ethiopia ( n 1012) and vietnam ( n 1083). results: there was a small, positive association between household cnfr and dds in ethiopia (cnfr\u2013dds, \u03b2 = 0\u00b713; (95 % ci 0\u00b707, 0\u00b719)), but not in vietnam. associations of crop diversity and child diet diversity were strongest among poor households in ethiopia and among subsistence-oriented households in vietnam. agricultural earnings positively mediated the crop diversity\u2013diet diversity association in ethiopia. discussion: children from households that are poorer and those that rely more on their own agricultural production for food may benefit most from increased crop diversity.",
            "contribution_ids": [
                "R182129"
            ]
        },
        {
            "instance_id": "R184018xR182137",
            "comparison_id": "R184018",
            "paper_id": "R182137",
            "text": "Understanding the Linkages between Crop Diversity and Household Dietary Diversity in the Semi-Arid Regions of India agriculture is fundamental to achieving nutrition goals; it provides the food, energy, and nutrients essential \\nfor human health and well-being. this paper has examined crop diversity and dietary diversity in six \\nvillages using the icrisat village level studies (vls) data from the telangana and maharashtra states \\nof india. the study has used the data of cultivating households for constructing the crop diversity index \\nwhile dietary diversity data is from the special purpose nutritional surveys conducted by icrisat in the \\nsix villages. the study has revealed that the cropping pattern is not uniform across the six study villages \\nwith dominance of mono cropping in telangana villages and of mixed cropping in maharashtra villages. \\nthe analysis has indicated a positive and significant correlation between crop diversity and household \\ndietary diversity at the bivariate level. in multiple linear regression model, controlling for the other \\ncovariates, crop diversity has not shown a significant association with household dietary diversity. however, \\nother covariates have shown strong association with dietary diversity. the regression results have revealed \\nthat households which cultivated minimum one food crop in a single cropping year have a significant and \\npositive relationship with dietary diversity. from the study it can be inferred that crop diversity alone \\ndoes not affect the household dietary diversity in the semi-arid tropics. enhancing the evidence base and \\nfuture research, especially in the fragile environment of semi-arid tropics, is highly recommended.",
            "contribution_ids": [
                "R182139"
            ]
        },
        {
            "instance_id": "R184018xR182396",
            "comparison_id": "R184018",
            "paper_id": "R182396",
            "text": "The influence of crop production and socioeconomic factors on seasonal household dietary diversity in Burkina Faso households in low-income settings are vulnerable to seasonal changes in dietary diversity because of fluctuations in food availability and access. we assessed seasonal differences in household dietary diversity in burkina faso, and determined the extent to which household socioeconomic status and crop production diversity modify changes in dietary diversity across seasons, using data from the nationally representative 2014 burkina faso continuous multisectoral survey (emc). a household dietary diversity score based on nine food groups was created from household food consumption data collected during four rounds of the 2014 emc. plot-level crop production data, and data on household assets and education were used to create variables on crop diversity and household socioeconomic status, respectively. analyses included data for 10,790 households for which food consumption data were available for at least one round. accounting for repeated measurements and controlling for the complex survey design and confounding covariates using a weighted multi-level model, household dietary diversity was significantly higher during both lean seasons periods, and higher still during the harvest season as compared to the post-harvest season (mean: post-harvest: 4.76 (se 0.04); beginning of lean: 5.13 (se 0.05); end of lean: 5.21 (se 0.05); harvest: 5.72 (se 0.04)), but was not different between the beginning and the end of lean season. seasonal differences in household dietary diversity were greater among households with higher food expenditures, greater crop production, and greater monetary value of crops sale (p<0.05). seasonal changes in household dietary diversity in burkina faso may reflect nutritional differences among agricultural households, and may be modified both by households\u2019 socioeconomic status and agricultural characteristics.",
            "contribution_ids": [
                "R182397"
            ]
        },
        {
            "instance_id": "R184018xR184012",
            "comparison_id": "R184018",
            "paper_id": "R184012",
            "text": "If They Grow It, Will They Eat and Grow? Evidence from Zambia on Agricultural Diversity and Child Undernutrition abstract in this article we address a gap in our understanding of how household agricultural production diversity affects the diets and nutrition of young children living in rural farming communities in sub-saharan africa. the specific objectives of this article are to assess: (1) the association between household agricultural production diversity and child dietary diversity; and (2) the association between household agricultural production diversity and child nutritional status. we use household survey data collected from 3,040 households as part of the realigning agriculture for improved nutrition (rain) intervention in zambia. the data indicate low agricultural diversity, low dietary diversity and high levels of chronic malnutrition overall in this area. we find a strong positive association between production diversity and dietary diversity among younger children aged 6\u201323 months, and significant positive associations between production diversity and height for age z-scores and stunting among older children aged 24\u201359 months.",
            "contribution_ids": [
                "R184014"
            ]
        },
        {
            "instance_id": "R186048xR180001",
            "comparison_id": "R186048",
            "paper_id": "R180001",
            "text": "A Deep Learning based Approach for Precise Video Tagging with the increase in smart devices and abundance of video contents, efficient techniques for the indexing, analysis and retrieval of videos are becoming more and more desirable. improved indexing and automated analysis of millions of videos could be accomplished by getting videos tagged automatically. a lot of existing methods fail to precisely tag videos because of their lack of ability to capture the video context. the context in a video represents the interactions of objects in a scene and their overall meaning. in this work, we propose a novel approach that integrates the video scene ontology with cnn (convolutional neural network) for improved video tagging. our method captures the content of a video by extracting the information from individual key frames. the key frames are then fed to a cnn based deep learning model to train its parameters. the trained parameters are used to generate the most frequent tags. highly frequent tags are used to summarize the input video. the proposed technique is benchmarked on the most widely used dataset of video activities, namely, ucf-101. our method managed to achieve an overall accuracy of 99.8% with an f1- score of 96.2%.",
            "contribution_ids": [
                "R180003",
                "R180014",
                "R180016"
            ]
        },
        {
            "instance_id": "R186111xR186093",
            "comparison_id": "R186111",
            "paper_id": "R186093",
            "text": "Assessing Business-IT Allignment Maturity strategic alignment focuses on the activities that management performs to achieve cohesive goals across the it (information technology) and other functional organizations (e.g., finance, marketing, h/r, r&amp;d, manufacturing). therefore, alignment addresses both how it is in harmony with the business, and how the business should, or could, be in harmony with it. alignment evolves into a relationship where the function of it and other business functions adapt their strategies together. achieving alignment is evolutionary and dynamic. it requires strong support from senior management, good working relationships, strong leadership, appropriate prioritization, trust, and effective communication, as well as a thorough understanding of the business and technical environments. the strategic alignment maturity assessment provides organizations with a vehicle to evaluate these activities. knowing the maturity of its strategic choices and alignment practices make it possible for a firm to see where it stands and how it can improve. this chapter discusses an approach for assessing the maturity of the business-it alignment. once maturity is understood, an organization can identify opportunities for enhancing the harmonious relationship of business and it.",
            "contribution_ids": [
                "R186095"
            ]
        },
        {
            "instance_id": "R189691xR189572",
            "comparison_id": "R189691",
            "paper_id": "R189572",
            "text": "Ionic supramolecular bonds preserve mechanical properties and enable synergetic performance at high humidity in water-borne, self-assembled nacre-mimetics \"although tremendous effort has been focused on enhancing the mechanical properties of nacre-mimetic materials, conservation of high stiffness and strength against hydration-induced decay of mechanical properties at high humidity remains a fundamental challenge in such water-borne high-performance materials. herein, we demonstrate that ionic supramolecular bonds, introduced by infiltration of divalent cu(2+) ions, allow efficient stabilization of the mechanical properties of self-assembled water-borne nacre-mimetics based on sustainable sodium carboxymethylcellulose (na(+)cmc) and natural sodium montmorillonite nanoclay (na(+)mtm) against high humidity (95% rh). the mechanical properties in the highly hydrated state (young's modulus up to 13.5 gpa and tensile strength up to 125 mpa) are in fact comparable to a range of non-crosslinked nacre-mimetic materials in the dry state. moreover, the cu(2+)-treated nacre-inspired materials display synergetic mechanical properties as found in a simultaneous improvement of stiffness, strength and toughness, as compared to the pristine material. significant inelastic deformation takes place considering the highly reinforced state. this contrasts the typical behaviour of tight, covalent crosslinks and is suggested to originate from a sacrificial, dynamic breakage and rebinding of transient supramolecular ionic bonds. considering easy access to a large range of ionic interactions and alteration of counter-ion charge via external stimuli, we foresee responsive and adaptive mechanical properties in highly reinforced and stiff bio-inspired bulk nanocomposites and in other bio-inspired materials, e.g. nanocellulose papers and peptide-based materials.\"",
            "contribution_ids": [
                "R189574"
            ]
        },
        {
            "instance_id": "R189691xR189668",
            "comparison_id": "R189691",
            "paper_id": "R189668",
            "text": "Nacre-Mimetic Clay/Xyloglucan Bionanocomposites: A Chemical Modification Route for Hygromechanical Performance at High Humidity \"nacre-mimetic bionanocomposites of high montmorillonite (mtm) clay content, prepared from hydrocolloidal suspensions, suffer from reduced strength and stiffness at high relative humidity. we address this problem by chemical modification of xyloglucan in (xg)/mtm nacre-mimetic nanocomposites, by subjecting the xg to regioselective periodate oxidation of side chains to enable it to form covalent cross-links to hydroxyl groups in neighboring xg chains or to the mtm surface. the resulting materials are analyzed by ftir spectroscopy, thermogravimetric analysis, carbohydrate analysis, calorimetry, x-ray diffraction, scanning electron microscopy, tensile tests, and oxygen barrier properties. we compare the resulting mechanical properties at low and high relative humidity. the periodate oxidation leads to a strong increase in modulus and strength of the materials. a modulus of 30 gpa for cross-linked composite at 50% relative humidity compared with 13.7 gpa for neat xg/mtm demonstrates that periodate oxidation of the xg side chains leads to crucially improved stress transfer at the xg/mtm interface, possibly through covalent bond formation. this enhanced interfacial adhesion and internal cross-linking of the matrix moreover preserves the mechanical properties at high humidity condition and leads to a young's modulus of 21 gpa at 90%rh.\"",
            "contribution_ids": [
                "R189670"
            ]
        },
        {
            "instance_id": "R189691xR189677",
            "comparison_id": "R189691",
            "paper_id": "R189677",
            "text": "Multifunctional Nanoclay Hybrids of High Toughness, Thermal, and Barrier Performances to address brittleness of nanoclay hybrids of high inorganic content, ductile polymers (polyethylene oxide and hydroxyethyl cellulose) and montmorillonite (mtm) have been assembled into hybrid films using a water-based filtration process. nacre-mimetic layered films resulted and were characterized by fe-sem and xrd. mechanical properties at ambient condition were studied by tensile test, while performance at elevated temperature and moisture conditions were evaluated by tga, dynamic vapor sorption, and dynamic thermomechanical and hygromechanical analyses. antiflammability and barrier properties against oxygen and water vapor were also investigated. despite their high mtm content in the 60-85 wt % range, the hybrids exhibit remarkable ductility and a storage modulus above 2 gpa even in severe conditions (300\u00b0c or 94% rh). moreover, they present fire-shielding property and are amongst the best oxygen and water vapor barrier hybrids reported in the literature. this study thus demonstrates nanostructure property advantages for synergistic effects in hybrids combining inexpensive, available, and environmentally benign constituents.",
            "contribution_ids": [
                "R189678"
            ]
        },
        {
            "instance_id": "R189691xR189685",
            "comparison_id": "R189691",
            "paper_id": "R189685",
            "text": "Deoxyguanosine Phosphate Mediated Sacrificial Bonds Promote Synergistic Mechanical Properties in Nacre-Mimetic Nanocomposites \"we show that functionalizing polymer-coated colloidal nanoplatelets with guanosine groups allows synergistic increase of mechanical properties in nacre-mimetic lamellar self-assemblies. anionic montmorillonite (mtm) was first coated using cationic poly(diallyldimethylammonium chloride) (pdadmac) to prepare core-shell colloidal platelets, and subsequently the remaining chloride counterions allowed exchange to functional anionic 2'-deoxyguanosine 5'-monophosphate (dgmp) counterions, containing hydrogen bonding donors and acceptors. the compositions were studied using elemental analysis, scanning and transmission electron microscopy, wide-angle x-ray scattering, and tensile testing. the lamellar spacing between the clays increases from 1.85 to 2.14 nm upon addition of the dgmp. adding dgmp increases the elastic modulus, tensile strength, and strain 33.0%, 40.9%, and 5.6%, respectively, to 13.5 gpa, 67 mpa, and 1.24%, at 50% relative humidity. this leads to an improved toughness seen as a ca. 50% increase of the work-to-failure. this is noteworthy, as previously it has been observed that connecting the core-shell nanoclay platelets covalently or ionically leads to increase of the stiffness but to reduced strain. we suggest that the dynamic supramolecular bonds allow slippage and sacrificial bonds between the self-assembling nanoplatelets, thus promoting toughness, still providing dynamic interactions between the platelets.\"",
            "contribution_ids": [
                "R189688"
            ]
        },
        {
            "instance_id": "R190010xR189603",
            "comparison_id": "R190010",
            "paper_id": "R189603",
            "text": "Detecting attacks to internal vehicle networks through Hamming distance analysis of in-vehicle networks is an open research area that gained relevance after recent reports of cyber attacks against connected vehicles. after those attacks gained international media attention, many security researchers started to propose different algorithms that are capable to model the normal behaviour of the can bus to detect the injection of malicious messages. however, despite the automotive area has different constraint than classical it security, many security research have been conducted by applying sophisticated algorithm used in it anomaly detection, thus proposing solutions that are not applicable on current electronic control units (ecus). this paper proposes a novel intrusion detection algorithm that aims to identify malicious can messages injected by attackers in the can bus of modern vehicles. moreover, the proposed algorithm has been designed and implemented with the very strict constraint of low-end ecus, having low computational complexity and small memory footprints. the proposed algorithm identifies anomalies in the sequence of the payloads of different classes of ids by computing the hamming distance between consecutive payloads. its detection performance are evaluated through experiments carried out using real can traffic gathered from an unmodified licensed vehicle.",
            "contribution_ids": [
                "R189605"
            ]
        },
        {
            "instance_id": "R191054xR190018",
            "comparison_id": "R191054",
            "paper_id": "R190018",
            "text": "Clinical Characteristics of COVID-19 Patients With Digestive Symptoms in Hubei, China: A Descriptive, Cross-Sectional, Multicenter Study objective: since the outbreak of coronavirus disease 2019 (covid-19) in december 2019, various digestive symptoms have been frequently reported in patients infected with the virus. in this study, we aimed to further investigate the prevalence and outcomes of covid-19 patients with digestive symptoms. methods: in this descriptive, cross-sectional, multicenter study, we enrolled confirmed patients with covid-19 who presented to 3 hospitals from january 18, 2020, to february 28, 2020. all patients were confirmed by real-time polymerase chain reaction and were analyzed for clinical characteristics, laboratory data, and treatment. data were followed up until march 18, 2020. results: in the present study, 204 patients with covid-19 and full laboratory, imaging, and historical data were analyzed. the average age was 52.9 years (sd \u00b1 16), including 107 men and 97 women. although most patients presented to the hospital with fever or respiratory symptoms, we found that 103 patients (50.5%) reported a digestive symptom, including lack of appetite (81 [78.6%] cases), diarrhea (35 [34%] cases), vomiting (4 [3.9%] cases), and abdominal pain (2 [1.9%] cases). if lack of appetite is excluded from the analysis (because it is less specific for the gastrointestinal tract), there were 38 total cases (18.6%) where patients presented with a gastrointestinal-specific symptom, including diarrhea, vomiting, or abdominal pain. patients with digestive symptoms had a significantly longer time from onset to admission than patients without digestive symptoms (9.0 days vs 7.3 days). in 6 cases, there were digestive symptoms, but no respiratory symptoms. as the severity of the disease increased, digestive symptoms became more pronounced. patients with digestive symptoms had higher mean liver enzyme levels, lower monocyte count, longer prothrombin time, and received more antimicrobial treatment than those without digestive symptoms. discussion: we found that digestive symptoms are common in patients with covid-19. moreover, these patients have a longer time from onset to admission, evidence of longer coagulation, and higher liver enzyme levels. clinicians should recognize that digestive symptoms, such as diarrhea, are commonly among the presenting features of covid-19 and that the index of suspicion may need to be raised earlier in at-risk patients presenting with digestive symptoms. however, further large sample studies are needed to confirm these findings.",
            "contribution_ids": [
                "R190020"
            ]
        },
        {
            "instance_id": "R191054xR190022",
            "comparison_id": "R191054",
            "paper_id": "R190022",
            "text": "Effect of Gastrointestinal Symptoms in Patients With COVID-19 because of accumulating evidence pointing to continuous person-to-person transmission of coronavirus disease 2019 (covid-19) in hospital and family settings,1,2 the world health organization has recently declared covid-19 a public health emergency of international concern. fever and respiratory symptoms tend to be initial and major, whereas gastrointestinal (gi) symptoms were also observed in a significant portion of patients.3 positive findings of reverse transcription polymerase chain reaction further showed that covid-19 may spread by fecal-oral transmission.",
            "contribution_ids": [
                "R190025"
            ]
        },
        {
            "instance_id": "R191054xR190053",
            "comparison_id": "R191054",
            "paper_id": "R190053",
            "text": "Association of Gastrointestinal System With Severity and Mortality of COVID-19: A Systematic Review and Meta-Analysis at present, the novel coronavirus disease (covid-19) is causing a major pandemic. covid-19 is caused by the severe acute respiratory syndrome coronavirus 2 (sars-cov-2). in covid-19, the patient usually presents with fever, dry cough, and respiratory manifestations. however, the involvement of other systems has also been reported in the literature. abdominal pain, diarrhea, vomiting, and nausea are the predominant gastrointestinal (gi) manifestations underlined in the literature. we conducted a literature search using four databases (pubmed, web of science, google scholar, and clinicaltrials.gov). our search strategy included medical subject headings (mesh) terms and keywords for covid-19, sars-cov-2, and gi system from inception to october 2020. after excluding duplicates, review articles, and non-relevant articles, we included 20 studies out of 842 articles reporting gi manifestations in covid-19 patients. using cochrane revman version 5.4 (cochrane, london, uk), a compute pooled analysis using a random-effect model was performed. our study included 6,022 patients with a median age of 49.5 years. pooled analysis via random effect model revealed an increased risk of severe covid-19 in patients manifesting gi symptoms with an odds ratio (or) of 2.07 (95% confidence interval [ci]: 1.34-3.18) with i2=41%). odds of mortality in covid-19 with gi manifestation and hepatic abnormalities included 0.92 (95% ci: 0.50-1.69) (i2=57%) and 1.26 (95% ci: 0.67-2.37) (i2=0%), respectively. severe covid-19 may have a strong association with gi manifestations and have a significant impact on gi practice. holistic knowledge of the spectrum of the gi consequences in covid-19 is crucial to get a hold of virus spread. in this article, we have summarized the association of gi manifestations in severe covid-19 patients.",
            "contribution_ids": [
                "R190055"
            ]
        },
        {
            "instance_id": "R191407xR191192",
            "comparison_id": "R191407",
            "paper_id": "R191192",
            "text": "Embracing Domain Differences in Fake News: Cross-domain Fake News Detection using Multi-modal Data with the rapid evolution of social media, fake news has become a significant social problem, which cannot be addressed in a timely manner using manual investigation. this has motivated numerous studies on automating fake news detection. most studies explore supervised training models with different modalities (e.g., text, images, and propagation networks) of news records to identify fake news. however, the performance of such techniques generally drops if news records are coming from different domains (e.g., politics, entertainment), especially for domains that are unseen or rarely-seen during training. as motivation, we empirically show that news records from different domains have significantly different word usage and propagation patterns. furthermore, due to the sheer volume of unlabelled news records, it is challenging to select news records for manual labelling so that the domain-coverage of the labelled dataset is maximized. hence, this work: (1) proposes a novel framework that jointly preserves domain-specific and cross-domain knowledge in news records to detect fake news from different domains; and (2) introduces an unsupervised technique to select a set of unlabelled informative news records for manual labelling, which can be ultimately used to train a fake news detection model that performs well for many domains while minimizing the labelling cost. our experiments show that the integration of the proposed fake news model and the selective annotation approach achieves state-of-the-art performance for cross-domain news datasets, while yielding notable improvements for rarely-appearing domains in news datasets.",
            "contribution_ids": [
                "R191194"
            ]
        },
        {
            "instance_id": "R191407xR191219",
            "comparison_id": "R191407",
            "paper_id": "R191219",
            "text": "Embedding Partial Propagation Network for Fake News Early Detection detecting fake news as early as possible has attracted growing attention due to its fast-spreading nature and the significant harm it can cause. as demonstrated in recent studies, the propagation pattern of fake news on social media differs from that of real news, and a number of works have extracted different types of features from the propagation pattern for detection. however, a major limitation of this approach is that the propagation network is not fully available in the early stages, and may take a long time to complete. as a result, existing network-based fake news detection methods yield low accuracy during the early stages of propagation. to bridge the research gap, in this work we: (1) propose a novel network embedding algorithm, based on the investigation of a wide range of features obtained from the propagation network, which are not well studied in previous work; and (2) design an autoencoder-based neural architecture to predict the embedding of the complete propagation network using the partially available network in the early stages of propagation. our experiments show that with the predicted embedding for the complete propagation network, our model can achieve state-of-the-art performance while only having access to the early stage propagation network.",
            "contribution_ids": [
                "R191221"
            ]
        },
        {
            "instance_id": "R191407xR191241",
            "comparison_id": "R191407",
            "paper_id": "R191241",
            "text": "dEFEND: Explainable Fake News Detection in recent years, to mitigate the problem of fake news, computational detection of fake news has been studied, producing some promising early results. while important, however, we argue that a critical missing piece of the study be the explainability of such detection, i.e., why a particular piece of news is detected as fake. in this paper, therefore, we study the explainable detection of fake news. we develop a sentence-comment co-attention sub-network to exploit both news contents and user comments to jointly capture explainable top-k check-worthy sentences and user comments for fake news detection. we conduct extensive experiments on real-world datasets and demonstrate that the proposed method not only significantly outperforms 7 state-of-the-art fake news detection methods by at least 5.33% in f1-score, but also (concurrently) identifies top-k user comments that explain why a news piece is fake, better than baselines by 28.2% in ndcg and 30.7% in precision.",
            "contribution_ids": [
                "R191243"
            ]
        },
        {
            "instance_id": "R191976xR189876",
            "comparison_id": "R191976",
            "paper_id": "R189876",
            "text": "Precision Wavelength Determination of 2^1P_1 - 1^1S_0 and 2^3P_1 - 1^1S_0 Transitions in Helium-Like Sulfur Ions transitions from the 21p1 - and 23p1 -state to the ground state 11s0 in helium-like sulphur ions have been measured with an accuracy of 4 \u00d7 10-5. energy calibration is described in detail and two reference wavelengths have been reevaluated. substantial line-blending was observed, due to long-lived spectator electrons. the two transition energies were corrected for doppler shift and compared with most refined theoretical calculations, including terms of order \u03b14z6 in the breit operator and terms of order \u03b15z6 in the quantum-electrodynamical corrections. the experimental contributions to the ground-state qed shifts agree within its error (\u223c 15%) with the theoretical values.",
            "contribution_ids": [
                "R189878"
            ]
        },
        {
            "instance_id": "R191976xR190068",
            "comparison_id": "R191976",
            "paper_id": "R190068",
            "text": "Precision X-ray wavelength measurements in helium-like argon recoil ions \"the authors report precise wavelength measurements of the 1s2 1s0-1s2p3p1,2,1p1 transitions in ar16+ produced by collisions of 5.9 mev amu-1 u66+ ions with an argon gas target. by use of this 'recoil source', the precision is not limited by doppler shifts while the influence of spectator electrons is minimised by observation of their relative importance as a function of gas pressure. the accuracy obtained is at the 12 p.p.m. level dominated by the x-ray calibration standard. the measurement is thus sensitive to quantum-electrodynamic (qed) and electron correlation effects.\"",
            "contribution_ids": [
                "R190070",
                "R190101",
                "R190133"
            ]
        },
        {
            "instance_id": "R191984xR191915",
            "comparison_id": "R191984",
            "paper_id": "R191915",
            "text": "A Methodology of CAN Communication Encryption Using a shuffling algorithm in-vehicle communication uses can bus, and for this, communication speed and security are important. since the current can communication is used without encryption, many cases have been reported of vehicle hacking over time. with the advent of autonomous driving and connected cars, vehicles no longer remain independent; they can be invaded from the outside and personal information such as vehicle location and driving habits can be accessed through the vehicle, which poses a serious threat to personal privacy and life. therefore, communication data must be encrypted in order to increase the security of the communication. in this paper, data frames are encrypted using a shuffling algorithm in the can communication system environment. to put it more precisely, the data frame is divided into bits and structured into blocks, which are then shuffled for data hiding. this method determines the level of obfuscation based on blockage and shuffle criteria. the encryption time was measured by changing both. this suggest ways to increase the security and communication speed in the vehicle.",
            "contribution_ids": [
                "R191917"
            ]
        },
        {
            "instance_id": "R191984xR191933",
            "comparison_id": "R191984",
            "paper_id": "R191933",
            "text": "A PUF Based CAN Security Framework we propose a method to include security and reliability to the messages sent over the can bus. our approach adheres to can standard iso 11898-1. a reliable puf response is used in key generation to create a unique shared aes-256 key between each ecu, allowing for all message paths to be encrypted. in addition, an hmac system with a counter is implemented to help protect against replay attacks and message tampering within the network.",
            "contribution_ids": [
                "R191935"
            ]
        },
        {
            "instance_id": "R191984xR191942",
            "comparison_id": "R191984",
            "paper_id": "R191942",
            "text": "Improving Timing Behavior on Encrypted CAN Buses \"can is probably the most successful bus in the automotive domain, especially, due to its low cost and robustness. however, with increasing connectivity, there is a need to encrypt data to avoid attacks such as spoofing and sniffing. this ends up exposing can's severe limitations. in particular, each encrypted message requires sending two frames due to its restrictive payload in can. moreover, each frame of an encrypted message undergoes a separate arbitration process which negatively impacts timing and makes it difficult to meet deadlines. in this paper, to work around this problem, we propose a technique that consists in assigning different priorities to encrypted can frames so as to compensate for increased delay. the basic idea is that, once the first frame of an encrypted can message wins arbitration, its second frame will always win arbitration within a specified scope and can be sent with lesser delay. we have conducted experiments on real hardware and performed extensive simulations indicating that the proposed technique reduces transmission delay to one half or even one third compared with the standard approach allowing us to still meet typical automotive deadlines on an encrypted can bus.\"",
            "contribution_ids": [
                "R191944"
            ]
        },
        {
            "instance_id": "R193278xR193173",
            "comparison_id": "R193278",
            "paper_id": "R193173",
            "text": "Representation of IP Routing Policies in a Routing Registry (ripe-81++) \"this document was originally published as a ripe document known as ripe-181 but is also being published as an informational rfc to reach a larger audience than its original scope. it has received community wide interest and acknowledgment throughout the internet service provider community and will be used as the basic starting point for future work on internet routing registries and routing policy representation. it can also be referred to as ripe-81++. this document is an update to the original `ripe-81'[1] proposal for representing and storing routing polices within the ripe database. it incorporates several extensions proposed by merit inc.[2] and gives details of a generalized ip routing policy representation to be used by all internet routing registries. it acts as both tutorial and provides details of database objects and attributes that use and make up a routing registry.\"",
            "contribution_ids": [
                "R193175"
            ]
        },
        {
            "instance_id": "R193278xR193197",
            "comparison_id": "R193278",
            "paper_id": "R193197",
            "text": "Origin authentication in interdomain routing attacks against internet routing are increasing in number and severity. contributing greatly to these attacks is the absence of origin authentication: there is no way to validate claims of address ownership or location. the lack of such services enables not only attacks by malicious entities, but indirectly allow seemingly inconsequential miconfigurations to disrupt large portions of the internet. this paper considers the semantics, design, and costs of origin authentication in interdomain routing. we formalize the semantics of address delegation and use on the internet, and develop and characterize broad classes of origin authentication proof systems. we estimate the address delegation graph representing the current use of ipv4 address space using available routing data. this effort reveals that current address delegation is dense and relatively static: as few as 16 entities perform 80% of the delegation on the internet. we conclude by evaluating the proposed services via traced based simulation. our simulation shows the enhanced proof systems can reduce significantly reduce resource costs associated with origin authentication.",
            "contribution_ids": [
                "R193199"
            ]
        },
        {
            "instance_id": "R193278xR193200",
            "comparison_id": "R193278",
            "paper_id": "R193200",
            "text": "SPV: Secure path vector routing for securing BGP as our economy and critical infrastructure increasingly relies on the internet, the insecurity of the underlying border gateway routing protocol (bgp) stands out as the achilles heel. recent misconfigurations and attacks have demonstrated the brittleness of bgp. securing bgp has become a priority.in this paper, we focus on a viable deployment path to secure bgp. we analyze security requirements, and consider tradeoffs of mechanisms that achieve the requirements. in particular, we study how to secure bgp update messages against attacks. we design an efficient cryptographic mechanism that relies only on symmetric cryptographic primitives to guard an aspath from alteration, and propose the secure path vector (spv) protocol. in contrast to the previously proposed s-bgp protocol, spv is around 22 times faster. with the current effort to secure bgp, we anticipate that spv will contribute several alternative mechanisms to secure bgp, especially for the case of incremental deployments.",
            "contribution_ids": [
                "R193202"
            ]
        },
        {
            "instance_id": "R193278xR193209",
            "comparison_id": "R193278",
            "paper_id": "R193209",
            "text": "Optimizing BGP security by exploiting path stability the border gateway protocol (bgp) is the de facto interdomain routing protocol on the internet. while the serious vulnerabilities of bgp are well known, no security solution has been widely deployed. the lack of adoption is largely caused by a failure to find a balance between deployability, cost, and security. in this paper, we consider the design and performance of bgp path authentication constructions that limit resource costs by exploiting route stability. based on a year-long study of bgp traffic and indirectly supported by findings within the networking community, we observe that routing paths are highly stable. this observation leads to comprehensive and efficient constructions for path authentication. we empirically analyze the resource consumption of the proposed constructions via trace-based simulations. this latter study indicates that our constructions can reduce validation costs by as much as 97.3% over existing proposals while requiring nominal storage resources. we conclude by considering operational issues related to incremental deployment of our solution.",
            "contribution_ids": [
                "R193211"
            ]
        },
        {
            "instance_id": "R193278xR193255",
            "comparison_id": "R193278",
            "paper_id": "R193255",
            "text": "An infrastructure to support secure internet routing this document describes an architecture for an infrastructure to\\nsupport secure internet routing. the foundation of this architecture\\nis a public key infrastructure (pki) that represents the allocation\\nhierarchy of ip address space and autonomous system numbers;\\ncertificates from this pki are used to verify signed objects that\\nauthorize autonomous systems to originate routes for specified ip\\naddress prefixes. the data objects that comprise the pki, as well as\\nother signed objects necessary for secure routing, are stored and\\ndisseminated through a distributed repository system. this document\\nalso describes at a high level how this architecture can be used to\\nadd security features to common operations such as ip address space\\nallocation and route filter construction.",
            "contribution_ids": [
                "R193257"
            ]
        },
        {
            "instance_id": "R193505xR178376",
            "comparison_id": "R193505",
            "paper_id": "R178376",
            "text": "SARS-CoV-2 viral load as a predictor for disease severity in outpatients and hospitalised patients with COVID-19: A prospective cohort study \\n introduction \\n we aimed to examine if severe acute respiratory syndrome coronavirus 2 (sars-cov-2) polymerase chain reaction (pcr) cycle quantification (c q ) value, as a surrogate for sars-cov-2 viral load, could predict hospitalisation and disease severity in adult patients with coronavirus disease 2019 (covid-19). \\n \\n \\n methods \\n we performed a prospective cohort study of adult patients with pcr positive sars-cov-2 airway samples including all out-patients registered at the department of infectious diseases, odense university hospital (ouh) march 9-march 17 2020, and all hospitalised patients at ouh march 10-april 21 2020. to identify associations between c q -values and a) hospital admission and b) a severe outcome, logistic regression analyses were used to compute odds ratios (or) and 95% confidence intervals (ci), adjusting for confounding factors (aor). \\n \\n \\n results \\n we included 87 non-hospitalised and 82 hospitalised patients. the median baseline c q -value was 25.5 (interquartile range 22.3\u201329.0). we found a significant association between increasing c q -value and hospital-admission in univariate analysis (or 1.11, 95% ci 1.04\u20131.19). however, this was due to an association between time from symptom onset to testing and c q -values, and no association was found in the adjusted analysis (aor 1.08, 95% ci 0.94\u20131.23). in hospitalised patients, a significant association between lower c q -values and higher risk of severe disease was found (aor 0.89, 95% ci 0.81\u20130.98), independent of timing of testing. \\n \\n \\n conclusions \\n sars-cov-2 pcr c q -values in outpatients correlated with time after symptom onset, but was not a predictor of hospitalisation. however, in hospitalised patients lower c q -values were associated with higher risk of severe disease. \\n",
            "contribution_ids": [
                "R178379",
                "R178429"
            ]
        },
        {
            "instance_id": "R193505xR191188",
            "comparison_id": "R193505",
            "paper_id": "R191188",
            "text": "Epidemiological Correlates of Polymerase Chain Reaction Cycle Threshold Values in the Detection of Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) abstract \\n \\n background \\n detection of severe acute respiratory syndrome coronavirus 2 (sars-cov-2) infection has principally been performed through the use of real-time reverse-transcription polymerase chain reaction testing. results of such tests can be reported as cycle threshold (ct) values, which may provide semi-quantitative or indirect measurements of viral load. previous reports have examined temporal trends in ct values over the course of a sars-cov-2 infection. \\n \\n \\n methods \\n using testing data collected during a prospective household transmission investigation of outpatient and mild coronavirus disease 2019 cases, we examined the relationships between ct values of the viral rna n1 target and demographic, clinical, and epidemiological characteristics collected through participant interviews and daily symptom diaries. \\n \\n \\n results \\n we found that ct values are lowest (corresponding to a higher viral rna concentration) soon after symptom onset and are significantly correlated with the time elapsed since onset (p\\u2005&amp;lt;\\u2005.001); within 7 days after symptom onset, the median ct value was 26.5, compared with a median ct value of 35.0 occurring 21 days after onset. ct values were significantly lower among participants under 18 years of age (p\\u2005=\\u2005.01) and those reporting upper respiratory symptoms at the time of sample collection (p\\u2005=\\u2005.001), and were higher among participants reporting no symptoms (p\\u2005=\\u2005.05). \\n \\n \\n conclusions \\n these results emphasize the importance of early testing for sars-cov-2 among individuals with symptoms of respiratory illness, and allow cases to be identified and isolated when their viral shedding may be highest. \\n",
            "contribution_ids": [
                "R191191"
            ]
        },
        {
            "instance_id": "R193505xR191238",
            "comparison_id": "R193505",
            "paper_id": "R191238",
            "text": "SARS-CoV-2 Viral Load on Admission Is Associated With 30-Day Mortality abstract \\n severe acute respiratory syndrome coronavirus 2 (sars-cov-2) viral load on admission was associated with a significantly increased 30-day mortality (odds ratio [or], 4.20; 95% ci, 1.62\u201310.86), and anti-sars-cov-2 nucleocapisid igg seropositivity on admission trended toward a reduced 30-day mortality (or, 0.43; 95% ci, 0.15\u20131.26). reporting of quantitative sars-cov-2 viral load and serologic assays may offer prognostic clinical information.",
            "contribution_ids": [
                "R191240"
            ]
        },
        {
            "instance_id": "R193505xR191301",
            "comparison_id": "R193505",
            "paper_id": "R191301",
            "text": "Impact of Severe Acute Respiratory Syndrome Coronavirus 2 Viral Load on Risk of Intubation and Mortality Among Hospitalized Patients With Coronavirus Disease 2019 abstract \\n \\n background \\n patients hospitalized with coronavirus disease 2019 (covid-19) frequently require mechanical ventilation and have high mortality rates. however, the impact of viral burden on these outcomes is unknown. \\n \\n \\n methods \\n we conducted a retrospective cohort study of patients hospitalized with covid-19 from 30 march 2020 to 30 april 2020 at 2 hospitals in new york city. severe acute respiratory syndrome coronavirus 2 (sars-cov-2) viral load was assessed using cycle threshold (ct) values from a reverse transcription-polymerase chain reaction assay applied to nasopharyngeal swab samples. we compared characteristics and outcomes of patients with high, medium, and low admission viral loads and assessed whether viral load was independently associated with intubation and in-hospital mortality. \\n \\n \\n results \\n we evaluated 678 patients with covid-19. higher viral load was associated with increased age, comorbidities, smoking status, and recent chemotherapy. in-hospital mortality was 35.0% (ct\\u2005&amp;lt;25; n\\u2005=\\u2005220), 17.6% (ct 25\u201330; n\\u2005=\\u2005216), and 6.2% (ct\\u2005&amp;gt;30; n\\u2005=\\u2005242) with high, medium, and low viral loads, respectively (p &amp;lt; .001). the risk of intubation was also higher in patients with a high viral load (29.1%) compared with those with a medium (20.8%) or low viral load (14.9%; p\\u2005&amp;lt;\\u2005.001). high viral load was independently associated with mortality (adjusted odds ratio [aor], 6.05; 95% confidence interval [ci], 2.92\u201312.52) and intubation (aor, 2.73; 95% ci, 1.68\u20134.44). \\n \\n \\n conclusions \\n admission sars-cov-2 viral load among hospitalized patients with covid-19 independently correlates with the risk of intubation and in-hospital mortality. providing this information to clinicians could potentially be used to guide patient care. \\n",
            "contribution_ids": [
                "R191303"
            ]
        },
        {
            "instance_id": "R193505xR191318",
            "comparison_id": "R193505",
            "paper_id": "R191318",
            "text": "Characteristics of viral specimens collected from asymptomatic and fatal cases of COVID-19 we sought to determine the characteristics of viral specimens associated with fatal cases, asymptomatic cases and non-fatal symptomatic cases of covid-19. this included the analysis of 1264 specimens found reactive for at least two sars-cov-2 specific loci from people screened for infection in northern nevada in march-may of 2020. of these, 30 were specimens from fatal cases, while 23 were from positive, asymptomatic cases. we assessed the relative amounts of sars-cov-2 rna from sample swabs by real-time pcr and use of the threshold crossing value (ct). moreover, we compared the amount of human rnase p found on the same swabs. a considerably higher viral load was found to be associated with swabs from cases involving fatality and the difference was found to be strongly statistically significant. noting this difference, we sought to assess whether any genetic correlation could be found in association with virus from fatal cases using whole genome sequencing. while no common genetic elements were discerned, one branch of epidemiologically linked fatal cases did have two point mutations, which no other of 156 sequenced cases from northern nevada had. the mutations caused amino acid changes in the 3\u2032-5\u2032 exonuclease protein, and the product of the gene, orf8.",
            "contribution_ids": [
                "R191320"
            ]
        },
        {
            "instance_id": "R193505xR191339",
            "comparison_id": "R193505",
            "paper_id": "R191339",
            "text": "SARS-CoV-2 viral load predicts COVID-19 mortality abstract the need for reliable and widely available sars-cov-2 testing is well recognized, but it will be equally necessary to develop quantitative methods that determine viral load in order to guide patient triage and medical decision making. we are the first to report that sars-cov-2 viral load at the time of presentation is an independent predictor of covid-19 mortality in a large patient cohort (n=1,145). viral loads should be used to identify higher-risk patients that may require more aggressive care and should be included as a key biomarker in the development of predictive algorithms.",
            "contribution_ids": [
                "R191341"
            ]
        },
        {
            "instance_id": "R193565xR192191",
            "comparison_id": "R193565",
            "paper_id": "R192191",
            "text": "Analysis of closed loop supply chain using genetic algorithm and particle swarm optimisation there are many reasons for the growing interest in reverse logistics. the most prominent reasons are the growing concern for the environment and cost reduction. next to environment, consumers demand for clean manufacturing and recycling. hence, customers and retailers expect original equipment manufacturers to set up a proper reverse logistics system and expect the returned products to be processed and recovered in an environmentally responsible way and another reason is cost reduction. a well-managed reverse logistics programme can provide important cost savings in procurement, disposal, inventory carrying and transportation. in this context, looking at the entire supply chain is the best starting point for solutions. supply chain management aims at the integration of traditional \u2018forward\u2019 supply chain processes, avoiding local optimisation by emphasising integrality. the main objective of this paper is to design an integrated forward logistics multi-echelon distribution inventory supply chain model (flmedim) and closed loop multi-echelon distribution inventory supply chain model (clmedim) for the built-to-order environment using genetic algorithm and particle swarm optimisation. in this paper, the proposed model is validated by considering two case studies: one for a tyre manufacturer and the other for a plastic goods manufacturer both located in the southern part of india. this paper utilises the multi-echelon distribution inventory supply chain model proposed by haq and kannan (2006a) for the flmedim. the software used was written in the java programming language.",
            "contribution_ids": [
                "R192193"
            ]
        },
        {
            "instance_id": "R193700xR193677",
            "comparison_id": "R193700",
            "paper_id": "R193677",
            "text": "Simulation analysis of supply chain risk management system based on IoT information platform abstract in this paper, iot (internet of things) information technology has been widely applied to the supply chain risk management (scrm). firstly, the source of risks has been sorted out, the external and internal risks have been described in detail with the risk management of supply chain system. secondly, the supply chain risk and case reasoning were mentioned. finally, the work actively explored the supply chain risk management by the iot information, such as 3g network, rfid and gps. the research on scrm based on iot information contributes to the construction and improvement of supply chain informatisation.",
            "contribution_ids": [
                "R193679"
            ]
        },
        {
            "instance_id": "R193700xR193694",
            "comparison_id": "R193700",
            "paper_id": "R193694",
            "text": "Assessing supply chain risk for apparel production in low cost countries using newsfeed analysis \\n purpose \\n with the growth of unstructured data, opportunities to generate insights into supply chain risks in low cost countries (lccs) are emerging. sourcing risk has primarily focused on short-term mitigation. this paper aims to offer an approach that uses newsfeed data to assess regional supply base risk in lcc\u2019s for the apparel sector, which managers can use to plan for future risk on a long-term planning horizon. \\n \\n \\n design/methodology/approach \\n this paper demonstrates that the bulk of supplier risk assessments focus on short-term responses to disruptions in developed countries, revealing a gap in assessments of long-term risks for supply base expansion in lccs. this paper develops an approach for predicting and planning for long-term supply base risk in lcc\u2019s to address this shortfall. a machine-based learning algorithm is developed that uses the analysis of competing hypotheses heuristic to convert data from multiple news feeds into numerical risk scores and visual maps of supply chain risk. this paper demonstrates the approach by converting large amounts of unstructured data into two measures, risk impact and risk probability, leading to visualization of country-level supply base risks for a global apparel company. \\n \\n \\n findings \\n this paper produced probability and impact scores for 23 distinct supply base risks across 10 countries in the apparel sector. the results suggest that the most significant long-term risks of supply disruption for apparel in lcc\u2019s are human resource regulatory risks, workplace issues, inflation costs, safety violations and social welfare violations. the results suggest that apparel brands seeking suppliers in the regions of cambodia, india, bangladesh, brazil and vietnam should be aware of the significant risks in these regions that may require mitigative action. \\n \\n \\n originality/value \\n this approach establishes a novel approach for objectively projecting future global sourcing risk, and yields visually mapped outcomes that can be applied in forecasting and planning for future risks when considering sourcing locations in lcc\u2019s. \\n",
            "contribution_ids": [
                "R193696"
            ]
        },
        {
            "instance_id": "R193700xR193697",
            "comparison_id": "R193700",
            "paper_id": "R193697",
            "text": "Extracting supply chain maps from news articles using deep neural networks \"supply chains are increasingly global, complex and multi-tiered. consequently, companies often struggle to maintain complete visibility of their supply network. this poses a problem as visibility of the network structure is required for tasks like effectively managing supply chain risk. in this paper, we discuss automated supply chain mapping as a means of maintaining structural visibility of a company's supply chain, and we use deep learning to automatically extract buyer\u2013supplier relations from natural language text. early results show that supply chain mapping solutions using natural language processing and deep learning could enable companies to (a) automatically generate rudimentary supply chain maps, (b) verify existing supply chain maps, or (c) augment existing maps with additional supplier information.\"",
            "contribution_ids": [
                "R193699"
            ]
        },
        {
            "instance_id": "R194697xR129608",
            "comparison_id": "R194697",
            "paper_id": "R129608",
            "text": "Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing \\n pretraining large neural language models, such as bert, has led to impressive gains on many natural language processing (nlp) tasks. however, most pretraining efforts focus on general domain corpora, such as newswire and web. a prevailing assumption is that even domain-specific pretraining can benefit by starting from general-domain language models. in this article, we challenge this assumption by showing that for domains with abundant unlabeled text, such as biomedicine, pretraining language models from scratch results in substantial gains over continual pretraining of general-domain language models. to facilitate this investigation, we compile a comprehensive biomedical nlp benchmark from publicly available datasets. our experiments show that domain-specific pretraining serves as a solid foundation for a wide range of biomedical nlp tasks, leading to new state-of-the-art results across the board. further, in conducting a thorough evaluation of modeling choices, both for pretraining and task-specific fine-tuning, we discover that some common practices are unnecessary with bert models, such as using complex tagging schemes in named entity recognition. to help accelerate research in biomedical nlp, we have released our state-of-the-art pretrained and task-specific models for the community, and created a leaderboard featuring our blurb benchmark (short for biomedical language understanding &amp; reasoning benchmark) at\\n https://aka.ms/blurb \\n .\\n",
            "contribution_ids": [
                "R194667",
                "R194670",
                "R194672",
                "R194674",
                "R194681",
                "R194682",
                "R194683",
                "R194684",
                "R194685",
                "R129609"
            ]
        },
        {
            "instance_id": "R196613xR196553",
            "comparison_id": "R196613",
            "paper_id": "R196553",
            "text": "Domain Independent Automatic Labeling system for Large-scale Social Data using Lexicon and Web-based Augmentation recently, with the large-scale adoption of social media, people have begun to express their opinion on these sites in the form of reviews. potential consumers often forced to wade through huge amount of reviews to make informed decision. sentiment analysis has become rapid and effective way to automatically gauge consumers\u2019 opinion. however, such analysis often requires tedious process of manual tagging of large training examples or manually building a lexicon for the purpose of classifying reviews as positive or negative. in this paper, we present a method to automate the tedious process of labeling large textual data in an unsupervised, domain independent and scalable manner. the proposed method combines the lexicon-based and web-based point wise mutual information (pmi) statistics to find the semantic orientation (so) of opinion expressed in a review.\\xa0 based on proposed methods a system called domain independent automatic labeling system (dials) has been implemented, which takes collection of text from any domain as input and generates fully labeled dataset in an unsupervised and scalable manner. the result generated can be used to track and summarize online discussion and/or use to train any classifier in the next stage of development. the effectiveness of system is tested by comparing it with baseline machine learning and lexicon-based methods. experiments on multi-domains dataset has shown that proposed method consistently shown improved recall and accuracy as compared to baseline machine learning and lexicon-based methods.\\xa0\\xa0\\xa0",
            "contribution_ids": [
                "R196555"
            ]
        },
        {
            "instance_id": "R196613xR196605",
            "comparison_id": "R196613",
            "paper_id": "R196605",
            "text": "Sentiment Analysis of Persian Movie Reviews Using Deep Learning sentiment analysis aims to automatically classify the subject\u2019s sentiment (e.g., positive, negative, or neutral) towards a particular aspect such as a topic, product, movie, news, etc. deep learning has recently emerged as a powerful machine learning technique to tackle the growing demand for accurate sentiment analysis. however, the majority of research efforts are devoted to english-language only, while information of great importance is also available in other languages. this paper presents a novel, context-aware, deep-learning-driven, persian sentiment analysis approach. specifically, the proposed deep-learning-driven automated feature-engineering approach classifies persian movie reviews as having positive or negative sentiments. two deep learning algorithms, convolutional neural networks (cnn) and long-short-term memory (lstm), are applied and compared with our previously proposed manual-feature-engineering-driven, svm-based approach. simulation results demonstrate that lstm obtained a better performance as compared to multilayer perceptron (mlp), autoencoder, support vector machine (svm), logistic regression and cnn algorithms.",
            "contribution_ids": [
                "R196608"
            ]
        },
        {
            "instance_id": "R197259xR196928",
            "comparison_id": "R197259",
            "paper_id": "R196928",
            "text": "Detection of human norovirus in intestinal biopsies from immunocompromised transplant patients human noroviruses (hunovs) can often cause chronic infections in solid organ and haematopoietic stem cell transplant (hsct) patients. based on histopathological changes observed during hunov infections, the intestine is the presumed site of virus replication in patients; however, the cell types infected by hunovs remain unknown. the objective of this study was to characterize histopathological changes during hunov infection and to determine the cell types that may be permissive for hunov replication in transplant patients. we analysed biopsies from hunov-infected and non-infected (control) transplant patients to assess histopathological changes in conjunction with detection of hunov antigens to identify the infected cell types. hunov infection in immunocompromised patients was associated with histopathological changes such as disorganization and flattening of the intestinal epithelium. the hunov major capsid protein, vp1, was detected in all segments of the small intestine, in areas of biopsies that showed histopathological changes. specifically, vp1 was detected in enterocytes, macrophages, t cells and dendritic cells. hunov replication was investigated by detecting the non-structural proteins, rdrp and vpg. we detected rdrp and vpg along with vp1 in duodenal and jejunal enterocytes. these results provide critical insights into histological changes due to hunov infection in immunocompromised patients and propose human enterocytes as a physiologically relevant cell type for hunov cultivation.",
            "contribution_ids": [
                "R196930",
                "R196956"
            ]
        },
        {
            "instance_id": "R197259xR196942",
            "comparison_id": "R197259",
            "paper_id": "R196942",
            "text": "Human norovirus targets enteroendocrine epithelial cells in the small intestine abstract human noroviruses are a major cause of diarrheal illness, but pathogenesis is poorly understood. here, we investigate the cellular tropism of norovirus in specimens from four immunocompromised patients. abundant norovirus antigen and rna are detected throughout the small intestinal tract in jejunal and ileal tissue from one pediatric intestinal transplant recipient with severe gastroenteritis. negative-sense viral rna, a marker of active viral replication, is found predominantly in intestinal epithelial cells, with chromogranin a-positive enteroendocrine cells (eecs) identified as a permissive cell type in this patient. these findings are consistent with the detection of norovirus-positive eecs in the other three immunocompromised patients. investigation of the signaling pathways induced in eecs that mediate communication between the gut and brain may clarify mechanisms of pathogenesis and lead to the development of in vitro model systems in which to evaluate norovirus vaccines and treatment.",
            "contribution_ids": [
                "R196946",
                "R196989"
            ]
        },
        {
            "instance_id": "R197259xR197081",
            "comparison_id": "R197259",
            "paper_id": "R197081",
            "text": "Chimpanzees as an animal model for human norovirus infection and vaccine development noroviruses are global agents of acute gastroenteritis, but the development of control strategies has been hampered by the absence of a robust animal model. studies in chimpanzees have played a key role in the characterization of several fastidious hepatitis viruses, and we investigated the feasibility of such studies for the noroviruses. seronegative chimpanzees inoculated i.v. with the human norovirus strain norwalk virus (nv) did not show clinical signs of gastroenteritis, but the onset and duration of virus shedding in stool and serum antibody responses were similar to that observed in humans. nv rna was detected in intestinal and liver biopsies concurrent with the detection of viral shedding in stool, and nv antigen expression was observed in cells of the small intestinal lamina propria. two infected chimpanzees rechallenged 4, 10, or 24 mo later with nv were resistant to reinfection, and the presence of nv-specific serum antibodies correlated with protection. we evaluated the immunogenicity and efficacy of virus-like particles (vlps) derived from nv (genogroup i, gi) and md145 (genogroup ii, gii) noroviruses as vaccines. chimpanzees vaccinated intramuscularly with gi vlps were protected from nv infection when challenged 2 and 18 mo after vaccination, whereas chimpanzees that received gii vlps vaccine or a placebo were not. this study establishes the chimpanzee as a viable animal model for the study of norovirus replication and immunity, and shows that nv vlp vaccines could induce protective homologous immunity even after extended periods of time.",
            "contribution_ids": [
                "R197083",
                "R197114"
            ]
        },
        {
            "instance_id": "R197375xR193559",
            "comparison_id": "R197375",
            "paper_id": "R193559",
            "text": "Animal-vehicle collisions during the COVID-19 lockdown in early 2020 in the Krakow metropolitan region, Poland abstract the interrelations between human activity and animal populations are of increasing interest due to the emergence of the novel covid-19 and the consequent pandemic across the world. anthropogenic impacts of the pandemic on animals in urban-suburban environments are largely unknown. in this study, the temporal and spatial patterns of urban animal response to the covid-19 lockdown were assessed using animal-vehicle collisions (avc) data. we collected avc data over two 6-month periods in 2019 and 2020 (january to june) from the largest metropolis in southern poland, which included lockdown months. furthermore, we used traffic data to understand the impact of lockdown on avc in the urban area. our analysis of 1063 avc incidents revealed that covid-19 related lockdown decreased avc rates in suburban areas. however, in the urban area, even though traffic volume had significantly reduced, avc did not decrease significantly, suggesting that lockdown did not influence the collision rates in the urban area. our results suggest that there is a need to focus on understanding the effects of changes in traffic volume on both human behaviour and wildlife space use on the resulting impacts on avc in the urban area.",
            "contribution_ids": [
                "R194716",
                "R195871",
                "R195873",
                "R195946",
                "R195947",
                "R195956"
            ]
        },
        {
            "instance_id": "R198562xR195616",
            "comparison_id": "R198562",
            "paper_id": "R195616",
            "text": "Emission Variations of Primary Air Pollutants from Highway Vehicles and Implications during the COVID-19 Pandemic in Beijing, China according to the traffic flow variation from january 2019 to august 2020, emissions of primary air pollutants from highway vehicles were calculated based on the emission factor method, which integrated the actual structure of on-road vehicles. the characteristics of on-highway traffic flow and pollution emissions were compared during various progression stages of coronavirus disease (covid-19). the results showed that the average daily traffic volume decreased by 38.2% in 2020, with a decrease of 62% during the strict lockdown due to the impact of covid-19. the daily emissions of primary atmospheric pollutants decreased by 29.2% in 2020 compared to the same period in 2019. as for the structure of on-highway vehicle types, the small and medium-sized passenger vehicles predominated, which accounted for 76.3% of traffic, while trucks and large passenger vehicles accounted for 19.7% and 4.0%, but contributed 58.4% and 33.9% of nitrogen oxide (nox) emissions, respectively. according to the simulation results of the adms model, the average concentrations of nox were reduced by 12.0 \u00b5g/m3 compared with the same period in 2019. as for the implication for future pollution control, it is necessary to further optimize the structure of on-highway and the road traffic vehicle types and increase the proportions of new-energy vehicles and vehicles with high emission standards.",
            "contribution_ids": [
                "R195619",
                "R200031"
            ]
        },
        {
            "instance_id": "R198562xR196747",
            "comparison_id": "R198562",
            "paper_id": "R196747",
            "text": "Differential Effects of the COVID-19 Lockdown and Regional Fire on the Air Quality of Medell\u00c3\u00adn, Colombia governments\u2019 responses to the covid-19 pandemic provide a unique opportunity to study the effects of restricted socioeconomic activity on air quality. here, we study the changes in air pollution levels during the lockdown in medell\u00edn and its metropolitan area, colombia, for periods with and without enhanced regional fire activity, considering the effects of meteorology using random forest and multiple linear regression methods. the lockdown measures, which reduced mean traffic volume by 70% compared to 2016\u20132019, resulted in reductions for pm2.5 (50\u201363%), pm10 (59\u201364%), no (75\u201376%), no2 (43\u201347%), and co (40\u201347%), while o3 concentration increased by 19\u201322%. in contrast, when fire activity was high, the effects of the lockdown on air quality were shadowed by the long-range transport of biomass burning emissions, increasing fine particulate matter and ozone. this study shows that healthier levels are achievable through significant efforts from decision-makers and society. the results highlight the need to develop integral measures that do not only consider reductions in the local emissions from transportation and industry, but also the role of fire activity in the region, as well as the difficulties of achieving reductions in ozone from measures that are effective at reducing primary pollutants.",
            "contribution_ids": [
                "R196748",
                "R200063",
                "R200087",
                "R200133",
                "R200136",
                "R200139",
                "R200142"
            ]
        },
        {
            "instance_id": "R198562xR196778",
            "comparison_id": "R198562",
            "paper_id": "R196778",
            "text": "Risk-Compensation Trends in Road Safety during COVID-19 the covid-19 pandemic has had a global impact, disrupting the normal trends of our everyday life. more specifically, the effects of covid-19 on road safety are still largely unexplored. hence, this study aims to investigate the change in road safety trends due to covid-19 using real-time traffic parameters. results from the extensive analyses of the 2017 to 2020 data of interstate-4 show that traffic volume decreased by 13.6% in 2020 compared to the average of 2017\u20132019\u2019s volume, whereas there is a decreasing number of crashes at the higher volume. average speed increased by 11.3% during the covid-19 period; however, the increase in average speed during the covid-19 period has an insignificant relationship with crash severities. fatal crashes increased, while total crashes decreased, during the covid-19 period; severe crashes decreased with the total crashes. alcohol-related crashes decreased by 22% from 2019 to 2020. thus, the road-safety trend due to the impact of covid-19 has evidently changed and presents a unique trend. the findings of the study suggest a larger need for a more in-depth study to analyze the impact of covid-19 on road safety, to minimize fatalities on roads through appropriate policy measures.",
            "contribution_ids": [
                "R196780"
            ]
        },
        {
            "instance_id": "R199173xR197551",
            "comparison_id": "R199173",
            "paper_id": "R197551",
            "text": "Non-Uniform Adversarially Robust Pruning neural networks often are highly redundant and can thus be effectively compressed to a fraction of their initial size using model pruning techniques without harming the overall prediction accuracy. additionally, pruned networks need to maintain robustness against attacks such as adversarial examples. recent research on combining all these objectives has shown significant advances using uniform compression strategies, that is, all weights or channels are compressed equally according to a preset compression ratio. in this paper, we show that employing non-uniform compression strategies allows to significantly improve clean data accuracy as well as adversarial robustness under high overall compression. we leverage reinforcement learning for finding an optimal trade-off and demonstrate that the resulting compression strategy can be used as a plug-in replacement for uniform compression ratios of existing state-of-the-art approaches.",
            "contribution_ids": [
                "R197552"
            ]
        },
        {
            "instance_id": "R199173xR197592",
            "comparison_id": "R199173",
            "paper_id": "R197592",
            "text": "What to expect of hardware metric predictors in NAS modern neural architecture search (nas) focuses on finding the best performing architectures in hardware-aware settings; e.g., those with an optimal tradeoff of accuracy and latency. due to many advantages of prediction models over live measurements, the search process is often guided by estimates of how well each considered network architecture performs on the desired metrics. typical prediction models range from operation-wise lookup tables over gradient-boosted trees and neural networks, with little known information on how they compare. we evaluate 18 different performance predictors on ten combinations of metrics, devices, network types, and training tasks, and find that mlp models are the most promising. we then simulate and evaluate how the guidance of such prediction models affects the subsequent architecture selection. due to inaccurate predictions, the selected architectures are generally suboptimal, which we quantify as an expected reduction in accuracy and hypervolume. we show that simply verifying the predictions of just the selected architectures can lead to substantially improved results. under a time budget, we find it preferable to use a fast and inaccurate prediction model over accurate but slow live measurements. code and results are available at https://github.com/cogsys-tuebingen/naslib",
            "contribution_ids": [
                "R197593"
            ]
        },
        {
            "instance_id": "R199173xR197596",
            "comparison_id": "R199173",
            "paper_id": "R197596",
            "text": "Differentiable Architecture Search for Reinforcement Learning in this paper, we investigate the fundamental question: to what extent are gradient-based neural architecture search (nas) techniques applicable to rl? using the original darts as a convenient baseline, we discover that the discrete architectures found can achieve up to 250% performance compared to manual architecture designs on both discrete and continuous action space environments across o-policy and on-policy rl algorithms, at only 3x more computation time. furthermore, through numerous ablation studies, we systematically verify that not only does darts correctly upweight operations during its supernet phrase, but also gradually improves resulting discrete cells up to 30x more eciently than random search, suggesting darts is surprisingly an eective tool for improving architectures in rl.",
            "contribution_ids": [
                "R197597"
            ]
        },
        {
            "instance_id": "R199176xR194747",
            "comparison_id": "R199176",
            "paper_id": "R194747",
            "text": "A health consumer ontology of fast food information a variety of severe health issues can be attributed to poor nutrition and poor eating behaviors. research has explored the impact of nutritional knowledge on an individual\u2019s inclination to purchase and consume certain foods. this paper introduces the ontology of fast food facts, a knowledge base that models consumer nutritional data from major fast food establishments. this artifact serves as an aggregate knowledge base to centralize nutritional information for consumers. as a semantically-linked data source, the ontology of fast food facts could engender methods and tools to further the research and impact the health consumers\u2019 diet and behavior, which is a factor in many severe health outcomes. we describe the initial development of this ontology and future directions we plan with this knowledge base.",
            "contribution_ids": [
                "R194750",
                "R194756",
                "R194757"
            ]
        },
        {
            "instance_id": "R199176xR195387",
            "comparison_id": "R199176",
            "paper_id": "R195387",
            "text": "FOBI: an ontology to represent food intake data and associate it with metabolomic data abstract \\n nutrition research can be conducted by using two complementary approaches: (i) traditional self-reporting methods or (ii) via metabolomics techniques to analyze food intake biomarkers in biofluids. however, the complexity and heterogeneity of these two very different types of data often hinder their analysis and integration. to manage this challenge, we have developed a novel ontology that describes food and their associated metabolite entities in a hierarchical way. this ontology uses a formal naming system, category definitions, properties and relations between both types of data. the ontology presented is called fobi (food-biomarker ontology) and it is composed of two interconnected sub-ontologies. one is a \u2019food ontology\u2019 consisting of raw foods and \u2018multi-component foods\u2019 while the second is a \u2018biomarker ontology\u2019 containing food intake biomarkers classified by their chemical classes. these two sub-ontologies are conceptually independent but interconnected by different properties. this allows data and information regarding foods and food biomarkers to be visualized in a bidirectional way, going from metabolomics to nutritional data or vice versa. potential applications of this ontology include the annotation of foods and biomarkers using a well-defined and consistent nomenclature, the standardized reporting of metabolomics workflows (e.g. metabolite identification, experimental design) or the application of different enrichment analysis approaches to analyze nutrimetabolomic data. availability: fobi is freely available in both owl (web ontology language) and obo (open biomedical ontologies) formats at the project\u2019s github repository (https://github.com/pcastellanoescuder/foodbiomarkerontology) and fobi visualization tool is available in https://polcastellano.shinyapps.io/fobi_visualization_tool/.",
            "contribution_ids": [
                "R195388",
                "R195406",
                "R195407",
                "R195408"
            ]
        },
        {
            "instance_id": "R200035xR199183",
            "comparison_id": "R200035",
            "paper_id": "R199183",
            "text": "Exposure to Human and Bovine Noroviruses in a Birth Cohort in Southern India from 2002 to 2006 abstract \\n human and bovine norovirus virus-like particles were used to evaluate antibodies in indian children at ages 6 and 36 months and their mothers. antibodies to genogroup ii viruses were acquired early and were more prevalent than antibodies to genogroup i. low levels of igg antibodies against bovine noroviruses indicate possible zoonotic transmission.",
            "contribution_ids": [
                "R199185",
                "R199194",
                "R199195"
            ]
        },
        {
            "instance_id": "R200035xR200014",
            "comparison_id": "R200035",
            "paper_id": "R200014",
            "text": "Presence of Antibodies against Genogroup VI Norovirus in Humans abstract \\n \\n background \\n noroviruses are important enteric pathogens in humans and animals. recently, we reported a novel canine norovirus (canov) in dogs with diarrhea belonging to a new genogroup (gvi). no data are available on exposure of humans to this virus. \\n \\n \\n methods \\n sera from 373 small animal veterinarians and 120 age-matched population controls were tested for igg antibodies to canov by a recombinant virus like particle based enzyme-linked immunosorbent assay. \\n \\n \\n results \\n antibodies to canov were found in 22.3% of the veterinarians and 5.8% of the control group (p\\u2009&lt;\\u20090.001). mean corrected od 450 values for canov antibodies were significantly higher in small animal veterinarians compared to the control group. \\n \\n \\n conclusions \\n these findings suggest that canov may infect humans and small animal veterinarians are at an increased risk for exposure to this virus. additional studies are needed to assess if this virus is able to cause disease in humans. \\n",
            "contribution_ids": [
                "R200016",
                "R200017"
            ]
        },
        {
            "instance_id": "R201263xR201164",
            "comparison_id": "R201263",
            "paper_id": "R201164",
            "text": "A robust and conductive metal-impregnated graphene oxide membrane selectively separating organic vapors a robust and conductive graphene oxide membrane with selective separation properties can be easily prepared by the vapor phase metal-impregnation effect provided by an atomic layer deposition process.",
            "contribution_ids": [
                "R201168"
            ]
        },
        {
            "instance_id": "R201263xR189410",
            "comparison_id": "R201263",
            "paper_id": "R189410",
            "text": "Graphene Oxide Papers Modified by Divalent Ions\u00e2\u0080\u0094Enhancing Mechanical Properties <i>via</i> Chemical Cross-Linking significant enhancement in mechanical stiffness (10-200%) and fracture strength (approximately 50%) of graphene oxide paper, a novel paperlike material made from individual graphene oxide sheets, can be achieved upon modification with a small amount (less than 1 wt %) of mg(2+) and ca(2+). these results can be readily rationalized in terms of the chemical interactions between the functional groups of the graphene oxide sheets and the divalent metals ions. while oxygen functional groups on the basal planes of the sheets and the carboxylate groups on the edges can both bond to mg(2+) and ca(2+), the main contribution to mechanical enhancement of the paper comes from the latter.",
            "contribution_ids": [
                "R201154",
                "R189412"
            ]
        },
        {
            "instance_id": "R201263xR189423",
            "comparison_id": "R201263",
            "paper_id": "R189423",
            "text": "Graphene Oxide Sheets Chemically Cross-Linked by Polyallylamine we report that a homogeneous aqueous colloidal suspension of chemically cross-linked graphene oxide sheets was generated by addition of polyallylamine to an aqueous suspension of graphene oxide sheets followed by sonication of the mixture. this is the first example for producing a homogeneous colloidal suspension of cross-linked graphene sheets. as a demonstration of the utility of such a colloidal suspension, \u201cpaper\u201d material samples made by simple filtration from such a suspension of cross-linked graphene oxide sheets showed excellent mechanical stiffness and strength.",
            "contribution_ids": [
                "R189425"
            ]
        },
        {
            "instance_id": "R201972xR201885",
            "comparison_id": "R201972",
            "paper_id": "R201885",
            "text": "Upper limb joint angle measurement in occupational health usual human motion capture systems are designed to work in controlled laboratory conditions. for occupational health, instruments that can measure during normal daily life are essential, as the evaluation of the workers' movements is a key factor to reduce employee injury- and illness-related costs. in this paper, we present a method for joint angle measurement, combining inertial sensors (accelerometers and gyroscopes) and magnetic sensors. this method estimates wrist flexion, wrist lateral deviation, elbow flexion, elbow pronation, shoulder flexion, shoulder abduction and shoulder internal rotation. the algorithms avoid numerical integration of the signals, which allows for long-time estimations without angle estimation drift. the system has been tested both under laboratory and field conditions. controlled laboratory tests show mean estimation errors between 0.06\u00b0 and of 1.05\u00b0, and standard deviation between 2.18\u00b0 and 9.20\u00b0. field tests seem to confirm these results when no ferromagnetic materials are close to the measurement system.",
            "contribution_ids": [
                "R201887"
            ]
        },
        {
            "instance_id": "R201972xR201888",
            "comparison_id": "R201972",
            "paper_id": "R201888",
            "text": "A Novel Kalman Filter for Human Motion Tracking With an Inertial-Based Dynamic Inclinometer goal: design and development of a linear kalman filter to create an inertial-based inclinometer targeted to dynamic conditions of motion. methods: the estimation of the body attitude (i.e., the inclination with respect to the vertical) was treated as a source separation problem to discriminate the gravity and the body acceleration from the specific force measured by a triaxial accelerometer. the sensor fusion between triaxial gyroscope and triaxial accelerometer data was performed using a linear kalman filter. wrist-worn inertial measurement unit data from ten participants were acquired while performing two dynamic tasks: 60-s sequence of seven manual activities and 90 s of walking at natural speed. stereophotogrammetric data were used as a reference. a statistical analysis was performed to assess the significance of the accuracy improvement over state-of-the-art approaches. results: the proposed method achieved, on an average, a root mean square attitude error of 3.6\u00b0 and 1.8\u00b0 in manual activities and locomotion tasks (respectively). the statistical analysis showed that, when compared to few competing methods, the proposed method improved the attitude estimation accuracy. conclusion: a novel kalman filter for inertial-based attitude estimation was presented in this study. a significant accuracy improvement was achieved over state-of-the-art approaches, due to a filter design that better matched the basic optimality assumptions of kalman filtering. significance: human motion tracking is the main application field of the proposed method. accurately discriminating the two components present in the triaxial accelerometer signal is well suited for studying both the rotational and the linear body kinematics.",
            "contribution_ids": [
                "R201890"
            ]
        },
        {
            "instance_id": "R201972xR201900",
            "comparison_id": "R201972",
            "paper_id": "R201900",
            "text": "A wearable inertial-sensing-based body sensor network for shoulder range of motion assessment this paper presents a wearable inertial-sensing-based body sensor network (bsn) composed of two inertial modules that are placed on human upper limb for real-time human motion capture applications. each inertial module consists of an arm-based 32-bit microcontroller (mcu), a triaxial accelerometer, a triaxial gyroscope, and a triaxial magnetometer. to estimate shoulder range of motion (rom), the accelerations, angular velocities, and magnetic signals are collected and processed by a quaternion-based complementary nonlinear filter for minimizing the cumulative errors caused by the intrinsic noise/drift of the inertial sensors. the proposed bsn is a cost-effective tool and can be used anywhere without any external reference device for shoulder rom. the sensor fusion algorithm can reduce orientation error effectively and thus can assess shoulder joint motions accurately.",
            "contribution_ids": [
                "R201902"
            ]
        },
        {
            "instance_id": "R201972xR201909",
            "comparison_id": "R201972",
            "paper_id": "R201909",
            "text": "Ambulatory human upper limb joint motion monitoring in order to make an ergonomic analysis of laborer working conditions, we need to measure the different joint angles along the daily work. these angles will be used to define the requirements of each workstation. this information, together with the medical examination of each worker, is then used to determine whether a worker can develop a task, or if the task may have caused an occupational disease. usual human motion capture systems are designed to work in laboratory controlled conditions. this paper presents a method of angular joint measurement, combining inertial sensors (accelerometers and gyroscopes) and magnetic sensors, which allows the ambulatory estimation of the 7 degrees of freedom of the upper limb, for a long time, without problems due to time integration of the signal.",
            "contribution_ids": [
                "R201911"
            ]
        },
        {
            "instance_id": "R201972xR201921",
            "comparison_id": "R201972",
            "paper_id": "R201921",
            "text": "Towards Miniaturization of a MEMS-Based Wearable Motion Capture System this paper presents a modular architecture to develop a wearable system for real-time human motion capture. the system is based on a network of smart inertial measurement units (imus) distributed on the human body. each of these modules is provided with a 32-bit risc microcontroller (mcu) and miniaturized mems sensors: three-axis accelerometer, three-axis gyroscopes, and three-axis magnetometer. the mcu collects measurements from the sensors and implement the sensor fusion algorithm, a quaternion-based extended kalman filter to estimate the attitude and the gyroscope biases. the design of the proposed imu, in order to overcome the problems of the commercial solution, aims to improve performance and to reduce size and weight. in this way, it can be easily embedded in a tracksuit for total body motion reconstruction with considerable enhancement of the wearability and comfort. furthermore, the main achievements will be presented with a performance comparison between the proposed imu and some commercial platforms.",
            "contribution_ids": [
                "R201923"
            ]
        },
        {
            "instance_id": "R201972xR201933",
            "comparison_id": "R201972",
            "paper_id": "R201933",
            "text": "A Fast Quaternion-Based Orientation Optimizer via Virtual Rotation for Human Motion Tracking for real-time ambulatory human motion tracking with low-cost inertial/magnetic sensors, a computationally efficient and robust algorithm for estimating orientation is critical. this paper presents a quaternion-based orientation optimizer for tracking human body motion, using triaxis rate gyro, accelerometer, and magnetometer signals. the proposed optimizer uses a gauss-newton (g-n) method for finding the best-fit quaternion. in order to decrease the computing time, the optimizer is formulated using a virtual rotation concept that allows very fast quaternion updates compared to the conventional g-n method. in addition, to guard against the effects of fast body motions and temporary ferromagnetic disturbances, a situational measurement vector selection procedure is adopted in conjunction with the g-n optimizer. the accuracy of orientation estimates is validated experimentally, using arm motion trials.",
            "contribution_ids": [
                "R201935"
            ]
        },
        {
            "instance_id": "R202077xR201686",
            "comparison_id": "R202077",
            "paper_id": "R201686",
            "text": "Accuracy Assessment of Kriging, artificial neural network, and a hybrid approach integrating spatial and terrain data in estimating and mapping of soil organic carbon this study aimed to produce a soil organic carbon (soc) content map with high accuracy and spatial resolution using the most effective factors in the model. the spatial soc estimation success of inverse distance weighting (idw), ordinary kriging (ok), empirical bayesian kriging (ebk), multi-layered perception network (mlp) and mlp-ok hybrid models were compared to obtain the most reliable model in estimating the soc content. the study area was located in besni district in the southeastern anatolia region of turkey. total of 132 surface (0\u201330 cm) soil samples were collected from the covers 1330 km 2 land and analyzed for soc, lime, clay and sand content and soil reaction included in the estimation models. mean annual precipitation and temperature, elevation, compound topographic index, enhanced vegetation and normalized difference vegetation index, were also used as the inputs in the modelling. the spatial distribution of soc was determined using a mlp and a two-stage ensemble model (mlp-ok) combining the estimation of ok residuals. soil surveys and covariates were used to train and validate the mlp-ok hybrid model. the mlp-ok model provided a more accurate estimation of soc content with minimal estimation errors (me: -0.028, 45 mae: 0.042, rmse: 0.066) for validation points compared to the other models. the mlp-ok model outperformed other models by 75.09 to 77.92%. the mlp-ok model estimated the lower and upper limits of the estimated and the measured values in a consistent manner compared to the other models. the spatial distribution map of soc content obtained by ann-kriging approach was significantly affected by ancillary variables, and revealed more detail than other interpolation methods in the northern, central, southwestern and southeastern parts of the study area. the results revealed that the assembling of mlp with ok model can contribute to obtain more reliable regional, national and global spatial soil information.",
            "contribution_ids": [
                "R201688"
            ]
        },
        {
            "instance_id": "R202077xR201997",
            "comparison_id": "R202077",
            "paper_id": "R201997",
            "text": "Ensemble Machine Learning Approach Improves Predicted Spatial Variation of Surface Soil Organic Carbon Stocks in Data-Limited Northern Circumpolar Region various approaches of differing mathematical complexities are being applied for spatial prediction of soil properties. regression kriging is a widely used hybrid approach of spatial variation that combines correlation between soil properties and environmental factors with spatial autocorrelation between soil observations. in this study, we compared four machine learning approaches (gradient boosting machine, multinarrative adaptive regression spline, random forest, and support vector machine) with regression kriging to predict the spatial variation of surface (0\u201330 cm) soil organic carbon (soc) stocks at 250-m spatial resolution across the northern circumpolar permafrost region. we combined 2,374 soil profile observations (calibration datasets) with georeferenced datasets of environmental factors (climate, topography, land cover, bedrock geology, and soil types) to predict the spatial variation of surface soc stocks. we evaluated the prediction accuracy at randomly selected sites (validation datasets) across the study area. we found that different techniques inferred different numbers of environmental factors and their relative importance for prediction of soc stocks. regression kriging produced lower prediction errors in comparison to multinarrative adaptive regression spline and support vector machine, and comparable prediction accuracy to gradient boosting machine and random forest. however, the ensemble median prediction of soc stocks obtained from all four machine learning techniques showed highest prediction accuracy. although the use of different approaches in spatial prediction of soil properties will depend on the availability of soil and environmental datasets and computational resources, we conclude that the ensemble median prediction obtained from multiple machine learning approaches provides greater spatial details and produces the highest prediction accuracy. thus an ensemble prediction approach can be a better choice than any single prediction technique for predicting the spatial variation of soc stocks.",
            "contribution_ids": [
                "R201999"
            ]
        },
        {
            "instance_id": "R202360xR202236",
            "comparison_id": "R202360",
            "paper_id": "R202236",
            "text": "xTSeH: A Trusted Platform Module Sharing Scheme Towards Smart IoT-eHealth Devices iot based ehealth system brings a revolution to healthcare industry, with which the old healthcare systems can be updated into smarter and more personalized ones. the practitioners can continue monitoring the physical status of the patients at anytime and anywhere, and develop more precise treatment plans by analyzing the collected data, such as heart rate, blood pressure, blood glucose. actually, these smart sensors used in ehealth system are smart embedded devices (sed). due to the limitations on hardware capabilities, these inter-connected seds lack of security considerations in design and implementation, and face the threats from the network. to prevent the malicious users (or programs) from tampering with the seds, trusted platform module (tpm) is adopted, which can guarantee the system integrity via detecting unauthorized modifications to data and system environment. however, due to the limited scalability and insufficient system resources, not all seds can be deployed with tpm chips. to address this issue, in this paper, a tpm extension scheme (xtseh) is proposed. in xtseh, we have extended the functions of a tpm deployed in a sed (tsed) to those non-tpm-protected seds (n-tsed) via network. a shadow tpm in the form of a kernel module is designed as the trust base for the n-tsed, which is the representative of the tpm in tsed. then, three protocols are proposed to implement the integrity verification and inter-sed authentication. finally, a raspberry pi based prototype system is designed and implemented. the feasibility and usability of our scheme are proved by the analysis of the experimental results of system performance.",
            "contribution_ids": [
                "R202243"
            ]
        },
        {
            "instance_id": "R202360xR202258",
            "comparison_id": "R202360",
            "paper_id": "R202258",
            "text": "PSL-MAAKA: Provably Secure and Lightweight Mutual Authentication and Key Agreement Protocol for Fully Public Channels in Internet of Medical Things designing efficient and secure mutual authentication and key agreement (maaka) protocols for internet of medical things (iomt) has been shown to be challenging, mainly due to the different security and privacy requirements in complex settings. existing schemes generally are subject to a number of limitations, ranging from performance to security issues. in this article, we introduce a provably secure and lightweight maaka (psl-maaka) protocol for fully public channels in iomt. first, the proposed scheme is lightweight since the major operations in the stage of authentication and key agreement are hash operation and xor operation, respectively. second, this article proves the security of the presented protocol taking the advantage of the random oracle model. next, this article gives that security requirements in iomt could be satisfied through our presented maaka protocol. finally, we demonstrate that it enjoys optimal performance than other competing schemes, in terms of communication overhead, computation overhead, and storage overhead.",
            "contribution_ids": [
                "R202264"
            ]
        },
        {
            "instance_id": "R203903xR203594",
            "comparison_id": "R203903",
            "paper_id": "R203594",
            "text": "Gaussian versus Uniform Distribution for Intrusion Detection in Wireless Sensor Networks in a wireless sensor network (wsn), intrusion detection is of significant importance in many applications in detecting malicious or unexpected intruder(s). the intruder can be an enemy in a battlefield, or a malicious moving object in the area of interest. with uniform sensor deployment, the detection probability is the same for any point in a wsn. however, some applications may require different degrees of detection probability at different locations. for example, an intrusion detection application may need improved detection probability around important entities. gaussian-distributed wsns can provide differentiated detection capabilities at different locations but related work is limited. this paper analyzes the problem of intrusion detection in a gaussian-distributed wsn by characterizing the detection probability with respect to the application requirements and the network parameters under both single-sensing detection and multiple-sensing detection scenarios. effects of different network parameters on the detection probability are examined in detail. furthermore, performance of gaussian-distributed wsns is compared with uniformly distributed wsns. this work allows us to analytically formulate detection probability in a random wsn and provides guidelines in selecting an appropriate deployment strategy and determining critical network parameters.",
            "contribution_ids": [
                "R203596"
            ]
        },
        {
            "instance_id": "R204005xR201735",
            "comparison_id": "R204005",
            "paper_id": "R201735",
            "text": "Frequent Detection of Noroviruses and Sapoviruses in Swine and High Genetic Diversity of Porcine Sapovirus in Japan during Fiscal Year 2008 abstract a molecular biological survey on porcine norovirus (nov) and sapovirus (sav) was conducted in toyama prefecture, japan, during fiscal year 2008. both nov and sav were detected from swine fecal samples throughout the surveillance period, indicating that these viruses were circulating in this region. nov strains detected in this study belonged to three genotypes that are known as typical swine novs. although human novs were occasionally detected, it was unclear whether they replicated in pigs. as for sav, genogroup vii (gvii) and other divergent genogroups were identified in addition to the dominant genogroup, giii, which is the prototypic porcine sav. in addition, 3 strains genetically related to human sav were detected. two of these 3 strains were closely related to human sav gv. our study showed that genetic diversification of porcine sav is currently progressing in the swine population.",
            "contribution_ids": [
                "R201737"
            ]
        },
        {
            "instance_id": "R204005xR201760",
            "comparison_id": "R204005",
            "paper_id": "R201760",
            "text": "Human Noroviruses in Swine and Cattle detection of gii.4 norovirus sequences in animal fecal samples and retail meats demonstrates that noroviruses may be transmitted zoonotically.",
            "contribution_ids": [
                "R201762",
                "R201764"
            ]
        },
        {
            "instance_id": "R204005xR201779",
            "comparison_id": "R204005",
            "paper_id": "R201779",
            "text": "Natural Norovirus Infections in Rhesus Macaques using a recently developed real-time reverse transcription pcr, i retested 500 fecal samples from rhesus macaques collected in 2008. previous conventional reverse transcription pcr testing identified 1 isolate of gii norovirus; retesting found gi, gii, and possible giv noroviruses in the samples, indicating the natural circulation of noroviruses in nonhuman primate colonies.",
            "contribution_ids": [
                "R201781"
            ]
        },
        {
            "instance_id": "R204005xR201975",
            "comparison_id": "R204005",
            "paper_id": "R201975",
            "text": "Complete Genome Sequence of a GII.17 Norovirus Isolated from a Rhesus Monkey in China abstract the previously silent gii.17 norovirus was found to be the predominant genotype causing major epidemics in china in the 2014\u20132015 winter epidemic season. we report here the complete genomic sequence of a gii.17 norovirus (mky/gii.17/km1509/chn/2015) that infected rhesus monkeys at a monkey farm in southwestern china.",
            "contribution_ids": [
                "R201977"
            ]
        },
        {
            "instance_id": "R204005xR203981",
            "comparison_id": "R204005",
            "paper_id": "R203981",
            "text": "Evidence for Human Norovirus Infection of Dogs in the United Kingdom abstract human noroviruses (hunovs) are a major cause of viral gastroenteritis, with an estimated 3 million cases per year in the united kingdom. hunovs have recently been isolated from pet dogs in europe (m. summa, c.-h. von bonsdorff, and l. maunula, j clin virol 53:244\u2013247, 2012, http://dx.doi.org/10.1016/j.jcv.2011.12.014 ), raising concerns about potential zoonotic infections. with 31% of united kingdom households owning a dog, this could prove to be an important transmission route. to examine this risk, canine tissues were studied for their ability to bind to hunov in vitro . in addition, canine stool samples were analyzed for the presence of viral nucleic acid, and canine serum samples were tested for the presence of anti-hunov antibodies. the results showed that seven different genotypes of hunov virus-like particles (vlps) can bind to canine gastrointestinal tissue, suggesting that infection is at least theoretically possible. although hunov rna was not identified in stool samples from 248 dogs, serological evidence of previous exposure to hunov was obtained in 43/325 canine serum samples. remarkably, canine seroprevalence for different hunov genotypes mirrored the seroprevalence in the human population. though entry and replication within cells have not been demonstrated, the canine serological data indicate that dogs produce an immune response to hunov, implying productive infection. in conclusion, this study reveals zoonotic implications for hunov, and to elucidate the significance of this finding, further epidemiological and molecular investigations will be essential.",
            "contribution_ids": [
                "R203984",
                "R203985"
            ]
        },
        {
            "instance_id": "R204080xR204018",
            "comparison_id": "R204080",
            "paper_id": "R204018",
            "text": "Cryptodl: Deep neural networks over encrypted data machine learning algorithms based on deep neural networks have achieved remarkable results and are being extensively used in different domains. however, the machine learning algorithms requires access to raw data which is often privacy sensitive. to address this issue, we develop new techniques to provide solutions for running deep neural networks over encrypted data. in this paper, we develop new techniques to adopt deep neural networks within the practical limitation of current homomorphic encryption schemes. more specifically, we focus on classification of the well-known convolutional neural networks (cnn). first, we design methods for approximation of the activation functions commonly used in cnns (i.e. relu, sigmoid, and tanh) with low degree polynomials which is essential for efficient homomorphic encryption schemes. then, we train convolutional neural networks with the approximation polynomials instead of original activation functions and analyze the performance of the models. finally, we implement convolutional neural networks over encrypted data and measure performance of the models. our experimental results validate the soundness of our approach with several convolutional neural networks with varying number of layers and structures. when applied to the mnist optical character recognition tasks, our approach achieves 99.52\\% accuracy which significantly outperforms the state-of-the-art solutions and is very close to the accuracy of the best non-private version, 99.77\\%. also, it can make close to 164000 predictions per hour. we also applied our approach to cifar-10, which is much more complex compared to mnist, and were able to achieve 91.5\\% accuracy with approximation polynomials used as activation functions. these results show that cryptodl provides efficient, accurate and scalable privacy-preserving predictions.",
            "contribution_ids": [
                "R204020"
            ]
        },
        {
            "instance_id": "R204080xR204022",
            "comparison_id": "R204080",
            "paper_id": "R204022",
            "text": "TAPAS: Tricks to accelerate (encrypted) prediction as a service machine learning methods are widely used for a variety of prediction problems. \\emph{prediction as a service} is a paradigm in which service providers with technological expertise and computational resources may perform predictions for clients. however, data privacy severely restricts the applicability of such services, unless measures to keep client data private (even from the service provider) are designed. equally important is to minimize the amount of computation and communication required between client and server. fully homomorphic encryption offers a possible way out, whereby clients may encrypt their data, and on which the server may perform arithmetic computations. the main drawback of using fully homomorphic encryption is the amount of time required to evaluate large machine learning models on encrypted data. we combine ideas from the machine learning literature, particularly work on binarization and sparsification of neural networks, together with algorithmic tools to speed-up and parallelize computation using encrypted data.",
            "contribution_ids": [
                "R204024"
            ]
        },
        {
            "instance_id": "R204080xR204030",
            "comparison_id": "R204080",
            "paper_id": "R204030",
            "text": "Secure outsourced matrix computation and application to neural networks homomorphic encryption (he) is a powerful cryptographic primitive to address privacy and security issues in outsourcing computation on sensitive data to an untrusted computation environment. comparing to secure multi-party computation (mpc), he has advantages in supporting non-interactive operations and saving on communication costs. however, it has not come up with an optimal solution for modern learning frameworks, partially due to a lack of efficient matrix computation mechanisms. in this work, we present a practical solution to encrypt a matrix homomorphically and perform arithmetic operations on encrypted matrices. our solution includes a novel matrix encoding method and an efficient evaluation strategy for basic matrix operations such as addition, multiplication, and transposition. we also explain how to encrypt more than one matrix in a single ciphertext, yielding better amortized performance. our solution is generic in the sense that it can be applied to most of the existing he schemes. it also achieves reasonable performance for practical use; for example, our implementation takes 9.21 seconds to multiply two encrypted square matrices of order 64 and 2.56 seconds to transpose a square matrix of order 64. our secure matrix computation mechanism has a wide applicability to our new framework edm, which stands for encrypted data and encrypted model. to the best of our knowledge, this is the first work that supports secure evaluation of the prediction phase based on both encrypted data and encrypted model, whereas previous work only supported applying a plain model to encrypted data. as a benchmark, we report an experimental result to classify handwritten images using convolutional neural networks (cnn). our implementation on the mnist dataset takes 28.59 seconds to compute ten likelihoods of 64 input images simultaneously, yielding an amortized rate of 0.45 seconds per image.",
            "contribution_ids": [
                "R204032"
            ]
        },
        {
            "instance_id": "R204080xR204076",
            "comparison_id": "R204080",
            "paper_id": "R204076",
            "text": "Cryptflow: Secure tensorflow inference we present cryptflow, a first of its kind system that converts tensorflow inference code into secure multi-party computation (mpc) protocols at the push of a button. to do this, we build three components. our first component, athos, is an end-to-end compiler from tensorflow to a variety of semihonest mpc protocols. the second component, porthos, is an improved semi-honest 3-party protocol that provides significant speedups for tensorflow like applications. finally, to provide malicious secure mpc protocols, our third component, aramis, is a novel technique that uses hardware with integrity guarantees to convert any semi-honest mpc protocol into an mpc protocol that provides malicious security. the malicious security of the protocols output by aramis relies on integrity of the hardware and semi-honest security of mpc. moreover, our system matches the inference accuracy of plaintext tensorflow.we experimentally demonstrate the power of our system by showing the secure inference of real-world neural networks such as resnet50 and densenet121 over the imagenet dataset with running times of about 30 seconds for semi-honest security and under two minutes for malicious security. prior work in the area of secure inference has been limited to semi-honest security of small networks over tiny datasets such as mnist or cifar. even on mnist/cifar, cryptflow outperforms prior work.",
            "contribution_ids": [
                "R204078"
            ]
        },
        {
            "instance_id": "R204130xR204088",
            "comparison_id": "R204130",
            "paper_id": "R204088",
            "text": "FlowRanger: A request prioritizing algorithm for controller DoS attacks in Software Defined Networks software defined networking (sdn) introduces a new communication network management paradigm and has gained much attention from academia and industry. however, the centralized nature of sdn is a potential vulnerability to the system since attackers may launch denial of services (dos) attacks against the controller. existing solutions limit requests rate to the controller by dropping overflowed requests, but they also drop legitimate requests to the controller. to address this problem, we propose flowranger, a buffer prioritizing solution for controllers to handle routing requests based on their likelihood to be attacking requests, which derives the trust values of the requesting sources. based on their trust values, flowranger classifies routing requests into multiple buffer queues with different priorities. thus, attacking requests are served with a lower priority than regular requests. our simulation results demonstrates that flowranger can significantly enhance the request serving rate of regular users under dos attacks against the controller. to the best of our knowledge, our work is the first solution to battle against controller dos attacks on the controller side.",
            "contribution_ids": [
                "R204090"
            ]
        },
        {
            "instance_id": "R204130xR204101",
            "comparison_id": "R204130",
            "paper_id": "R204101",
            "text": "Tolerating SDN application failures with LegoSDN despite software defined network's (sdn) proven benefits, there remains significant reluctance in adopting it. among the issues that hamper sdn's adoption two stand out: reliability and fault tolerance. at the heart of these issues is a set of fate-sharing relationships: the first between the sdn-apps and controllers, where-in the crash of the former induces a crash of the latter, and thereby affecting availability; and, the second between the sdn-app and the network, where-in a byzantine failure e.g., black-holes and network-loops, induces a failure in the network, and thereby affecting network availability. the principal position of this paper is that availability is of utmost concern -- second only to security. to this end, we present a re-design of the controller architecture centering around a set of abstractions to eliminate these fate-sharing relationships, and make the controllers and network resilient to sdn-app failures. we illustrate how these abstractions can be used to improve the reliability of an sdn environment, thus eliminating one of the barriers to sdn's adoption.",
            "contribution_ids": [
                "R204103"
            ]
        },
        {
            "instance_id": "R204130xR204120",
            "comparison_id": "R204130",
            "paper_id": "R204120",
            "text": "Study on authentication protocol of SDN trusted domain currently software define network (sdn) architecture has become a hot topic. aiming at the authentication security issues of sdn network architecture, we introduce an authentication protocol based on sdn network architecture without any trusted third party between trusted domains. by applying avispa security analysis system of network interaction protocol, we can guarantee protocol security and provide complete safety tests. our work fill the gap of mutual trust between different trusted domains and provide security foundation for interaction between different trusted domains.",
            "contribution_ids": [
                "R204122"
            ]
        },
        {
            "instance_id": "R204130xR204124",
            "comparison_id": "R204130",
            "paper_id": "R204124",
            "text": "A secure northbound interface for SDN applications software-defined networking (sdn) promises to introduce flexibility and programmability into networks by offering a northbound interface (nbi) for developers to create sdn applications. however, current designs and implementations have several drawbacks, including the lack of extended security features. in this paper, we present a secure northbound interface, through which an sdn controller can offer network resources, such as statistics, flow information or topology data, via a rest-like api to registered sdn applications. a trust manager ensures that only authenticated and trusted applications can utilize the interface. furthermore, a permission system allows for fine-grained authorization and access control to the aforementioned resources. we present a prototypical implementation of our interface and developed example applications using our interface, including an sdn management dashboard.",
            "contribution_ids": [
                "R204126"
            ]
        },
        {
            "instance_id": "R204209xR204174",
            "comparison_id": "R204209",
            "paper_id": "R204174",
            "text": "Enigma: Decentralized computation platform with guaranteed privacy a peer-to-peer network, enabling different parties to jointly store and run computations on data while keeping the data completely private. enigma's computational model is based on a highly optimized version of secure multi-party computation, guaranteed by a verifiable secret-sharing scheme. for storage, we use a modified distributed hashtable for holding secret-shared data. an external blockchain is utilized as the controller of the network, manages access control, identities and serves as a tamper-proof log of events. security deposits and fees incentivize operation, correctness and fairness of the system. similar to bitcoin, enigma removes the need for a trusted third party, enabling autonomous control of personal data. for the first time, users are able to share their data with cryptographic guarantees regarding their privacy.",
            "contribution_ids": [
                "R204176"
            ]
        },
        {
            "instance_id": "R204209xR204183",
            "comparison_id": "R204209",
            "paper_id": "R204183",
            "text": "Provchain: A blockchain-based data provenance architecture in cloud environment with enhanced privacy and availability cloud data provenance is metadata that records the history of the creation and operations performed on a cloud data object. secure data provenance is crucial for data accountability, forensics and privacy. in this paper, we propose a decentralized and trusted cloud data provenance architecture using blockchain technology. blockchain-based data provenance can provide tamper-proof records, enable the transparency of data accountability in the cloud, and help to enhance the privacy and availability of the provenance data. we make use of the cloud storage scenario and choose the cloud file as a data unit to detect user operations for collecting provenance data. we design and implement provchain, an architecture to collect and verify cloud data provenance, by embedding the provenance data into blockchain transactions. provchain operates mainly in three phases: (1) provenance data collection, (2) provenance data storage, and (3) provenance data validation. results from performance evaluation demonstrate that provchain provides security features including tamper-proof provenance, user privacy and reliability with low overhead for the cloud storage applications.",
            "contribution_ids": [
                "R204185"
            ]
        },
        {
            "instance_id": "R204209xR204207",
            "comparison_id": "R204209",
            "paper_id": "R204207",
            "text": "A blockchain-based framework for data sharing with fine-grained access control in decentralized storage systems in traditional cloud storage systems, attribute-based encryption (abe) is regarded as an important technology for solving the problem of data privacy and fine-grained access control. however, in all abe schemes, the private key generator has the ability to decrypt all data stored in the cloud server, which may bring serious problems such as key abuse and privacy data leakage. meanwhile, the traditional cloud storage model runs in a centralized storage manner, so single point of failure may leads to the collapse of system. with the development of blockchain technology, decentralized storage mode has entered the public view. the decentralized storage approach can solve the problem of single point of failure in traditional cloud storage systems and enjoy a number of advantages over centralized storage, such as low price and high throughput. in this paper, we study the data storage and sharing scheme for decentralized storage systems and propose a framework that combines the decentralized storage system interplanetary file system, the ethereum blockchain, and abe technology. in this framework, the data owner has the ability to distribute secret key for data users and encrypt shared data by specifying access policy, and the scheme achieves fine-grained access control over data. at the same time, based on smart contract on the ethereum blockchain, the keyword search function on the cipher text of the decentralized storage systems is implemented, which solves the problem that the cloud server may not return all of the results searched or return wrong results in the traditional cloud storage systems. finally, we simulated the scheme in the linux system and the ethereum official test network rinkeby, and the experimental results show that our scheme is feasible.",
            "contribution_ids": [
                "R204208"
            ]
        },
        {
            "instance_id": "R206187xR206100",
            "comparison_id": "R206187",
            "paper_id": "R206100",
            "text": "A multi-objective optimization model for sustainable supply chain network with using genetic algorithm purpose the purpose of this paper is to design and optimize economic and environmental dimensions in a sustainable supply chain (ssc) network. this paper developed a mixed-integer linear programing (milp) model to incorporate economical and environmental data for multi-objective optimization of the ssc network. design/methodology/approach the overall objective of the present study is to use high-quality raw materials, at the same time the lowest amount of pollution emission and the highest profitability is achieved. the model in the problem is solved using two algorithms, namely, multi-objective genetic and multi-objective particle swarm. in this research, to integrate sustainable supplier selection and optimization of sustainability performance indicators in supply chain network design considering minimization of cost and time and maximization of sustainability indexes of the system. findings the differences found between the genetic algorithms (gas) and the milp approaches can be explained by handling the constraints and their various logics. the solutions are contrasted with the original crisp model based on either milp or ga, offering more robustness to the proposed approach. practical implications the model is applied to mega motor company to optimize the sustainability performance of the supply chain i.e. economic (cost), social (time) and environmental (pollution of raw material). the research method has two approaches, namely, applied and mathematical modeling. originality/value there is limited research designing and optimizing the ssc network. this study is among the first to integrate sustainable supplier selection and optimization of sustainability performance indicators in supply chain network design considering minimization of cost and time and maximization of sustainability indexes of the system.",
            "contribution_ids": [
                "R206103"
            ]
        },
        {
            "instance_id": "R206309xR206216",
            "comparison_id": "R206309",
            "paper_id": "R206216",
            "text": "Ambulatory Position and Orientation Tracking Fusing Magnetic and Inertial Sensing this paper presents the design and testing of a portable magnetic system combined with miniature inertial sensors for ambulatory 6 degrees of freedom ( dof) human motion tracking. the magnetic system consists of three orthogonal coils, the source, fixed to the body and 3-d magnetic sensors, fixed to remote body segments, which measure the fields generated by the source. based on the measured signals, a processor calculates the relative positions and orientations between source and sensor. magnetic actuation requires a substantial amount of energy which limits the update rate with a set of batteries. moreover, the magnetic field can easily be disturbed by ferromagnetic materials or other sources. inertial sensors can be sampled at high rates, require only little energy and do not suffer from magnetic interferences. however, accelerometers and gyroscopes can only measure changes in position and orientation and suffer from integration drift. by combing measurements from both systems in a complementary kalman filter structure, an optimal solution for position and orientation estimates is obtained. the magnetic system provides 6 dof measurements at a relatively low update rate while the inertial sensors track the changes position and orientation in between the magnetic updates. the implemented system is tested against a lab-bound camera tracking system for several functional body movements. the accuracy was about 5 mm for position and 3 degrees for orientation measurements. errors were higher during movements with high velocities due to relative movement between source and sensor within one cycle of magnetic actuation",
            "contribution_ids": [
                "R206218"
            ]
        },
        {
            "instance_id": "R206309xR206222",
            "comparison_id": "R206309",
            "paper_id": "R206222",
            "text": "Reducing Drifts in the Inertial Measurements of Wrist and Elbow Positions in this paper, we present an inertial-sensor-based monitoring system for measuring the movement of human upper limbs. two wearable inertial sensors are placed near the wrist and elbow joints, respectively. the measurement drift in segment orientation is dramatically reduced after a kalman filter is applied to estimate inclinations using accelerations and turning rates from gyroscopes. using premeasured lengths of the upper and lower arms, we compute the position of the wrist and elbow joints via a proposed kinematic model. experimental results demonstrate that this new motion capture system, in comparison to an optical motion tracker, possesses an rms position error of less than 0.009 m, with a drift of less than 0.005 ms-1 in five daily activities. in addition, the rms angle error is less than 3\u00b0. this indicates that the proposed approach has performed well in terms of accuracy and reliability.",
            "contribution_ids": [
                "R206224"
            ]
        },
        {
            "instance_id": "R207120xR206262",
            "comparison_id": "R207120",
            "paper_id": "R206262",
            "text": "A Deep Learning Framework for Detection of COVID-19 Fake News on Social Media Platforms the fast growth of technology in online communication and social media platforms alleviated numerous difficulties during the covid-19 epidemic. however, it was utilized to propagate falsehoods and misleading information about the disease and the vaccination. in this study, we investigate the ability of deep neural networks, namely, long short-term memory (lstm), bi-directional lstm, convolutional neural network (cnn), and a hybrid of cnn and lstm networks, to automatically classify and identify fake news content related to the covid-19 pandemic posted on social media platforms. these deep neural networks have been trained and tested using the \u201ccovid-19 fake news\u201d dataset, which contains 21,379 real and fake news instances for the covid-19 pandemic and its vaccines. the real news data were collected from independent and internationally reliable institutions on the web, such as the world health organization (who), the international committee of the red cross (icrc), the united nations (un), the united nations children\u2019s fund (unicef), and their official accounts on twitter. the fake news data were collected from different fact-checking websites (such as snopes, politifact, and factcheck). the evaluation results showed that the cnn model outperforms the other deep neural networks with the best accuracy of 94.2%.",
            "contribution_ids": [
                "R206265"
            ]
        },
        {
            "instance_id": "R207120xR206370",
            "comparison_id": "R207120",
            "paper_id": "R206370",
            "text": "FANG: Leveraging Social Context for Fake News Detection Using Graph Representation we propose factual news graph (fang), a novel graphical social context representation and learning framework for fake news detection. unlike previous contextual models that have targeted performance, our focus is on representation learning. compared to transductive models, fang is scalable in training as it does not have to maintain all nodes, and it is efficient at inference time, without the need to re-process the entire graph. our experimental results show that fang is better at capturing the social context into a high fidelity representation, compared to recent graphical and non-graphical models. in particular, fang yields significant improvements for the task of fake news detection, and it is robust in the case of limited training data. we further demonstrate that the representations learned by fang generalize to related tasks, such as predicting the factuality of reporting of a news medium.",
            "contribution_ids": [
                "R206372"
            ]
        },
        {
            "instance_id": "R207120xR207084",
            "comparison_id": "R207120",
            "paper_id": "R207084",
            "text": "exBAKE: Automatic Fake News Detection Model Based on Bidirectional Encoder Representations from Transformers (BERT) news currently spreads rapidly through the internet. because fake news stories are designed to attract readers, they tend to spread faster. for most readers, detecting fake news can be challenging and such readers usually end up believing that the fake news story is fact. because fake news can be socially problematic, a model that automatically detects such fake news is required. in this paper, we focus on data-driven automatic fake news detection methods. we first apply the bidirectional encoder representations from transformers model (bert) model to detect fake news by analyzing the relationship between the headline and the body text of news. to further improve performance, additional news data are gathered and used to pre-train this model. we determine that the deep-contextualizing nature of bert is best suited for this task and improves the 0.14 f-score over older state-of-the-art models.",
            "contribution_ids": [
                "R207086"
            ]
        },
        {
            "instance_id": "R209290xR209021",
            "comparison_id": "R209290",
            "paper_id": "R209021",
            "text": "A large-scale benchmark dataset for event recognition in surveillance video we introduce a new large-scale video dataset designed to assess the performance of diverse visual event recognition algorithms with a focus on continuous visual event recognition (cver) in outdoor areas with wide coverage. previous datasets for action recognition are unrealistic for real-world surveillance because they consist of short clips showing one action by one individual [15, 8]. datasets have been developed for movies [11] and sports [12], but, these actions and scene conditions do not apply effectively to surveillance videos. our dataset consists of many outdoor scenes with actions occurring naturally by non-actors in continuously captured videos of the real world. the dataset includes large numbers of instances for 23 event types distributed throughout 29 hours of video. this data is accompanied by detailed annotations which include both moving object tracks and event examples, which will provide solid basis for large-scale evaluation. additionally, we propose different types of evaluation modes for visual recognition tasks and evaluation metrics along with our preliminary experimental results. we believe that this dataset will stimulate diverse aspects of computer vision research and help us to advance the cver tasks in the years ahead.",
            "contribution_ids": [
                "R209023"
            ]
        },
        {
            "instance_id": "R209290xR209045",
            "comparison_id": "R209290",
            "paper_id": "R209045",
            "text": "The highD Dataset: A Drone Dataset of Naturalistic Vehicle Trajectories on German Highways for Validation of Highly Automated Driving Systems scenario-based testing for the safety validation of highly automated vehicles is a promising approach that is being examined in research and industry. this approach heavily relies on data from real-world scenarios to derive the necessary scenario information for testing. measurement data should be collected at a reasonable effort, contain naturalistic behavior of road users and include all data relevant for a description of the identified scenarios in sufficient quality. however, the current measurement methods fail to meet at least one of the requirements. thus, we propose a novel method to measure data from an aerial perspective for scenario-based validation fulfilling the mentioned requirements. furthermore, we provide a large-scale naturalistic vehicle trajectory dataset from german highways called highd. we evaluate the data in terms of quantity, variety and contained scenarios. our dataset consists of 16.5 hours of measurements from six locations with 110 000 vehicles, a total driven distance of 45 000 km and 5600 recorded complete lane changes. the highd dataset is available online at: http://www.highd-dataset.com",
            "contribution_ids": [
                "R209047"
            ]
        },
        {
            "instance_id": "R209290xR209016",
            "comparison_id": "R209290",
            "paper_id": "R209016",
            "text": "Statistical models of pedestrian behaviour in the Forum this dissertation describes an msc project for which the purpose was to develop a system that could be used for automated surveillance. the main novelty is the use of a vertical camera. the project investigates whether such a system can effectively detect moving objects, track their trajectories, and use these to recognise anomalous events.",
            "contribution_ids": [
                "R209017"
            ]
        },
        {
            "instance_id": "R209290xR209042",
            "comparison_id": "R209290",
            "paper_id": "R209042",
            "text": "An Evaluation of Trajectory Prediction Approaches and Notes on the TrajNet Benchmark in recent years, there is a shift from modeling the tracking problem based on bayesian formulation towards using deep neural networks. towards this end, in this paper the effectiveness of various deep neural networks for predicting future pedestrian paths are evaluated. the analyzed deep networks solely rely, like in the traditional approaches, on observed tracklets without human-human interaction information. the evaluation is done on the publicly available trajnet benchmark dataset, which builds up a repository of considerable and popular datasets for trajectory-based activity forecasting. we show that a recurrent-encoder with a dense layer stacked on top, referred to as red-predictor, is able to achieve sophisticated results compared to elaborated models in such scenarios. further, we investigate failure cases and give explanations for observed phenomena and give some recommendations for overcoming demonstrated shortcomings.",
            "contribution_ids": [
                "R209044"
            ]
        },
        {
            "instance_id": "R210471xR203395",
            "comparison_id": "R210471",
            "paper_id": "R203395",
            "text": "Use of Synergistic Interactions to Fabricate Strong, Tough, and Conductive Artificial Nacre Based on Graphene Oxide and Chitosan graphene is the strongest and stiffest material, leading to the development of promising applications in many fields. however, the assembly of graphene nanosheets into macrosized nanocomposites for practical applications remains a challenge. nacre in its natural form sets the \"gold standard\" for toughness and strength, which serves as a guide to the assembly of graphene nanosheets into high-performance nanocomposites. here we show the strong, tough, conductive artificial nacre based on graphene oxide through synergistic interactions of hydrogen and covalent bonding. tensile strength and toughness was 4 and 10 times higher, respectively, than that of natural nacre. the exceptional integrated strong and tough artificial nacre has promising applications in aerospace, artificial muscle, and tissue engineering, especially for flexible supercapacitor electrodes due to its high electrical conductivity. the use of synergistic interactions is a strategy for the development of high-performance nanocomposites.",
            "contribution_ids": [
                "R203396"
            ]
        },
        {
            "instance_id": "R210471xR203397",
            "comparison_id": "R210471",
            "paper_id": "R203397",
            "text": "Superior Fatigue Resistant Bioinspired Graphene-Based Nanocomposite via Synergistic Interfacial Interactions excellent fatigue resistance is a prerequisite for flexible energy devices to achieve high and stable performance under repeated deformation state. inspired by the sophisticated interfacial architecture of nacre, herein a super fatigue\u2010resistant graphene\u2010based nanocomposite with integrated high tensile strength and toughness through poly(dopamine)\u2010nickel ion (ni2+) chelate architecture that mimics byssal threads is demonstrated. these kind of synergistic interfacial interactions of covalent and ionic bonding effectively suppress the crack propagation in the process of fatigue testing, resulting in superhigh fatigue life of this bioinspired graphene\u2010based nanocomposite (bgbn). in addition, the electrical conductivity is well kept after fatigue testing. the proposed synergistic interfacial interactions could serve as a guideline for fabricating high\u2010performance multifunctional bgbns with promising applications in flexible energy devices, such as flexible electrodes for supercapacitors and lithium batteries, etc.",
            "contribution_ids": [
                "R203399"
            ]
        },
        {
            "instance_id": "R211056xR207034",
            "comparison_id": "R211056",
            "paper_id": "R207034",
            "text": "Postmortem examination of COVID\u00e2\u0080\u009019 patients reveals diffuse alveolar damage with severe capillary congestion and variegated findings in lungs and other organs suggesting vascular dysfunction coronavirus disease 2019 (covid\u201019), caused by severe acute respiratory syndrome coronavirus 2 (sars\u2010cov\u20102), has rapidly evolved into a sweeping pandemic. its major manifestation is in the respiratory tract, and the general extent of organ involvement and the microscopic changes in the lungs remain insufficiently characterised. autopsies are essential to elucidate covid\u201019\u2010associated organ alterations.",
            "contribution_ids": [
                "R207038",
                "R209149"
            ]
        },
        {
            "instance_id": "R211056xR209082",
            "comparison_id": "R211056",
            "paper_id": "R209082",
            "text": "Multiorgan and Renal Tropism of SARS-CoV-2 multiorgan and renal tropism of sars-cov-2 in this autopsy series, the authors found that sars-cov-2 has an organotropism beyond the respiratory tract, including the kidneys, heart, liver, and brai...",
            "contribution_ids": [
                "R209086",
                "R209126",
                "R209127",
                "R209128",
                "R209129"
            ]
        },
        {
            "instance_id": "R211056xR209253",
            "comparison_id": "R211056",
            "paper_id": "R209253",
            "text": "Ultrastructural examination of lung \u00e2\u0080\u009ccryobiopsies\u00e2\u0080\u009d from a series of fatal COVID-19 cases hardly revealed infected cells abstract ultrastructural analysis of autopsy samples from covid-19 patients usually suffers from significant structural impairment possibly caused by the rather long latency between death of the patient and an appropriate sample fixation. to improve structural preservation of the tissue, we obtained samples from ventilated patients using a trans-bronchial \u201ccryobiopsy\u201d within 30 min after their death and fixed them immediately for electron microscopy. samples of six covid-19 patients with a documented histopathology were systematically investigated by thin section electron microscopy. the different samples and areas inspected revealed the ultrastructural correlates of the different phases of diffuse alveolar damage, including detachment of the alveolar epithelium, hyperplasia of type 2 cells, exudates, and accumulation of extracellular material, such as the hyaline membranes and fibrin. macrophages and neutrophilic granulocytes were regularly detected. structural integrity of endothelium was intact in regions where the alveolar epithelium was already detached. aggregates of erythrocytes, leukocytes with fibrin, and thrombocytes were not observed. coronavirus particles were only found in and around very few cells in one of the six patient samples. the type and origin of these cells could not be assessed although the overall structural preservation of the samples allowed the identification of pulmonary cell types. hence, the observed alveolar damage is not associated with virus presence or structural impairment due to ongoing replication at later stages of the disease in fatal cases, which implies that the lung damage in these patients is at least propagated by alternative mechanisms, perhaps, an inappropriate immune or stress response.",
            "contribution_ids": [
                "R209256"
            ]
        },
        {
            "instance_id": "R211935xR193044",
            "comparison_id": "R211935",
            "paper_id": "R193044",
            "text": "From Ideas to Expressed Needs: an Empirical Study on the Evolution of Requirements during Elicitation requirements are elicited from the customer and other stakeholders through an iterative process of interviews, prototyping, and other interactive sessions. many communication phenomena may emerge in these early iterations, that lead initial ideas to be transformed, renegotiated, or reframed. understanding how this process takes place can help in solving possible communication issues as well as their consequences. in this work, we perform an exploratory study of descriptive nature to understand in which way requirements get transformed from initial ideas into documented needs. to this end, we select 30 subjects that act as requirements analysts, and we perform a set of elicitation sessions with a fictional customer. the customer is required to study a sample requirements document for a system beforehand and to answer the questions of the analysts about the system. after the elicitation sessions, the analysts produce user stories for the system. these are compared with the original ones by two researchers to assess to which extent and in which way the initial requirements evolved throughout the interactive sessions. our results show that between 30% and 38% of the produced user stories include content that can be fully traced to the initial ones, while the rest of the content is dedicated to new requirements. we also show what types of requirements are introduced through the elicitation process, and how they vary depending on the analyst. our work contributes to theory in requirements engineering, with empirically grounded, quantitative data, concerning the impact of elicitation activities with respect to initial ideas.",
            "contribution_ids": [
                "R193046"
            ]
        },
        {
            "instance_id": "R211935xR193089",
            "comparison_id": "R211935",
            "paper_id": "R193089",
            "text": "On the Role of User Feedback in Software Evolution: a Practitioners\u00e2\u0080\u0099 Perspective user feedback is indispensable in software evolution. previous work has proposed ways for automatically extracting requirements, bug reports and other valuable information from feedback. however, little is actually known about how user feedback\u2014 especially the one available through newer channels, such as social media\u2014is incorporated in development processes. to date, only a few case studies discuss the matter and the results are not always consistent. we carried out a mixed methods study to understand the current state of practice of harnessing user feedback in software development. qualitatively, we performed interviews with 18 software practitioners to get a deeper understanding of the role of user feedback in software evolution. quantitatively, we surveyed 101 software practitioners to cross-validate the interview findings and improve the generalizability of the results. we found that feedback is captured to (1) identify bugs, features and usability issues, (2) get a better understanding of the user, and (3) prioritize requirements. our results indicate that analyzing feedback is time-consuming and has a number of challenges. among them, feedback is typically analyzed manually and is spread over a wide range of channels and company departments. our findings stress the current importance for cross-department cooperation and call for the exploration of tools that can centralize user feedback.",
            "contribution_ids": [
                "R193091"
            ]
        },
        {
            "instance_id": "R211935xR193308",
            "comparison_id": "R211935",
            "paper_id": "R193308",
            "text": "The Role of Linguistic Relativity on the Identification of Sustainability Requirements: An Empirical Study linguistic-relativity-theory states that language and its structure influence people\u2019s world view and cognition. we investigate how this theory impacts the identification of requirements in practice. to this end, we conducted two controlled experiments with 101 participants. we randomly showed participants a set of requirements dimensions (i.e. a language structure) either with a focus on software quality or on sustainability and asked them to identify the requirements for a grocery shopping app according to these dimensions. participants of the control group were not given any dimensions. the results show that the use of requirements dimensions significantly increases the number of identified requirements in comparison to the control group. furthermore, participants who were given the sustainability dimensions identified more sustainability requirements. in follow up interviews with 16 practitioners, the interviewees reported benefits of the dimensions such as a holistic guidance but were also concerned about the customers acceptance. furthermore, they stated challenges of implementing sustainability dimensions in the daily business but also suggested solutions like establishing sustainability as a common standard. our study indicates that carefully structuring requirements engineering along sustainability dimensions can guide development teams towards considering and ensuring software sustainability.",
            "contribution_ids": [
                "R193309"
            ]
        },
        {
            "instance_id": "R211935xR193357",
            "comparison_id": "R211935",
            "paper_id": "R193357",
            "text": "What\u00e2\u0080\u0099s up with Requirements Engineering for Artificial Intelligence Systems? in traditional approaches to building software systems (that do not include an artificial intelligent (ai) or machine learning (ml) component), requirements engineering (re) activities are well-established and researched. however, building software systems with one or more ai components may depend heavily on data with limited or no insight into the system\u2019s workings. therefore, engineering such systems poses significant new challenges to re. our search showed that literature has focused on using ai to manage re activities, with limited research on re for ai (re4ai). our study\u2019s main objective was to investigate current approaches in writing requirements for ai/ml systems, identify available tools and techniques used to model requirements, and find existing challenges and limitations. we performed a systematic literature review (slr) of current re4ai methods and identified 27 primary studies. using these studies, we analysed the key tools and techniques used to specify and model requirements and found several challenges and limitations of existing re4ai practices. we further provide recommendations for future research, based on our analysis of the primary studies and mapping to industry guidelines in google pair). the slr findings highlighted that present re applications were not adaptive to manage most ai/ml systems and emphasised the need to provide new techniques and tools to support re4ai.",
            "contribution_ids": [
                "R193358"
            ]
        },
        {
            "instance_id": "R211935xR193828",
            "comparison_id": "R211935",
            "paper_id": "R193828",
            "text": "Mining reddit as a new source for software requirements mining app stores and social media has proven to be a good source for collecting user feedback to foster requirements engineering and software evolution. recent literature on mining software-related data from social platforms, such as twitter and facebook, shows that it complements app store mining. however, there are many other platforms where users discuss and provide feedback on software applications that are not thoroughly researched and analysed. one of such platforms is reddit. in this paper, we introduce reddit as a new potential data source and explore if and how requirements engineering and software evolution can benefit from obtaining user feedback from reddit. we also present an exploratory study in which we analysed the usage characteristics (i.e., frequency of posts, number of comments, and number of users for each subreddit) of reddit posts about software applications. furthermore, we examined the content of the posts and the results reveal that almost 54% of posts contain useful information. finally, we investigated the potential of automatic classification and applied machine learning algorithms to unstructured and noisy reddit data to perform automated classification into the categories of bug reports, feature related, and irrelevant. we found that the support vector machine algorithm with the f1-score of 84% can be effective in categorizing reddit posts. our results show that reddit posts provide useful feedback on software applications that can foster requirements engineering and software evolution.",
            "contribution_ids": [
                "R193829"
            ]
        },
        {
            "instance_id": "R211935xR193849",
            "comparison_id": "R211935",
            "paper_id": "R193849",
            "text": "TEM: a transparency engineering methodology enabling users\u00e2\u0080\u0099 trust judgement transparency is key to enhancing users\u2019 trust by enabling their judgment on the outcomes and consequences of a system\u2019s operations. this paper presents the transparency engineering methodology (tem) to generate transparency requirements that enable users\u2019 trust judgement. the idea is to identify where transparency is lacking and to address this through patterns augmenting the specification of data, use case, and process requirements. due to the complexity of software, it is impossible (and undesirable) to achieve full transparency throughout the system. however, transparency can be improved for selected system aspects. this is demonstrated using the results from an industrial case study with a medical technology company where, with the help of tem, existing functional requirements were refined, and transparency requirements generated systematically.",
            "contribution_ids": [
                "R193850"
            ]
        },
        {
            "instance_id": "R211935xR193866",
            "comparison_id": "R211935",
            "paper_id": "R193866",
            "text": "The Rise and Fall of COVID-19 Contact-Tracing Apps: when NFRs Collide with Pandemic to complement the manual contact-tracing methods, a flood of coronavirus-related apps was launched in the first half of 2020. despite the incredible promises made by the governments, contact-tracing apps did not live up to expectations. we provide a contextual perspective of the government commissioned contact-tracing apps from four countries to understand the non-functional requirements (nfrs) and socio-technical factors that hindered the success of these apps. we collected the user reviews from the app stores for ios and android versions and identified top news articles related to each app. our analysis revealed that the dominant factors behind the negligible success of these apps are complex and entangled with the cultural and political dimensions rather than being just technical. the multilayer diversity of the target users also impacted the design and development of contact-tracing apps in an extremely challenging situation. this perspective paper brings into light important elements, such as politics and socio-cultural aspects that should be studied in the design of contact-tracing apps, and public apps in general.",
            "contribution_ids": [
                "R193868"
            ]
        },
        {
            "instance_id": "R212902xR209382",
            "comparison_id": "R212902",
            "paper_id": "R209382",
            "text": "ThinkHome: A smart home as digital ecosystem smart homes have become increasingly popular in the past few years. similarly, new buildings are nowadays planned and built following sustainability guidelines. energy efficient residential homes have gained importance for two reasons. they contribute to the protection of our environment and they simultaneously reduce operational costs over the whole building lifecycle. however, the full potential of smart homes still lies fallow due to the high complexity of the underlying automation systems as well as the physical processes that are to be controlled. this is the motivation to review smart homes under a digital ecosystem perspective. with respect to this viewpoint, this paper proposes a system concept that applies artificial intelligence in smart homes. main goals are to minimize energy consumption while at the same time guaranteeing user comfort. therefore, intelligent control strategies are developed that take a multitude of parameters into consideration and operate automatically. for this purpose, an agent part populated by a society of autonomous agents that implement artificial intelligence is developed. it is supported by an ontology based knowledge representation that contains all relevant data in a structured way.",
            "contribution_ids": [
                "R209384"
            ]
        },
        {
            "instance_id": "R212902xR209385",
            "comparison_id": "R212902",
            "paper_id": "R209385",
            "text": "A Unified Semantic Ontology for Energy Management Applications current research evidences an increase of use of semantic web technologies within city energy management solutions. different ontologies have been developed in order to improve energy data interoperability. however, these ontologies represent different energy domains, with different level of detail and using different terminology. this heterogeneity leads to an interoperability problem that hinders the full adoption of these ontologies in real scenarios. this paper presents the oema (ontology for energy management applications) ontology network. this ontology is an attempt to unify existing heterogeneous ontologies that represent energy performance and contextual data. the paper describes the oema ontology network development process, which has included ontology reuse, ontology engineering and ontology integration activities. the paper also describes the main oema ontology network modules.",
            "contribution_ids": [
                "R209387"
            ]
        },
        {
            "instance_id": "R25093xR25066",
            "comparison_id": "R25093",
            "paper_id": "R25066",
            "text": "Predicting Personality from Twitter \"social media is a place where users present themselves to the world, revealing personal details and insights into their lives. we are beginning to understand how some of this information can be utilized to improve the users' experiences with interfaces and with one another. in this paper, we are interested in the personality of users. personality has been shown to be relevant to many types of interactions, it has been shown to be useful in predicting job satisfaction, professional and romantic relationship success, and even preference for different interfaces. until now, to accurately gauge users' personalities, they needed to take a personality test. this made it impractical to use personality analysis in many social media domains. in this paper, we present a method by which a user's personality can be accurately predicted through the publicly available information on their twitter profile. we will describe the type of data collected, our methods of analysis, and the machine learning techniques that allow us to successfully predict personality. we then discuss the implications this has for social media design, interface design, and broader domains.\"",
            "contribution_ids": [
                "R25067",
                "R25072"
            ]
        },
        {
            "instance_id": "R25093xR25077",
            "comparison_id": "R25093",
            "paper_id": "R25077",
            "text": "Personality and patterns of Facebook usage \"we show how users' activity on facebook relates to their personality, as measured by the standard five factor model. our dataset consists of the personality profiles and facebook profile data of 180,000 users. we examine correlations between users' personality and the properties of their facebook profiles such as the size and density of their friendship network, number uploaded photos, number of events attended, number of group memberships, and number of times user has been tagged in photos. our results show significant relationships between personality traits and various features of facebook profiles. we then show how multivariate regression allows prediction of the personality traits of an individual user given their facebook profile. the best accuracy of such predictions is achieved for extraversion and neuroticism, the lowest accuracy is obtained for agreeableness, with openness and conscientiousness lying in the middle.\"",
            "contribution_ids": [
                "R25078"
            ]
        },
        {
            "instance_id": "R25093xR25083",
            "comparison_id": "R25093",
            "paper_id": "R25083",
            "text": "Evaluating Content-Independent Features for Personality Recognition this paper describes our submission for the wcpr14 shared task on computational personality recognition. we have investigated whether the features proposed by soler and wanner (2014) for gender prediction might also be useful in personality recognition. we have compared these features with simple approaches using token unigrams, character trigrams and liwc features. although the newly investigated features seem to work quite well on certain personality traits, they do not outperform the simple approaches.",
            "contribution_ids": [
                "R25084"
            ]
        },
        {
            "instance_id": "R25093xR25089",
            "comparison_id": "R25093",
            "paper_id": "R25089",
            "text": "Predicting Personality Traits using Multimodal Information measuring personality traits has a long story in psychology where analysis has been done by asking sets of questions. these question sets (inventories) have been designed by investigating lexical terms that we use in our daily communications or by analyzing biological phenomena. whether consciously or unconsciously we express our thoughts and behaviors when communicating with others, either verbally, non-verbally or using visual expressions. recently, research in behavioral signal processing has focused on automatically measuring personality traits using different behavioral cues that appear in our daily communication. in this study, we present an approach to automatically recognize personality traits using a video-blog (vlog) corpus, consisting of transcription and extracted audio-visual features. we analyzed linguistic, psycholinguistic and emotional features in addition to the audio-visual features provided with the dataset. we also studied whether we can better predict a trait by identifying other traits. using our best models we obtained very promising results compared to the official baseline.",
            "contribution_ids": [
                "R25090"
            ]
        },
        {
            "instance_id": "R25115xR25103",
            "comparison_id": "R25115",
            "paper_id": "R25103",
            "text": "Sustained Participatory Design: Extending the Iterative Approach with its 10th biennial anniversary conference in 2008, participatory design (pd) was leaving its teens and must now be considered ready to join the adult world and to think big: pd should engage in large-scale information-systems development and opt for a sustained pd approach applied throughout design and organizational implementation. to pursue this aim we extend the iterative pd approach by (1) emphasizing pd experiments that transcend traditional prototyping and evaluate systems during real work; (2) incorporating improvisational change management including anticipated, emergent, and opportunity-based change; and (3) extending initial design and development into a sustained, stepwise implementation that constitutes an overall technology-driven organizational change. sustained pd is exemplified through a pd experiment in the danish healthcare sector. we reflect on our experiences from this experiment and discuss four challenges pd must address in dealing with large-scale systems development.",
            "contribution_ids": [
                "R25104"
            ]
        },
        {
            "instance_id": "R25115xR25107",
            "comparison_id": "R25115",
            "paper_id": "R25107",
            "text": "Participants' view on personal gains and PD process \"while it is commonly claimed that users of participatory design projects reap benefits from their participation, little research exists that shows if this truly occurs in the real world. in this paper, we introduce the method and results of assessing the participants' perception of their personal benefits and the degree of participation in a large project in the healthcare field. our research shows that a well-executed participatory design project can produce most of the benefits hypothesized in the literature but also highlights the challenges of assessing individual benefits and the pd process.\"",
            "contribution_ids": [
                "R25108"
            ]
        },
        {
            "instance_id": "R25160xR25122",
            "comparison_id": "R25160",
            "paper_id": "R25122",
            "text": "Assessment of safety levels and an innovative design for the Lane Change Assistant in this paper we propose a novel design for the lane change assistant (lca). for drivers on the highway, lca advises them on whether it is safe to change lanes under the current traffic conditions. we focus on how the lca can provide a reliable advice in practice by considering the issues of changing circumstances and measurement uncertainties. under some generic assumptions we develop a micro-simulation model for the lane change safety assessment. the model is in line with the car following models and lane change algorithms available in literature. it retains a probabilistic character to accurately represent realistic situations. based on a sensitivity study we are able to develop a robust design for the lca. in this design the system accounts for the practical uncertainties by including appropriate extra safety distances. the driver interface consists of a spectrum of five led lights, each operating on a distinct color (varying from red to green) and guaranteeing a certain safety degree. our results allow car developers to easily acquire reliable designs for the lca.",
            "contribution_ids": [
                "R25123"
            ]
        },
        {
            "instance_id": "R25160xR25124",
            "comparison_id": "R25160",
            "paper_id": "R25124",
            "text": "\"Should I stay or should I go?\" \"ambient lighting systems have been introduced by several manufacturers to increase the driver's comfort. also, some works proposed warning systems based on light displays. expanding on those works, we are searching for designs of lumicons (i.e. light patterns) that can not only warn drivers in critical situations but also keep them informed in a non-distracting way. we present first ideas for lumicons for a given scenario coming from a participatory design process.\"",
            "contribution_ids": [
                "R25125"
            ]
        },
        {
            "instance_id": "R25160xR25129",
            "comparison_id": "R25160",
            "paper_id": "R25129",
            "text": "A New Driving Assistant for Automobiles this paper introduces an inexpensive car security system which addresses the needs for broader area coverage around the vehicle and stronger indication signals to drivers. the new driving assistant features simple ultrasonic-based sensors, implemented at the two front corners and the two blind spots of the vehicle. in order to report the close-by objects to the driver, the system employs a multitude of feedback devices, including tactile vibrators attached to the steering wheel, audible signals, and an led display mounted on the dash board. the sensor system and the feedback devices are controlled in real-time by microcontrollers over a wireless communication network the final prototype system was installed and tested on a ride-on toy car.",
            "contribution_ids": [
                "R25130"
            ]
        },
        {
            "instance_id": "R25160xR25131",
            "comparison_id": "R25160",
            "paper_id": "R25131",
            "text": "Evaluation of Six Night Vision Enhancement Systems: Qualitative and Quantitative Support for Intelligent Image Processing objective: an evaluation study was conducted to answer the question of which system properties of night vision enhancement systems (nvess) provide a benefit for drivers without increasing their workload. background: different infrared sensor, image processing, and display technologies can be integrated into an nves to support nighttime driving. because each of these components has its specific strengths and weaknesses, careful testing is required to determine their best combination. method: six prototypical systems were assessed in two steps. first, a heuristic evaluation with experts from ergonomics, perception, and traffic psychology was conducted. it produced a broad overview of possible effects of system properties on driving. based on these results, an experimental field study with 15 experienced drivers was performed. criteria used to evaluate the development potential of the six prototypes were the usability dimensions of effectiveness, efficiency, and user satisfaction (international organization for standardization, 1998). results: results showed that the intelligibility of information, the easiness with which obstacles could be located in the environment, and the position of the display presenting the output of the system were of crucial importance for the usability of the nves and its acceptance. conclusion: all relevant requirements are met best by nvess that are positioned at an unobtrusive location and are equipped with functions for the automatic identification of objects and for event-based warnings. application: these design recommendations and the presented approach to evaluate the systems can be directly incorporated into the development process of future nvess.",
            "contribution_ids": [
                "R25132"
            ]
        },
        {
            "instance_id": "R25160xR25133",
            "comparison_id": "R25160",
            "paper_id": "R25133",
            "text": "Complementary Audio-Visual Collision Warnings the growing number of driver assistance systems increases the demand for warnings that are intuitively comprehensible. particularly in hazardous situations, such as a threatening collision, a driver must understand the warning immediately. for this reason, collision warnings should convey as much information as needed to interpret the situation properly and to prepare preventive actions. the present study investigated whether informing about the object and the location of an imminent crash by a multimodal warning (visual and auditory) leads to shorter reaction times and fewer collisions compared to warning signals which only inform about the object of the crash (auditory icons) or give no additional information (simple tone). results reveal that multimodal warnings have the potential to produce a significant advantage over unimodal signals as long as their components complement each other in a way that realistically fits the situation at hand.",
            "contribution_ids": [
                "R25134"
            ]
        },
        {
            "instance_id": "R25160xR25137",
            "comparison_id": "R25160",
            "paper_id": "R25137",
            "text": "Driver assistance via optical information with spatial reference \"the occurrence of accidents caused by deficiencies in risk recognition by the driver can be prevented by presenting relevant information in real time to the driver. in this paper it is proposed to draw the driver's attention towards relevant traffic objects, which might be a safety hazard, by a led strip which is affixed 360\u00b0 around the interior of the car's cabin. with this approach a higher number of use cases can be covered than with existing hmis. the effectiveness of this system is evaluated in a driving simulator study with 13 subjects in four critical traffic situations. the gaze attention times are ascertained with eye tracking technology; mental effort and acceptance are determined by questionnaires and the comprehensibility by semi-structured interviews. there are indications of shortened gaze attention times using the led strip compared to the baseline without driver support. the subjects understand the information submitted mostly intuitively. the acceptance ratings overall are in a positive range, but differ between scenarios.\"",
            "contribution_ids": [
                "R25138"
            ]
        },
        {
            "instance_id": "R25201xR25169",
            "comparison_id": "R25201",
            "paper_id": "R25169",
            "text": "SVM-DSmT Combination for Off-Line Signature Verification we propose in this work a signature verification system based on decision combination of off-line signatures for managing conflict provided by the svm classifiers. the system is basically divided into three modules: i) radon transform-svm, ii) ridgelet transform-svm and iii) pcr5 combination rule based on the generalized belief functions of dezert-smarandache theory. the proposed framework allows combining the normalized svm outputs and uses an estimation technique based on the dissonant model of appriou to compute the belief assignments. decision making is performed through likelihood ratio. experiments are conducted on the well known cedar database using false rejection and false acceptance criteria. the obtained results show that the proposed combination framework improves the verification accuracy compared to individual svm classifiers.",
            "contribution_ids": [
                "R25170"
            ]
        },
        {
            "instance_id": "R25201xR25175",
            "comparison_id": "R25201",
            "paper_id": "R25175",
            "text": "Offline Signature Verification Using Classifier Combination of HOG and LBP Features \"we present an offline signature verification system based on a signature's local histogram features. the signature is divided into zones using both the cartesian and polar coordinate systems and two different histogram features are calculated for each zone: histogram of oriented gradients (hog) and histogram of local binary patterns (lbp).\"",
            "contribution_ids": [
                "R25176"
            ]
        },
        {
            "instance_id": "R25201xR25178",
            "comparison_id": "R25201",
            "paper_id": "R25178",
            "text": "Tsang Ing Re, Off-line signature verification: an approach based on combining distances and one-class classifiers this paper presents an off-line signature verification system composed of a combination of several different classifiers. identity authentication is a very important characteristics specially in systems that requires a high degree of security such as in bank transactions. in our experiments, one-class classifier was used to create a signature verification system, consequently only genuine signatures were necessary for the training phase. we proposed five distances measurement as features for the classification system. the distances extracted from the signature database were: furthest, nearest, template, central and ncentral. also, a normalization procedure was applied to turn the distance scale invariant. these distances were combined using four operation: product, mean, maximum and minimum. the calculated distances were used as a feature vector to represent the signatures. finally, the distances measurement and their combinations were used as input vector for different classifiers. the proposed signature verification method obtained very good rates.",
            "contribution_ids": [
                "R25179"
            ]
        },
        {
            "instance_id": "R25223xR25207",
            "comparison_id": "R25223",
            "paper_id": "R25207",
            "text": "Replica Placement Algorithms in Content Distribution Networks the replica placement problems (rpps) in the content distribution networks have been widely studied. in this paper, we propose an optimization model for the rpps and design efficient algorithms to minimize the total cost of the network. the algorithms include three parts: replication algorithm preprocess, constraint p-median model and algorithm of solving constraint p-median models. in the simulation, we compare our algorithms to other heuristic methods numerically. the results show that our algorithms perform better with less cost.",
            "contribution_ids": [
                "R25208"
            ]
        },
        {
            "instance_id": "R25223xR25211",
            "comparison_id": "R25223",
            "paper_id": "R25211",
            "text": "Distributed Selfish Caching although cooperation generally increases the amount of resources available to a community of nodes, thus improving individual and collective performance, it also allows for the appearance of potential mistreatment problems through the exposition of one node\\'s resources to others. we study such concerns by considering a group of independent, rational, self-aware nodes that cooperate using online caching algorithms, where the exposed resource is the storage at each node. motivated by content networking applications - including web caching, content delivery networks (cdns), and peer-to-peer (p2p) - this paper extends our previous work on the offline version of the problem, which was conducted under a game-theoretic framework and limited to object replication. we identify and investigate two causes of mistreatment: 1) cache state interactions (due to the cooperative servicing of requests) and 2) the adoption of a common scheme for cache management policies. using analytic models, numerical solutions of these models, and simulation experiments, we show that online cooperation schemes using caching are fairly robust to mistreatment caused by state interactions. to appear in a substantial manner, the interaction through the exchange of miss streams has to be very intense, making it feasible for the mistreated nodes to detect and react to exploitation. this robustness ceases to exist when nodes fetch and store objects in response to remote requests, that is, when they operate as level-2 caches (or proxies) for other nodes. regarding mistreatment due to a common scheme, we show that this can easily take place when the \"outlier\" characteristics of some of the nodes get overlooked. this finding underscores the importance of allowing cooperative caching nodes the flexibility of choosing from a diverse set of schemes to fit the peculiarities of individual nodes. to that end, we outline an emulation-based framework for the development of mistreatment-resilient distributed selfish caching schemes.",
            "contribution_ids": [
                "R25212"
            ]
        },
        {
            "instance_id": "R25223xR25205",
            "comparison_id": "R25223",
            "paper_id": "R25205",
            "text": "A QOS-Aware Intelligent Replica Management Architecture for Content Distribution in Peer-to-Peer Overlay Networks the large scale content distribution systems were improved broadly using the replication techniques. the demanded contents can be brought closer to the clients by multiplying the source of information geographically, which in turn reduce both the access latency and the network traffic. the system scalability can be improved by distributing the load across multiple servers which is proposed by replication. if a copy of the requested object (e.g., a web page or an image) is located in its closer proximity then the clients would feel low access latency. depending on the position of the replicas, the effectiveness of replication tends to a large extent. a qos based overlay network architecture involving an intelligent replica placement algorithm is proposed in this paper. its main goal is to improve the network utilization and fault tolerance of the p2p system. in addition to the replica placement, it also has a caching technique, to reduce the search latency. we are able to show that our proposed architecture attains less latency and better throughput with reduced bandwidth usage, through the simulation results. keywords-clusters, content, overlay, qos, replica, routing",
            "contribution_ids": [
                "R25206"
            ]
        },
        {
            "instance_id": "R25255xR25235",
            "comparison_id": "R25255",
            "paper_id": "R25235",
            "text": "Automatic Lexicon Construction for Arabic Sentiment Analysis sentiment analysis (sa) is the process of determining the sentiment of a text written in a natural language to be positive, negative or neutral. it is one of the most interesting subfields of natural language processing (nlp) and web mining due to its diverse applications and the challenges associated with applying it on the massive amounts of textual data available online (especially, on social networks). most of the current works on sa focus on the english language and follow one of two main approaches, (corpus-based and lexicon-based) or a hybrid of them. this work focuses on a less studied aspect of sa, which is lexicon-based sa for the arabic language. in addition to experimenting and comparing three different lexicon construction techniques, an arabic sa tool is designed and implemented to effectively take advantage of the constructed lexicons. the proposed sa tool possesses many novel features such as the way negation and intensification are handled. the experimental results show encouraging outcomes with 74.6% accuracy in addition to revealing new insights and guidelines that could direct the future research efforts.",
            "contribution_ids": [
                "R25236"
            ]
        },
        {
            "instance_id": "R25255xR25253",
            "comparison_id": "R25255",
            "paper_id": "R25253",
            "text": "AraSenTi: Large-Scale Twitter-Specific Arabic Sentiment Lexicons sentiment analysis (sa) is an active research area nowadays due to the tremendous interest in aggregating and evaluating opinions being disseminated by users on the web. sa of english has been thoroughly researched; however research on sa of arabic has just flourished. twitter is considered a powerful tool for disseminating information and a rich resource for opinionated text containing views on many different topics. in this paper we attempt to bridge a gap in arabic sa of twitter which is the lack of sentiment lexicons that are tailored for the informal language of twitter. we generate two lexicons extracted from a large dataset of tweets using two approaches and evaluate their use in a simple lexicon based method. the evaluation is performed on internal and external datasets. the performance of these automatically generated lexicons was very promising, albeit the simple method used for classification. the best f-score obtained was 89.58% on the internal dataset and 63.1-64.7% on the exter-",
            "contribution_ids": [
                "R25254"
            ]
        },
        {
            "instance_id": "R25255xR25241",
            "comparison_id": "R25255",
            "paper_id": "R25241",
            "text": "SANA: A large scale multi-genre, multi-dialect lexicon for Arabic subjectivity and sentiment analysis the computational treatment of subjectivity and sentiment in natural language is usually significantly improved by applying features exploiting lexical resources where entries are tagged with semantic orientation (e.g., positive, negative values). in spite of the fair amount of work on arabic sentiment analysis over the past few years (e.g., (abbasi et al., 2008; abdul-mageed et al., 2014; abdul-mageed et al., 2012; abdul-mageed and diab, 2012a; abdul-mageed and diab, 2012b; abdul-mageed et al., 2011a; abdul-mageed and diab, 2011)), the language remains under-resourced as to these polarity repositories compared to the english language. in this paper, we report efforts to build and present sana, a large-scale, multi-genre, multi-dialect multi-lingual lexicon for the subjectivity and sentiment analysis of the arabic language and dialects.",
            "contribution_ids": [
                "R25242"
            ]
        },
        {
            "instance_id": "R25358xR25280",
            "comparison_id": "R25358",
            "paper_id": "R25280",
            "text": "Discovering semantic Web services via advanced graph-based matching one of the main advantages of web services is that they can be composed into more complex processes in order to achieve a given business goal. however, such potentiality cannot be fully exploited until suitable methods and techniques allowing us to enable automatic discovery of composed processes are provided. indeed, nowadays service discovery still focuses on matching atomic services by typically checking the similarity of functional parameters, such as inputs and outputs. however, a more profitable process discovering can be reached if both internal structure and component services are taken into account. based on this main intuition, in this paper we describe a method for discovering composite owl-s processes that founds on the following main contributions: (i) proposing a graph-based representation of composite owl-s processes; and (ii) introducing an algorithm that matches over such (graph-based) representations and computes their degree of matching via combining the similarity of the atomic services they comprise and the similarity of the control flow among them. finally, as another contribution of our research, we conducted a comprehensive experimental campaign where we tested our proposed algorithm by deriving insightful trade-offs of benefits and limitations of the overall framework for discovering semantic web services.",
            "contribution_ids": [
                "R25281"
            ]
        },
        {
            "instance_id": "R25358xR25285",
            "comparison_id": "R25358",
            "paper_id": "R25285",
            "text": "YASA-M: A Semantic Web Service Matchmaker in this paper, we present new algorithms for matching web services described in yasa4wsdl (yasa for short). we have already defined yasa, a semantic description of services that overcomes some issues in wsdl or sawsdl. in this paper, we continue on our contribution and show how yasa web services are matched based on the specificities of yasa descriptions. our matching algorithm consists of three variants based on three different semantic matching degree aggregations. this algorithm was implemented in yasa-m, a new web service matchmaker. yasa-m is evaluated and compared to well known approaches for service matching. experiments show that yasa-m provides better results, in terms of precision, response time, and scalability, than a well known matchmaker.",
            "contribution_ids": [
                "R25286"
            ]
        },
        {
            "instance_id": "R25358xR25288",
            "comparison_id": "R25358",
            "paper_id": "R25288",
            "text": "A QoS Broker Based Architecture for Dynamic Web Service Selection \"the increasing number of web services over the web makes the requester to use tools to search for suitable web services available throughout the globe. uddi is the first step towards meeting these demands. however the requester's demand may include not only functional aspects of web services but also nonfunctional aspects like quality of service (qos). there is a need to select the most suitable (qualitatively optimal) web service based on the requester's qos requirements and preferences. in this paper we explore the different types of requester's qos requirements (demands) with illustrations. we propose the qos broker based architecture for dynamic web service selection which facilitates the requester to specify his/her qos requirements along with functional requirements. the paper presents the web service selection mechanism which selects the best (most suitable) web service based on the requester's functional and quality requirements.\"",
            "contribution_ids": [
                "R25289"
            ]
        },
        {
            "instance_id": "R25358xR25298",
            "comparison_id": "R25358",
            "paper_id": "R25298",
            "text": "Research on Services Matching and Ranking Based on Fuzzy QoS Ontology services discovery based on the non-functional qos service features has received increasing attention by service-oriented computing research community. in order to implement qos description provided the express of the uncertain knowledge, in this paper, a fuzzy qos ontology is proposed firstly. then, services match based on fuzzy qos description can be transformed to reasoning in fuzzy description logic, and the rationality of this method be illustrated through an example. at last, a novel rank algorithm for the match results is proposed.",
            "contribution_ids": [
                "R25299"
            ]
        },
        {
            "instance_id": "R25358xR25311",
            "comparison_id": "R25358",
            "paper_id": "R25311",
            "text": "Web Service Matching by Ontology Instance Categorization identifying similar web services is becoming increasingly important to ensure the success of dynamically integrated web-service-based applications. we propose a categorization-based scheme to match equivalent web services that can operate on heterogeneous domain ontologies. given the upper ontology for services and domain ontologies, our service matching scheme determines whether a given web service is a possible replacement using a categorization utility called onexcat. onexcat categorizes ontology instances extracted from the service descriptions by a probabilistic categorization measurement that incorporates the concept relationships in the upper ontology for services. in addition to tackling the issue of heterogeneity of domain ontology in service descriptions using categorization, our matching scheme also adapts itself by enhancing the known ontologies with newly discovered ontology instances. experiments on service matching using our matching scheme based on the onexcat utility have been performed with promising results, a correct matching rate of over 85%.",
            "contribution_ids": [
                "R25312"
            ]
        },
        {
            "instance_id": "R25358xR25323",
            "comparison_id": "R25358",
            "paper_id": "R25323",
            "text": "Semantic Web Service Selection Based on Business Offering semantic web service discovery finds a match between service requirement and service advertisements based on the semantic description. the discovery mechanism does not consider quality and business offers of advertised web services. in this paper, we propose ontology based semantic web service architecture for selection which recommends the best match for the requester. we design semantic broker which allows providers to advertise their services by creating owl-s service profile consisting of functional, quality and business offers. the broker computes and records information for matchmaking during service publishing to improve the performance. the broker reads requirements from the requester and finds the best (profitable) web service by matching functionality, capability, quality and business offers.",
            "contribution_ids": [
                "R25324"
            ]
        },
        {
            "instance_id": "R25358xR25334",
            "comparison_id": "R25358",
            "paper_id": "R25334",
            "text": "URBE: Web Service Retrieval Based on Similarity Evaluation in this work, we present uddi registry by example (urbe), a novel approach for web service retrieval based on the evaluation of similarity between web service interfaces. our approach assumes that the web service interfaces are defined with web service description language (wsdl) and the algorithm combines the analysis of their structures and the analysis of the terms used inside them. the higher the similarity, the less are the differences among their interfaces. as a consequence, urbe is useful when we need to find a web service suitable to replace an existing one that fails. especially in autonomic systems, this situation is very common since we need to ensure the self-management, the self-configuration, the self-optimization, the self-healing, and the self-protection of the application that is based on the failed web service. a semantic-oriented variant of the approach is also proposed, where we take advantage of annotations semantically enriching wsdl specifications. semantic annotation for wsdl (sawsdl) is adopted as a language to annotate a wsdl description. the urbe approach has been implemented in a prototype that extends a universal description, discovery and integration (uddi) compliant web service registry.",
            "contribution_ids": [
                "R25335"
            ]
        },
        {
            "instance_id": "R25400xR25367",
            "comparison_id": "R25400",
            "paper_id": "R25367",
            "text": "Evolving object oriented design to improve code traceability traceability is a key issue to ensure consistency among software artifacts of subsequent phases of the development cycle. however, few works have so far addressed the theme of tracing object oriented design into its implementation and evolving it. the paper presents an approach to checking the compliance of oo design with respect to source code and support its evolution. the process works on design artifacts expressed in the omt notation and accepts c++ source code. it recovers an \"as is\" design from the code, compares recovered design with the actual design and helps the user to deal with inconsistencies. the recovery process exploits the edit distance computation and the maximum match algorithm to determine traceability links between design and code. the output is a similarity measure associated to each matched class, plus a set of unmatched classes. a graphic display of the design with different colors associated to different levels of match is provided as a support to update the design and improve its traceability to the code.",
            "contribution_ids": [
                "R25368"
            ]
        },
        {
            "instance_id": "R25400xR25374",
            "comparison_id": "R25400",
            "paper_id": "R25374",
            "text": "DSL-based support for semi-automated architectural component model abstraction throughout the software lifecycle in this paper we present an approach for supporting the semi-automated abstraction of architectural models throughout the software lifecycle. it addresses the problem that the design and the implementation of a software system often drift apart as software systems evolve, leading to architectural knowledge evaporation. our approach provides concepts and tool support for the semi-automatic abstraction of architectural knowledge from implemented systems and keeping the abstracted architectural knowledge up-to-date. in particular, we propose architecture abstraction concepts that are supported through a domain-specific language (dsl). our main focus is on providing architectural abstraction specifications in the dsl that only need to be changed, if the architecture changes, but can tolerate non-architectural changes in the underlying source code. the dsl and its tools support abstracting the source code into uml component models for describing the architecture. once the software architect has defined an architectural abstraction in the dsl, we can automatically generate uml component models from the source code and check whether the architectural design constraints are fulfilled by the models. our approach supports full traceability between source code elements and architectural abstractions, and allows software architects to compare different versions of the generated uml component model with each other. we evaluate our research results by studying the evolution of architectural abstractions in different consecutive versions and the execution times for five existing open source systems.",
            "contribution_ids": [
                "R25375"
            ]
        },
        {
            "instance_id": "R25400xR25384",
            "comparison_id": "R25400",
            "paper_id": "R25384",
            "text": "A tactic-centric approach for automating traceability of quality concerns the software architectures of business, mission, or safety critical systems must be carefully designed to balance an exacting set of quality concerns describing characteristics such as security, reliability, and performance. unfortunately, software architectures tend to degrade over time as maintainers modify the system without understanding the underlying architectural decisions. although this problem can be mitigated by manually tracing architectural decisions into the code, the cost and effort required to do this can be prohibitively expensive. in this paper we therefore present a novel approach for automating the construction of traceability links for architectural tactics. our approach utilizes machine learning methods and lightweight structural analysis to detect tactic-related classes. the detected tactic-related classes are then mapped to a tactic traceability information model. we train our trace algorithm using code extracted from fifteen performance-centric and safety-critical open source software systems and then evaluate it against the apache hadoop framework. our results show that automatically generated traceability links can support software maintenance activities while helping to preserve architectural qualities.",
            "contribution_ids": [
                "R25385"
            ]
        },
        {
            "instance_id": "R25447xR25426",
            "comparison_id": "R25447",
            "paper_id": "R25426",
            "text": "An Enhance Approach For Web Services Discovery with QoS \"the quality of service for web services here mainly refers to the quality aspect of a web service. the qos for web services is becoming increasingly important to service providers and service requesters due to increasing use of web services. web services providing similar functionalities, more emphasis is being placed on how to find the service that best fits the consumer's requirements. in order to find services that best meet their qos requirements, the service consumers and/or discovery agents need to know both the qos information for the services and the reliability of this information. in this paper first of all we implement reputation-enhanced web services discovery protocol. and after implementation we enhance the protocol over memory used, time to discovery and response time of given web service.\"",
            "contribution_ids": [
                "R25427"
            ]
        },
        {
            "instance_id": "R25447xR25423",
            "comparison_id": "R25447",
            "paper_id": "R25423",
            "text": "Reliability Modeling for SOA Systems service-oriented architecture (soa) is a popular paradigm for development of distributed systems by composing the functionality provided by the services exposed on the network. in effect, the services can use functionalities of other services to accomplish their own goals. although such an architecture provides an elegant solution to simple construction of loosely coupled distributed systems, it also introduces additional concerns. one of the primary concerns in designing a soa system is the overall system reliability. since the building blocks are services provided by various third parties, it is often not possible to apply the well established fault removal techniques during the development phases. therefore, in order to reach desirable system reliability for soa systems, the focus shifts towards fault prediction and fault tolerance techniques. in this paper an overview of existing reliability modeling techniques for soa-based systems is given. furthermore, we present a model for reliability estimation of a service composition using directed acyclic graphs. the model is applied to the service composition based on the orchestration model. a case study for the proposed model is presented by analyzing a simple web service composition scenario.",
            "contribution_ids": [
                "R25424"
            ]
        },
        {
            "instance_id": "R25447xR25442",
            "comparison_id": "R25447",
            "paper_id": "R25442",
            "text": "Synergies between SOA and Grid computing service oriented architecture (soa) is an architectural style for developing and integrating enterprise applications to enable an enterprise to deliver self-describing and platform independent business functionality. grid computing (gc) is a framework that allows pooling of physical resources to enable virtualisation of distributed computing, enterprise data and enterprise functionality. the two are synergetic in the sense that, whereas soa can provide a strong basis for gc, technical framework based on gc provides the optimum foundation for soa. this paper discusses the two paradigms and provides some useful information for the benefit of large enterprises that wish to embark on the development and implementation of soa based on grid computing.",
            "contribution_ids": [
                "R25443"
            ]
        },
        {
            "instance_id": "R25495xR25457",
            "comparison_id": "R25495",
            "paper_id": "R25457",
            "text": "Event-Triggered Model Predictive Control for Embedded Artificial Pancreas Systems objective: the development of artificial pancreas (ap) technology for deployment in low-energy, embedded devices is contingent upon selecting an efficient control algorithm for regulating glucose in people with type 1 diabetes mellitus. in this paper, we aim to lower the energy consumption of the ap by reducing controller updates, that is, the number of times the decision-making algorithm is invoked to compute an appropriate insulin dose. methods: physiological insights into glucose management are leveraged to design an event-triggered model predictive controller (mpc) that operates efficiently, without compromising patient safety. the proposed event-triggered mpc is deployed on a wearable platform. its robustness to latent hypoglycemia, model mismatch, and meal misinformation is tested, with and without meal announcement, on the full version of the us-fda accepted uva/padova metabolic simulator. results: the event-based controller remains on for 18\\xa0h of 41\\xa0h in closed loop with unannounced meals, while maintaining glucose in 70\u2013180\\xa0mg/dl for 25\\xa0h, compared to 27\\xa0h for a standard mpc controller. with meal announcement, the time in 70\u2013180\\xa0mg/dl is almost identical, with the controller operating a mere 25.88% of the time in comparison with a standard mpc. conclusion: a novel control architecture for ap systems enables safe glycemic regulation with reduced processor computations. significance: our proposed framework integrated seamlessly with a wide variety of popular mpc variants reported in ap research, customizes tradeoff between glycemic regulation and efficacy according to prior design specifications, and eliminates judicious prior selection of controller sampling times.",
            "contribution_ids": [
                "R25458"
            ]
        },
        {
            "instance_id": "R25495xR25473",
            "comparison_id": "R25495",
            "paper_id": "R25473",
            "text": "Toward a Run-to-Run Adaptive Artificial Pancreas: In Silico Results objective : contemporary and future outpatient long-term artificial pancreas (ap) studies need to cope with the well-known large intra- and interday glucose variability occurring in type 1 diabetic (t1d) subjects. here, we propose an adaptive model predictive control (mpc) strategy to account for it and test it in silico. methods : a run-to-run (r2r) approach adapts the subcutaneous basal insulin delivery during the night and the carbohydrate-to-insulin ratio (cr) during the day, based on some performance indices calculated from subcutaneous continuous glucose sensor data. in particular, r2r aims, first, to reduce the percentage of time in hypoglycemia and, secondarily, to improve the percentage of time in euglycemia and average glucose. in silico simulations are performed by using the university of virginia/padova t1d simulator enriched by incorporating three novel features: intra- and interday variability of insulin sensitivity, different distributions of cr at breakfast, lunch, and dinner, and dawn phenomenon. results : after about two months, using the r2r approach with a scenario characterized by a random $\\\\pm$ 30% variation of the nominal insulin sensitivity the time in range and the time in tight range are increased by 11.39% and 44.87%, respectively, and the time spent above 180 mg/dl is reduced by 48.74%. conclusions : an adaptive mpc algorithm based on r2r shows in silico great potential to capture intra- and interday glucose variability by improving both overnight and postprandial glucose control without increasing hypoglycemia. significance : making an ap adaptive is key for long-term real-life outpatient studies. these good in silico results are very encouraging and worth testing in vivo .",
            "contribution_ids": [
                "R25474"
            ]
        },
        {
            "instance_id": "R25495xR25479",
            "comparison_id": "R25495",
            "paper_id": "R25479",
            "text": "A Long-Term Model of the Glucose-Insulin Dynamics of Type 1 Diabetes a new glucose-insulin model is introduced which fits with the clinical data from in- and outpatients for two days. its stability property is consistent with the glycemia behavior for type 1 diabetes. this is in contrast to traditional glucose-insulin models. prior models fit with clinical data for a few hours only or display some nonnatural equilibria. the parameters of this new model are identifiable from standard clinical data as continuous glucose monitoring, insulin injection, and carbohydrate estimate. moreover, it is shown that the parameters from the model allow the computation of the standard tools used in functional insulin therapy as the basal rate of insulin and the insulin sensitivity factor. this is a major outcome as they are required in therapeutic education of type 1 diabetic patients.",
            "contribution_ids": [
                "R25480"
            ]
        },
        {
            "instance_id": "R25529xR25505",
            "comparison_id": "R25529",
            "paper_id": "R25505",
            "text": "Social finance and crowdfunding for social enterprises: a public\u00e2\u0080\u0093private case study providing legitimacy and leverage the authors work closely with academia and governmental organizations in the uk and abroad to develop new, innovative schemes for social impact investing. such schemes include considerations for public\u2013private collaborations, legislative actions, and especially in this case, for the leveraged use of public and philanthropic funds in crowdfunding (cf). the relatively new phenomenon of cf can not only provide necessary funds for the social enterprises, it may also lead to a higher legitimacy of these through early societal interaction and participation. this legitimacy can be understood as a strong positive signal for further investors. governmental tax-reliefs and guarantees from venture-philanthropic funds provide additional incentives for investment and endorse future scaling by leveraging additional debt-finance from specialized social banks. this case study identifies idiosyncratic hurdles to why an efficient social finance market has yet to be created and examines a schema as a case of how individual players\u2019 strengths and weaknesses can be balanced out by a concerted action. the paper discusses the necessary actions, benefits and implications for the involved actors from the public, private and third sector.",
            "contribution_ids": [
                "R25506"
            ]
        },
        {
            "instance_id": "R25529xR25525",
            "comparison_id": "R25529",
            "paper_id": "R25525",
            "text": "Effects of Social Interaction Dynamics on Platforms abstract despite the increasing relevance of online social interactions on platforms, there is still little research on the temporal interaction dynamics between electronic word-of-mouth (ewom, a form of opinion-based social interaction), popularity information (a form of action-based social interaction), and consumer decision making. drawing on a panel data set of more than 23,300 crowdfunding campaigns from indiegogo, we investigate the dynamic effects of these social interactions on consumers\u2019 funding decisions using the panel vector autoregressive methodology. our analysis shows that both ewom and popularity information are critical influencing mechanisms in crowdfunding. however, our overarching finding is that ewom surrounding crowdfunding campaigns on indiegogo or facebook has a significant yet substantially weaker predictive power than popularity information. we also find that whereas popularity information has a more immediate effect on consumers\u2019 funding behavior, its effectiveness decays rather quickly, while the impact of ewom recedes more slowly. this study contributes to the extant literature by (1) providing a more nuanced understanding of the dynamic effects of opinion-based and action-based social interactions, (2) unraveling both within-platform and cross-platform dynamics, and (3) showing that social interactions are perceived as quality indicators on crowdfunding platforms that help consumers reduce risks associated with their investment decisions. these results can help platform providers and complementors to stimulate contribution behavior and increase the prosperity of a platform.",
            "contribution_ids": [
                "R25526"
            ]
        },
        {
            "instance_id": "R25529xR25527",
            "comparison_id": "R25529",
            "paper_id": "R25527",
            "text": "What Goes around Comes Around? Rewards as Strategic Assets in Crowdfunding in crowdfunding, rewards can make or break success. yet reward design, choice, and planning still occur based on availability rather than strategy. to address this challenge, this article provides an empirically derived crowd-funding reward toolbox offering guidance in strategically selecting rewards. based on a large-scale analysis of successful and unsuccessful kickstarter projects, this article classifies rewards that are currently offered along eight dimensions. it identifies emerging patterns and derives five strategic core tools and two add-on tools. finally, it delivers exploratory insights into the relative effectiveness of different tools that can facilitate decision making and strategic planning for entrepreneurs and individuals who plan to launch a crowdfunding project and who seek ways to reward their supporters.",
            "contribution_ids": [
                "R25528"
            ]
        },
        {
            "instance_id": "R25583xR25531",
            "comparison_id": "R25583",
            "paper_id": "R25531",
            "text": "A DSL for rapid prototyping of cross-platform tower defense games because of the increasing expansion of the videogame industry, shorten videogame time to market for diverse platforms (e.g, mac, android, ios, blackberry) is a quest. this paper presents how a domain specific language (dsl) in conjunction with model-driven engineering (mde) techniques can automate the development of games, in particular, tower defense games such as plants vs. zombies. the dsl allows the expression of structural and behavioral aspects of tower defense games. the mde techniques allow us to generate code from the game expressed in the dsl. the generated code is written in an existing open source language that leverages the portability of the games. we present our approach using an example so-called space attack. the example shows the significant benefits offered by our proposal in terms of productivity and portability.",
            "contribution_ids": [
                "R25532"
            ]
        },
        {
            "instance_id": "R25583xR25533",
            "comparison_id": "R25583",
            "paper_id": "R25533",
            "text": "A Flexible Model-Driven Game Development Approach game developers are facing an increasing demand for new games every year. game development tools can be of great help, but require highly specialized professionals. also, just as any software development effort, game development has some challenges. model-driven game development (mdgd) is suggested as a means to solve some of these challenges, but with a loss in flexibility. we propose a mdgd approach that combines multiple domain-specific languages (dsls) with design patterns to provide flexibility and allow generated code to be integrated with manual code. after experimentation, we observed that, with the approach, less experienced developers can create games faster and more easily, and the product of code generation can be customized with manually written code, providing flexibility. however, with mdgd, developers become less familiar with the code, making manual codification more difficult.",
            "contribution_ids": [
                "R25534"
            ]
        },
        {
            "instance_id": "R25583xR25537",
            "comparison_id": "R25583",
            "paper_id": "R25537",
            "text": "Building a Game Engine: A Tale of Modern Model-Driven Engineering game engines enable developers to reuse assets from previously developed games, thus easing the software-engineering challenges around the video-game development experience and making the implementation of games less expensive, less technologically brittle, and more efficient. however, the construction of game engines is challenging in itself, it involves the specification of well defined architectures and typical game play behaviors, flexible enough to enable game designers to implement their vision, while, at the same time, simplifying the implementation through asset and code reuse. in this paper we present a set of lessons learned through the design and construction phydsl-2, a game engine for 2d physics-based games. our experience involves the active use of modern model-driven engineering technologies, to overcome the complexity of the engine design and to systematize its maintenance and evolution.",
            "contribution_ids": [
                "R25538"
            ]
        },
        {
            "instance_id": "R25583xR25551",
            "comparison_id": "R25583",
            "paper_id": "R25551",
            "text": "Model-driven development of interactive and integrated 2D and 3D user interfaces using mml while there is a lot of research done in the area of 2d or 3d user interfaces (uis) construction, comparatively little is known about systematic approaches to designing and developing integrated 2d/3d uis and applications. the previously developed multimedia modeling language (mml) provides a top down approach for a model driven development of 2d/3d uis and applications. the mml structure model and media components provide support for including x3d based content and automatic generation of application skeletons. we use a work instruction manual for a woodchipper as an example to illustrate how to apply mml. we discuss the ramifications of this approach and opportunities for some improvements.",
            "contribution_ids": [
                "R25552"
            ]
        },
        {
            "instance_id": "R25583xR25569",
            "comparison_id": "R25583",
            "paper_id": "R25569",
            "text": "Engine- Cooperative Game Modeling (ECGM) today game engines are popular in commercial game development, as they lower the threshold of game production by providing common technologies and convenient content-creation tools. game engine based development is therefore the mainstream methodology in the game industry. model-driven game development (mdgd) is an emerging game development methodology, which applies the model-driven software development (mdsd) method in the game development domain. this simplifies game development by reducing the gap between game design and implementation. mdgd has to take advantage of the existing game engines in order to be useful in commercial game development practice. however, none of the existing mdgd approaches in literature has convincingly demonstrated good integration of its tools with the game engine tool-chain. in this paper, we propose a hybrid approach named ecgm to address the integration challenges of two methodologies with a focus on the technical aspects. the approach makes a run-time engine the base of the domain framework, and uses the game engine tool-chain together with the mdgd tool-chain. ecgm minimizes the change to the existing workflow and technology, thus reducing the cost and risk of adopting mdgd in commercial game development. our contribution is one important step towards mdgd industrialization.",
            "contribution_ids": [
                "R25570"
            ]
        },
        {
            "instance_id": "R25583xR25577",
            "comparison_id": "R25583",
            "paper_id": "R25577",
            "text": "How to integrate domain-specific languages into the game development process domain-specific languages make the relevant details of a domain explicit while omitting the distracting ones. this implies many benefits regarding development speed and quality as well as the exchange of information between expert groups. in order to utilize these benefits for game development, we present a language engineering workflow that describes best practices to identify a reasonable domain abstraction, illustrated by means of a language for 2d point &click adventures. we discuss how this process can be integrated into an agile, iterative development process and what thereby needs to be considered.",
            "contribution_ids": [
                "R25578"
            ]
        },
        {
            "instance_id": "R25583xR25565",
            "comparison_id": "R25583",
            "paper_id": "R25565",
            "text": "Using domain-specific modeling towards computer games development industrialization this paper proposes that computer games development, in spite of its inherently creative and innovative nature, is subject of systematic industrialization targeted at predictability and productivity. the proposed approach encompasses visual domain-specific languages, semantic validators and code generators to make game developers and designers to work more productively, with a higher level of abstraction and closer to their application domain. such concepts were implemented and deployed into a host development environment, and a real-world scenario was developed to illustrate and validate the proposal.",
            "contribution_ids": [
                "R25566"
            ]
        },
        {
            "instance_id": "R25629xR25595",
            "comparison_id": "R25629",
            "paper_id": "R25595",
            "text": "Agile systems development and stakeholder satisfaction: a South African empirical study \"the high rate of systems development (sd) failure is often attributed to the complexity of traditional sd methodologies (e.g. waterfall) and their inability to cope with changes brought about by today's dynamic and evolving business environment. agile methodologies (am) have emerged to challenge traditional sd and overcome their limitations. yet empirical research into am is sparse. this paper develops and tests a research model that hypothesizes the effects of five characteristics of agile systems development (iterative development; continuous integration; test-driven design; feedback; and collective ownership) on two dependent stakeholder satisfaction measures, namely stakeholder satisfaction with the development process and with the development outcome. an empirical study of 59 south african development projects (using self reported data) provided support for all hypothesized relationships and generally supports the efficacy of am. iteration and integration together with collective ownership have the strongest effects on the dependent satisfaction measures.\"",
            "contribution_ids": [
                "R25596"
            ]
        },
        {
            "instance_id": "R25629xR25599",
            "comparison_id": "R25629",
            "paper_id": "R25599",
            "text": "Effects of agile practices on social factors programmers are living in an age of accelerated change. state of the art technology that was employed to facilitate projects a few years ago are typically obsolete today. presently, there are requirements for higher quality software with less tolerance for errors, produced in compressed timelines with fewer people. therefore, project success is more elusive than ever and is contingent upon many key aspects. one of the most crucial aspects is social factors. these social factors, such as knowledge sharing. motivation, and customer collaboration, can be addressed through agile practices. this paper will demonstrate two successful industrial software projects which are different in all aspects; however, both still apply agile practices to address social factors. the readers will see how agile practices in both projects were adapted to fit each unique team environment. the paper will also provide lessons learned and recommendations based on retrospective reviews and observations. these recommendations can lead to an improved chance of success in a software development project.",
            "contribution_ids": [
                "R25600"
            ]
        },
        {
            "instance_id": "R25629xR25605",
            "comparison_id": "R25629",
            "paper_id": "R25605",
            "text": "Agile Team Perceptions of Productivity Factors in this paper, we investigate agile team perceptions of factors impacting their productivity. within this overall goal, we also investigate which productivity concept was adopted by the agile teams studied. we here conducted two case studies in the industry and analyzed data from two projects that we followed for six months. from the perspective of agile team members, the three most perceived factors impacting on their productivity were appropriate team composition and allocation, external dependencies, and staff turnover. teams also mentioned pair programming and collocation as agile practices that impact productivity. as a secondary finding, most team members did not share the same understanding of the concept of productivity. while some known factors still impact agile team productivity, new factors emerged from the interviews as potential productivity factors impacting agile teams.",
            "contribution_ids": [
                "R25606"
            ]
        },
        {
            "instance_id": "R25629xR25625",
            "comparison_id": "R25629",
            "paper_id": "R25625",
            "text": "Assimilation of agile practices in use agile method use in information systems development (isd) has grown dramatically in recent years. the emergence of these alternative approaches was very much industry\u2010led at the outset, and while agile method research is growing, the vast majority of these studies are descriptive and often lack a strong theoretical and conceptual base. insights from innovation adoption research can provide a new perspective on analysing agile method use. this paper is based on an exploratory study of the application of the innovation assimilation stages to understand the use of agile practices, focusing in particular on the later stages of assimilation, namely acceptance, routinisation and infusion. four case studies were conducted, and based on the case study findings, the concepts of acceptance, routinisation and infusion were adapted and applied to agile software development. these adapted concepts were used to glean interesting insights into agile practice use. for example, it was shown that the period of use of agile practices does not have a proportional effect on their assimilation depths. we also reflected on the sequential assumption underlying the assimilation stages, showing that adopting teams do not always move through the assimilation stages in a linear manner.",
            "contribution_ids": [
                "R25626"
            ]
        },
        {
            "instance_id": "R25663xR25641",
            "comparison_id": "R25663",
            "paper_id": "R25641",
            "text": "An empirical task analysis of warehouse order picking using head-mounted displays evaluations of task guidance systems often focus on evaluations of new technologies rather than comparing the nuances of interaction across the various systems. one common domain for task guidance systems is warehouse order picking. we present a method involving an easily reproducible ecologically motivated order picking environment for quantitative user studies designed to reveal differences in interactions. using this environment, we perform a 12 participant within-subjects experiment demonstrating the advantages of a head-mounted display based picking chart over a traditional text-based pick list, a paper-based graphical pick chart, and a mobile pick-by-voice system. the test environment proved sufficiently sensitive, showing statistically significant results along several metrics with the head-mounted display system performing the best. we also provide a detailed analysis of the strategies adopted by our participants.",
            "contribution_ids": [
                "R25642"
            ]
        },
        {
            "instance_id": "R25663xR25657",
            "comparison_id": "R25663",
            "paper_id": "R25657",
            "text": "Pick from here! order picking is not only one of the most important but also most mentally demanding and error-prone tasks in the industry. both stationary and wearable systems have been introduced to facilitate this task. existing stationary systems are not scalable because of the high cost and wearable systems have issues being accepted by the workers. in this paper, we introduce a mobile camera-projector cart called orderpickar, which combines the benefits of both stationary and mobile systems to support order picking through augmented reality. our system dynamically projects in-situ picking information into the storage system and automatically detects when a picking task is done. in a lab study, we compare our system to existing approaches, i.e, pick-by-paper, pick-by-voice, and pick-by-vision. the results show that using the proposed system, order picking is almost twice as fast as other approaches, the error rate is decreased up to 9 times, and mental demands are reduced up to 50%.",
            "contribution_ids": [
                "R25658"
            ]
        },
        {
            "instance_id": "R25663xR25659",
            "comparison_id": "R25663",
            "paper_id": "R25659",
            "text": "Exploring the role of picker personality in predicting picking performance with pick by voice, pick to light and RF-terminal picking order pickers and individual differences between them could have a substantial impact on picking performance, but are largely ignored in studies on order picking. this paper explores the role of individual differences in picking performance with various picking tools (pick by voice, rf-terminal picking and pick to light) and methods (parallel, zone and dynamic zone picking). a unique realistic field experiment with 101 participants (academic students, vocational students and professional pickers) is employed to investigate the influence of individual differences, especially the big five personality traits, on picking performance in terms of productivity and quality. the results suggest that (pbv) performs better than rf-terminal picking, and that neuroticism, extraversion, conscientiousness and the age of the picker play a significant role in predicting picking performance with voice and rf-terminals. furthermore, achieving higher productivity appears to be possible without sacrificing quality. managers can increase picking performance by incorporating the insights in assigning the right pickers to work with a particular picking tool or method, leading to increased picking performance and reduced warehousing costs.",
            "contribution_ids": [
                "R25660"
            ]
        },
        {
            "instance_id": "R25694xR6499",
            "comparison_id": "R25694",
            "paper_id": "R6499",
            "text": "Facets and Pivoting for Flexible and Usable Linked Data Exploration the success of open data initiatives has increased the amount of data available on the web. unfortunately, most of this data is only available in raw tabular form, what makes analysis and reuse quite difficult for non-experts. linked data principles allow for a more sophisticated approach by making explicit both the structure and semantics of the data. however, from the end-user viewpoint, they continue to be monolithic files completely opaque or difficult to explore by making tedious semantic queries. our objective is to facilitate the user to grasp what kind of entities are in the dataset, how they are interrelated, which are their main properties and values, etc. rhizomer is a tool for data publishing whose interface provides a set of components borrowed from information architecture (ia) that facilitate awareness of the dataset at hand. it automatically generates navigation menus and facets based on the kinds of things in the dataset and how they are described through metadata properties and values. moreover, motivated by recent tests with end-users, it also provides the possibility to pivot among the faceted views created for each class of resources in the dataset.",
            "contribution_ids": [
                "R25668",
                "R6500"
            ]
        },
        {
            "instance_id": "R25726xR25701",
            "comparison_id": "R25726",
            "paper_id": "R25701",
            "text": "GrOWL: A Tool for Visualization and Editing of OWL Ontologies in an effort to optimize visualization and editing of owl ontologies we have developed growl-a browser and visual editor for owl that accurately visualizes the underlying dl semantics of owl ontologies while avoiding the difficulties of the verbose owl syntax. in this paper, we discuss growl visualization model and the essential visualization techniques implemented in growl.",
            "contribution_ids": [
                "R25702"
            ]
        },
        {
            "instance_id": "R25726xR25724",
            "comparison_id": "R25726",
            "paper_id": "R25724",
            "text": "graphVizdb: A scalable platform for interactive large graph visualization we present a novel platform for the interactive visualization of very large graphs. the platform enables the user to interact with the visualized graph in a way that is very similar to the exploration of maps at multiple levels. our approach involves an offline preprocessing phase that builds the layout of the graph by assigning coordinates to its nodes with respect to a euclidean plane. the respective points are indexed with a spatial data structure, i.e., an r-tree, and stored in a database. multiple abstraction layers of the graph based on various criteria are also created offline, and they are indexed similarly so that the user can explore the dataset at different levels of granularity, depending on her particular needs. then, our system translates user operations into simple and very efficient spatial operations (i.e., window queries) in the backend. this technique allows for a fine-grained access to very large graphs with extremely low latency and memory requirements and without compromising the functionality of the tool. our web-based prototype supports three main operations: (1) interactive navigation, (2) multi-level exploration, and (3) keyword search on the graph metadata.",
            "contribution_ids": [
                "R25725"
            ]
        },
        {
            "instance_id": "R25726xR25706",
            "comparison_id": "R25726",
            "paper_id": "R25706",
            "text": "Gephi: An Open Source Software for Exploring and Manipulating Networks gephi is an open source software for graph and network analysis. it uses a 3d render engine to display large networks in real-time and to speed up the exploration. a flexible and multi-task architecture brings new possibilities to work with complex data sets and produce valuable visual results.\\xa0 we present several key features of gephi in the context of interactive exploration and interpretation of networks. it provides easy and broad access to network data and allows for spatializing, filtering, navigating, manipulating and clustering. finally, by presenting dynamic features of gephi, we highlight key aspects of dynamic network visualization.",
            "contribution_ids": [
                "R25707"
            ]
        },
        {
            "instance_id": "R25726xR6445",
            "comparison_id": "R25726",
            "paper_id": "R6445",
            "text": "ZoomRDF: semantic fisheye zooming on RDF data. with the development of semantic web in recent years, an increasing amount of semantic data has been created in form of resource description framework (rdf). current visualization techniques help users quickly understand the underlying rdf data by displaying its structure in an overview. however, detailed information can only be accessed by further navigation. an alternative approach is to display the global context as well as the local details simultaneously in a unified view. this view supports the visualization and navigation on rdf data in an integrated way. in this demonstration, we present zoomrdf, a framework that: i) adapts a space-optimized visualization algorithm for rdf, which allows more resources to be displayed, thus maximizes the utilization of display space, ii) combines the visualization with a fisheye zooming concept, which assigns more space to some individual nodes while still preserving the overview structure of the data, iii) considers both the importance of resources and the user interaction on them, which offers more display space to those elements the user may be interested in. we implement the framework based on the gene ontology and demonstrate that it facilitates tasks like rdf data exploration and editing.",
            "contribution_ids": [
                "R25713",
                "R6446"
            ]
        },
        {
            "instance_id": "R25762xR25728",
            "comparison_id": "R25762",
            "paper_id": "R25728",
            "text": "A fast high utility itemsets mining algorithm association rule mining (arm) identifies frequent itemsets from databases and generates association rules by considering each item in equal value. however, items are actually different in many aspects in a number of real applications, such as retail marketing, network log, etc. the difference between items makes a strong impact on the decision making in these applications. therefore, traditional arm cannot meet the demands arising from these applications. by considering the different values of individual items as utilities, utility mining focuses on identifying the itemsets with high utilities. as \"downward closure property\" doesn\\'t apply to utility mining, the generation of candidate itemsets is the most costly in terms of time and memory space. in this paper, we present a two-phase algorithm to efficiently prune down the number of candidates and can precisely obtain the complete set of high utility itemsets. in the first phase, we propose a model that applies the \"transaction-weighted downward closure property\" on the search space to expedite the identification of candidates. in the second phase, one extra database scan is performed to identify the high utility itemsets. we also parallelize our algorithm on shared memory multi-process architecture using common count partitioned database (ccpd) strategy. we verify our algorithm by applying it to both synthetic and real databases. it performs very efficiently in terms of speed and memory cost, and shows good scalability on multiple processors, even on large databases that are difficult for existing algorithms to handle.",
            "contribution_ids": [
                "R25729"
            ]
        },
        {
            "instance_id": "R25762xR25742",
            "comparison_id": "R25762",
            "paper_id": "R25742",
            "text": "A transaction mapping algorithm for frequent itemsets mining in this paper, we present a novel algorithm for mining complete frequent itemsets. this algorithm is referred to as the tm (transaction mapping) algorithm from hereon. in this algorithm, transaction ids of each itemset are mapped and compressed to continuous transaction intervals in a different space and the counting of itemsets is performed by intersecting these interval lists in a depth-first order along the lexicographic tree. when the compression coefficient becomes smaller than the average number of comparisons for intervals intersection at a certain level, the algorithm switches to transaction id intersection. we have evaluated the algorithm against two popular frequent itemset mining algorithms, fp-growth and declat, using a variety of data sets with short and long frequent patterns. experimental data show that the tm algorithm outperforms these two algorithms.",
            "contribution_ids": [
                "R25743"
            ]
        },
        {
            "instance_id": "R25762xR25746",
            "comparison_id": "R25762",
            "paper_id": "R25746",
            "text": "Mining High Utility Itemsets in Large High Dimensional Data existing algorithms for utility mining are inadequate on datasets with high dimensions or long patterns. this paper proposes a hybrid method, which is composed of a row enumeration algorithm (i.e., inter-transaction) and a column enumeration algorithm (i.e., two-phase), to discover high utility itemsets from two directions: two-phase seeks short high utility itemsets from the bottom, while inter-transaction seeks long high utility itemsets from the top. in addition, optimization technique is adopted to improve the performance of computing the intersection of transactions. experiments on synthetic data show that the hybrid method achieves high performance in large high dimensional datasets.",
            "contribution_ids": [
                "R25747"
            ]
        },
        {
            "instance_id": "R25857xR25787",
            "comparison_id": "R25857",
            "paper_id": "R25787",
            "text": "Promotional effect of Pd single atoms on Au nanoparticles supported on silica for the selective hydrogenation of acetylene in excess ethylene a pd single-atom alloy (saa) structure was constructed by alloying pd with au supported on silica. the xrd and hrtem results demonstrated that the addition of a small amount of pd efficiently prevented the sintering of au nanoparticles. the drifts and exafs results confirmed that the pd saa structure was formed when the atomic ratios of pd/au were lower than 0.025. the pd saa structure exhibits a much better catalytic performance for the selective hydrogenation of acetylene in excess ethylene than the corresponding monometallic au or pd systems.",
            "contribution_ids": [
                "R25788"
            ]
        },
        {
            "instance_id": "R25857xR25791",
            "comparison_id": "R25857",
            "paper_id": "R25791",
            "text": "Performance of Cu-Alloyed Pd Single-Atom Catalyst for Semihydrogenation of Acetylene under Simulated Front-End Conditions selective hydrogenation of acetylene to ethylene is an industrially important reaction. pd-based catalysts have been proved to be efficient for the acetylene conversion, while enhancing the selectivity to ethylene is challenging. here, we chose cu as the partner of pd, fabricated an alloyed pd single-atom catalyst (sac), and investigated its catalytic performance for the selective hydrogenation of acetylene to ethylene under a simulated front-end hydrogenation process in industry: that is, with a high concentration of hydrogen and ethylene. the cu-alloyed pd sac showed \u223c85% selectivity to ethylene and 100% acetylene elimination. in comparison with the au- or ag-alloyed pd sac, the cu-alloyed analogue exceeded both of them in conversion, while the selectivity rivaled that of the ag-alloyed pd sac and surpassed that of the au-alloyed pd sac. as cu is a low-cost metal, cu-alloyed pd sac would minimize the noble-metal usage and possess high utilization potential for industry. the cu-alloyed pd sac was verifie...",
            "contribution_ids": [
                "R25792"
            ]
        },
        {
            "instance_id": "R25857xR25816",
            "comparison_id": "R25857",
            "paper_id": "R25816",
            "text": "Single-Atom Pd1/Graphene Catalyst Achieved by Atomic Layer Deposition: Remarkable Performance in Selective Hydrogenation of 1,3-Butadiene we reported that atomically dispersed pd on graphene can be fabricated using the atomic layer deposition technique. aberration-corrected high-angle annular dark-field scanning transmission electron microscopy and x-ray absorption fine structure spectroscopy both confirmed that isolated pd single atoms dominantly existed on the graphene support. in selective hydrogenation of 1,3-butadiene, the single-atom pd1/graphene catalyst showed about 100% butenes selectivity at 95% conversion at a mild reaction condition of about 50 \u00b0c, which is likely due to the changes of 1,3-butadiene adsorption mode and enhanced steric effect on the isolated pd atoms. more importantly, excellent durability against deactivation via either aggregation of metal atoms or carbonaceous deposits during a total 100 h of reaction time on stream was achieved. therefore, the single-atom catalysts may open up more opportunities to optimize the activity, selectivity, and durability in selective hydrogenation reactions.",
            "contribution_ids": [
                "R25817"
            ]
        },
        {
            "instance_id": "R25857xR25820",
            "comparison_id": "R25857",
            "paper_id": "R25820",
            "text": "Atomically Dispersed Pd on Nanodiamond/Graphene Hybrid for Selective Hydrogenation of Acetylene we reported here a strategy to use a defective nanodiamond-graphene (nd@g) to prepare an atomically dispersed metal catalyst, i.e., in the current case atomically dispersed palladium catalyst which is used for selective hydrogenation of acetylene in the presence of abundant ethylene. the catalyst exhibits remarkable performance for the selective conversion of acetylene to ethylene: high conversion (100%), ethylene selectivity (90%), and good stability. the unique structure of the catalyst (i.e., atomically dispersion of pd atoms on graphene through pd-c bond anchoring) blocks the formation of unselective subsurface hydrogen species and ensures the facile desorption of ethylene against the overhydrogenation to undesired ethane, which is the key for the outstanding selectivity of the catalyst.",
            "contribution_ids": [
                "R25821"
            ]
        },
        {
            "instance_id": "R25857xR25842",
            "comparison_id": "R25857",
            "paper_id": "R25842",
            "text": "Cooperative Effects in Ternary Cu\u00e2\u0088\u0092Ni\u00e2\u0088\u0092Fe Catalysts Lead to Enhanced Alkene Selectivity in Alkyne Hydrogenation a new generation of heterogeneous cu-ni-fe catalysts with appropriate metal ratios displayed outstanding alkene selectivity in the gas-phase hydrogenation of propyne (s(c(3)h(6)) up to 100%) and ethyne (s(c(2)h(4)) up to 80%). the design was accomplished by orchestrating key functions in the catalyst: copper is the base hydrogenation metal, nickel increases the hydrogen coverage to minimize oligomerization, and iron acts as structural promoter. in addition to the largely improved alkene selectivity compared to that of the commonly applied pd catalysts, the ternary cu-ni-fe catalysts promise substantial process advantages, since they do not require co feeding as selectivity enhancer and they yield high alkene selectivity in a broad window of h(2)/alkyne ratios. the ternary system requires higher operating temperatures compared to those for palladium.",
            "contribution_ids": [
                "R25843"
            ]
        },
        {
            "instance_id": "R25857xR25853",
            "comparison_id": "R25857",
            "paper_id": "R25853",
            "text": "Semihydrogenation of Acetylene on Indium Oxide: Proposed Single-Ensemble Catalysis indium oxide catalyzes acetylene hydrogenation with high selectivity to ethylene (>85\\u2009%); even with a large excess of the alkene. in\\u2005situ characterization reveals the formation of oxygen vacancies under reaction conditions, while an in depth theoretical analysis links the surface reduction with the creation of well-defined vacancies and surrounding in3 o5 ensembles, which are considered responsible for this outstanding catalytic function. this behavior, which differs from that of other common reducible oxides, originates from the presence of four crystallographically inequivalent oxygen sites in the indium oxide surface. these resulting ensembles are 1)\\u2005stable against deactivation, 2)\\u2005homogeneously and densely distributed, and 3)\\u2005spatially isolated and confined against transport; thereby broadening the scope of oxides in hydrogenation catalysis.",
            "contribution_ids": [
                "R25854"
            ]
        },
        {
            "instance_id": "R25900xR25865",
            "comparison_id": "R25900",
            "paper_id": "R25865",
            "text": "Pd-Pb Alloy Nanocrystals with Tailored Composition for Semihydrogenation: Taking Advantage of Catalyst Poisoning metallic nanocrystals (ncs) with well-defined sizes and shapes represent a new family of model systems for establishing structure-function relationships in heterogeneous catalysis. here in this study, we show that catalyst poisoning can be utilized as an efficient strategy for nanocrystals shape and composition control, as well as a way to tune the catalytic activity of catalysts. lead species, a well-known poison for noble-metal catalysts, was investigated in the growth of pd ncs. we discovered that pb atoms can be incorporated into the lattice of pd ncs and form pd-pb alloy ncs with tunable composition and crystal facets. as model catalysts, the alloy ncs with different compositions showed different selectivity in the semihydrogenation of phenylacetylene. pd-pb alloy ncs with better selectivity than that of the commercial lindlar catalyst were discovered. this study exemplified that the poisoning effect in catalysis can be explored as efficient shape-directing reagents in nc growth, and more importantly, as a strategy to tailor the performance of catalysts with high selectivity.",
            "contribution_ids": [
                "R25866",
                "R25867"
            ]
        },
        {
            "instance_id": "R25900xR25872",
            "comparison_id": "R25900",
            "paper_id": "R25872",
            "text": "Metal-Ligand Core-Shell Nanocomposite Catalysts for the Selective Semihydrogenation of Alkynes in recent years, hybrid nanocomposites with core\u2013shell structures have increasingly attracted enormous attention in many important research areas such as quantum dots, optical, magnetic, and electronic devices, and catalysts. in the catalytic applications of core\u2013shell materials, core-metals having magnetic properties enable easy separation of the catalysts from the reaction mixtures by a magnet. the core-metals can also affect the active shell-metals, delivering significant improvements in their activities and selectivities. however, it is difficult for core-metals to act directly as the catalytic active species because they are entirely covered by the shell. thus, few successful designs of core\u2013shell nanocomposite catalysts having active metal species in the core have appeared to date. recently, we have demonstrated the design of a core\u2013shell catalyst consisting of active metal nanoparticles (nps) in the core and closely assembled oxides with nano-gaps in the shell, allowing the access of substrates to the core-metal. the shell acted as a macro ligand (shell ligand) for the core-metal and the core\u2013shell structure maximized the metal\u2013ligand interaction (ligand effect), promoting highly selective reactions. the design concept of core\u2013shell catalysts having core-metal nps with a shell ligand is highly useful for selective organic transformations owing to the ideal structure of these catalysts for maximizing the ligand effect, leading to superior catalytic performances compared to those of conventional supported metal nps. semihydrogenation of alkynes is a powerful tool to synthesize (z)-alkenes which are important building blocks for fine chemicals, such as bioactive molecules, flavors, and natural products. in this context, the lindlar catalyst (pd/ caco3 treated with pb(oac)2) has been widely used. [13] unfortunately, the lindlar catalyst has serious drawbacks including the requirement of a toxic lead salt and the addition of large amounts of quinoline to suppress the over-hydrogenation of the product alkenes. furthermore, the lindlar catalyst has a limited substrate scope; terminal alkynes cannot be converted selectively into terminal alkenes because of the rapid over-hydrogenation of the resulting alkenes to alkanes. aiming at the development of environmentally benign catalyst systems, a number of alternative lead-free catalysts have been reported. 15] recently, we also developed a leadfree catalytic system for the selective semihydrogenation consisting of sio2-supported pd nanoparticles (pdnps) and dimethylsulfoxide (dmso), in which the addition of dmso drastically suppressed the over-hydrogenation and isomerization of the alkene products even after complete consumption of the alkynes. this effect is due to the coordination of dmso to the pdnps. dmso adsorbed on the surface of pdnps inhibits the coordination of alkenes to the pdnps, while alkynes can adsorb onto the pdnps surface because they have a higher coordination ability than dmso. this phenomenon inspired us to design pdnps coordinated with a dmso-like species in a solid matrix. if a core\u2013shell structured nanocomposite involving pdnps encapsulated by a shell having a dmso-like species could be constructed, it would act as an efficient and functional solid catalyst for the selective semihydrogenation of alkynes. herein, we successfully synthesized core\u2013shell nanocomposites of pdnps covered with a dmso-like matrix on the surface of sio2 (pd@mpso/sio2). the shell, consisting of an alkyl sulfoxide network, acted as a macroligand and allowed the selective access of alkynes to the active center of the pdnps, promoting the selective semihydrogenation of not only internal but also terminal alkynes without any additives. moreover, these catalysts were reusable while maintaining high activity and selectivity. pd@mpso/sio2 catalysts were synthesized as follows. pd/ sio2 prepared according to our procedure [16] was stirred in n-heptane with small amounts of 3,5-di-tert-butyl-4-hydroxytoluene (bht) and water at room temperature. next, methyl3-trimethoxysilylpropylsulfoxide (mpso) was added to the mixture and the mixture was heated. the slurry obtained was collected by filtration, washed, and dried in vacuo, affording pd@mpso/sio2 as a gray powder. altering the molar ratios of mpso to pd gave two kinds of catalysts: pd@mpso/sio21 (mpso:pd = 7:1), and pd@mpso/sio2-2 (mpso:pd = 100:1). [*] dr. t. mitsudome, y. takahashi, dr. t. mizugaki, prof. dr. k. jitsukawa, prof. dr. k. kaneda department of materials engineering science graduate school of engineering science, osaka university 1\u20133, machikaneyama, toyonaka, osaka 560-8531 (japan) e-mail: kaneda@cheng.es.osaka-u.ac.jp",
            "contribution_ids": [
                "R25873"
            ]
        },
        {
            "instance_id": "R25900xR25874",
            "comparison_id": "R25900",
            "paper_id": "R25874",
            "text": "Dual Pd and CuFe2O4 nanoparticles encapsulated in a core/shell silica microsphere for selective hydrogenation of arylacetylenes a dual catalyst containing pd and cufe(2)o(4) nanoparticles in a silica shell exhibits >98% conversion of arylacetylenes to related styrenes with selectivity greater than 98%, which are better than those obtained using a commercial lindlar catalyst. the excellent synergy was likely a result of the proximal interaction between pd and cufe(2)o(4) nanoparticles.",
            "contribution_ids": [
                "R25875"
            ]
        },
        {
            "instance_id": "R25900xR25878",
            "comparison_id": "R25900",
            "paper_id": "R25878",
            "text": "Selective Semihydrogenation of Alkynes Catalyzed by Pd Nanoparticles Immobilized on Heteroatom-Doped Hierarchical Porous Carbon Derived from Bamboo Shoots highly dispersed palladium nanoparticles (pd nps) immobilized on heteroatom-doped hierarchical porous carbon supports (n,o-carbon) with large specific surface areas are synthesized by a wet chemical reduction method. the n,o-carbon derived from naturally abundant bamboo shoots is fabricated by a tandem hydrothermal-carbonization process without assistance of any templates, chemical activation reagents, or exogenous n or o sources in a simple and ecofriendly manner. the prepared pd/n,o-carbon catalyst shows extremely high activity and excellent chemoselectivity for semihydrogenation of a broad range of alkynes to versatile and valuable alkenes under ambient conditions. the catalyst can be readily recovered for successive reuse with negligible loss in activity and selectivity, and is also applicable for practical gram-scale reactions.",
            "contribution_ids": [
                "R25879"
            ]
        },
        {
            "instance_id": "R25900xR25880",
            "comparison_id": "R25900",
            "paper_id": "R25880",
            "text": "Palladium nanoparticles supported on mpg-C3N4 as active catalyst for semihydrogenation of phenylacetylene under mild conditions pd-nanoparticles supported on mesoporous graphitic carbon nitride is found to be an effective, heterogeneous catalyst for the liquid-phase semihydrogenation of phenylacetylenes under mild conditions.",
            "contribution_ids": [
                "R25881"
            ]
        },
        {
            "instance_id": "R25900xR25886",
            "comparison_id": "R25900",
            "paper_id": "R25886",
            "text": "Achieving the Trade-Off between Selectivity and Activity in Semihydrogenation of Alkynes by Fabrication of (Asymmetrical Pd@Ag Core)@(CeO2 Shell) Nanocatalysts via Autoredox Reaction (asymmetrical pd@ag core)@(ceo2 shell) nanostructures are successfully fabricated via a clean and facile modified autoredox reaction by the preaddition of pd seeds in the growth solution. in a subsequent catalytic test, it is found that the as-obtained bimetallic core@shell nanoparticles exhibit excellent catalytic performance in semihydrogenation of alkynes. the trade-off between selectivity and activity is well realized.",
            "contribution_ids": [
                "R25887"
            ]
        },
        {
            "instance_id": "R25999xR25983",
            "comparison_id": "R25999",
            "paper_id": "R25983",
            "text": "Using stochastic syntactic analysis for extracting a logical structure from a document image \"a method of stochastic syntactic analysis is applied to extracting the logical structure of a printed document from its physical layout and keywords indicating logical components. the document is parsed as a sentence consisting of text lines and graphic objects according to a stochastic regular grammar with attributes. by using stochastic analysis, the parser can retain possible results in order of their probability, and thus, if ambiguity occurs, it selects an optimal result more appropriately than deterministic systems. a mark up system applying the method was constructed, and 87% of the logical components of manuals and 82% of those of technical papers are correctly marked up. the rate improved to 89% when the second candidates were considered, showing the advantage of the authors' approach over the deterministic approach.\"",
            "contribution_ids": [
                "R25984",
                "R26010"
            ]
        },
        {
            "instance_id": "R26063xR26023",
            "comparison_id": "R26063",
            "paper_id": "R26023",
            "text": "Two Dimensional Displacement-Stress Distributions in Adhesive Bonded Composite Structures abstract computerized analysis of composite structures formed by the adhesive bonding of materials is presented. the adhesive is considered to be a part of a linearly elastic system whose components are individually characterized by two bulk property elastic constants. solution is obtained by finite difference minimization of the internal energy distribution in a discretized, piecewise homogeneous continuum. the plane-stress, plane-strain problems are considered, and yield displacement and stress distributions for the composite system. displacement and/or stress boundary conditions are allowed. acute contour angles are not allowed. this is the only restriction for otherwise arbitrary plane geometries. results are presented for typical lap shear specimens as well as for a particular case of a butt joint in which a void exists in the adhesive layer.",
            "contribution_ids": [
                "R26024"
            ]
        },
        {
            "instance_id": "R26063xR26027",
            "comparison_id": "R26063",
            "paper_id": "R26027",
            "text": "The efficient design of adhesive bonded joints \"abstract a concise method of analysis is used to study the numerous parameters influencing the stress distribution within the adhesive of a single lap joint. the formulation includes transverse shear and normal strain deformations. both isotropic or anisotropic material systems of similar or dissimilar adherends are analysed. results indicate that the primary young's modulus of the adherend, the overlap length, and the adhesive's material properties are the parameters most influential in optimizing the design of a single lap joint.\"",
            "contribution_ids": [
                "R26028"
            ]
        },
        {
            "instance_id": "R26063xR26035",
            "comparison_id": "R26063",
            "paper_id": "R26035",
            "text": "Stresses in Adhesively Bonded Joints: A Closed-Form Solution in this paper the general plane strain problem of adhesively bonded struc tures which consist of two different orthotropic adherends is considered. assuming that the thicknesses of the adherends are constant and are small in relation to the lateral dimensions of the bonded region, the adherends are treated as plates. also, assuming that the thickness of the adhesive is small compared to that of the adherends, the thickness variation of the stresses in the adhesive layer is neglected. however, the transverse shear effects in the adherends and the in-plane normal strain in the adhesive are taken into ac count. the problem is reduced to a system of differential equations for the adhesive stresses which is solved in closed form. a single lap joint and a stif fened plate under various loading conditions are considered as examples. to verify the basic trend of the solutions obtained from the plate theory and to give some idea about the validity of the plate assumption itself, a sample pro blem is solved by using the finite element method and by treating the adherends and the adhesive as elastic continua. it is found that the plate theory used in the analysis not only predicts the correct trend for the adhesive stresses but also gives rather surprisingly accurate results. the solution is ob tained by assuming linear stress-strain relations for the adhesive. in the ap pendix the problem is formulated by using a nonlinear material for the adhesive and by following two different approaches.",
            "contribution_ids": [
                "R26036"
            ]
        },
        {
            "instance_id": "R26107xR26089",
            "comparison_id": "R26107",
            "paper_id": "R26089",
            "text": "Environmental and human factors influencing thermal comfort of office occupants in hot\u00e2\u0080\u0094humid and hot\u00e2\u0080\u0094arid climates the effects of environmental and individual factors on thermal sensation in air-conditioned office environments were analysed for two large, fully compatible thermal comfort field studies in contrasting australian climates. in the hot\u2014humid location of townsville, 836 office workers were surveyed; 935 workers participated in hot\u2014arid kalgoorlie-boulder. overall perceived work area temperature and measured indoor operative temperature correlated moderately with thermal sensation for townsville (t) subjects but only perceived temperature correlated with kalgoorlie-boulder (kb) sensation. multiple regression analyses confirmed that indoor climatic variables (including predicted mean vote) contributed to actual thermal sensation vote (24% t; 15% kb), with operative temperature having more of an effect in t than in kb. subsequent analyses of individual characteristics showed no linear contributions to thermal sensation. the remaining variances were significantly related to perceived work area temperature (7% additional explained variance in t; 12% in kb). mann whitney analyses (after correction for climatic variables) showed that t subjects with higher job satisfaction had thermal sensations closer to \u2018neutral\u2019. males, healthier subjects, non-smokers, respondents with earlier survey times and underweight occupants had lower median thermal sensations in kb. townsville occupants appeared more adapted to their outdoor climatic conditions than kalgoorlie-boulder respondents, perhaps due to limited home air-conditioning. further research into non-thermal impacts on gender-related thermal acceptability is suggested.",
            "contribution_ids": [
                "R26090"
            ]
        },
        {
            "instance_id": "R26107xR26105",
            "comparison_id": "R26107",
            "paper_id": "R26105",
            "text": "Subjective indoor air quality in schools in relation to exposure this paper presents data on indoor air quality in schools as perceived by those working in them and relates these data to exposure measurements. data on subjective air quality, domestic exposures and health aspects were gathered by means of a questionnaire which was sent to all personnel in 38 schools; it was completed by 1410 persons (85\u20194 of the total). data on exposure were gathered by exposure measurements in classrooms. the results indicate that 53% of the personnel perceived the indoor air quality as bad or very bad. it was perceived as worse by those who were younger, those who were dissatisfied with their psychosocial work climate and those who were not exposed to tobacco smoke at home. in older school buildings and buildings with displacement ventilation there was less dissatisfaction with the air quality. there were no significant relations between complaints and air exchange rate or concentration of carbon dioxide. the air quality was perceived as worse at higher levels of exposure to a number of airborne compounds including volatile organic compounds, moulds, bacteria and respirable dust. it was concluded that exposure to indoor pollutants affects perception even at the low concentrations normally found indoors in nonindustrial buildings.",
            "contribution_ids": [
                "R26106"
            ]
        },
        {
            "instance_id": "R26127xR26115",
            "comparison_id": "R26127",
            "paper_id": "R26115",
            "text": "The underground economy in the United States: Reply to comments by Feige, Thomas, and Zilberfarb the fate that an author should dread the most is to see his/her writings ignored. while i have experienced this fate with some of my writings, this is definitely not what has happened to my articles on the underground economy in the united states. for these i have been \"flattered\" by more attention than i would perhaps have liked. the three comments and criticisms discussed here are quite different: they deal in part with the methodology of my work in this area and in part with the empirical results. there are several ways in which i could deal with them but perhaps the simplest is to take the authors\\' comments alphabetically. i shall allocate far more space to feige\\'s \"comment\" than to the other two, largely because his is not just a comment on my paper but is also an attempt to \"sell\" his work to the readers of staff papers. thus, i must inevitably discuss his method and results while attempting to answer his specific criticism of my work.",
            "contribution_ids": [
                "R26116"
            ]
        },
        {
            "instance_id": "R26146xR26128",
            "comparison_id": "R26146",
            "paper_id": "R26128",
            "text": "Small scale entrepreneurs in Ghana and development planning summary this article attempts an assessment of entrepreneurial contributions to the solution of some of the objectives of central economic development planning\u2014contributions which are ignored by planners for reasons that are described in this social anthropological study of one aspect of economic development in ghana. the author wishes to express his gratitude to the managers of the smuts\u2019 memorial fund for providing much of his financial backing during field\u2010work; also to the ling roth fund, the anthony wilkin fund, the bartle frere fund, the mary euphrasia mosley fund, the west african research unit, and the warmington fund. he held a department of education and science studentship during the years 1965\u201368. the author also wishes to thank jack goody, esther goody, enid schild\u2010krout and jeremy eades for discussing a preliminary draft of this paper; and marion pearsall for comments on later versions; richard cornes and mike faber have also been most helpful. responsibility for the final draft is entirely ...",
            "contribution_ids": [
                "R26129"
            ]
        },
        {
            "instance_id": "R26194xR26156",
            "comparison_id": "R26194",
            "paper_id": "R26156",
            "text": "A Combined Vehicle Routing and Inventory Allocation Problem we address the combined problem of allocating a scarce resource among several locations, and planning deliveries using a fleet of vehicles. demands are random, and holding and shortage costs must be considered in the decision along with transportation costs. we show how to extend some of the available methods for the deterministic vehicle routing problem to this case. computational results using one such adaptation show that the algorithm is fast enough for practical work, and that substantial cost savings can be achieved with this approach.",
            "contribution_ids": [
                "R26157"
            ]
        },
        {
            "instance_id": "R26194xR26173",
            "comparison_id": "R26194",
            "paper_id": "R26173",
            "text": "An Integrated Inventory Allocation and Vehicle Routing Problem we address the problem of distributing a limited amount of inventory among customers using a fleet of vehicles so as to maximize profit. both the inventory allocation and the vehicle routing problems are important logistical decisions. in many practical situations, these two decisions are closely interrelated, and therefore, require a systematic approach to take into account both activities jointly. we formulate the integrated problem as a mixed integer program and develop a lagrangian-based procedure to generate both good upper bounds and heuristic solutions. computational results show that the procedure is able to generate solutions with small gaps between the upper and lower bounds for a wide range of cost structures.",
            "contribution_ids": [
                "R26174"
            ]
        },
        {
            "instance_id": "R26194xR26175",
            "comparison_id": "R26194",
            "paper_id": "R26175",
            "text": "Stochastic Inventory Routing: Route Design with Stockouts and Route Failures \" the stochastic inventory routing problem involves the distribution of a commodity such as heating oil over a long period of time to a large set of customers. the customers maintain a local inventory of the commodity which they consume at a daily rate. their consumption varies daily and seasonally and their exact demand is known only upon the arrival of the delivery vehicle. this paper presentes a detailed analysis of this problem incorporating the stochastic nature of customers' consumptions and the possibility of route failures when the actual demand on a route exceeds the capacity of a vehicle. a number of solution procedures are compared on a large set of real life data for a period of 12 consecutive weeks. the winning strategy, though computationally more expensive, provides the best system performance and reduces (almost eliminates) the stockout phenomena. \"",
            "contribution_ids": [
                "R26176"
            ]
        },
        {
            "instance_id": "R26262xR26244",
            "comparison_id": "R26262",
            "paper_id": "R26244",
            "text": "A branch-and-cut algorithm for a vendor-managed inventory-routing problem we consider a distribution problem in which a product has to be shipped from a supplier to several retailers over a given time horizon. each retailer defines a maximum inventory level. the supplier monitors the inventory of each retailer and determines its replenishment policy, guaranteeing that no stockout occurs at the retailer (vendor-managed inventory policy). every time a retailer is visited, the quantity delivered by the supplier is such that the maximum inventory level is reached (deterministic order-up-to level policy). shipments from the supplier to the retailers are performed by a vehicle of given capacity. the problem is to determine for each discrete time instant the quantity to ship to each retailer and the vehicle route. we present a mixed-integer linear programming model and derive new additional valid inequalities used to strengthen the linear relaxation of the model. we implement a branch-and-cut algorithm to solve the model optimally. we then compare the optimal solution of the problem with the optimal solution of two problems obtained by relaxing in different ways the deterministic order-up-to level policy. computational results are presented on a set of randomly generated problem instances.",
            "contribution_ids": [
                "R26245"
            ]
        },
        {
            "instance_id": "R26352xR26274",
            "comparison_id": "R26352",
            "paper_id": "R26274",
            "text": "Two-echelon distribution systems with vehicle routing costs and central inventory we consider distribution systems with a single depot and many retailers each of which faces external demands for a single item that occurs at a specific deterministic demand rate. all stock enters the systems through the depot where it can be stored and then picked up and distributed to the retailers by a fleet of vehicles, combining deliveries into efficient routes. we extend earlier methods for obtaining low complexity lower bounds and heuristics for systems without central stock. we show under mild probabilistic assumptions that the generated solutions and bounds come asymptotically within a few percentage points of optimality (within the considered class of strategies). a numerical study exhibits the performance of these heuristics and bounds for problems of moderate size.",
            "contribution_ids": [
                "R26275"
            ]
        },
        {
            "instance_id": "R26352xR26279",
            "comparison_id": "R26352",
            "paper_id": "R26279",
            "text": "A Markov Decision Model and Decomposition Heuristic for Dynamic Vehicle Dispatching \" we describe a dynamic and stochastic vehicle dispatching problem called the delivery dispatching problem. this problem is modeled as a markov decision process. because exact solution of this model is impractical, we adopt a heuristic approach for handling the problem. the heuristic is based in part on a decomposition of the problem by customer, where customer subproblems generate penalty functions that are applied in a master dispatching problem. we describe how to compute bounds on the algorithm's performance, and apply it to several examples with good results. \"",
            "contribution_ids": [
                "R26280"
            ]
        },
        {
            "instance_id": "R26352xR26288",
            "comparison_id": "R26352",
            "paper_id": "R26288",
            "text": "A Location Based Heuristic for General Routing Problems we present a general framework for modeling routing problems based on formulating them as a traditional location problem called the capacitated concentrator location problem. we apply this framework to two classical routing problems: the capacitated vehicle routing problem and the inventory routing problem. in the former case, the heuristic is proven to be asymptotically optimal for any distribution of customer demands and locations. computational experiments show that the heuristic performs well for both problems and, in most cases, outperforms all published heuristics on a set of standard test problems.",
            "contribution_ids": [
                "R26289"
            ]
        },
        {
            "instance_id": "R26352xR26302",
            "comparison_id": "R26352",
            "paper_id": "R26302",
            "text": "Probabilistic Analyses and Algorithms for Three-Level Distribution Systems we consider the problem of integrating inventory control and vehicle routing into a cost-effective strategy for a distribution system consisting of a single outside vendor, a fixed number of warehouses and many geographically dispersed retailers. each retailer faces a constant, retailer specific, demand rate and inventory holding cost is charged at the retailers and the warehouses. we show that, in an effective strategy which minimizes the asymptotic long run average cost, each warehouse receives fully loaded trucks from the vendor but never holds inventory. that is, each warehouse serves only as a coordinator of the frequency, time and sizes of deliveries to the retailers. this insight is used to construct an inventory control policy and vehicle routing strategy for multi-echelon distribution systems. computational results are also reported.",
            "contribution_ids": [
                "R26303"
            ]
        },
        {
            "instance_id": "R26352xR26321",
            "comparison_id": "R26352",
            "paper_id": "R26321",
            "text": "Dynamic Programming Approximations for a Stochastic Inventory Routing Problem this work is motivated by the need to solve the inventory routing problem when implementing a business practice called vendor managed inventory replenishment (vmi). with vmi, vendors monitor their customers\u2032 inventories and decide when and how much inventory should be replenished at each customer. the inventory routing problem attempts to coordinate inventory replenishment and transportation in such a way that the cost is minimized over the long run. we formulate a markov decision process model of the stochastic inventory routing problem and propose approximation methods to find good solutions with reasonable computational effort. we indicate how the proposed approach can be used for other markov decision processes involving the control of multiple resources.",
            "contribution_ids": [
                "R26322"
            ]
        },
        {
            "instance_id": "R26352xR26336",
            "comparison_id": "R26352",
            "paper_id": "R26336",
            "text": "The storage constrained, inbound inventory routing problem purpose this paper aims to describe the storage constrained, inbound inventory routeing problem and presents bounds and heuristics for solutions to this problem. it also seeks to analyze various characteristics of this problem by comparing the solutions generated by the two proposed heuristics with each other and with the lower bound solutions. design/methodology/approach the proposed heuristics use a sequential decomposition strategy for generating solutions for this problem. these heuristics are evaluated on a set of problem instances which are based on an actual application in the automotive manufacturing industry. findings the storage space clearly has a significant effect on both the routeing and inventory decisions, and there are complex and interesting interactions between the problem factors and performance measures. practical implications facility design decisions for the storage of inbound materials should carefully consider the impact of storage space on transportation and logistics costs. originality/value this problem occurs in a number of different industrial applications while most of the existing literature addresses outbound distribution. other papers that address similar problems do not consider all of the practical constraints in the problem or do not adequately benchmark and analyze their proposed solutions.",
            "contribution_ids": [
                "R26337"
            ]
        },
        {
            "instance_id": "R26377xR26359",
            "comparison_id": "R26377",
            "paper_id": "R26359",
            "text": "Reducing Logistics Costs at General Motors \" automobile and truck production at general motors involves shipping a broad variety of materials, parts, and components from 20,000 supplier plants to over 160 gm plants. to help reduce logistics costs at gm, the decision tool transpart was developed. in its initial application for gm's delco electronics division, transpart identified a 26 percent logistics cost savings opportunity ($2.9 million per year). today, transpart ii\u2014a commercial version of the tool\u2014is being used in more than 40 gm plants. \"",
            "contribution_ids": [
                "R26360"
            ]
        },
        {
            "instance_id": "R26421xR26399",
            "comparison_id": "R26421",
            "paper_id": "R26399",
            "text": "Production of Two Chitosanases from a Chitosan-Assimilating Bacterium, Acinetobacter sp. Strain CHB101. a bacterial strain capable of utilizing chitosan as a sole carbon source was isolated from soil and was identified as a member of the genus acinetobacter. this strain, designated chb101, produced extracellular chitosan-degrading enzymes in the absence of chitosan. the chitosan-degrading activity in the culture fluid increased when cultures reached the early stationary phase, although the level of activity was low in the exponential growth phase. two chitosanases, chitosanases i and ii, which had molecular weights of 37,000 and 30,000, respectively, were purified from the culture fluid. chitosanase i exhibited substrate specificity for chitosan that had a low degree of acetylation (10 to 30%), while chitosanase ii degraded colloidal chitin and glycol chitin, as well as chitosan that had a degree of acetylation of 30%. rapid decreases in the viscosities of chitosan solutions suggested that both chitosanases catalyzed an endo type of cleavage reaction; however, chitosan oligomers (molecules smaller than pentamers) were not produced after a prolonged reaction.",
            "contribution_ids": [
                "R26400"
            ]
        },
        {
            "instance_id": "R26421xR26403",
            "comparison_id": "R26421",
            "paper_id": "R26403",
            "text": "Purification and Mode of Action of Chitosanolytic Enzyme fromEnterobactersp. G-1 a chitosanolytic enzyme was purified from enterobacter sp. g-1 by fractionation of 30% saturation with ammonium sulfate, isoelectric focusing, and sephadex g-100 gel chromatography. the purified enzyme. showed a single band on sodium dodecyl sulfate polyacrylamide gel electrophoresis, and the molecular mass was estimated to be 50 kda. the enzyme degraded n-acetyl-chitooligosaccharides, glycol chitin, colloidal chitin, and colloidal chitosan (about 80% deacetylated), but did not degrade chitooligosaccharides, colloidal chitosan (100% deacetylated), or micrococcus lysodeikticus cell walls. it hydrolyzed glcnac4\u20136 and colloidal chitin to glcnac2, finally. the main cleavage site with glcnac3\u20136 was the second linkage from the non-reducing end, based on the pattern of pnp-glcnac2\u20135. colloidal chitosan was hydrolyzed to glcnac2 and to similar partially n-acetylated chitooligosaccharides.",
            "contribution_ids": [
                "R26404"
            ]
        },
        {
            "instance_id": "R26421xR26405",
            "comparison_id": "R26421",
            "paper_id": "R26405",
            "text": "Purification, Characterization, and Gene Analysis of a Chitosanase (ChoA) from Matsuebacter chitosanotabidus3001 abstract \\n \\n the extracellular chitosanase (34,000\\n m \\n r \\n ) produced by a novel gram-negative bacterium\\n matsuebacter chitosanotabidus \\n 3001 was purified. the optimal ph of this chitosanase was 4.0, and the optimal temperature was between 30 and 40\u00b0c. the purified chitosanase was most active on 90% deacetylated colloidal chitosan and glycol chitosan, both of which were hydrolyzed in an endosplitting manner, but this did not hydrolyze chitin, cellulose, or their derivatives. among potential inhibitors, the purified chitosanase was only inhibited by ag\\n + \\n . internal amino acid sequences of the purified chitosanase were obtained. a pcr fragment corresponding to one of these amino acid sequences was then used to screen a genomic library for the entire\\n choa \\n gene encoding chitosanase. sequencing of the\\n choa \\n gene revealed an open reading frame encoding a 391-amino-acid protein. the n-terminal amino acid sequence had an excretion signal, but the sequence did not show any significant homology to other proteins, including known chitosanases. the 80-amino-acid excretion signal of choa fused to green fluorescent protein was functional in\\n escherichia coli \\n . taken together, these results suggest that we have identified a novel, previously unreported chitosanase.\\n",
            "contribution_ids": [
                "R26406"
            ]
        },
        {
            "instance_id": "R26421xR26413",
            "comparison_id": "R26421",
            "paper_id": "R26413",
            "text": "An Aspergillus chitosanase with potential for large-scale preparation of chitosan oligosaccharides a chitosan\u2010degrading fungus, designated aspergillus sp. y2k, was isolated from soil. the micro\u2010organism was used for producing chitosanase (ec 3.2.1.132) in a minimal medium containing chitosan as the sole carbon source. the induced chitosanase was purified to homogeneity from the culture filtrate by concentration and cationic sp\u2010sepharose chromatography. the purified enzyme is a monomer with an estimated molecular mass of 25 kda by sds/page and of 22 kda by gel\u2010filtration chromatography. pi, optimum ph and optimum temperature values were 8.4, 6.5 and 65\u201370 \u00b0c, respectively. the chitosanase is stable in the ph range from 4 to 7.5 at 55 \u00b0c. higher deacetylated chitosan is a better substrate. chitin, xylan, 6\u2010o \u2010sulphated chitosan and o \u2010carboxymethyl chitin were indigestible by the purified enzyme. by endo\u2010splitting activity, the chitosanase hydrolysed chitosan to form chitosan oligomers with chitotriose, chitotetraose and chitopentaose as the major products. the enzyme hydrolyses chitohexaose to form chitotriose, while the chitopentaose and shorter oligomers remain intact. the n\u2010terminal amino acid sequence of the enzyme was determined as ynlpnnlkqiyddhk, which provides useful information for further gene cloning of this enzyme. a 275 g\u2010scale hydrolysis of chitosan was performed. the product distribution was virtually identical to that of the small\u2010scale reaction. owing to the simple purification process and high stability of the enzyme, it is potentially valuable for industrial applications.",
            "contribution_ids": [
                "R26414"
            ]
        },
        {
            "instance_id": "R26550xR26435",
            "comparison_id": "R26550",
            "paper_id": "R26435",
            "text": "Um sistema simples para prepara\u00c3\u00a7\u00c3\u00a3o de microesferas de quitosana this article describes the construction and optimization of an inexpensive apparatus for the production of uniform and porous chitosan microspheres. it also describes the control of the main operational parameters and strategies for the production of uniform chitosan microspheres.",
            "contribution_ids": [
                "R26436"
            ]
        },
        {
            "instance_id": "R26550xR26471",
            "comparison_id": "R26550",
            "paper_id": "R26471",
            "text": "Antidiabetic Effects of Chitosan Oligosaccharides in Neonatal Streptozotocin-Induced Noninsulin-Dependent Diabetes Mellitus in Rats the antidiabetic effect of chitosan oligosaccharide (cos) was investigated in neonatal streptozotocin (stz)-induced noninsulin-dependent diabetes mellitus rats. the fasting glucose level was reduced by about 19% in diabetic rats after treatment with 0.3% cos. glucose tolerance was lower in the diabetic group compared with the normal group. after diabetic rats had been treated with 0.3% cos for 4 weeks, glucose tolerance increased significantly versus the diabetic control group, and glucose-inducible insulin expression increased significantly. in addition, fed-triglyceride (tg) levels in diabetic rats drinking 0.3% cos were reduced by 49% compared with those in diabetic control rats. the cholesterol levels of animals treated with cos were reduced by about 10% in fed or fasting conditions versus the corresponding controls, although the difference was not statistically significant. it was found that cos has a tg-lowering effect in diabetic rats, and that cos reduces signs of diabetic cardiomyopathy such as vacuolation of mitochondria and the separation and degeneration of myofibrils. in conclusion, these results indicate that cos can be used as an antidiabetic agent because it increases glucose tolerance and insulin secretion and decreases tg.",
            "contribution_ids": [
                "R26472"
            ]
        },
        {
            "instance_id": "R26550xR26477",
            "comparison_id": "R26550",
            "paper_id": "R26477",
            "text": "Chitosan Induces Apoptosis via Caspase-3 Activation in Bladder Tumor Cells recently, because of its low toxicity and biological effects, chitosan has been widely used in the medical and pharmaceutical fields, e.g., for nasal or oral delivery of peptide or polar drug delivery. here, we report a growth\u2010inhibitory effect of chitosan on tumor cells. the growth inhibition was examined by wst\u20101 colorimetric assay and cell counting. we also observed dna fragmentation, which is characteristic of apoptosis, and elevated caspase\u20103\u2010like activity in chitosan\u2010treated cancer cells. the findings suggest that chitosan may have potential value in cancer therapy.",
            "contribution_ids": [
                "R26478"
            ]
        },
        {
            "instance_id": "R26550xR26489",
            "comparison_id": "R26550",
            "paper_id": "R26489",
            "text": "EFFECTS OF SHRIMP (MACROBRACIUM ROSENBERGII)-DERIVED CHITOSAN ON PLASMA LIPID PROFILE AND LIVER LIPID PEROXIDE LEVELS IN NORMO- AND HYPERCHOLESTEROLAEMIC RATS 1 the effects of chitosan (cs) derived from the exoskeleton of the shrimp macrobracium rosenbergii on bodyweight, plasma lipid profile, fatty acid composition, liver lipid peroxide (lpo) levels and plasma levels of glutamate pyruvate transaminase (gpt) were determined in normocholesterolaemic (nc) and hypercholesterolaemic (hc) long evans rats. 2 the nc rats were fed a diet containing 2% cs and the hc rats were fed a diet containing 2 and 4% cs for 8 weeks. chitosan significantly reduced bodyweight gain only in hc + 4% cs rats compared with hc rats, but not in nc + 2% cs or hc + 2% cs rats. 3 chitosan reduced plasma total cholesterol in the hc + 2% cs, hc + 4% cs and nc + 2% cs rats; however, low density lipoprotein\u2013cholesterol decreased only in the first two groups. high\u2010density lipoprotein\u2013cholesterol (hdl\u2010c) increased in the hc + 4% cs rats by 24% compared with the hc + 2% cs group and by 30% compared with hc rats; however, hdl\u2010c did not increase in the nc + 2% cs group compared with nc rats. the level of plasma triglycerides decreased significantly only in hc + 2% cs rats compared with hc rats. 4 chitosan significantly decreased plasma levels of arachidonic acid in the hc + 2% cs and hc + 4% cs groups, with a concurrent increase in the molar ratio of total unsaturated fatty acid (tufa) to total saturated fatty acid (tsfa). 5 moreover, cs increased liver lpo levels without affecting plasma levels of gpt. liver lpo levels were positively correlated with the tufa/tsfa molar ratio. 6 the present study suggests that dietary cs decreases the atherogenic lipid profiles of both nc and hc rats and reduces the bodyweight gain of hc rats.",
            "contribution_ids": [
                "R26490"
            ]
        },
        {
            "instance_id": "R26550xR26524",
            "comparison_id": "R26550",
            "paper_id": "R26524",
            "text": "Antimicrobial actions of degraded and native chitosan against spoilage organisms in laboratory media and foods abstract \\n the objective of this study was to determine whether chitosan (poly-\u03b2-1,4-glucosamine) and hydrolysates of chitosan can be used as novel preservatives in foods. chitosan was hydrolyzed by using oxidative-reductive degradation, crude papaya latex, and lysozyme. mild hydrolysis of chitosan resulted in improved microbial inactivation in saline and greater inhibition of growth of several spoilage yeasts in laboratory media, but highly degraded products of chitosan exhibited no antimicrobial activity. in pasteurized apple-elderflower juice stored at 7\u00b0c, addition of 0.3 g of chitosan per liter eliminated yeasts entirely for the duration of the experiment (13 days), while the total counts and the lactic acid bacterial counts increased at a slower rate than they increased in the control. addition of 0.3 or 1.0 g of chitosan per kg had no effect on the microbial flora of houmous, a chickpea dip; in the presence of 5.0 g of chitosan per kg, bacterial growth but not yeast growth was substantially reduced compared with growth in control dip stored at 7\u00b0c for 6 days. improved antimicrobial potency of chitosan hydrolysates like that observed in the saline and laboratory medium experiments was not observed in juice and dip experiments. we concluded that native chitosan has potential for use as a preservative in certain types of food but that the increase in antimicrobial activity that occurs following partial hydrolysis is too small to justify the extra processing involved.",
            "contribution_ids": [
                "R26525"
            ]
        },
        {
            "instance_id": "R26550xR26527",
            "comparison_id": "R26550",
            "paper_id": "R26527",
            "text": "Antimicrobial Edible Films and Coatings increasing consumer demand for microbiologicallysafer foods, greater convenience,smaller packages, and longer product shelf life is forcing the industry to develop new food-processing,cooking, handling, and packaging strategies. nonfluid ready-to-eat foods are frequently exposed to postprocess surface contamination, leading to a reduction in shelf life. the food industry has at its disposal a wide range of nonedible polypropylene- and polyethylene-based packaging materials and various biodegradable protein- and polysaccharide-based edible films that can potentially serve as packaging materials. research on the use of edible films as packaging materials continues because of the potential for these films to enhance food quality, food safety, and product shelf life. besides acting as a barrier against mass diffusion (moisture, gases, and volatiles), edible films can serve as carriers for a wide range of food additives, including flavoring agents, antioxidants, vitamins, and colorants. when antimicrobial agents such as benzoic acid, sorbic acid, propionic acid, lactic acid, nisin, and lysozyme have been incorporated into edible films, such films retarded surface growth of bacteria, yeasts, and molds on a wide range of products, including meats and cheeses. various antimicrobial edible films have been developed to minimize growth of spoilage and pathogenic microorganisms, including listeria monocytogenes, which may contaminate the surface of cooked ready-to-eat foods after processing. here, we review the various types of protein-based (wheat gluten, collagen, corn zein, soy, casein, and whey protein), polysaccharide-based (cellulose, chitosan, alginate, starch, pectin, and dextrin), and lipid-based (waxes, acylglycerols, and fatty acids) edible films and a wide range of antimicrobial agents that have been or could potentially be incorporated into such films during manufacture to enhance the safety and shelf life of ready-to-eat foods.",
            "contribution_ids": [
                "R26528"
            ]
        },
        {
            "instance_id": "R26654xR26624",
            "comparison_id": "R26654",
            "paper_id": "R26624",
            "text": "APTEEN: a hybrid protocol for efficient routing and comprehensive information retrieval in wireless wireless sensor networks with thousands of tiny sensor nodes, are expected to find wide applicability and increasing deployment in coming years, as they enable reliable monitoring and analysis of the environment. in this paper, we propose a hybrid routing protocol (apteen) which allows for comprehensive information retrieval. the nodes in such a network not only react to time-critical situations, but also give an overall picture of the network at periodic intervals in a very energy efficient manner. such a network enables the user to request past, present and future data from the network in the form of historical, one-time and persistent queries respectively. we evaluated the performance of these protocols and observe that these protocols are observed to outperform existing protocols in terms of energy consumption and longevity of the network.",
            "contribution_ids": [
                "R26625"
            ]
        },
        {
            "instance_id": "R26654xR26631",
            "comparison_id": "R26654",
            "paper_id": "R26631",
            "text": "Low energy adaptive clustering hierarchy with deterministic cluster-head selection \"this paper focuses on reducing the power consumption of wireless microsensor networks. therefore, a communication protocol named leach (low-energy adaptive clustering hierarchy) is modified. we extend leach's stochastic cluster-head selection algorithm by a deterministic component. depending on the network configuration an increase of network lifetime by about 30% can be accomplished. furthermore, we present a new approach to define lifetime of microsensor networks using three new metrics fnd (first node dies), hna (half of the nodes alive), and lnd (last node dies).\"",
            "contribution_ids": [
                "R26632"
            ]
        },
        {
            "instance_id": "R26654xR26652",
            "comparison_id": "R26654",
            "paper_id": "R26652",
            "text": "Distance based thresholds for cluster head selection in wireless sensor networks central to the cluster-based routing protocols is the cluster head (ch) selection procedure that allows even distribution of energy consumption among the sensors, and therefore prolonging the lifespan of a sensor network. we propose a distributed ch selection algorithm that takes into account the distances from sensors to a base station that optimally balances the energy consumption among the sensors. ns-2 simulations show that our proposed scheme outperforms existing algorithms in terms of the average node lifespan and the time to first node death.",
            "contribution_ids": [
                "R26653"
            ]
        },
        {
            "instance_id": "R26729xR26679",
            "comparison_id": "R26729",
            "paper_id": "R26679",
            "text": "Distributed clustering with directional antennas for wireless sensor networks this paper proposes a decentralized algorithm for organizing an ad hoc sensor network into clusters with directional antennas. the proposed autonomous clustering scheme aims to reduce the sensing redundancy and maintain sufficient sensing coverage and network connectivity in sensor networks. with directional antennas, random waiting timers, and local criterions, cluster performance may be substantially improved and sensing redundancy can be drastically suppressed. the simulation results show that the proposed scheme achieves connected coverage and provides efficient network topology management.",
            "contribution_ids": [
                "R26680"
            ]
        },
        {
            "instance_id": "R26729xR26704",
            "comparison_id": "R26729",
            "paper_id": "R26704",
            "text": "A centralized energy-efficient routing protocol for wireless sensor networks wireless sensor networks consist of small battery powered devices with limited energy resources. once deployed, the small sensor nodes are usually inaccessible to the user, and thus replacement of the energy source is not feasible. hence, energy efficiency is a key design issue that needs to be enhanced in order to improve the life span of the network. several network layer protocols have been proposed to improve the effective lifetime of a network with a limited energy supply. in this article we propose a centralized routing protocol called base-station controlled dynamic clustering protocol (bcdcp), which distributes the energy dissipation evenly among all sensor nodes to improve network lifetime and average energy savings. the performance of bcdcp is then compared to clustering-based schemes such as low-energy adaptive clustering hierarchy (leach), leach-centralized (leach-c), and power-efficient gathering in sensor information systems (pegasis). simulation results show that bcdcp reduces overall energy consumption and improves network lifetime over its comparatives.",
            "contribution_ids": [
                "R26705"
            ]
        },
        {
            "instance_id": "R26729xR26727",
            "comparison_id": "R26729",
            "paper_id": "R26727",
            "text": "LCM: A Link-Aware Clustering Mechanism for Energy-Efficient Routing in Wireless Sensor Networks in wireless sensor networks, nodes in the area of interest must report sensing readings to the sink, and this report always satisfies the report frequency required by the sink. this paper proposes a link-aware clustering mechanism, called lcm, to determine an energy-efficient and reliable routing path. the lcm primarily considers node status and link condition, and uses a novel clustering metric called the predicted transmission count (ptx), to evaluate the qualification of nodes for clusterheads and gateways to construct clusters. each clusterhead or gateway candidate depends on the ptx to derive its priority, and the candidate with the highest priority becomes the clusterhead or gateway. simulation results validate that the proposed lcm significantly outperforms the clustering mechanisms using random selection and by considering only link quality and residual energy in the packet delivery ratio, energy consumption, and delivery latency.",
            "contribution_ids": [
                "R26728"
            ]
        },
        {
            "instance_id": "R26775xR26739",
            "comparison_id": "R26775",
            "paper_id": "R26739",
            "text": "PRODUCE: A Probability-Driven Unequal Clustering Mechanism for Wireless Sensor Networks there has been proliferation of research on seeking for distributing the energy consumption among nodes in each cluster and between cluster heads to extend the network lifetime. however, they hardly consider the hot spots problem caused by heavy relay traffic forwarded. in this paper, we propose a distributed and randomized clustering algorithm that consists of unequal sized clusters. the cluster heads closer to the base station may focus more on inter-cluster communication while distant cluster heads concentrate more on intra-cluster communication. as a result, it nearly guarantees no communication in the network gets excessively long communication distance that significantly attenuates signal strength. simulation results show that our algorithm achieves abundant improvement in terms of the coverage time and network lifetime, especially when the density of distributed nodes is high.",
            "contribution_ids": [
                "R26740"
            ]
        },
        {
            "instance_id": "R26775xR26754",
            "comparison_id": "R26775",
            "paper_id": "R26754",
            "text": "An Energy-Aware Distributed Unequal Clustering Protocol for Wireless Sensor Networks due to the imbalance of energy consumption of nodes in wireless sensor networks (wsns), some local nodes die prematurely, which causes the network partitions and then shortens the lifetime of the network. the phenomenon is called \u201chot spot\u201d or \u201cenergy hole\u201d problem. for this problem, an energy-aware distributed unequal clustering protocol (eaduc) in multihop heterogeneous wsns is proposed. compared with the previous protocols, the cluster heads obtained by eaduc can achieve balanced energy, good distribution, and seamless coverage for all the nodes. moreover, the complexity of time and control message is low. simulation experiments show that eaduc can prolong the lifetime of the network significantly.",
            "contribution_ids": [
                "R26755"
            ]
        },
        {
            "instance_id": "R26775xR26757",
            "comparison_id": "R26775",
            "paper_id": "R26757",
            "text": "Unequal clustering scheme based leach for wireless sensor networks clustering technique is an effective topology control approach which can improve the scalability and lifetime in wireless sensor networks (wsns). leach is a classical clustering algorithm for low energy scheme, however, it still have some deficiencies. this paper studies leach protocol, and put an improved leach protocol which has more reasonable set-up phase. in the cluster heads election phase, we put the energy ratio and competition distance as two elements to join the cluster head election. simulation results demonstrate that improved leach algorithm has better energy balance and prolong network lifetime.",
            "contribution_ids": [
                "R26758"
            ]
        },
        {
            "instance_id": "R26850xR26819",
            "comparison_id": "R26850",
            "paper_id": "R26819",
            "text": "The Heterogeneous Vehicle-Routing Game in this paper, we study a cost-allocation problem that arises in a distribution-planning situation at the logistics department at norsk hydro olje ab, stockholm, sweden. we consider the routes from one depot during one day. the total distribution cost for these routes is to be divided among the customers that are visited. this cost-allocation problem is formulated as a vehicle-routing game (vrg), allowing the use of vehicles with different capacities. cost-allocation methods based on different concepts from cooperative game theory, such as the core and the nucleolus, are discussed. a procedure that can be used to investigate whether the core is empty or not is presented, as well as a procedure to compute the nucleolus. computational results for the norsk hydro case are presented and discussed.",
            "contribution_ids": [
                "R26820"
            ]
        },
        {
            "instance_id": "R26850xR26839",
            "comparison_id": "R26850",
            "paper_id": "R26839",
            "text": "Valid inequalities for the fleet size and mix vehicle routing problem with fixed costs in the well\u2010known vehicle routing problem (vrp), a set of identical vehicles located at a central depot is to be optimally routed to supply customers with known demands subject to vehicle capacity constraints. an important variant of the vrp arises when a mixed fleet of vehicles, characterized by different capacities and costs, is available for distribution activities. the problem is known as fleet size and mix vrp with fixed costs fsmf and has several practical applications. in this article, we present a new mixed integer programming formulation for fsmf based on a two\u2010commodity network flow approach. new valid inequalities are proposed to strengthen the linear programming relaxation of the mathematical formulation. the effectiveness of the proposed cuts is extensively tested on benchmark instances. \u00a9 2009 wiley periodicals, inc. networks, 2009",
            "contribution_ids": [
                "R26840"
            ]
        },
        {
            "instance_id": "R26918xR26906",
            "comparison_id": "R26918",
            "paper_id": "R26906",
            "text": "Heuristic Approaches for the Fleet Size and Mix Vehicle Routing Problem with Time Windows the fleet size and mix vehicle routing problem with time windows (fsmvrptw) is the problem of determining, at the same time, the composition and the routing of a fleet of heterogeneous vehicles aimed to serve a given set of customers. the routing problem requires us to design a set of minimum-cost routes originating and terminating at a central depot and serving customers with known demands, within given time windows. this paper develops a constructive insertion heuristic and a metaheuristic algorithm for fsmvrptw. extensive computational experiments on benchmark instances show that the proposed method is robust and efficient, and outperforms the previously published results.",
            "contribution_ids": [
                "R26907"
            ]
        },
        {
            "instance_id": "R26918xR26910",
            "comparison_id": "R26918",
            "paper_id": "R26910",
            "text": "An Effective Multirestart Deterministic Annealing Metaheuristic for the Fleet Size and Mix Vehicle-Routing Problem with Time Windows this paper presents a new deterministic annealing metaheuristic for the fleet size and mix vehicle-routing problem with time windows. the objective is to service, at minimal total cost, a set of customers within their time windows by a heterogeneous capacitated vehicle fleet. first, we motivate and define the problem. we then give a mathematical formulation of the most studied variant in the literature in the form of a mixed-integer linear program. we also suggest an industrially relevant, alternative definition that leads to a linear mixed-integer formulation. the suggested metaheuristic solution method solves both problem variants and comprises three phases. in phase 1, high-quality initial solutions are generated by means of a savings-based heuristic that combines diversification strategies with learning mechanisms. in phase 2, an attempt is made to reduce the number of routes in the initial solution with a new local search procedure. in phase 3, the solution from phase 2 is further improved by a set of four local search operators that are embedded in a deterministic annealing framework to guide the improvement process. some new implementation strategies are also suggested for efficient time window feasibility checks. extensive computational experiments on the 168 benchmark instances have shown that the suggested method outperforms the previously published results and found 167 best-known solutions. experimental results are also given for the new problem variant.",
            "contribution_ids": [
                "R26911"
            ]
        },
        {
            "instance_id": "R26982xR26929",
            "comparison_id": "R26982",
            "paper_id": "R26929",
            "text": "A Decision Support System for Fleet Management: A Linear Programming Approach this paper describes a successful implementation of a decision support system that is used by the fleet management division at north american van lines to plan fleet configuration. at the heart of the system is a large linear programming (lp) model that helps management decide what type of tractors to sell to owner/operators or to trade in each week. the system is used to answer a wide variety of \u201cwhat if\u201d questions, many of which have significant financial impact.",
            "contribution_ids": [
                "R26930"
            ]
        },
        {
            "instance_id": "R26982xR26936",
            "comparison_id": "R26982",
            "paper_id": "R26936",
            "text": "Vehicle fleet planning the road transportation industry planning the composition of a vehicle fleet in order to satisfy transportation service demands is an important resource management activity for any trucking company. its complexity is such, however, that formal fleet management cannot be done adequately without the help of a decision support system. an important part of such a system is the generation of minimal discounted cost plans covering the purchase, replacement, sale, and/or rental of the vehicles necessary to deal with a seasonal stochastic demand. a stochastic programming model is formulated to address this problem. it reduces to a separable program based on information about the service demand, the state of the current fleet, and the cash flows generated by an acquisition/disposal plan. an efficient algorithm for solving the model is also presented. the discussion concerns the operations of a number of canadian road carriers. >",
            "contribution_ids": [
                "R26937"
            ]
        },
        {
            "instance_id": "R27039xR26987",
            "comparison_id": "R27039",
            "paper_id": "R26987",
            "text": "An Industrial Ocean-Cargo Shipping Problem this paper reports the modeling and solution of an industrial ocean-cargo shipping problem. the problem involves the delivery of bulk products from an overseas port to transshipment ports on the atlantic coast, and then over land to customers. the decisions made include the number and the size of ships to charter in each time period during the planning horizon, the number and location of transshipment ports to use, and transportation from ports to customers. the complexity of this problem is compounded by the cost structure, which includes fixed charges in both ship charters and port operations. such a large scale, dynamic, and stochastic problem is reduced to a solvable stationary, deterministic, and cyclical model. the process of modeling the problem and the solution of the resultant mixed integer program are described in detail. recommendations from this study have been implemented.",
            "contribution_ids": [
                "R26988"
            ]
        },
        {
            "instance_id": "R27039xR27002",
            "comparison_id": "R27039",
            "paper_id": "R27002",
            "text": "Scheduling short-term marine transport of bulk products a multinational company uses a personal computer to schedule a fleet of coastal tankers and barges transporting liquid bulk products among plants, distribution centres (tank farms), and industrial customers. a simple spreadsheet interface cloaks a sophisticated optimization-based decision support system and makes this system useable via a varity of natural languages. the dispatchers, whose native language is not english, and some of whom presumably speak no english at all, communicate via the spreadsheet, and view recommended schedules displayed in gantt charts both internationally familiar tools. inside the spreadsheet, a highly detailed simulation can generate every feasible alternate vessel employment schedule, and an integer linear set partitioning model selects one schedule for each vessel so that all loads and deliveries are completed at minimal cost while satisfying all operational requirements. the optimized fleet employment schedule is displyed graphically with hourly time resolution over a planning horizon of 2-3 weeks. each vessel will customarily make several voyages and many port calls to load and unload products during this time.",
            "contribution_ids": [
                "R27003"
            ]
        },
        {
            "instance_id": "R27039xR27005",
            "comparison_id": "R27039",
            "paper_id": "R27005",
            "text": "Fleet management models and algorithms for an oil-tanker routing and scheduling problem this paper explores models and algorithms for routing and scheduling ships in a maritime transportation system. the principal thrust of this research effort is focused on the kuwait petroleum corporation (kpc) problem. this problem is of great economic significance to the state of kuwait, whose economy has been traditionally dominated to a large extent by the oil sector, and any enhancement in the existing ad-hoc scheduling procedure has the potential for significant savings. a mixed-integer programming model for the kpc problem is constructed in this paper. the resulting mathematical formulation is rather complex to solve due to the integrality conditions and the overwhelming size of the problem for a typical demand contract scenario. consequently, an alternate aggregate model that retains the principal features of the kpc problem is formulated. the latter model is computationally far more tractable than the initial model, and a specialized rolling horizon heuristic is developed to solve it. the proposed heuristic procedure enables us to derive solutions for practical sized problems that could not be handled by directly solving even the aggregate model. the initial formulation is solved using cplex-4.0-mip capabilities for a number of relatively small-sized test cases, whereas for larger problem instances, the aggregate formulation is solved using cplex-4.0-mip in concert with the developed rolling horizon heuristic, and related results are reported. an ad-hoc routing procedure that is intended to simulate the current kpc scheduling practice is also described and implemented. the results demonstrate that the proposed approach substantially improves upon the results obtained using the current scheduling practice at kpc.",
            "contribution_ids": [
                "R27006"
            ]
        },
        {
            "instance_id": "R27039xR27027",
            "comparison_id": "R27039",
            "paper_id": "R27027",
            "text": "Ship Routing and Scheduling: Status and Perspectives the objective of this paper is to review the current status of ship routing and scheduling. we focus on literature published during the last decade. because routing and scheduling problems are closely related to many other fleet planning problems, we have divided this review into several parts. we start at the strategic fleet planning level and discuss the design of fleets and sea transport systems. we continue with the tactical and operational fleet planning level and consider problems that comprise various ship routing and scheduling aspects. here, we separately discuss the different modes of operations: industrial, tramp, and liner shipping. finally, we take a glimpse at naval applications and other related problems that do not naturally fall into these categories. the paper also presents some perspectives regarding future developments and use of optimization-based decision-support systems for ship routing and scheduling. several of the trends indicate both accelerating needs for and benefits from such systems and, hopefully, this paper will stimulate further research in this area.",
            "contribution_ids": [
                "R27028"
            ]
        },
        {
            "instance_id": "R27061xR27057",
            "comparison_id": "R27061",
            "paper_id": "R27057",
            "text": "Smart City Development: A Business Process-centric Conceptualisation smart city development has been proposed as a response to urbanisation challenges and changing citizen \\nneeds in the cities. it allows the city as a complex system of systems to be efficient and integrated, in order to \\nwork as a whole, and provide effective services to citizens through its inter-connected sector. this research \\nattempts to conceptualise smart city, by looking at its requirements and components from a process change \\nperspective, not a merely technology-led innovation within a city. in view of that, the research also gains \\nbenefits from the principles of smart city development such as systems thinking approach, city as a system of \\nsystems, and the necessity of systems integration. the outcome of this study emphasises the significance of \\nconsidering a city as a system of systems and necessity of city systems integration and city process change \\nfor smart city development. consequently, the research offers a city process-centric conceptualisation of smart \\ncity.",
            "contribution_ids": [
                "R27058"
            ]
        },
        {
            "instance_id": "R27061xR27059",
            "comparison_id": "R27061",
            "paper_id": "R27059",
            "text": "Using cloud technologies for large-scale house data in smart city in the smart city environment, a wide variety of data are collected from sensors and devices to achieve value-added services. in this paper, we especially focus on data taken from smart houses in the smart city, and propose a platform, called scallop4sc, that stores and processes the large-scale house data. the house data is classified into log data or configuration data. since the amount of the log is extremely large, we introduce the hadoop/mapreduce with a multi-node cluster. on top of this, we use hbase key-value store to manage heterogeneous log data in a schemaless manner. on the other hand, to manage the configuration data, we choose mysql to process various queries to the house data efficiently. we propose practical data models of the log data and the configuration data on hbase and mysql, respectively. we then show how scallop4sc works as a efficient data platform for smart city services. we implement a prototype with 12 linux servers. we conduct an experimental evaluation to calculate device-wise energy consumption, using actual house log recorded for one year in our smart house. based on the result, we discuss the applicability of scallop4sc to city-scale data processing.",
            "contribution_ids": [
                "R27060"
            ]
        },
        {
            "instance_id": "R27235xR27168",
            "comparison_id": "R27235",
            "paper_id": "R27168",
            "text": "Exchange Rate Volatility and International Prices \"we examine how exchange rate volatility affects exporter's pricing decisions in the presence of optimal forward covering. by taking account of forward covering, we are able to derive an expression for the risk premium in the foreign exchange market, which is then estimated as a generalized arch model to obtain the time-dependent variance of the exchange rate. our theory implies a connection between the estimated risk premium equation, and the influence of exchange rate volatility on export prices. in particular, we argue that if there is no risk premium, then exchange rate variance can only have a negative impact on export prices. in the presence of a risk premium, however, the effect of exchange rate variance on export prices is ambiguous, and may be statistically insignificant with aggregate data. these results are supported using data on aggregate u.s. imports and exchange rates of the dollar against the pound. yen and mark.\"",
            "contribution_ids": [
                "R27169"
            ]
        },
        {
            "instance_id": "R27235xR27190",
            "comparison_id": "R27235",
            "paper_id": "R27190",
            "text": "Does Exchange Rate Volatility Depress Trade Flows? Evidence from Error- Correction Models this paper examines the impact of exchange rate volatility on the trade flows of the g-7 countries in the context of a multivariate error-correction model. the error-correction models do not show any sign of parameter instability. the results indicate that the exchange rate volatility has a significant negative impact on the volume of exports in each of the g-7 countries. assuming market participants are risk averse, these results imply that exchange rate uncertainty causes them to reduce their activities, change prices, or shift sources of demand and supply in order to minimize their exposure to the effects of exchange rate volatility. this, in turn, can change the distribution of output across many sectors in these countries. it is quite possible that the surprisingly weak relationship between trade flows and exchange rate volatility reported in several previous studies are due to insufficient attention to the stochastic properties of the relevant time series. copyright 1993 by mit press.",
            "contribution_ids": [
                "R27191"
            ]
        },
        {
            "instance_id": "R27235xR27209",
            "comparison_id": "R27235",
            "paper_id": "R27209",
            "text": "Estimating the impact of exchange rate volatility on exports: evidence from Asian countries the paper examines the impact of exchange rate volatility on the exports of five asian countries. the countries are turkey, south korea, malaysia, indonesia and pakistan. the impact of a volatility term on exports is examined by using an engle-granger residual-based cointegrating technique. the results indicate that the exchange rate volatility reduced real exports for these countries. this might mean that producers in these countries are risk-averse. the producers will prefer to sell in domestic markets rather than foreign markets if the exchange rate volatility increases.",
            "contribution_ids": [
                "R27210"
            ]
        },
        {
            "instance_id": "R27235xR27220",
            "comparison_id": "R27235",
            "paper_id": "R27220",
            "text": "On the Trade Impact of Nominal Exchange Rate Volatility what is the effect of nominal exchange rate variability on trade? i argue that the methods conventionally used to answer this perennial question are plagued by a variety of sources of systematic bias. i propose a novel approach that simultaneously addresses all of these biases, and present new estimates from a broad sample of countries from 1970 to 1997. the answer to the question is: not much.",
            "contribution_ids": [
                "R27221"
            ]
        },
        {
            "instance_id": "R27264xR27259",
            "comparison_id": "R27264",
            "paper_id": "R27259",
            "text": "Cyberbotics ltd. webots professional mobile robot simulation cyberbotics ltd. develops webots \u2122 , a mobile robotics simulation software that provides you with a rapid prototyping environment for modelling, programming and simulating mobile robots. the provided robot libraries enable you to transfer your control programs to several commercially available real mobile robots. webots \u2122 lets you define and modify a complete mobile robotics setup, even several different robots sharing the same environment. for each object, you can define a number of properties, such as shape, color, texture, mass, friction, etc. you can equip each robot with a large number of available sensors and actuators. you can program these robots using your favorite development environment, simulate them and optionally transfer the resulting programs onto your real robots. webots \u2122 has been developed in collaboration with the swiss federal institute of technology in lausanne, thoroughly tested, well documented and continuously maintained for over 7 years. it is now the main commercial product available from cyberbotics ltd.",
            "contribution_ids": [
                "R27260"
            ]
        },
        {
            "instance_id": "R27380xR27281",
            "comparison_id": "R27380",
            "paper_id": "R27281",
            "text": "On the Changes in Residual Stress Produced by Plastic Torsion Due to Repeated Stressing setting process is often practiced on coil springs in order to improve their fatigue resistance and prevent their creep deflection. torsional residual stresses are produced by this process, and it is generally understood that these stresses would play a role in improving the fatigue properties. in this experiment, round bar specimens of the spring steel sup2 were used, and after being twisted by the torsional moment 25% beyond that corresponding to the yield point, they were subjected to the fatigue test in alternating torsion. the distribution of residual stresses was measured by the etching method, by measuring the angle of torsion during the etching process. three stress levels were employed in repeated stressing and the number of stress cycles was made to be the same in each stress level. as a new attempt, we studied the fading of residual stresses under repeated stressing in successive two stress levels.the results obtained are summariaed as follows:(1) residual stresses produced by plastic torsion are of the thermal stress type near the surface, being negative at the surface layers.(2) residual stresses subjected to repeated stressing fade noticeably in the first stage of fading and then gradually with the repetition of stress cycles. in the second stage of fading, the relation obtained between the ratio of surface residual stresses \u03c4r/\u03c4o, (\u03c4r is the current value and \u03c4o is the initial value of surface residual stress) and the logarithm of cycle ratio n/n, formed straight lines, and experimental formulas concerning the fading of residual stresses were established.(3) in repeated stressing under successive two stress levels, the fading of residual stresses is larger in the case of descending stressing than in the case of ascending stressing, when the same numbers of stress cycles are given to each stress level, respectively. hardness has also the same tendency as the residual stress.",
            "contribution_ids": [
                "R27282"
            ]
        },
        {
            "instance_id": "R27380xR27354",
            "comparison_id": "R27380",
            "paper_id": "R27354",
            "text": "Contact fatigue of automotive gears: evolution and effects of residual stresses introduced by surface treatments helical gears from an automotive gearbox, previously subjected to the surface treatments of carbo-nitriding and shot-peening, were submitted to contact fatigue tests. the x-ray diffraction technique was used to characterize the evolution of different mechanical and metallurgical parameters as a function of gear damage. particular attention was paid to residual stress relief. a numerical model was developed to predict residual stress relaxation and estimate the most likely localization of contact fatigue crack initiation. the stress\u2013strain laws of the surface-treated layers were determined by means of two separate experimental methods, based on locally measured parameters. the dang van multiaxial fatigue criterion was used to analyse the failure of the gears, taking into account the effects of friction and roughness.",
            "contribution_ids": [
                "R27355"
            ]
        },
        {
            "instance_id": "R27380xR27366",
            "comparison_id": "R27380",
            "paper_id": "R27366",
            "text": "Consideration of shot peening treatment applied to a high strength aeronautical steel with different hardnesses one of the most important components in a aircraft is its landing gear, due to the high load that it is submitted to during, principally, the take off and landing. for this reason, the aisi 4340 steel is widely used in the aircraft industry for fabrication of structural components, in which strength and toughness are fundamental design requirements [i]. fatigue is an important parameter to be considered in the behavior of mechanical components subjected to constant and variable amplitude loading. one of the known ways to improve fatigue resistance is by using the shot peening process to induce a conlpressive residual stress in the surface layers of the material, making the nucleation and propagation of fatigue cracks more difficult [2,3]. the shot peening results depend on various parameters. these parameters can be grouped in three different classes according to i<. fathallah et a1 (41: parameters describing the treated part, parameters of stream energy produced by the process and parameters describing the contact conditions. furthermore, relaxation of the cksf induced by shot peening has been observed during the fatigue process 15-71. in the present research the gain in fatigue life of aisi 4340 steel, obtained by shot peening treatment, is evaluated under the two different hardnesses used in landing gear. rotating bending fatigue tests were conducted and the crsf was measured by an x-ray tensometry prior and during fatigue tests. the evaluation of fatigue life due the shot peening in relation to the relaxation of crsf, of crack sources position and roughness variation is done.",
            "contribution_ids": [
                "R27367"
            ]
        },
        {
            "instance_id": "R27380xR27347",
            "comparison_id": "R27380",
            "paper_id": "R27347",
            "text": "Influence of the shot peening temperature on the relaxation behaviour of residual stresses during cyclic bending shot peening of steels at elevated temperatures (warm peening) can improve the fatigue behaviour of workpieces. for the steel ai sf 4140 (german grade 42crm04) in a quenched and tempered condition, it is shown that this is not only caused by the higher compressive residual stresses induced but also due to an enlarged stability of these residual stresses during cyclic bending. this can be explained by strain aging effects during shot peening, which cause different and more stable dislocation structures.",
            "contribution_ids": [
                "R27348"
            ]
        },
        {
            "instance_id": "R27461xR27413",
            "comparison_id": "R27461",
            "paper_id": "R27413",
            "text": "Approximate Correlations for Chevron-Type Plate Heat Exchangers there exists very little useful data representing the performance of industrial plate heat exchangers (phes) in the open literature. as a result, it has been difficult to arrive at any generalized correlations. while every phe manufacturer is believed to have a comprehensive set of performance curves for their own designs, there exists the need to generate an approximate set of generalized correlations for the heat-transfer community. such correlations can be used for preliminary designs and analytical studies. this paper attempts to develop such a set of generalized correlations to quantify the heat-transfer and pressure-drop performance of chevron-type phes. for this purpose, the experimental data reported by heavner et al. were used for the turbulent region. for the laminar region, a semi-theoretical approach was used to express, for example, the friction factor as a function of the reynolds number and the chevron angle. asymptotic curves were used for the transitional region. physical explanations are provided for the trends shown by the generalized correlations. the correlations are compared against the open-literature data, where appropriate. these correlations are expected to be improved in the future when more data become available.",
            "contribution_ids": [
                "R27414"
            ]
        },
        {
            "instance_id": "R27620xR27527",
            "comparison_id": "R27620",
            "paper_id": "R27527",
            "text": "The relationship between energy consumption and economic growth in Pakistan energy is substantial for economic development. this study aims to unveil the causal relationship and long-term association between economic growth and energy consumption in pakistan. the granger-causality test finds that; natural gas consumption, electricity consumption and coal consumption have uni-directional causal relationship with economic growth as (gc, ec and cc\u2192gdp), however, gdp growth rate, natural gas consumption and coal consumption unilaterally granger causes inflation (gdp, gc and cc\u2192cpi) and lastly coal consumption\u2192natural gas consumption (gc), electricity consumption (ec)\u2192gc. the ardl estimations delineate natural gas consumption and oil consumption having a positive and negative association with gdp growth rate may have significant long term impacts respectively on the the economic growth of pakistan.",
            "contribution_ids": [
                "R27528",
                "R27666"
            ]
        },
        {
            "instance_id": "R27705xR27682",
            "comparison_id": "R27705",
            "paper_id": "R27682",
            "text": "Electricity consumption, income, foreign direct investment, and population in Malaysia: new evidence from multivariate framework analysis purpose this study attempts to re\u2010investigate the electricity consumption function for malaysia through the cointegration and causality analyses over the period 1970 to 2005. design/methodology/approach the study employed the bounds\u2010testing procedure for cointegration to examine the potential long\u2010run relationship, while an autoregressive distributed lag model is used to derive the short\u2010 and long\u2010run coefficients. the granger causality test is applied to determine the causality direction between electricity consumption and its determinants. findings new evidence is found in this study: first, electricity consumption, income, foreign direct investment, and population in malaysia are cointegrated. second, the influx of foreign direct investment and population growth are positively related to electricity consumption in malaysia and the granger causality evidence indicates that electricity consumption, income, and foreign direct investment are of bilateral causality. originality/value the estimated multivariate electricity consumption function for malaysia implies that malaysia is an energy\u2010dependent country; thus energy\u2010saving policies may have an inverse effect on current and also future economic development in malaysia.",
            "contribution_ids": [
                "R27683"
            ]
        },
        {
            "instance_id": "R27835xR27761",
            "comparison_id": "R27835",
            "paper_id": "R27761",
            "text": "Blending video games with learning: Issues and challenges with classroom implementations in the Turkish context the research design for this study focuses on examining the core issues and challenges when video games are used in the classroom. for this purpose three naturalistic contexts in turkey were examined in which educational video games were used as the basis for teaching units on world continents and countries, first aid, and basic computer hardware and peripherals, in primary, secondary and higher education contexts respectively. methods employed in the data collection include observing lessons, taking field notes, interviewing students and teachers, saving online discourse data, and collecting student artifacts and reflections. findings identified issues related to (1) the design of the video game environment, (2) school infrastructure, (3) the nature of learning, the role of the teacher and classroom culture, and (4) engagement.",
            "contribution_ids": [
                "R27762"
            ]
        },
        {
            "instance_id": "R27835xR27781",
            "comparison_id": "R27835",
            "paper_id": "R27781",
            "text": "Gameplaying for maths learning: cooperative or not? this study investigated the effects of gameplaying on fifth-graders\u2019 maths performance and attitudes. one hundred twenty five fifth graders were recruited and assigned to a cooperative teams-games-tournament (tgt), interpersonal competitive or no gameplaying condition. a state standards-based maths exam and an inventory on attitudes towards maths were used for the pretest and posttest. the students\u2019 gender, socio-economic status and prior maths ability were examined as the moderating variables and covariate. multivariate analysis of covariance (mancova) indicated that gameplaying was more effective than drills in promoting maths performance, and cooperative gameplaying was most effective for promoting positive maths attitudes regardless of students\u2019 individual differences.",
            "contribution_ids": [
                "R27782"
            ]
        },
        {
            "instance_id": "R27835xR27790",
            "comparison_id": "R27835",
            "paper_id": "R27790",
            "text": "New Directions for Traditional Lessons\u00e2\u0080\u009d: Can Handheld Game Consoles Enhance Mental Mathematics Skills? this paper reports on a pilot study that compared the use of commercial off-the-shelf (cots) handheld game consoles (hgcs) with traditional teaching methods to develop the automaticity of mathematical calculations and self-concept towards mathematics for year 4 students in two metropolitan schools. one class conducted daily sessions using the hgcs and the dr kawashima\u2019s brain training software to enhance their mental maths skills while the comparison class engaged in mental maths lessons using more traditional classroom approaches. students were assessed using standardised tests at the beginning and completion of the term and findings indicated that students who undertook the brain training pilot study using the hgcs showed significant improvement in both the speed and accuracy of their mathematical calculations and selfconcept compared to students in the control school. an exploration of the intervention, discussion of methodology and the implications of the use of hgcs in the primary classroom are presented.",
            "contribution_ids": [
                "R27791"
            ]
        },
        {
            "instance_id": "R27835xR27833",
            "comparison_id": "R27835",
            "paper_id": "R27833",
            "text": "Learning blood management in orthopedic surgery through gameplay \"orthopedic surgery treats the musculoskeletal system, in which bleeding is common and can be fatal. to help train future surgeons in this complex practice, researchers designed and implemented a serious game for learning orthopedic surgery. the game focuses on teaching trainees blood management skills, which are critical for safe operations. using state-of-the-art graphics technologies, the game provides an interactive and realistic virtual environment. it also integrates game elements, including task-oriented and time-attack scenarios, bonuses, game levels, and performance evaluation tools. to study the system's effect, the researchers conducted experiments on player completion time and off-target contacts to test their learning of psychomotor skills in blood management.\"",
            "contribution_ids": [
                "R27834"
            ]
        },
        {
            "instance_id": "R27835xR27753",
            "comparison_id": "R27835",
            "paper_id": "R27753",
            "text": "International Evaluation of a Localized Geography Educational Software a report on the implementation and evaluation of an intelligent learning system; the multimedia geography tutor and game software titled lainos world sm was localized into english, french, spanish, german, portuguese, russian and simplified chinese. thereafter, multilingual online surveys were setup to which high school students were globally invited via mails to schools, targeted adverts and recruitment on facebook, google, etc. 1125 respondents from selected nations completed both the initial and final surveys. the effect of the software on students\u2019 geographical knowledge was analyzed through pre and post achievement test scores. in general, the mean score were higher after exposure to the educational software for fifteen days and it was established that the score differences were statistically significant. this positive effect and other qualitative data show that the localized software from students\u2019 perspective is a widely acceptable and effective educational tool for learning geography in an interactive and gaming environment..",
            "contribution_ids": [
                "R27754"
            ]
        },
        {
            "instance_id": "R27835xR27757",
            "comparison_id": "R27835",
            "paper_id": "R27757",
            "text": "Combining software games with education: Evaluation of its educational effectiveness computer games are very popular among children and adolescents. in this respect, they could be exploited by educational software designers to render educational software more attractive and motivating. however, it remains to be explored what the educational scope of educational software games is. in this paper, we explore several issues concerning the educational effectiveness, appeal and scope of educational software games through an evaluation study of an intelligent tutoring system (its) that operates as a virtual reality educational game. the results of the evaluation show that educational virtual reality games can be very motivating while retaining or even improving the educational effects on students. moreover, one important finding of the study was that the educational effectiveness of the game was particularly high for students who used to have poor performance in the domain taught prior to their learning experience with the game.",
            "contribution_ids": [
                "R27758"
            ]
        },
        {
            "instance_id": "R27835xR27792",
            "comparison_id": "R27835",
            "paper_id": "R27792",
            "text": "A Study on Exploiting Commercial Digital Games into School Context digital game-based learning is a research field within the context of technology-enhanced learning that has attracted significant research interest. commercial off-the-shelf digital games have the potential to provide concrete learning experiences and allow for drawing links between abstract concepts and real-world situations. the aim of this paper is to provide evidence for the effect of a general-purpose commercial digital game (namely, the \u201csims 2-open for business\u201d) on the achievement of standard curriculum mathematics educational objectives as well as general educational objectives as defined by standard taxonomies. furthermore, students\u2019 opinions about their participation in the proposed game-supported educational scenario and potential changes in their attitudes toward math teaching and learning in junior high school are investigated. the results of the conducted research showed that: (i) students engaged in the game-supported educational activities achieved the same results with those who did not, with regard to the subject matter educational objectives, (ii) digital gamesupported educational activities resulted in better achievement of the general educational objectives, and (iii) no significant differences were observed with regard to students\u2019 attitudes towards math teaching and learning.",
            "contribution_ids": [
                "R27793"
            ]
        },
        {
            "instance_id": "R28099xR27851",
            "comparison_id": "R28099",
            "paper_id": "R27851",
            "text": "How Far Can We Go with Local Optimization in Real-Time Stereo Matching applications such as robot navigation and augmented reality require high-accuracy dense disparity maps in real-time and online. due to time constraint, most realtime stereo applications rely on local winner-take-all optimization in the disparity computation process. these local approaches are generally outperformed by offline global optimization based algorithms. however, recent research shows that, through carefully selecting and aggregating the matching costs of neighboring pixels, the disparity maps produced by a local approach can be more accurate than those generated by many global optimization techniques. we are therefore motivated to investigate whether these cost aggregation approaches can be adopted in real-time stereo applications and, if so, how well they perform under the real-time constraint. the evaluation is conducted on a real-time stereo platform, which utilizes the processing power of programmable graphics hardware. several recent cost aggregation approaches are also implemented and optimized for graphics hardware so that real-time speed can be achieved. the performances of these aggregation approaches in terms of both processing speed and result quality are reported.",
            "contribution_ids": [
                "R27852"
            ]
        },
        {
            "instance_id": "R28099xR27902",
            "comparison_id": "R28099",
            "paper_id": "R27902",
            "text": "On building an accurate stereo matching system on graphics hardware this paper presents a gpu-based stereo matching system with good performance in both accuracy and speed. the matching cost volume is initialized with an ad-census measure, aggregated in dynamic cross-based regions, and updated in a scanline optimization framework to produce the disparity results. various errors in the disparity results are effectively handled in a multi-step refinement process. each stage of the system is designed with parallelism considerations such that the computations can be accelerated with cuda implementations. experimental results demonstrate the accuracy and the efficiency of the system: currently it is the top performer in the middlebury benchmark, and the results are achieved on gpu within 0.1 seconds. we also provide extra examples on stereo video sequences and discuss the limitations of the system.",
            "contribution_ids": [
                "R27903"
            ]
        },
        {
            "instance_id": "R28099xR27971",
            "comparison_id": "R28099",
            "paper_id": "R27971",
            "text": "Efficient GPU-Based Graph Cuts for Stereo Matching \"although graph cuts (gc) is popularly used in many computer vision problems, slow execution time due to its high complexity hinders wide usage. manycore solution using graphics processing unit (gpu) may solve this problem. however, conventional gc implementation does not fully exploit gpu's computing power. to address this issue, a new gc algorithm which is suitable for gpu environment is presented in this paper. first, we present a novel graph construction method that accelerates the convergence speed of gc. next, a repetitive block-based push and relabel method is used to increase the data transfer efficiency. finally, we propose a low-overhead global relabeling algorithm to increase the gpu occupancy ratio. the experiments on middlebury stereo dataset shows that 5.2x speedup can be achieved over the baseline implementation, with identical gpu platform and parameters.\"",
            "contribution_ids": [
                "R27972"
            ]
        },
        {
            "instance_id": "R28099xR27978",
            "comparison_id": "R28099",
            "paper_id": "R27978",
            "text": "Real-time stereo vision: Optimizing Semi-Global Matching \"semi-global matching (sgm) is arguably one of the most popular algorithms for real-time stereo vision. it is already employed in mass production vehicles today. thinking of applications in intelligent vehicles (and fully autonomous vehicles in the long term), we aim at further improving sgm regarding its accuracy. in this study, we propose a straight-forward extension of the algorithm's parametrization. we consider individual penalties for different path orientations, weighted integration of paths, and penalties depending on intensity gradients. in order to tune all parameters, we applied evolutionary optimization. for a more efficient offline optimization and evaluation, we implemented sgm on graphics hardware. we describe the implementation using cuda in detail. for our experiments, we consider two publicly available datasets: the popular middlebury benchmark as well as a synthetic sequence from the .enpeda. project. the proposed extensions significantly improve the performance of sgm. the number of incorrect disparities was reduced by up to 27.5 % compared to the original approach, while the runtime was not increased.\"",
            "contribution_ids": [
                "R27979"
            ]
        },
        {
            "instance_id": "R28099xR28000",
            "comparison_id": "R28099",
            "paper_id": "R28000",
            "text": "Real-Time Stereo Matching on CUDA Using an Iterative Refinement Method for Adaptive Support-Weight Correspondences high-quality real-time stereo matching has the potential to enable various computer vision applications including semi-automated robotic surgery, teleimmersion, and 3-d video surveillance. a novel real-time stereo matching method is presented that uses a two-pass approximation of adaptive support-weight aggregation, and a low-complexity iterative disparity refinement technique. through an evaluation of computationally efficient approaches to adaptive support-weight cost aggregation, it is shown that the two-pass method produces an accurate approximation of the support weights while greatly reducing the complexity of aggregation. the refinement technique, constructed using a probabilistic framework, incorporates an additive term into matching cost minimization and facilitates iterative processing to improve the accuracy of the disparity map. this method has been implemented on massively parallel high-performance graphics hardware using the compute unified device architecture computing engine. results show that the proposed method is the most accurate among all of the real-time stereo matching methods listed on the middlebury stereo benchmark.",
            "contribution_ids": [
                "R28001"
            ]
        },
        {
            "instance_id": "R28099xR28024",
            "comparison_id": "R28099",
            "paper_id": "R28024",
            "text": "Stereo matching by adaptive weighting selection based cost aggregation cost aggregation is the most essential step for dense stereo correspondence searching, which measures the similarity between pixels in the stereo images. in this paper, based on the analysis of the optimal adaptive weight, we propose a novel support aggregation strategy by adaptive weighting selection. the proposed method calculates the aggregation cost by the joint optimization of both left and right matching cost. by assigning more reasonable weighting coefficients, we exclude the occlusion pixels while preserving sufficient support region for accurate matching. the proposed optimal strategy can be integrated by any other adaptive weighting based cost aggregation method to generate more reasonable similarity measurement. experimental results show that, compare with traditional methods, our algorithm can reduce the foreground fatten phenomenon while increasing the accuracy in the high texture regions.",
            "contribution_ids": [
                "R28025"
            ]
        },
        {
            "instance_id": "R28099xR28035",
            "comparison_id": "R28099",
            "paper_id": "R28035",
            "text": "A new high resolution depth map estimation system using stereo vision and depth sensing device depth map estimation is a classical problem in computer vision. conventional depth estimation relies on stereo/multi-view matching or depth sensing devices alone. in this paper, we propose a system which addresses high resolution and high quality depth estimation based on joint fusion of stereo and kinect data. the problem is formulated as a maximum a posteriori probability (map) estimation problem and reliability of two devices are derived. the depth map estimated is further refined by color image guided depth matting and a 2d polynomial regression (lpr)-based filtering. experimental results show that our system can provide high quality and resolution depth map, which complements the strengths of stereo vision and kinect depth sensor.",
            "contribution_ids": [
                "R28036"
            ]
        },
        {
            "instance_id": "R28099xR28044",
            "comparison_id": "R28099",
            "paper_id": "R28044",
            "text": "A modified census transform based on the neighborhood information for stereo matching algorithm census transform is a non-parametric local transform. its weakness is that the results relied on the center pixel too much. this paper proposes a modified census transform based on the neighborhood information for stereo matching. by improving the classic census transform, the new technique utilizes more bits to represent the differences between the pixel and its neighborhood information. the result image of the modified census transform has more detailed information at depth discontinuity. after stereo correspondence, sub-pixel interpolation and the disparity refinement, a better dense disparity map can be obtained. the experiments present that the proposed algorithm has simple mechanism and strong robustness. it can improve the accuracy of matching and is applicable to hardware systems.",
            "contribution_ids": [
                "R28045"
            ]
        },
        {
            "instance_id": "R28099xR28053",
            "comparison_id": "R28099",
            "paper_id": "R28053",
            "text": "Fast stereo matching using adaptive guided filtering dense disparity map is required by many great 3d applications. in this paper, a novel stereo matching algorithm is presented. the main contributions of this work are three-fold. firstly, a new cost...",
            "contribution_ids": [
                "R28054"
            ]
        },
        {
            "instance_id": "R28099xR28067",
            "comparison_id": "R28099",
            "paper_id": "R28067",
            "text": "Hardware-Efficient Design of Real-Time Profile Shape Matching Stereo Vision Algorithm on FPGA a variety of platforms, such as micro-unmanned vehicles, are limited in the amount of computational hardware they can support due to weight and power constraints. an efficient stereo vision algorithm implemented on an fpga would be able to minimize payload and power consumption in microunmanned vehicles, while providing 3d information and still leaving computational resources available for other processing tasks. this work presents a hardware design of the efficient profile shape matching stereo vision algorithm. hardware resource usage is presented for the targeted micro-uv platform, helio-copter, that uses the xilinx virtex 4 fx60 fpga. less than a fifth of the resources on this fgpa were used to produce dense disparity maps for image sizes up to 450 \u00d7 375, with the ability to scale up easily by increasing bram usage. a comparison is given of accuracy, speed performance, and resource usage of a census transform-based stereo vision fpga implementation by jin et al. results show that the profile shape matching algorithm is an efficient real-time stereo vision algorithm for hardware implementation for resource limited systems such as microunmanned vehicles.",
            "contribution_ids": [
                "R28068"
            ]
        },
        {
            "instance_id": "R28099xR28078",
            "comparison_id": "R28099",
            "paper_id": "R28078",
            "text": "High-speed segmentation-driven high-resolution matching this paper proposes a segmentation-based approach for matching of high-resolution stereo images in real time. the approach employs direct region matching in a raster scan fashion influenced by scanline approaches, but with pixel decoupling. to enable real-time performance it is implemented as a heterogeneous system of an fpga and a sequential processor. additionally, the approach is designed for low resource usage in order to qualify as part of unified image processing in an embedded system.",
            "contribution_ids": [
                "R28079"
            ]
        },
        {
            "instance_id": "R28099xR27916",
            "comparison_id": "R28099",
            "paper_id": "R27916",
            "text": "A local iterative refinement method for adaptive support-weight stereo matching a new stereo matching algorithm is introduced that performs iterative refinement on the results of adaptive support-weight stereo matching. during each iteration of disparity refinement, adaptive support-weights are used by the algorithm to penalize disparity differences within local windows. analytical results show that the addition of iterative refinement to adaptive support-weight stereo matching does not significantly increase complexity. in addition, this new algorithm does not rely on image segmentation or plane fitting, which are used by the majority of the most accurate stereo matching algorithms. as a result, this algorithm has lower complexity, is more suitable for parallel implementation, and does not force locally planar surfaces within the scene. when compared to other algorithms that do not rely on image segmentation or plane fitting, results show that the new stereo matching algorithm is one of the most accurate listed on the middlebury performance benchmark.",
            "contribution_ids": [
                "R27917"
            ]
        },
        {
            "instance_id": "R28099xR28012",
            "comparison_id": "R28099",
            "paper_id": "R28012",
            "text": "A near real-time color stereo matching method for GPU this paper presents a near real-time stereo matching method with acceptable matching results. this method consists of three important steps: sad-ald cost measure, cost aggregation in adaptive window in cross-based support regions and a refinement step. these three steps are well organized to be adopted by the gpu\u2019s parallel architecture. the parallelism brought by gpu and cuda implementations provides significant acceleration in running time. this method is tested on six pairs of images from middlebury dataset, each possibly declined within different sizes. for each pair of images it can generate acceptable matching results in roughly less than 100 milliseconds. the method is also compared with three gpu-based methods and one cpu-based method on increasing size image pairs.",
            "contribution_ids": [
                "R28013"
            ]
        },
        {
            "instance_id": "R28140xR28104",
            "comparison_id": "R28140",
            "paper_id": "R28104",
            "text": "A Metastatic Endocrine-Neurogenic Tumor of the Ampulla of Vater with Multiple Endocrine Immunoreaction Malignant Paraganglioma? the present case report demonstrates the history of a 50-year-old man with a mixed endocrine-neurogenous tumor of the ampulla of vater. the tumor was localized endoscopically after an attack of melena. there were no signs of endocrinopathy. a local resection with suturing of the pancreatic duct was performed. morphologically, there were two different tissue types (neurogenous and carcinoid-like) with numerous cells and nerve fibers reacting immunohistochemically with somatostatin and neurotensin antisera: some immunoreactivity to pp-antibodies was observed. still, after 20 months, the patient seems to have been cured by local resection.",
            "contribution_ids": [
                "R28105"
            ]
        },
        {
            "instance_id": "R28140xR28135",
            "comparison_id": "R28140",
            "paper_id": "R28135",
            "text": "Duodenal gangliocytic paraganglioma showing lymph node metastasis: A rare case report abstract \\n we describe a case of duodenal gangliocytic paraganglioma showing lymph node metastasis. a 61-year-old japanese man underwent pylorus preserving pancreaticoduodenectomy to remove a tumor at the papilla of vater. the section of the tumor extending from the mucosa to submucosa of the duodenum was sharply demarcated, solid, and white-yellowish. neither necrosis nor hemorrhage was present. histological examination confirmed the immunohistochemical identification of three components comprising epithelioid cells, spindle-shaped cells, and ganglion-like cells. epithelioid cells showed positive reactivity for synaptophysin, somatostatin, and cd56. in contrast, spindle-shaped cells showed positive reactivity for s-100 protein, but not for synaptophysin, somatostatin or cd56. furthermore, we found lymph node metastasis despite lack of bcl-2 and p53 expression. in addition to the rarity of the tumor, we are describing here the present case suggests the malignant potency of the tumor despite lack of acceptable prognostic indicators for neuroendocrine tumor.",
            "contribution_ids": [
                "R28136"
            ]
        },
        {
            "instance_id": "R28191xR28177",
            "comparison_id": "R28191",
            "paper_id": "R28177",
            "text": "On cost-efficiency of the global container shipping network this paper presents a simple formulation in the form of a pipe network for modelling the global container-shipping network. the cost-efficiency and movement-patterns of the current container-shipping network have been investigated using heuristic methods. the model is able to reproduce the overall incomes, costs, and container movement patterns for the industry as well as for the individual shipping lines and ports. it was found that the cost of repositioning empties is 27% of the total world fleet running cost and that overcapacity continues to be a problem. the model is computationally efficient. implemented in the java language, it takes one minute to run a full-scale network on a pentium iv computer.",
            "contribution_ids": [
                "R28178"
            ]
        },
        {
            "instance_id": "R28191xR28166",
            "comparison_id": "R28191",
            "paper_id": "R28166",
            "text": "Seasonal slot allocation planning for a container liner shipping service this research addresses a slot allocation planning problem of the container shipping company for satisfying the estimated seasonal demands on a liner service. we explore in detail the influenced factors of planning and construct a quantitative model for the optimum allocation of the ship\u2019s slot spaces. an integer programming model is formulated to maximize the potential profits per round trip voyage for a liner company, and a real life example of an eastern asia short sea service has been studied. analysis results reveal that containers with the higher contributions like reefers and 40 feet dry containers have priorities to be allocated more than others, but not all because of satisfying necessary operational constraints. our model is not only providing a higher space utilization rate and more detailed allocation results, but also helpful for the ship size assessment in long-term planning.",
            "contribution_ids": [
                "R28167"
            ]
        },
        {
            "instance_id": "R28235xR28200",
            "comparison_id": "R28235",
            "paper_id": "R28200",
            "text": "Empty container reposition planning for intra-Asia liner shipping this paper addresses empty container reposition planning by plainly considering safety stock management and geographical regions. this plan could avoid drawback in practice which collects mass empty containers at a port then repositions most empty containers at a time. empty containers occupy slots on vessel and the liner shipping company loses chance to yield freight revenue. the problem is drawn up as a two-stage problem. the upper problem is identified to estimate the empty container stock at each port and the lower problem models the empty container reposition planning with shipping service network as the transportation problem by liner problem. we looked at case studies of the taiwan liner shipping company to show the application of the proposed model. the results show the model provides optimization techniques to minimize cost of empty container reposition and to provide an evidence to adjust strategy of restructuring the shipping service network.",
            "contribution_ids": [
                "R28201"
            ]
        },
        {
            "instance_id": "R28333xR28260",
            "comparison_id": "R28333",
            "paper_id": "R28260",
            "text": "Analysis of an exact algorithm for the vessel speed optimization problem increased fuel costs together with environmental concerns have led shipping companies to consider the optimization of vessel speeds. given a fixed sequence of port calls, each with a time window, and fuel cost as a convex function of vessel speed, we show that optimal speeds can be found in quadratic time. \u00a9 2013 wiley periodicals, inc. networks, 2013",
            "contribution_ids": [
                "R28261"
            ]
        },
        {
            "instance_id": "R28333xR28268",
            "comparison_id": "R28333",
            "paper_id": "R28268",
            "text": "A chance constrained programming model for short-term liner ship fleet planning problems this article deals with a short-term liner ship fleet planning (lsfp) problem with cargo shipment demand uncertainty for a single liner container shipping company. the cargo shipment demand uncertainty enables us to propose a chance constraint for each liner service route, which guarantees that the liner service route can satisfy the customers\u2019 demand at least with a predetermined probability. assuming that cargo shipment demand between any two ports on each liner service route is normally distributed, this article develops an integer linear programming model with chance constraints for the short-term lsfp problem. the proposed integer linear programming model can be efficiently solved by any optimization solver such as cplex. finally, a numerical example is carried out to assess the model and analyze impact of the chance constraints and cargo shipment demand.",
            "contribution_ids": [
                "R28269"
            ]
        },
        {
            "instance_id": "R28333xR28280",
            "comparison_id": "R28333",
            "paper_id": "R28280",
            "text": "Ship assignment with hub and spoke constraints \"as the shipping industry enters the future, an increasing number of technological developments are being introduced into this market. this has led to a significant change in business operations, such as the innovative design of hub and spoke systems, resulting in cargo consolidation and a better use of the ship's capacity. in the light of this new scenario, the authors present a successful application of integer linear programming to support the decision-making process of assigning ships to previously defined voyages \u2014 the rosters. the tool used to build the final models was the ms-excel solver (microsoft\u00ae excel 97 sr-2, 1997), a package that enabled the real case studies addressed to be solved. the results of the experiment prompted the authors to favour the assignment of very small fleets, as opposed to the existing high number of ships employed in such real trades,\"",
            "contribution_ids": [
                "R28281"
            ]
        },
        {
            "instance_id": "R28369xR28356",
            "comparison_id": "R28369",
            "paper_id": "R28356",
            "text": "A model and solution algorithm for optimal routing of a time-chartered containership we formulate a mathematical programming model for optimally routing a chartered container ship. our model helps in evaluating whether a container ship should be chartered or not. the model calculates the optimal sequence of port calls, the number of containers transported between port pairs, and the number of trips the ship makes in the chartered period. a specialized algorithm is developed to solve the integer network subprograms which determine the sequence of port calls. our algorithm, which solves an integer program optimally, is quite efficient. comparison of computational results with a lagrangean relaxation method and an embedded dynamic program are also presented.",
            "contribution_ids": [
                "R28357"
            ]
        },
        {
            "instance_id": "R28369xR28349",
            "comparison_id": "R28369",
            "paper_id": "R28349",
            "text": "A mixed integer programming model for routing containerships in this paper, we formulate a mixed integer programming model for routing containerships. our model helps in evaluating the optimal sequence of port calls and the number of containers transported between port pairs given the trip cycle time. some numerical examples and a real world application of the trans pacific route are presented. the computational results show that our model, which solve the mixed integer programming optimally, is quite efficient and applicable to real world problem.",
            "contribution_ids": [
                "R28350"
            ]
        },
        {
            "instance_id": "R28407xR28375",
            "comparison_id": "R28407",
            "paper_id": "R28375",
            "text": "Network Design and Allocation Mechanisms for Carrier Alliances in Liner Shipping many real-world systems operate in a decentralized manner, where individual operators interact with varying degrees of cooperation and self motive. in this paper, we study transportation networks that operate as an alliance among different carriers. in particular, we study alliance formation among carriers in liner shipping. we address tactical problems such as the design of large-scale networks (that result from integrating the service networks of different carriers in an alliance) and operational problems such as the allocation of limited capacity on a transportation network among the carriers in the alliance. we utilize concepts from mathematical programming and game theory and design a mechanism to guide the carriers in an alliance to pursue an optimal collaborative strategy. the mechanism provides side payments to the carriers, as an added incentive, to motivate them to act in the best interest of the alliance while maximizing their own profits. our computational results suggest that the mechanism can be used to help carriers form sustainable alliances.",
            "contribution_ids": [
                "R28376"
            ]
        },
        {
            "instance_id": "R28407xR28388",
            "comparison_id": "R28407",
            "paper_id": "R28388",
            "text": "A path based model for a green liner shipping network design problem abstract\u2014liner shipping networks are the backbone ofinternational trade providing low transportation cost, whichis a major driver of globalization. these networks are underconstant pressure to deliver capacity, cost effectiveness and envi-ronmentally conscious transport solutions. this article proposesa new path based mip model for the liner shipping networkdesign problem minimizing the cost of vessels and their fuelconsumption facilitating a green network. the proposed modelreduces problem size using a novel aggregation of demands.a decomposition method enabling delayed column generationis presented. the subproblems have similar structure to ve-hicle routing problems, which can be solved using dynamicprogramming.index terms\u2014liner shipping, network design, mathematicalprogramming, column generation, green logistics i. i ntroduction g lobal liner shipping companies provide port to porttransport of containers, on a network which representsa billion dollar investment in assets and operational costs.the liner shipping network can be viewed as a transporta-tion system for general cargo not unlike an urban mass transitsystem for commuters, where each route (service) providestransportation links between ports and the ports allow fortranshipment in between routes (services). the liner shippingindustry is distinct from other maritime transportation modesprimarily due to a \ufb01xed public schedule with weekly fre-quency of port calls as an industry standard (stopford 1997).the network consists of a set of services. a service connectsa sequence of ports in a cycle at a given frequency, usuallyweekly. in figure 1 a service connecting montreal-halifaxand europe is illustrated. the weekly frequency means thatseveral vessels are committed to the service as illustrated byfigure 1, where four vessels cover a round trip of 28 daysplaced with one week in between vessels. this roundtrip forthe vessel is referred to as a rotation. note that the montrealservice carries cargo to the mediterranean and asia. thisillustrates that transhipments to other connecting servicesis at the core of liner shipping. therefore, the design of aservice is complex, as the set of rotations and their interactionthrough transhipment is a transportation system extending thesupply chains of a multiplum of businesses. figure 2 illus-trates two services interacting in transporting goods betweenmontreal-halifax and the mediterranean, while individually",
            "contribution_ids": [
                "R28389"
            ]
        },
        {
            "instance_id": "R28446xR28439",
            "comparison_id": "R28446",
            "paper_id": "R28439",
            "text": "Dynamic programming of port position and scale in the hierarchized container ports network \"a hierarchized container ports network, with several super hubs and many multilevel hub ports, will be established, mainly serving transshipment and carrying out most of its business in the hub-spoke mode. this paper sums up a programming model, in which the elementary statistic units, cost and expense of every phase of any shipment are the straight objects, and the minimum cost of the whole network is taken as the objective. this is established based on a dynamic system to make out the hierarchical structure of the container ports network, i.e. the trunk hub and feeder hubs can be planned in a economic zone, then the optimal scale vector can also be obtained for all container ports concerned with the network. the vector is a standard measurement to decide a port's position and their scale distribution in the whole network.\"",
            "contribution_ids": [
                "R28440"
            ]
        },
        {
            "instance_id": "R28487xR28485",
            "comparison_id": "R28487",
            "paper_id": "R28485",
            "text": "Optimization of shipping network of trunk and feeder lines for inter-regional and intra-regional container transport this paper firstly analyzes the structure of the existing container shipping network, which covers several areas located respectively in two counties, and develops a new kind of shipping network that consists of trunk and feeder lines. secondly, the paper constructs a bi-level programming model that can be used to optimize the container shipping network with the aim to minimize the generalized transport costs. then the model is tested with container o-d data between the ports in the surrounding bohai area in china and two ports in the west of the usa. through the test calculation, a feasible optimized shipping network consisting of trunk and feeder lines is founded for the case study area.",
            "contribution_ids": [
                "R28486"
            ]
        },
        {
            "instance_id": "R28614xR28532",
            "comparison_id": "R28614",
            "paper_id": "R28532",
            "text": "A Case of Primary Undifferentiated Sarcoma of the Liver: Diagnosed by Peritoneoscopy and Guided Biopsy the authors report a case of primary undifferentiated sarcoma of the liver, observed in a 36-year-old man. diagnosis was established at peritoneoscopy and guided biopsy, and confirmed by autopsy two months later.",
            "contribution_ids": [
                "R28533"
            ]
        },
        {
            "instance_id": "R28614xR28535",
            "comparison_id": "R28614",
            "paper_id": "R28535",
            "text": "Undifferentiated (embryonal) sarcoma of the liver.Report of 31 cases thirty\u2010one cases of undifferentiated (embryonal) sarcoma of the liver are presented. the tumor is found predominantly in the pediatric age group, the majority of patients (51.6%) being between 6 and 10 years of age. an abdominal mass and pain are the usual presenting symptoms. radiographic examination is nonspecific except to demonstrate a space\u2010occupying lesion of the liver. the tumors are large, single, usually globular and well demarcated, and have multiple cystic areas of hemorrhage, necrosis, and gelatinous degeneration. histologic examination shows a pseudocapsule partially separating the normal liver from undifferentiated sarcomatous cells that, near the periphery of the tumor, surround entrapped hyperplastic or degenerating bile duct\u2010like structures. eosinophilic globules that are pas positive are usually found within and adjacent to tumor cells. areas of necrosis and hemorrhage are prominent. the prognosis is poor, with a median survival of less than 1 year following diagnosis.",
            "contribution_ids": [
                "R28536",
                "R28537",
                "R28538",
                "R28539"
            ]
        },
        {
            "instance_id": "R28614xR28544",
            "comparison_id": "R28614",
            "paper_id": "R28544",
            "text": "Primary sarcoma of the liver in the adult primary undifferentiated saroma of the liver is a rare tumor, being documented primarily in the pediatric age group. this report describes the occurrence of such a tumor in a 55\u2010year\u2010old white woman with meyenburg\u2010s complexes of the liver and the crst syndrome. the clinicopathologic features of the tumor in the adult are characterized and the literature is reviewed.",
            "contribution_ids": [
                "R28545"
            ]
        },
        {
            "instance_id": "R28614xR28554",
            "comparison_id": "R28614",
            "paper_id": "R28554",
            "text": "Hepatic undifferentiated (embryonal) sarcoma and rhabdomyosarcoma in children. Results of therapy \"from july 1972 through september 1984, 8 of 44 children diagnosed as having primary malignant hepatic tumors, who were treated at st. jude children's research hospital, had undifferentiated (embryonal) sarcoma (five patients) or rhabdomyosarcoma (three patients). the natural history and response to multimodal therapy of these rare tumors are described. the pathologic material was reviewed and evidence for the differentiating potential of undifferentiated (embryonal) sarcoma is presented. at diagnosis, disease was restricted to the right lobe of the liver in three patients, was bilobar in four patients, and extended from the left lobe into the diaphragm in one patient. lung metastases were present in two patients at diagnosis. all three patients with rhabdomyosarcoma had intrahepatic lesions without involvement of the biliary tree. survival ranged from 6 to 73 months from diagnosis (median, 19.5 months); two patients are surviving disease\u2010free for 55+ and 73+ months, and one patient recently underwent resection of a recurrent pulmonary nodule 22 months from initial diagnosis. three patients died of progressive intrahepatic and extrahepatic abdominal tumors, and two patients, who died of progressive pulmonary tumor, also had bone or brain metastasis but no recurrence of intra\u2010abdominal tumor. six patients had objective evidence of response to chemotherapy. the authors suggest an aggressive multimodal approach to the treatment of these rare tumors in children.\"",
            "contribution_ids": [
                "R28555"
            ]
        },
        {
            "instance_id": "R28614xR28583",
            "comparison_id": "R28614",
            "paper_id": "R28583",
            "text": "Hepatic Undifferentiated (Embryonal) Sarcoma Arising in a Mesenchymal Hamartoma we report the case of a hepatic undifferentiated (embryonal) sarcoma (ues) arising within a mesenchymal hamartoma (mh) in a 15-year-old girl. mapping of the tumor demonstrated a typical mh transforming gradually into a ues composed of anaplastic stromal cells. when evaluated by flow cytometry, the mh was diploid and the ues showed a prominent aneuploid peak. karyotypic analysis of the ues showed structural alterations of chromosome 19, which have been implicated as a potential genetic marker of mh. the histogenesis of mh and ues is still debated, and reports of a relationship between them, although suggested on the basis of histomorphologic similarities, have never been convincing. the histologic, flow cytometric, and cytogenetic evidence reported herein suggests a link between these two hepatic tumors of the pediatric population.",
            "contribution_ids": [
                "R28584"
            ]
        },
        {
            "instance_id": "R28614xR28593",
            "comparison_id": "R28614",
            "paper_id": "R28593",
            "text": "Undifferentiated (embryonal) sarcoma of the liver in middle-aged adults: Smooth muscle differentiation determined by immunohistochemistry and electron microscopy undifferentiated (embryonal) sarcoma of the liver (uesl) is a rare pediatric liver malignancy that is extremely uncommon in middle-aged individuals. we studied 2 cases of uesl in middle-aged adults (1 case in a 49-year-old woman and the other in a 62-year-old man) by histology, immunohistochemistry, and electron microscopy to clarify the cellular characteristics of this peculiar tumor. one tumor showed a mixture of spindle cells, polygonal cells, and multinucleated giant cells within a myxoid matrix and also revealed focal areas of a storiform pattern in a metastatic lesion. the other tumor was composed mainly of anaplastic large cells admixed with few fibrous or spindle-shaped components and many multinucleated giant cells. in both cases, some tumor cells contained eosinophilic hyaline globules that were diastase resistant and periodic acid-schiff positive. immunohistochemically, the tumor cells showed positive staining for smooth muscle markers, such as desmin, alpha-smooth muscle actin, and muscle-specific actin, and also for histiocytic markers, such as alpha-1-antitrypsin, alpha-1-antichymotrypsin, and cd68. electron microscope examination revealed thin myofilaments with focal densities and intermediate filaments in the cytoplasm of tumor cells. our studies suggest that uesl exhibits at least a partial smooth muscle phenotype in middle-aged adults, and this specific differentiation may be more common in this age group than in children. tumor cells of uesl with smooth muscle differentiation in middle-aged adults show phenotypic diversity comparable to those of malignant fibrous histiocytoma with myofibroblastic differentiation.",
            "contribution_ids": [
                "R28594",
                "R28595"
            ]
        },
        {
            "instance_id": "R28614xR28599",
            "comparison_id": "R28614",
            "paper_id": "R28599",
            "text": "Undifferentiated (embryonal) sarcoma of liver in adult: a case report we report a case of undifferentiated (embryonal) sarcoma of the liver (uesl), which showed cystic formation in a 20-year-old man with no prior history of any hepatitis or liver cirrhosis. he was admitted with abdominal pain and a palpable epigastric mass. the physical examination findings were unremarkable except for a tenderness mass and the results of routine laboratory studies were all within normal limits. abdominal ultrasound and computed tomography (ct) both showed a cystic mass in the left hepatic lobe. subsequently, the patient underwent a tumor excision and another two times of hepatectomy because of tumor recurrence. immunohistochemical study results showed that the tumor cells were positive for vimentin, alpha-1-antichymotrypsin (aact) and desmin staining, and negative for alpha-fetoprotein (afp), and eosinophilic hyaline globules in the cytoplasm of some giant cells were strongly positive for periodic acid-schiff (pas) staining. the pathological diagnosis was uesl. the patient is still alive with no tumor recurrence for four months.",
            "contribution_ids": [
                "R28600"
            ]
        },
        {
            "instance_id": "R28889xR28626",
            "comparison_id": "R28889",
            "paper_id": "R28626",
            "text": "A Study of the Multi-Objective Next Release Problem one of the first issues which has to be taken into account by software companies is to determine what should be included in the next release of their products, in such a way that the highest possible number of customers get satisfied while this entails a minimum cost for the company. this problem is known as the next release problem (nrp). since minimizing the total cost of including new features into a software package and maximizing the total satisfaction of customers are contradictory objectives, the problem has a multi-objective nature. in this work we study the nrp problem from the multi-objective point of view, paying attention to the quality of the obtained solutions, the number of solutions, the range of solutions covered by these fronts, and the number of optimal solutions obtained.also, we evaluate the performance of two state-of-the-art multi-objective metaheuristics for solving nrp: nsga-ii and mocell. the obtained results show that mocell outperforms nsga-ii in terms of the range of solutions covered, while this latter is able of obtaining better solutions than mocell in large instances. furthermore, we have observed that the optimal solutions found are composed of a high percentage of low-cost requirements and, also, the requirements that produce most satisfaction on the customers.",
            "contribution_ids": [
                "R28627",
                "R28776"
            ]
        },
        {
            "instance_id": "R28889xR28633",
            "comparison_id": "R28889",
            "paper_id": "R28633",
            "text": "A Multiobjective Optimization Approach to the Software Release Planning with Undefined Number of Releases and Interdependent Requirements release planning is an important and complex activity in software development. it involves several aspects related to which functionalities are going to be developed in each release of the system. consistent planning must meet the customers\u2019 needs and comply with existing constraints. optimization techniques have been successfully applied to solve problems in the software engineering field, including the software release planning problem. in this context, this work presents an approach based on multiobjective optimization for the problem when the number of releases is not known a priori or when the number of releases is a value expected by stakeholders. the strategy regards on the stakeholders\u2019 satisfaction, business value and risk management, as well as provides ways for handling requirements interdependencies. experiments show the feasibility of the proposed approach.",
            "contribution_ids": [
                "R28634",
                "R28779"
            ]
        },
        {
            "instance_id": "R28889xR28652",
            "comparison_id": "R28889",
            "paper_id": "R28652",
            "text": "On the value of user preferences in search-based software engineering: A case study in software product lines software design is a process of trading off competing objectives. if the user objective space is rich, then we should use optimizers that can fully exploit that richness. for example, this study configures software product lines (expressed as feature maps) using various search-based software engineering methods. as we increase the number of optimization objectives, we find that methods in widespread use (e.g. nsga-ii, spea2) perform much worse than ibea (indicator-based evolutionary algorithm). ibea works best since it makes most use of user preference knowledge. hence it does better on the standard measures (hypervolume and spread) but it also generates far more products with 0% violations of domain constraints. our conclusion is that we need to change our methods for search-based software engineering, particularly when studying complex decision spaces.",
            "contribution_ids": [
                "R28653",
                "R28783"
            ]
        },
        {
            "instance_id": "R28889xR28657",
            "comparison_id": "R28889",
            "paper_id": "R28657",
            "text": "Identifying \"Good\" Architectural Design Alternatives with Multi-Objective Optimization Strategies architecture trade-off analysis methods are appropriate techniques to evaluate design decisions and design alternatives with respect to conflicting quality requirements. however, the identification of good design alternatives is a time consuming task, which is currently performed manually. to automate this task, this paper proposes to use evolutionary algorithms and multi-objective optimization strategies based on architecture refactorings to identify a sufficient set of design alternatives. this approach will reduce development costs and improve the quality of the final system, because an automated and systematic search will identify more and better design alternatives.",
            "contribution_ids": [
                "R28658",
                "R28785"
            ]
        },
        {
            "instance_id": "R28889xR28664",
            "comparison_id": "R28889",
            "paper_id": "R28664",
            "text": "Pareto Optimal Search Based Refactoring at the Design Level \"refactoring aims to improve the quality of a software systems' structure, which tends to degrade as the system evolves. while manually determining useful refactorings can be challenging, search based techniques can automatically discover useful refactorings. current search based refactoring approaches require metrics to be combined in a complex fashion, and producea single sequence of refactorings. in this paper we show how pareto optimality can improve search based refactoring, making the combination of metrics easier, and aiding the presentation of multiple sequences of optimal refactorings to users.\"",
            "contribution_ids": [
                "R28665",
                "R28787"
            ]
        },
        {
            "instance_id": "R28889xR28795",
            "comparison_id": "R28889",
            "paper_id": "R28795",
            "text": "User-centered, Evolutionary Search in Conceptual Software Design although much evidence exists to suggest that conceptual software engineering design is a difficult task for software engineers to perform, current computationally intelligent tool support for software engineers is limited. while search-based approaches involving module clustering and refactoring have been proposed and show promise, such approaches are downstream in terms of the software development lifecycle - the designer must manually produce a design before search-based clustering and refactoring can take place. interactive, user-centered search-based approaches, on the other hand, support the designer at the beginning of, and during, conceptual software design, and are investigated in this paper by means of a case study. results show that interactive evolutionary search, supported by software agents, appears highly promising. as an open system, search is steered jointly by designer preferences and software agents. directly traceable to the design problem domain, a mass of useful and interesting conceptual class designs are arrived at which may be visualized by the designer with quantitative measures of structural integrity such as design coupling and class cohesion. the conceptual class designs are found to be of equivalent or better coupling and cohesion when compared to a manual conceptual design of the case study, and by exploiting concurrent execution, the performance of the software agents is highly favorable.",
            "contribution_ids": [
                "R28796"
            ]
        },
        {
            "instance_id": "R28889xR28801",
            "comparison_id": "R28889",
            "paper_id": "R28801",
            "text": "Generating Software Architecture Spectrum with Multi-Objective Genetic Algorithms a possible approach to partly automated software architecture design is the application of heuristic search methods like genetic algorithms. however, traditional genetic algorithms use a single fitness function with weighted terms for different quality attributes. this is inadequate for software architecture design that has to satisfy multiple incomparable quality requirements simultaneously. to overcome this problem, the use of pareto optimality is proposed. this technique is studied in the presence of two central quality attributes of software architectures, modifiability and efficiency. the technique produces a spectrum of architecture proposals, ranging from highly modifiable (and less efficient) to highly efficient (and less modifiable). the technique has been implemented and evaluated using an example system. the results demonstrate that pareto optimality has potential for producing a sensible set of architectures in the efficiency-modifiability space.",
            "contribution_ids": [
                "R28802"
            ]
        },
        {
            "instance_id": "R28889xR28820",
            "comparison_id": "R28889",
            "paper_id": "R28820",
            "text": "Pareto efficient multi-objective test case selection previous work has treated test case selection as a single objective optimisation problem. this paper introduces the concept of pareto efficiency to test case selection. the pareto efficient approach takes multiple objectives such as code coverage, past fault-detection history and execution cost, and constructs a group of non-dominating, equivalently optimal test case subsets. the paper describes the potential bene?ts of pareto efficient multi-objective test case selection, illustrating with empirical studies of two and three objective formulations.",
            "contribution_ids": [
                "R28821"
            ]
        },
        {
            "instance_id": "R28889xR28833",
            "comparison_id": "R28889",
            "paper_id": "R28833",
            "text": "A Multi-Objective Genetic Algorithm to Test Data Generation evolutionary testing has successfully applied search based optimization algorithms to the test data generation problem. the existing works use different techniques and fitness functions. however, the used functions consider only one objective, which is, in general, related to the coverage of a testing criterion. but, in practice, there are many factors that can influence the generation of test data, such as memory consumption, execution time, revealed faults, and etc. considering this fact, this work explores a ultiobjective optimization approach for test data generation. a framework that implements a multi-objective genetic algorithm is described. two different representations for the population are used, which allows the test of procedural and object-oriented code. combinations of three objectives are experimentally evaluated: coverage of structural test criteria, ability to reveal faults, and execution time.",
            "contribution_ids": [
                "R28834"
            ]
        },
        {
            "instance_id": "R28889xR28851",
            "comparison_id": "R28889",
            "paper_id": "R28851",
            "text": "Establishing Integration Test Orders of Classes with Several Coupling Measures during the inter-class test, a common problem, named class integration and test order (cito) problem, involves the determination of a test class order that minimizes stub creation effort, and consequently test costs. the approach based on multi-objective evolutionary algorithms (moeas) has achieved promising results because it allows the use of different factors and measures that can affect the stubbing process. many times these factors are in conflict and usually there is no a single solution for the problem. existing works on moeas present some limitations. the approach was evaluated with only two coupling measures, based on the number of attributes and methods of the stubs to be created. other moeas can be explored and also other coupling measures. considering this fact, this paper investigates the performance of two evolutionary algorithms: nsga-ii and spea2, for the cito problem with four coupling measures (objectives) related to: attributes, methods, number of distinct return types and distinct parameter types. an experimental study was performed with four real systems developed in java. the obtained results point out that the moeas can be efficiently used to solve this problem with several objectives, achieving solutions with balanced compromise between the measures, and of minimal effort to test.",
            "contribution_ids": [
                "R28852"
            ]
        },
        {
            "instance_id": "R28889xR28859",
            "comparison_id": "R28889",
            "paper_id": "R28859",
            "text": "Evolutionary Algorithms for the Multi-objective Test Data Generation Problem automatic test data generation is a very popular domain in the field of search\u2010based software engineering. traditionally, the main goal has been to maximize coverage. however, other objectives can be defined, such as the oracle cost, which is the cost of executing the entire test suite and the cost of checking the system behavior. indeed, in very large software systems, the cost spent to test the system can be an issue, and then it makes sense by considering two conflicting objectives: maximizing the coverage and minimizing the oracle cost. this is what we did in this paper. we mainly compared two approaches to deal with the multi\u2010objective test data generation problem: a direct multi\u2010objective approach and a combination of a mono\u2010objective algorithm together with multi\u2010objective test case selection optimization. concretely, in this work, we used four state\u2010of\u2010the\u2010art multi\u2010objective algorithms and two mono\u2010objective evolutionary algorithms followed by a multi\u2010objective test case selection based on pareto efficiency. the experimental analysis compares these techniques on two different benchmarks. the first one is composed of 800 java programs created through a program generator. the second benchmark is composed of 13 real programs extracted from the literature. in the direct multi\u2010objective approach, the results indicate that the oracle cost can be properly optimized; however, the full branch coverage of the system poses a great challenge. regarding the mono\u2010objective algorithms, although they need a second phase of test case selection for reducing the oracle cost, they are very effective in maximizing the branch coverage. copyright \u00a9 2011 john wiley & sons, ltd.",
            "contribution_ids": [
                "R28860"
            ]
        },
        {
            "instance_id": "R28889xR28863",
            "comparison_id": "R28889",
            "paper_id": "R28863",
            "text": "Software Project Planning for Robustness and Completion Time in the Presence of Uncertainty using Multi Objective Search Based Software Engineering all large-scale projects contain a degree of risk and uncertainty. software projects are particularly vulnerable to overruns, due to the this uncertainty and the inherent difficulty of software project cost estimation. in this paper we introduce a search based approach to software project robustness. the approach is to formulate this problem as a multi objective search based software engineering problem, in which robustness and completion time are treated as two competing objectives. the paper presents the results of the application of this new approach to four large real-world software projects, using two different models of uncertainty.",
            "contribution_ids": [
                "R28864"
            ]
        },
        {
            "instance_id": "R28889xR28875",
            "comparison_id": "R28889",
            "paper_id": "R28875",
            "text": "Multiobjective Simulation Optimisation in Software Project Management traditionally, simulation has been used by project managers in optimising decision making. however, current simulation packages only include simulation optimisation which considers a single objective (or multiple objectives combined into a single fitness function). this paper aims to describe an approach that consists of using multiobjective optimisation techniques via simulation in order to help software project managers find the best values for initial team size and schedule estimates for a given project so that cost, time and productivity are optimised. using a system dynamics (sd) simulation model of a software project, the sensitivity of the output variables regarding productivity, cost and schedule using different initial team size and schedule estimations is determined. the generated data is combined with a well-known multiobjective optimisation algorithm, nsga-ii, to find optimal solutions for the output variables. the nsga-ii algorithm was able to quickly converge to a set of optimal solutions composed of multiple and conflicting variables from a medium size software project simulation model. multiobjective optimisation and sd simulation modeling are complementary techniques that can generate the pareto front needed by project managers for decision making. furthermore, visual representations of such solutions are intuitive and can help project managers in their decision making process.",
            "contribution_ids": [
                "R28876"
            ]
        },
        {
            "instance_id": "R29012xR29000",
            "comparison_id": "R29012",
            "paper_id": "R29000",
            "text": "Localizing Parts of Faces Using a Consensus of Exemplars we present a novel approach to localizing parts in images of human faces. the approach combines the output of local detectors with a nonparametric set of global models for the part locations based on over 1,000 hand-labeled exemplar images. by assuming that the global models generate the part locations as hidden variables, we derive a bayesian objective function. this function is optimized using a consensus of models for these hidden variables. the resulting localizer handles a much wider range of expression, pose, lighting, and occlusion than prior ones. we show excellent performance on real-world face datasets such as labeled faces in the wild (lfw) and a new labeled face parts in the wild (lfpw) and show that our localizer achieves state-of-the-art performance on the less challenging bioid dataset.",
            "contribution_ids": [
                "R29001",
                "R29017",
                "R29102"
            ]
        },
        {
            "instance_id": "R29012xR29008",
            "comparison_id": "R29012",
            "paper_id": "R29008",
            "text": "The First Facial Landmark Tracking in-the-Wild Challenge: Benchmark and Results \"detection and tracking of faces in image sequences is among the most well studied problems in the intersection of statistical machine learning and computer vision. often, tracking and detection methodologies use a rigid representation to describe the facial region 1, hence they can neither capture nor exploit the non-rigid facial deformations, which are crucial for countless of applications (e.g., facial expression analysis, facial motion capture, high-performance face recognition etc.). usually, the non-rigid deformations are captured by locating and tracking the position of a set of fiducial facial landmarks (e.g., eyes, nose, mouth etc.). recently, we witnessed a burst of research in automatic facial landmark localisation in static imagery. this is partly attributed to the availability of large amount of annotated data, many of which have been provided by the first facial landmark localisation challenge (also known as 300-w challenge). even though now well established benchmarks exist for facial landmark localisation in static imagery, to the best of our knowledge, there is no established benchmark for assessing the performance of facial landmark tracking methodologies, containing an adequate number of annotated face videos. in conjunction with iccv'2015 we run the first competition/challenge on facial landmark tracking in long-term videos. in this paper, we present the first benchmark for long-term facial landmark tracking, containing currently over 110 annotated videos, and we summarise the results of the competition.\"",
            "contribution_ids": [
                "R29009"
            ]
        },
        {
            "instance_id": "R29034xR28973",
            "comparison_id": "R29034",
            "paper_id": "R28973",
            "text": "Hyperface: A deep multi-task learning framework for face detection, land- mark localization, pose estimation, and gender recognition we present an algorithm for simultaneous face detection, landmarks localization, pose estimation and gender recognition using deep convolutional neural networks (cnn). the proposed method called, hyperface, fuses the intermediate layers of a deep cnn using a separate cnn followed by a multi-task learning algorithm that operates on the fused features. it exploits the synergy among the tasks which boosts up their individual performances. additionally, we propose two variants of hyperface: (1)\\xa0hyperface-resnet that builds on the resnet-101 model and achieves significant improvement in performance, and (2)\\xa0fast-hyperface that uses a high recall fast face detector for generating region proposals to improve the speed of the algorithm. extensive experiments show that the proposed models are able to capture both global and local information in faces and performs significantly better than many competitive algorithms for each of these four tasks.",
            "contribution_ids": [
                "R28974",
                "R29015"
            ]
        },
        {
            "instance_id": "R29034xR29021",
            "comparison_id": "R29034",
            "paper_id": "R29021",
            "text": "Face alignment by coarse-to-fine shape searching we present a novel face alignment framework based on coarse-to-fine shape searching. unlike the conventional cascaded regression approaches that start with an initial shape and refine the shape in a cascaded manner, our approach begins with a coarse search over a shape space that contains diverse shapes, and employs the coarse solution to constrain subsequent finer search of shapes. the unique stage-by-stage progressive and adaptive search i) prevents the final solution from being trapped in local optima due to poor initialisation, a common problem encountered by cascaded regression approaches; and ii) improves the robustness in coping with large pose variations. the framework demonstrates real-time performance and state-of-the-art results on various benchmarks including the challenging 300-w dataset.",
            "contribution_ids": [
                "R29022"
            ]
        },
        {
            "instance_id": "R29080xR29047",
            "comparison_id": "R29080",
            "paper_id": "R29047",
            "text": "Pose-Free Facial Landmark Fitting via Optimized Part Mixtures and Cascaded Deformable Shape Model this paper addresses the problem of facial landmark localization and tracking from a single camera. we present a two-stage cascaded deformable shape model to effectively and efficiently localize facial landmarks with large head pose variations. for face detection, we propose a group sparse learning method to automatically select the most salient facial landmarks. by introducing 3d face shape model, we use procrustes analysis to achieve pose-free facial landmark initialization. for deformation, the first step uses mean-shift local search with constrained local model to rapidly approach the global optimum. the second step uses component-wise active contours to discriminatively refine the subtle shape variation. our framework can simultaneously handle face detection, pose-free landmark localization and tracking in real time. extensive experiments are conducted on both laboratory environmental face databases and face-in-the-wild databases. all results demonstrate that our approach has certain advantages over state-of-the-art methods in handling pose variations.",
            "contribution_ids": [
                "R29048"
            ]
        },
        {
            "instance_id": "R29080xR29050",
            "comparison_id": "R29080",
            "paper_id": "R29050",
            "text": "Detector of facial landmarks learned by the structured output SVM in this paper we describe a detector of facial landmarks based on the deformable part models. we treat the task of landmark detection as an instance of the structured output classification problem. we propose to learn the parameters of the detector from data by the structured output support vector machines algorithm. in contrast to the previous works, the objective function of the learning algorithm is directly related to the performance of the resulting detector which is controlled by a user-defined loss function. the resulting detector is real-time on a standard pc, simple to implement and it can be easily modified for detection of a different set of landmarks. we evaluate performance of the proposed landmark detector on a challenging \u201clabeled faces in the wild\u201d (lfw) database. the empirical results demonstrate that the proposed detector is consistently more accurate than two public domain implementations based on the active appearance models and the deformable part models. we provide an open-source implementation of the proposed detector and the manual annotation of the facial landmarks for all images in the lfw database.",
            "contribution_ids": [
                "R29051"
            ]
        },
        {
            "instance_id": "R29080xR29053",
            "comparison_id": "R29080",
            "paper_id": "R29053",
            "text": "Facial point detection using boosted regression and graph models \"finding fiducial facial points in any frame of a video showing rich naturalistic facial behaviour is an unsolved problem. yet this is a crucial step for geometric-feature-based facial expression analysis, and methods that use appearance-based features extracted at fiducial facial point locations. in this paper we present a method based on a combination of support vector regression and markov random fields to drastically reduce the time needed to search for a point's location and increase the accuracy and robustness of the algorithm. using markov random fields allows us to constrain the search space by exploiting the constellations that facial points can form. the regressors on the other hand learn a mapping between the appearance of the area surrounding a point and the positions of these points, which makes detection of the points very fast and can make the algorithm robust to variations of appearance due to facial expression and moderate changes in head pose. the proposed point detection algorithm was tested on 1855 images, the results of which showed we outperform current state of the art point detectors.\"",
            "contribution_ids": [
                "R29054"
            ]
        },
        {
            "instance_id": "R29080xR29056",
            "comparison_id": "R29080",
            "paper_id": "R29056",
            "text": "Robust Discriminative Response Map Fitting with Constrained Local Models we present a novel discriminative regression based approach for the constrained local models (clms) framework, referred to as the discriminative response map fitting (drmf) method, which shows impressive performance in the generic face fitting scenario. the motivation behind this approach is that, unlike the holistic texture based features used in the discriminative aam approaches, the response map can be represented by a small set of parameters and these parameters can be very efficiently used for reconstructing unseen response maps. furthermore, we show that by adopting very simple off-the-shelf regression techniques, it is possible to learn robust functions from response maps to the shape parameters updates. the experiments, conducted on multi-pie, xm2vts and lfpw database, show that the proposed drmf method outperforms state-of-the-art algorithms for the task of generic face fitting. moreover, the drmf method is computationally very efficient and is real-time capable. the current matlab implementation takes 1 second per image. to facilitate future comparisons, we release the matlab code and the pre-trained models for research purposes.",
            "contribution_ids": [
                "R29057"
            ]
        },
        {
            "instance_id": "R29153xR29123",
            "comparison_id": "R29153",
            "paper_id": "R29123",
            "text": "The emergence of enterprise systems management: a challenge to the IS curriculum this paper proposes four cornerstones of a future information systems (is) curriculum. it analyses the challenges of the is curriculum based on the development of enterprise systems, and further argues that the practice and the research into enterprise systems have progressed to a new stage resulting in the emergence of enterprise systems management (esm). esm calls for new competences and consequently represents new challenges to the is curriculum. the paper outlines potential teaching issues and discusses the impact on the is curriculum. finally the paper suggests ways of approaching the challenges.",
            "contribution_ids": [
                "R29124"
            ]
        },
        {
            "instance_id": "R29153xR29140",
            "comparison_id": "R29153",
            "paper_id": "R29140",
            "text": "An Updated ERP Systems Annotated Bibliography: 2001-2005 this study provides an updated annotated bibliography of erp publications published in the main is conferences and journals during the period 2001-2005, categorizing them through an erp lifecycle-based framework that is structured in phases. the first version of this bibliography was published in 2001 (esteves and pastor, 2001c). however, so far, we have extended the bibliography with a significant number of new publications in all the categories used in this paper. we also reviewed the categories and some incongruities were eliminated.",
            "contribution_ids": [
                "R29141"
            ]
        },
        {
            "instance_id": "R29153xR29143",
            "comparison_id": "R29153",
            "paper_id": "R29143",
            "text": "Enterprise Resource Planning (ERP): a review of the literature this article is a review of work published in various journals on the topics of enterprise resource planning (erp) between january 2000 and may 2006. a total of 313 articles from 79 journals are reviewed. the article intends to serve three goals. first, it will be useful to researchers who are interested in understanding what kinds of questions have been addressed in the area of erp. second, the article will be a useful resource for searching for research topics. third, it will serve as a comprehensive bibliography of the articles published during the period. the literature is analysed under six major themes and nine sub-themes.",
            "contribution_ids": [
                "R29144"
            ]
        },
        {
            "instance_id": "R29153xR29146",
            "comparison_id": "R29153",
            "paper_id": "R29146",
            "text": "A review of literature on Enterprise Resource Planning systems enterprise resource planning (erp) systems are currently involved into every aspect of organization as they provide a highly integrated solution to meet the information system needs. erp systems have attracted a large amount of researchers and practitioners attention and received a variety of investigate and study. in this paper, we have selected a certain number of papers concerning erp systems between 1998 and 2006, and this is by no means a comprehensive review. the literature is further classified by its topic and the major outcomes and research methods of each study are addressed. following implications for future research are provided.",
            "contribution_ids": [
                "R29147"
            ]
        },
        {
            "instance_id": "R29184xR29159",
            "comparison_id": "R29184",
            "paper_id": "R29159",
            "text": "Planning for ERP systems: analysis and future trend the successful implementation of various enterprise resource planning (erp) systems has provoked considerable interest over the last few years. management has recently been enticed to look toward these new information technologies and philosophies of manufacturing for the key to survival or competitive edges. although there is no shortage of glowing reports on the success of erp installations, many companies have tossed millions of dollars in this direction with little to show for it. since many of the erp failures today can be attributed to inadequate planning prior to installation, we choose to analyze several critical planning issues including needs assessment and choosing a right erp system, matching business process with the erp system, understanding the organizational requirements, and economic and strategic justification. in addition, this study also identifies new windows of opportunity as well as challenges facing companies today as enterprise systems continue to evolve and expand.",
            "contribution_ids": [
                "R29160"
            ]
        },
        {
            "instance_id": "R29184xR29161",
            "comparison_id": "R29184",
            "paper_id": "R29161",
            "text": "Enterprise resource planning (ERP) systems: a research agenda the continuing development of enterprise resource planning (erp) systems has been considered by many researchers and practitioners as one of the major it innovations in this decade. erp solutions seek to integrate and streamline business processes and their associated information and work flows. what makes this technology more appealing to organizations is increasing capability to integrate with the most advanced electronic and mobile commerce technologies. however, as is the case with any new it field, research in the erp area is still lacking and the gap in the erp literature is huge. attempts to fill this gap by proposing a novel taxonomy for erp research. also presents the current status with some major themes of erp research relating to erp adoption, technical aspects of erp and erp in is curricula. the discussion presented on these issues should be of value to researchers and practitioners. future research work will continue to survey other major areas presented in the taxonomy framework.",
            "contribution_ids": [
                "R29162"
            ]
        },
        {
            "instance_id": "R29240xR29191",
            "comparison_id": "R29240",
            "paper_id": "R29191",
            "text": "Critical factors for successful implementation of enterprise systems enterprise resource planning (erp) systems have emerged as the core of successful information management and the enterprise backbone of organizations. the difficulties of erp implementations have been widely cited in the literature but research on the critical factors for initial and ongoing erp implementation success is rare and fragmented. through a comprehensive review of the literature, 11 factors were found to be critical to erp implementation success \u2013 erp teamwork and composition; change management program and culture; top management support; business plan and vision; business process reengineering with minimum customization; project management; monitoring and evaluation of performance; effective communication; software development, testing and troubleshooting; project champion; appropriate business and it legacy systems. the classification of these factors into the respective phases (chartering, project, shakedown, onward and upward) in markus and tanis\u2019 erp life cycle model is presented and the importance of each factor is discussed.",
            "contribution_ids": [
                "R29192"
            ]
        },
        {
            "instance_id": "R29240xR29208",
            "comparison_id": "R29240",
            "paper_id": "R29208",
            "text": "A Review of Critical Success Factors for ERP-Projects erp projects are complex purposes which influence main internal and external operations of companies. the success of the project directly influences the performance and the survival of the organisation. recent research has me- thodically collected plausible data in the field of critical success factors (csfs) within erp projects. this article describes how the collected publications were used to identify the main csfs and how they can be ranked according to the impor- tance of success or failure through a literature review. because of the influence of csfs to erp-projects in general, the term \"erp project\" is used in the further parts of this paper. the second part of this paper proposes how csfs can be in- tegrated into classical erp project phases. past researches did nearly not investigate how csfs which were mentioned in different publications can influence the erp-project phases. at the end of the paper the trend of csf in relation of the publication year and the origin of the author are shown.",
            "contribution_ids": [
                "R29209"
            ]
        },
        {
            "instance_id": "R29240xR29217",
            "comparison_id": "R29240",
            "paper_id": "R29217",
            "text": "The Core Critical Success Factors in Implementation of Enterprise Resource Planning Systems the implementation of enterprise resource planning (erp) systems require huge investments while ineffective implementations of such projects are commonly observed. a considerable number of these projects have been reported to fail or take longer than it was initially planned, while previous studies show that the aim of rapid implementation of such projects has not been successful and the failure of the fundamental goals in these projects have imposed huge amounts of costs on investors. some of the major consequences are the reduction in demand for such products and the introduction of further skepticism to the managers and investors of erp systems. in this regard, it is important to understand the factors determining success or failure of erp implementation. the aim of this paper is to study the critical success factors (csfs) in implementing erp systems and to develop a conceptual model which can serve as a basis for erp project managers. these critical success factors that are called \u201ccore critical success factors\u201d are extracted from 62 published papers using the content analysis and the entropy method. the proposed conceptual model has been verified in the context of five multinational companies.",
            "contribution_ids": [
                "R29218"
            ]
        },
        {
            "instance_id": "R29240xR29194",
            "comparison_id": "R29240",
            "paper_id": "R29194",
            "text": "Critical successful factors of ERP implementation: a review recently e -business has become the focus of management interest both in academics and in business. among the major components of e -business, erp (enterprise resource planning) is the backbone of other applications. therefore more and more enterprises attempt to adopt this new application in order to improve their business competitiveness. owing to the specific characteristics of erp, its implementation is more difficult than that of traditional information systems. for this reason, how to implement erp successfully becomes an important issue for both academics and practitioners. in this paper, a review on critical successful factors of erp in important mis publications will be presented. additionally traditional is implementatio n and erp implementation will be compared and the findings will be served as the basis for further research.",
            "contribution_ids": [
                "R29195"
            ]
        },
        {
            "instance_id": "R29240xR29203",
            "comparison_id": "R29240",
            "paper_id": "R29203",
            "text": "Critical success factors in ERP implementation: a review erp systems have become vital strategic tools in today\u2019s competitive business environment. this ongoing research study presents a review of recent research work in erp systems. it attempts to identify the main benefits of erp systems, the drawbacks and the critical success factors for implementation discussed in the relevant literature. the findings revealed that despite some organizations have faced challenges undertaking erp implementations, many others have enjoyed the benefits that the systems have brought to the organizations. erp system facilitates the smooth flow of common functional information and practices across the entire organization. in addition, it improves the performance of the supply chain and reduces the cycle times. however, without top management support, having appropriate business plan and vision, re-engineering business process, effective project management, user involvement and education and training, organizations can not embrace the full benefits of such complex system and the risk of failure might be at high level.",
            "contribution_ids": [
                "R29204"
            ]
        },
        {
            "instance_id": "R29240xR29229",
            "comparison_id": "R29240",
            "paper_id": "R29229",
            "text": "Strategic success factors in ERP system implementation different ways of approaching erp implementation give different results. in order to successfully implement an erp system it is necessary to properly balance critical success factors. by researching what the critical success factors in erp implementation are, why they are critical, and to what extent they are relevant to users, consultants and suppliers, this paper seeks to identify strategic critical success factors in erp implementation and to understand the impact of each factor on the success of erp system introduction. this paper lists strategic critical success factors (csf), which are influence the long-term goals. key-words: erp implementation, measuring success, cost, critical success factors, management, it project",
            "contribution_ids": [
                "R29230"
            ]
        },
        {
            "instance_id": "R29351xR29304",
            "comparison_id": "R29351",
            "paper_id": "R29304",
            "text": "Deconstructing information packages: organizational and behavioural implications of ERP systems argues that the organizational involvement of large scale information technology packages, such as those known as enterprise resource planning (erp), has important implications that go far beyond the acknowledged effects of keeping the organizational operations accountable and integrated across functions and production sites. claims that erp packages are predicated on an understanding of human agency as a procedural affair and of organizations as an extended series of functional or cross\u2010functional transactions. accordingly, the massive introduction of erp packages to organizations is bound to have serious implications that precisely recount the procedural forms by which such packages instrument organizational operations and fashion organizational roles. the conception of human agency and organizational operations in procedural terms may seem reasonable yet it recounts a very specific and, in a sense, limited understanding of humans and organizations. the distinctive status of framing human agency and organizations in procedural terms becomes evident in its juxtaposition with other forms of human action like improvisation, exploration or playing. these latter forms of human involvement stand out against the serial fragmentation underlying procedural action. they imply acting on the world on loose premises that trade off a variety of forms of knowledge and courses of action in attempts to explore and discover alternative ways of coping with reality.",
            "contribution_ids": [
                "R29305"
            ]
        },
        {
            "instance_id": "R29351xR29312",
            "comparison_id": "R29351",
            "paper_id": "R29312",
            "text": "Extended-enterprise systems\u00e2\u0080\u0099 impact on enterprise risk management\u00e2\u0080\u009d \" purpose \u2013 this article aims to focus on raising awareness of the limitations of traditional \u201centerprise\u2010centric\u201d views of enterprise risk management that ignore the risks that are inherited from key business and supply chain partners. in essence, enterprise systems implementations have allowed organizations to couple their operations more tightly with other business partners, particularly in the area of supply chain management, and in the process enterprise systems applications are redefining the boundaries of the entity in terms of risk management concerns and the scope of financial audits. design/methodology/approach \u2013 the prior literature that has begun to explore aspects of assessing key risk components in these relationships is reviewed with an eye to highlighting the limitations of what is understood about risk in interorganizational relationships. this analysis of the prior research establishes the basis for the logical formation of a framework for future enterprise risk management research in the area of e\u2010commerce relationships. findings \u2013 conclusions focus on the overall framework of risks that should be considered when interorganizational relationships are critical to an enterprise's operations and advocate an \u201cextended\u2010enterprise\u201d view of enterprise risk management. research limitations/implications \u2013 the framework introduced in this paper provides guidance for future research in the area of interorganizational systems control and risk assessment. practical implications \u2013 the framework further highlights areas of risk that auditors and corporate risk managers should consider in assessing the risk inherited through interorganizational relationships. originality/value \u2013 the paper highlights the need to shift from an enterprise\u2010centric view of risk management to an extended\u2010enterprise risk management view. \"",
            "contribution_ids": [
                "R29313"
            ]
        },
        {
            "instance_id": "R29351xR29328",
            "comparison_id": "R29351",
            "paper_id": "R29328",
            "text": "A comparison of ERP-success measurement approaches\u00e2\u0080\u009d erp projects are complex purposes which influence main internal and external operations of companies. there are different research approaches which try to develop models for is / erp success measurement or it-success measurement in general. each model has its own area of application and sometimes a specific measurement approach based, for instance, on different systems or different stakeholders involved. this research paper shows some of the most important models developed in the literature and an overview of the different approaches of the models. an analysis which shows the strengths, weaknesses and the cases in which the specific model could be used is made.",
            "contribution_ids": [
                "R29329"
            ]
        },
        {
            "instance_id": "R29351xR29332",
            "comparison_id": "R29351",
            "paper_id": "R29332",
            "text": "Taking knowledge management on the ERP road: a two-dimensional analysis\u00e2\u0080\u009d \"in today's fierce business competition, companies face the tremendous challenge of expanding markets, improving their products, services and processes and exploiting their intellectual capital in a dynamic network of knowledge-intensive relations inside and outside their borders. in order to accomplish these objectives, more and more companies are turning to the enterprise resource planning systems (erp). on the other hand, knowledge management (km) has received considerable attention in the last decade and is continuously gaining interest by industry, enterprises and academia. as we are moving into an era of \u201cknowledge capitalism\u201d, knowledge management will play a fundamental role in the success of today's businesses. this paper aims at throwing light on the role of km in the erp success first and on their possible integration second. a wide range of academic and practitioner literature related to km and erp is reviewed. on the basis of this review, the paper gives answers to specific research questions and analyses future research directions.\"",
            "contribution_ids": [
                "R29333"
            ]
        },
        {
            "instance_id": "R29351xR29349",
            "comparison_id": "R29351",
            "paper_id": "R29349",
            "text": "Factors for the acceptance of enterprise resource planning (ERP) systems and financial performance\u00e2\u0080\u009d this paper examined the effects of ntbs on maize price received by smallholder famers and traders in mbozi and momba districts of mbeya region in tanzania. cross sectional data were collected from 240 smallholder farmers and 50 traders from selected villages and markets using structure questionnaires and focused group discussion. a two stage - stratified sampling procedures were used in the selection of farmers. findings from study show that, ntbs has an inversely relationship with maize prices having coefficient valued at -0.062. this implies that, for a unit increase in ntbs costs there would be a 6.2% decline in farmer\u2019s prices in the rural areas and rise in consumer\u2019 prices by the same percent in the urban centers. moreover, maize prices seem to decrease with an increase in distance from the rural markets to urban markets and that contributions of ntbs on producer prices were higher between rural and districts markets. the paper concluded that, ntbs play a significant contribution on the increase in transaction costs which leads to lowering farm gate prices in the rural and increased consumer prices in the urban areas. it is therefore recommended that, protective food policy such as ntbs strategies should be minimized in order to maintain reasonably high prices in rural areas and low prices in urban areas.",
            "contribution_ids": [
                "R29350"
            ]
        },
        {
            "instance_id": "R29351xR29316",
            "comparison_id": "R29351",
            "paper_id": "R29316",
            "text": "Organisations and vanilla software: what do we know about ERP systems and competitive advantage? enterprise resource planning (erp) systems have become a de facto standard for integrating business functions. but an obvious question arises: if every business is using the same socalled \u201cvanilla\u201d software (e.g. an sap erp system) what happens to the competitive advantage from implementing it systems? if we discard our custom-built legacy systems in favour of enterprise systems do we also jettison our valued competitive advantage from it? while for some organisations erps have become just a necessity for conducting business, others want to exploit them to outperform their competitors. in the last few years, researchers have begun to study the link between erp systems and competitive advantage. this link will be the focus of this paper. we outline a framework summarizing prior research and suggest two researchable questions. a future article will develop the framework with two empirical case studies from within part of the european food industry.",
            "contribution_ids": [
                "R29317"
            ]
        },
        {
            "instance_id": "R30476xR29422",
            "comparison_id": "R30476",
            "paper_id": "R29422",
            "text": "Growth and the Environment in Canada: An Empirical Analysis standard reduced form models are estimated for canada to examine the relationships between real per capita gdp and four measures of environmental degradation. of the four chosen measures of environmental degradation, only concentrations of carbon monoxide appear to decline in the long run with increases in real per capita income. the data used in the reduced form models are also tested for the presence of unit roots and for the existence of cointegration between each of the measures of environmental degradation and per capita income. unit root tests indicate nonstationarity in logs of the measures of environmental degradation and per capita income. the engle-granger test and the maximum eigenvalue test suggest that per capita income and the measures of environmental degradation are not cointegrated, or that a long-term relationship between the variables does not exist. causality tests also indicate a bi-directional causality, rather than a uni-directional causality, from income to the environment. the results suggest that canada does not have the luxury of being able to grow out of its environmental problems. the implication is that to prevent further environmental degradation, canada requires concerted policies and incentives to reduce pollution intensity per unit of output across sectors, to shift from more to less pollution-producing-outputs and to lower the environmental damage associated with aggregate consumption.",
            "contribution_ids": [
                "R29423"
            ]
        },
        {
            "instance_id": "R30476xR29502",
            "comparison_id": "R30476",
            "paper_id": "R29502",
            "text": "Environmental Kuznets Curves for CO2: Heterogeneity versus Homogeneity we explore the emissions income relationship for co2 in oecd countries using various modelling strategies.even for this relatively homogeneous sample, we find that the inverted-u-shaped curve is quite sensitive to the degree of heterogeneity included in the panel estimations.this finding is robust, not only across different model specifications but also across estimation techniques, including the more flexible non-parametric approach.differences in restrictions applied in panel estimations are therefore responsible for the widely divergent findings for an inverted-u shape for co2.our findings suggest that allowing for enough heterogeneity is essential to prevent spurious correlation from reduced-form panel estimations.moreover, this inverted u for co2 is likely to exist for many, but not for all, countries.",
            "contribution_ids": [
                "R29503"
            ]
        },
        {
            "instance_id": "R30476xR29637",
            "comparison_id": "R30476",
            "paper_id": "R29637",
            "text": "Environmental Kuznets curve for CO2 in Canada the environmental kuznets curve hypothesis is a theory by which the relationship between per capita gdp and per capita pollutant emissions has an inverted u shape. this implies that, past a certain point, economic growth may actually be profitable for environmental quality. most studies on this subject are based on estimating fully parametric quadratic or cubic regression models. while this is not technhically wrong, such an approach somewhat lacks flexibility since it may fail to detect the true shape of the relationship if it happens not to be of the specified form. we use semiparametric and flexible nonlinear parametric modelling methods in an attempt to provide more robust inferences. we find little evidence in favour of the environmental kuznets curve hypothesis. our main results could be interpreted as indicating that the oil shock of the 1970s has had an important impact on progress towards less polluting technology and production.",
            "contribution_ids": [
                "R29638"
            ]
        },
        {
            "instance_id": "R30476xR29816",
            "comparison_id": "R30476",
            "paper_id": "R29816",
            "text": "Environmental Kuznets curve and growth source in Iran recent empirical research has examined the relationship between certain\\n indicators of environmental degradation and income, concluding that in some\\n cases an inverted u-shaped relationship, which has been called an\\n environmental kuznets curve (ekc), exists between these variables. the source\\n of growth explanation is important for two reasons. first, it demonstrates\\n how the pollution consequences of growth depend on the source of growth.\\n therefore, the analogy drawn by some in the environmental community between\\n the damaging effects of economic development and those of liberalized trade\\n is, at best, incomplete. second, the source of growth explanation\\n demonstrates that a strong policy response to income gains is not necessary\\n for pollution to fall with growth. the aim of this paper investigates the\\n role of differences source of growth in environmental quality of iran. the\\n results show the two growth resources in iran cause, in the early stages, co2\\n emission decreases until turning point but beyond this level of income per\\n capita, economic growth leads to environmental degradation. i find a u\\n relationship between environmental degradation (co2 emission) and economic\\n growth in iran.",
            "contribution_ids": [
                "R29817"
            ]
        },
        {
            "instance_id": "R30476xR29881",
            "comparison_id": "R30476",
            "paper_id": "R29881",
            "text": "Environmental Kuznets curve: evidences from developed and developing economies previous studies show that the environmental quality and economic growth can be represented by the inverted u curve called environmental kuznets curve (ekc). in this study, we conduct empirical analyses on detecting the existence of ekc using the five common pollutants emissions (i.e. co2, so2, bod, spm10, and ghg) as proxy for environmental quality. the data spanning from year 1961 to 2009 and cover 40 countries. we seek to investigate if the ekc hypothesis holds in two groups of economies, i.e. developed versus developing economies. applying panel data approach, our results show that the ekc does not hold in all countries. we also detect the existence of u shape and increasing trend in other cases. the results reveal that co2 and spm10 are good data to proxy for environmental pollutant and they can be explained well by gdp. also, it is observed that the developed countries have higher turning points than the developing countries. higher economic growth may lead to different impacts on environmental quality in different economies.",
            "contribution_ids": [
                "R29882"
            ]
        },
        {
            "instance_id": "R30476xR29973",
            "comparison_id": "R30476",
            "paper_id": "R29973",
            "text": "The environmental Kuznets curve in Asia: the case of sulphur and carbon emissions\u00e2\u0080\u009d the present study examines whether the race to the bottom and revised ekc scenarios presented by dasgupta and others (2002) are, with regard to the analytical framework of the environmental kuznets curve (ekc), applicable in asia to representative environmental indices, such as sulphur emissions and carbon emissions. to carry out this study, a generalized method of moments (gmm) estimation was made, using panel data of 19 economies for the period 1950-2009. the main findings of the analysis on the validity of ekc indicate that sulphur emissions follow the expected inverted u-shape pattern, while carbon emissions tend to increase in line with per capita income in the observed range. as for the race to the bottom and revised ekc scenarios, the latter was verified in sulphur emissions, as their ekc trajectories represent a linkage of the later development of the economy with the lower level of emissions while the former one was not present in neither sulphur nor carbon emissions.",
            "contribution_ids": [
                "R29974"
            ]
        },
        {
            "instance_id": "R30476xR30076",
            "comparison_id": "R30476",
            "paper_id": "R30076",
            "text": "Beyond the Environmental Kuznets Curve in Africa: Evidence from Panel Cointegration abstract the main objective of this study is to establish the applicability of the environmental kuznets curve (ekc) hypothesis in explaining the relationship between environmental pollution and development in africa. the ekc has been used to explain such relationships in a variety of contexts, yet rarely applied in africa, despite it hosting both the poorest countries in the world, 60% of those with extreme environmental pollution vulnerability and having a distinct socio-economic and institutional profile that tests the validity of such a model. this paper describes an empirical model that applies the ekc hypothesis and its modifications to 50 african countries, using data from 1995\u20132010. the empirical analysis suggests that there is a long-term relationship between co2 and particulate matter emissions with per capita income and other variables, including institutional factors and trade, leading to specific recommendations on future strategies for sustainable development in an african context.",
            "contribution_ids": [
                "R30077"
            ]
        },
        {
            "instance_id": "R30476xR30088",
            "comparison_id": "R30476",
            "paper_id": "R30088",
            "text": "Environmental Kuznets curve in an open economy: a bounds testing and causality analysis for Tunisia the aim of this paper is to investigate the existence of environmental kuznets curve (ekc) in an open economy like tunisia using annual time series data for the period of 1971-2010. the ardl bounds testing approach to cointegration is applied to test long run relationship in the presence of structural breaks and vector error correction model (vecm) to detect the causality among the variables. the robustness of causality analysis has been tested by applying the innovative accounting approach (iaa). the findings of this paper confirmed the long run relationship between economic growth, energy consumption, trade openness and co2 emissions in tunisian economy. the results also indicated the existence of ekc confirmed by the vecm and iaa approaches. the study has significant contribution for policy implications to curtail energy pollutants by implementing environment friendly regulations to sustain the economic development in tunisia.",
            "contribution_ids": [
                "R30089"
            ]
        },
        {
            "instance_id": "R30476xR30260",
            "comparison_id": "R30476",
            "paper_id": "R30260",
            "text": "The environmental Kuznets curve at different levels of economic development: a counterfactual quantile regression analysis for CO2emissions \"this paper applies the quantile fixed effects technique in exploring the co2 environmental kuznets curve within two groups of economic development (oecd and non-oecd countries) and six geographical regions \u2013 west, east europe, latin america, east asia, west asia and africa. a comparison of the findings resulting from the use of this technique with those of conventional fixed effects method reveals that the latter may depict a flawed summary of the prevailing income\u2013emissions nexus depending on the conditional quantile examined. the paper also extends the machado and mata decomposition method to the kuznets curve framework to explore the most important explanations for co2 emissions gap between oecd and non-oecd countries. we find a statistically significant oecd--non-oecd emissions gap and the decomposition reveals that there are non-income related factors working against the non-oecd group's greening. we tentatively conclude that deliberate and systematic mitigation of current co2 emissions in the non-oecd group is required.\"",
            "contribution_ids": [
                "R30261"
            ]
        },
        {
            "instance_id": "R30476xR30284",
            "comparison_id": "R30476",
            "paper_id": "R30284",
            "text": "The Relationship between CO2 Emission, Energy Consumption, Urbanization and Trade Openness for Selected CEECs this paper investigates the relationship between co2 emission, real gdp, energy consumption, urbanization and trade openness for 10 for selected central and eastern european countries (ceecs), including, albania, bulgaria, croatia, czech republic, macedonia, hungary, poland, romania, slovak republic and slovenia for the period of 1991\u20132011. the results show that the environmental kuznets curve (ekc) hypothesis holds for these countries. the fully modified ordinary least squares (fmols) results reveal that a 1% increase in energy consumption leads to a %1.0863 increase in co2 emissions. results for the existence and direction of panel vector error correction model (vecm) granger causality method show that there is bidirectional causal relationship between co2 emissions - real gdp and energy consumption-real gdp as well.",
            "contribution_ids": [
                "R30285"
            ]
        },
        {
            "instance_id": "R30476xR30373",
            "comparison_id": "R30476",
            "paper_id": "R30373",
            "text": "CO2emissions in Australia: economic and non-economic drivers in the long-run abstract australia has sustained a relatively high economic growth rate since the 1980s compared to other developed countries. per capita co2 emissions tend to be highest amongst oecd countries, creating new challenges to cut back emissions towards international standards. this research explores the long-run dynamics of co2 emissions, economic and population growth along with the effects of globalization tested as contributing factors. we find economic growth is not emission-intensive in australia, while energy consumption is emissions intensive. second, in an environment of increasing population, our findings suggest australia needs to be energy efficient at the household level, creating appropriate infrastructure for sustainable population growth. high population growth and open migration policy can be detrimental in reducing co2 emissions. finally, we establish globalized environment has been conducive in combating emissions. in this respect, we establish the beneficial effect of economic globalization compared to social and political dimensions of globalization in curbing emissions.",
            "contribution_ids": [
                "R30374"
            ]
        },
        {
            "instance_id": "R30476xR29741",
            "comparison_id": "R30476",
            "paper_id": "R29741",
            "text": "Economic Development and Environmental Quality in Nigeria: Is There an Environmental Kuznets Curve? this study utilizes standard- and nested-ekc models to investigate the income-environment relation for nigeria, between 1960 and 2008. the results from the standard-ekc model provides weak evidence of an inverted-u shaped relationship with turning point (t.p) around $280.84, while the nested model presents strong evidence of an n-shaped relationship between income and emissions in nigeria, with a t.p around $237.23. tests for structural breaks caused by the 1973 oil price shocks and 1986 structural adjustment are not rejected, implying that these factors have not significantly affected the income-environment relationship in nigeria. further, results from the rolling interdecadal analysis shows that the observed relationship is stable and insensitive to the sample interval chosen. overall, our findings imply that economic development is compatible with environmental improvements in nigeria. however, tighter and concentrated environmental policy regimes will be required to ensure that the relationship is maintained around the first two-strands of the n-shape",
            "contribution_ids": [
                "R29742"
            ]
        },
        {
            "instance_id": "R30476xR30390",
            "comparison_id": "R30476",
            "paper_id": "R30390",
            "text": "Relationship between economic growth and environmental degradation: is there evidence of an environmental Kuznets curve for Brazil? this study investigates the relationship between co2 emissions, economic growth, energy use and electricity production by hydroelectric sources in brazil. to verify the environmental kuznets curve (ekc) hypothesis we use time-series data for the period 1971-2011. the autoregressive distributed lag methodology was used to test for cointegration in the long run. additionally, the vector error correction model granger causality test was applied to verify the predictive value of independent variables. empirical results find that there is a quadratic long run relationship between co2emissions and economic growth, confirming the existence of an ekc for brazil. furthermore, energy use shows increasing effects on emissions, while electricity production by hydropower sources has an inverse relationship with environmental degradation. the short run model does not provide evidence for the ekc theory. the differences between the results in the long and short run models can be considered for establishing environmental policies. this suggests that special attention to both variables-energy use and the electricity production by hydroelectric sources- could be an effective way to mitigate co2 emissions in brazil",
            "contribution_ids": [
                "R30391"
            ]
        },
        {
            "instance_id": "R30512xR30482",
            "comparison_id": "R30512",
            "paper_id": "R30482",
            "text": "BeWell+ \"smartphone sensing and persuasive feedback design is enabling a new generation of wellbeing applications capable of automatically monitoring multiple aspects of physical and mental health. in this paper, we present bewell+ the next generation of the bewell smartphone health app, which continuously monitors user behavior along three distinct health dimensions, namely sleep, physical activity, and social interaction. bewell promotes improved behavioral patterns via feedback rendered as an ambient display on the smartphone's wallpaper. with bewell+, we introduce new wellbeing mechanisms to address challenges identified during the initial deployment of the bewell app; specifically, (i) community adaptive wellbeing feedback, which automatically generalize to diverse user communities (e.g., elderly, young adults, children) by balancing the need to promote better behavior yet remains realistic to the user's goals; and, (ii) wellbeing adaptive energy allocation, which prioritizes monitoring fidelity and feedback responsiveness on specific health dimensions of wellbeing (e.g., social interaction) where the user needs most help. we evaluate the performance of these mechanisms as part of an initial deployment and user study that includes 27 people using bewell+ over a 19 day field trial. our findings show that not only can bewell+ operate successfully on consumer-grade smartphones, but users understand feedback and respond by taking positive steps towards leading healthier lifestyles.\"",
            "contribution_ids": [
                "R30483"
            ]
        },
        {
            "instance_id": "R30512xR30484",
            "comparison_id": "R30512",
            "paper_id": "R30484",
            "text": "Activmon \"in this paper we discuss the use of low-complexity interfaces to encourage users to increase their level of physical activity. we present activmon - a wearable device capable of representing a user's individual activity level, and that of a group, using an ambient display. we discuss the results of a preliminary usability evaluation of activmon.\"",
            "contribution_ids": [
                "R30485"
            ]
        },
        {
            "instance_id": "R30512xR30504",
            "comparison_id": "R30512",
            "paper_id": "R30504",
            "text": "TripleBeat \"we present triplebeat, a mobile phone based system that assists runners in achieving predefined exercise goals via musical feedback and two persuasive techniques: a glanceable interface for increased personal awareness and a virtual competition. triplebeat is based on a previous system named mptrain. first, we describe triplebeat's hardware and software, emphasizing how it differs from its predecessor mptrain. then, we present the results of a runner study with 10 runners. the study compared the runners efficacy and enjoyment in achieving predefined workout goals when running with mptrain and triplebeat. the conclusions from the study include: (1) significantly higher efficacy and enjoyment with triplebeat, and (2) a unanimous preference for triplebeat over mptrain. the glanceable interface and the virtual competition are the two main reasons for the improvements in the running experience. we believe that systems like triplebeat will play an important role in enhancing the exercise experience and in assisting users towards more active lifestyles.\"",
            "contribution_ids": [
                "R30505"
            ]
        },
        {
            "instance_id": "R30512xR30508",
            "comparison_id": "R30512",
            "paper_id": "R30508",
            "text": "Mobile system to motivate teenagers' physical activity this paper reports a mobile persuasive application to motivate teenagers to start and continue being physically active. being physically active can lead to reduced risks of having weight and cardiovascular problems; however efforts in this direction had variable success. designing technology that will be engaging and motivating for teenagers requires an understanding of the factors that contribute to behavior adoption in teenagers. to understand these, we approach the design from several theoretical models: theory of planned behavior, theory of meaning behavior, and personality theory. we found that 1) personality traits affect perceptions on physical activities and the usefulness of devices that motivate them; 2) favored motivational phrases are universal across traits; 3) those who tried our prototype was generally positive and stated that they would use it on their own; 5) the characteristics of games that are desired are: social or competitive, outdoor, simple to learn and with large variations.",
            "contribution_ids": [
                "R30509"
            ]
        },
        {
            "instance_id": "R30512xR30510",
            "comparison_id": "R30512",
            "paper_id": "R30510",
            "text": "Self-setting of physical activity goals and effects on perceived difficulty, importance and competence goal setting can be a powerful method for persuading individuals to adopt an active lifestyle. in order for this to be the case, it is important to set concrete and challenging goals, and to strongly commit to them. in this study, we explored how people set goals for physical activity and how these goals were reflected in self-regulatory mechanisms to drive goal attainment. our approach is novel in two ways: first, we used an unobtrusive wearable sensor to accurately measure physical activity throughout the day rather than rely on self-report, and second, we provided individuals with feedback about the contribution of their common daily activities (e.g., household activities) to their physical activity level. our results showed that on the basis of this feedback, participants were able to indicate to what degree they intended to change their behavior. nevertheless, they failed to set concrete goals that matched their intentions precisely. in particular, we observed that overall the set goals were in accordance with intentions (i.e., goals were set in the desired direction), but we saw a strong tendency to focus on enhancing vigorous activity at the cost of moderate intensity activity. this suggests that many individuals have intentions to change and goal setting support is needed to compose goals that accurately reflect these intentions. technology-mediated interventions might be ideal to support individuals along that path.",
            "contribution_ids": [
                "R30511"
            ]
        },
        {
            "instance_id": "R30579xR30567",
            "comparison_id": "R30579",
            "paper_id": "R30567",
            "text": "A distributed key management framework with cooperative message authentication in VANETs in this paper, we propose a distributed key management framework based on group signature to provision privacy in vehicular ad hoc networks (vanets). distributed key management is expected to facilitate the revocation of malicious vehicles, maintenance of the system, and heterogeneous security policies, compared with the centralized key management assumed by the existing group signature schemes. in our framework, each road side unit (rsu) acts as the key distributor for the group, where a new issue incurred is that the semi-trust rsus may be compromised. thus, we develop security protocols for the scheme which are able to detect compromised rsus and their colluding malicious vehicles. moreover, we address the issue of large computation overhead due to the group signature implementation. a practical cooperative message authentication protocol is thus proposed to alleviate the verification burden, where each vehicle just needs to verify a small amount of messages. details of possible attacks and the corresponding solutions are discussed. we further develop a medium access control (mac) layer analytical model and carry out ns2 simulations to examine the key distribution delay and missed detection ratio of malicious messages, with the proposed key management framework being implemented over 802.11 based vanets.",
            "contribution_ids": [
                "R30568"
            ]
        },
        {
            "instance_id": "R30579xR30570",
            "comparison_id": "R30579",
            "paper_id": "R30570",
            "text": "A Group Signature Based Secure and Privacy-Preserving Vehicular Communication Framework we propose a novel group signature based security framework for vehicular communications. compared to the traditional digital signature scheme, the new scheme achieves authenticity, data integrity, anonymity, and accountability at the same time. furthermore, we describe a scalable role-based access control approach for vehicular networks. finally, we present a probabilistic signature verification scheme that can efficiently detect the tampered messages or the messages from an unauthorized node.",
            "contribution_ids": [
                "R30571"
            ]
        },
        {
            "instance_id": "R30579xR30573",
            "comparison_id": "R30579",
            "paper_id": "R30573",
            "text": "Defense against Sybil attack in vehicular ad hoc network based on roadside unit support in this paper, we propose a timestamp series approach to defend against sybil attack in a vehicular ad hoc network (vanet) based on roadside unit support. the proposed approach targets the initial deployment stage of vanet when basic roadside unit (rsu) support infrastructure is available and a small fraction of vehicles have network communication capability. unlike previously proposed schemes that require a dedicated vehicular public key infrastructure to certify individual vehicles, in our approach rsus are the only components issuing the certificates. due to the differences of moving dynamics among vehicles, it is rare to have two vehicles passing by multiple rsus at exactly the same time. by exploiting this spatial and temporal correlation between vehicles and rsus, two messages will be treated as sybil attack issued by one vehicle if they have the similar timestamp series issued by rsus. the timestamp series approach needs neither vehicular-based public-key infrastructure nor internet accessible rsus, which makes it an economical solution suitable for the initial stage of vanet.",
            "contribution_ids": [
                "R30574"
            ]
        },
        {
            "instance_id": "R30646xR30584",
            "comparison_id": "R30646",
            "paper_id": "R30584",
            "text": "Precise eye localization through a general-to-specific model definition we present a method for precise eye localization that uses two support vector machines trained on properly selected haar wavelet coefficients. the evaluation of our technique on many standard databases exhibits very good performance. furthermore, we study the strong correlation between the eye localization error and the face recognition rate.",
            "contribution_ids": [
                "R30585",
                "R30642"
            ]
        },
        {
            "instance_id": "R30646xR30586",
            "comparison_id": "R30646",
            "paper_id": "R30586",
            "text": "PRECISE EYE AND MOUTH LOCALIZATION the literature on the topic has shown a strong correlation between the degree of precision of face localization and the face recognition performance. hence, there is a need for precise facial feature detectors, as well as objective measures for their evaluation and comparison. in this paper, we will present significant improvements to a previous method for precise eye center localization, by integrating a module for mouth localization. the technique is based on support vector machines trained on optimally chosen haar wavelet coefficients. the method has been tested on several public databases; the results are reported and compared according to a standard error measure. the tests show that the algorithm achieves high precision of localization.",
            "contribution_ids": [
                "R30587",
                "R30619",
                "R30639",
                "R30640"
            ]
        },
        {
            "instance_id": "R30646xR30590",
            "comparison_id": "R30646",
            "paper_id": "R30590",
            "text": "Average of Synthetic Exact Filters this paper introduces a class of correlation filters called average of synthetic exact filters (asef). for asef, the correlation output is completely specified for each training image. this is in marked contrast to prior methods such as synthetic discriminant functions (sdfs) which only specify a single output value per training image. advantages of asef training include: insensitivity to over-fitting, greater flexibility with regard to training images, and more robust behavior in the presence of structured backgrounds. the theory and design of asef filters is presented using eye localization on the feret database as an example task. asef is compared to other popular correlation filters including sdf, mace, otf, and umace, and with other eye localization methods including gabor jets and the opencv cascade classifier. asef is shown to outperform all these methods, locating the eye to within the radius of the iris approximately 98.5% of the time.",
            "contribution_ids": [
                "R30591"
            ]
        },
        {
            "instance_id": "R30646xR30602",
            "comparison_id": "R30646",
            "paper_id": "R30602",
            "text": "Robust precise eye location under probabilistic framework eye feature location is an important step in automatic visual interpretation and human face recognition. in this paper, a novel approach for locating eye centers in face areas under probabilistic framework is devised. after grossly locating a face, we first find the areas which left and right eyes lies in. then an appearance-based eye detector is used to detect the possible left and right eye separately. according to their probabilities, the candidates are subsampled to merge those in near positions. finally, the remaining left and right eye candidates are paired; each possible eye pair is normalized and verified. according to their probabilities, the precise eye positions are decided. the experimental results demonstrate that our method can effectively cope with different eye variations and achieve better location performance on diverse test sets than some newly proposed methods. and the influence of precision of eye location on face recognition is also probed. the location of other face organs such as mouth and nose can be incorporated in the framework easily.",
            "contribution_ids": [
                "R30603"
            ]
        },
        {
            "instance_id": "R30646xR30620",
            "comparison_id": "R30646",
            "paper_id": "R30620",
            "text": "Eye localization through multiscale sparse dictionaries this paper presents a new eye localization method via multiscale sparse dictionaries (msd). we built a pyramid of dictionaries that models context information at multiple scales. eye locations are estimated at each scale by fitting the image through sparse coefficients of the dictionary. by using context information, our method is robust to various eye appearances. the method also works efficiently since it avoids sliding a search window in the image during localization. the experiments in bioid database prove the effectiveness of our method.",
            "contribution_ids": [
                "R30621"
            ]
        },
        {
            "instance_id": "R30698xR30662",
            "comparison_id": "R30698",
            "paper_id": "R30662",
            "text": "The prevalence of dental erosion in preschool children in China 00-5712/$ see front matter q 200 i:10.1016/j.jdent.2004.08.007 * corresponding author. tel.: c44 7 5 1282. e-mail address: r.bedi@eastman.uc summary objective. to describe the prevalence of dental erosion and associated factors in preschool children in guangxi and hubei provinces of china. methods. dental examinations were carried out on 1949 children aged 3\u20135 years. measurement of erosion was confined to primary maxillary incisors. the erosion index used was based upon the 1993 uk national survey of children\u2019s dental health. the children\u2019s general information as well as social background and dietary habits were collected based on a structured questionnaire. results. a total of 112 children (5.7%) showed erosion on their maxillary incisors. ninety-five (4.9%) was scored as being confined to enamel and 17 (0.9%) as erosion extending into dentine or pulp. there was a positive association between erosion and social class in terms of parental education. a significantly higher prevalence of erosion was observed in children whose parents had post-secondary education than those whose parents had secondary or lower level of education. there was also a correlation between the presence of dental erosion and intake of fruit drink from a feeding bottle or consumption of fruit drinks at bedtime. conclusion. erosion is not a serious problem for dental heath in chinese preschool children. the prevalence of erosion is associated with social and dietary factors in this sample of children. q 2004 elsevier ltd. all rights reserved.",
            "contribution_ids": [
                "R30663"
            ]
        },
        {
            "instance_id": "R30698xR30676",
            "comparison_id": "R30698",
            "paper_id": "R30676",
            "text": "Comparison of factors potentially related to the occurrence of dental erosion in high- and low-erosion groups soft drink intake, method of drinking, ph variations, plaque topography, and various salivary, microbial and clinical factors were compared in saudi men with high (n = 10, mean = 20.5 yr) and low (n = 9, mean = 20.3 yr) dental erosion. ph-measurements were carried out with a microtouch electrode at six different intraoral locations after the subjects had consumed 330 ml of regular cola-type drink in their customary manner. the results showed that higher intake of cola-type drinks was more common in the high- (253 l yr(-1)) than in the low-erosion group (140 l yr(-1)). high erosion was associated with a method of drinking whereby the drink was kept in the mouth for a longer period (71 s vs. 40 s). ph after drinking did not differ between the groups for any of the six measuring sites. plaque accumulation on the palatal surfaces of maxillary anterior teeth and urea concentration in unstimulated saliva were lower in high-erosion subjects. aside from these, there were no differences in salivary and microbial factors between the groups. first molar cuppings, buccal cervical defects, and mouth breathing were more common in the high- than in the low-erosion group. in summary, consumption of cola-type drink, method of drinking, amount of palatal plaque on anterior teeth, and salivary urea concentration are factors associated with dental erosion.",
            "contribution_ids": [
                "R30677",
                "R30732"
            ]
        },
        {
            "instance_id": "R30698xR30684",
            "comparison_id": "R30698",
            "paper_id": "R30684",
            "text": "Is there a relationship between asthma and dental erosion? A case control study objectives\\nthe aims of this study were firstly to assess and compare the prevalence of dental erosion and dietary intake between three groups of children; children with asthma, those with significant tooth erosion but with no history of asthma, and children with no history of asthma or other medical problems. secondly, to discover whether there was a relationship between medical history and dietary practises of these children and the levels of dental erosion. thirdly, to measure and compare their salivary flow rates, ph and buffering capacity.\\n\\n\\nmethods\\nthe study consisted of 3 groups of children aged 11-18 years attending birmingham dental hospital: 20 children with asthma requiring long-term medication, 20 children referred with dental erosion, and 20 children in the age and sex matched control group. tooth wear was recorded using a modification of the tooth wear index (twi) of smith and knight. data on the medical and dietary history were obtained from a self-reported questionnaire supplemented by a structured interview. the salivary samples were collected under standard methods for measurements.\\n\\n\\nresults\\nfifty percent of the children in the control group had low erosion and 50% moderate erosion. however, high levels were recorded in 35% of children in the asthma group and 65% in the erosion group. there appeared to be no overall differences in diet between the groups. there was an association between dental erosion and the consumption of soft drinks, carbonated beverages and fresh fruits in all the three groups. more variables related to erosion were found in the erosion and asthma groups. a comparison between the three groups showed no significant differences in unstimulated and stimulated salivary flow rates, or ph and buffering capacity.\\n\\n\\nconclusion\\nthere were significant differences in the prevalence of erosion between the three groups, children with asthma having a higher prevalence than the control group. although there was a relationship between the levels of erosion and some medical history and acidic dietary components, these did not explain the higher levels in asthmatic children. further investigation is required into the factors affecting the increased prevalence of erosion in children with asthma.",
            "contribution_ids": [
                "R30685"
            ]
        },
        {
            "instance_id": "R30698xR30693",
            "comparison_id": "R30698",
            "paper_id": "R30693",
            "text": "The oral health of children with clefts of the lip, palate, or both \" objective: the purpose of this study was to assess the prevalence of dental caries, developmental defects of enamel, and related factors in children with clefts. design: this cross-sectional prevalence study used standard dental indices for assessment. setting: children underwent a dental examination under standard conditions of seating and lighting in the outpatient department of a dental hospital as part of an ongoing audit to monitor clinical outcomes. participants: ninety-one children aged 4, 8, and 12 years were included in the study. outcome measurements dental caries were assessed by use of the decayed, missing, and filled index for primary teeth (dmft); decayed, missing, and filled index for permanent teeth (dmft) according to the criteria as used in the national survey of children's dental health in the united kingdom (o'brien, 1994). developmental defects were assessed using the modified developmental defects of enamel index (clarkson and o'mullane, 1989). dental erosion was assessed using the criteria derived for the national survey of children's dental health (o'brien, 1994). results: caries prevalence increased with age; 63% of patients at 4 years and 34% at 12 years were caries free. the mean dmft for the 4-year-olds was 1.3 with a mean dmft for the 12-year-olds of 1.8. all the 4-year-olds had evidence of erosion of enamel in the primary teeth (incisors and first molars) and 56% of the 12-year-olds had erosion of permanent teeth (incisors and first permanent molars). developmental defects of enamel became more prevalent with age, with at least one opacity in 56% of 4-year-olds and 100% of 12-year-olds. hypoplasia was not found in the primary dentition but affected permanent teeth in 38% of 8-year-olds and 23% of the 12-year-olds. conclusion: this study has shown that dental disease is prevalent in these patients. these assessments not only provide a baseline on oral health parameters in young people with clefts but underline the need for a more aggressive approach to prevention of oral disease to optimize clinical outcome. \"",
            "contribution_ids": [
                "R30694"
            ]
        },
        {
            "instance_id": "R30739xR30700",
            "comparison_id": "R30739",
            "paper_id": "R30700",
            "text": "Tooth surface loss in adult subjects attending a university dental clinic in Trinidad objectives\\nto determine the prevalence of tooth surface loss (tsl) in a sample of subjects attending a university dental clinic in trinidad and to investigate the relationship to tooth brushing, medical history, parafunction and dietary habits.\\n\\n\\ndesign\\ntooth surface loss was measured clinically by the index used in the 1998 uk, adult dental health survey.\\n\\n\\nsetting\\ntrinidad, west indies.\\n\\n\\nparticipants\\nconvenience sample of adult subjects attending the university of the west indies dental school polyclinic, mount hope.\\n\\n\\nmethods\\na questionnaire was administered and tooth surface loss measured clinically.\\n\\n\\nmain outcome measures\\nmild, moderate and severe tooth surface loss.\\n\\n\\nresults\\n155 subjects were examined (mean age 40.6 years) of whom 72% had some degree of tsl with the majority (52%), exhibiting mild, 16% with moderate and 4% with severe tsl. there were associations found between tsl and age (or=3.14), reflux (or=1.37), parafunction (or=1.06), weekly consumption of citrus fruits (or=1.31) and soft drinks (or=1.78), daily consumption of alcohol (or=1.40) and a vegetarian diet (or=2.79).\\n\\n\\nconclusions\\ntooth surface loss in this trinidadian population group appears to be common. data supports an association between tsl and age, reflux parafunction and certain dietary patterns.",
            "contribution_ids": [
                "R30701"
            ]
        },
        {
            "instance_id": "R30739xR30723",
            "comparison_id": "R30739",
            "paper_id": "R30723",
            "text": "Associated factors of tooth wear in southern Thailand the purpose of this study was to evaluate the possible risk factors connected with tooth wear. using the tooth wear index (twi) and the charting of pre-disposing factors tooth surface loss was recorded in 506 patients, of the dental hospital, prince of songkla university. we found that age, sex, number of tooth loss, frequency of alcohol, sour fruit and carbonate intake were significant risk factors. regarding the tooth position, the first molar showed the greatest degree of wear, while the canine and premolar showed the least, respectively. the occlusal surface showed the greatest wear and the cervical, lingual and buccal surfaces showed the least, respectively.",
            "contribution_ids": [
                "R30724"
            ]
        },
        {
            "instance_id": "R31214xR31182",
            "comparison_id": "R31214",
            "paper_id": "R31182",
            "text": "Advanced models of cellular genetic algorithms evaluated on SAT cellular genetic algorithms (cgas) are mainly characterized by their spatially decentralized population, in which individuals can only interact with their neighbors. in this work, we study the behavior of a large number of different cgas when solving the well-known 3-sat problem. these cellular algorithms differ in the policy of individuals update and the population shape, since these two features affect the balance between exploration and exploitation of the algorithm. we study in this work both synchronous and asynchronous cgas, having static and dynamically adaptive shapes for the population. our main conclusion is that the proposed adaptive cgas outperform other more traditional genetic algorithms for a well known benchmark of 3-sat.",
            "contribution_ids": [
                "R31183"
            ]
        },
        {
            "instance_id": "R31214xR31191",
            "comparison_id": "R31214",
            "paper_id": "R31191",
            "text": "Multinational evolutionary algorithms since practical problems often are very complex with a large number of objectives, it can be difficult or impossible to create an objective function expressing all the criteria of good solutions. sometimes a simpler function can be used where local optimas could be both valid and interesting. because evolutionary algorithms are population based, they have the best potential for finding more of the best solutions among the possible solutions. however, standard eas often converge to one solution and leave therefore only this single option for a final human selection. so far, at least two methods, sharing and tagging, have been proposed to solve the problem. the paper presents a new method for finding more quality solutions, not only global optimas but local as well. the method tries to adapt its search strategy to the problem by taking the topology of the fitness landscape into account. the idea is to use the topology to group the individuals into sub-populations, each covering a part of the fitness landscape.",
            "contribution_ids": [
                "R31192"
            ]
        },
        {
            "instance_id": "R31281xR31228",
            "comparison_id": "R31281",
            "paper_id": "R31228",
            "text": "Middle-Income Transitions: Trap or Myth? during the last few years, the newly coined term middle-income trap has been widely used by policymakers to refer to the middle-income economies that seem to be stuck in the middle-income range. however, there is no accepted definition of the term in the literature. in this paper, we study historical transitions across income groups to see whether there is any evidence that supports the claim that economies do not advance. overall, the data rejects this proposition. instead, we argue that what distinguishes economies in their transition from middle to high income is fast versus slow transitions. we find that, historically, it has taken a \u201ctypical\u201d economy 55 years to graduate from lower-middle income ($2,000 in 1990 purchasing power parity [ppp] $) to upper-middle income ($7,250 in 1990 ppp $). likewise, we find that, historically, it has taken 15 years for an economy to graduate from upper-middle income to high income (above $11,750 in 1990 ppp $). our analysis implies that as of 2013, there were 10 (out of 39) lower-middle-income economies and that 4 (out of 15) upper-middle-income economies that were experiencing slow transitions (i.e., above 55 and 15 years, respectively). the historical evidence presented in this paper indicates that economies move up across income groups. analyzing a large sample of economies over many decades, indicates that experiences are wide, including many economies that today are high income that spent many decades traversing the middle-income segment.",
            "contribution_ids": [
                "R31229",
                "R31268"
            ]
        },
        {
            "instance_id": "R31281xR31247",
            "comparison_id": "R31281",
            "paper_id": "R31247",
            "text": "On the Existence of a Middle-Income Trap. University of Western Australia Working the term \"middle income trap\" has been widely used in the literature, without having been clearly de ned or formally tested. we propose a statistical de nition of a middle income trap and derive a simple time-series test. we nd that the concept survives a rigorous scrutiny of the data, with the growth patterns of 19 countries being consistent with our de nition of a middle income trap..",
            "contribution_ids": [
                "R31248",
                "R31270"
            ]
        },
        {
            "instance_id": "R31669xR31336",
            "comparison_id": "R31669",
            "paper_id": "R31336",
            "text": "Composition estimations in a middle-vessel batch distillation column using artificial neural networks a virtual sensor that estimates product compositions in a middle-vessel batch distillation column has been developed. the sensor is based on a recurrent artificial neural network, and uses information available from secondary measurements (such as temperatures and flow rates). the criteria adopted for selecting the most suitable training data set and the benefits deriving from pre-processing these data by means of principal component analysis are demonstrated by simulation. the effects of sensor location, model initialization, and noisy temperature measurements on the performance of the soft sensor are also investigated. it is shown that the estimated compositions are in good agreement with the actual values.",
            "contribution_ids": [
                "R31337"
            ]
        },
        {
            "instance_id": "R31669xR31413",
            "comparison_id": "R31669",
            "paper_id": "R31413",
            "text": "Online prediction of polymer product quality in an industrial reactor using recurrent neural networks in this paper, internally recurrent neural networks (irnn) are used to predict a key polymer product quality variable from an industrial polymerization reactor. irnn are selected as the modeling tools for two reasons: 1) over the wide range of operating regions required to make multiple polymer grades, the process is highly nonlinear; and 2) the finishing of the polymer product after it leaves the reactor imparts significant dynamics to the process by \"mixing\" effects. irnn are shown to be very effective tools for predicting key polymer quality variables from secondary measurements taken around the reactor.",
            "contribution_ids": [
                "R31414"
            ]
        },
        {
            "instance_id": "R31669xR31456",
            "comparison_id": "R31669",
            "paper_id": "R31456",
            "text": "Applications of Artificial Neural Network for the Prediction of Flow Boiling Curves \"an artificial neural network (ann) was applied successfully to predict flow boiling curves. the databases used in the analysis are from the 1960's, including 1,305 data points which cover these parameter ranges: pressure p=100\u20131,000 kpa, mass flow rate g=40\u2013500 kg/m2-s, inlet subcooling \u03b4tsub =0\u201335\u00b0c, wall superheat \u03b4tw = 10\u2013300\u00b0c and heat flux q=20\u20138,000kw/m2. the proposed methodology allows us to achieve accurate results, thus it is suitable for the processing of the boiling curve data. the effects of the main parameters on flow boiling curves were analyzed using the ann. the heat flux increases with increasing inlet subcooling for all heat transfer modes. mass flow rate has no significant effects on nucleate boiling curves. the transition boiling and film boiling heat fluxes will increase with an increase in the mass flow rate. pressure plays a predominant role and improves heat transfer in all boiling regions except the film boiling region. there are slight differences between the steady and the transient boiling curves in all boiling regions except the nucleate region. the transient boiling curve lies below the corresponding steady boiling curve.\"",
            "contribution_ids": [
                "R31457"
            ]
        },
        {
            "instance_id": "R31669xR31638",
            "comparison_id": "R31669",
            "paper_id": "R31638",
            "text": "Dynamic modeling and optimal control of batch reactors, based on structure approaching hybrid neural networks a novel structure approaching hybrid neural network (sahnn) approach to model batch reactors is presented. the virtual supervisor\u2212artificial immune algorithm method is utilized for the training of sahnn, especially for the batch processes with partial unmeasurable state variables. sahnn involves the use of approximate mechanistic equations to characterize unmeasured state variables. since the main interest in batch process operation is on the end-of-batch product quality, an extended integral square error control index based on the sahnn model is applied to track the desired temperature profile of a batch process. this approach introduces model mismatches and unmeasured disturbances into the optimal control strategy and provides a feedback channel for control. the performance of robustness and antidisturbances of the control system are then enhanced. the simulation result indicates that the sahnn model and model-based optimal control strategy of the batch process are effective.",
            "contribution_ids": [
                "R31639"
            ]
        },
        {
            "instance_id": "R31669xR31460",
            "comparison_id": "R31669",
            "paper_id": "R31460",
            "text": "Using artificial neural network to predict the pressure drop in a rotating packed bed although rotating beds are good equipments for intensified separations and multiphase reactions, but the fundamentals of its hydrodynamics are still unknown. in the wide range of operating conditions, the pressure drop across an irrigated bed is significantly lower than dry bed. in this regard, an approach based on artificial intelligence, that is, artificial neural network (ann) has been proposed for prediction of the pressure drop across the rotating packed beds (rpb). the experimental data sets used as input data (280 data points) were divided into training and testing subsets. the training data set has been used to develop the ann model while the testing data set was used to validate the performance of the trained ann model. the results of the predicted pressure drop values with the experimental values show a good agreement between the prediction and experimental results regarding to some statistical parameters, for example (aard% = 4.70, mse = 2.0 \u00d7 10\u22125 and r2 = 0.9994). the designed ann model can estimate the pressure drop in the countercurrent flow rotating packed bed with unexpected phenomena for higher pressure drop in dry bed than in wet bed. also, the designed ann model has been able to predict the pressure drop in a wet bed with the good accuracy with experimental.",
            "contribution_ids": [
                "R31461"
            ]
        },
        {
            "instance_id": "R31689xR31683",
            "comparison_id": "R31689",
            "paper_id": "R31683",
            "text": "A probabilistic active support vector learning algorithm the paper describes a probabilistic active learning strategy for support vector machine (svm) design in large data applications. the learning strategy is motivated by the statistical query model. while most existing methods of active svm learning query for points based on their proximity to the current separating hyperplane, the proposed method queries for a set of points according to a distribution as determined by the current separating hyperplane and a newly defined concept of an adaptive confidence factor. this enables the algorithm to have more robust and efficient learning capabilities. the confidence factor is estimated from local information using the k nearest neighbor principle. the effectiveness of the method is demonstrated on real-life data sets both in terms of generalization performance, query complexity, and training time.",
            "contribution_ids": [
                "R31684"
            ]
        },
        {
            "instance_id": "R31689xR31687",
            "comparison_id": "R31689",
            "paper_id": "R31687",
            "text": "Balancing Exploration and Exploitation: A New Algorithm for Active Machine Learning active machine learning algorithms are used when large numbers of unlabeled examples are available and getting labels for them is costly (e.g. requiring consulting a human expert). many conventional active learning algorithms focus on refining the decision boundary, at the expense of exploring new regions that the current hypothesis misclassifies. we propose a new active learning algorithm that balances such exploration with refining of the decision boundary by dynamically adjusting the probability to explore at each step. our experimental results demonstrate improved performance on data sets that require extensive exploration while remaining competitive on data sets that do not. our algorithm also shows significant tolerance of noise.",
            "contribution_ids": [
                "R31688"
            ]
        },
        {
            "instance_id": "R31689xR31674",
            "comparison_id": "R31689",
            "paper_id": "R31674",
            "text": "Query learning with large margin classifiers the active selection of instances can significantly improve the generalisation performance of a learning machine. large margin classifiers such as support vector machines classify data using the most informative instances (the support vectors). this makes them natural candidates for instance selection strategies. in this paper we propose an algorithm for the training of support vector machines using instance selection. we give a theoretical justification for the strategy and experimental results on real and artificial data demonstrating its effectiveness. the technique is most efficient when the data set can be learnt using few support vectors.",
            "contribution_ids": [
                "R31675"
            ]
        },
        {
            "instance_id": "R31725xR31695",
            "comparison_id": "R31725",
            "paper_id": "R31695",
            "text": "Design Patterns in Software Maintenance: An Experiment Replication at Freie Universit\u00e4t Berlin \"an article published in 2001 reported a controlled experiment that compared maintenance of small programs using design patterns with maintenance of equivalent programs using simplified design solutions. a replication of that experiment was published in 2004. in 2010, a group of researchers from multiple countries picked this experiment as the subject of an attempt to perform a joint replication: many groups performing an experiment using the same setup, each contributing a few data points to a larger overall data set. this article reports on one of those sub-replications. only one of the results is statistically significant; it confirms the result of the original experiment stating that the simplified version of the gr program could be extended more quickly than the pattern version which used the abstract factory and composite patterns. the article's main contributions, however, are (a) its description of the peculiarities of this particular subdataset and (b) its (implicit) suggestions for possible evaluation methods.\"",
            "contribution_ids": [
                "R31696"
            ]
        },
        {
            "instance_id": "R31725xR31701",
            "comparison_id": "R31725",
            "paper_id": "R31701",
            "text": "Design Patterns in Software Maintenance: An Experiment Replication at Brigham Young University \"in 2001 prechelt et al. published the results of a controlled experiment in software maintenance comparing design patterns to simpler solutions. since that time, only one replication of the experiment has been performed (published in 2004). the replication found remarkably (though not surprisingly) different results. in this paper we present the results of another replication of prechelt's experiment, conducted at brigham young university (byu) in 2010. this replication was performed as part of a joint replication project hosted by the 2011 workshop on replication in empirical software engineering research (reser). the data and results from this experiment are meant to be considered in connection with the results of other contributions to the joint replication project.\"",
            "contribution_ids": [
                "R31702"
            ]
        },
        {
            "instance_id": "R31725xR31715",
            "comparison_id": "R31725",
            "paper_id": "R31715",
            "text": "State Design Pattern Implementation of a DSP processor: A case study of TMS5416C \"this paper presents an empirical study of the impact of state design pattern implementation on the memory and execution time of popular fixed-point dsp processor from texas instruments; tms320vc5416. actually, the object-oriented approach is known to introduce a significant performance penalty compared to classical procedural programming [1]. one can find the studies of the object-oriented penalty on the system performance, in terms of execution time and memory overheads in the literature. since, to the author's best knowledge the study of the overheads of design patterns (dp) in the embedded system programming is not widely published in the literature. the main contribution of the paper is to bring further evidence that embedded system software developers have to consider the memory and the execution time overheads of dps in their implementations. the results of the experiment show that implementation in c++ with dp increases the memory usage and the execution time but meanwhile these overheads would not prevent embedded system software developers to use dps.\"",
            "contribution_ids": [
                "R31716"
            ]
        },
        {
            "instance_id": "R31725xR31721",
            "comparison_id": "R31725",
            "paper_id": "R31721",
            "text": "Defect frequency and design patterns: an empirical study of industrial code software \"design patterns\" seek to package proven solutions to design problems in a form that makes it possible to find, adapt, and reuse them. a common claim is that a design based on properly applied patterns will have fewer defects than more ad hoc solutions. this case study analyzes the weekly evolution and maintenance of a large commercial product (c++, 500,000 loc) over three years, comparing defect rates for classes that participated in selected design patterns to the code at large. we found that there are significant differences in defect rates among the patterns, ranging from 63 percent to 154 percent of the average rate. we developed a new set of tools able to extract design pattern information at a rate of 3/spl times/10/sup 6/ lines of code per hour, with relatively high precision. based on a qualitative analysis of the code and the nature of the patterns, we conclude that the observer and singleton patterns are correlated with larger code structures and, so, can serve as indicators of code that requires special attention. conversely, code designed with the factory pattern is more compact and possibly less closely coupled and, consequently, has lower defect numbers. the template method pattern was used in both simple and complex situations, leading to no clear tendency.",
            "contribution_ids": [
                "R31722"
            ]
        },
        {
            "instance_id": "R31768xR31731",
            "comparison_id": "R31768",
            "paper_id": "R31731",
            "text": "Comparison of the Loop-Mediated Isothermal Amplification (LAMP) Method and Conventional Culture Method for the Detection of Campylobacter Species from Retail Chickens \u65b0\u305f\u306bc.jejuni\u304a\u3088\u3073c.coli\u306elamp\u30d7\u30e9\u30a4\u30de\u30fc\u304c\u8a2d\u8a08\u3055\u308c\u305f\u3053\u3068\u3092\u6a5f\u306b, lamp\u6cd5\u3092\u7528\u3044\u3066\u5e02\u8ca9\u9d8f\u8089134\u691c\u4f53\u304b\u3089\u30ab\u30f3\u30d4\u30ed\u30d0\u30af\u30bf\u30fc\u306e\u691c\u51fa\u3092\u8a66\u307f, \u57f9\u990a\u6cd5\u3068\u306e\u6bd4\u8f03\u3092\u884c\u3044, lamp\u6cd5\u306e\u6709\u7528\u6027\u306b\u3064\u3044\u3066\u691c\u8a0e\u3057\u305f.\u4e21\u8a66\u9a13\u65b9\u6cd5\u306b\u304a\u3044\u3066, \u3068\u3082\u306b\u967d\u6027\u306e\u691c\u4f53\u304c24\u691c\u4f53 (17.9%), \u9670\u6027\u306e\u691c\u4f53\u304c99\u691c\u4f53 (73.9%) \u3042\u308a, \u4e21\u6cd5\u306e\u4e00\u81f4\u7387\u306f91.8%\u3068\u9ad8\u304b\u3063\u305f.\u307e\u305f, \u6210\u7e3e\u304c\u7570\u306a\u3063\u305f\u691c\u4f53\u306f, lamp\u6cd5\u967d\u6027, \u57f9\u990a\u6cd5\u9670\u6027\u304c10\u691c\u4f53 (7.5%), \u9006\u306b\u57f9\u990a\u6cd5\u967d\u6027, lamp\u6cd5\u9670\u6027\u304c\u308f\u305a\u304b\u306b1\u691c\u4f53 (0.7%) \u3067\u3042\u3063\u305f.\u3053\u308c\u3089lamp\u6cd5\u3068\u57f9\u990a\u6cd5\u306b\u3088\u308b\u691c\u51fa\u72b6\u6cc1\u306b\u3064\u3044\u3066x2\u691c\u5b9a\u3092\u884c\u3063\u305f\u304c, \u4e21\u8a66\u9a13\u6cd5\u306e\u9593\u306b\u6709\u610f\u5dee\u306f\u8a8d\u3081\u3089\u308c\u306a\u304b\u3063\u305f.\u6750\u6599\u306e\u7a2e\u985e\u5225\u306b\u304a\u3051\u308b\u30ab\u30f3\u30d4\u30ed\u30d0\u30af\u30bf\u30fc\u306e\u691c\u51fa\u72b6\u6cc1\u3067\u306f\u624b\u7fbd23\u691c\u4f53\u306b\u304a\u3044\u3066, lamp\u6cd5\u3067\u306f5\u691c\u4f53 (21.7%) \u304c\u967d\u6027\u3067\u3042\u3063\u305f\u304c, \u57f9\u990a\u6cd5\u3067\u306f1\u691c\u4f53\u3082\u5206\u96e2\u3055\u308c\u306a\u304b\u3063\u305f, \u305d\u306e\u4ed6, \u30e2\u30e2\u8089, \u30ec\u30d0\u30fc, \u633d\u8089, \u30e0\u30cd\u8089, \u30b5\u30b5\u30df\u306a\u3069\u3067\u306f\u4e21\u8a66\u9a13\u6cd5\u306b\u3088\u308b\u691c\u51fa\u7387\u306b\u5dee\u7570\u306f\u8a8d\u3081\u3089\u308c\u306a\u304b\u3063\u305f.\u4eca\u56de\u306elamp\u6cd5\u306e\u6210\u7e3e\u306f, \u57f9\u990a\u6cd5\u3068\u6bd4\u8f03\u3057\u3066\u905c\u8272\u306a\u3044\u826f\u597d\u306a\u3082\u306e\u3067\u3042\u3063\u305f.\u306a\u304a, \u672c\u7a3f\u306e\u8981\u65e8\u306f\u65e5\u672c\u9632\u83cc\u9632\u5fbd\u5b66\u4f1a\u7b2c33\u56de\u5e74\u6b21\u5927\u4f1a (\u6771\u4eac) \u306b\u304a\u3044\u3066\u767a\u8868\u3057\u305f.",
            "contribution_ids": [
                "R31732",
                "R31741"
            ]
        },
        {
            "instance_id": "R31809xR31787",
            "comparison_id": "R31809",
            "paper_id": "R31787",
            "text": "DNA methylation and embryogenic compe- tence in leaves and callus of napiergrass (Pennisetum purpureum Schum quantitative and qualitative levels of dna methylation were evaluated in leaves and callus of pennisetum purpureum schum. the level of methylation did not change during leaf differentiation or aging and similar levels of methylation were found in embryogenic and nonembryogenic callus.",
            "contribution_ids": [
                "R31788"
            ]
        },
        {
            "instance_id": "R31809xR31801",
            "comparison_id": "R31809",
            "paper_id": "R31801",
            "text": "Genetic characterization of late-flowering traits induced by DNA hypomethylation mutation in Arabidopsis thaliana arabidopsis dna hypomethylation mutation, ddm1, results in a variety of developmental abnormalities by slowly inducing heritable lesions at unlinked loci. here, late-flowering traits observed at high frequencies in independently-established ddm1 lines were genetically characterized. in all of the four late-flowering lines examined the traits were dominant and mapped to the same chromosomal region, which is close or possibly identical to the fwa locus. the ddm1-induced phenotypic onsets are apparently not random mutation events, but specific to a group of genes, suggesting the underlying epigenetic mechanism. the dna methylation mutant provide useful system for identifying epigenetically-regulated genes important for plant development.",
            "contribution_ids": [
                "R31802"
            ]
        },
        {
            "instance_id": "R31928xR31908",
            "comparison_id": "R31928",
            "paper_id": "R31908",
            "text": "Cost estimate for biosynfuel production via biosyncrude gasification production of synthetic fuels from lignocellulose like wood or straw involves complex technology. there\u2010fore, a large btl (biomass to liquid) plant for biosynfuel production is more economic than many small facilities. a reasonable btl\u2010plant capacity is \u22651 mt/a biosynfuel similar to the already existing commercial ctl and gtl (coal to liquid, gas to liquid) plants of sasol and shell, corresponding to at least 10% of the capacity of a modern oil refinery. btl\u2010plant cost estimates are therefore based on reported experience with ctl and gtl plants. direct supply of large btl plants with low bulk density biomass by trucks is limited by high transport costs and intolerable local traffic density. biomass densification by liquefaction in a fast pyrolysis process generates a compact bioslurry or biopaste, also denoted as biosyncrude as produced by the bioliq\u00ae process. the densified biosyncrude intermediate can now be cheaply transported from many local facilities in silo wagons by electric rail over long distances to a large and more economic central biosynfuel plant. in addition to the capital expenditure (capex) for the large and complex central biosynfuel plant, a comparable investment effort is required for the construction of several dozen regional pyrolysis plants with simpler technology. investment costs estimated for fast pyrolysis plants reported in the literature have been complemented by own studies for plants with ca. 100 mwth biomass input. the breakdown of btl synfuel manufacturing costs of ca. 1 \u20ac /kg in central eu shows that about half of the costs are caused by the biofeedstock, including transport. this helps to generate new income for farmers. the other half is caused by technical costs, which are about proportional to the total capital investment (tci) for the pyrolysis and biosynfuel production plants. labor is a minor contribution in the relatively large facilities. \u00a9 2009 society of chemical industry and john wiley & sons, ltd",
            "contribution_ids": [
                "R31909"
            ]
        },
        {
            "instance_id": "R32061xR32040",
            "comparison_id": "R32061",
            "paper_id": "R32040",
            "text": "A two-stage approach to domain adaptation for statistical classifiers in this paper, we consider the problem of adapting statistical classifiers trained from some source domains where labeled examples are available to a target domain where no labeled example is available. one characteristic of such a domain adaptation problem is that the examples in the source domains and the target domain are known to follow different distributions. thus a regular classification method would tend to overfit the source domains. we present a two-stage approach to domain adaptation, where at the first <generalization stage, we look for a set of features generalizable across domains, and at the second adaptation stage, we pick up useful features specific to the target domain. observing that the exact objective function is hard to optimize, we then propose a number of heuristics to approximately achieve the goal of generalization and adaptation. our experiments on gene name recognition using a real data set show the effectiveness of our general framework and the heuristics.",
            "contribution_ids": [
                "R32041"
            ]
        },
        {
            "instance_id": "R32061xR32050",
            "comparison_id": "R32061",
            "paper_id": "R32050",
            "text": "Hierarchical Bayesian domain adaptation multi-task learning is the problem of maximizing the performance of a system across a number of related tasks. when applied to multiple domains for the same task, it is similar to domain adaptation, but symmetric, rather than limited to improving performance on a target domain. we present a more principled, better performing model for this problem, based on the use of a hierarchical bayesian prior. each domain has its own domain-specific parameter for each feature but, rather than a constant prior over these parameters, the model instead links them via a hierarchical bayesian global prior. this prior encourages the features to have similar weights across domains, unless there is good evidence to the contrary. we show that the method of (daume iii, 2007), which was presented as a simple \"preprocessing step,\" is actually equivalent, except our representation explicitly separates hyperparameters which were tied in his work. we demonstrate that allowing different values for these hyperparameters significantly improves performance over both a strong baseline and (daume iii, 2007) within both a conditional random field sequence model for named entity recognition and a discriminatively trained dependency parser.",
            "contribution_ids": [
                "R32051"
            ]
        },
        {
            "instance_id": "R32061xR32059",
            "comparison_id": "R32061",
            "paper_id": "R32059",
            "text": "Instance weighting for domain adaptation in nlp domain adaptation is an important problem in natural language processing (nlp) due to the lack of labeled data in novel domains. in this paper, we study the domain adaptation problem from the instance weighting perspective. we formally analyze and characterize the domain adaptation problem from a distributional view, and show that there are two distinct needs for adaptation, corresponding to the different distributions of instances and classification functions in the source and the target domains. we then propose a general instance weighting framework for domain adaptation. our empirical results on three nlp tasks show that incorporating and exploiting more information from the target domain through instance weighting is effective.",
            "contribution_ids": [
                "R32060"
            ]
        },
        {
            "instance_id": "R32189xR32077",
            "comparison_id": "R32189",
            "paper_id": "R32077",
            "text": "Development of a real-time learning scheduler using reinforcement learning concepts a scheme for the scheduling of flexible manufacturing systems (fms) has been developed which divides the scheduling function (built upon a generic controller architecture) into four different steps: candidate rule selection, transient phenomena analysis, multicriteria compromise analysis, and learning. this scheme is based on a hybrid architecture which utilizes neural networks, simulation, genetic algorithms, and induction mechanism. this paper investigates the candidate rule selection process, which selects a small list of scheduling rules from a larger list of such rules. this candidate rule selector is developed by using the integration of dynamic programming and neural networks. the system achieves real-time learning using this approach. in addition, since an expert scheduler is not available, it utilizes reinforcement signals from the environment (a measure of how desirable the achieved state is as measured by the resulting performance criteria). the approach is discussed and further research issues are presented. >",
            "contribution_ids": [
                "R32078"
            ]
        },
        {
            "instance_id": "R32189xR32081",
            "comparison_id": "R32189",
            "paper_id": "R32081",
            "text": "Applications of genetic algorithm and simulation to dispatching rule-based FMS scheduling this paper presents a hybrid intelligent approach to a production scheduling problem in fms. an fms scheduling system is modelled as a four-level simultaneous decision-making problem. the genetic algorithm and simulation approaches are integrated to seek efficiently the best combination of dispatching rules in order to obtain an appropriate production schedule under specific performance measures.",
            "contribution_ids": [
                "R32082"
            ]
        },
        {
            "instance_id": "R32189xR32085",
            "comparison_id": "R32189",
            "paper_id": "R32085",
            "text": "A GA embedded dynamic search algorithm over a Petri Net model an FMS scheduling in this paper, a genetic algorithm (ga) embedded dynamic search strategy over a petri net model provides a new scheduling method for a flexible manufacturing system (fms). the chromosome representation of the search nodes is constructed directly from the petri net model of an fms, recording the information about all conflict resolutions, such as resource assignments and orders for resource allocation. the ga operators may enforce some change to the chromosome information in the next generation. a petri net based schedule builder receives a chromosome and an initial marking as input, and then produces a near-optimal schedule. due to the np-complete nature of the scheduling problem of an fms, we also propose a dynamic fms scheduler incorporating the proposed ga embedded search scheme, which generates successive partial schedules, instead of generating a full schedule for all raw parts, as the production evolves.",
            "contribution_ids": [
                "R32086"
            ]
        },
        {
            "instance_id": "R32189xR32091",
            "comparison_id": "R32189",
            "paper_id": "R32091",
            "text": "Genetically tuned fuzzy scheduling for flexible manufacturing systems this paper focuses on the development and implementation of a genetically tuned fuzzy scheduler (gtfs) for heterogeneous fms under uncertainty. the scheduling system takes input from a table and creates an optimum master schedule. the gtfs uses fuzzy rulebase and inferencing where fuzzy sets are generated by a genetic algorithm to tune the optimization. the fuzzy optimization is based on time criticality in deadline and machine need, taking into account machine availability, uniformity, process time and selectability.",
            "contribution_ids": [
                "R32092"
            ]
        },
        {
            "instance_id": "R32189xR32142",
            "comparison_id": "R32189",
            "paper_id": "R32142",
            "text": "A pareto based multi-objective genetic algorithm for scheduling of FMS many real-world engineering and scientific problems involve simultaneous optimization of multiple objectives that often are competing. in this work, we have addressed issues relating to scheduling with multiple (and competing) objectives of flexible manufacturing system (fms) and have developed a mechanism by employing a pareto based ga to generate nearer optimal schedules. in the proposed method we have applied pareto ranking to identify the elite solutions and their fitness values are derated using fitness sharing method. the procedure is evaluated with sample problem environment found in literature and results are compared with other available heuristics found in literature. the proposed niched pareto genetic algorithm (npga) exhibits a superiority over the other heuristics and scheduling rules",
            "contribution_ids": [
                "R32143"
            ]
        },
        {
            "instance_id": "R32189xR32165",
            "comparison_id": "R32189",
            "paper_id": "R32165",
            "text": "A hybrid multi-objective GA for simultaneous scheduling of machines and AGVs in FMS a carefully designed and efficiently managed material handling system plays an important role in planning and operation of a flexiblemanufacturing system.most of the researchers have addressed machine and vehicle scheduling as two independent problems and most of the research has been emphasized only on single objective optimization. multiobjective problems in scheduling with conflicting objectives are more complex and combinatorial in nature and hardly have a unique solution. this paper addresses multiobjective scheduling problems in a flexiblemanufacturing environment using evolutionary algorithms. in this paper the authors made an attempt to consider simultaneously the machine and vehicle scheduling aspects in an fms and addressed the combined problem for the minimization of makespan, mean flow time and mean tardiness objectives.",
            "contribution_ids": [
                "R32166"
            ]
        },
        {
            "instance_id": "R32189xR32168",
            "comparison_id": "R32189",
            "paper_id": "R32168",
            "text": "Multi-objective Genetic Algorithm for Multistage-based Job Processing Schedules in FMS Environment in this paper, we propose a multi-objective genetic algorithm for effectively solving multistage-based job processing schedules in fms environment. the proposed method is random-weight approach to obtaining a variable search direction toward pareto solution. the objectives are to minimize the makespan and the total flow time, simultaneously. the feasibility and adaptability of the proposed moga are investigated through experimental results.",
            "contribution_ids": [
                "R32169"
            ]
        },
        {
            "instance_id": "R32189xR32187",
            "comparison_id": "R32189",
            "paper_id": "R32187",
            "text": "HPA-PN: a new algorithm for scheduling FMS using combinational genetic algorithm and Timed Petri Net in flexible manufacturing systems (fms), each job is formed of a set of operations that should be executed consecutive. determining the sequence of operations and assigning proper machine to each operation are two important problems in scheduling fms\u2019s. this is an np-hard problem. recently using heuristic methods, numerous algorithms are presented for solving this problem. in this paper for scheduling of flexible manufacturing systems, a new algorithm called hybrid genetic algorithm-petri net (hga-pn) is presented using timed petri net and combinational genetic algorithm. in our purposed algorithm, first the flexible manufacturing system is modeled by using timed petri net, and then an appropriate scheduling is manufactured using combinational genetic algorithm. the experimental results illustrates that our proposed algorithm has higher efficiency over other existing algorithms.",
            "contribution_ids": [
                "R32188"
            ]
        },
        {
            "instance_id": "R32424xR32210",
            "comparison_id": "R32424",
            "paper_id": "R32210",
            "text": "Extraction by Steam Distillation ofArtemisia herba-albsEssential Oil from Algeria: Kinetic Study and Optimization of the Operating Conditions abstract in order to study the extraction process of essential oil from artemisia herba-alba, kinetic studies as well as an optimization of the operating conditions were achieved. the optimization was carried out by a parametric study and experiments planning method. three operational parameters were chosen: artemisia mass to be treated, steam flow rate and extraction time. the optimal extraction conditions obtained by the parametric study correspond to: a mass of 30 g, a steam flow rate of 1.65 ml.min\u22121 and the extraction time of 60 min. the results reveal that the combined effects of two parameters, the steam water flow rate and the extraction time, are the most significant. the yield is also affected by the interaction of the three parameters. the essential oil obtained with optimal conditions was analyzed by gc-ms and a kinetic study was realised.",
            "contribution_ids": [
                "R32211"
            ]
        },
        {
            "instance_id": "R32424xR32233",
            "comparison_id": "R32424",
            "paper_id": "R32233",
            "text": "Fungicidal Activity of Artemisia herba alba Asso (Asteraceae) the antifungal activity of artemisia herba alba was found to be associated with two major volatile compounds isolated from the fresh leaves of the plant. carvone and piperitone were isolated and identified by gc/ms, gc/ir, and nmr spectroscopy. antifungal activity was measured against penicillium citrinum (atcc 10499) and mucora rouxii (atcc 24905). the antifungal activity (ic50) of the purified compounds was estimated to be 5 \u03bc g/ml, 2 \u03bc g/ml against penicillium citrinum and 7 \u03bc g/ml, 1.5 \u03bc g/ml against mucora rouxii carvone and piperitone, respectively.",
            "contribution_ids": [
                "R32234"
            ]
        },
        {
            "instance_id": "R32424xR32258",
            "comparison_id": "R32424",
            "paper_id": "R32258",
            "text": "Chemovariation ofArtemisia herba albaAsso. Aromatic Plants of the Holy Land and the Sinai. Part XVI. abstract in continuation of our investigation of aromatic flora of the holy land, the systematic study of artemisia herba alba essential oils has been conducted. the detailed composition of five relatively rare chemotypes of a. herba alba obtained through gc and gc/ms analysis are presented. to ensure the integrity of each chemotype the volatiles were extracted from individual plant specimens and bulked only if the gc profiles were substantially similar. the major constituents were: type 1: 1,8 cineole (10.8%), \u03b1-thujone (40.9%) and \u03b2-thujone (34.9%); type 2: 1,8 cineole (26.0%) and camphor (42.1%); type 3; 1,8 cineole (26.6%) and \u03b2-thujone (44.0%); type 4: cis-chrysanthenyl acetate (8.9%) and cis-chrysanthenol (30.0%); type 5: cis-chysanthenol (6.8%) and cis-chrysanthenyl acetate (69.0%). this study showed that the population of a. herba alba in israel consists of a much greater number of chemovarieties than was previously believed. though chemovarieties are unevenly distributed in different geographic areas, no clear relation between the plant type and environmental conditions could be established.",
            "contribution_ids": [
                "R32259"
            ]
        },
        {
            "instance_id": "R32424xR32286",
            "comparison_id": "R32424",
            "paper_id": "R32286",
            "text": "Chemical variability of Artemisia herba-alba Asso essential oils from East Morocco abstract chemical compositions of 16 artemisia herba-alba oil samples harvested in eight east moroccan locations were investigated by gc and gc/ms. chemical variability of the a. herba-alba oils is also discussed using statistical analysis. detailed analysis of the essential oils led to the identification of 52 components amounting to 80.5\u201398.6 % of the total oil. the investigated chemical compositions showed significant qualitative and quantitative differences. according to their major components (camphor, chrysanthenone, and \u03b1- and \u03b2-thujone), three main groups of essential oils were found. this study also found regional specificity of the major components.",
            "contribution_ids": [
                "R32287"
            ]
        },
        {
            "instance_id": "R32424xR32385",
            "comparison_id": "R32424",
            "paper_id": "R32385",
            "text": "Composition and intraspecific chemical vari- ability of the essential oil from Artemisia herba alba growing wild in a Tunisian arid zone the intraspecific chemical variability of essential oils (50 samples) isolated from the aerial parts of artemisia herba\u2010alba asso growing wild in the arid zone of southeastern tunisia was investigated. analysis by gc (ri) and gc/ms allowed the identification of 54 essential oil components. the main compounds were \u03b2\u2010thujone and \u03b1\u2010thujone, followed by 1,8\u2010cineole, camphor, chrysanthenone, trans\u2010sabinyl acetate, trans\u2010pinocarveol, and borneol. chemometric analysis (k\u2010means clustering and pca) led to the partitioning into three groups. the composition of two thirds of the samples was dominated by \u03b1\u2010thujone or \u03b2\u2010thujone. therefore, it could be expected that wild plants of a. herba\u2010alba randomly harvested in the area of kirchaou and transplanted by local farmers for the cultivation in arid zones of southern tunisia produce an essential oil belonging to the \u03b1\u2010thujone/\u03b2\u2010thujone chemotype and containing also 1,8\u2010cineole, camphor, and trans\u2010sabinyl acetate at appreciable amounts.",
            "contribution_ids": [
                "R32386"
            ]
        },
        {
            "instance_id": "R32424xR32369",
            "comparison_id": "R32424",
            "paper_id": "R32369",
            "text": "The essential oil from Artemisia herba-alba Asso cultivated in Arid Land (South Tunisia) abstract seedlings of artemisia herba-alba asso collected from kirchaou area were transplanted in an experimental garden near the institut des r\u00e9gions arides of m\u00e9denine (tunisia). during three years, the aerials parts were harvested (three levels of cutting, 25%, 50% and 75% of the plant), at full blossom and during the vegetative stage. the essential oil was isolated by hydrodistillation and its chemical composition was determined by gc(ri) and 13c-nmr. with respect to the quantity of vegetable material and the yield of hydrodistillation, it appears that the best results were obtained for plants cut at 50% of their height and during the full blossom. the chemical composition of the essential oil was dominated by \u03b2-thujone, \u03b1-thujone, 1,8-cineole, camphor and trans-sabinyl acetate, irrespective of the level of cutting and the period of harvest. it remains similar to that of plants growing wild in the same area.",
            "contribution_ids": [
                "R32370"
            ]
        },
        {
            "instance_id": "R32541xR32437",
            "comparison_id": "R32541",
            "paper_id": "R32437",
            "text": "\u00c2\u00abOver and Undereducation in the UK Graduate Labour Market\u00c2\u00bb abstract the authors examine the apparent underutilisation of the skills of employed graduates. as in the usa, concern has arisen in britain over the numbers of graduates working in jobs which might be carried out equally well by those with subdegree qualifications. the authors discuss whether or not overeducation represents a serious problem, outlining theoretical explanations of over- and undereducation. two measures of over/undereducation are then used to examine the british graduate jobs market. drawing on labour force survey data, the authors relate over- and undereducation to a range of personal and employment characteristics. they conclude that the significance of the problem of overeducation can be exaggerated, since it may represent a rational response of individuals to labour market conditions. they also point out that undereducation\u2014where people hold graduate-level jobs without possessing degrees\u2014is a form of labour market advantage which accrues disproportionately to white males.",
            "contribution_ids": [
                "R32438"
            ]
        },
        {
            "instance_id": "R32541xR32457",
            "comparison_id": "R32541",
            "paper_id": "R32457",
            "text": "\u00c2\u00abOvereducation and the Skills of UK Graduates\u00c2\u00bb summary.\\u2002 during the early 1990s the proportion of a cohort entering higher education in the uk doubled over a short period of time. the paper investigates the effect of the expansion on graduates\u2019 early labour market attainment, focusing on overeducation. we define overeducation by combining occupation codes and a self\u2010reported measure for the appropriateness of the match between qualification and the job. we therefore define three groups of graduates: matched, apparently overeducated and genuinely overeducated. this measure is well correlated with alternative definitions of overeducation. comparing pre\u2010 and post\u2010expansion cohorts of graduates, we find with this measure that the proportion of overeducated graduates has doubled, even though overeducation wage penalties have remained stable. we do not find that type of institution affects the probability of genuine overeducation. apparently overeducated graduates are mostly indistinguishable from matched graduates, whereas genuinely overeducated graduates principally lack non\u2010academic skills and suffer a large wage penalty. individual unobserved heterogeneity differs between the three groups of graduates but controlling for it does not alter these conclusions.",
            "contribution_ids": [
                "R32458",
                "R32504"
            ]
        },
        {
            "instance_id": "R32541xR32475",
            "comparison_id": "R32541",
            "paper_id": "R32475",
            "text": "\u00c2\u00abRecruitment of Overeducated Personnel: Insider-Outsider Effects on Fair Employee Selection Practice we analyze a standard employee selection model given two institutional constraints: first, professional experience perfectly substitutes insufficient formal education for insiders while this substitution is imperfect for outsiders. second, in the latter case the respective substitution rate increases with the advertised minimum educational requirement. optimal selection implies that the expected level of formal education is higher for outsider than for insider recruits. moreover, this difference in educational attainments increases with lower optimal minimum educational job requirements. investigating data of a large us public employer confirms both of the above theoretical implications. generally, the econometric model exhibits a \ufffdgood fit\ufffd.",
            "contribution_ids": [
                "R32476"
            ]
        },
        {
            "instance_id": "R32541xR32502",
            "comparison_id": "R32541",
            "paper_id": "R32502",
            "text": "OPTIMAL \u00e2\u0080\u0098MISMATCH\u00e2\u0080\u0099 AND PROMOTIONS \"seeming 'mismatches,' in which workers are either under- or overqualified, are shown to be optimal. from the firm's point of view, although turnover will be positively related to overqualification, training costs will be inversely related to overqualification. further, overqualified workers constitute a pool from which promotions are made. workers enter seeming mismatches due to search and mobility costs and because of opportunities for promotion. estimates using a unique data set indicate that workers who are overqualified at hire receive less training and more promotions and that workers overqualified for their current job are more likely to quit. copyright 1995 by oxford university press.\"",
            "contribution_ids": [
                "R32503"
            ]
        },
        {
            "instance_id": "R32541xR32529",
            "comparison_id": "R32541",
            "paper_id": "R32529",
            "text": "Overeducation, Undereducation and the British Labour Market this paper addresses the issue of overeducation and undereducation using for the first time a british dataset which contains explicit information on the level of required education to enter a job across the generality of occupations. three key issues within the overeducation literature are addressed. first, what determines the existence of over and undereducation and to what extent are over and undereducation substitutes for experience, tenure and training? second, to what extent are over and undereducation temporary or permanent phenomena? third, what are the returns to over and undereducation and do certain stylized facts discovered for the us and a number of european countries hold for britain?",
            "contribution_ids": [
                "R32530"
            ]
        },
        {
            "instance_id": "R32541xR32537",
            "comparison_id": "R32541",
            "paper_id": "R32537",
            "text": "The Impact of Schooling Surplus on Earnings: Some Additional Findings\u00c2\u00bb this paper examines the impact of overeducation (or surplus schooling) on earnings. overeducated workers are defined as those with educational attainments substantially above the mean for their specific occupations. two models are estimated using data from the 1980 census. though our models, data, and measure of overeducation are different from those used by rumberger (1987), our results are similar. our results show that overeducated workers often earn less than their adequately educated and undereducated counterparts.",
            "contribution_ids": [
                "R32538"
            ]
        },
        {
            "instance_id": "R32871xR32568",
            "comparison_id": "R32871",
            "paper_id": "R32568",
            "text": "Ship detection and classification from overhead imagery this paper presents a sequence of image-processing algorithms suitable for detecting and classifying ships from nadir panchromatic electro-optical imagery. results are shown of techniques for overcoming the presence of background sea clutter, sea wakes, and non-uniform illumination. techniques are presented to measure vessel length, width, and direction-of-motion. mention is made of the additional value of detecting identifying features such as unique superstructure, weaponry, fuel tanks, helicopter landing pads, cargo containers, etc. various shipping databases are then described as well as a discussion of how measured features can be used as search parameters in these databases to pull out positive ship identification. these are components of a larger effort to develop a low-cost solution for detecting the presence of ships from readily-available overhead commercial imagery and comparing this information against various open-source ship-registry databases to categorize contacts for follow-on analysis.",
            "contribution_ids": [
                "R32569"
            ]
        },
        {
            "instance_id": "R32871xR32571",
            "comparison_id": "R32871",
            "paper_id": "R32571",
            "text": "Measuring Overlap-Rate in Hierarchical Cluster Merging for Image Segmentation and Ship Detection in this paper, we present a definition on the degree of overlap between two clusters and develop an algorithm for calculating the overlap rate. using this theory, we also develop a new hierarchical cluster merging algorithm for image segmentation and apply it to the ship detection in high resolution image. in our experiment, we compare our method with several existing popular methods. experimental results demonstrate the effectiveness of the overlap rate measuring method and the new ship detection method.",
            "contribution_ids": [
                "R32572"
            ]
        },
        {
            "instance_id": "R32871xR32578",
            "comparison_id": "R32871",
            "paper_id": "R32578",
            "text": "Using SPOT-5 HRG Data in Panchromatic Mode for Operational Detection of Small Ships in Tropical Area nowadays, there is a growing interest in applications of space remote sensing systems for maritime surveillance which includes among others traffic surveillance, maritime security, illegal fisheries survey, oil discharge and sea pollution monitoring. within the framework of several french and european projects, an algorithm for automatic ship detection from spot\u20135 hrg data was developed to complement existing fishery control measures, in particular the vessel monitoring system. the algorithm focused on feature\u2013based analysis of satellite imagery. genetic algorithms and neural networks were used to deal with the feature\u2013borne information. based on the described approach, a first prototype was designed to classify small targets such as shrimp boats and tested on panchromatic spot\u20135, 5\u2013m resolution product taking into account the environmental and fishing context. the ability to detect shrimp boats with satisfactory detection rates is an indicator of the robustness of the algorithm. still, the benchmark revealed problems related to increased false alarm rates on particular types of images with a high percentage of cloud cover and a sea cluttered background.",
            "contribution_ids": [
                "R32579"
            ]
        },
        {
            "instance_id": "R32871xR32594",
            "comparison_id": "R32871",
            "paper_id": "R32594",
            "text": "Automatic ship detection in HJ-1A satellite data in this paper, we use hj-1a satellite data to ship detection and a ship target detection algorithm based on optical remote sensing images of moving window and entropy maximum is presented. the method uses a moving window to get ship candidates and the shannon theory to image segmentation. basic principle is that the entropy of the image segmented by the threshold value is max. after completing the image segmentation, an automatic discriminator is used. the identify algorithm is used to get rid of the false alarm caused by spray, cloudy and solar flare. some feature is considered include area, length ratio and extent. the detection results indicate that most ship target can be detected without regard to cloudy.",
            "contribution_ids": [
                "R32595"
            ]
        },
        {
            "instance_id": "R32871xR32610",
            "comparison_id": "R32871",
            "paper_id": "R32610",
            "text": "Ship detection in satellite imagery using rank-order grayscale hit-or-miss transforms \"ship detection from satellite imagery is something that has great utility in various communities. knowing where ships are and their types provides useful intelligence information. however, detecting and recognizing ships is a difficult problem. existing techniques suffer from too many false-alarms. we describe approaches we have taken in trying to build ship detection algorithms that have reduced false alarms. our approach uses a version of the grayscale morphological hit-or-miss transform. while this is well known and used in its standard form, we use a version in which we use a rank-order selection for the dilation and erosion parts of the transform, instead of the standard maximum and minimum operators. this provides some slack in the fitting that the algorithm employs and provides a method for tuning the algorithm's performance for particular detection problems. we describe our algorithms, show the effect of the rank-order parameter on the algorithm's performance and illustrate the use of this approach for real ship detection problems with panchromatic satellite imagery.\"",
            "contribution_ids": [
                "R32611"
            ]
        },
        {
            "instance_id": "R32871xR32612",
            "comparison_id": "R32871",
            "paper_id": "R32612",
            "text": "Ship detection by salient convex boundaries automatic ship detection from remote sensing imagery has many applications, such as maritime security, traffic surveillance, fisheries management. however, it is still a difficult task for noise and distractors. this paper is concerned with perceptual organization, which detect salient convex structures of ships from noisy images. because the line segments of contour of ships compose a convex set, a local gradient analysis is adopted to filter out the edges which are not on the contour as preprocess. for convexity is the significant feature, we apply the salience as the prior probability to detect. feature angle constraint helps us compute probability estimate and choose correct contour in many candidate closed line groups. finally, the experimental results are demonstrated on the satellite imagery from google earth.",
            "contribution_ids": [
                "R32613"
            ]
        },
        {
            "instance_id": "R32871xR32621",
            "comparison_id": "R32871",
            "paper_id": "R32621",
            "text": "Graph-based ship extraction scheme for optical satellite image automatic detection and recognition of ship in satellite images is very important and has a wide array of applications. this paper concentrates on optical satellite sensor, which provides an important approach for ship monitoring. graph-based fore/background segmentation scheme is used to extract ship candidant from optical satellite image chip after the detection step, from course to fine. shadows on the ship are extracted in a cfar scheme. because all the parameters in the graph-based algorithms and cfar are adaptively determined by the algorithms, no parameter tuning problem exists in our method. experiments based on measured optical satellite images shows our method achieved good balance between computation speed and ship extraction accuracy.",
            "contribution_ids": [
                "R32622"
            ]
        },
        {
            "instance_id": "R32871xR32625",
            "comparison_id": "R32871",
            "paper_id": "R32625",
            "text": "Ship detection in MODIS imagery understanding the capabilities of satellite sensors with spatial and spectral characteristics similar to those of modis for maritime domain awareness (mda) is of importance because of the upcoming npoes with 100 minutes revisit time carrying the modis-like viirs multispectral imaging sensor. this paper presents an experimental study of ship detection using modis imagery. we study the use of ship signatures such as contaminant plumes in clouds and the spectral contrast between the ship and the sea background for detection. results show the potential and challenges for such approach in mda.",
            "contribution_ids": [
                "R32626"
            ]
        },
        {
            "instance_id": "R32871xR32628",
            "comparison_id": "R32871",
            "paper_id": "R32628",
            "text": "A novel ship detection method based on sea state analysis from optical imagery this paper proposes a novel ship detection method based on analyzing the sea state in optical images. this method is composed of three phases. first, the image is segmented with the improved region splitting and merging method, which divides the sea into separated regions. then, the sea state of each divided region of sea is analyzed by extracting texture roughness and ripple density of a modified differential box counting (dbc) method. finally, an appropriate algorithm is applied to detect ships for each region of sea. experimental results test on 36 real remote sensing images and 133 images obtained from google earth demonstrate that the method is free of image resolution and has little limitation of sea conditions.",
            "contribution_ids": [
                "R32629"
            ]
        },
        {
            "instance_id": "R32871xR32638",
            "comparison_id": "R32871",
            "paper_id": "R32638",
            "text": "Saliency and gist features for target detection in satellite images reliably detecting objects in broad-area overhead or satellite images has become an increasingly pressing need, as the capabilities for image acquisition are growing rapidly. the problem is particularly difficult in the presence of large intraclass variability, e.g., finding \u201cboats\u201d or \u201cbuildings,\u201d where model-based approaches tend to fail because no good model or template can be defined for the highly variable targets. this paper explores an automatic approach to detect and classify targets in high-resolution broad-area satellite images, which relies on detecting statistical signatures of targets, in terms of a set of biologically-inspired low-level visual features. broad-area images are cut into small image chips, analyzed in two complementary ways: \u201cattention/saliency\u201d analysis exploits local features and their interactions across space, while \u201cgist\u201d analysis focuses on global nonspatial features and their statistics. both feature sets are used to classify each chip as containing target(s) or not, using a support vector machine. four experiments were performed to find \u201cboats\u201d (experiments 1 and 2), \u201cbuildings\u201d (experiment 3) and \u201cairplanes\u201d (experiment 4). in experiment 1, 14 416 image chips were randomly divided into training (300 boat, 300 nonboat) and test sets (13 816), and classification was performed on the test set (roc area: 0.977 \u00b10.003). in experiment 2, classification was performed on another test set of 11 385 chips from another broad-area image, keeping the same training set as in experiment 1 (roc area: 0.952 \u00b10.006). in experiment 3, 600 training chips (300 for each type) were randomly selected from 108 885 chips, and classification was conducted (roc area: 0.922 \u00b10.005). in experiment 4, 20 training chips (10 for each type) were randomly selected to classify the remaining 2581 chips (roc area: 0.976 \u00b10.003). the proposed algorithm outperformed the state-of-the-art sift, hmax, and hidden-scale salient structure methods, and previous gist-only features in all four experiments. this study shows that the proposed target search method can reliably and effectively detect highly variable target objects in large image datasets.",
            "contribution_ids": [
                "R32639"
            ]
        },
        {
            "instance_id": "R32871xR32643",
            "comparison_id": "R32871",
            "paper_id": "R32643",
            "text": "Detection and classification of man-made offshore objects in TerraSAR-X and RapidEye imagery: Selected results of the DeMarine-DEKO project the project deko (detection of artificial objects in sea areas) is integrated in the german demarine-security project and focuses on the detection and classification of ships and offshore artificial objects relying on terrasar-x as well as on rapideye multispectral optical images. the objectives are 1/ the development of reliable detection algorithms and 2/ the definition of effective, customized service concepts. in addition to an earlier publication, we describe in the following paper some selected results of our work. the algorithms for terrasar-x have been extended to a processing chain including all needed steps for ship detection and ship signature analysis, with an emphasis on object segmentation. for rapid eye imagery, a ship detection algorithm has been developed. finally, some applications are described: ship monitoring in the strait of dover based on terrasar-x stripmap using ais information for verification, analyzing terrasar-x highresolution scenes of an industrial harbor and finally an example of surveying a wind farm using change detection.",
            "contribution_ids": [
                "R32644"
            ]
        },
        {
            "instance_id": "R32871xR32651",
            "comparison_id": "R32871",
            "paper_id": "R32651",
            "text": "A Novel Algorithm for Ship Detection Based on Dynamic Fusion Model of Multi-feature and Support Vector Machine ship detection is one of the most important applications of target recognition based on optical remote sensing images. in this paper, we propose an uncertain ship target extraction algorithm based on dynamic fusion model of multi-feature and variance feature of optical remote sensing image. we choose several geometrical features, such as length, wide, rectangular ratio, tightness ratio and so on, using svm to train and predict the uncertain ship targets extracted by our algorithm automatically. experiments show that our algorithm is very robust, and the recognition rate of our algorithm can reach or even better than 95%, with the false alarm rate is kept at 3%.",
            "contribution_ids": [
                "R32652"
            ]
        },
        {
            "instance_id": "R32871xR32656",
            "comparison_id": "R32871",
            "paper_id": "R32656",
            "text": "A sea-land segmentation scheme based on statistical model of sea sea-land segmentation is a key step for target detection. due to the complex texture and uneven gray value of the land in optical remote sensing image, traditional sea-land segmentation algorithms often recognize land as sea incorrectly. a new segmentation scheme is presented in this paper to solve this problem. this scheme determines the threshold according to the adaptively established statistical model of the sea area, and removes the incorrectly classified land according to the difference of the variance in the statistical model between land and sea. experimental results show our segmentation scheme has small computation complexity, and it has better performance and higher robustness compared to the traditional algorithms.",
            "contribution_ids": [
                "R32657"
            ]
        },
        {
            "instance_id": "R32871xR32709",
            "comparison_id": "R32871",
            "paper_id": "R32709",
            "text": "A new method on inshore ship detection in high-resolution satellite images using shape and context information in this letter, we present a new method to detect inshore ships using shape and context information. we first propose a new energy function based on an active contour model to segment water and land and minimize it with an iterative global optimization method. the proposed energy performs well on the different intensity distributions between water and land and produces a result that can be well used in shape and context analyses. in the segmented image, ships are detected with successive shape analysis, including shape analysis in the localization of ship head and region growing in computing the width and length of ship. finally, to locate ships accurately and remove the false alarms, we unify them with a binary linear programming problem by utilizing the context information. experiments on quickbird images show the robustness and precision of our method.",
            "contribution_ids": [
                "R32710"
            ]
        },
        {
            "instance_id": "R32871xR32714",
            "comparison_id": "R32871",
            "paper_id": "R32714",
            "text": "Ship detection in high-resolution optical imagery based on anomaly detector and local shape feature ship detection in high-resolution optical imagery is a challenging task due to the variable appearances of ships and background. this paper aims at further investigating this problem and presents an approach to detect ships in a \u201ccoarse-to-fine\u201d manner. first, to increase the separability between ships and background, we concentrate on the pixels in the vicinities of ships. we rearrange the spatially adjacent pixels into a vector, transforming the panchromatic image into a \u201cfake\u201d hyperspectral form. through this procedure, each produced vector is endowed with some contextual information, which amplifies the separability between ships and background. afterward, for the \u201cfake\u201d hyperspectral image, a hyperspectral algorithm is applied to extract ship candidates preliminarily and quickly by regarding ships as anomalies. finally, to validate real ships out of ship candidates, an extra feature is provided with histograms of oriented gradients (hogs) to generate a hypothesis using adaboost algorithm. this extra feature focuses on the gray values rather than the gradients of an image and includes some information generated by very near but not closely adjacent pixels, which can reinforce hog to some degree. experimental results on real database indicate that the hyperspectral algorithm is robust, even for the ships with low contrast. in addition, in terms of the shape of ships, the extended hog feature turns out to be better than hog itself as well as some other features such as local binary pattern.",
            "contribution_ids": [
                "R32715"
            ]
        },
        {
            "instance_id": "R32871xR32731",
            "comparison_id": "R32871",
            "paper_id": "R32731",
            "text": "Rotation Sliding Window of the Hog Feature in Remote Sensing Images for Ship Detection ship detection plays a relatively vital role in the effect of the traditional of military. in remote sensing image, we combined histograms of oriented gradients features and support vector machine for ship detection. however, hog feature does not have a rotation of invariant, ship can be in any direction. consequently, in this paper, we proposes a measure of continuous interval rotating detection sliding window of hog feature. we extract and train hog feature of positive and negative samples. then, continuous interval rotating sliding window of hog feature to improve the accuracy of detecting ship. the experiments reveal that the detection rate can reach high of 72.7% in the vertical direction of test ship. it is of practical significance for civil and military field.",
            "contribution_ids": [
                "R32732"
            ]
        },
        {
            "instance_id": "R32871xR32733",
            "comparison_id": "R32871",
            "paper_id": "R32733",
            "text": "A remote sensing ship recognition method based on co-training model aiming at detecting sea targets efficiently, an approach using optical remote sensing data based on co-training model is proposed. firstly, using size, texture, shape, moment invariants features and ratio codes, feature extraction is realized. secondly, based on rough set theory, the common discernibility degree is used to select valid recognition features automatically. finally, a co-training model for classification is introduced. firstly, two diverse ruducts are generated, and then the model employs them to train two base classifiers on labeled dada, and makes two base classifiers teach each other on unlabeled data to boot their performance iteratively. experimental results show the proposed approach can get better performance than k-nearest neighbor (knn), support vector machines (svm), traditional hierarchical discriminant regression (hdr).",
            "contribution_ids": [
                "R32734",
                "R32735"
            ]
        },
        {
            "instance_id": "R32871xR32745",
            "comparison_id": "R32871",
            "paper_id": "R32745",
            "text": "Ship detection for high resolution optical imagery with adaptive target filter ship detection is important due to both its civil and military use. in this paper, we propose a novel ship detection method, adaptive target filter (atf), for high resolution optical imagery. the proposed framework can be grouped into two stages, where in the first stage, a test image is densely divided into different detection windows and each window is transformed to a feature vector in its feature space. the histograms of oriented gradients (hog) is accumulated as a basic feature descriptor. in the second stage, the proposed atf highlights all the ship regions and suppresses the undesired backgrounds adaptively. each detection window is assigned a score, which represents the degree of the window belonging to a certain ship category. the atf can be adaptively obtained by the weighted logistic regression (wlr) according to the distribution of backgrounds and targets of the input image. the main innovation of our method is that we only need to collect positive training samples to build the filter, while the negative training samples are adaptively generated by the input image. this is different to other classification method such as support vector machine (svm) and logistic regression (lr), which need to collect both positive and negative training samples. the experimental result on 1-m high resolution optical images shows the proposed method achieves a desired ship detection performance with higher quality and robustness than other methods, e.g., svm and lr.",
            "contribution_ids": [
                "R32746"
            ]
        },
        {
            "instance_id": "R32871xR32762",
            "comparison_id": "R32871",
            "paper_id": "R32762",
            "text": "Compressed-Domain Ship Detection on Spaceborne Optical Image Using Deep Neural Network and Extreme Learning Machine ship detection on spaceborne images has attracted great interest in the applications of maritime security and traffic control. optical images stand out from other remote sensing images in object detection due to their higher resolution and more visualized contents. however, most of the popular techniques for ship detection from optical spaceborne images have two shortcomings: 1) compared with infrared and synthetic aperture radar images, their results are affected by weather conditions, like clouds and ocean waves, and 2) the higher resolution results in larger data volume, which makes processing more difficult. most of the previous works mainly focus on solving the first problem by improving segmentation or classification with complicated algorithms. these methods face difficulty in efficiently balancing performance and complexity. in this paper, we propose a ship detection approach to solving the aforementioned two issues using wavelet coefficients extracted from jpeg2000 compressed domain combined with deep neural network (dnn) and extreme learning machine (elm). compressed domain is adopted for fast ship candidate extraction, dnn is exploited for high-level feature representation and classification, and elm is used for efficient feature pooling and decision making. extensive experiments demonstrate that, in comparison with the existing relevant state-of-the-art approaches, the proposed method requires less detection time and achieves higher detection accuracy.",
            "contribution_ids": [
                "R32763"
            ]
        },
        {
            "instance_id": "R32871xR32802",
            "comparison_id": "R32871",
            "paper_id": "R32802",
            "text": "A real-time on-board ship targets detection method for optical remote sensing satellite optical remote sensing satellite holds great potential for ship detection. however, it is challenging for real-time detection due to the relatively low resolution and complicated background. we propose a real-time on-board ship detection method based on statistical analysis and shape identification. first, gaussian and median filter are used to reduce the periodical and pepper noise generated by the camera sensor system. then, mathematical morphology processing is employed to remove the background interference and thus enhances the ship targets. next, statistic analysis is performed on inspected and neighbor areas to distinguish the suspected ship target and pure-sea, land, islands or strong waves. finally, features, such as the length-width ratio, circular degree of the suspected targets, are used to detect the targets. the proposed method was implemented on a single fpga and was validated on real high-orbit optical satellite images. for an image as large as 1024\u00d71024 of 8bits, the computation time was less than 10 seconds. the detection rate was above 90% while the false alarm rate was under 5%. the experimental results demonstrate the ability to support low-power consumption, miniaturization for the real-time ship targets detection on-board.",
            "contribution_ids": [
                "R32803"
            ]
        },
        {
            "instance_id": "R32871xR32813",
            "comparison_id": "R32871",
            "paper_id": "R32813",
            "text": "A Novel Inshore Ship Detection via Ship Head Classification and Body Boundary Determination in this letter, we propose a novel method for inshore ship detection via ship head classification and body boundary determination. compared with some traditional ship head detection methods depending on accurate ship head segmentation, we generate novel ship head features in the transformed domain of polar coordinate, where the ship heads have an approximate trapezoid shape and can be more easily detected. then, these features are used in the classification based on support vector machine to detect the ship head candidates, and give the important information of initial ship head direction. next, the surrounding consistent line segments are utilized to refine the ship direction, and the ship boundary is determined based on the saliency of directional gradient information symmetrical about the ship body. finally, the context information of sea areas is introduced to remove false alarms. experimental results show that the proposed method can accurately and robustly detect the inshore ships in high-resolution optical remote sensing images.",
            "contribution_ids": [
                "R32814"
            ]
        },
        {
            "instance_id": "R32871xR32819",
            "comparison_id": "R32871",
            "paper_id": "R32819",
            "text": "Ship detection based on surface fitting modeling for large range background of ocean images \"for the seawater background interference problem in ship detection of high resolution remote sensing images, the characteristics of seawater background are analyzed deeply in this paper. and it's found that there is consistent in local but continuous variation in large range. on the basis of above analysis, a gauss variable surface seawater background model for high resolution remote sensing images is built, and the estimation of mean surface and variance surface are also given. then, a novel ship detection method based on sea background statistical modeling is proposed for large range high resolution remote sensing images. the experimental results show the feasibility of our proposed method in sea background modeling and target detection for different kinds of high resolution remote sensing images. compared with the other relative method, the proposed method has higher recall rate and lower missing rate.\"",
            "contribution_ids": [
                "R32820"
            ]
        },
        {
            "instance_id": "R32871xR32830",
            "comparison_id": "R32871",
            "paper_id": "R32830",
            "text": "Ship Rotated Bounding Box Space for Ship Extraction From High-Resolution Optical Satellite Images With Complex Backgrounds extracting ships from complex backgrounds is the bottleneck of ship detection in high-resolution optical satellite images. in this letter, we propose a nearly closed-form ship rotated bounding box space used for ship detection and design a method to generate a small number of highly potential candidates based on this space. we first analyze the possibility of accurately covering all ships by labeling rotated bounding boxes. moreover, to reduce search space, we construct a nearly closed-form ship rotated bounding box space. then, by scoring for each latent candidate in the space using a two-cascaded linear model followed by binary linear programming, we select a small number of highly potential candidates. moreover, we also propose a fast version of our method. experiments on our data set validate the effectiveness of our method and the efficiency of its fast version, which achieves a close detection rate in near real time.",
            "contribution_ids": [
                "R32831"
            ]
        },
        {
            "instance_id": "R32871xR32833",
            "comparison_id": "R32871",
            "paper_id": "R32833",
            "text": "Attribute learning for ship category recognition in remote sensing imagery object category recognition, in remote sensing imagery, usually relies on exemplar-based training. the latter is achieved by modeling intricate relationships between object categories and visual features. however, for real-world and fine grained object categories - exhibiting complex visual appearance and strong variability - these models may fail especially when training data are scarce. in this paper, we introduce an effective object category recognition approach that alleviates the limitation caused by small training sets. the method learns discriminant mid-level representations (a.k.a. attributes) through nonlinear mappings that make these attributes highly discriminant while being easily trainable and predictable. we demonstrate the effectiveness of our method, through extensive experiments on the challenging task of ship recognition in maritime environments, and we show how our attribute learning model generalizes well in spite of the scarcity of training data.",
            "contribution_ids": [
                "R32834"
            ]
        },
        {
            "instance_id": "R32871xR32836",
            "comparison_id": "R32871",
            "paper_id": "R32836",
            "text": "A ship target automatic recognition method for sub-meter remote sensing images the spatial resolution is increasingly high as development of optical remote sensing, and more and more optical sensors can achieve the detection ability of sub meter, which lays down the data foundation for automatic recognition of ship targets. however, mature technology is lacked to identify the ship models automatically with remote sensing images. in this study, an automatic recognition method for ship targets is proposed based on the local invariant feature extraction algorithm sift (scale invariant feature transform), which is consist of feature extraction and description, feature matching and target recognition. the model of unknown target is identified based on the target library using the matching difference of targets with the same model and different models. the experiment results show that this automatic recognition flow is effective to identify the ship targets of interest based on the target library, and the total correct recognition rate is 92%. this method provides a new flow for automatic model recognition of ship targets, and has considerable potential for wide applications.",
            "contribution_ids": [
                "R32837"
            ]
        },
        {
            "instance_id": "R32871xR32838",
            "comparison_id": "R32871",
            "paper_id": "R32838",
            "text": "A ship target automatic detection method for high-resolution remote sensing with the increasement of spatial resolution of remote sensing, the ship detection methods for low-resolution images are no longer suitable. in this study, a ship target automatic detection method for high-resolution remote sensing is proposed, which mainly contains steps of otsu binary segmentation, morphological operation, calculation of target features and target judgment. the results show that almost all of the offshore ships can be detected, and the total detection rates are 94% and 91% with the experimental google earth data and gf-1 data respectively. the ship target automatic detection method proposed in this study is more suitable for detecting ship targets offshore rather than anchored along the dock.",
            "contribution_ids": [
                "R32839"
            ]
        },
        {
            "instance_id": "R32871xR32847",
            "comparison_id": "R32871",
            "paper_id": "R32847",
            "text": "Fast ship detection from optical satellite images based on ship distribution probability analysis automatic ship detection from optical satellite images remains a tough task. in this paper, a novel method of ship detection from optical satellites is proposed by analyzing the ship distribution probability. first, an anomaly detection model is constructed by the sea cluster histogram model; then, the ship distribution based on the ship safety navigational criterion is analyzed to obtain the ship candidates, and obvious non-ship objects are removed by the area properties from ship candidates; finally, a structural continuity descriptor is designed to remove false alarms from the ship candidates. experiments on numerous satellite images from panchromatic and one band within multispectral sensors are conducted. the results verified that the proposed method outperforms existing methods in both effectiveness and efficiency.",
            "contribution_ids": [
                "R32848"
            ]
        },
        {
            "instance_id": "R32871xR32851",
            "comparison_id": "R32871",
            "paper_id": "R32851",
            "text": "Ship detection in panchromatic images: a new method and its DSP implementation in this paper, a new ship detection method is proposed after analyzing the characteristics of panchromatic remote sensing images and ship targets. firstly, adaboost(adaptive boosting) classifiers trained by haar features are utilized to make coarse detection of ship targets. then lsd (line segment detector) is adopted to extract the line features in target slices to make fine detection. experimental results on a dataset of panchromatic remote sensing images with a spatial resolution of 2m show that the proposed algorithm can achieve high detection rate and low false alarm rate. meanwhile, the algorithm can meet the needs of practical applications on dsp (digital signal processor).",
            "contribution_ids": [
                "R32852"
            ]
        },
        {
            "instance_id": "R32871xR32546",
            "comparison_id": "R32871",
            "paper_id": "R32546",
            "text": "Ship detection from Landsat imagery recent inspection of landsat cct printouts revealed that the detection of ships is possible. experience has shown that mss band 7, because of low radiance values from water and the resultant high s/n ratio, is the best mss band for a \"quick look\" inspection of cct printouts for possible ships. following verification of the target on cct printouts of other mms bands the ship\\'s size, orientation, state of motion, and direction of movement can be determined from the total number of pixels occupied by the target for each mss band, the orientation of these pixels, and the target\\'s maximum and total pixel radiance values. this paper presents the procedures used for detecting ships, and discusses the problems and limitations of the overall technique as related to ship parameters, sea state and turbidity, pixel overlap, relative geometric fidelity between pixels, and solar elevation angle. /author/",
            "contribution_ids": [
                "R32547"
            ]
        },
        {
            "instance_id": "R32871xR32669",
            "comparison_id": "R32871",
            "paper_id": "R32669",
            "text": "A method of ship detection from spaceborne optical image operational sdsoi and novel hierarchical complete approach based on shape and texture properties, whic h is considered a sequential coarse-to-fine deleting pro cess of fake alarms. simple shape analysis is adopt ed to delete evident fake candidates generated by image segmentation with world and local information and to extrac t ship candidates with missing alarms as low as possible a nd a novel semi supervised hierarchical classificat ion approach based on different features is presented to disting uish between ships and non ships besides a complete and operational sdsoi approach, the other contributions of our approach include the following three aspect s: 1) it identify ship candidates by using their class proba bility distributions rather than the extracted feat ures; 2) the related classes are automatically built by the samples\u2019 app earances and their feature attribute in a semi supe rvised mode; and 3) besides commonly used shape and texture features, a new texture operator, i.e., local multiple patterns, is introduced to enhance the representation ability of the feature set in feature extraction. experimenta l results of sdsoi on a big image set captured by optical sensor s from multiple satellites show that our approach i s effective in distinguishing between ships and non ships, and obt ains a well ship detection performance.",
            "contribution_ids": [
                "R32670"
            ]
        },
        {
            "instance_id": "R32914xR32881",
            "comparison_id": "R32914",
            "paper_id": "R32881",
            "text": "E-Government and Public Financial Reporting: The Case of Spanish Regional Governments \" technology has changed the way public organizations relate to the public. government's use of the internet and other associated technologies, known as e-government, could become the instrument that makes regular timely information on public finances more forthcoming. new technologies can improve government responsiveness and empower individual citizens. by making government financial information available, the public could continuously assess a government agency through everyday interaction. the financial accountability of government and its response to public demands for information and services are thus a contribution to government openness. it is therefore relevant to determine whether public organizations are also becoming more aware of the importance of placing financial information on their web sites to help in decision-making processes. this article focuses on the e-democracy process, specifically the transparency of government information, by analyzing governmental financial disclosures on the web as a tool for the public to assess its financial accountability. to this end, an empirical study was carried out on regional governments in spain. \"",
            "contribution_ids": [
                "R32882"
            ]
        },
        {
            "instance_id": "R32914xR32895",
            "comparison_id": "R32914",
            "paper_id": "R32895",
            "text": "Accountability Disclosures by Queensland Local Government Councils: 1997\u00e2\u0080\u00931999 the annual report is promoted and regarded as the primary medium of accountability for government agencies. in australia, anecdotal evidence suggests the quality of annual reports is variable. however, there is scant empirical evidence on the quality of reports. the aim of this research is to gauge the quality of annual reporting by local governments in queensland, and to investigate the factors that may contribute to that level of quality. the results of the study indicate that although the quality of reporting by local governments has improved over time, councils generally do not report information on aspects of corporate governance, remuneration of executive staff, personnel, occupational health and safety, equal opportunity policies, and performance information. in addition, the results indicate there is a correlation between the size of the local government and the quality of reporting but the quality of disclosures is not correlated with the timeliness of reports. the study will be of interest to the accounting profession, public sector regulators who are responsible for the integrity of the accountability mechanisms and public sector accounting practitioners. it will form the basis for future longitudinal research, which will map changes in the quality of local government annual reporting.",
            "contribution_ids": [
                "R32896"
            ]
        },
        {
            "instance_id": "R32914xR32911",
            "comparison_id": "R32914",
            "paper_id": "R32911",
            "text": "Economic Incentives and the Choice of State Government Accounting Practices several recent studies have examined possible economic determinants of accounting policy choices of local government entities. for example, zimmerman [1977] and maher and keller [1978] proposed economic reasons for the current (diverse) state of municipal accounting and financial reporting, and evans and patton [1983] identified economic incentives leading to participation in the municipal finance officers association certificate of conformance program. a recent survey by the council on state governments (csg) [1980], in its summary of major accounting and reporting practices for individual state governments, characterizes both the general status of state government accounting and the diversity of accounting practices observed across states. using the data reported by the csg and some of the economic arguments offered in earlier research, this study provides preliminary evidence on the association between economic factors and cross-sectional variations in accounting practices of state governments. the specific evidence presented is characteristic of states that report quantitatively",
            "contribution_ids": [
                "R32912"
            ]
        },
        {
            "instance_id": "R32940xR32928",
            "comparison_id": "R32940",
            "paper_id": "R32928",
            "text": "Risk Factors for Anastomotic Leak and Mortality in Diabetic Patients Undergoing Colectomy objectives\\nto determine the risk factors in diabetic patients that are associated with increased postcolectomy mortality and anastomotic leak.\\n\\n\\ndesign\\na prospectively acquired statewide database of patients who underwent colectomy was reviewed. primary risk factors were diabetes mellitus, hyperglycemia (glucose level \u2265 140 mg/dl), steroid use, and emergency surgery. categorical analysis, univariate logistic regression, and multivariate regression were used to evaluate the effects of these risk factors on outcomes.\\n\\n\\nsetting\\nparticipating hospitals within the michigan surgical quality collaborative.\\n\\n\\npatients\\ndatabase review of patients from hospitals within the michigan surgical quality collaborative.\\n\\n\\nmain outcome measures\\nanastomotic leak and 30- day mortality rate.\\n\\n\\nresults\\nof 5123 patients, 153 (3.0%) had leaks and 153 (3.0%) died. preoperative hyperglycemia occurred in 15.6% of patients, only 54% of whom were known to have diabetes. multivariate analysis showed that the risk of leak for patients with and without diabetes increased only by preoperative steroid use (p<.05). mortality among diabetic patients was associated with emergency surgery (p<.01) and anastomotic leak (p<.05); it was not associated with hyperglycemia. mortality among nondiabetic patients was associated with hyperglycemia (p<.005). the presence of an anastomotic leak was associated with increased mortality among diabetic patients (26.3% vs 4.5%; p<.001) compared with nondiabetic patients (6.0% vs 2.5%; p<.05).\\n\\n\\nconclusions\\nthe presence of diabetes did not have an effect on the presence of an anastomotic leak, but diabetic patients who had a leak had more than a 4-fold higher mortality compared with nondiabetic patients. preoperative steroid use led to increased rates of anastomotic leak in diabetic patients. mortality was associated with hyperglycemia for nondiabetic patients only. improved screening may identify high-risk patients who would benefit from perioperative intervention.",
            "contribution_ids": [
                "R32929"
            ]
        },
        {
            "instance_id": "R32940xR32936",
            "comparison_id": "R32940",
            "paper_id": "R32936",
            "text": "Smoking is a major risk factor for anastomotic leak in patients undergoing low anterior resection aim\\u2002 to examine modifiable risk factors for anastomotic leak in patients undergoing low anterior resection.",
            "contribution_ids": [
                "R32937"
            ]
        },
        {
            "instance_id": "R33008xR32995",
            "comparison_id": "R33008",
            "paper_id": "R32995",
            "text": "Chromosomal abnormalities in untreated patients with non-Hodgkin\u00e2\u0080\u0099s lymphoma: associations with histology, clinical characteristics, and treatment outcome. The Nebraska Lymphoma Study Group \" abstract \\n we describe the chromosomal abnormalities found in 104 previously untreated patients with non-hodgkin's lymphoma (nhl) and the correlations of these abnormalities with disease characteristics. the cytogenetic method used was a 24- to 48-hour culture, followed by g- banding. several significant associations were discovered. a trisomy 3 was correlated with high-grade nhl. in the patients with an immunoblastic nhl, an abnormal chromosome no. 3 or 6 was found significantly more frequently. as previously described, a t(14;18) was significantly correlated with a follicular growth pattern. abnormalities on chromosome no. 17 were correlated with a diffuse histology and a shorter survival. a shorter survival was also correlated with a +5, +6, +18, all abnormalities on chromosome no. 5, or involvement of breakpoint 14q11\u201312. in a multivariate analysis, these chromosomal abnormalities appeared to be independent prognostic factors and correlated with survival more strongly than any traditional prognostic variable. patients with a t(11;14)(q13;q32) had an elevated lactate dehydrogenase (ldh). skin infiltration was correlated with abnormalities on 2p. abnormalities involving breakpoints 6q11\u201316 were correlated with b symptoms. patients with abnormalities involving breakpoints 3q21\u201325 and 13q21\u201324 had more frequent bulky disease. the correlations of certain clinical findings with specific chromosomal abnormalities might help unveil the pathogenetic mechanisms of nhl and tailor treatment regimens. \"",
            "contribution_ids": [
                "R32996"
            ]
        },
        {
            "instance_id": "R33008xR33003",
            "comparison_id": "R33008",
            "paper_id": "R33003",
            "text": "Abnormalities of chromosome 1p \u00e2\u0081\u0084 q are highly associated with chromosome 13 \u00e2\u0081\u0084 13q deletions and are an adverse prognostic factor for the outcome of high-dose chemotherapy in patients with multiple myeloma the prognostic value of chromosomal abnormalities was studied in untreated multiple myeloma patients who were registered into a prospective randomised multicentre phase 3 study for intensified treatment (hovon24). a total of 453 patients aged less than 66\\u2003years with stage ii and iii a/b disease were registered in the clinical study. cytogenetic analysis was introduced as a standard diagnostic assay in 1998. it was performed at diagnosis in 160 patients and was successful in 137/160 patients (86%). an abnormal karyotype was observed in 53/137 (39%) of the patients. abnormalities of chromosome 1p and 1q were found in 19 (36% of patients with an abnormal karyotype) and 21 patients (40%). there was a strong association between chromosome 1p and/or 1q abnormalities and deletion of chromosome 13 or 13q (n\\u2003=\\u200327, p\\u2003<\\u20030\u00b7001). patients with karyotypic abnormalities had a significantly shorter overall survival (os) than patients with normal karyotypes. complex abnormalities, hypodiploidy, chromosome 1p abnormalities, chromosome 1q abnormalities, and chromosome 13 abnormalities were associated with inferior os on univariate analysis, as well as after adjustment for other prognostic factors. in conclusion, chromosome 13 abnormalities and chromosome 1p and/or 1q abnormalities were highly associated, and are risk factors for poor outcome after intensive therapy in multiple myeloma.",
            "contribution_ids": [
                "R33004"
            ]
        },
        {
            "instance_id": "R33091xR33009",
            "comparison_id": "R33091",
            "paper_id": "R33009",
            "text": "Partial trisomy of the long arm of chromosome 1 in myelofibrosis and polycythemia vera we have identified partial trisomy 1q in 2 patients with different hematologic disorders. the first patient was a 55\u2010year\u2010old female with myelosclerosis and myeloid metaplasia diagnosed at age 38 years presenting with anemia, fatigue, bruising, fever, and splenomegaly. at age 56, she had 50\u201395% myeloblast cells and 95\u2013100 nucleated rbc precursors per 100 wbc. chromosome analysis of unstimulated leukocytes with q, g, and c banding showed 46,xx,\u20106,+t(1;6) (q25;p22) in all metaphase cells. in vitro incorporation of fe55 was demonstrated in 90% of metaphases by autoradiography. the second patient, a 49\u2010year\u2010old male, was diagnosed as having polycythemia vera at age 30 during a regular checkup. he since developed hepatosplenomegaly. chromosome analysis from a direct bone marrow preparation at age 44 and 45 showed grossly normal karyotypes. at age 49, his marrow by q and g banding showed almost 100% of cells with 46,xy,\u201313,+t(1;13) (q12;p12). eleven cases of trisomy of 1q have been reported in various hematologic disorders. it is apparent that partial trisomy 1q represents another nonrandom chromosomal abnormality, in addition to the most common nonrandom chromosomal aberrations, such as the philadelphia chromosome, trisomy 8, trisomy 9, and monosomy 7 in hematologic disorders.",
            "contribution_ids": [
                "R33010"
            ]
        },
        {
            "instance_id": "R33091xR33013",
            "comparison_id": "R33091",
            "paper_id": "R33013",
            "text": "An identical translocation between chromosome 1 and 7 in three patients with myelofibrosis and myeloid metaplasia summary. an identical chromosome abnormality was observed in three unrelated patients with myelofibrosis and myeloid metaplasia, two of the patients showing a history of polycythaemia vera (pv) before development of the myelofibrosis. unstimulated peripheral blood cultures showed a translocation between chromosomes 1 and 7 replacing a homologue of pair 7. it was identified by g\u2010 and c\u2010banding as t(1;7)(7pter\u21927p11::1p1?\u21921qter).",
            "contribution_ids": [
                "R33014"
            ]
        },
        {
            "instance_id": "R33091xR33033",
            "comparison_id": "R33091",
            "paper_id": "R33033",
            "text": "Cytogenetic studies and their prognostic significance in agnogenic myeloid metaplasia: a report on 47 cases abstract \\n cytogenetic analysis was performed in 47 newly diagnosed patients with agnogenic myeloid metaplasia (amm); 32 had a normal karyotype (68%, group i), whereas 15 had clonal abnormalities (32%, group ii). the most frequent abnormal findings were a 20q- deletion in six cases (either alone or within complex anomalies), interstitial 13q- deletion in three cases (and monosomy 13 in one case), and acquired trisomy 21 or 21p+ in three cases. four cases exhibited complex aberrations involving several chromosomes, sometimes with a mosaicism. in two patients with an initial abnormal karyotype, further cytogenetic analysis during the disease course showed the appearance of additional clonal anomalies, and particularly of a probable philadelphia (ph1) variant in one case. treatment was essentially supportive. survival was significantly shorter in group ii (median, 30 months) compared with group i (median, not reached at 6 years; p = .015). in univariate analysis, other parameters significantly associated with a poor prognosis (p less than .05) were higher age, anemia, and increased percentage of circulating blasts. however, in a multivariate analysis, only cytogenetic abnormalities and age retained their independent prognostic value.",
            "contribution_ids": [
                "R33034"
            ]
        },
        {
            "instance_id": "R33091xR33086",
            "comparison_id": "R33091",
            "paper_id": "R33086",
            "text": "Prognostic relevance of cytogenetics determined by fluorescent in situ hybridization in patients having myelofibrosis with myeloid metaplasia in chronic myelofibrosis (mf), distinct recurrent cytogenetic aberrations have been identified but their true prognostic relevance remains uncertain. in this disease, cytogenetic studies as assessed by conventional metaphase karyotyping are limited due to the inherent difficulties in obtaining adequate bone marrow aspirates and the low proliferative capacity of the clonal cells. interphase fluorescent in situ hybridization (fish) can partly overcome these limitations and increase the sensitivity of cytogenetic assessment in mf.",
            "contribution_ids": [
                "R33087"
            ]
        },
        {
            "instance_id": "R33581xR33213",
            "comparison_id": "R33581",
            "paper_id": "R33213",
            "text": "Virtual supply-chain management in global business competition, companies believe greater transparency in supply-chain operations and collaboration is very important for success. transparency brings accountability and responsibility. this openness in the supply-chain allows companies to see how their suppliers are performing, from their sourcing of raw materials to their delivery to the retail outlet. achieving greater transparency in the supply chain requires the development of comprehensive e-logistics tools, which provide all players with open communication and shared information in every stage of the order-to-delivery process. supply-chain transparency in ordering, inventory and transportation is a prerequisite for optimization and is critical for making business decisions. in this paper, the experiences of a virtual supply-chain (vsc) company are discussed with reference to the strategies, methods and technologies of its supply-chain. the supply-chain aims for improved customer satisfaction and hence for overall competitiveness in a global market. this discussion will be useful for other companies intending to emulate some of the critical success factors in vsc management.",
            "contribution_ids": [
                "R33214"
            ]
        },
        {
            "instance_id": "R33581xR33245",
            "comparison_id": "R33581",
            "paper_id": "R33245",
            "text": "Assessing supply chain management success factors: a case study purpose the purpose of this study is to examine important operational issues related to strategic success factors that are necessary when implementing scm plans in an organization. design/methodology/approach a questionnaire was distributed to top and middle management within a large manufacturing firm, specializing in producing consumer and building products, to examine the importance and the extent to which the selected manufacturing company practiced the strategies based on these identified operational issues. findings reducing cost of operations, improving inventory, lead times and customer satisfaction, increasing flexibility and cross\u2010functional communication, and remaining competitive appear to be the most important objectives to implement scm strategies. the responses by the survey respondents indicate that not enough resources were allocated to implement and support scm initiatives in their divisions. in addition, they perceived that resource allocation could be improved in the areas of better information systems, greater commitment, setting clear\u2010cut goals, increased training, more personnel, and aligning scm initiatives with current priorities and resource commitments. practical implications the results will help to provide greater understanding of strategic and operational issues that support scm framework and implementing scm strategies to reduce supply chain\u2010wide costs and meeting customer service levels. originality/value the results will be useful for business managers to understand and implement scm plans in terms of their importance and the company\\'s culture.",
            "contribution_ids": [
                "R33246"
            ]
        },
        {
            "instance_id": "R33581xR33328",
            "comparison_id": "R33581",
            "paper_id": "R33328",
            "text": "Critical success factors in the context of humanitarian aid supply chains purpose critical success factors (csfs) have been widely used in the context of commercial supply chains. however, in the context of humanitarian aid (ha) this is a poorly addressed area and this paper therefore aims to set out the key areas for research. design/methodology/approach this paper is based on a conceptual discussion of csfs as applied to the ha sector. a detailed literature review is undertaken to identify csfs in a commercial context and to consider their applicability to the ha sector. findings csfs have not previously been identified for the ha sector, an issue addressed in this paper. research limitations/implications the main constraint on this paper is that csfs have not been previously considered in the literature as applied to ha. the relevance of csfs will therefore need to be tested in the ha environment and qualitative research is needed to inform further work. practical implications this paper informs the ha community of key areas of activity which have not been fully addressed and offers. originality/value this paper contributes to the understanding of supply chain management in an ha context.",
            "contribution_ids": [
                "R33329"
            ]
        },
        {
            "instance_id": "R33581xR33348",
            "comparison_id": "R33581",
            "paper_id": "R33348",
            "text": "Critical success factors for B2B e\u00e2\u0080\u0090commerce use within the UK NHS pharmaceutical supply chain purpose the purpose of this paper is to determine those factors perceived by users to influence the successful on\u2010going use of e\u2010commerce systems in business\u2010to\u2010business (b2b) buying and selling transactions through examination of the views of individuals acting in both purchasing and selling roles within the uk national health service (nhs) pharmaceutical supply chain. design/methodology/approach literature from the fields of operations and supply chain management (scm) and information systems (is) is used to determine candidate factors that might influence the success of the use of e\u2010commerce. a questionnaire based on these is used for primary data collection in the uk nhs pharmaceutical supply chain. factor analysis is used to analyse the data. findings the paper yields five composite factors that are perceived by users to influence successful e\u2010commerce use. \u201csystem quality,\u201d \u201cinformation quality,\u201d \u201cmanagement and use,\u201d \u201cworld wide web \u2013 assurance and empathy,\u201d and \u201ctrust\u201d are proposed as potential critical success factors. of these, all respondents ranked information quality, system quality, and trust as being of most importance, but differences in the rankings between purchasing and selling respondents are evident. research limitations/implications the empirical study is limited to a single supply network, and although the findings seem intuitively to be of relevance to other sectors and supply contexts, there remains an opportunity to test this through further research. there is also an opportunity to extend the survey research, particularly into the wholesaler organisations that operate in the sector of study. practical implications the managerial implications that result from this research provide practical guidance to organisations in this sector on how to ensure that e\u2010commerce systems for b2b buying and selling are used successfully. originality/value this paper furthers knowledge and understanding in the fields of operations management, is, and scm, by suggesting potential determinants of successful e\u2010commerce use in both buying and selling organisations within supply networks.",
            "contribution_ids": [
                "R33349"
            ]
        },
        {
            "instance_id": "R33581xR33358",
            "comparison_id": "R33581",
            "paper_id": "R33358",
            "text": "Requirements for forming an \u00e2\u0080\u0098e-supply chain\u00e2\u0080\u0099 \"in today's digital economy, web-based integration of the enterprises to form an e-supply chain is a critical weapon for orchestrating the whole supply chain towards competitiveness. this paper intends to discuss the requirements for forming an e-supply chain from different perspectives, such as integration with the legacy systems, timing and prior presence of erp (enterprise resources planning) systems, bpr (business process re-engineering) needs of internal and external business processes and business intelligence/decision support needs. a look at technical knowledge and structure to construct an e-supply chain is provided. challenges involved in forming an e-supply chain are also briefly mentioned as a separate section in this paper. during the study, requirements are gathered by making a review of recent literature.\"",
            "contribution_ids": [
                "R33359"
            ]
        },
        {
            "instance_id": "R33581xR33368",
            "comparison_id": "R33581",
            "paper_id": "R33368",
            "text": "Managing Supply Chain at High Technology Companies there is an expectation that high technology companies use unique and leading edge technology, and invest heavily in supply chain management. this research uses multiple case study methodology to determine factors affecting the supply chain management at high technology companies. the research benchmarks the supply chain performance of these high technology companies with supply chain of other supply chains at both strategic at tactical levels. the results indicate that at the strategic level the high technology companies and benchmark companies have a similar approach to supply chain management. however at the tactical, or critical, supply chain factor level, the analysis suggests that the benchmark companies (which happen to be companies dealing in commodity-type products) have a different approach to supply chain management.",
            "contribution_ids": [
                "R33369"
            ]
        },
        {
            "instance_id": "R33581xR33406",
            "comparison_id": "R33581",
            "paper_id": "R33406",
            "text": "A study of supplier selection factors for high-tech industries in the supply chain amid the intensive competition among global industries, the relationship between manufacturers and suppliers has turned from antagonist to cooperative. through partnerships, both parties can be mutually benefited, and the key factor that maintains such relationship lies in how manufacturers select proper suppliers. the purpose of this study is to explore the key factors considered by manufacturers in supplier selection and the relationships between these factors. through a literature review, eight supplier selection factors, comprising price response capability, quality management capability, technological capability, delivery capability, flexible capability, management capability, commercial image, and financial capability are derived. based on the theoretic foundation proposed by previous researchers, a causal model of supplier selection factors is further constructed. the results of a survey on high-tech industries are used to verify the relationships between the eight factors using structural equation modelling (sem). based on the empirical results, conclusions and suggestions are finally proposed as a reference for manufacturers and suppliers.",
            "contribution_ids": [
                "R33407"
            ]
        },
        {
            "instance_id": "R33581xR33436",
            "comparison_id": "R33581",
            "paper_id": "R33436",
            "text": "A Study of Key Success Factors for Supply Chain Management System in Semiconductor Industry \"developing a supply chain management (scm) system is costly, but important. however, because of its complicated nature, not many of such projects are considered successful. few research publications directly relate to key success factors (ksfs) for implementing and operating a scm system. motivated by the above, this research proposes two hierarchies of ksfs for scm system implementation and operation phase respectively in the semiconductor industry by using a two-step approach. first, a literature review indicates the initial hierarchy. the second step includes a focus group approach to finalize the proposed ksf hierarchies by extracting valuable experiences from executives and managers that actively participated in a project, which successfully establish a seamless scm integration between the world's largest semiconductor foundry manufacturing company and the world's largest assembly and testing company. finally, this research compared the ksf's between the two phases and made a conclusion. future project executives may refer the resulting ksf hierarchies as a checklist for scm system implementation and operation in semiconductor or related industries.\"",
            "contribution_ids": [
                "R33437"
            ]
        },
        {
            "instance_id": "R33581xR33447",
            "comparison_id": "R33581",
            "paper_id": "R33447",
            "text": "Linking Success Factors to Financial Performance problem statement: based on a literature survey, an attempt has been made in this study to \\ndevelop a framework for identifying the success factors. in addition, a list of key success factors is \\npresented. the emphasis is on success factors dealing with breadth of services, internationalization of \\noperations, industry focus, customer focus, 3pl experience, relationship with 3pls, investment in \\nquality assets, investment in information systems, availability of skilled professionals and supply chain \\nintegration. in developing the factors an effort has been made to align and relate them to financial \\nperformance. conclusion/recommendations: we found success factors \u201crelationship with 3pls and skilled logistics professionals\u201d would substantially improves financial performance metric profit growth. our findings also contribute to managerial practice by offering a benchmarking tool that can be used by managers in the 3pl service provider industry in india.",
            "contribution_ids": [
                "R33448"
            ]
        },
        {
            "instance_id": "R33581xR33461",
            "comparison_id": "R33581",
            "paper_id": "R33461",
            "text": "Supply chain management: success factors from the Malaysian manufacturer's perspective the purpose of this paper is to shed the light on the critical success factors that lead to high supply chain performance outcomes in a malaysian manufacturing company. the critical success factors consist of relationship with customer and supplier, information communication and technology (ict), material flow management, corporate culture and performance measurement. questionnaire was the main instrument for the study and it was distributed to 84 staff from departments of purchasing, planning, logistics and operation. data analysis was conducted by employing descriptive analysis (mean and standard deviation), reliability analysis, pearson correlation analysis and multiple regression. the findings show that there are relationships exist between relationship with customer and supplier, ict, material flow management, performance measurement and supply chain management (scm) performance, but not for corporate culture. forming a good customer and supplier relationship is the main predictor of scm performance, followed by performance measurement, material flow management and ict. it is recommended that future study to determine additional success factors that are pertinent to firms\u2019 current scm strategies and directions, competitive advantages and missions. logic suggests that further study to include more geographical data coverage, other nature of businesses and research instruments. \\n \\n \\xa0 \\n \\n key words:\\xa0supply chain management, critical success factor.",
            "contribution_ids": [
                "R33462"
            ]
        },
        {
            "instance_id": "R33581xR33482",
            "comparison_id": "R33581",
            "paper_id": "R33482",
            "text": "Key success factors and their performance implications in the Indian third-party logistics (3PL) industry this paper uses the extant literature to identify the key success factors that are associated with performance in the indian third-party logistics service providers (3pl) sector. we contribute to the sparse literature that has examined the relationship between key success factors and performance in the indian 3pl context. this study offers new insights and isolates key success factors that vary in their impact on operations and financial performance measures. specifically, we found that the key success factor of relationship with customers significantly influenced the operations measures of on-time delivery performance and customer satisfaction and the financial measure of profit growth. similarly, the key success factor of skilled logistics professionals improved the operational measure of customer satisfaction and the financial measure of profit growth. the key success factor of breadth of service significantly affected the financial measure of revenue growth, but did not affect any operational measure. to further unravel the patterns of these results, a contingency analysis of these relationships according to firm size was also conducted. relationship with 3pls was significant irrespective of firm size. our findings contribute to academic theory and managerial practice by offering context-specific suggestions on the usefulness of specific key success factors based on their potential influence on operational and financial performance in the indian 3pl industry.",
            "contribution_ids": [
                "R33483"
            ]
        },
        {
            "instance_id": "R33581xR33489",
            "comparison_id": "R33581",
            "paper_id": "R33489",
            "text": "Identifying critical enablers and pathways to high performance supply chain quality management purpose the aim of this paper is threefold: first, to examine the content of supply chain quality management (scqm); second, to identify the structure of scqm; and third, to show ways for finding improvement opportunities and organizing individual institution\\'s resources/actions into collective performance outcomes. design/methodology/approach to meet the goals of this work, the paper uses abductive reasoning and two qualitative methods: content analysis and formal concept analysis (fca). primary data were collected from both original design manufacturers (odms) and original equipment manufacturers (oems) in taiwan. findings according to the qualitative empirical study, modern enterprises need to pay immediate attention to the following two pathways: a compliance approach and a voluntary approach. for the former, three strategic content variables are identified: training programs, iso, and supplier quality audit programs. as for initiating a voluntary effort, modern lead firms need to instill \u201cmotivation\u201d into a supply chain quality system. practical implications the findings based on the abductive model reveal numerous strategic and tactical enablers, key sequences to move firms from their current situation to their preferred one, and critical opportunities for supply chain\u2010wide quality system designs. originality/value this study will be of great value to supply chain policy makers, supply chain operators, and decision makers in lead firms in a supply chain setting and their channel partners. the proactive use of the authors\\' proposed research procedure is indispensable to effective supply chain quality planning.",
            "contribution_ids": [
                "R33490"
            ]
        },
        {
            "instance_id": "R33581xR33521",
            "comparison_id": "R33581",
            "paper_id": "R33521",
            "text": "Evaluating the critical success factors of supplier development: a case study purpose the purpose of this paper is to identify and evaluate the critical success factors (csfs) responsible for supplier development (sd) in a manufacturing supply chain environment. design/methodology/approach in total, 13 csfs for sd are identified (i.e. long\u2010term strategic goal; top management commitment; incentives; supplier\\'s supplier condition; proximity to manufacturing base; supplier certification; innovation capability; information sharing; environmental readiness; external environment; project completion experience; supplier status and direct involvement) through extensive literature review and discussion held with managers/engineers in different indian manufacturing companies. a fuzzy analytic hierarchy process (fahp) is proposed and developed to evaluate the degree of impact of each csf on sd. findings the degree of impact for each csf on sd is established for an indian company. the results are discussed in detail with managerial implications. the long\u2010term strategic goal is found to be the most significant csf for successful sd implementation. research limitations/implications this study has not been statistically validated in a manufacturing supply chain environment for complete acceptability. practical implications the simplicity and clarity of the proposed approach enhances its acceptability for evaluating csfs in manufacturing supply chain environment. it also provides the direction for optimally allocating the efforts and resources for successful implementation of sd in short duration. originality/value although both csfs and sd have been widely researched, but no study has been reported in the literature to prioritize and rank the csfs of sd in an indian manufacturing environment. the paper contributes to research in the supply chain management area in general and sd in particular for manufacturing environment. the proposed approach has the ability to capture the judgment of multiple experts to prioritize and rank csfs for sd.",
            "contribution_ids": [
                "R33522"
            ]
        },
        {
            "instance_id": "R33581xR33343",
            "comparison_id": "R33581",
            "paper_id": "R33343",
            "text": "Critical success factors for improving decision quality on collaborative design in the IC supply chain because the design process of integrated circuit (ic) product is knowledge-intensive and time-consuming, the collaboration among ic designers and manufacturers is crucial for reducing time to market of designing product. to enhance the quality of manufacturing strategic decisions for collaborative ic design, manufacturing practices must be identified as the core elements of manufacturing strategy. however, little research has been done regarding the essentials of implementing collaboration among ic designers. this study aims to clarify terminology of decision quality in manufacturing strategy and define critical success factors (csfs) as manufacturing practices for improving decision quality on collaborative design in the ic supply chain through comprehensive literature review. moreover, this study proposes a framework in which the csfs can be identified for different parties in ic supply chain.",
            "contribution_ids": [
                "R33344"
            ]
        },
        {
            "instance_id": "R33581xR33388",
            "comparison_id": "R33581",
            "paper_id": "R33388",
            "text": "E-procurement, the golden key to optimizing the supply chains system procurement is an important component in the field of operating resource management and e-procurement is the golden key to optimizing the supply chains system. global firms are optimistic on the level of savings that can be achieved through full implementation of e-procurement strategies. e-procurement is an internet-based business process for obtaining materials and services and managing their inflow into the organization. in this paper, the subjects of supply chains and e-procurement and its benefits to organizations have been studied. also, e-procurement in construction and its drivers and barriers have been discussed and a framework of supplier selection in an e-procurement environment has been demonstrated. this paper also has addressed critical success factors in adopting e-procurement in supply chains. keywords\u2014e-procurement, supply chain, benefits, construction, drivers, barriers, supplier selection, cfss.",
            "contribution_ids": [
                "R33389"
            ]
        },
        {
            "instance_id": "R33783xR33645",
            "comparison_id": "R33783",
            "paper_id": "R33645",
            "text": "Estimation and elimination of harmonics in power system using modified FFT with variable learning of Adaline \"this paper presents a new technique for harmonic detection, estimation and elimination in power system. the approach expresses the input signal in the form of fourier transformation and adjusts the fourier coefficients using linear adaptive filters (adaline). two of the existing approaches using conventional fast fourier transformation (fft) and fft with modified w-h learning have been discussed with their merits and demerits. a new approach has been proposed using a network comprising three different adalines and involving variable learning rate. this approach is able to mitigate the shortcomings of the existing techniques and is time efficient as well. the detailed architecture for the proposed approach has been discussed and the algorithm has then been tested on different test signals. the approach has been compared with the existing techniques and it's superiority over these has thus been established.\"",
            "contribution_ids": [
                "R33646",
                "R33736"
            ]
        },
        {
            "instance_id": "R33783xR33647",
            "comparison_id": "R33783",
            "paper_id": "R33647",
            "text": "Improved shunt APF based on using adaptive RBF neural network and modified hysteresis current control in this paper, a new combination is proposed to control shunt active power filters (apf). the recommended system has better specifications in comparison with other control methods. in the proposed combination, an rbf neural network is employed to extract compensation reference currents for a variable non-linear load. in order to make the employed model much simpler and tighter, an adaptive learning algorithm for rbf network is proposed. in addition, a modified hysteresis current control technique based on defining a variable hysteresis band is employed to avoid any power system resonance. in this method the hysteresis band is expressed as a function of source voltage, rate of reference current variations and voltage of dc link capacitor in such a way that the switching frequency of the inverter switches remains almost constant. in summary, extraction of compensation reference current is done with lower amount of computations. beside, the threat of resonance occurrence is cancelled. the simulation results which are done by matlab/simulink illustrate the validity and effectiveness of the proposed combination.",
            "contribution_ids": [
                "R33648",
                "R33737"
            ]
        },
        {
            "instance_id": "R33783xR33651",
            "comparison_id": "R33783",
            "paper_id": "R33651",
            "text": "Neural Network-Based Approach for Identification of the Harmonic Content of a Nonlinear Load in a Single-Phase System in this paper an alternative method based on artificial neural networks is presented to determine harmonic components in the load current of a single-phase electric power system with nonlinear loads, whose parameters can vary so much in reason of the loads characteristic behaviors as because of the human intervention. the first six components in the load current are determined using the information contained in the time-varying waveforms. the effectiveness of this method is verified by using it in a single-phase active power filter with selective compensation of the current drained by an ac controller. the proposed method is compared with the fast fourier transform.",
            "contribution_ids": [
                "R33652",
                "R33739"
            ]
        },
        {
            "instance_id": "R33783xR33655",
            "comparison_id": "R33783",
            "paper_id": "R33655",
            "text": "New Research on Harmonic Detection Based on Neural Network for Power System analysis and control for power quality by neural network is a new research field in electrical power system. rapid and reliable extract the harmonic components determine the overall performance of active power filter (apf). this paper presents a new three-layer feedforward neural network based on error back-propagation algorithm that the training sample without time delay, which can detecting harmonics for power system in real-time. with the simulation study using matlab, the simulation results illustrate that the harmonic detection method based on neural network is feasible, which can quickly detecting the harmonics for non-linear load.",
            "contribution_ids": [
                "R33656",
                "R33741"
            ]
        },
        {
            "instance_id": "R33783xR33675",
            "comparison_id": "R33783",
            "paper_id": "R33675",
            "text": "Predictive and Adaptive ANN (Adaline) Based Harmonic Compensation for Shunt Active Power Filter estimation of the current-reference to compensate for the harmonic and reactive component of the load current is important in a shunt type active power filter. this paper applies ann based predictive and adaptive reference generation technique. predictive scheme extracts the information of the fundamental component through an ann that replaces a low pass filter. this ann based low pass-filter is trained offline with large number of training set to predict the fundamental magnitude of load current. these predictive reference generation techniques work well for load change pattern closer to the trained data and for clean source voltage. however, the performance deteriorates in case of distortion in source voltage and also if training data drifts quite significantly from test data. to overcome this, an adaline based ann is applied after the operation of the predictive algorithm. it has been shown that the combined predictive adaptive approach offers better performance. extensive results from simulation have confirmed the usefulness of the proposed technique.",
            "contribution_ids": [
                "R33676",
                "R33751"
            ]
        },
        {
            "instance_id": "R33783xR33685",
            "comparison_id": "R33783",
            "paper_id": "R33685",
            "text": "A Neural Network Adaptive Detecting Approach of Harmonic Current a neural network adaptive detecting approach of harmonic current for apf (active power filter) is proposed in this paper. it bases on the adaptive noise canceling technology (anct). regarding the fundamental current as noise source, it can be cancelled from the load current, and then the harmonic current is obtained. artificial neural network (ann) with two layers is used to cancel the harmonics. the structure of this neural network and the adaptive adjusting algorithm are presented. the study has been carried out through detail digital dynamic simulation using the matlab simulink power system toolbox. the results of simulation show that this approach can detect harmonic components at real time with high precision, little calculation and strong adaptive ability.",
            "contribution_ids": [
                "R33686",
                "R33756"
            ]
        },
        {
            "instance_id": "R33783xR33689",
            "comparison_id": "R33783",
            "paper_id": "R33689",
            "text": "Active Power Filter of Three-Phase Based on Neural Network this paper presents a novel control design of shunt active power filter to compensate reactive power and reduce the unwanted harmonics. a shunt active filter is realized employing three-phase voltage source inverter (vsi) and a control circuit. the shunt active filter acts as a current source, which is connected in parallel with a nonlinear load and controlled to generate the required compensation currents. the control circuit using neural network controller is proposed. one adaptive neural network (ann) controller is designed to estimate the harmonic components of the distorted load current and supply voltage [1]. a power factor correction function is incorporated in the shunt active filter to achieve a power factor that is near to unity. the different cases are considered and then simulated in order to show validity of the active power filter with neural network control.",
            "contribution_ids": [
                "R33690",
                "R33758"
            ]
        },
        {
            "instance_id": "R33783xR33699",
            "comparison_id": "R33783",
            "paper_id": "R33699",
            "text": "A Single-Phase DG Generation Unit With Shunt Active Power Filter Capability by Adaptive Neural Filtering this paper deals with a single-phase distributed generation (dg) system with active power filtering (apf) capability, devised for utility current harmonic compensation. the idea is to integrate the dg unit functions with the shunt apf capabilities, since the dg is connected in parallel to the grid. with the proposed approach, the control of the dg unit is performed by injecting into the grid a current with the same phase and frequency of the grid voltage and with amplitude depending on the power available from the renewable sources. on the other hand, the load harmonic current compensation is performed by injecting into the ac system harmonic currents as those of the load but with opposite phase, thus keeping the line current almost sinusoidal. both the phase detection of the grid voltage and the computation of the load harmonic compensation current have been performed by two neural adaptive filters with the same structure, one in configuration \"notch\" and the other complementary in configuration \"band\". the methodology has been tested successfully both in numerical simulation and experimentally on a suitably devised test setup",
            "contribution_ids": [
                "R33700",
                "R33763"
            ]
        },
        {
            "instance_id": "R33783xR33709",
            "comparison_id": "R33783",
            "paper_id": "R33709",
            "text": "Design of Single-phase Shunt Active Power Filter Based on ANN in this paper, a single-phase shunt active power filter (apf) is presented to compensate reactive power and eliminate harmonics in power system. sensing load current, dc bus voltage, reference dc bus voltage and source voltage compute reference current of apf through modified adaptive artificial neural network (ann). a modified hysteretic current controller is used to generate the firing pulses of the voltage source inverter which generate reactive and harmonic current to compensate the nonlinear loads. the proposed system is implemented using digital signal processor (dsp). simulating and experimental results are presented to confirm the validity of the scheme.",
            "contribution_ids": [
                "R33710",
                "R33768"
            ]
        },
        {
            "instance_id": "R33783xR33711",
            "comparison_id": "R33783",
            "paper_id": "R33711",
            "text": "A Unified Artificial Neural Network Architecture for Active Power Filters in this paper, an efficient and reliable neural active power filter (apf) to estimate and compensate for harmonic distortions from an ac line is proposed. the proposed filter is completely based on adaline neural networks which are organized in different independent blocks. we introduce a neural method based on adalines for the online extraction of the voltage components to recover a balanced and equilibrated voltage system, and three different methods for harmonic filtering. these three methods efficiently separate the fundamental harmonic from the distortion harmonics of the measured currents. according to either the instantaneous power theory or to the fourier series analysis of the currents, each of these methods are based on a specific decomposition. the original decomposition of the currents or of the powers then allows defining the architecture and the inputs of adaline neural networks. different learning schemes are then used to control the inverter to inject elaborated reference currents in the power system. results obtained by simulation and their real-time validation in experiments are presented to compare the compensation methods. by their learning capabilities, artificial neural networks are able to take into account time-varying parameters, and thus appreciably improve the performance of traditional compensating methods. the effectiveness of the algorithms is demonstrated in their application to harmonics compensation in power systems",
            "contribution_ids": [
                "R33712",
                "R33769"
            ]
        },
        {
            "instance_id": "R33783xR33723",
            "comparison_id": "R33783",
            "paper_id": "R33723",
            "text": "Artificial Neural Networks as Harmonic Detectors \"in order to succeed harmonic mitigation in electrical circuits, it's very important to estimate or extract the compensating harmonic references. any failure in this last procedure will cause failure in the harmonic elimination. in fact, in the literature many harmonic detection or estimation methods were presented, in this paper we focus on a new idea to apply artificial intelligence methods namely artificial neural networks in harmonic detection\"",
            "contribution_ids": [
                "R33724",
                "R33775"
            ]
        },
        {
            "instance_id": "R33783xR33729",
            "comparison_id": "R33783",
            "paper_id": "R33729",
            "text": "Power harmonic identification and compensation with an artificial neural network method this paper introduces a new neural method for harmonic identification and compensation. based on adaline networks, the proposed method is called the diphase currents method. the architecture and the learning are formulated based on an original decomposition of the disturbed currents. these currents are converted in the alphabeta- or dq-spaces to separate each harmonic component in a linear expression. in this harmonic compensation method, the harmonic components may be individually selected and the reactive power may be compensated. the proposed method is robust and has been efficiently compared to other conventional and neural harmonic compensation methods. in order to validate the performance of the diphase currents method, simulation studies are carried out in the presence of plant variations. experiments are also presented to show the performance of the proposed neural method under many practical industrial conditions.",
            "contribution_ids": [
                "R33730",
                "R33778"
            ]
        },
        {
            "instance_id": "R33783xR33779",
            "comparison_id": "R33783",
            "paper_id": "R33779",
            "text": "Neural Network controlled three-phase three-wire shunt active Power Filter \"three-phase shunt active power filters (shunt apfs) are widely used in industrial applications to compensate for harmonics, generated by nonlinear loads. in order to succeed the compensation it's necessary to assure current control in the ac side of the apf and voltage or current control in the dc side of the apf. in real practice pi controllers are the most common, as a novel and intelligent control technique neural network controllers are under study and investigation in such application. in this paper, a neural network controller is used to control a three- phase three-wire voltage source shunt apf, its performance in terms of harmonic compensation and speed of response are compared to those of classic pi controller.\"",
            "contribution_ids": [
                "R33780"
            ]
        },
        {
            "instance_id": "R33783xR33781",
            "comparison_id": "R33783",
            "paper_id": "R33781",
            "text": "Comparison of PI and ANN Control Strategies of Unified Shunt Series Compensator this paper presents the compensation principle using pi and ann control strategies of the ussc in detail. the ussc is an active filter (af) and it compensates the reactive power, harmonics in both the voltage and current caused by loads. the ussc makes use of two back to back connected igbt based voltage source inverters (vsis) with a common dc bus. one inverter is connected in series and the other one is placed in shunt with the load. the shunt inverter works as a current source and it compensates the current harmonics. the series inverter works as a voltage source and it helps in compensating the voltage harmonics. previous works presented a control strategy for shunt active filter with pi control. then, this control strategy was extended to develop the two controllers for shunt and series active filters. the simulation results of these control strategies are listed for comparison and verification of results",
            "contribution_ids": [
                "R33782"
            ]
        },
        {
            "instance_id": "R33783xR33713",
            "comparison_id": "R33783",
            "paper_id": "R33713",
            "text": "Neural Network Controlled Shunt Active Filter For Non Linear Loads as industry power demand become increasingly sensitive, power quality distortion becomes a critical issue. the recent increase in nonlinear loads drawing non-sinusoidal currents has seen the introduction to manage the clean delivery of power. in this paper, a three-phase shunt active power filter (apf) using artificial neural network technique is proposed to mitigate harmonics, to compensate reactive power, to improve power factor and to remedy system unbalance. the simulation is done on a three-phase system and the results are used for comparison.",
            "contribution_ids": [
                "R33714",
                "R33770"
            ]
        },
        {
            "instance_id": "R33851xR33795",
            "comparison_id": "R33851",
            "paper_id": "R33795",
            "text": "Comparative analysis of algorithms for identifying amplifications and deletions in array CGH data motivation\\narray comparative genomic hybridization (cgh) can reveal chromosomal aberrations in the genomic dna. these amplifications and deletions at the dna level are important in the pathogenesis of cancer and other diseases. while a large number of approaches have been proposed for analyzing the large array cgh datasets, the relative merits of these methods in practice are not clear.\\n\\n\\nresults\\nwe compare 11 different algorithms for analyzing array cgh data. these include both segment detection methods and smoothing methods, based on diverse techniques such as mixture models, hidden markov models, maximum likelihood, regression, wavelets and genetic algorithms. we compute the receiver operating characteristic (roc) curves using simulated data to quantify sensitivity and specificity for various levels of signal-to-noise ratio and different sizes of abnormalities. we also characterize their performance on chromosomal regions of interest in a real dataset obtained from patients with glioblastoma multiforme. while comparisons of this type are difficult due to possibly sub-optimal choice of parameters in the methods, they nevertheless reveal general characteristics that are helpful to the biological investigator.",
            "contribution_ids": [
                "R33796"
            ]
        },
        {
            "instance_id": "R33851xR33819",
            "comparison_id": "R33851",
            "paper_id": "R33819",
            "text": "The Effect of Algorithms on Copy Number Variant Detection background the detection of copy number variants (cnvs) and the results of cnv-disease association studies rely on how cnvs are defined, and because array-based technologies can only infer cnvs, cnv-calling algorithms can produce vastly different findings. several authors have noted the large-scale variability between cnv-detection methods, as well as the substantial false positive and false negative rates associated with those methods. in this study, we use variations of four common algorithms for cnv detection (penncnv, quantisnp, hmmseg, and cnvpartition) and two definitions of overlap (any overlap and an overlap of at least 40% of the smaller cnv) to illustrate the effects of varying algorithms and definitions of overlap on cnv discovery. methodology and principal findings we used a 56 k illumina genotyping array enriched for cnv regions to generate hybridization intensities and allele frequencies for 48 caucasian schizophrenia cases and 48 age-, ethnicity-, and gender-matched control subjects. no algorithm found a difference in cnv burden between the two groups. however, the total number of cnvs called ranged from 102 to 3,765 across algorithms. the mean cnv size ranged from 46 kb to 787 kb, and the average number of cnvs per subject ranged from 1 to 39. the number of novel cnvs not previously reported in normal subjects ranged from 0 to 212. conclusions and significance motivated by the availability of multiple publicly available genome-wide snp arrays, investigators are conducting numerous analyses to identify putative additional cnvs in complex genetic disorders. however, the number of cnvs identified in array-based studies, and whether these cnvs are novel or valid, will depend on the algorithm(s) used. thus, given the variety of methods used, there will be many false positives and false negatives. both guidelines for the identification of cnvs inferred from high-density arrays and the establishment of a gold standard for validation of cnvs are needed.",
            "contribution_ids": [
                "R33820"
            ]
        },
        {
            "instance_id": "R33851xR33824",
            "comparison_id": "R33851",
            "paper_id": "R33824",
            "text": "Accuracy of CNV Detection from GWAS Data \"several computer programs are available for detecting copy number variants (cnvs) using genome-wide snp arrays. we evaluated the performance of four cnv detection software suites\u2014birdsuite, partek, helixtree, and penncnv-affy\u2014in the identification of both rare and common cnvs. each program's performance was assessed in two ways. the first was its recovery rate, i.e., its ability to call 893 cnvs previously identified in eight hapmap samples by paired-end sequencing of whole-genome fosmid clones, and 51,440 cnvs identified by array comparative genome hybridization (acgh) followed by validation procedures, in 90 hapmap ceu samples. the second evaluation was program performance calling rare and common cnvs in the bipolar genome study (bigs) data set (1001 bipolar cases and 1033 controls, all of european ancestry) as measured by the affymetrix snp 6.0 array. accuracy in calling rare cnvs was assessed by positive predictive value, based on the proportion of rare cnvs validated by quantitative real-time pcr (qpcr), while accuracy in calling common cnvs was assessed by false positive/false negative rates based on qpcr validation results from a subset of common cnvs. birdsuite recovered the highest percentages of known hapmap cnvs containing >20 markers in two reference cnv datasets. the recovery rate increased with decreased cnv frequency. in the tested rare cnv data, birdsuite and partek had higher positive predictive values than the other software suites. in a test of three common cnvs in the bigs dataset, birdsuite's call was 98.8% consistent with qpcr quantification in one cnv region, but the other two regions showed an unacceptable degree of accuracy. we found relatively poor consistency between the two \u201cgold standards,\u201d the sequence data of kidd et al., and acgh data of conrad et al. algorithms for calling cnvs especially common ones need substantial improvement, and a \u201cgold standard\u201d for detection of cnvs remains to be established.\"",
            "contribution_ids": [
                "R33825"
            ]
        },
        {
            "instance_id": "R33953xR33869",
            "comparison_id": "R33953",
            "paper_id": "R33869",
            "text": "An Ant Colony Optimization Approach to Test Sequence Generation for Statebased Software Testing properly generated test suites may not only locate the defects in software systems, but also help in reducing the high cost associated with software testing, ft is often desired that test sequences in a test suite can be automatically generated to achieve required test coverage. however, automatic test sequence generation remains a major problem in software testing. this paper proposes an ant colony optimization approach to automatic test sequence generation for state-based software testing. the proposed approach can directly use uml artifacts to automatically generate test sequences to achieve required test coverage.",
            "contribution_ids": [
                "R33870"
            ]
        },
        {
            "instance_id": "R33953xR33873",
            "comparison_id": "R33953",
            "paper_id": "R33873",
            "text": "Automatic Mutation Test Input Data Generation via Ant Colony fault-based testing is often advocated to overcome limitations ofother testing approaches; however it is also recognized as beingexpensive. on the other hand, evolutionary algorithms have beenproved suitable for reducing the cost of data generation in the contextof coverage based testing. in this paper, we propose a newevolutionary approach based on ant colony optimization for automatictest input data generation in the context of mutation testingto reduce the cost of such a test strategy. in our approach the antcolony optimization algorithm is enhanced by a probability densityestimation technique. we compare our proposal with otherevolutionary algorithms, e.g., genetic algorithm. our preliminaryresults on java testbeds show that our approach performed significantlybetter than other alternatives.",
            "contribution_ids": [
                "R33874"
            ]
        },
        {
            "instance_id": "R33953xR33894",
            "comparison_id": "R33953",
            "paper_id": "R33894",
            "text": "Variable Strength Interaction Testing with an Ant Colony System Approach interaction testing (also called combinatorial testing) is an cost-effective test generation technique in software testing. most research work focuses on finding effective approaches to build optimal t-way interaction test suites. however, the strength of different factor sets may not be consistent due to the practical test requirements. to solve this problem, a variable strength combinatorial object and several approaches based on it have been proposed. these approaches include simulated annealing (sa) and greedy algorithms. sa starts with a large randomly generated test suite and then uses a binary search process to find the optimal solution. although this approach often generates the minimal test suites, it is time consuming. greedy algorithms avoid this shortcoming but the size of generated test suites is usually not as small as sa. in this paper, we propose a novel approach to generate variable strength interaction test suites (vsits). in our approach, we adopt a one-test-at-a-time strategy to build final test suites. to generate a single test, we adopt ant colony system (acs) strategy, an effective variant of ant colony optimization (aco). in order to successfully adopt acs, we formulize the solution space, the cost function and several heuristic settings in this framework. we also apply our approach to some typical inputs. experimental results show the effectiveness of our approach especially compared to greedy algorithms and several existing tools.",
            "contribution_ids": [
                "R33895"
            ]
        },
        {
            "instance_id": "R33953xR33899",
            "comparison_id": "R33953",
            "paper_id": "R33899",
            "text": "Building Prioritized Pairwise Interaction Test Suites with Ant Colony Optimization interaction testing offers a stable cost-benefit ratio in identifying faults. but in many testing scenarios, the entire test suite cannot be fully executed due to limited time or cost. in these situations, it is essential to take the importance of interactions into account and prioritize these tests. to tackle this issue, the biased covering array is proposed and the weighted density algorithm (wda) is developed. to find a better solution, in this paper we adopt ant colony optimization (aco) to build this prioritized pairwise interaction test suite (pits). in our research, we propose four concrete test generation algorithms based on ant system, ant system with elitist, ant colony system and max-min ant system respectively. we also implement these algorithms and apply them to two typical inputs and report experimental results. the results show the effectiveness of these algorithms.",
            "contribution_ids": [
                "R33900"
            ]
        },
        {
            "instance_id": "R33953xR33907",
            "comparison_id": "R33953",
            "paper_id": "R33907",
            "text": "An approach of optimal path generation using ant colony optimization software testing is one of the indispensable parts of the software development lifecycle and structural testing is one of the most widely used testing paradigms to test various software. structural testing relies on code path identification, which in turn leads to identification of effective paths. aim of the current paper is to present a simple and novel algorithm with the help of an ant colony optimization, for the optimal path identification by using the basic property and behavior of the ants. this novel approach uses certain set of rules to find out all the effective/optimal paths via ant colony optimization (aco) principle. the method concentrates on generation of paths, equal to the cyclomatic complexity. this algorithm guarantees full path coverage.",
            "contribution_ids": [
                "R33908"
            ]
        },
        {
            "instance_id": "R33953xR34961",
            "comparison_id": "R33953",
            "paper_id": "R34961",
            "text": "Introduction: A Survey of the Evolutionary Computation Techniques for Software Engineering this chapter aims to present a part of the computer science literature in which the evolutionary computation techniques, optimization techniques and other bio-inspired techniques are used to solve different search and optimization problems in the area of software engineering.",
            "contribution_ids": [
                "R33948",
                "R34963"
            ]
        },
        {
            "instance_id": "R34099xR33985",
            "comparison_id": "R34099",
            "paper_id": "R33985",
            "text": "Up-estuary dispersal of young-of-the-year bay anchovy Anchoa mitchilli in the Chesapeake Bay: inferences from microprobe analysis of strontium in otoliths young-of-the-year (yoy) bay anchovy anchoa mitchilli occur in higher proportion rel- ative to larvae in the upper chesapeake bay. this has led to the hypothesis that up-bay dispersal favors recruitment. here we test whether recruitment of bay anchovy to different parts of the chesa- peake bay results from differential dispersal rates. electron microprobe analysis of otolith strontium was used to hind-cast patterns and rates of movement across salinity zones. individual chronologies of strontium were constructed for 55 bay anchovy aged 43 to 103 d collected at 5 chesapeake bay mainstem sites representing upper, middle, and lower regions of the bay during september 1998. most yoy anchovy were estimated to have originated in the lower bay. those collected at 5 and 11 psu sites exhibited the highest past dispersal rates, all in an up-estuary direction. no significant net dispersal up- or down-estuary occurred for recruits captured at the polyhaline (\u266218 psu) site. ini- tiation of ingress to lower salinity waters (<15 psu) was estimated to occur near metamorphosis, dur- ing the early juvenile stage, at sizes \u2662 25 mm standard length (sl) and ages \u2662 50 d after hatch. esti- mated maximum upstream dispersal rate (over-the-ground speed) during the first 50 to 100 d of life exceeded 50 mm s -1 .",
            "contribution_ids": [
                "R33986"
            ]
        },
        {
            "instance_id": "R34099xR34053",
            "comparison_id": "R34099",
            "paper_id": "R34053",
            "text": "Coexistence of anadromous and lacustrine life histories of the shirauo, Sala- nichthys microdon the environmental history of the shirauo, salangichthys microdon, was examined in terms of strontium (sr) and calcium (ca) uptake in the otolith, by means of wavelength dispersive x-ray spectrometry on an electron microprobe. anadromous and lacustrine type of the shirauo were found to occur sympatric. otolith sr concentration or sr\\xa0:\\xa0ca ratios of anadromous shirauo fluctuated strongly along the life-history transect in accordance with the migration (habitat) pattern from sea to freshwater. in contrast, the sr concentration or the sr\\xa0:\\xa0ca ratios of lacustrine shirauo remained at consistently low levels throughout the otolith. the higher ratios in anadromous shirauo, in the otolith region from the core to 90\u2013230\\xa0\u03bcm, corresponded to the initial sea-going period, probably reflecting the ambient salinity or the seawater\u2013freshwater gradient in sr concentration. the findings clearly indicated that otolith sr\\xa0:\\xa0ca ratios reflected individual life histories, enabling these anadromous shirauo to be distinguished from lacustrine shirauo.",
            "contribution_ids": [
                "R34054"
            ]
        },
        {
            "instance_id": "R34099xR34057",
            "comparison_id": "R34099",
            "paper_id": "R34057",
            "text": "Migration and rearing histories of chinook salmon (Oncorhynchus tshawytscha) determined by ion microprobe Sr isotope and Sr/Ca transects of otoliths \" strontium isotope and sr/ca ratios measured in situ by ion microprobe along radial transects of otoliths of juvenile chinook salmon (oncorhynchus tshawytscha) vary between watersheds with contrasting geology. otoliths from ocean-type chinook from skagit river estuary, washington, had prehatch regions with 87 sr/ 86 sr ratios of ~0.709, suggesting a maternally inherited marine signature, extensive fresh water growth zones with 87 sr/ 86 sr ratios similar to those of the skagit river at ~0.705, and marine-like 87 sr/ 86 sr ratios near their edges. otoliths from stream-type chinook from central idaho had prehatch 87 sr/ 86 sr ratios \u22650.711, indicating that a maternal marine sr isotopic signature is not preserved after the ~1000- to 1400-km migration from the pacific ocean. 87 sr/ 86 sr ratios in the outer portions of otoliths from these idaho juveniles were similar to those of their respective streams (~0.708\\x960.722). for skagit juveniles, fresh water growth was marked by small decreases in otolith sr/ca, with increases in sr/ca corresponding to increases in 87 sr/ 86 sr with migration into salt water. otoliths of idaho fish had sr/ca radial variation patterns that record seasonal fluctuation in ambient water sr/ca ratios. the ion microprobe's ability to measure both 87 sr/ 86 sr and sr/ca ratios of otoliths at high spatial resolution in situ provides a new tool for studies of fish rearing and migration. \"",
            "contribution_ids": [
                "R34058"
            ]
        },
        {
            "instance_id": "R34099xR34063",
            "comparison_id": "R34099",
            "paper_id": "R34063",
            "text": "Evidence of different habitat use by New Zealand freshwater eels Anguilla australis and A. dieffenbachii, as revealed by otolith microchemistry the apparent use of marine and freshwater habitats by anguilla australis and a. dieffenbachii was examined by analyzing the strontium (sr) and calcium (ca) concentrations in otoliths of silver eels collected from lake ellesmere, which is a shallow brackish-water coastal lagoon in new zealand. the age and growth of these eels was also examined using their otolith annuli. size and ages of females were greater than those of males for both species. growth rates were similar among sex and species, but the highest growth rates were observed in eels that experienced saline environments. line analyses of sr:ca ratios along a life-history transect in each otolith showed peaks (ca. 15 to 21 \u00d7 10 -3 in a. australis, 14 to 20 \u00d7 10 -3 in a. dieffenbachii) between the core and elver mark, which corresponded to the period of their leptocephalus and early glass eel stage in the ocean. out- side the elver mark, the sr:ca ratios indicated that eels had remained in different habitats that included freshwater (average sr:ca ratios, 1.8 to 2.4 \u00d7 10 -3 ), areas with relatively high salinities (aver- age sr:ca ratios, 3.0 to 7.4 \u00d7 10 -3 ), and in some cases individuals showed clear evidence of shifts in the salinity of their environments. these shifts either indicated movements between different loca- tions, or changes in the salinity of the lake. there were more individuals of a. australis that used areas with intermediate or high salinities, at least for a short time (85% of individuals), than a. dief- fenbachii (30%). these findings suggest that these 2 southern temperate species may have the same behavioral plasticity regarding whether or not to enter freshwater or remain in marine environments, as has been recently documented in several northern temperate anguillid species.",
            "contribution_ids": [
                "R34064",
                "R34065"
            ]
        },
        {
            "instance_id": "R34099xR34097",
            "comparison_id": "R34099",
            "paper_id": "R34097",
            "text": "Estimating contemporary early life-history dispersal in an estuarine fish: integrating molecular and otolith elemental approaches \"dispersal during the early life history of the anadromous rainbow smelt, osmerus mordax, was examined using assignment testing and mixture analysis of multilocus genotypes and otolith elemental composition. six spawning areas and associated estuarine nurseries were sampled throughout southeastern newfoundland. samples of adults and juveniles isolated by > 25 km displayed moderate genetic differentiation (fst ~ 0.05), whereas nearby ( 80% self\u2010assignment) with nearby runs self\u2010assigning at rates between 50 % and 70%. assignment and mixture analysis of juveniles using adult baselines indicated high local recruitment at several locations (70\u201390%). nearby (< 25 km) estuaries at the head of st mary's bay showed mixtures of individuals (i.e. 20\u201340% assignment to adjacent spawning location). laser ablation inductively coupled mass spectrometry transects across otoliths of spawning adults of unknown dispersal history were used to estimate dispersal among estuaries across the first year of life. single\u2010element trends and multivariate discriminant function analysis (sr:ca and ba:ca) classified the majority of samples as estuarine suggesting limited movement between estuaries (< 0.5%). the mixtures of juveniles evident in the genetic data at nearby sites and a lack of evidence of straying in the otolith data support a hypothesis of selective mortality of immigrants. if indeed selective mortality of immigrants reduces the survivorship of dispersers, estimates of dispersal in marine environments that neglect survival may significantly overestimate gene flow.\"",
            "contribution_ids": [
                "R34098"
            ]
        },
        {
            "instance_id": "R34126xR34102",
            "comparison_id": "R34126",
            "paper_id": "R34102",
            "text": "Optic neuritis: oligoclo- nal bands increase the risk of multiple sclerosis abstract\u2010 in 1974 we examined 30 patients 0.5\u201314 (mean 5) years after acute unilateral optic neuritis (on), when no clinical signs of multiple sclerosis (ms) were discernable. 11 of the patients had oligoclonal bands in the cerebrospinal fluid (csf). re\u2010examination after an additional 6 years revealed that 9 of the 11 on patients with oligoclonal bands (but only 1 of the 19 without this csf abnormality) had developed ms. the occurrence of oligoclonal bands in csf in a patient with on is \u2010 within the limits of the present observation time \u2010 accompanied by a significantly increased risk of the future development of ms. recurrent on also occurred significantly more often in those on patients who later developed ms.",
            "contribution_ids": [
                "R34103"
            ]
        },
        {
            "instance_id": "R34126xR34108",
            "comparison_id": "R34126",
            "paper_id": "R34108",
            "text": "Optic neuritis: Prognosis for multiple sclerosis from MRI, CSF, and HLA findings we investigated the paraclinical profile of monosymptomatic optic neuritis(on) and its prognosis for multiple sclerosis (ms). the correct identification of patients with very early ms carrying a high risk for conversion to clinically definite ms is important when new treatments are emerging that hopefully will prevent or at least delay future ms. we conducted a prospective single observer and population-based study of 147 consecutive patients (118 women, 80%) with acute monosymptomatic on referred from a catchment area of 1.6 million inhabitants between january 1, 1990 and december 31, 1995. of 116 patients examined with brain mri, 64 (55%) had three or more high signal lesions, 11 (9%) had one to two high signal lesions, and 41 (35%) had a normal brain mri. among 143 patients examined, oligoclonal igg (ob) bands in csf only were demonstrated in 103 patients (72%). of 146 patients analyzed, 68 (47%) carried the dr15,dq6,dw2 haplotype. during the study period, 53 patients (36%) developed clinically definite ms. the presence of three or more ms-like mri lesions as well as the presence of ob were strongly associated with the development of ms (p < 0.001). also, dw2 phenotype was related to the development of ms (p = 0.046). mri and csf studies in patients with on give clinically important information regarding the risk for future ms.",
            "contribution_ids": [
                "R34109"
            ]
        },
        {
            "instance_id": "R34126xR34124",
            "comparison_id": "R34126",
            "paper_id": "R34124",
            "text": "Can CSF predict the course of optic neuritis? to discuss the implications of csf abnormalities for the course of acute monosymptomatic optic neuritis (amon), various csf markers were analysed in patients being randomly selected from a population-based cohort. paired serum and csf were obtained within a few weeks from onset of amon. csf-restricted oligoclonal igg bands, free kappa and free lambda chain bands were observed in 17, 15, and nine of 27 examined patients, respectively. sixteen patients showed a polyspecific intrathecal synthesis of oligoclonal igg antibodies against one or more viruses. at 1 year follow-up five patients had developed clinically definite multiple sclerosis (cdms); all had csf oligoclonal igg bands and virus-specific oligoclonal igg antibodies at onset. due to the relative small number studied at the short-term follow-up, no firm conclusion of the prognostic value of these analyses could be reached. csf myelin basic protein-like material was increased in only two of 29 patients with amon, but may have potential value in reflecting disease activity, as the highest values were obtained among patients with csf sampled soon after the worst visual acuity was reached, and among patients with severe visual impairment. in most previous studies of patients with amon qualitative and quantitative analyses of csf igg had a predictive value for development of cdms, but the results are conflicting.",
            "contribution_ids": [
                "R34125"
            ]
        },
        {
            "instance_id": "R34183xR34136",
            "comparison_id": "R34183",
            "paper_id": "R34136",
            "text": "Case study in benefits and risks of agricultural biotechnology: Roundup Ready soybeans. abstract this case study describes the us regulatory process governing agricultural biotechnology and traces the approval of roundup ready soyabeans (with transgenic tolerance of the herbicide glyphosate), summarizing the information that was submitted to us regulatory agencies by monsanto. estimates of the impact that the adoption of roundup ready soyabeans has had on us agriculture are also provided. the us regulatory structure for agricultural biotechnology has evolved over the past 25 years, as technology allowing for genetic modification developed. the system continues to evolve as new and different applications of the technology emerge. in reviewing the studies that were conducted on the safety of roundup ready soyabeans, no indication of greater health or environmental risks were found compared with conventional varieties. the benefits of the introduction of roundup ready soyabeans include cost savings of us$216 million in annual weed control and 19 million fewer soyabean herbicide applications per year.",
            "contribution_ids": [
                "R34137",
                "R34150",
                "R34170"
            ]
        },
        {
            "instance_id": "R34183xR34163",
            "comparison_id": "R34183",
            "paper_id": "R34163",
            "text": "Genetically modified crops, corporate pricing strategies, and farmers' adoption: the case of Bt cotton in Argentina \"this article analyzes adoption and impacts of bt cotton in argentina against the background of monopoly pricing. based on survey data, it is shown that the technology significantly reduces insecticide applications and increases yields; however, these advantages are curbed by the high price charged for genetically modified seeds. using the contingent valuation method, it is shown that farmers' average willingness to pay is less than half the actual technology price. a lower price would not only increase benefits for growers, but could also multiply company profits, thus, resulting in a pareto improvement. implications of the sub-optimal pricing strategy are discussed.\"",
            "contribution_ids": [
                "R34164",
                "R34165"
            ]
        },
        {
            "instance_id": "R34183xR34179",
            "comparison_id": "R34183",
            "paper_id": "R34179",
            "text": "Potential Benefits of Agricultural Biotechnology: An Example from the Mexican Potato Sector the study analyzes ex ante the socioeconomic effects of transgenic virus resistance technology for potatoes in mexico. all groups of potato growers could significantly gain from the transgenic varieties to be introduced, and the technology could even improve income distribution. nonetheless, public support is needed to fully harness this potential. different policy alternatives are tested within scenario calculations in order to supply information on how to optimize the technological outcome, both from an efficiency and an equity perspective. transgenic disease resistance is a promising technology for developing countries. providing these countries with better access to biotechnology should be given higher political priority.",
            "contribution_ids": [
                "R34180"
            ]
        },
        {
            "instance_id": "R34183xR34140",
            "comparison_id": "R34183",
            "paper_id": "R34140",
            "text": "A critical assessment of methods for analysis of social welfare impacts of genetically modified crops: A literature survey this paper is a review of existing literature on economic and environmental costs and benefits of genetically modified (gm) crops focusing on methodological issues arising from this literature. particular attention is given to the production function framework commonly used to quantify costs and benefits of gm crops at the farm level and to equilibrium displacement models used to quantify impacts of gm crops on social welfare. methods are discussed with respect to their sensitivity to specific parameter values and key areas are identified for further research.",
            "contribution_ids": [
                "R34141",
                "R34142"
            ]
        },
        {
            "instance_id": "R34183xR34145",
            "comparison_id": "R34183",
            "paper_id": "R34145",
            "text": "The distribution of benefits from the introduction of transgenic cotton varieties a handful of vertically coordinated \u201clife science\u201d firms have been the key players in ushering in the biotechnology revolution in the united states. these firms have been successful in linking useful genetic events with high quality germplasm to create genetically modified varieties ( gmvs) with the ability to gain rapid market penetration and to capture value for the creators. these life science firms have fundamentally altered the structure of the seed industry, using mergers, acquisitions and licensing agreements to ally their financial, scientific, and organizational strengths with the genetic resources of traditional seed companies such as pioneer, delta and pineland, asgrow, dekalb and dozens of smaller seed companies. intellectual property right (ipr) laws have been used to provide incentives for inventors to invest in research since the founding of this country. ipr protection provides inventors with limited monopoly power, increasing their ability to appropriate the benefits created by their research effort. the firm producing the ipr-protected innovation is able to price their product above the marginal cost of producing the input, thereby appropriating profit that would otherwise be passed on to consumers through lower prices. major changes have also taken place in t he laws and enforcement of ipr for biological innovations so that protection is now similar to that afforded to discovery in other sectors, but it is really only the specifics of how ipr laws apply to biological innovations that have changed in recent years.",
            "contribution_ids": [
                "R34146"
            ]
        },
        {
            "instance_id": "R34251xR34190",
            "comparison_id": "R34251",
            "paper_id": "R34190",
            "text": "Monetary union in West Africa: who might gain, who might lose, and why? \"we develop a model in which governments' financing needs exceed the socially optimal level because public resources are diverted to serve the narrow interests of the group in power. from a social welfare perspective, this results in undue pressure on the central bank to extract seigniorage. monetary policy also suffers from an expansive bias, owing to the authorities' inability to precommit to price stability. such a conjecture about the fiscal-monetary policy mix appears quite relevant in africa, with deep implications for the incentives of fiscally heterogeneous countries to form a currency union. we calibrate the model to data for west africa and use it to assess proposed ecowas monetary unions. fiscal heterogeneity indeed appears critical in shaping regional currency blocs that would be mutually beneficial for all their members. in particular, nigeria's membership in the configurations currently envisaged would not be in the interests of other ecowas countries unless it were accompanied by effective containment on nigeria's financing needs.\"",
            "contribution_ids": [
                "R34191"
            ]
        },
        {
            "instance_id": "R34251xR34231",
            "comparison_id": "R34251",
            "paper_id": "R34231",
            "text": "West African Single Currency and Competitiveness this paper compares different nominal anchors to promote internal and external competitiveness in the case of a fixed exchange rate regime for the future single regional currency of the economic community of the west african states (ecowas). we use counterfactual analyses and estimate a model of dependent economy for small commodity exporting countries. we consider four foreign anchor currencies: the us dollar, the euro, the yen and the yuan. our simulations show little support for a dominant peg in the ecowas area if they pursue several goals: maximizing the export revenues, minimizing their variability, stabilizing them and minimizing the real exchange rate misalignments from the fundamental value.",
            "contribution_ids": [
                "R34232"
            ]
        },
        {
            "instance_id": "R34251xR34245",
            "comparison_id": "R34251",
            "paper_id": "R34245",
            "text": "Analysis of convergence criteria in a proposed monetary union: a study of the economic community of West African States this study examines the processes of the monetary union of the economic community of west african states (ecowas). it takes a critical look at the convergence criteria and the various conditions under which they are to be met. using the panel least square technique an estimate of the beta convergence was made for the period 2000-2008. the findings show that nearly all the explanatory variables have indirect effects on the income growth rate and that there tends to be convergence in income over time. the speed of adjustment estimated is 0.2% per year and the half-life is -346.92. thus the economies can make up for half of the distance that separates them from their stationary state. from the findings, it was concluded that a well integrated economy could further the achievement of steady growth in these countries in the long run.",
            "contribution_ids": [
                "R34246"
            ]
        },
        {
            "instance_id": "R34282xR34264",
            "comparison_id": "R34282",
            "paper_id": "R34264",
            "text": "A Fast-Track East African Community Monetary Union? Convergence Evidence from a Cointegration Analysis. there is a proposal for a fast-tracked approach to the african community (eac) monetary union. this paper uses cointegration techniques to determine whether the member countries would form a successful monetary union based on the long-run behavior of nominal and real exchange rates and monetary base. the three variables are each analyzed for co-movements among the five countries. the empirical results indicate only partial convergence for the variables considered, suggesting there could be substantial costs for the member countries from a fast-tracked process. this implies the eac countries need significant adjustments to align their monetary policies and to allow a period of monetary policy coordination to foster convergence that will improve the chances of a sustainable currency union.",
            "contribution_ids": [
                "R34265"
            ]
        },
        {
            "instance_id": "R34282xR34270",
            "comparison_id": "R34282",
            "paper_id": "R34270",
            "text": "Design and implementation of a common currency area in the East African community the east african community (eac) has fast-tracked its plans to create a single currency for the five countries making up the region, and hopes to conclude negotiations on a monetary union protocol by the end of 2012. while the benefits of lower transactions costs from a common currency may be significant, countries will also lose the ability to use monetary policy to respond to different shocks. evidence presented shows that the countries differ in a number of respects, facing asymmetric shocks and different production structures. countries have had difficulty meeting convergence criteria, most seriously as concerns fiscal deficits. preparation for monetary union will require effective institutions for macroeconomic surveillance and enforcing fiscal discipline, and euro zone experience indicates that these institutions will be difficult to design and take a considerable time to become effective. this suggests that a timetable for monetary union in the eac should allow for a substantial initial period of institution building. in order to have some visible evidence of the commitment to monetary union, in the meantime the eac may want to consider introducing a common basket currency in the form of notes and coin, to circulate in parallel with national currencies.",
            "contribution_ids": [
                "R34271"
            ]
        },
        {
            "instance_id": "R34316xR34299",
            "comparison_id": "R34316",
            "paper_id": "R34299",
            "text": "The Process of Monetary Integration in the SADC Region* the african union has agreed, in principle, to implement monetary union and a single currency in africa by 2021. this would be based upon the prior formation of regional monetary unions, including one in the sadc region. this article considers the economic prerequisites and implications for a monetary union and, in the light of this, whether a sadc monetary union is feasible. after reviewing the existing monetary union within sadc (the rand-based common monetary area) and current sadc macroeconomic convergence initiatives, the article examines the extent to which key economic and monetary variables \u2013 inflation, interest rates and exchange rates \u2013 are converging within sadc. it concludes that there is a core \u2018convergence\u2019 group comprising the cma countries \u2013 south africa, lesotho, namibia and swaziland \u2013 plus botswana, mauritius, mozambique and tanzania whose macroeconomic performance satisfies some of the criteria for monetary union. the remaining sadc countries \u2013 angola, drc, malawi, zambia and zimbabwe \u2013 make up a \u2018non-converging\u2019 group that cannot yet be considered potential candidates for monetary union. however, even within the convergence group, countries remain far from satisfying the other prerequisites for monetary union, including significant intra-regional trade, and full capital and labour mobility. there are also major political constraints, making the au monetary union proposals and timetable highly ambitious.",
            "contribution_ids": [
                "R34300"
            ]
        },
        {
            "instance_id": "R34316xR34308",
            "comparison_id": "R34316",
            "paper_id": "R34308",
            "text": "On the feasibility of a monetary union in the Southern Africa Development Community this paper investigates the feasibility of a monetary union in southern africa development community (sadc) by looking at evidence of nominal exchange rate and inflation convergence. using a methodology based on estimating time-varying parameters, the evidence suggests non-convergence. the non-convergence of nominal exchange rate and consumer price inflation suggests that presently the chances of sadc member countries satisfying some form of maastricht-type criteria is quite low. copyright \u00a9 2007 john wiley & sons, ltd.",
            "contribution_ids": [
                "R34309"
            ]
        },
        {
            "instance_id": "R34316xR34314",
            "comparison_id": "R34316",
            "paper_id": "R34314",
            "text": "Assessment of monetary union in SADC: evidence from cointegration and panel unit root tests in this paper we investigate the likelihood of a proposed monetary union in the southern african development community (sadc) being successful from the viewpoint of the generalised purchasing power parity (gppp) hypothesis and optimum currency area (oca) theory. we apply johansen\u2019s multivariate co-integration technique, panel unit root tests, pedroni\u2019s residual cointegration test and error correction based panel cointegration tests. the findings from this study confirm that gppp holds among sadc member countries included in this study on account of cointegration and stationarity in real exchange rate series. the south african rand normalised long run beta coefficients of all the real exchange rates are below one except in the case of the mauritian rupee and all bear negative signs except in the case of the angolan new kwanza and mauritian rupee. this evidence support monetary union in the region except for angola and mauritius. however, the absolute magnitudes of the short run adjustment coefficients of sadc countries\u2019 real exchange rates are low and bear positive signs in some cases. this finding implies that the observed slow speed of adjustment for the (log) real exchange rate of sadc member states might constrain the effectiveness of stabilization policies in the wake of external shocks, rendering sadc countries vulnerable to macroeconomic instability in the region. this result has important policy implications for the proposed monetary union in sadc.",
            "contribution_ids": [
                "R34315"
            ]
        },
        {
            "instance_id": "R34411xR34372",
            "comparison_id": "R34411",
            "paper_id": "R34372",
            "text": "Isolation of Clostridium difficile from human jejunum: identification of a reservoir for disease? the possibility that the small intestine may represent a reservoir for clostridium difficile was studied, using segments of human jejunum collected at necropsy. our results (three of 100 specimens positive for c difficile culture) support the hypothesis that c difficile can be found in human jejunum and that it adheres to the normal mucosa as a resident bacterium. these findings suggest that gastrointestinal disease caused by c difficile has an endogenous origin.",
            "contribution_ids": [
                "R34373"
            ]
        },
        {
            "instance_id": "R34411xR34384",
            "comparison_id": "R34411",
            "paper_id": "R34384",
            "text": "Fatal Clostridium difficile infection of the small bowel after complex colorectal surgery pseudomembranous colitis is a well recognized complication of antibiotic use1 and is due to disturbances of the normal colonic bacterial flora, resulting in overgrowth of clostridium difficile. for recurrent or severe cases, oral vancomycin or metronidazole is the treatment of choice. progression to acute fulminant colitis with systemic toxic effects occasionally occurs, especially in the elderly and in the immunosuppressed. some of these patients may need surgical intervention for complications such as perforation.2 clostridium difficile is commonly regarded as a colonic pathogen and there are few reports of c. difficile enteritis with involvement of the small bowel (table 1). pseudomembrane formation caused by c. difficile is generally restricted to the colon, with abrupt termination at the ileocaecal valve.1,3,5,8,9 we report a case of fulminant and fatal c. difficile infection with pseudomembranes throughout the entire small bowel and colon in a patient following complex colorectal surgery. the relevant literature is reviewed.",
            "contribution_ids": [
                "R34385"
            ]
        },
        {
            "instance_id": "R34411xR34400",
            "comparison_id": "R34411",
            "paper_id": "R34400",
            "text": "Fulminant Clostridium difficile enteritis after proctocolectomy and ileal pouch-anal anastamosis clostridium difficile ( c. difficile ) infection of the small bowel is very rare. the disease course is more severe than that of c. difficile colitis, and the mortality is high. we present a case of c. difficile enteritis in a patient with with ileal pouch-anal anastamosis (ipaa), and review previous case reports in order to better characterize this unusual condition.",
            "contribution_ids": [
                "R34401"
            ]
        },
        {
            "instance_id": "R34454xR34444",
            "comparison_id": "R34454",
            "paper_id": "R34444",
            "text": "Facial Expression Recognition from Line-Based Caricatures the automatic recognition of facial expression presents a significant challenge to the pattern analysis and man-machine interaction research community. recognition from a single static image is particularly a difficult task. in this paper, we present a methodology for facial expression recognition from a single static image using line-based caricatures. the recognition process is completely automatic. it also addresses the computational expensive problem and is thus suitable for real-time applications. the proposed approach uses structural and geometrical features of a user sketched expression model to match the line edge map (lem) descriptor of an input face image. a disparity measure that is robust to expression variations is defined. the effectiveness of the proposed technique has been evaluated and promising results are obtained. this work has proven the proposed idea that facial expressions can be characterized and recognized by caricatures.",
            "contribution_ids": [
                "R34445"
            ]
        },
        {
            "instance_id": "R34454xR34448",
            "comparison_id": "R34454",
            "paper_id": "R34448",
            "text": "Facial expression recognition and synthesis based on an appearance model facial expression interpretation, recognition and analysis is a key issue in visual communication and man to machine interaction. we address the issues of facial expression recognition and synthesis and compare the proposed bilinear factorization based representations with previously investigated methods such as linear discriminant analysis and linear regression. we conclude that bilinear factorization outperforms these techniques in terms of correct recognition rates and synthesis photorealism especially when the number of training samples is restrained.",
            "contribution_ids": [
                "R34449"
            ]
        },
        {
            "instance_id": "R34454xR34452",
            "comparison_id": "R34454",
            "paper_id": "R34452",
            "text": "Facial event classification with task oriented dynamic bayesian network facial events include all activities of face and facial features in spatial or temporal space, such as facial expressions, face gesture, gaze and furrow happening, etc. developing an automated system for facial event classification is always a challenging task due to the richness, ambiguity and dynamic nature of facial expressions. this paper presents an efficient approach to real-world facial event classification. by integrating dynamic bayesian network (dbn) with a general-purpose facial behavior description language, a task-oriented stochastic and temporal framework is constructed to systematically represent and classify facial events of interest. based on the task oriented dbn, we can spatially and temporally incorporate results from previous times and prior knowledge of the application domain. with the top-down inference, the system can make active selection among multiple visual channels to identify the most effective sensory channels to use. with the bottom-up inference from observed evidences, the current facial event can be classified with a desired confident level via the belief propagation. we applied the task-oriented dbn framework to monitoring driver vigilance. experimental results demonstrate the feasibility and efficiency of our approach.",
            "contribution_ids": [
                "R34453"
            ]
        },
        {
            "instance_id": "R34605xR34522",
            "comparison_id": "R34605",
            "paper_id": "R34522",
            "text": "Towards identity anonymization on graphs the proliferation of network data in various application domains has raised privacy concerns for the individuals involved. recent studies show that simply removing the identities of the nodes before publishing the graph/social network data does not guarantee privacy. the structure of the graph itself, and in its basic form the degree of the nodes, can be revealing the identities of individuals. to address this issue, we study a specific graph-anonymization problem. we call a graph k-degree anonymous if for every node v, there exist at least k-1 other nodes in the graph with the same degree as v. this definition of anonymity prevents the re-identification of individuals by adversaries with a priori knowledge of the degree of certain nodes. we formally define the graph-anonymization problem that, given a graph g, asks for the k-degree anonymous graph that stems from g with the minimum number of graph-modification operations. we devise simple and efficient algorithms for solving this problem. our algorithms are based on principles related to the realizability of degree sequences. we apply our methods to a large spectrum of synthetic and real datasets and demonstrate their efficiency and practical utility.",
            "contribution_ids": [
                "R34523"
            ]
        },
        {
            "instance_id": "R34605xR34533",
            "comparison_id": "R34605",
            "paper_id": "R34533",
            "text": "Comparisons of randomization and K-degree anonymization schemes for privacy preserving social network publishing many applications of social networks require identity and/or relationship anonymity due to the sensitive, stigmatizing, or confidential nature of user identities and their behaviors. recent work showed that the simple technique of anonymizing graphs by replacing the identifying information of the nodes with random ids does not guarantee privacy since the identification of the nodes can be seriously jeopardized by applying background based attacks. in this paper, we investigate how well an edge based graph randomization approach can protect node identities and sensitive links. we quantify both identity disclosure and link disclosure when adversaries have one specific type of background knowledge (i.e., knowing the degrees of target individuals). we also conduct empirical comparisons with the recently proposed k-degree anonymization schemes in terms of both utility and risks of privacy disclosures.",
            "contribution_ids": [
                "R34534",
                "R34583"
            ]
        },
        {
            "instance_id": "R34605xR34540",
            "comparison_id": "R34605",
            "paper_id": "R34540",
            "text": "On identity disclosure in weighted graphs as an integral part of data security, identity disclosureis a major privacy breach, which reveals the identification of entities with certain background knowledge known by an adversary. most recent studies on this problem focus on the protection of relational data or simple graph data (i.e. undirected, un weighted and acyclic). however, a weighted graph can introduce much more unique information than its simple version, which makes the disclosure easier. as more real-world graphs or social networks are released publicly, there is growing concern about privacy breaching for the entities involved. in this paper, we first formalize a general anonymizing model to deal with weight-related attacks, and discuss an efficient metric to quantify information loss incurred in the perturbation. then we consider a very practical attack based on the sum of adjacent weights for each vertex, which is known as volume in graph theory field. we also propose a complete solution for the weight anonymization problem to prevent a graph from volume attack. our approaches are efficient and practical, and have been validated by extensive experiments on both synthetic and real-world datasets.",
            "contribution_ids": [
                "R34541"
            ]
        },
        {
            "instance_id": "R34605xR34550",
            "comparison_id": "R34605",
            "paper_id": "R34550",
            "text": "k-automorphism the growing popularity of social networks has generated interesting data management and data mining problems. an important concern in the release of these data for study is their privacy, since social networks usually contain personal information. simply removing all identifiable personal information (such as names and social security number) before releasing the data is insufficient. it is easy for an attacker to identify the target by performing different structural queries. in this paper we propose k-automorphism to protect against multiple structural attacks and develop an algorithm (called km) that ensures k-automorphism. we also discuss an extension of km to handle \"dynamic\" releases of the data. extensive experiments show that the algorithm performs well in terms of protection it provides.",
            "contribution_ids": [
                "R34551"
            ]
        },
        {
            "instance_id": "R34605xR34567",
            "comparison_id": "R34605",
            "paper_id": "R34567",
            "text": "The link prediction problem for social networks given a snapshot of a social network, can we infer which new interactions among its members are likely to occur in the near future? we formalize this question as the link prediction problem, and develop approaches to link prediction based on measures the \"proximity\" of nodes in a network. experiments on large co-authorship networks suggest that information about future interactions can be extracted from network topology alone, and that fairly subtle measures for detecting node proximity can outperform more direct measures.",
            "contribution_ids": [
                "R34568"
            ]
        },
        {
            "instance_id": "R34605xR34584",
            "comparison_id": "R34605",
            "paper_id": "R34584",
            "text": "Supervised random walks: predicting and recommending links in social networks predicting the occurrence of links is a fundamental problem in networks. in the link prediction problem we are given a snapshot of a network and would like to infer which interactions among existing members are likely to occur in the near future or which existing interactions are we missing. although this problem has been extensively studied, the challenge of how to effectively combine the information from the network structure with rich node and edge attribute data remains largely open.\\n we develop an algorithm based on supervised random walks that naturally combines the information from the network structure with node and edge level attributes. we achieve this by using these attributes to guide a random walk on the graph. we formulate a supervised learning task where the goal is to learn a function that assigns strengths to edges in the network such that a random walker is more likely to visit the nodes to which new links will be created in the future. we develop an efficient training algorithm to directly learn the edge strength estimation function.\\n our experiments on the facebook social graph and large collaboration networks show that our approach outperforms state-of-the-art unsupervised approaches as well as approaches that are based on feature extraction.",
            "contribution_ids": [
                "R34585",
                "R34586"
            ]
        },
        {
            "instance_id": "R34663xR34622",
            "comparison_id": "R34663",
            "paper_id": "R34622",
            "text": "Optimizing Medical Data Quality Based on Multiagent Web Service Framework one of the most important issues in e-healthcare information systems is to optimize the medical data quality extracted from distributed and heterogeneous environments, which can extremely improve diagnostic and treatment decision making. this paper proposes a multiagent web service framework based on service-oriented architecture for the optimization of medical data quality in the e-healthcare information system. based on the design of the multiagent web service framework, an evolutionary algorithm (ea) for the dynamic optimization of the medical data quality is proposed. the framework consists of two main components; first, an ea will be used to dynamically optimize the composition of medical processes into optimal task sequence according to specific quality attributes. second, a multiagent framework will be proposed to discover, monitor, and report any inconstancy between the optimized task sequence and the actual medical records. to demonstrate the proposed framework, experimental results for a breast cancer case study are provided. furthermore, to show the unique performance of our algorithm, a comparison with other works in the literature review will be presented.",
            "contribution_ids": [
                "R34623"
            ]
        },
        {
            "instance_id": "R34706xR34666",
            "comparison_id": "R34706",
            "paper_id": "R34666",
            "text": "User-Priority guided min min scheduling algorithm for load balancing in cloud computing \"cloud computing is emerging as a new paradigm of large-scale distributed computing. in order to utilize the power of cloud computing completely, we need an efficient task scheduling algorithm. the traditional min-min algorithm is a simple, efficient algorithm that produces a better schedule that minimizes the total completion time of tasks than other algorithms in the literature [7]. however the biggest drawback of it is load imbalanced, which is one of the central issues for cloud providers. in this paper, an improved load balanced algorithm is introduced on the ground of min-min algorithm in order to reduce the makespan and increase the resource utilization (lbimm). at the same time, cloud providers offer computer resources to users on a pay-per-use base. in order to accommodate the demands of different users, they may offer different levels of quality for services. then the cost per resource unit depends on the services selected by the user. in return, the user receives guarantees regarding the provided resources. to observe the promised guarantees, user-priority was considered in our proposed pa-lbimm so that user's demand could be satisfied more completely. at last, the introduced algorithm is simulated using matlab toolbox. the simulation results show that the improved algorithm can lead to significant performance gain and achieve over 20% improvement on both vip user satisfaction and resource utilization ratio.\"",
            "contribution_ids": [
                "R34667"
            ]
        },
        {
            "instance_id": "R34706xR34670",
            "comparison_id": "R34706",
            "paper_id": "R34670",
            "text": "Load Balancing for Internet Distributed Services Using Limited Redirection Rates the internet has become the universal support for computer applications. this increases the need for solutions that provide dependability and qos for web applications. the replication of web servers on geographically distributed data centers allows the service provider to tolerate disastrous failures and to improve the response times perceived by clients. a key issue for good performance of worldwide distributed web services is the efficiency of the load balancing mechanism used to distribute client requests among the replicated servers. load balancing can reduce the need for over-provision of resources, and help tolerate abrupt load peaks and/or partial failures through load conditioning. in this paper, we propose a new load balancing solution that reduces service response times by redirecting requests to the closest remote servers without overloading them. we also describe a middle ware that implements this protocol and present the results of a set of simulations that show its usefulness.",
            "contribution_ids": [
                "R34671"
            ]
        },
        {
            "instance_id": "R34706xR34678",
            "comparison_id": "R34706",
            "paper_id": "R34678",
            "text": "A Lock-Free Solution for Load Balancing in Multi-Core Environment load balancing device is an important part of cloud platform. one of the most common applications of load balancing is to provide a single powerful virtual machine from multiple servers. in multi-core environment, the load balancing device can run multiple physically parallel load-balancing processes to increase overall performance. an important issue when operating a load-balanced service is how to send all requests in a user session consistently to the same backend server, i.e. session maintaining. most of multiprocessing load balancing solutions use shared memory and lock when manage session. by modifying linux kernel, we avoid using shared memory and implement a lock-free multiprocessing load balancing solution.",
            "contribution_ids": [
                "R34679"
            ]
        },
        {
            "instance_id": "R34845xR34761",
            "comparison_id": "R34845",
            "paper_id": "R34761",
            "text": "Effects of some egg characteristics on the mass loss and hatchability of ostrich (Struthio camelus) eggs 1. this study was conducted to examine some egg characteristics and determine the effects of eggshell thickness and eggshell porosity on water loss and hatchability of eggs in ostriches. 2. shell thickness did not correlate significantly with hatchability. however, eggs of low shell thickness lost more mass (13\u00b703%) than those with intermediate (11\u00b722%) and high (10\u00b736%) shell thickness. mass loss during incubation was higher in hatched (11\u00b798%) than unhatched eggs (11\u00b709%). shell thickness was negatively correlated to egg mass loss (r = \u22120\u00b765). 3. the pore density was correlated with hatchability. hatchability was 50% lower in eggs with low pore densities (40\u00b793%) than with high densities (80\u00b794%). pore density was positively correlated with egg mass loss (r = 0\u00b763). incubation mass losses of hatched and unhatched eggs were not significantly different. 4. mean eggshell water vapour conductance (g) value and shell conductance constant (k) were 87\u00b777 \u00b1 4\u00b721 mg h2o/d/torr and 2\u00b744 respectively (n = 15). 5. because of eggshell functional properties and resulting low egg mass loss hatchability is low when ostrich eggs are artificially incubated. the mass of eggs used in the experiment was relatively high and their eggshell water vapour conductance was low. as a result, egg incubation mass loss was lower than it should be. it is concluded that incubator humidity should be low (25%) to allow enough mass loss during incubation from the eggs.",
            "contribution_ids": [
                "R34762"
            ]
        },
        {
            "instance_id": "R34845xR34773",
            "comparison_id": "R34845",
            "paper_id": "R34773",
            "text": "The Effect of Embryonic Development on the Thickness of the Egg Shells of Coturnix Quail abstract the average thickness of the shells from 75 unincubated coturnix quail eggs was found to be 0.193 mm. this was 7.3 percent greater than the average thickness (0.179 mm.) of the shells from 60 fully incubated eggs from the same hens. the two sets of eggs were collected simultaneously. this thickness difference was statistically significant (t-test:p",
            "contribution_ids": [
                "R34774"
            ]
        },
        {
            "instance_id": "R34845xR34796",
            "comparison_id": "R34845",
            "paper_id": "R34796",
            "text": "Avian embryonic development does not change the stable isotope composition of the calcite eggshell the avian embryo resorbs most of the calcium for bone formation from the calcite eggshell but the exact mechanisms of the resorption are unknown. the present study tested whether this process results in variable fractionation of the oxygen and carbon isotopes in shell calcium carbonate, which could provide a detailed insight into the temporal and spatial use of the eggshell by the developing embryo. despite the uncertainty regarding changes in stable isotope composition of the eggshell across developmental stages or regions of the shell, eggshells are a popular resource for the analysis of historic and extant trophic relationships. to clarify how the stable isotope composition varies with embryonic development, the \u03b413c and \u03b418o content of the carbonate fraction in shells of black-headed gull (larus ridibundus) eggs were sampled at four different stages of embryonic development and at five eggshell regions. no consistent relationship between the stable isotope composition of the eggshell and embryonic development, shell region or maculation was observed, although shell thickness decreased with development in all shell regions. by contrast, individual eggs differed significantly in isotope composition. these results establish that eggshells can be used to investigate a species\u2019 carbon and oxygen sources, regardless of the egg\u2019s developmental stage.",
            "contribution_ids": [
                "R34797"
            ]
        },
        {
            "instance_id": "R34845xR34824",
            "comparison_id": "R34845",
            "paper_id": "R34824",
            "text": "California Condors and DDE: a re-evaluation \"eggshells of wild california condors gymnogyps californianus were much thinner in the 1960s, when ddt was used heavily, than during earlier pre-ddt and later reduced-ddt periods. however, eggshell thickness was more strongly linked to egg size (mass) than to measured levels of p,p\u2032dde (the primary metabolite of ddt). egg size was consistent within individual females and yielded correlation coefficients with shell thickness ranging from 0.49 to 0.97, depending on the period and the analysis assumptions used. measured dde levels, although often substantial, provided only a weak correlation (r\\xa0=\\xa0\u22120.33) with shell thickness. in part, the absence of a strong dde/thickness correlation may have been an artefact of losses of dde from fragment membranes over time. nevertheless, the extreme (28\u201329%) shell thinning of the 1960s was not linked with clearly increased egg-breakage or nest-failure rates, and one female of the 1980s with 25.6% shell thinning was the most productive female of her era. some eggs with over 30% shell thinning hatched successfully, and broken eggs closely resembled hatched eggs in shell thickness, strongly suggesting that shell thinning was not an important cause of breakage. the apparent absence of harmful effects from the extreme shell thinning of the 1960s may have resulted from (1) the fact that historic pre-ddt condor eggs were on average 16.7% thicker shelled for their mass than predicted by the overall egg mass/shell thickness curve for birds, and (2) a possible egg-size decline or sampling bias toward small-egged females in the 1960s. that dde was an important cause of the condor's decline appears unlikely from overall available data.\"",
            "contribution_ids": [
                "R34825"
            ]
        },
        {
            "instance_id": "R36153xR36106",
            "comparison_id": "R36153",
            "paper_id": "R36106",
            "text": "Characterizing the transmission and identifying the control strategy for COVID-19 through epidemiological modeling abstract the outbreak of the novel coronavirus disease, covid-19, originating from wuhan, china in early december, has infected more than 70,000 people in china and other countries and has caused more than 2,000 deaths. as the disease continues to spread, the biomedical society urgently began identifying effective approaches to prevent further outbreaks. through rigorous epidemiological analysis, we characterized the fast transmission of covid-19 with a basic reproductive number 5.6 and proved a sole zoonotic source to originate in wuhan. no changes in transmission have been noted across generations. by evaluating different control strategies through predictive modeling and monte carlo simulations, a comprehensive quarantine in hospitals and quarantine stations has been found to be the most effective approach. government action to immediately enforce this quarantine is highly recommended.",
            "contribution_ids": [
                "R36107"
            ]
        },
        {
            "instance_id": "R36153xR36149",
            "comparison_id": "R36153",
            "paper_id": "R36149",
            "text": "Analysis of the epidemic growth of the early 2019-nCoV outbreak using internationally confirmed cases abstract background on january 23, 2020, a quarantine was imposed on travel in and out of wuhan, where the 2019 novel coronavirus (2019-ncov) outbreak originated from. previous analyses estimated the basic epidemiological parameters using symptom onset dates of the confirmed cases in wuhan and outside china. methods we obtained information on the 46 coronavirus cases who traveled from wuhan before january 23 and have been subsequently confirmed in hong kong, japan, korea, macau, singapore, and taiwan as of february 5, 2020. most cases have detailed travel history and disease progress. compared to previous analyses, an important distinction is that we used this data to informatively simulate the infection time of each case using the symptom onset time, previously reported incubation interval, and travel history. we then fitted a simple exponential growth model with adjustment for the january 23 travel ban to the distribution of the simulated infection time. we used a bayesian analysis with diffuse priors to quantify the uncertainty of the estimated epidemiological parameters. we performed sensitivity analysis to different choices of incubation interval and the hyperparameters in the prior specification. results we found that our model provides good fit to the distribution of the infection time. assuming the travel rate to the selected countries and regions is constant over the study period, we found that the epidemic was doubling in size every 2.9 days (95% credible interval [cri], 2 days\u20144.1 days). using previously reported serial interval for 2019-ncov, the estimated basic reproduction number is 5.7 (95% cri, 3.4\u20149.2). the estimates did not change substantially if we assumed the travel rate doubled in the last 3 days before january 23, when we used previously reported incubation interval for severe acute respiratory syndrome (sars), or when we changed the hyperparameters in our prior specification. conclusions our estimated epidemiological parameters are higher than an earlier report using confirmed cases in wuhan. this indicates the 2019-ncov could have been spreading faster than previous estimates.",
            "contribution_ids": [
                "R36150"
            ]
        },
        {
            "instance_id": "R38484xR23443",
            "comparison_id": "R38484",
            "paper_id": "R23443",
            "text": "The Norwegian Earth System Model, NorESM1-M \u00e2\u0080\u0093 Part 1: Description and basic evaluation of the physical climate \" abstract. the core version of the norwegian climate center's earth system model, named noresm1-m, is presented. the noresm family of models are based on the community climate system model version 4 (ccsm4) of the university corporation for atmospheric research, but differs from the latter by, in particular, an isopycnic coordinate ocean model and advanced chemistry\u2013aerosol\u2013cloud\u2013radiation interaction schemes. noresm1-m has a horizontal resolution of approximately 2\u00b0 for the atmosphere and land components and 1\u00b0 for the ocean and ice components. noresm is also available in a lower resolution version (noresm1-l) and a version that includes prognostic biogeochemical cycling (noresm1-me). the latter two model configurations are not part of this paper. here, a first-order assessment of the model stability, the mean model state and the internal variability based on the model experiments made available to cmip5 are presented. further analysis of the model performance is provided in an accompanying paper (iversen et al., 2013), presenting the corresponding climate response and scenario projections made with noresm1-m.\\n \"",
            "contribution_ids": [
                "R23444"
            ]
        },
        {
            "instance_id": "R38484xR9221",
            "comparison_id": "R38484",
            "paper_id": "R9221",
            "text": "The ACCESS coupled model: description, control climate and evaluation 4oasis3.2\u20135 coupling framework. the primary goal of the access-cm development is to provide the australian climate community with a new generation fully coupled climate model for climate research, and to participate in phase five of the coupled model inter-comparison project (cmip5). this paper describes the access-cm framework and components, and presents the control climates from two versions of the access-cm, access1.0 and access1.3, together with some fields from the 20 th century historical experiments, as part of model evaluation. while sharing the same ocean sea-ice model (except different setups for a few parameters), access1.0 and access1.3 differ from each other in their atmospheric and land surface components: the former is configured with the uk met office hadgem2 (r1.1) atmospheric physics and the met office surface exchange scheme land surface model version 2, and the latter with atmospheric physics similar to the uk met office global atmosphere 1.0 includ ing modifications performed at cawcr and the csiro community atmosphere biosphere land exchange land surface model version 1.8. the global average annual mean surface air temperature across the 500-year preindustrial control integrations show a warming drift of 0.35 \u00b0c in access1.0 and 0.04 \u00b0c in access1.3. the overall skills of access-cm in simulating a set of key climatic fields both globally and over australia significantly surpass those from the preceding csiro mk3.5 model delivered to the previous coupled model inter-comparison. however, access-cm, like other cmip5 models, has deficiencies in various as pects, and these are also discussed.",
            "contribution_ids": [
                "R9222",
                "R9228"
            ]
        },
        {
            "instance_id": "R41148xR41128",
            "comparison_id": "R41148",
            "paper_id": "R41128",
            "text": "Verification and implications of the dissolution-electrodeposition process during the electro-reduction of solid silica in molten CaCl 2 with the verification of the existence of the dissolution-electrodeposition mechanism during the electro-reduction of solid silica in molten cacl2, the present study not only provides direct scientific support for the controllable electrolytic extraction of nanostructured silicon in molten salts but it also opens an avenue to a continuous silicon extraction process via the electro-deposition of dissolved silicates in molten cacl2. in addition, the present study increases the general understanding of the versatile material extraction route via the electro-deoxidization process of solid oxides in molten salts, which also provokes reconsiderations on the electrochemistry of insulating compounds.",
            "contribution_ids": [
                "R41129"
            ]
        },
        {
            "instance_id": "R41148xR41136",
            "comparison_id": "R41148",
            "paper_id": "R41136",
            "text": "Toward cost-effective manufacturing of silicon solar cells: electrodeposition of high-quality Si films in a CaCl 2 -based molten salt electrodeposition of si films from a si-containing electrolyte is a cost-effective approach for the manufacturing of solar cells. proposals relying on fluoride-based molten salts have suffered from low product quality due to difficulties in impurity control. here we demonstrate the successful electrodeposition of high-quality si films from a cacl2 -based molten salt. soluble siiv -o anions generated from solid sio2 are electrodeposited onto a graphite substrate to form a dense film of crystalline si. impurities in the deposited si film are controlled at low concentrations (both b and p are less than 1\\u2005ppm). in the photoelectrochemical measurements, the film shows p-type semiconductor character and large photocurrent. a p-n junction fabricated from the deposited si film exhibits clear photovoltaic effects. this study represents the first step to the ultimate goal of developing a cost-effective manufacturing process for si solar cells based on electrodeposition.",
            "contribution_ids": [
                "R41137"
            ]
        },
        {
            "instance_id": "R41148xR41142",
            "comparison_id": "R41148",
            "paper_id": "R41142",
            "text": "Electrochemical formation of a p\u00e2\u0088\u0092n junction of thin film silicon deposited in molten salt herein we report the demonstration of electrochemical deposition of silicon p-n junctions all in molten salt. the results show that a dense robust silicon thin film with embedded junction formation can be produced directly from inexpensive silicates/silicon oxide precursors by a two-step electrodeposition process. the fabricated silicon p-n junction exhibits clear diode rectification behavior and photovoltaic effects, indicating promise for application in low-cost silicon thin film solar cells.",
            "contribution_ids": [
                "R41143"
            ]
        },
        {
            "instance_id": "R41466xR41016",
            "comparison_id": "R41466",
            "paper_id": "R41016",
            "text": "Unique epidemiological and clinical features of the emerging 2019 novel coronavirus pneumonia (COVID-19) implicate special control measures by 27 february 2020, the outbreak of coronavirus disease 2019 (covid\u201019) caused 82\\u2009623 confirmed cases and 2858 deaths globally, more than severe acute respiratory syndrome (sars) (8273 cases, 775 deaths) and middle east respiratory syndrome (mers) (1139 cases, 431 deaths) caused in 2003 and 2013, respectively. covid\u201019 has spread to 46 countries internationally. total fatality rate of covid\u201019 is estimated at 3.46% by far based on published data from the chinese center for disease control and prevention (china cdc). average incubation period of covid\u201019 is around 6.4 days, ranges from 0 to 24 days. the basic reproductive number (r0) of covid\u201019 ranges from 2 to 3.5 at the early phase regardless of different prediction models, which is higher than sars and mers. a study from china cdc showed majority of patients (80.9%) were considered asymptomatic or mild pneumonia but released large amounts of viruses at the early phase of infection, which posed enormous challenges for containing the spread of covid\u201019. nosocomial transmission was another severe problem. a total of 3019 health workers were infected by 12 february 2020, which accounted for 3.83% of total number of infections, and extremely burdened the health system, especially in wuhan. limited epidemiological and clinical data suggest that the disease spectrum of covid\u201019 may differ from sars or mers. we summarize latest literatures on genetic, epidemiological, and clinical features of covid\u201019 in comparison to sars and mers and emphasize special measures on diagnosis and potential interventions. this review will improve our understanding of the unique features of covid\u201019 and enhance our control measures in the future.",
            "contribution_ids": [
                "R41017",
                "R41019",
                "R41020",
                "R41022",
                "R41023",
                "R41025"
            ]
        },
        {
            "instance_id": "R44930xR44793",
            "comparison_id": "R44930",
            "paper_id": "R44793",
            "text": "Effects of voluntary event cancellation and school closure as countermeasures against COVID\u00e2\u0088\u009219 outbreak in Japan abstract background to control the covid-19 outbreak in japan, sports and entertainment events were canceled and schools were closed throughout japan from february 26 through march 19. that policy has been designated as voluntary event cancellation and school closure (vecsc). object this study assesses vecsc effectiveness based on predicted outcomes. method: a simple susceptible\u2013infected\u2013recovery model was applied to data of patients with symptoms in japan during january 14 through march 25. the respective reproduction numbers were estimated before vecsc (r), during vecsc (r e ), and after vecsc (r a ). results results suggest r before vecsc as 1.987 [1.908, 2.055], r e during vecsc as 1.122 [0.980, 1.260], and r a after vecsc as 3.086 [2.529, 3.739]. discussion and conclusion results demonstrated that vecsc can reduce covid-19 infectiousness considerably, but the value of r rose to exceed 2.5 after vecsc.",
            "contribution_ids": [
                "R44794"
            ]
        },
        {
            "instance_id": "R44930xR44812",
            "comparison_id": "R44930",
            "paper_id": "R44812",
            "text": "Pattern of early human-to-human transmission of Wuhan 2019-nCoV abstract on december 31, 2019, the world health organization was notified about a cluster of pneumonia of unknown aetiology in the city of wuhan, china. chinese authorities later identified a new coronavirus (2019-ncov) as the causative agent of the outbreak. as of january 23, 2020, 655 cases have been confirmed in china and several other countries. understanding the transmission characteristics and the potential for sustained human-to-human transmission of 2019-ncov is critically important for coordinating current screening and containment strategies, and determining whether the outbreak constitutes a public health emergency of international concern (pheic). we performed stochastic simulations of early outbreak trajectories that are consistent with the epidemiological findings to date. we found the basic reproduction number, r 0 , to be around 2.2 (90% high density interval 1.4\u20143.8), indicating the potential for sustained human-to-human transmission. transmission characteristics appear to be of a similar magnitude to severe acute respiratory syndrome-related coronavirus (sars-cov) and the 1918 pandemic influenza. these findings underline the importance of heightened screening, surveillance and control efforts, particularly at airports and other travel hubs, in order to prevent further international spread of 2019-ncov.",
            "contribution_ids": [
                "R44815"
            ]
        },
        {
            "instance_id": "R44930xR44825",
            "comparison_id": "R44930",
            "paper_id": "R44825",
            "text": "Preliminary estimation of the basic reproduction number of novel coronavirus (2019-nCoV) in China, from 2019 to 2020: A data-driven analysis in the early phase of the outbreak backgrounds an ongoing outbreak of a novel coronavirus (2019-ncov) pneumonia hit a major city of china, wuhan, december 2019 and subsequently reached other provinces/regions of china and countries. we present estimates of the basic reproduction number, r0, of 2019-ncov in the early phase of the outbreak. methods accounting for the impact of the variations in disease reporting rate, we modelled the epidemic curve of 2019-ncov cases time series, in mainland china from january 10 to january 24, 2020, through the exponential growth. with the estimated intrinsic growth rate (\u03b3), we estimated r0 by using the serial intervals (si) of two other well-known coronavirus diseases, mers and sars, as approximations for the true unknown si. findings the early outbreak data largely follows the exponential growth. we estimated that the mean r0 ranges from 2.24 (95%ci: 1.96-2.55) to 3.58 (95%ci: 2.89-4.39) associated with 8-fold to 2-fold increase in the reporting rate. we demonstrated that changes in reporting rate substantially affect estimates of r0. conclusion the mean estimate of r0 for the 2019-ncov ranges from 2.24 to 3.58, and significantly larger than 1. our findings indicate the potential of 2019-ncov to cause outbreaks.",
            "contribution_ids": [
                "R44828",
                "R44832"
            ]
        },
        {
            "instance_id": "R44930xR44842",
            "comparison_id": "R44930",
            "paper_id": "R44842",
            "text": "Early Transmissibility Assessment of a Novel Coronavirus in Wuhan, China between december 1, 2019 and january 26, 2020, nearly 3000 cases of respiratory illness caused by a novel coronavirus originating in wuhan, china have been reported. in this short analysis, we combine publicly available cumulative case data from the ongoing outbreak with phenomenological modeling methods to conduct an early transmissibility assessment. our model suggests that the basic reproduction number associated with the outbreak (at time of writing) may range from 2.0 to 3.1. though these estimates are preliminary and subject to change, they are consistent with previous findings regarding the transmissibility of the related sars-coronavirus and indicate the possibility of epidemic potential.",
            "contribution_ids": [
                "R44843"
            ]
        },
        {
            "instance_id": "R44930xR44856",
            "comparison_id": "R44930",
            "paper_id": "R44856",
            "text": "Time-varying transmission dynamics of Novel Coronavirus Pneumonia in China abstract rationale several studies have estimated basic production number of novel coronavirus pneumonia (ncp). however, the time-varying transmission dynamics of ncp during the outbreak remain unclear. objectives we aimed to estimate the basic and time-varying transmission dynamics of ncp across china, and compared them with sars. methods data on ncp cases by february 7, 2020 were collected from epidemiological investigations or official websites. data on severe acute respiratory syndrome (sars) cases in guangdong province, beijing and hong kong during 2002-2003 were also obtained. we estimated the doubling time, basic reproduction number ( r 0 ) and time-varying reproduction number ( r t ) of ncp and sars. measurements and main results as of february 7, 2020, 34,598 ncp cases were identified in china, and daily confirmed cases decreased after february 4. the doubling time of ncp nationwide was 2.4 days which was shorter than that of sars in guangdong (14.3 days), hong kong (5.7 days) and beijing (12.4 days). the r 0 of ncp cases nationwide and in wuhan were 4.5 and 4.4 respectively, which were higher than r 0 of sars in guangdong ( r 0 =2.3), hongkong ( r 0 =2.3), and beijing ( r 0 =2.6). the r t for ncp continuously decreased especially after january 16 nationwide and in wuhan. the r 0 for secondary ncp cases in guangdong was 0.6, and the r t values were less than 1 during the epidemic. conclusions ncp may have a higher transmissibility than sars, and the efforts of containing the outbreak are effective. however, the efforts are needed to persist in for reducing time-varying reproduction number below one. at a glance commentary scientific knowledge on the subject since december 29, 2019, pneumonia infection with 2019-ncov, now named as novel coronavirus pneumonia (ncp), occurred in wuhan, hubei province, china. the disease has rapidly spread from wuhan to other areas. as a novel virus, the time-varying transmission dynamics of ncp remain unclear, and it is also important to compare it with sars. what this study adds to the field we compared the transmission dynamics of ncp with sars, and found that ncp has a higher transmissibility than sars. time-varying production number indicates that rigorous control measures taken by governments are effective across china, and persistent efforts are needed to be taken for reducing instantaneous reproduction number below one.",
            "contribution_ids": [
                "R44857",
                "R44861"
            ]
        },
        {
            "instance_id": "R44930xR44918",
            "comparison_id": "R44930",
            "paper_id": "R44918",
            "text": "Estimation of the Transmission Risk of the 2019-nCoV and Its Implication for Public Health Interventions since the emergence of the first cases in wuhan, china, the novel coronavirus (2019-ncov) infection has been quickly spreading out to other provinces and neighboring countries. estimation of the basic reproduction number by means of mathematical modeling can be helpful for determining the potential and severity of an outbreak and providing critical information for identifying the type of disease interventions and intensity. a deterministic compartmental model was devised based on the clinical progression of the disease, epidemiological status of the individuals, and intervention measures. the estimations based on likelihood and model analysis show that the control reproduction number may be as high as 6.47 (95% ci 5.71\u20137.23). sensitivity analyses show that interventions, such as intensive contact tracing followed by quarantine and isolation, can effectively reduce the control reproduction number and transmission risk, with the effect of travel restriction adopted by wuhan on 2019-ncov infection in beijing being almost equivalent to increasing quarantine by a 100 thousand baseline value. it is essential to assess how the expensive, resource-intensive measures implemented by the chinese authorities can contribute to the prevention and control of the 2019-ncov infection, and how long they should be maintained. under the most restrictive measures, the outbreak is expected to peak within two weeks (since 23 january 2020) with a significant low peak value. with travel restriction (no imported exposed individuals to beijing), the number of infected individuals in seven days will decrease by 91.14% in beijing, compared with the scenario of no travel restriction.",
            "contribution_ids": [
                "R44921"
            ]
        },
        {
            "instance_id": "R44978xR44693",
            "comparison_id": "R44978",
            "paper_id": "R44693",
            "text": "A randomised controlled trial of cognitive behaviour therapy vs treatment as usual in the treatment of mild to moderate late life depression this study provides an empirical evaluation of cognitive behaviour therapy (cbt) alone vs treatment as usual (tau) alone (generally pharmacotherapy) for late life depression in a uk primary care setting.",
            "contribution_ids": [
                "R44694"
            ]
        },
        {
            "instance_id": "R44978xR44700",
            "comparison_id": "R44978",
            "paper_id": "R44700",
            "text": "Telephone-based treatment for family practice patients with mild depression the need for treating milder forms of depression has recently been of increased interest. this was a randomized, controlled study to evaluate the effects of telephone-based problem-solving therapy for mild depression. comparison groups were a treatment-as-usual group and another group receiving stress-management training by telephone. from 1,742 family practice patients screened for depression, 54 with mild depression entered the study. treatment was provided by experienced family practice nurses, trained and supervised in the treatments. the hamilton rating scale for depression was administered before and after the intervention period, and the beck depression inventory and duke health profile were administered at the end of the intervention period. of the 36 subjects assigned to the problem-solving and stress-management groups, half dropped out early in the study. five from the treatment-as-usual group were lost to follow-up. in the remaining subjects, there was a significant decrease in depression scores. there were no significant differences in the amount of decrease between the groups on any scores. the small sample and high dropout rate limit the interpretation of the findings. however, since all subjects tended to improve, regardless of treatment received, mild levels of depression may generally remit even without focal intervention, and watchful waiting may be a reasonable alternative for management.",
            "contribution_ids": [
                "R44701"
            ]
        },
        {
            "instance_id": "R44978xR44709",
            "comparison_id": "R44978",
            "paper_id": "R44709",
            "text": "Acute and one-year outcome of a randomised controlled trial of brief cognitive therapy for major depressive disorder in primary care background the consensus statement on the treatment of depression (paykel &amp; priest, 1992) advocates the use of cognitive therapy techniques as an adjunct to medication. method this paper describes a randomised controlled trial of brief cognitive therapy (bct) plus \u2018treatment as usual\u2019 versus treatment as usual in the management of 48 patients with major depressive disorder presenting in primary care. results at the end of the acute phase, significantly more subjects ( p &lt; 0.05) met recovery criteria in the intervention group ( n =15) compared with the control group ( n =8). when initial neuroticism scores were controlled for, reductions in beck depression inventory and hamilton rating scale for depression scores favoured the bct group throughout the 12 months of follow-up. conclusions bct may be beneficial, but given the time constraints, therapists need to be more rather than less skilled in cognitive therapy. this, plus methodological limitations, leads us to advise caution before applying this approach more widely in primary care.",
            "contribution_ids": [
                "R44710"
            ]
        },
        {
            "instance_id": "R46295xR45100",
            "comparison_id": "R46295",
            "paper_id": "R45100",
            "text": "Charge carrier trapping and recombination dynamics in small semiconductor particles reference lpi-article-1985-033doi:10.1021/ja00312a043view record in web of science record created on 2006-02-21, modified on 2017-05-12",
            "contribution_ids": [
                "R45101"
            ]
        },
        {
            "instance_id": "R46295xR45112",
            "comparison_id": "R46295",
            "paper_id": "R45112",
            "text": "Photochemical Reduction of Oxygen Adsorbed to Nanocrystalline TiO2 Films:\u00e2\u0080\u0089 A Transient Absorption and Oxygen Scavenging Study of Different TiO2 Preparations transient absorption spectroscopy (tas) has been used to study the interfacial electron-transfer reaction between photogenerated electrons in nanocrystalline titanium dioxide (tio(2)) films and molecular oxygen. tio(2) films from three different starting materials (tio(2) anatase colloidal paste and commercial anatase/rutile powders degussa tio(2) p25 and vp tio(2) p90) have been investigated in the presence of ethanol as a hole scavenger. separate investigations on the photocatalytic oxygen consumption by the films have also been performed with an oxygen membrane polarographic detector. results show that a correlation exists between the electron dynamics of oxygen consumption observed by tas and the rate of oxygen consumption through the photocatalytic process. the highest activity and the fastest oxygen reduction dynamics were observed with films fabricated from anatase tio(2) colloidal paste. the use of tas as a tool for the prediction of the photocatalytic activities of the materials is discussed. tas studies indicate that the rate of reduction of molecular oxygen is limited by interfacial electron-transfer kinetics rather than by the electron trapping/detrapping dynamics within the tio(2) particles.",
            "contribution_ids": [
                "R45113"
            ]
        },
        {
            "instance_id": "R46295xR45122",
            "comparison_id": "R46295",
            "paper_id": "R45122",
            "text": "Dynamics of photogenerated charges in the phosphate modified TiO 2 and the enhanced activity for photoelectrochemical water splitting phosphate modified nanocrystalline tio2 (nc-tio2) films were prepared by a doctor blade method, followed by post-treatment with monometallic sodium orthophosphate solution. the dynamic processes of the photogenerated charges from the resulting nc-tio2 films were thoroughly investigated by means of transient absorption spectroscopy (tas). it is shown that photogenerated holes in the un-modified tio2 film exhibit the same dynamic decay process as its photogenerated electrons, in oxygen-free water of ph 7. however, photogenerated holes in the phosphate modified film display a slightly faster dynamic decay process than its photogenerated electrons, and photogenerated charges of the modified film have a much longer lifetime than those of the un-modified film. these differences are attributed to the surface-carried negative charges of nc-tio2 resulting from the phosphate groups (\u2013ti\u2013o\u2013p\u2013o\u2212). interestingly, the photoelectrochemical (pec) experiments show that modification with an appropriate amount of phosphate could improve the photocurrent density of the nc-tio2 film electrode by about 2 times, at a voltage of 0 v in the neutral electrolyte. based on the tas and pec measurements of un-modified and phosphate modified nc-tio2 films, with different conditions, it is suggested that the prolonged lifetime of photogenerated charges can be attributed to the negative electrostatic field formed in the surface layers. it is also responsible for the increase in activity for pec water splitting and for the reported photocatalytic degradation of pollutants. the suggested mechanism would be applicable to other oxide semiconductor photocatalysts and to modification with other inorganic anions.",
            "contribution_ids": [
                "R45123"
            ]
        },
        {
            "instance_id": "R46295xR45124",
            "comparison_id": "R46295",
            "paper_id": "R45124",
            "text": "Photocatalytic Oxidation Reactivity of Holes in the Sulfur- and Carbon-Doped TiO2 Powders Studied by Time-Resolved Diffuse Reflectance Spectroscopy the photocatalytic oxidation reactivities of the photogenerated holes (h+) during ultraviolet or visible laser flash photolysis of pure anatase and sulfur- and carbon-doped tio2 powders were investigated using time-resolved diffuse reflectance (tdr) spectroscopy. the one-electron oxidation processes of substrates such as methanol and 4-(methylthio)phenyl methanol (mtpm) by h+ at the tio2 surface were examined. the tdr spectra and time traces observed for charge carriers and the mtpm radical cation (mtpm\u2022+) revealed that the oxidation reactions of substrates by h+ generated during the 355-nm laser photolysis of tio2 powders increased in the order of pure tio2 > s-doped tio2 > c-doped tio2. on the other hand, no one-electron oxidation reactions of the substrates were observed during the 430-nm laser photolysis of the s- and c-doped tio2 powders, although the charge carriers were sufficiently generated upon excitation. the effects of the trapping and detrapping processes of h+ at the doping sites on the oxid...",
            "contribution_ids": [
                "R45125"
            ]
        },
        {
            "instance_id": "R46296xR46068",
            "comparison_id": "R46296",
            "paper_id": "R46068",
            "text": "N-Doped TiO2 Nanoparticle Based Visible Light Photocatalyst by Modified Peroxide Sol\u00e2\u0088\u0092Gel Method the peroxide gel route is employed to synthesize n-doped tio2 nanoparticles (np) at low temperature using titanium tetraisopropoxide, ethylmethylamine, and hydrogen peroxide as precursors. structural studies show anatase phase in the undoped titania nps as well as at 5 at. % n-doped titania nps, although with a degree of matrix disorder in the latter case. the annealing of n-doped titania nps at different temperatures shows that above 400 \u00b0c nitrogen escapes the o\u2212ti\u2212o matrix and at 500 \u00b0c the sample becomes crystalline. transmission electron microscopy reveals that the particle size is in the range of 20\u221230 nm for the undoped tio2 but only 5\u221210 nm for n-doped tio2. at higher nitrogen concentration (10 at. %) bubble-like agglomerates form. ftir and photoluminescence quenching also confirm the incorporation of nitrogen in anatase tio2. optical properties reveal an extended tailing of the absorption edge toward the visible region upon nitrogen doping. x-ray photoelectron spectroscopy is used to examine the ...",
            "contribution_ids": [
                "R46069"
            ]
        },
        {
            "instance_id": "R46296xR46080",
            "comparison_id": "R46296",
            "paper_id": "R46080",
            "text": "One-step solvothermal synthesis of a carbon@ TiO2 dyade structure effectively promoting visible-light photocatalysis the development of sunlight harvesting chemical systems to catalyze relevant reactions, i.e., water splitting, co 2 fi xation, and organic mineralization, is the key target in artifi cial photosynthesis but remains a diffi cult challenge. titanium dioxide (tio 2 ) has been widely used as a photocatalyst for solar energy conversion and environmental applications because of its low toxicity, abundance, high photostability, and high effi ciency. [ 1\u20134 ] however, the application of pure tio 2 is limited, because it requires ultraviolet (uv) light, which makes up only a small fraction ( < 4%) of the total solar spectrum reaching the surface of the earth. therefore, over the past few years, considerable efforts have been directed towards the improvement of the photocatalytic effi ciency of tio 2 in the visible (vis)-light region. [ 5\u20137 ] this has been mainly achieved by introducing various dopants into the tio 2 structure which can narrow the bandgap. the initial approach to dope tio 2 materials was achieved using transition metals ions such as v, cr, or fe. [ 6 , 8\u201310 ] however, such metal doped materials lack the necessary thermal stability, exhibit atom diffusion and a remarkably increased electron/hole recombination of defect sites, which results in a low photocatalytic effi ciency. [ 11 ] non-metal doping has since proved to be far more successful and has been extensively investigated. thus, numerous reports on tio 2 doped with b, f, n, c, s, or i have demonstrated a signifi cant improvement of the visible-light photocatalytic effi ciency. [ 4 , 12\u201316 ]",
            "contribution_ids": [
                "R46081"
            ]
        },
        {
            "instance_id": "R46296xR46084",
            "comparison_id": "R46296",
            "paper_id": "R46084",
            "text": "Electrical Properties of Nb\u00e2\u0080\u0090, Ga\u00e2\u0080\u0090, and Y\u00e2\u0080\u0090Substituted Nanocrystalline Anatase TiO2 Prepared by Hydrothermal Synthesis \"nanocrystalline anatase titanium dioxide powders were produced by a hydrothermal synthesis route in pure form and substituted with trivalent ga3+ and y3+ or pentavalent nb5+ with the intention of creating acceptor or donor states, respectively. the electrical conductivity of each powder was measured using the powder-solution-composite (psc) method. the conductivity increased with the addition of nb5+ from 3 similar to x similar to 10-3 similar to s/cm to 10 similar to x similar to 10-3 similar to s/cm in as-prepared powders, and from 0.3 similar to x similar to 10-3 similar to s/cm to 0.9 similar to x similar to 10-3 similar to s/cm in heat-treated powders (520 degrees c, 1 similar to h). in contrast, substitution with ga3+ and y3+ had no measureable effect on the material's conductivity. the lack of change with the addition of ga3+ and y3+, and relatively small increase upon nb5+ addition is attributed to ionic compensation owing to the highly oxidizing nature of hydrothermal synthesis.\"",
            "contribution_ids": [
                "R46086"
            ]
        },
        {
            "instance_id": "R46296xR46087",
            "comparison_id": "R46296",
            "paper_id": "R46087",
            "text": "Preparation, Photocatalytic Activity, and Mechanism of Nano-TiO2 Co-Doped with Nitrogen and Iron (III) nanoparticles of titanium dioxide co-doped with nitrogen and iron (iii) were first prepared using the homogeneous precipitation-hydrothermal method. the structure and properties of the co-doped were studied by xrd, xps, raman, fl, and uv-diffuse reflectance spectra. by analyzing the structures and photocatalytic activities of the undoped and nitrogen and/or fe3+-doped tio2 under ultraviolet and visible light irradiation, the probable mechanism of co-doped particles was investigated. it is presumed that the nitrogen and fe3+ ion doping induced the formation of new states closed to the valence band and conduction band, respectively. the co-operation of the nitrogen and fe3+ ion leads to the much narrowing of the band gap and greatly improves the photocatalytic activity in the visible light region. meanwhile, the co-doping can also promote the separation of the photogenerated electrons and holes to accelerate the transmission of photocurrent carrier. the photocatalyst co-doped with nitrogen and 0.5% fe3+ sho...",
            "contribution_ids": [
                "R46088"
            ]
        },
        {
            "instance_id": "R46296xR46105",
            "comparison_id": "R46296",
            "paper_id": "R46105",
            "text": "Improved photocatalytic activity of Sn 4+ doped TiO 2 nanoparticulate films prepared by plasma-enhanced chemical vapor deposition sn4+ ion doped tio2 \\n (tio2\u2013sn4+) nanoparticulate films with a doping ratio of about 7\u2236100 [(sn)\u2236(ti)] were prepared by the plasma-enhanced chemical vapor deposition (pcvd) method. the doping mode (lattice ti substituted by sn4+ ions) and the doping energy level of sn4+ were determined by x-ray diffraction (xrd), x-ray photoelectron spectroscopy (xps), surface photovoltage spectroscopy (sps) and electric field induced surface photovoltage spectroscopy (efisps). it is found that the introduction of a doping energy level of sn4+ ions is profitable to the separation of photogenerated carriers under both uv and visible light excitation. characterization of the films with xrd and sps indicates that after doping by sn, more surface defects are present on the surface. consequently, the photocatalytic activity for photodegradation of phenol in the presence of the tio2\u2013sn4+ film is higher than that of the pure tio2 film under both uv and visible light irradiation.",
            "contribution_ids": [
                "R46106"
            ]
        },
        {
            "instance_id": "R46299xR46221",
            "comparison_id": "R46299",
            "paper_id": "R46221",
            "text": "CO2 reduction over NaNbO3 and NaTaO3 perovskite photocatalysts both nanbo 3 and natao 3 exhibit interesting intrinsic photocatalytic activities for co 2 reduction in terms of conversion and selectivity.",
            "contribution_ids": [
                "R46222"
            ]
        },
        {
            "instance_id": "R46299xR46235",
            "comparison_id": "R46299",
            "paper_id": "R46235",
            "text": "Photocatalytic CO2 Reduction by Re(I) Polypyridyl Complexes Immobilized on Niobates Nanoscrolls \"immobilization of re(i) co2 reduction photocatalysts on metal oxide surfaces is an interesting approach to improve their stability and recyclability. in this work, we describe the photocatalytic activity of two re(i) complexes (fac-[re(nn)(co)3(cl)], nn = 4,4'-dicarboxylic acid-2,2'-bipyridine, 1, or 5,6-dione-1,10-phenantroline, 2) on the surface of hexaniobate nanoscrolls. after adsorption, the turnover number for co production (tonco) in dmf/teoa of 1 was increased from 9 to 58, which is 20% higher than that observed on tio2, being among the highest reported values for a re(i)-based photocatalyst under visible light irradiation without any sensitizer. the complex 2 is inactive in solution under visible-light irradiation, but it has a tonco of 35 when immobilized on hexaniobate nanoscrolls. transient absorption spectroscopy studies reveal that the slow back-electron transfer and the higher reducing power of the hexaniobate conduction-band electrons play a major role for the photocatalytic process. the r...\"",
            "contribution_ids": [
                "R46236"
            ]
        },
        {
            "instance_id": "R48103xR46670",
            "comparison_id": "R48103",
            "paper_id": "R46670",
            "text": "A Two-Phase Bio-NER System Based on Integrated Classifiers and Multiagent Strategy biomedical named entity recognition (bio-ner) is a fundamental step in biomedical text mining. this paper presents a two-phase bio-ner model targeting at jnlpba task. our two-phase method divides the task into two subtasks: named entity detection (ned) and named entity classification (nec). the ned subtask is accomplished based on the two-layer stacking method in the first phase, where named entities (nes) are distinguished from nonnamed-entities (nnes) in biomedical literatures without identifying their types. then six classifiers are constructed by four toolkits (crf++, yamcha, maximum entropy, mallet) with different training methods and integrated based on the two-layer stacking method. in the second phase for the nec subtask, the multiagent strategy is introduced to determine the correct entity type for entities identified in the first phase. the experiment results show that the presented approach can achieve an f-score of 76.06 percent, which outperforms most of the state-of-the-art systems.",
            "contribution_ids": [
                "R46671"
            ]
        },
        {
            "instance_id": "R48392xR48233",
            "comparison_id": "R48392",
            "paper_id": "R48233",
            "text": "A scaling approach to project regional sea level rise and its uncertainties abstract. climate change causes global mean sea level to rise due to thermal expansion of seawater and loss of land ice from mountain glaciers, ice caps and ice sheets. locally, sea level can strongly deviate from the global mean rise due to changes in wind and ocean currents. in addition, gravitational adjustments redistribute seawater away from shrinking ice masses. however, the land ice contribution to sea level rise (slr) remains very challenging to model, and comprehensive regional sea level projections, which include appropriate gravitational adjustments, are still a nascent field (katsman et al., 2011; slangen et al., 2011). here, we present an alternative approach to derive regional sea level changes for a range of emission and land ice melt scenarios, combining probabilistic forecasts of a simple climate model (magicc6) with the new cmip5 general circulation models. the contribution from ice sheets varies considerably depending on the assumptions for the ice sheet projections, and thus represents sizeable uncertainties for future sea level rise. however, several consistent and robust patterns emerge from our analysis: at low latitudes, especially in the indian ocean and western pacific, sea level will likely rise more than the global mean (mostly by 10\u201320%). around the northeastern atlantic and the northeastern pacific coasts, sea level will rise less than the global average or, in some rare cases, even fall. in the northwestern atlantic, along the american coast, a strong dynamic sea level rise is counteracted by gravitational depression due to greenland ice melt; whether sea level will be above- or below-average will depend on the relative contribution of these two factors. our regional sea level projections and the diagnosed uncertainties provide an improved basis for coastal impact analysis and infrastructure planning for adaptation to climate change.\\n",
            "contribution_ids": [
                "R48236",
                "R48239",
                "R48242",
                "R48244"
            ]
        },
        {
            "instance_id": "R48392xR48265",
            "comparison_id": "R48392",
            "paper_id": "R48265",
            "text": "Probabilistic 21st and 22nd century sea-level projections at a global network of tide-gauge sites. sea\u2010level rise due to both climate change and non\u2010climatic factors threatens coastal settlements, infrastructure, and ecosystems. projections of mean global sea\u2010level (gsl) rise provide insufficient information to plan adaptive responses; local decisions require local projections that accommodate different risk tolerances and time frames and that can be linked to storm surge projections. here we present a global set of local sea\u2010level (lsl) projections to inform decisions on timescales ranging from the coming decades through the 22nd century. we provide complete probability distributions, informed by a combination of expert community assessment, expert elicitation, and process modeling. between the years 2000 and 2100, we project a very likely (90% probability) gsl rise of 0.5\u20131.2\\u2009m under representative concentration pathway (rcp) 8.5, 0.4\u20130.9\\u2009m under rcp 4.5, and 0.3\u20130.8\\u2009m under rcp 2.6. site\u2010to\u2010site differences in lsl projections are due to varying non\u2010climatic background uplift or subsidence, oceanographic effects, and spatially variable responses of the geoid and the lithosphere to shrinking land ice. the antarctic ice sheet (ais) constitutes a growing share of variance in gsl and lsl projections. in the global average and at many locations, it is the dominant source of variance in late 21st century projections, though at some sites oceanographic processes contribute the largest share throughout the century. lsl rise dramatically reshapes flood risk, greatly increasing the expected number of \u201c1\u2010in\u201010\u201d and \u201c1\u2010in\u2010100\u201d year events.",
            "contribution_ids": [
                "R48267",
                "R48269",
                "R48271",
                "R48273",
                "R48275",
                "R48277"
            ]
        },
        {
            "instance_id": "R52143xR52079",
            "comparison_id": "R52143",
            "paper_id": "R52079",
            "text": "Patterns of trait convergence and divergence among native and exotic species in herbaceous plant communities are not modified by nitrogen enrichment 1.\\u2002community assembly theories predict that the success of invading species into a new community should be predictable by functional traits. environmental filters could constrain the number of successful ecological strategies in a habitat, resulting in similar suites of traits between native and successfully invading species (convergence). conversely, concepts of limiting similarity and competitive exclusion predict native species will prevent invasion by functionally similar exotic species, resulting in trait divergence between the two species pools. nutrient availability may further alter the strength of convergent or divergent forces in community assembly, by relaxing environmental constraints and/or influencing competitive interactions.",
            "contribution_ids": [
                "R52080"
            ]
        },
        {
            "instance_id": "R52143xR52090",
            "comparison_id": "R52143",
            "paper_id": "R52090",
            "text": "Variation in resource acquisition and utilization traits between native and invasive perennial forbs understanding the functional traits that allow invasives to outperform natives is a necessary first step in improving our ability to predict and manage the spread of invaders. in nutrient-limited systems, plant competitive ability is expected to be closely tied to the ability of a plant to exploit nutrient-rich microsites and use these captured nutrients efficiently. the broad objective of this work was to compare the ability of native and invasive perennial forbs to acquire and use nutrients from nutrient-rich microsites. we evaluated morphological and physiological responses among four native and four invasive species exposed to heterogeneous (patch) or homogeneous (control) nutrient distribution. invasives, on average, allocated more biomass to roots and allocated proportionately more root length to nutrient-rich microsites than did natives. invasives also had higher leaf n, photosynthetic rates, and photosynthetic nitrogen use efficiency than natives, regardless of treatment. while these results suggest multiple traits may contribute to the success of invasive forbs in low-nutrient environments, we also observed large variation in these traits among native forbs. these observations support the idea that functional trait variation in the plant community may be a better predictor of invasion resistance than the functional group composition of the plant community.",
            "contribution_ids": [
                "R52091"
            ]
        },
        {
            "instance_id": "R52143xR52102",
            "comparison_id": "R52143",
            "paper_id": "R52102",
            "text": "Functional differences between alien and native species: do biotic interactions determine the functional structure of highly invaded grasslands? summary 1. although observed functional differences between alien and native plant species support the idea that invasions are favoured by niche differentiation (nd), when considering invasions along large ecological gradients, habitat filtering (hf) has been proposed to constrain alien species such that they exhibit similar trait values to natives. 2. to reconcile these contrasting observations, we used a multiscale approach using plant functional traits to evaluate how biotic interactions with native species and grazing might determine the functional structure of highly invaded grasslands along an elevation gradient in new zealand. 3. at a regional scale, functional differences between alien and native plant species translated into nonrandom community assembly and high nd. alien and native species showed contrasting responses to elevation and the degree of nd between them decreased as elevation increased, suggesting a role for hf. at the plant-neighbourhood scale, species with contrasting traits were generally spatially segregated, highlighting the impact of biotic interactions in structuring local plant communities. a confirmatory multilevel path analysis showed that the effect of elevation and grazing was moderated by the presence of native species, which in turn influenced the local abundance of alien species. 4. our study showed that functional differences between aliens and natives are fundamental to understand the interplay between multiple mechanisms driving alien species success and their coexistence with natives. in particular, the success of alien species is driven by the presence of native species which can have a negative (biotic resistance) or a positive (facilitation) effect depending on the functional identity of alien species.",
            "contribution_ids": [
                "R52103"
            ]
        },
        {
            "instance_id": "R52143xR52109",
            "comparison_id": "R52143",
            "paper_id": "R52109",
            "text": "Establishment and Management of Native Functional Groups in Restoration the limiting similarity hypothesis predicts that communities should be more resistant to invasion by non\u2010natives when they include natives with a diversity of traits from more than one functional group. in restoration, planting natives with a diversity of traits may result in competition between natives of different functional groups and may influence the efficacy of different seeding and maintenance methods, potentially impacting native establishment. we compare initial establishment and first\u2010year performance of natives and the effectiveness of maintenance techniques in uniform versus mixed functional group plantings. we seeded ruderal herbaceous natives, longer\u2010lived shrubby natives, or a mixture of the two functional groups using drill\u2010 and hand\u2010seeding methods. non\u2010natives were left undisturbed, removed by hand\u2010weeding and mowing, or treated with herbicide to test maintenance methods in a factorial design. native functional groups had highest establishment, growth, and reproduction when planted alone, and hand\u2010seeding resulted in more natives as well as more of the most common invasive, brassica nigra. wick herbicide removed more non\u2010natives and resulted in greater reproduction of natives, while hand\u2010weeding and mowing increased native density. our results point to the importance of considering competition among native functional groups as well as between natives and invasives in restoration. interactions among functional groups, seeding methods, and maintenance techniques indicate restoration will be easier to implement when natives with different traits are planted separately.",
            "contribution_ids": [
                "R52110",
                "R52111"
            ]
        },
        {
            "instance_id": "R52143xR52116",
            "comparison_id": "R52143",
            "paper_id": "R52116",
            "text": "Are competitive effects of native species on an invader mediated by water availability? question \\n \\nclimate change processes could influence the dynamics of biotic interactions such as plant competition, especially in response to disturbance phenomena such as invasional processes. are competitive effects of native species on an invader mediated by water availability? \\n \\n \\n \\nlocation \\n \\nglasshouse facility, new south wales, australia. \\n \\n \\n \\nmethods \\n \\nwe constructed competitive hierarchies for a representative suite of species from coastal dune communities that have been invaded by the asteraceae shrub, bitou (chrysanthemoides monilifera subsp. rotundata). we used a comparative phytometer approach, where the invader species was grown with or without a suite of native species in glasshouse trials. this was used to construct competition hierarchies under two water stress conditions: non-droughted and droughted. the treatments were designed to simulate current and potential future water availability respectively. \\n \\n \\n \\nresults \\n \\nwe found that the invader experienced fewer competitive effects from some native species under water stress, particularly with regard to below-ground biomass effects. native species were often poor competitors with the invader, despite their adaptation to periodic water stress in native coastal environments. of the native species with significant competitive effects on the invader, functionally similar shrub species were the most effective competitors, as expressed in below-ground biomass. the relative position of species in the hierarchy was consistent across water treatments based on below-ground bitou biomass, but was contingent on water treatment when based on above-ground bitou biomass. \\n \\n \\n \\nconclusions \\n \\nthe competitive effects of native species on an invader are affected by water stress. while the direction of response to water stress is species-specific, many species have small competitive effects on the invader under droughted conditions. this could allow an increase in invader dominance with climate change.",
            "contribution_ids": [
                "R52117"
            ]
        },
        {
            "instance_id": "R52143xR52131",
            "comparison_id": "R52143",
            "paper_id": "R52131",
            "text": "Experimental invasion by legumes reveals non-random assembly rules in grassland communities 1 although experimental studies usually reveal that resistance to invasion increases with species diversity, observational studies sometimes show the opposite trend. the higher resistance of diverse plots to invasion may be partly due to the increased probability of a plot containing a species with similar resource requirements to the invader. 2 we conducted a study of the invasibility of monocultures belonging to three different functional groups by seven sown species of legume. by only using experimentally established monocultures, rather than manipulating the abundance of particular functional groups, we removed both species diversity and differences in underlying abiotic conditions as potentially confounding variables. 3 we found that legume monocultures were more resistant than monocultures of grasses or non\u2010leguminous forbs to invasion by sown legumes but not to invasion by other unsown species. the functional group effect remained after controlling for differences in total biomass and the average height of the above\u2010ground biomass. 4 the relative success of legume species and types also varied with monoculture characteristics. the proportional biomass of climbing legumes increased strongly with biomass height in non\u2010leguminous forb monocultures, while it declined with biomass height in grass monocultures. trifolium pratense was the most successful invader in grass monocultures, while vicia cracca was the most successful in non\u2010leguminous forb monocultures. 5 our results suggest that non\u2010random assembly rules operate in grassland communities both between and within functional groups. legume invaders found it much more difficult to invade legume plots, while grass and non\u2010leguminous forb plots favoured non\u2010climbing and climbing legumes, respectively. if plots mimic monospecific patches, the effect of these assembly rules in diverse communities might depend upon the patch structure of diverse communities. this dependency on patch structure may contribute to differences in results of research from experimental vs. natural communities.",
            "contribution_ids": [
                "R52132"
            ]
        },
        {
            "instance_id": "R52143xR52140",
            "comparison_id": "R52143",
            "paper_id": "R52140",
            "text": "Functionally Similar Species Confer Greater Resistance to Invasion: Implications for Grassland Restoration plant community functional composition can be manipulated in restored ecosystems to reduce the establishment potential of invading species. this study was designed to compare invasion resistance among communities with species functionally similar or dissimilar to yellow starthistle (centaurea solstitialis), a late\u2010season annual. a field experiment was conducted in the central valley of california with six experimental plant communities that included (1) six early\u2010season native annual forbs (af); (2) five late\u2010season native perennials and one summer annual forb (np); (3) a combination of three early\u2010season native annual forbs and three late\u2010season native perennials (fp); (4) six early\u2010season non\u2010native annual grasses (ag); (5) monoculture of the late\u2010season native perennial grass elymus glaucus (eg); and (6) monoculture of the late\u2010season native perennial grindelia camporum (gc). following establishment, c. solstitialis seed was added to half of the plots, and a monoculture of c. solstitialis (cs) was established as a control. over a 5\u2010year period, the af and ag communities were ineffective at preventing c. solstitialis invasion. centaurea solstitialis cover remained less than 10% in the fp and np communities, except in year 1. by the fourth year, e. glaucus cover was greater than 50% in np and fp communities and had spread to all other communities (e.g., 27% cover in cs in year 5). communities containing e. glaucus, which is functionally similar to c. solstitialis, better resisted invasion than communities lacking a functional analog. in contrast, g. camporum, which is also functionally similar to c. solstitialis, failed to survive. consequently, species selection for restored communities must consider not only functional similarity to the invader but also establishment success, competitiveness, and survivorship.",
            "contribution_ids": [
                "R52141"
            ]
        },
        {
            "instance_id": "R53407xR53258",
            "comparison_id": "R53407",
            "paper_id": "R53258",
            "text": "Patterns of phylogenetic diversity are linked to invasion impacts- not invasion resistance- in a native grassland question: there are often more invasive species in communities that are less phylogenetically diverse or distantly related to the invaders. this is thought to indicate reduced biotic resistance, but recent theory predicts that phylogenetic relationships have more influence on competitive outcomes when interactions are more pair-wise than diffuse. therefore, phylogenetic relationships should change when the invader becomes dominant and interactions are more pairwise, rather than alter biotic resistance, which is the outcome of diffuse interactions with the resident community; however both processes can produce similar phylogenetic structures within communities. we ask whether phylogenetic structure is more associated with biotic resistance or invasion impacts following bromus inermis (brome) invasion and identify the mechanisms behind changes to phylogenetic structure. location: native grassland in alberta, canada. methods: we tested whether phylogenetic structure affected biotic resistance by transplanting brome seedlings into intact vegetation and quantified invasion impacts on community structure by surveying across multiple invasion edges. additionally, we tested whether relatedness, rarity, average patch size, evolutionary distinctiveness or environmental tolerances determined species\u2019 response to brome invasion. results: neither phylogenetic diversity, nor relatedness to brome, influenced the strength of biotic resistance; resource availability was the strongest determinant of resistance. however, communities did become less diverse and phylogenetically over-dispersed following brome invasion, but not because of the loss of related species. brome invasion was associated with declines in common species from common lineages and increases in shade-tolerant species and rare species from species-poor lineages. conclusions: ourresults suggest that invasion is morelikelytoaffectthe phylogenetic structure of the community than the phylogenetic structure of the community will affect invasion. however, they also suggest that the degree of relatedness between the invader and the resident community is unlikely todrive these effects on phylogenetic community structure. consistent with previous studies, invasion effects were stronger for common species as they have reduced shade tolerance and cannot persist in a subordinate role. this suggests that invasion effects on phylogenetic community structure will depend on which species exhibit traits that enable persistence with the invader and how these traits are distributed across the phylogeny.",
            "contribution_ids": [
                "R53259"
            ]
        },
        {
            "instance_id": "R53407xR53261",
            "comparison_id": "R53407",
            "paper_id": "R53261",
            "text": "A phylogenetic approach towards understanding the drivers of plant invasiveness on Robben Island- South Africa \"invasive plant species are a considerable threat to ecosystems globally and on islands in particular where species diversity can be relatively low. in this study, we examined the phylogenetic basis of invasion success on robben island in south africa. the flora of the island was sampled extensively and the phylogeny of the local community was reconstructed using the two core dna barcode regions, rbcla and matk. by analysing the phylogenetic patterns of native and invasive floras at two different scales, we found that invasive alien species are more distantly related to native species, a confirmation of darwin's naturalization hypothesis. however, this pattern also holds even for randomly generated communities, therefore discounting the explanatory power of darwin's naturalization hypothesis as the unique driver of invasion success on the island. these findings suggest that the drivers of invasion success on the island may be linked to species traits rather than their evolutionary history alone, or to the combination thereof. this result also has implications for the invasion management programmes currently being implemented to rehabilitate the native diversity on robben island.\\xa0\u00a9 2013 the linnean society of london, botanical journal of the linnean society, 2013, 172, 142\u2013152.\"",
            "contribution_ids": [
                "R53262",
                "R53264"
            ]
        },
        {
            "instance_id": "R53407xR53322",
            "comparison_id": "R53407",
            "paper_id": "R53322",
            "text": "Is invasiveness a legacy of evolution? Phylogenetic patterns in the alien flora of Mediterranean islands 1 the mediterranean region has been invaded by a wide range of introduced plant species which differ greatly in their ecology, morphology and human utilization. in order to identify a suite of traits which characterize invasiveness, recent studies have advocated the use of evolutionary relationships to unravel highly confounded influences. 2 this study attempts to identify an evolutionary component to invasiveness and other complex invasion\u2010related traits in the mediterranean alien flora using an autocorrelation technique, the \u2018phylogenetic association test\u2019. i compared a traditional hierarchical taxonomy with the recent phylogeny of the angiosperm phylogeny group. 3 invasiveness did not have a significant phylogenetic component. any weak clustering was generally at the genus level. 4 several associated \u2018meta\u2010traits\u2019 (high introduction frequency, adaptation to several habitat types and favourability for different modes of introduction), exhibited stronger phylogenetic components. although each of these conveys some of the attributes of invasiveness, their clustering patterns differed considerably, suggesting that they arise from independent evolutionary pressures. furthermore, within each meta\u2010trait, different clusters may have been selected for different reasons. 5 other reasons for the lack of a detectable evolutionary component to invasiveness are discussed. firstly, the results of our test simulations suggested that incorrect phylogeny could result in a moderate degree of error. secondly, over evolutionary time, complex or stochastic events such as ecosystem change could radically alter the adaptive advantages of particular traits. 6 synthesis. since invasiveness has little phylogenetic component, i argue that it is less likely to be predictable from as yet unidentified traits in any simple way. although trait syndromes could develop without leaving a phylogenetic pattern, its absence probably indicates that the dominant selective forces are responses to short\u2010term ecological shifts, and a greater mechanistic understanding of these is needed.",
            "contribution_ids": [
                "R53323"
            ]
        },
        {
            "instance_id": "R53407xR53325",
            "comparison_id": "R53407",
            "paper_id": "R53325",
            "text": "How strongly do interactions with closely-related native species influence plant invasions? Darwin's naturalization hypothesis assessed on Mediterranean islands aim\\u2002 recent works have found the presence of native congeners to have a small effect on the naturalization rates of introduced plants, some suggesting a negative interaction (as proposed by charles darwin in the origin of species), and others a positive association. we assessed this question for a new biogeographic region, and discuss some of the problems associated with data base analyses of this type.",
            "contribution_ids": [
                "R53326"
            ]
        },
        {
            "instance_id": "R53407xR53340",
            "comparison_id": "R53407",
            "paper_id": "R53340",
            "text": "Patterns of bird invasion are consistent with environmental filtering predicting invasion potential has global significance for managing ecosystems as well as important theoretical implications for understanding community assembly. phylogenetic relationships of introduced species to the extant community may be predictive of establishment success because of the opposing forces of competition/shared enemies (which should limit invasions by close relatives) versus environmental filtering (which should allow invasions by close relatives). we examine here the association between establishment success of introduced birds and their phylogenetic relatedness to the extant avifauna within three highly invaded regions (florida, new zealand, and hawaii). published information on both successful and failed introductions, as well as native species, was compiled for all three regions. we created a phylogeny for each avifauna including all native and introduced bird species. from the estimated branch lengths on these phylogenies, we calculated multiple measurements of relatedness between each introduced species and the extant avifauna. we used generalized linear models to test for an association between relatedness and establishment success. we found that close relatedness to the extant avifauna was significantly associated with increased establishment success for exotic birds both at the regional (florida, hawaii, new zealand) and sub-regional (islands within hawaii) levels. our results suggest that habitat filtering may be more important than interspecific competition in avian communities assembled under high rates of anthropogenic species introductions. this work also supports the utility of community phylogenetic methods in the study of vertebrate invasions.",
            "contribution_ids": [
                "R53341",
                "R53343"
            ]
        },
        {
            "instance_id": "R53407xR53366",
            "comparison_id": "R53407",
            "paper_id": "R53366",
            "text": "Distinctiveness magnifies the impact of biological invaders in aquatic ecosystems there exist few empirical rules for the effects of introduced species, reflecting the context-dependent nature of biological invasions. a promising approach toward developing generalizations is to explore hypotheses that incorporate characteristics of both the invader and the recipient system. we present the first general test of the hypothesis that an invader\u2019s impact is determined by the system\u2019s evolutionary experience with similar species. through a meta-analysis, we compared the taxonomic distinctiveness of high- and low-impact invaders in several aquatic systems. we find that high-impact invaders (i.e. those that displace native species) are more likely to belong to genera not already present in the system.",
            "contribution_ids": [
                "R53367"
            ]
        },
        {
            "instance_id": "R53407xR53382",
            "comparison_id": "R53407",
            "paper_id": "R53382",
            "text": "Exotic taxa less related to native species are more invasive some species introduced into new geographical areas from their native ranges wreak ecological and economic havoc in their new environment. although many studies have searched for either species or habitat characteristics that predict invasiveness of exotic species, the match between characteristics of the invader and those of members of the existing native community may be essential to understanding invasiveness. here, we find that one metric, the phylogenetic relatedness of an invader to the native community, provides a predictive tool for invasiveness. using a phylogenetic supertree of all grass species in california, we show that highly invasive grass species are, on average, significantly less related to native grasses than are introduced but noninvasive grasses. the match between the invader and the existing native community may explain why exotic pest species are not uniformly noxious in all novel habitats. relatedness of invaders to the native biota may be one useful criterion for prioritizing management efforts of exotic species.",
            "contribution_ids": [
                "R53383",
                "R53385"
            ]
        },
        {
            "instance_id": "R53407xR53393",
            "comparison_id": "R53407",
            "paper_id": "R53393",
            "text": "Establishment success of introduced amphibians increases in the presence of congeneric species darwin\u2019s naturalization hypothesis predicts that the success of alien invaders will decrease with increasing taxonomic similarity to the native community. alternatively, shared traits between aliens and the native assemblage may preadapt aliens to their novel surroundings, thereby facilitating establishment (the preadaptation hypothesis). here we examine successful and failed introductions of amphibian species across the globe and find that the probability of successful establishment is higher when congeneric species are present at introduction locations and increases with increasing congener species richness. after accounting for positive effects of congeners, residence time, and propagule pressure, we also find that invader establishment success is higher on islands than on mainland areas and is higher in areas with abiotic conditions similar to the native range. these findings represent the first example in which the preadaptation hypothesis is supported in organisms other than plants and suggest that preadaptation has played a critical role in enabling introduced species to succeed in novel environments.",
            "contribution_ids": [
                "R53394"
            ]
        },
        {
            "instance_id": "R54244xR54028",
            "comparison_id": "R54244",
            "paper_id": "R54028",
            "text": "Jack-of-all-trades: phenotypic plasticity facilitates the invasion of an alien slug species \\n invasive alien species might benefit from phenotypic plasticity by being able to (i) maintain fitness in stressful environments (\u2018robust\u2019), (ii) increase fitness in favourable environments (\u2018opportunistic\u2019), or (iii) combine both abilities (\u2018robust and opportunistic\u2019). here, we applied this framework, for the first time, to an animal, the invasive slug,\\n arion lusitanicus \\n , and tested (i) whether it has a more adaptive phenotypic plasticity compared with a congeneric native slug,\\n arion fuscus \\n , and (ii) whether it is robust, opportunistic or both. during one year, we exposed specimens of both species to a range of temperatures along an altitudinal gradient (700\u20132400 m a.s.l.) and to high and low food levels, and we compared the responsiveness of two fitness traits: survival and egg production\\n . \\n during summer, the invasive species had a more adaptive phenotypic plasticity, and at high temperatures and low food levels, it survived better and produced more eggs than\\n a. fuscus \\n , representing the robust phenotype. during winter,\\n a. lusitanicus \\n displayed a less adaptive phenotype than\\n a. fuscus \\n . we show that the framework developed for plants is also very useful for a better mechanistic understanding of animal invasions. warmer summers and milder winters might lead to an expansion of this invasive species to higher altitudes and enhance its spread in the lowlands, supporting the concern that global climate change will increase biological invasions.\\n",
            "contribution_ids": [
                "R54029"
            ]
        },
        {
            "instance_id": "R54244xR54034",
            "comparison_id": "R54244",
            "paper_id": "R54034",
            "text": "Norway maple displays greater seasonal growth and phenotypic plasticity to light than native sugar maple norway maple (acer platanoides l), which is among the most invasive tree species in forests of eastern north america, is associated with reduced regeneration of the related native species, sugar maple (acer saccharum marsh) and other native flora. to identify traits conferring an advantage to norway maple, we grew both species through an entire growing season under simulated light regimes mimicking a closed forest understorey vs. a canopy disturbance (gap). dynamic shade-houses providing a succession of high-intensity direct-light events between longer periods of low, diffuse light were used to simulate the light regimes. we assessed seedling height growth three times in the season, as well as stem diameter, maximum photosynthetic capacity, biomass allocation above- and below-ground, seasonal phenology and phenotypic plasticity. given the north european provenance of norway maple, we also investigated the possibility that its growth in north america might be increased by delayed fall senescence. we found that norway maple had significantly greater photosynthetic capacity in both light regimes and grew larger in stem diameter than sugar maple. the differences in below- and above-ground biomass, stem diameter, height and maximum photosynthesis were especially important in the simulated gap where norway maple continued extension growth during the late fall. in the gap regime sugar maple had a significantly higher root : shoot ratio that could confer an advantage in the deepest shade of closed understorey and under water stress or browsing pressure. norway maple is especially invasive following canopy disturbance where the opposite (low root : shoot ratio) could confer a competitive advantage. considering the effects of global change in extending the potential growing season, we anticipate that the invasiveness of norway maple will increase in the future.",
            "contribution_ids": [
                "R54035"
            ]
        },
        {
            "instance_id": "R54244xR54048",
            "comparison_id": "R54244",
            "paper_id": "R54048",
            "text": "The relative importance for plant invasiveness of trait means, and their plasticity and integration in a multivariate framework functional traits, their plasticity and their integration in a phenotype have profound impacts on plant performance. we developed structural equation models (sems) to evaluate their relative contribution to promote invasiveness in plants along resource gradients. we compared 20 invasive-native phylogenetically and ecologically related pairs. sems included one morphological (root-to-shoot ratio (r/s)) and one physiological (photosynthesis nitrogen-use efficiency (pnue)) trait, their plasticities in response to nutrient and light variation, and phenotypic integration among 31 traits. additionally, these components were related to two fitness estimators, biomass and survival. the relative contributions of traits, plasticity and integration were similar in invasive and native species. trait means were more important than plasticity and integration for fitness. invasive species showed higher fitness than natives because: they had lower r/s and higher pnue values across gradients; their higher pnue plasticity positively influenced biomass and thus survival; and they offset more the cases where plasticity and integration had a negative direct effect on fitness. our results suggest that invasiveness is promoted by higher values in the fitness hierarchy--trait means are more important than trait plasticity, and plasticity is similar to integration--rather than by a specific combination of the three components of the functional strategy.",
            "contribution_ids": [
                "R54049"
            ]
        },
        {
            "instance_id": "R54244xR54052",
            "comparison_id": "R54244",
            "paper_id": "R54052",
            "text": "Light Response of Native and Introduced Miscanthus sinensis Seedlings \"the asian grass miscanthus sinensis (poaceae) is being considered for use as a bioenergy crop in the u.s. corn belt. originally introduced to the united states for ornamental plantings, it escaped, forming invasive populations. the concern is that naturalized m. sinensis populations have evolved shade tolerance. we tested the hypothesis that seedlings from within the invasive u.s. range of m. sinensis would display traits associated with shade tolerance, namely increased area for light capture and phenotypic plasticity, compared with seedlings from the native japanese populations. in a common garden experiment, seedlings of 80 half-sib maternal lines were grown from the native range (japan) and 60 half-sib maternal lines from the invasive range (u.s.) under four light levels. seedling leaf area, leaf size, growth, and biomass allocation were measured on the resulting seedlings after 12 wk. seedlings from both regions responded strongly to the light gradient. high light conditions resulted in seedlings with greater leaf area, larger leaves, and a shift to greater belowground biomass investment, compared with shaded seedlings. japanese seedlings produced more biomass and total leaf area than u.s. seedlings across all light levels. generally, u.s. and japanese seedlings allocated a similar amount of biomass to foliage and equal leaf area per leaf mass. subtle differences in light response by region were observed for total leaf area, mass, growth, and leaf size. u.s. seedlings had slightly higher plasticity for total mass and leaf area but lower plasticity for measures of biomass allocation and leaf traits compared with japanese seedlings. our results do not provide general support for the hypothesis of increased m. sinensis shade tolerance within its introduced u.s. range compared with native japanese populations. nomenclature: eulaliagrass; miscanthus sinensis anderss. management implications: eulaliagrass (miscanthus sinensis), an asian species under consideration for biomass production in the midwest, has escaped ornamental plantings in the united states to form naturalized populations. evidence suggests that u.s. populations are able to tolerate relatively shady conditions, but it is unclear whether u.s. populations have greater shade tolerance than the relatively shade-intolerant populations within the species' native range in asia. increased shade tolerance could result in a broader range of invaded light environments within the introduced range of m. sinensis. however, results from our common garden experiment do not support the hypothesis of increased shade tolerance in introduced u.s. populations compared with seedlings from native asian populations. our results do demonstrate that for both u.s. and japanese populations under low light conditions, m. sinensis seeds germinate and seedlings gain mass and leaf area; therefore, land managers should carefully monitor or eradicate m. sinensis within these habitats.\"",
            "contribution_ids": [
                "R54053"
            ]
        },
        {
            "instance_id": "R54244xR54064",
            "comparison_id": "R54244",
            "paper_id": "R54064",
            "text": "Plastic Traits of an Exotic Grass Contribute to Its Abundance but Are Not Always Favourable \"in herbaceous ecosystems worldwide, biodiversity has been negatively impacted by changed grazing regimes and nutrient enrichment. altered disturbance regimes are thought to favour invasive species that have a high phenotypic plasticity, although most studies measure plasticity under controlled conditions in the greenhouse and then assume plasticity is an advantage in the field. here, we compare trait plasticity between three co-occurring, c4 perennial grass species, an invader eragrostis curvula, and natives eragrostis sororia and aristida personata to grazing and fertilizer in a three-year field trial. we measured abundances and several leaf traits known to correlate with strategies used by plants to fix carbon and acquire resources, i.e. specific leaf area (sla), leaf dry matter content (ldmc), leaf nutrient concentrations (n, c\u2236n, p), assimilation rates (amax) and photosynthetic nitrogen use efficiency (pnue). in the control treatment (grazed only), trait values for sla, leaf c\u2236n ratios, amax and pnue differed significantly between the three grass species. when trait values were compared across treatments, e. curvula showed higher trait plasticity than the native grasses, and this correlated with an increase in abundance across all but the grazed/fertilized treatment. the native grasses showed little trait plasticity in response to the treatments. aristida personata decreased significantly in the treatments where e. curvula increased, and e. sororia abundance increased possibly due to increased rainfall and not in response to treatments or invader abundance. overall, we found that plasticity did not favour an increase in abundance of e. curvula under the grazed/fertilized treatment likely because leaf nutrient contents increased and subsequently its' palatability to consumers. e. curvula also displayed a higher resource use efficiency than the native grasses. these findings suggest resource conditions and disturbance regimes can be manipulated to disadvantage the success of even plastic exotic species.\"",
            "contribution_ids": [
                "R54065"
            ]
        },
        {
            "instance_id": "R54244xR54072",
            "comparison_id": "R54244",
            "paper_id": "R54072",
            "text": "Phenotypic Plasticity Influences the Size, Shape and Dynamics of the Geographic Distribution of an Invasive Plant phenotypic plasticity has long been suspected to allow invasive species to expand their geographic range across large-scale environmental gradients. we tested this possibility in australia using a continental scale survey of the invasive tree parkinsonia aculeata (fabaceae) in twenty-three sites distributed across four climate regions and three habitat types. using tree-level responses, we detected a trade-off between seed mass and seed number across the moisture gradient. individual trees plastically and reversibly produced many small seeds at dry sites or years, and few big seeds at wet sites and years. bigger seeds were positively correlated with higher seed and seedling survival rates. the trade-off, the relation between seed mass, seed and seedling survival, and other fitness components of the plant life-cycle were integrated within a matrix population model. the model confirms that the plastic response resulted in average fitness benefits across the life-cycle. plasticity resulted in average fitness being positively maintained at the wet and dry range margins where extinction risks would otherwise have been high (\u201cjack-of-all-trades\u201d strategy jt), and fitness being maximized at the species range centre where extinction risks were already low (\u201cmaster-of-some\u201d strategy ms). the resulting hybrid \u201cjack-and-master\u201d strategy (jm) broadened the geographic range and amplified average fitness in the range centre. our study provides the first empirical evidence for a jm species. it also confirms mechanistically the importance of phenotypic plasticity in determining the size, the shape and the dynamic of a species distribution. the jm allows rapid and reversible phenotypic responses to new or changing moisture conditions at different scales, providing the species with definite advantages over genetic adaptation when invading diverse and variable environments. furthermore, natural selection pressure acting on phenotypic plasticity is predicted to result in maintenance of the jt and strengthening of the ms, further enhancing the species invasiveness in its range centre.",
            "contribution_ids": [
                "R54073"
            ]
        },
        {
            "instance_id": "R54244xR54082",
            "comparison_id": "R54244",
            "paper_id": "R54082",
            "text": "Geographically distinct Ceratophyllum demersum populations differ in growth, photosynthetic responses and phenotypic plasticity to nitrogen availability \\n\\ntwo geographically distinct populations of the submerged aquatic macrophyte ceratophyllum demersum l. were compared after acclimation to five different nitrogen concentrations (0.005, 0.02, 0.05, 0.1 and 0.2\\u2009mm n) in a common garden setup. the two populations were an apparent invasive population from new zealand (nz) and a noninvasive population from denmark (dk). the populations were compared with a focus on both morphological and physiological traits. the nz population had higher relative growth rates (rgrs) and photosynthesis rates (pmax) (range: rgr, 0.06\u20130.08 per day; pmax, 200\u2013395\\u2009\u00b5mol\\u2009o2\\u2009g\u20131 dry mass (dm) h\u20131) compared with the danish population (range: rgr, 0.02\u20130.05 per day; pmax, 88\u2013169\\u2009\u00b5mol o2 g\u20131 dm h\u20131). the larger, faster-growing nz population also showed higher plasticity than the dk population in response to nitrogen in traits important for growth. hence, the observed differences in growth behaviour between the two populations are a result of genetic differences and differences in their level of plasticity. here, we show that two populations of the same species from similar climates but different geographical areas can differ in several ecophysiological traits after growth in a common garden setup.\\n",
            "contribution_ids": [
                "R54083"
            ]
        },
        {
            "instance_id": "R54244xR54094",
            "comparison_id": "R54244",
            "paper_id": "R54094",
            "text": "Multispecies comparison reveals that invasive and native plants differ in their traits but not in their plasticity summary 1. plastic responses to spatiotemporal environmental variation strongly influence species distribution, with widespread species expected to have high phenotypic plasticity. theoretically, high phenotypic plasticity has been linked to plant invasiveness because it facilitates colonization and rapid spreading over large and environmentally heterogeneous new areas. 2. to determine the importance of phenotypic plasticity for plant invasiveness, we compare well-known exotic invasive species with widespread native congeners. first, we characterized the phenotype of 20 invasive\u2013native ecologically and phylogenetically related pairs from the mediterranean region by measuring 20 different traits involved in resource acquisition, plant competition ability and stress tolerance. second, we estimated their plasticity across nutrient and light gradients. 3. on average, invasive species had greater capacity for carbon gain and enhanced performance over a range of limiting to saturating resource availabilities than natives. however, both groups responded to environmental variations with high albeit similar levels of trait plasticity. therefore, contrary to the theory, the extent of phenotypic plasticity was not significantly higher for invasive plants. 4. we argue that the combination of studying mean values of a trait with its plasticity can render insightful conclusions on functional comparisons of species such as those exploring the performance of species coexisting in heterogeneous and changing environments.",
            "contribution_ids": [
                "R54095"
            ]
        },
        {
            "instance_id": "R54244xR54120",
            "comparison_id": "R54244",
            "paper_id": "R54120",
            "text": "Variation in morphological characters of two invasive leafminers, Liriomyza huidobrensis and L. sativae, across a tropical elevation gradient abstract changes in morphological traits along elevation and latitudinal gradients in ectotherms are often interpreted in terms of the temperature-size rule, which states that the body size of organisms increases under low temperatures, and is therefore expected to increase with elevation and latitude. however other factors like host plant might contribute to spatial patterns in size as well, particularly for polyphagous insects. here elevation patterns for trait size and shape in two leafminer species are examined, liriomyza huidobrensis (blanchard) (diptera: agromyzidae) and l. sativae blanchard, along a tropical elevation gradient in java, indonesia. adult leafminers were trapped from different locations in the mountainous area of dieng in the province of central java. to separate environmental versus genetic effects, l. huidobrensis originating from 1378 m and 2129 m asl were reared in the laboratory for five generations. size variation along the elevation gradient was only found in l. huidobrensis and this followed expectations based on the temperature-size rule. there were also complex changes in wing shape along the gradient. morphological differences were influenced by genetic and environmental effects. findings are discussed within the context of adaptation to different elevations in the two species.",
            "contribution_ids": [
                "R54121"
            ]
        },
        {
            "instance_id": "R54244xR54126",
            "comparison_id": "R54244",
            "paper_id": "R54126",
            "text": "Differential patterns of plasticity to water availability along native and naturalized latitudinal gradients questions: does plasticity to water availability differ between native and naturalized and laboratory plant accessions? is there a relationship between morphological plasticity and a fitness measure? can we account for latitudinal patterns of plasticity with rainfall data from the seed source location? organism: we examined an array of 23 native, 14 naturalized, and 5 laboratory accessions of arabidopsis thaliana. methods: we employed a split-plot experimental design in the greenhouse with two water treatments. we measured morphological and fitness-related traits at various developmental stages. we utilized a published dataset representing 30-year average precipitation trends for each accession origin. results: we detected evidence of differential patterns of plasticity between native, naturalized, and laboratory populations for several morphological traits. native, laboratory, and naturalized populations also differed in which traits were positively associated with fitness, and did not follow the jack-of-all-trades or master-of-some scenarios. significant negative relationships were detected for plasticity in morphological traits with latitude. we found modest evidence that rainfall may play a role in this latitudinal trend.",
            "contribution_ids": [
                "R54127"
            ]
        },
        {
            "instance_id": "R54244xR54136",
            "comparison_id": "R54244",
            "paper_id": "R54136",
            "text": "Invasion strategies in clonal aquatic plants: are phenotypic differences caused by phenotypic plasticity or local adaptation?  background and aims\\nthe successful spread of invasive plants in new environments is often linked to multiple introductions and a diverse gene pool that facilitates local adaptation to variable environmental conditions. for clonal plants, however, phenotypic plasticity may be equally important. here the primary adaptive strategy in three non-native, clonally reproducing macrophytes (egeria densa, elodea canadensis and lagarosiphon major) in new zealand freshwaters were examined and an attempt was made to link observed differences in plant morphology to local variation in habitat conditions.\\n\\n\\nmethods\\nfield populations with a large phenotypic variety were sampled in a range of lakes and streams with different chemical and physical properties. the phenotypic plasticity of the species before and after cultivation was studied in a common garden growth experiment, and the genetic diversity of these same populations was also quantified.\\n\\n\\nkey results\\nfor all three species, greater variation in plant characteristics was found before they were grown in standardized conditions. moreover, field populations displayed remarkably little genetic variation and there was little interaction between habitat conditions and plant morphological characteristics.\\n\\n\\nconclusions\\nthe results indicate that at the current stage of spread into new zealand, the primary adaptive strategy of these three invasive macrophytes is phenotypic plasticity. however, while limited, the possibility that genetic diversity between populations may facilitate ecotypic differentiation in the future cannot be excluded. these results thus indicate that invasive clonal aquatic plants adapt to new introduced areas by phenotypic plasticity. inorganic carbon, nitrogen and phosphorous were important in controlling plant size of e. canadensis and l. major, but no other relationships between plant characteristics and habitat conditions were apparent. this implies that within-species differences in plant size can be explained by local nutrient conditions. all together this strongly suggests that invasive clonal aquatic plants adapt to a wide range of habitats in introduced areas by phenotypic plasticity rather than local adaptation.",
            "contribution_ids": [
                "R54137"
            ]
        },
        {
            "instance_id": "R54244xR54170",
            "comparison_id": "R54244",
            "paper_id": "R54170",
            "text": "Life history plasticity magnifies the ecological effects of a social wasp invasion  \\n an unresolved question in ecology concerns why the ecological effects of invasions vary in magnitude. many introduced species fail to interact strongly with the recipient biota, whereas others profoundly disrupt the ecosystems they invade through predation, competition, and other mechanisms. in the context of ecological impacts, research on biological invasions seldom considers phenotypic or microevolutionary changes that occur following introduction. here, we show how plasticity in key life history traits (colony size and longevity), together with omnivory, magnifies the predatory impacts of an invasive social wasp (\\n vespula pensylvanica \\n ) on a largely endemic arthropod fauna in hawaii. using a combination of molecular, experimental, and behavioral approaches, we demonstrate (\\n i \\n ) that yellowjackets consume an astonishing diversity of arthropod resources and depress prey populations in invaded hawaiian ecosystems and (\\n ii \\n ) that their impact as predators in this region increases when they shift from small annual colonies to large perennial colonies. such trait plasticity may influence invasion success and the degree of disruption that invaded ecosystems experience. moreover, postintroduction phenotypic changes may help invaders to compensate for reductions in adaptive potential resulting from founder events and small population sizes. the dynamic nature of biological invasions necessitates a more quantitative understanding of how postintroduction changes in invader traits affect invasion processes.\\n",
            "contribution_ids": [
                "R54171"
            ]
        },
        {
            "instance_id": "R54244xR54176",
            "comparison_id": "R54244",
            "paper_id": "R54176",
            "text": "Inducible defences as key adaptations for the successful invasion of Daphnia lumholtzi in North America? the mechanisms underlying successful biological invasions often remain unclear. in the case of the tropical water flea daphnia lumholtzi , which invaded north america, it has been suggested that this species possesses a high thermal tolerance, which in the course of global climate change promotes its establishment and rapid spread. however, d. lumholtzi has an additional remarkable feature: it is the only water flea that forms rigid head spines in response to chemicals released in the presence of fishes. these morphologically (phenotypically) plastic traits serve as an inducible defence against these predators. here, we show in controlled mesocosm experiments that the native north american species daphnia pulicaria is competitively superior to d. lumholtzi in the absence of predators. however, in the presence of fish predation the invasive species formed its defences and became dominant. this observation of a predator-mediated switch in dominance suggests that the inducible defence against fish predation may represent a key adaptation for the invasion success of d. lumholtzi .",
            "contribution_ids": [
                "R54177"
            ]
        },
        {
            "instance_id": "R54244xR54198",
            "comparison_id": "R54244",
            "paper_id": "R54198",
            "text": "Predicting invasiveness in exotic species: do subtropical native and invasive exotic aquatic plants differ in their growth responses to macronutrients? we investigated whether plasticity in growth responses to nutrients could predict invasive potential in aquatic plants by measuring the effects of nutrients on growth of eight non\u2010invasive native and six invasive exotic aquatic plant species. nutrients were applied at two levels, approximating those found in urbanized and relatively undisturbed catchments, respectively. to identify systematic differences between invasive and non\u2010invasive species, we compared the growth responses (total biomass, root:shoot allocation, and photosynthetic surface area) of native species with those of related invasive species after 13 weeks growth. the results were used to seek evidence of invasive potential among four recently naturalized species. there was evidence that invasive species tend to accumulate more biomass than native species (p = 0.0788). root:shoot allocation did not differ between native and invasive plant species, nor was allocation affected by nutrient addition. however, the photosynthetic surface area of invasive species tended to increase with nutrients, whereas it did not among native species (p = 0.0658). of the four recently naturalized species, hydrocleys nymphoides showed the same nutrient\u2010related plasticity in photosynthetic area displayed by known invasive species. cyperus papyrus showed a strong reduction in photosynthetic area with increased nutrients. h. nymphoides and c. papyrus also accumulated more biomass than their native relatives. h. nymphoides possesses both of the traits we found to be associated with invasiveness, and should thus be regarded as likely to be invasive.",
            "contribution_ids": [
                "R54199"
            ]
        },
        {
            "instance_id": "R54244xR54200",
            "comparison_id": "R54244",
            "paper_id": "R54200",
            "text": "Spreading of the invasive Carpobrotus aff. acinaciformis in Mediterranean ecosystems: The advantage of performing in different light environments abstract question: do specific environmental conditions affect the performance and growth dynamics of one of the most invasive taxa (carpobrotus aff. acinaciformis) on mediterranean islands? location: four populations located on mallorca, spain. methods: we monitored growth rates of main and lateral shoots of this stoloniferous plant for over two years (2002\u20132003), comparing two habitats (rocky coast vs. coastal dune) and two different light conditions (sun vs. shade). in one population of each habitat type, we estimated electron transport rate and the level of plant stress (maximal photochemical efficiency fv/fm) by means of chlorophyll fluorescence. results: main shoots of carpobrotus grew at similar rates at all sites, regardless habitat type. however, growth rate of lateral shoots was greater in shaded plants than in those exposed to sunlight. its high phenotypic plasticity, expressed in different allocation patterns in sun and shade individuals, and its clonal growth which promotes the continuous search of available resources, contributed to a good growth and photochemical efficiency of carpobrotus in the relatively moderate shade of the understories of mediterranean shrublands and woodlands. each main shoot of a carpobrotus clone (which can have several dozens main shoots) grows ca. 40 cm per year, which explains its vigorous habitat colonization capacity. conclusion: the highly plastic morphological response to different light regimes of this taxon contributes to a rapid colonization of heterogeneous coastal mediterranean environments spreading well beyond the open sand dune systems where it has been often reported. nomenclature: tutin et al. (1964\u20131980).",
            "contribution_ids": [
                "R54201"
            ]
        },
        {
            "instance_id": "R54244xR54202",
            "comparison_id": "R54244",
            "paper_id": "R54202",
            "text": "Photosynthesis and water-use efficiency: A comparison between invasive (exotic) and non-invasive (native) species invasive species have been hypothesized to out-compete natives though either a jack-of-all-trades strategy, where they are able to utilize resources effectively in unfavourable environments, a master-of-some, where resource utilization is greater than its competitors in favourable environments, or a combination of the two (jack-and-master). we examined the invasive strategy of berberis darwinii in new zealand compared with four co-occurring native species by examining germination, seedling survival, photosynthetic characteristics and water-use efficiency of adult plants, in sun and shade environments. berberis darwinii seeds germinated more in shady sites than the other natives, but survival was low. in contrast, while germination of b.\\xa0darwinii was the same as the native species in sunny sites, seedling survival after 18\\xa0months was nearly twice that of the all native species. the maximum photosynthetic rate of b.\\xa0darwinii was nearly double that of all native species in the sun, but was similar among all species in the shade. other photosynthetic traits (quantum yield and stomatal conductance) did not generally differ between b.\\xa0darwinii and the native species, regardless of light environment. berberis darwinii had more positive values of \u03b413c than the four native species, suggesting that it gains more carbon per unit water transpired than the competing native species. these results suggest that the invasion success of b.\\xa0darwinii may be partially explained by combination of a jack-of-all-trades scenario of widespread germination with a master-of-some scenario through its ability to photosynthesize at higher rates in the sun and, hence, gain a rapid height and biomass advantage over native species in favourable environments.",
            "contribution_ids": [
                "R54203"
            ]
        },
        {
            "instance_id": "R54244xR54214",
            "comparison_id": "R54244",
            "paper_id": "R54214",
            "text": "Phenotypic plasticity, precipitation, and invasiveness in the fire-promoting grass Pennisetum setaceum (poaceae) invasiveness may result from genetic variation and adaptation or phenotypic plasticity, and genetic variation in fitness traits may be especially critical. pennisetum setaceum (fountain grass, poaceae) is highly invasive in hawaii (hi), moderately invasive in arizona (az), and less invasive in southern california (ca). in common garden experiments, we examined the relative importance of quantitative trait variation, precipitation, and phenotypic plasticity in invasiveness. in two very different environments, plants showed no differences by state of origin (hi, ca, az) in aboveground biomass, seeds/flower, and total seed number. plants from different states were also similar within watering treatment. plants with supplemental watering, relative to unwatered plants, had greater biomass, specific leaf area (sla), and total seed number, but did not differ in seeds/flower. progeny grown from seeds produced under different watering treatments showed no maternal effects in seed mass, germination, biomass or sla. high phenotypic plasticity, rather than local adaptation is likely responsible for variation in invasiveness. global change models indicate that temperature and precipitation patterns over the next several decades will change, although the direction of change is uncertain. drier summers in southern california may retard further invasion, while wetter summers may favor the spread of fountain grass.",
            "contribution_ids": [
                "R54215"
            ]
        },
        {
            "instance_id": "R54244xR54218",
            "comparison_id": "R54244",
            "paper_id": "R54218",
            "text": "Rapid evolution in response to introduced predators I: rates and patterns of morphological and life-history trait divergence abstract \\n \\n background \\n introduced species can have profound effects on native species, communities, and ecosystems, and have caused extinctions or declines in native species globally. we examined the evolutionary response of native zooplankton populations to the introduction of non-native salmonids in alpine lakes in the sierra nevada of california, usa. we compared morphological and life-history traits in populations of daphnia with a known history of introduced salmonids and populations that have no history of salmonid introductions. \\n \\n \\n results \\n our results show that daphnia populations co-existing with fish have undergone rapid adaptive reductions in body size and in the timing of reproduction. size-related traits decreased by up to 13 percent in response to introduced fish. rates of evolutionary change are as high as 4,238 darwins (0.036 haldanes). \\n \\n \\n conclusion \\n species introductions into aquatic habitats can dramatically alter the selective environment of native species leading to a rapid evolutionary response. knowledge of the rates and limits of adaptation is an important component of understanding the long-term effects of alterations in the species composition of communities. we discuss the evolutionary consequences of species introductions and compare the rate of evolution observed in the sierra nevada daphnia to published estimates of evolutionary change in ecological timescales. \\n",
            "contribution_ids": [
                "R54219"
            ]
        },
        {
            "instance_id": "R54244xR54230",
            "comparison_id": "R54244",
            "paper_id": "R54230",
            "text": "Leaf-level phenotypic variability and plasticity of invasive Rhododendron ponticum and non-invasive Ilex aquifolium co-occurring at two contrasting European sites to understand the role of leaf-level plasticity and variability in species invasiveness, foliar characteristics were studied in relation to seasonal average integrated quantum flux density (qint) in the understorey evergreen species rhododendron ponticum and ilex aquifolium at two sites. a native relict population of r. ponticum was sampled in southern spain (mediterranean climate), while an invasive alien population was investigated in belgium (temperate maritime climate). ilex aquifolium was native at both sites. both species exhibited a significant plastic response to qint in leaf dry mass per unit area, thickness, photosynthetic potentials, and chlorophyll contents at the two sites. however, r. ponticum exhibited a higher photosynthetic nitrogen use efficiency and larger investment of nitrogen in chlorophyll than i. aquifolium. since leaf nitrogen (n) contents per unit dry mass were lower in r. ponticum, this species formed a larger foliar area with equal photosynthetic potential and light-harvesting efficiency compared with i. aquifolium. the foliage of r. ponticum was mechanically more resistant with larger density in the belgian site than in the spanish site. mean leaf-level phenotypic plasticity was larger in the belgian population of r. ponticum than in the spanish population of this species and the two populations of i. aquifolium. we suggest that large fractional investments of foliar n in photosynthetic function coupled with a relatively large mean, leaf-level phenotypic plasticity may provide the primary explanation for the invasive nature and superior performance of r. ponticum at the belgian site. with alleviation of water limitations from mediterranean to temperate maritime climates, the invasiveness of r. ponticum may also be enhanced by the increased foliage mechanical resistance observed in the alien populations.",
            "contribution_ids": [
                "R54231"
            ]
        },
        {
            "instance_id": "R54244xR54241",
            "comparison_id": "R54244",
            "paper_id": "R54241",
            "text": "Greater morphological plasticity of exotic honeysuckle species may make them better invaders than native species sempervirens l., a non-invasive native. we hypothesized that greater morphological plasticity may contribute to the ability of l. japonica to occupy more habitat types, and contribute to its invasiveness. we compared the morphology of plants provided with climbing supports with plants that had no climbing supports, and thus quantified their morphological plasticity in response to an important variable in their habitats. the two species responded differently to the treatments, with l. japonica showing greater responses in more characters. for example, lonicera japonica responded to climbing supports with a 15.3% decrease in internode length, a doubling of internode number and a 43% increase in shoot biomass. in contrast, climbing supports did not influence internode length or shoot biomass for l. sempervirens, and only resulted in a 25% increase in internode number. this plasticity may allow l. japonica to actively place plant modules in favorable microhabitats and ultimately affect plant fitness.",
            "contribution_ids": [
                "R54242"
            ]
        },
        {
            "instance_id": "R54867xR54574",
            "comparison_id": "R54867",
            "paper_id": "R54574",
            "text": "Anthropogenic Disturbance Can Determine the Magnitude of Opportunistic Species Responses on Marine Urban Infrastructures background coastal landscapes are being transformed as a consequence of the increasing demand for infrastructures to sustain residential, commercial and tourist activities. thus, intertidal and shallow marine habitats are largely being replaced by a variety of artificial substrata (e.g. breakwaters, seawalls, jetties). understanding the ecological functioning of these artificial habitats is key to planning their design and management, in order to minimise their impacts and to improve their potential to contribute to marine biodiversity and ecosystem functioning. nonetheless, little effort has been made to assess the role of human disturbances in shaping the structure of assemblages on marine artificial infrastructures. we tested the hypothesis that some negative impacts associated with the expansion of opportunistic and invasive species on urban infrastructures can be related to the severe human disturbances that are typical of these environments, such as those from maintenance and renovation works. methodology/principal findings maintenance caused a marked decrease in the cover of dominant space occupiers, such as mussels and oysters, and a significant enhancement of opportunistic and invasive forms, such as biofilm and macroalgae. these effects were particularly pronounced on sheltered substrata compared to exposed substrata. experimental application of the disturbance in winter reduced the magnitude of the impacts compared to application in spring or summer. we use these results to identify possible management strategies to inform the improvement of the ecological value of artificial marine infrastructures. conclusions/significance we demonstrate that some of the impacts of globally expanding marine urban infrastructures, such as those related to the spread of opportunistic, and invasive species could be mitigated through ecologically-driven planning and management of long-term maintenance of these structures. impact mitigation is a possible outcome of policies that consider the ecological features of built infrastructures and the fundamental value of controlling biodiversity in marine urban systems.",
            "contribution_ids": [
                "R54575"
            ]
        },
        {
            "instance_id": "R54867xR54585",
            "comparison_id": "R54867",
            "paper_id": "R54585",
            "text": "The incidence of exotic species following clearfelling of Eucalyptus regnans forest in the Central Highlands, Victoria invasion by exotic species following clearfelling of eucalyptus regnans f. muell. (mountain ash) forest was examined in the toolangi state forest in the central highlands of victoria. coupes ranging in age from < 1- to 10-years-old and the spar-stage forests (1939 bushfire regrowth) adjacent to each of these coupes and a mature, 250-year-old forest were surveyed. the dispersal and establishment of weeds was facilitated by clearfelling. an influx of seeds of exotic species was detected in recently felled coupes but not in the adjacent, unlogged forests. vehicles and frequently disturbed areas, such as roadside verges, are likely sources of the seeds of exotic species. the soil seed bank of younger coupes had a greater number and percentage of seeds of exotics than the 10-year-old coupes and the spar-stage and mature forests. exotic species were a minor component (< 1% vegetation cover) in the more recently logged coupes and were not present in 10-year-old coupes and the spar-stage and mature forests. these particular exotic species did not persist in the dense regeneration nor exist in the older forests because the weeds were ruderal species (light-demanding, short-lived and short-statured plants). the degree of influence that these particular exotic species have on the regeneration and survival of native species in e. regnans forests is almost negligible. however, the current management practices may need to be addressed to prevent a more threatening exotic species from establishing in these coupes and forests.",
            "contribution_ids": [
                "R54586",
                "R54587"
            ]
        },
        {
            "instance_id": "R54867xR54605",
            "comparison_id": "R54867",
            "paper_id": "R54605",
            "text": "Interannual variation of fish assemblage structure in a Mediterranean River: Implications of streamflow on the dominance of native or exotic species streams in mediterranean\u2010type climate regions are shaped by predictable seasonal events of flooding and drying over an annual cycle, but also present a strong interannual flow variation.",
            "contribution_ids": [
                "R54606"
            ]
        },
        {
            "instance_id": "R54867xR54607",
            "comparison_id": "R54867",
            "paper_id": "R54607",
            "text": "Determinants of Caulerpa racemosa distribution in the north-western Mediterranean predicting community susceptibility to invasion has become a priority for preserving biodiversity. we tested the hypothesis that the occurrence and abundance of the seaweed caulerpa racemosa in the north-western (nw) mediterranean would increase with increasing levels of human disturbance. data from a survey encompassing areas subjected to different human influences (i.e. from urbanized to protected areas) were fitted by means of generalized linear mixed models, including descriptors of habitats and communities. the incidence of occurrence of c. racemosa was greater on urban than extra-urban or protected reefs, along the coast of tuscany and nw sardinia, respectively. within the marine protected area of capraia island (tuscan archipelago), the probability of \\ndetecting c. racemosa did not vary according to the degree of protection (partial versus total). human influence was, however, a poor predictor of the seaweed cover. at the seascape level, c. racemosa was more widely spread within degraded (i.e. posidonia oceanica dead matte or algal turfs) than in better preserved habitats (i.e. canopy-forming macroalgae or p. oceanica seagrass meadows). at a smaller spatial scale, the presence of the seaweed was positively correlated to the diversity of macroalgae and negatively to that of sessile invertebrates. these results suggest that c. racemosa can take advantage of habitat degradation. thus, predicting invasion scenarios requires a thorough knowledge of ecosystem structure, at a hierarchy of levels of biological organization (from the \\nlandscape to the assemblage) and detailed information on the nature and intensity of sources of disturbance and spatial scales at which they operate.",
            "contribution_ids": [
                "R54608"
            ]
        },
        {
            "instance_id": "R54867xR54642",
            "comparison_id": "R54867",
            "paper_id": "R54642",
            "text": "Re-colonisation rate differs between co-existing indigenous and invasive intertidal mussels following major disturbance the potential of introduced species to become invasive is often linked to their ability to colonise disturbed habitats rapidly. we studied the effects of major disturbance by severe storms on the indigenous mussel perna perna and the invasive mussel mytilus galloprovincialis in sympatric intertidal populations on the south coast of south africa. at the study sites, these species dominate different shore levels and co-exist in the mid mussel zone. we tested the hypotheses that in the mid- zone p. perna would suffer less dislodgment than m. galloprovincialis, because of its greater tenacity, while m. galloprovincialis would respond with a higher re-colonisation rate. we estimated the per- cent cover of the 2 mussels in the mid-zone from photographs, once before severe storms and 3 times afterwards. m. galloprovincialis showed faster re-colonisation and 3 times more cover than p. perna 1 and 1.5 yr after the storms (when populations had recovered). storm-driven dislodgment in the mid- zone was highest for the species that initially dominated at each site, conforming to the concept of compensatory mortality. this resulted in similar cover of the 2 species immediately after the storms. thus, the storm wave forces exceeded the tenacity even of p. perna, while the higher recruitment rate of m. galloprovincialis can explain its greater colonisation ability. we predict that, because of its weaker attachment strength, m. galloprovincialis will be largely excluded from open coast sites where wave action is generally stronger, but that its greater capacity for exploitation competition through re-colonisation will allow it to outcompete p. perna in more sheltered areas (especially in bays) that are periodically disturbed by storms.",
            "contribution_ids": [
                "R54643"
            ]
        },
        {
            "instance_id": "R54867xR54663",
            "comparison_id": "R54867",
            "paper_id": "R54663",
            "text": "Fire and competition in a southern California grassland: impacts on the rare forb Erodium macrophyllum summary 1. the use of off-season burns to control exotic vegetation shows promise for land managers. in california, wildfires tend to occur in the summer and autumn, when most grassland vegetation is dormant. the effects of spring fires on native bunchgrasses have been examined but their impacts on native forbs have received less attention. 2. we introduced erodium macrophyllum, a rare native annual forb, by seeding plots in 10 different areas in a california grassland. we tested the hypotheses that e. macrophyllum would perform better (increased fecundity and germination) when competing with native grasses than with a mixture of exotic and native grasses, and fire would alter subsequent demography of e. macrophyllum and other species\u2019 abundances. we monitored the demography of e. macrophyllum for two seasons in plots manually weeded so that they were free from exotics, and in areas that were burned or not burned the spring after seeding. 3. weeding increased e. macrophyllum seedling emergence, survival and fecundity during both seasons. when vegetation was burned in june 2001 (at the end of the first growing season) to kill exotic grass seeds before they dispersed, all e. macrophyllum plants had finished their life cycle and dispersed seeds, suggesting that burns at this time of year would not directly impact on fecundity. in the growing season after burning (2002), burned plots had less recruitment of e. macrophyllum but more establishment of native grass seedlings, suggesting burning may differentially affect seedling recruitment. 4. at the end of the second growing season (june 2002), burned plots had less cover of exotic and native grasses but more cover of exotic forbs. nevertheless, e. macrophyllum plants in burned plots had greater fecundity than in non-burned plots, suggesting that exotic grasses are more competitive than exotic forbs. 5. a glasshouse study showed that exotic grasses competitively suppress e. macrophyllum to a greater extent than native grasses, indicating that the poor performance of e. macrophyllum in the non-burned plots was due to exotic grass competition. 6. synthesis and applications. this study illustrates that fire can alter the competitive environment in grasslands with differential effects on rare forbs, and that exotic grasses strongly interfere with e. macrophyllum. for land managers, the benefits of prescribed spring burns will probably outweigh the costs of decreased e. macrophyllum establishment. land managers can use spring burns to cause a flush of native grass recruitment and to create an environment that is, although abundant with exotic forbs, ultimately less competitive compared with non-burned areas dominated by exotic grasses.",
            "contribution_ids": [
                "R54664"
            ]
        },
        {
            "instance_id": "R54867xR54689",
            "comparison_id": "R54867",
            "paper_id": "R54689",
            "text": "Effect of disturbance and nutrient addition on native and introduced annuals in plant communities in the Western Australian wheatbelt to investigate factors affecting the ability of introduced species to invade natural communities in the western australian wheatbelt, five communities were examined within a nature reserve near kellerberrin. transect studies indicated that introduced annuals were more abundant in woodland than in shrub communities, despite an input of introduced seed into all communities. the response of native and introduced annuals to soil disturbance and fertilizer addition was examined. small areas were disturbed and/or provided with fertilizer prior to addition of seed of introduced annuals. in most communities, the introduced species used (avena fatua and ursinia anthemoides) established well only where the soil had been disturbed, but their growth was increased greatly when fertilizer was also added. establishment and growth of other introduced species also increased where nutrient addition and soil disturbance were combined. growth of several native annuals increased greatly with fertilizer addition, but showed little response to disturbance. fertilizer addition also significantly increased the number of native species present in most communities. this indicates that growth of both native and introduced species is limited by nutrient availability in these communities, but also that introduced species respond more to a combination of nutrient addition and soil disturbance.",
            "contribution_ids": [
                "R54690",
                "R54691"
            ]
        },
        {
            "instance_id": "R54867xR54694",
            "comparison_id": "R54867",
            "paper_id": "R54694",
            "text": "Removal of nonnative vines and post-hurricane recruitment in tropical hardwood forests of Florida abstract in hardwood subtropical forests of southern florida, nonnative vines have been hypothesized to be detrimental, as many species form dense \u201cvine blankets\u201d that shroud the forest. to investigate the effects of nonnative vines in post-hurricane regeneration, we set up four large (two pairs of 30 \u00d7 60 m) study areas in each of three study sites. one of each pair was unmanaged and the other was managed by removal of nonnative plants, predominantly vines. within these areas, we sampled vegetation in 5 \u00d7 5 m plots for stems 2 cm dbh (diameter at breast height) or greater and in 2 \u00d7 0.5 m plots for stems of all sizes. for five years, at annual censuses, we tagged and measured stems of vines, trees, shrubs and herbs in these plots. for each 5 \u00d7 5 m plot, we estimated percent coverage by individual vine species, using native and nonnative vines as classes. we investigated the hypotheses that: (1) plot coverage, occurrence and recruitment of nonnative vines were greater than that of native vines in unmanaged plots; (2) the management program was effective at reducing cover by nonnative vines; and (3) reduction of cover by nonnative vines improved recruitment of seedlings and saplings of native trees, shrubs, and herbs. in unmanaged plots, nonnative vines recruited more seedlings and had a significantly higher plot-cover index, but not a higher frequency of occurrence. management significantly reduced cover by nonnative vines and had a significant overall positive effect on recruitment of seedlings and saplings of native trees, shrubs and herbs. management also affected the seedling community (which included vines, trees, shrubs, and herbs) in some unanticipated ways, favoring early successional species for a longer period of time. the vine species with the greatest potential to \u201cstrangle\u201d gaps were those that rapidly formed dense cover, had shade tolerant seedling recruitment, and were animal-dispersed. this suite of traits was more common in the nonnative vines than in the native vines. our results suggest that some vines may alter the spatiotemporal pattern of recruitment sites in a forest ecosystem following a natural disturbance by creating many very shady spots very quickly.",
            "contribution_ids": [
                "R54695",
                "R54696"
            ]
        },
        {
            "instance_id": "R54867xR54697",
            "comparison_id": "R54867",
            "paper_id": "R54697",
            "text": "Alien Grass Invasion and Fire In the Seasonal Submontane Zone of Hawaii \"island ecosystems are notably susceptible to biological invasions (elton 1958), and the hawaiian islands in particular have been colonized by many introduced species (loope and mueller-dombois 1989). introduced plants now dominate extensive areas of the hawaiian islands, and 86 species of alien plants are presently considered to pose serious threats to hawaiian communities and ecosystems (smith 1985). among the most important invasive plants are several species of tropical and subtropical grasses that use the c4 photosynthetic pathway. these grasses now dominate extensive areas of dry and seasonally dry habitats in hawai'i. they may compete with native species, and they have also been shown to alter hydrological properties in the areas they invade (muellerdombois 1973). most importantly, alien grasses can introduce fire into areas where it was previously rare or absent (smith 1985), thereby altering the structure and functioning of previously native-dominated ecosystems. many of these grasses evolved in fire-affected areas and have mechanisms for surviving and recovering rapidly from fire (vogl 1975, christensen 1985), while most native species in hawai'i have little background with fire (mueller-dombois 1981) and hence few or no such mechanisms. consequently, grass invasion could initiate a grass/fire cycle whereby invading grasses promote fire, which in turn favors alien grasses over native species. such a scenario has been suggested in a number of areas, including latin america, western north america, australia, and hawai'i (parsons 1972, smith 1985, christensen and burrows 1986, mack 1986, macdonald and frame 1988). in most of these cases, land clearing by humans initiates colonization by alien grasses, and the grass/fire cycle then leads to their persistence. in hawai'i and perhaps other areas, however, grass invasion occurs without any direct human intervention. where such invasions initiate a grass/fire cy-\"",
            "contribution_ids": [
                "R54698"
            ]
        },
        {
            "instance_id": "R54867xR54704",
            "comparison_id": "R54867",
            "paper_id": "R54704",
            "text": "Prescribed fire effects on dalmation toadflax prescribed fires are important for rangeland restoration and affect plant community composition and species interactions. many rangeland plant communities have been, or are under the threat of noxious weed invasion, however there is little information on how fire effects weeds. our objective was to determine the effects of prescribed rangeland fire on dalmatian toadflax [linaria dalmatica (l.) miller] density, cover, biomass, and seed production. these plant characteristics, as well as density, cover, and biomass of perennial grasses and forbs were measured within burned and adjacent not-burned areas on 3 artemisia tridentata/agropyron spicatum habitat types in montana. areas were burned in the spring and measured in the fall 1999. comparisons of plant characteristics between the burned and not-burned sites were made using t-tests and non-parametric wilcoxon rank sum tests. after 1 growing season, fire did not affect density or cover of dalmatian toadflax. burning increased dalmatian toadflax bio- mass per square meter at 2 sites, and per plant biomass at all 3 sites. seed production of dalmatian toadflax was increased by fire at all 3 sites. fire reduced forb cover at 1 site and increased grass biomass at 2 sites. the increases in dalmatian toadflax biomass and seed production suggest that fire used to restore healthy plant communities may increase dalmatian toadflax dominance. we recommend weed management procedures, such as herbicide control and seeding desirable species, be integrated with prescribed fire where dalmatian toadflax is present in the plant community.",
            "contribution_ids": [
                "R54705",
                "R54706"
            ]
        },
        {
            "instance_id": "R54867xR54707",
            "comparison_id": "R54867",
            "paper_id": "R54707",
            "text": "Do biodiversity and human impact influence the introduction or establishment of alien mammals? what determines the number of alien species in a given region? \u2018native biodiversity\u2019 and \u2018human impact\u2019 are typical answers to this question. indeed, studies comparing different regions have frequently found positive relationships between number of alien species and measures of both native biodiversity (e.g. the number of native species) and human impact (e.g. human population). these relationships are typically explained by biotic acceptance or resistance, i.e. by influence of native biodiversity and human impact on the second step of the invasion process, establishment. the first step of the invasion process, introduction, has often been ignored. here we investigate whether relationships between number of alien mammals and native biodiversity or human impact in 43 european countries are mainly shaped by differences in number of introduced mammals or establishment success. our results suggest that correlation between number of native and established mammals is spurious, as it is simply explainable by the fact that both quantities are linked to country area. we also demonstrate that countries with higher human impact host more alien mammals than other countries because they received more introductions than other countries. differences in number of alien mammals cannot be explained by differences in establishment success. our findings highlight importance of human activities and question, at least for mammals in europe, importance of biotic acceptance and resistance.",
            "contribution_ids": [
                "R54708",
                "R57247"
            ]
        },
        {
            "instance_id": "R54867xR54720",
            "comparison_id": "R54867",
            "paper_id": "R54720",
            "text": "The influence of anthropogenic disturbance and environmental suitability on the distribution of the nonindigenous amphipod, Echinogammarus ischnus, at Laurentian Great Lakes coastal margins \"abstract invasion ecology offers a unique opportunity to examine drivers of ecological processes that regulate communities. biotic resistance to nonindigenous species establishment is thought to be greater in communities that have not been disturbed by human activities. alternatively, invasion may occur wherever environmental conditions are appropriate for the colonist, regardless of the composition of the existing community and the level of disturbance. we tested these hypotheses by investigating distribution of the nonindigenous amphipod, echinogammarus ischnus stebbing, 1899, in co-occurrence with a widespread amphipod, gammarus fasciatus say, 1818, at 97 sites across the laurentian great lakes coastal margins influenced by varying types and levels of anthropogenic stress. e. ischnus was distributed independently of disturbance gradients related to six anthropogenic disturbance variables that summarized overall nutrient input, nitrogen, and phosphorus load carried from the adjacent coastal watershed, agricultural land area, human population density, overall pollution loading, and the site-specific dominant stressor, consistent with the expectations of regulation by general environmental characteristics. our results support the view that the biotic facilitation by dreissenid mussels and distribution of suitable habitats better explain e. ischnus' distribution at laurentian great lakes coastal margins than anthropogenic disturbance.\"",
            "contribution_ids": [
                "R54721"
            ]
        },
        {
            "instance_id": "R54867xR54749",
            "comparison_id": "R54867",
            "paper_id": "R54749",
            "text": "Large Herbivore Grazing and Non-native Plant Invasions in Montane Grasslands of Central Argentina abstract: \\n grazing by large herbivores has the potential to facilitate invasion of natural grasslands by non-native plant species. often, both herbivore identity and plant community type modulate this effect. the objective of this study was to evaluate the impact of grazing on non-native plant species richness and cover in montane grasslands of central argentina as related to herbivore identity (horse or cattle) and plant community type. the study was conducted in piedmont valleys of the ventania mountains. the area is occupied by two major types of plant communities: short-needlegrass and tall-tussock grasslands. short-needlegrass grasslands occupy poor soils and have higher plant species diversity compared to tall-tussock grasslands which typically grow on rich soils. part of the study area is devoted to cattle husbandry, part is inhabited by feral horses, and part has been free of grazing by large herbivores for the last 15 years. we compared non-native species richness and cover at three levels of grazing (horse grazing, cattle grazing, grazing exclusion) and two levels of plant community type (short-needlegrass grassland and tall-tussock grassland) at the end of the growing season in 2006 and 2007. thirty-one nonnative plant species were found growing in the study area. grazing increased non-native species richness and cover and was highest under horse grazing and in communities on resource-rich soils. our results are consistent with the hypothesis that grazing by large non-native herbivores can facilitate non-native plant species invasion of natural grasslands. they also suggest that herbivore identity and community type modulate the effect of large herbivore grazing on grassland invasion by non-native plant species.",
            "contribution_ids": [
                "R54750"
            ]
        },
        {
            "instance_id": "R54867xR54751",
            "comparison_id": "R54867",
            "paper_id": "R54751",
            "text": "Old World Climbing Fern (Lygodium microphyllum) Invasion in Hurricane Caused Treefalls abstract: \\n we examined effects of a natural disturbance (hurricanes) on potential invasion of tree islands by an exotic plant (old world climbing fern, lygodium microphyllum) in the arthur r. marshall loxahatchee national wildlife refuge, florida. three major hurricanes in 2004 and 2005 caused varying degrees of impacts to trees on tree islands within the refuge. physical impacts of hurricanes were hypothesized to promote invasion and growth of l. microphyllum. we compared presence and density of l. microphyllum in plots of disturbed soil created by hurricane-caused treefalls to randomly selected non-disturbed plots on 12 tree islands. we also examined relationships between disturbed area size, canopy cover, and presence of standing water on presence and density of l. microphyllum. lygodium microphyllum was present in significantly more treefall plots than random non-treefall plots (76% of the treefall plots (n=55) and only 14% of random non-treefall plots (n=55)). density of l. microphyllum was higher in treefall plots compared to random non-disturbed plots (6.0 stems per m2 for treefall plots; 0.5 stems per m2 for random non-disturbed plots), and l. microphyllum density was correlated with disturbed area size (p = 0.005). lygodium microphyllum presence in treefall sites was significantly related to canopy cover and presence of water: it was present in five times more treefalls with water than those without. these results suggest that disturbances, such as hurricanes, that result in canopy openings and the creation of disturbed areas with standing water contribute to the ability of l. microphyllum to invade natural areas.",
            "contribution_ids": [
                "R54752"
            ]
        },
        {
            "instance_id": "R54867xR54781",
            "comparison_id": "R54867",
            "paper_id": "R54781",
            "text": "Are invaders disturbance-limited? Conservation of mountain grasslands in Central Argentina abstract extensive areas in the mountain grasslands of central argentina are heavily invaded by alien species from europe. a decrease in biodiversity and a loss of palatable species is also observed. the invasibility of the tall-grass mountain grassland community was investigated in an experiment of factorial design. six alien species which are widely distributed in the region were sown in plots where soil disturbance, above-ground biomass removal by cutting and burning were used as treatments. alien species did not establish in undisturbed plots. all three types of disturbances increased the number and cover of alien species; the effects of soil disturbance and biomass removal was cumulative. cirsium vulgare and oenothera erythrosepala were the most efficient alien colonizers. in conditions where disturbances did not continue the cover of aliens started to decrease in the second year, by the end of the third season, only a few adults were established. consequently, disturbances are needed to maintain alien populations in tall-grass mountain grasslands. burning also increased the species richness of native species. we conclude that an efficient way to control the distribution of alien species is to decrease grazing pressure while burning as a traditional management tool may be continued. nomenclature: cantero & bianco (1986).",
            "contribution_ids": [
                "R54782",
                "R54783"
            ]
        },
        {
            "instance_id": "R54867xR54791",
            "comparison_id": "R54867",
            "paper_id": "R54791",
            "text": "EFFECTS OF DISTURBANCE ON HERBACEOUS EXOTIC PLANT-SPECIES ON THE FLOODPLAIN OF THE POTOMAC RIVER \"-the objective of this study was to investigate specific effects of disturbance on exotic species in floodplain environments and to provide baseline data on the abundance of exotic herbs in the potomac river floodplain. frequency of exotics generally increased with man-made disturbance (forest fragmentation and recreational use of land) and decreased with increasing flooding frequency. species richness of exotics followed a similar pattern. some variation was found in individual species' responses to disturbance. the spread of alliaria officinalis and glecoma hederacea, the most frequent exotic species, was inhibited by forest fragmentation.\"",
            "contribution_ids": [
                "R54792"
            ]
        },
        {
            "instance_id": "R54867xR54797",
            "comparison_id": "R54867",
            "paper_id": "R54797",
            "text": "Mammals of the northern Philippines: tolerance for habitat disturbance and resistance to invasive species in an endemic insular fauna aim\\u2002 island faunas, particularly those with high levels of endemism, usually are considered especially susceptible to disruption from habitat disturbance and invasive alien species. we tested this general hypothesis by examining the distribution of small mammals along gradients of anthropogenic habitat disturbance in northern luzon island, an area with a very high level of mammalian endemism.",
            "contribution_ids": [
                "R54798"
            ]
        },
        {
            "instance_id": "R54867xR54817",
            "comparison_id": "R54867",
            "paper_id": "R54817",
            "text": "Recent Invasion of the Symbiont-Bearing Foraminifera Pararotalia into the Eastern Mediterranean Facilitated by the Ongoing Warming Trend the eastern mediterranean is a hotspot of biological invasions. numerous species of indo-pacific origin have colonized the mediterranean in recent times, including tropical symbiont-bearing foraminifera. among these is the species pararotalia calcariformata. unlike other invasive foraminifera, this species was discovered only two decades ago and is restricted to the eastern mediterranean coast. combining ecological, genetic and physiological observations, we attempt to explain the recent invasion of this species in the mediterranean sea. using morphological and genetic data, we confirm the species attribution to p. calcariformata mcculloch 1977 and identify its symbionts as a consortium of diatom species dominated by minutocellus polymorphus. we document photosynthetic activity of its endosymbionts using pulse amplitude modulated fluorometry and test the effects of elevated temperatures on growth rates of asexual offspring. the culturing of asexual offspring for 120 days shows a 30-day period of rapid growth followed by a period of slower growth. a subsequent 48-day temperature sensitivity experiment indicates a similar developmental pathway and high growth rate at 28\u00b0c, whereas an almost complete inhibition of growth was observed at 20\u00b0c and 35\u00b0c. this indicates that the offspring of this species may have lower tolerance to cold temperatures than what would be expected for species native to the mediterranean. we expand this hypothesis by applying a species distribution model (sdm) based on modern occurrences in the mediterranean using three environmental variables: irradiance, turbidity and yearly minimum temperature. the model reproduces the observed restricted distribution and indicates that the range of the species will drastically expand westwards under future global change scenarios. we conclude that p. calcariformata established a population in the levant because of the recent warming in the region. in line with observations from other groups of organisms, our results indicate that continued warming of the eastern mediterranean will facilitate the invasion of more tropical marine taxa into the mediterranean, disturbing local biodiversity and ecosystem structure.",
            "contribution_ids": [
                "R54818"
            ]
        },
        {
            "instance_id": "R54867xR54826",
            "comparison_id": "R54867",
            "paper_id": "R54826",
            "text": "Shoreline development drives invasion of Phragmites australis and the loss of plant diversity on New England salt marshes abstract:\\u2002 the reed phragmites australis cav. is aggressively invading salt marshes along the atlantic coast of north america. we examined the interactive role of habitat alteration (i.e., shoreline development) in driving this invasion and its consequences for plant richness in new england salt marshes. we surveyed 22 salt marshes in narragansett bay, rhode island, and quantified shoreline development, phragmites cover, soil salinity, and nitrogen availability. shoreline development, operationally defined as removal of the woody vegetation bordering marshes, explained >90% of intermarsh variation in phragmites cover. shoreline development was also significantly correlated with reduced soil salinities and increased nitrogen availability, suggesting that removing woody vegetation bordering marshes increases nitrogen availability and decreases soil salinities, thus facilitating phragmites invasion. soil salinity (64%) and nitrogen availability (56%) alone explained a large proportion of variation in phragmites cover, but together they explained 80% of the variation in phragmites invasion success. both univariate and aggregate (multidimensional scaling) analyses of plant community composition revealed that phragmites dominance in developed salt marshes resulted in an almost three\u2010fold decrease in plant species richness. our findings illustrate the importance of maintaining integrity of habitat borders in conserving natural communities and provide an example of the critical role that local conservation can play in preserving these systems. in addition, our findings provide ecologists and natural resource managers with a mechanistic understanding of how human habitat alteration in one vegetation community can interact with species introductions in adjacent communities (i.e., flow\u2010on or adjacency effects) to hasten ecosystem degradation.",
            "contribution_ids": [
                "R54827"
            ]
        },
        {
            "instance_id": "R54867xR54828",
            "comparison_id": "R54867",
            "paper_id": "R54828",
            "text": "Quantifying the impact of an extreme climate event on species diversity in fragmented temperate forests: the effect of the October 1987 storm on British broadleaved woodlands we report the impact of an extreme weather event, the october 1987 severe storm, on fragmented woodlands in southern britain. we analysed ecological changes between 1971 and 2002 in 143 200\u2010m2 plots in 10 woodland sites exposed to the storm with an ecologically equivalent sample of 150 plots in 16 non\u2010exposed sites. comparing both years, understorey plant species\u2010richness, species composition, soil ph and woody basal area of the tree and shrub canopy were measured. we tested the hypothesis that the storm had deflected sites from the wider national trajectory of an increase in woody basal area and reduced understorey species\u2010richness associated with ageing canopies and declining woodland management. we also expected storm disturbance to amplify the background trend of increasing soil ph, a uk\u2010wide response to reduced atmospheric sulphur deposition. path analysis was used to quantify indirect effects of storm exposure on understorey species richness via changes in woody basal area and soil ph. by 2002, storm exposure was estimated to have increased mean species richness per 200 m2 by 32%. woody basal area changes were highly variable and did not significantly differ with storm exposure. increasing soil ph was associated with a 7% increase in richness. there was no evidence that soil ph increased more as a function of storm exposure. changes in species richness and basal area were negatively correlated: a 3.4% decrease in richness occurred for every 0.1\u2010m2 increase in woody basal area per plot. despite all sites substantially exceeding the empirical critical load for nitrogen deposition, there was no evidence that in the 15 years since the storm, disturbance had triggered a eutrophication effect associated with dominance of gaps by nitrophilous species. synthesis. although the impacts of the 1987 storm were spatially variable in terms of impacts on woody basal area, the storm had a positive effect on understorey species richness. there was no evidence that disturbance had increased dominance of gaps by invasive species. this could change if recovery from acidification results in a soil ph regime associated with greater macronutrient availability.",
            "contribution_ids": [
                "R54829"
            ]
        },
        {
            "instance_id": "R54867xR54839",
            "comparison_id": "R54867",
            "paper_id": "R54839",
            "text": "Altered stream-flow regimes and invasive plant species: the Tamarix case aim to test the hypothesis that anthropogenic alteration of stream-flow regimes is a key driver of compositional shifts from native to introduced riparian plant species. location the arid south-western united states; 24 river reaches in the gila and lower colorado drainage basins of arizona. methods we compared the abundance of three dominant woody riparian taxa (native populus fremontii and salix gooddingii , and introduced tamarix ) between river reaches that varied in stream-flow permanence (perennial vs. intermittent), presence or absence of an upstream flow-regulating dam, and presence or absence of municipal effluent as a stream water source. results populus and salix were the dominant pioneer trees along the reaches with perennial flow and a natural flood regime. in contrast, tamarix had high abundance (patch area and basal area) along reaches with intermittent stream flows (caused by natural and cultural factors), as well as those with dam-regulated flows. main conclusions stream-flow regimes are strong determinants of riparian vegetation structure, and hydrological alterations can drive dominance shifts to introduced species that have an adaptive suite of traits. deep alluvial groundwater on intermittent rivers favours the deep-rooted, stress-adapted tamarix over the shallower-rooted and more competitive populus and salix . on flow-regulated rivers, shifts in flood timing favour the reproductively opportunistic tamarix over populus and salix , both of which have narrow germination windows . the prevailing hydrological conditions thus favour a new dominant pioneer species in the riparian corridors of the american southwest. these results reaffirm the importance of reinstating stream-flow regimes (inclusive of groundwater flows) for re-establishing the native pioneer trees as the dominant forest type.",
            "contribution_ids": [
                "R54840"
            ]
        },
        {
            "instance_id": "R54867xR54857",
            "comparison_id": "R54867",
            "paper_id": "R54857",
            "text": "Case studies of the expansion of Acacia dealbata in the valley of the river Mino (Galicia, Spain) aim of study: acacia dealbata is a naturalized tree of invasive behaviour that has expanded from small plots associated with vineyards into forest ecosystems. our main objective is to find evidence to support the notion that disturbances, particularly forest fires, are important driving factors in the current expansion of a. dealbata. area of study: we mapped it current distribution using three study areas and assesses the temporal changes registered in forest cover in these areas of the valley of the river mino. material and methods: the analyses were based on visual interpretation of aerial photographs taken in 1985 and 2003 of three 1x1 km study areas and field works. main result: a 62.4%, 48.6% and 22.2% of the surface area was covered by a. dealbata in 2003 in pure or mixed stands. furthermore, areas composed exclusively of a. dealbata make up 33.8%, 15.2% and 5.7% of the stands. the transition matrix analyses between the two dates support our hypothesis that the areas currently covered by a. dealbata make up a greater proportion of the forest area previously classified as unwooded or open forest than those without a. dealbata cover. both of these surface types are the result of an important impact of fire in the region. within each area, a. dealbata is mainly located on steeper terrain, which is more affected by fires. research highlights: a. dealbata is becoming the dominant tree species over large areas and the invasion of this species gives rise to monospecific stands, which may have important implications for future fire regimes. keywords: fire regime; mimosa; plant invasion; silver wattle.",
            "contribution_ids": [
                "R54858"
            ]
        },
        {
            "instance_id": "R55219xR54967",
            "comparison_id": "R55219",
            "paper_id": "R54967",
            "text": "Succession of floodplain grasslands following reduction in land use intensity: the importance of environmental conditions, management and dispersal summary 1. classical ecological theory predicts a succession towards plant communities that are determined by environmental conditions. however, in ecological restoration, species composition often remains different from the predicted target community, compromising the success of restoration measures. 2. we analysed the relative importance of environmental conditions, management and distance to source populations for floodplain grassland succession following re-conversion from intensive to traditional use. the study was established at 33 grassland sites in central german river valleys. species composition, environmental variables, past and current management, and the distance to source populations of characteristic species of traditional management (indicator species) were recorded and compared using multivariate statistics. we further tested the speed of colonization by two indicator species, silaum silaus and serratula tinctoria , along transects from source populations into unoccupied fields. 4. the species composition of the successional grassland was mainly determined by elevation, total soil nitrogen, distance to remnant species-rich grasslands and frequency of mowing or grazing. elevation and distance were negatively, and frequency was positively related to the occurrence of late successional species. 5. colonization by indicator species was only dependent on the distance to source populations; other explanatory variables were not significant. migration from adjacent source sites of s. silaus and s. tinctoria into re-converted grasslands was slow, reaching only 40 m and 15 m after 15 years. 6. synthesis and applications . the results demonstrated the limitations of the deterministic view on plant succession and the high relative importance of propagule availability in grassland restoration. natural colonization will only be successful if source populations of the target species are adjacent to the restoration sites. artificial introduction techniques are recommended to overcome dispersal barriers.",
            "contribution_ids": [
                "R54968"
            ]
        },
        {
            "instance_id": "R55219xR54981",
            "comparison_id": "R55219",
            "paper_id": "R54981",
            "text": "Dealing with scarce data to understand how environmental gradients and propagule pressure shape fine-scale alien distribution patterns on coastal dunes questions: on sandy coastal habitats, factors related to substrate and to wind action vary along the sea\u2013inland ecotone, forming a marked directional disturbance and stress gradient. further, input of propagules of alien plant species associated to touristic exploitation and development is intense. this has contributed to establishment and spread of aliens in coastal systems. records of alien species in databases of such heterogeneous landscapes remain scarce, posing a challenge for statistical modelling. we address this issue and attempt to shed light on the role of environmental stress/disturbance gradients and propagule pressure on invasibility of plant communities in these typical model systems. \\n \\nlocation: sandy coasts of lazio (central italy). \\n \\nmethods: we proposed an innovative methodology to deal with low prevalence of alien occurrence in a data set and high cost of field-based sampling by taking advantage, through predictive modelling, of the strong interrelation between vegetation and abiotic features in coastal dunes. we fitted generalized additive models to analyse (1) overall patterns of alien occurrence and spread and (2) specific patterns of the most common alien species recorded. \\n \\nconclusion: even in the presence of strong propagule pressure, variation in local abiotic conditions can explain differences in invasibility within a local environment, and intermediate levels of natural disturbance and stress offer the best conditions for spread of alien species. however, in our model system, propagule pressure is actually the main determinant of alien species occurrence and spread. we demonstrated that extending the information of environmental features measured in a subsample of vegetation plots through predictive modelling allows complex questions in invasion biology to be addressed without requiring disproportionate funding and sampling effort.",
            "contribution_ids": [
                "R54982",
                "R54983"
            ]
        },
        {
            "instance_id": "R55219xR54989",
            "comparison_id": "R55219",
            "paper_id": "R54989",
            "text": "Effects of pre-existing submersed vegetation and propagule pressure on the invasion success of Hydrilla verticillata summary \\n \\n \\n1 \\nwith biological invasions causing widespread problems in ecosystems, methods to curb the colonization success of invasive species are needed. the effective management of invasive species will require an integrated approach that restores community structure and ecosystem processes while controlling propagule pressure of non-native species. \\n \\n2 \\nwe tested the hypotheses that restoring native vegetation and minimizing propagule pressure of invasive species slows the establishment of an invader. in field and greenhouse experiments, we evaluated (i) the effects of a native submersed aquatic plant species, vallisneria americana, on the colonization success of a non-native species, hydrilla verticillata; and (ii) the effects of h. verticillata propagule density on its colonization success. \\n \\n3 \\nresults from the greenhouse experiment showed that v. americana decreased h. verticillata colonization through nutrient draw-down in the water column of closed mesocosms, although data from the field experiment, located in a tidal freshwater region of chesapeake bay that is open to nutrient fluxes, suggested that v. americana did not negatively impact h. verticillata colonization. however, h. verticillata colonization was greater in a treatment of plastic v. americana look-alikes, suggesting that the canopy of v. americana can physically capture h. verticillata fragments. thus pre-emption effects may be less clear in the field experiment because of complex interactions between competitive and facilitative effects in combination with continuous nutrient inputs from tides and rivers that do not allow nutrient draw-down to levels experienced in the greenhouse. \\n \\n4 \\ngreenhouse and field tests differed in the timing, duration and density of propagule inputs. however, irrespective of these differences, propagule pressure of the invader affected colonization success except in situations when the native species could draw-down nutrients in closed greenhouse mesocosms. in that case, no propagules were able to colonize. \\n \\n5 \\nsynthesis and applications. we have shown that reducing propagule pressure through targeted management should be considered to slow the spread of invasive species. this, in combination with restoration of native species, may be the best defence against non-native species invasion. thus a combined strategy of targeted control and promotion of native plant growth is likely to be the most sustainable and cost-effective form of invasive species management.",
            "contribution_ids": [
                "R54990",
                "R54991"
            ]
        },
        {
            "instance_id": "R55219xR54998",
            "comparison_id": "R55219",
            "paper_id": "R54998",
            "text": "COMPETITION BETWEEN NATIVE PERENNIAL AND EXOTIC ANNUAL GRASSES: IMPLICATIONS FOR AN HISTORICAL INVASION \"though established populations of invasive species can exert substantial competitive effects on native populations, exotic propagules may require disturbances that decrease competitive interference by resident species in order to become established. we compared the relative competitiveness of native perennial and exotic annual grasses in a california coastal prairie grassland to test whether the introduction of exotic propagules to coastal grasslands in the 19th century was likely to have been sufficient to shift community composition from native perennial to exotic annual grasses. under experimental field con- ditions, we compared the aboveground productivity of native species alone to native species competing with exotics, and exotic species alone to exotic species competing with natives. over the course of the four-year experiment, native grasses became increasingly dominant in the mixed-assemblage plots containing natives and exotics. although the competitive interactions in the first growing season favored the exotics, over time the native grasses significantly reduced the productivity of exotic grasses. the number of exotic seedlings emerging and the biomass of dicot seedlings removed during weeding were also significantly lower in plots containing natives as compared to plots that did not contain natives. we found evidence that the ability of established native perennial species to limit space available for exotic annual seeds to germinate and to limit the light available to exotic seedlings reduced exotic productivity and shifted competitive interactions in favor of the natives. if interactions between native perennial and exotic annual grasses follow a similar pattern in other coastal grassland habitats, then the introduction of exotic grass propagules alone without changes in land use or climate, or both, was likely insufficient to convert the region's grasslands.\"",
            "contribution_ids": [
                "R54999"
            ]
        },
        {
            "instance_id": "R55219xR55030",
            "comparison_id": "R55219",
            "paper_id": "R55030",
            "text": "GRASSLAND DIVERSITY AND PRODUCTIVITY: THE INTERPLAY OF RESOURCE AVAILABILITY AND PROPAGULE POOLS processes operating at multiple spatial scales govern the structure and functioning of ecological communities. we conducted a resource manipulation and propagule addition experiment in grassland to evaluate the interaction of local resource availability and propagule pools in governing local-scale plant colonization, biodiversity, and aboveground productivity. the availabilities of establishment microsites and water were manipulated in field plots for two years through the application of experimental soil disturbances and irrigation, respectively. resource manipulations led to increased invasibility of the community, as predicted by the theory of fluctuating resources. rates of colonization, enhanced by the sowing of 32 grassland species, increased plant diversity and aboveground productivity, but to a greater extent under conditions of resource enrichment. although resource enrichment generally increased diversity and productivity, these responses were contingent upon species availability and tended to be more pronounced in the presence of an expanded propagule pool. these findings suggest that biodiversity at the level of the available propagule pool and fluctuations in resources interact to regulate local resident diversity and productivity by determining opportunities for species sorting, by mediating community assembly, and by governing the potential for functional compensation in the community.",
            "contribution_ids": [
                "R55031"
            ]
        },
        {
            "instance_id": "R55219xR55074",
            "comparison_id": "R55219",
            "paper_id": "R55074",
            "text": "Predicting invasions by woody species in a temperate zone: a test of three risk assessment schemes in the Czech Republic (Central Europe) to assess the validity of previously developed risk assessment schemes in the conditions of central europe, we tested (1) australian weed risk assessment scheme (wra; pheloung et al. 1999); (2) wra with additional analysis by daehler et al. (2004); and (3) decision tree scheme of reichard and hamilton (1997) developed in north america, on a data set of 180 alien woody species commonly planted in the czech republic. this list included 17 invasive species, 9 naturalized but non\u2010invasive, 31 casual aliens, and 123 species not reported to escape from cultivation. the wra model with additional analysis provided best results, rejecting 100% of invasive species, accepting 83.8% of non\u2010invasive, and recommending further 13.0% for additional analysis. overall accuracy of the wra model with additional analysis was 85.5%, higher than that of the basic wra scheme (67.9%) and the reichard\u2013hamilton model (61.6%). only the reichard\u2013hamilton scheme accepted some invaders. the probability that an accepted species will become an invader was zero for both wra models and 3.2% for the reichard\u2013hamilton model. the probability that a rejected species would have been an invader was 77.3% for both wra models and 24.0% for the reichard\u2013hamilton model. it is concluded that the wra model, especially with additional analysis, appears to be a promising template for building a widely applicable system for screening out invasive plant introductions.",
            "contribution_ids": [
                "R55075",
                "R57005",
                "R57006",
                "R57007"
            ]
        },
        {
            "instance_id": "R55219xR55076",
            "comparison_id": "R55219",
            "paper_id": "R55076",
            "text": "The relative importance of latitude matching and propagule pressure in the colonization success of an invasive forb \"factors that influence the early stages of invasion can be critical to invasion success, yet are seldom studied. in particular, broad pre-adaptation to recipient climate may importantly influence early colonization success, yet few studies have explicitly examined this. i performed an experiment to determine how similarity between seed source and transplant site latitude, as a general indicator of pre-adaptation to climate, interacts with propagule pressure (100, 200 and 400 seeds/pot) to influence early colonization success of the widespread north american weed, st. john's wort hypericum perforatum. seeds originating from seven native european source populations were sown in pots buried in the ground in a field in western montana. seed source populations were either similar or divergent in latitude to the recipient transplant site. across seed density treatments, the match between seed source and recipient latitude did not affect the proportion of pots colonized or the number of individual colonists per pot. in contrast, propagule pressure had a significant and positive effect on colonization. these results suggest that propagules from many climatically divergent source populations can be viable invaders.\"",
            "contribution_ids": [
                "R55077"
            ]
        },
        {
            "instance_id": "R55219xR55083",
            "comparison_id": "R55219",
            "paper_id": "R55083",
            "text": "ALIEN FISHES IN CALIFORNIA WATERSHEDS: CHARACTERISTICS OF SUCCESSFUL AND FAILED INVADERS the literature on alien animal invaders focuses largely on successful invasions over broad geographic scales and rarely examines failed invasions. as a result, it is difficult to make predictions about which species are likely to become successful invaders or which environments are likely to be most susceptible to invasion. to address these issues, we developed a data set on fish invasions in watersheds throughout california (usa) that includes failed introductions. our data set includes information from three stages of the invasion process (establishment, spread, and integration). we define seven categorical predictor variables (trophic status, size of native range, parental care, maximum adult size, physiological tolerance, distance from nearest native source, and propagule pressure) and one continuous predictor variable (prior invasion success) for all introduced species. using an information-theoretic approach we evaluate 45 separate hypotheses derived from the invasion literature over these three sta...",
            "contribution_ids": [
                "R55084"
            ]
        },
        {
            "instance_id": "R55219xR55095",
            "comparison_id": "R55219",
            "paper_id": "R55095",
            "text": "The effect of propagule size on the invasion of an alien insect \"1. the movement of species from their native ranges to alien environments is a serious threat to biological diversity. the number of individuals involved in an invasion provides a strong theoretical basis for determining the likelihood of establishment of an alien species. 2. here a field experiment was used to manipulate the critical first stages of the invasion of an alien insect, a psyllid weed biocontrol agent, arytainilla spartiophila forster, in new zealand and to observe the progress of the invasion over the following 6 years. 3. fifty-five releases were made along a linear transect 135 km long: 10 releases of two, four, 10, 30 and 90 psyllids and five releases of 270 psyllids. six years after their original release, psyllids were present in 22 of the 55 release sites. analysis by logistic regression showed that the probability of establishment was significantly and positively related to initial release size, but that this effect was important only during the psyllids' first year in the field. 4. although less likely to establish, some of the releases of two and four psyllids did survive 5 years in the field. overall, releases that survived their first year had a 96% chance of surviving thereafter, providing the release site remained secure. the probability of colony loss due to site destruction remained the same throughout the experiment, whereas the probability of natural extinction reduced steeply over time. 5. during the first year colonies were undergoing a process of establishment and, in most cases, population size decreased. after this first year, a period of exponential growth ensued. 6. a lag period was observed before the populations increased dramatically in size. this was thought to be due to inherent lags caused by the nature of population growth, which causes the smaller releases to appear to have a longer lag period.\"",
            "contribution_ids": [
                "R55096"
            ]
        },
        {
            "instance_id": "R55219xR55122",
            "comparison_id": "R55219",
            "paper_id": "R55122",
            "text": "Behavioural plasticity associated with propagule size, resources, and the invasion success of the Argentine ant Linepithema humile summary 1. the number of individuals involved in an invasion event, or \u2018propagule size\u2019, has a strong theoretical basis for influencing invasion success. however, rarely has propagule size been experimentally manipulated to examine changes in invader behaviour, and propagule longevity and success. 2. we manipulated propagule size of the invasive argentine ant linepithema humile in laboratory and field studies. laboratory experiments involved l. humile propagules containing two queens and 10, 100, 200 or 1000 workers. propagules were introduced into arenas containing colonies of queens and 200 workers of the competing native ant monomorium antarcticum . the effects of food availability were investigated via treatments of only one central resource, or 10 separated resources. field studies used similar colony sizes of l. humile , which were introduced into novel environments near an invasion front. 3. in laboratory studies, small propagules of l. humile were quickly annihilated. only the larger propagule size survived and killed the native ant colony in some replicates. aggression was largely independent of food availability, but the behaviour of l. humile changed substantially with propagule size. in larger propagules, aggressive behaviour was significantly more frequent, while l. humile were much more likely to avoid conflict in smaller propagules. 4. in field studies, however, propagule size did not influence colony persistence. linepithema humile colonies persisted for up to 2 months, even in small propagules of 10 workers. factors such as temperature or competitor abundance had no effect, although some colonies were decimated by m. antarcticum . 5. synthesis and applications. although propagule size has been correlated with invasion success in a wide variety of taxa, our results indicate that it will have limited predictive power with species displaying behavioural plasticity. we recommend that aspects of animal behaviour be given much more consideration in attempts to model invasion success. secondly, areas of high biodiversity are thought to offer biotic resistance to invasion via the abundance of predators and competitors. invasive pests such as l. humile appear to modify their behaviour according to local conditions, and establishment was not related to resource availability. we cannot necessarily rely on high levels of native biodiversity to repel invasions.",
            "contribution_ids": [
                "R55123",
                "R55124"
            ]
        },
        {
            "instance_id": "R55219xR55150",
            "comparison_id": "R55219",
            "paper_id": "R55150",
            "text": "Propagule pressure and colony social organization are associated with the successful invasion and rapid range expansion of fire ants in China we characterized patterns of genetic variation in populations of the fire ant solenopsis invicta in china using mitochondrial dna sequences and nuclear microsatellite loci to test predictions as to how propagule pressure and subsequent dispersal following establishment jointly shape the invasion success of this ant in this recently invaded area. fire ants in wuchuan (guangdong province) are genetically differentiated from those found in other large infested areas of china. the immediate source of ants in wuchuan appears to be somewhere near texas, which ranks first among the southern usa infested states in the exportation of goods to china. most colonies from spatially distant, outlying areas in china are genetically similar to one another and appear to share a common source (wuchuan, guangdong province), suggesting that long\u2010distance jump dispersal has been a prevalent means of recent spread of fire ants in china. furthermore, most colonies at outlier sites are of the polygyne social form (featuring multiple egg\u2010laying queens per nest), reinforcing the important role of this social form in the successful invasion of new areas and subsequent range expansion following invasion. several analyses consistently revealed characteristic signatures of genetic bottlenecks for s. invicta populations in china. the results of this study highlight the invasive potential of this pest ant, suggest that the magnitude of international trade may serve as a predictor of propagule pressure and indicate that rates and patterns of subsequent range expansion are partly determined by the interplay between species traits and the trade and transportation networks.",
            "contribution_ids": [
                "R55151"
            ]
        },
        {
            "instance_id": "R56110xR56080",
            "comparison_id": "R56110",
            "paper_id": "R56080",
            "text": "The island biogeography of exotic bird species aim: a recent upsurge of interest in the island biogeography of exotic species has followed from the argument that they may provide valuable information on the natural processes structuring island biotas. here, we use data on the occurrence of exotic bird species across oceanic islands worldwide to demonstrate an alternative and previously untested hypothesis that these distributional patterns are a simple consequence of where humans have released such species, and hence of the number of species released. location: islands around the world. methods: statistical analysis of published information on the numbers of exotic bird species introduced to, and established on, islands around the world. results: established exotic birds showed very similar species-area relationships to native species, but different species-isolation relationships. however, in both cases the relationship for established exotics simply mimicked that for the number of exotic bird species introduced. exotic bird introductions scaled positively with human population size and island isolation, and islands that had seen more native species extinctions had had more exotic species released. main conclusion: the island biogeography of exotic birds is primarily a consequence of human, rather than natural, processes. \u00a9 2007 the authors journal compilation \u00a9 2007 blackwell publishing ltd.",
            "contribution_ids": [
                "R56081"
            ]
        },
        {
            "instance_id": "R56945xR56537",
            "comparison_id": "R56945",
            "paper_id": "R56537",
            "text": "Widespread association of the invasive ant Solenopsis invicta with an invasive mealybug \"factors such as aggressiveness and adaptation to disturbed environments have been suggested as important characteristics of invasive ant species, but diet has rarely been considered. however, because invasive ants reach extraordinary densities at introduced locations, increased feeding efficiency or increased exploitation of new foods should be important in their success. earlier studies suggest that honeydew produced by homoptera (e.g., aphids, mealybugs, scale insects) may be important in the diet of the invasive ant species solenopsis invicta. to determine if this is the case, we studied associations of s. invicta and homoptera in east texas and conducted a regional survey for such associations throughout the species' range in the southeast united states. in east texas, we found that s. invicta tended ho- moptera extensively and actively constructed shelters around them. the shelters housed a variety of homoptera whose frequency differed according to either site location or season, presumably because of differences in host plant availability and temperature. overall, we estimate that the honeydew produced in homoptera shelters at study sites in east texas could supply nearly one-half of the daily energetic requirements of an s. invicta colony. of that, 70% may come from a single species of invasive homoptera, the mealybugantonina graminis. homoptera shelters were also common at regional survey sites and a. graminis occurred in shelters at nine of 11 survey sites. a comparison of shelter densities at survey sites and in east texas suggests that our results from east texas could apply throughout the range of s. invicta in the southeast united states. antonina graminis may be an ex- ceptionally important nutritional resource for s. invicta in the southeast united states. while it remains largely unstudied, the tending of introduced or invasive homoptera also appears important to other, and perhaps all, invasive ant species. exploitative or mutually beneficial associations that occur between these insects may be an important, previously unrecognized factor promoting their success.\"",
            "contribution_ids": [
                "R56538"
            ]
        },
        {
            "instance_id": "R56945xR56541",
            "comparison_id": "R56945",
            "paper_id": "R56541",
            "text": "Seed and seedling demography of invasive and native trees of subtropical Pacific islands abstract bischofia javanica is an invasive tree of the bonin islands in the western pacific, japan. this species has aggressive growth, competitively replacing native trees in the natural forest of the islands. the aim of this study was to examine seed and seedling factors which might confer an advantage to the establishment of bischofia over native trees. during a 5-yr period we compared the demographic parameters of early life history of bischofia and elaeocarpus photiniaefolius, a native canopy dominant, in actively invaded forests. predation of elaeocarpus seeds by in troduced rodents was much higher before (27.9\u201332.9%) and after (41.3\u2013100%) dispersal of seeds than that of b. javanica. most elaeocarpus seeds lost viability ca. 6 mo after burial in forest soil while some seeds of bischofia remained viable for more than 2 yr. seedling survival in the first 2 yr was much higher in bischofia (16%) than in elaeocarpus (1.3%). the high persistence of bischofia in the shade, coupled to its rapid acclimation to high light levels, is an unusual combination because in forest tree species there is generally a trade-off between seedling survival in the shade and response to canopy opening. compared with a native canopy dominant, greater seed longevity, lower seed predation by introduced rodents, longer fruiting periods and the ability to form seedling banks under closed canopy appear to have contributed to the invasive success of bischofia on the bonin islands. nomenclature: satake et al. (1989).",
            "contribution_ids": [
                "R56542"
            ]
        },
        {
            "instance_id": "R56945xR56563",
            "comparison_id": "R56945",
            "paper_id": "R56563",
            "text": "Positive interactions between nonindigenous species facilitate transport by human vectors numerous studies have shown how interactions between nonindigenous spe- cies (nis) can accelerate the rate at which they establish and spread in invaded habitats, leading to an \"invasional meltdown.\" we investigated facilitation at an earlier stage in the invasion process: during entrainment of propagules in a transport pathway. the introduced bryozoan watersipora subtorquata is tolerant of several antifouling biocides and a common component of hull-fouling assemblages, a major transport pathway for aquatic nis. we predicted that colonies of w. subtorquata act as nontoxic refugia for other, less tolerant species to settle on. we compared rates of recruitment of w. subtorquata and other fouling organisms to surfaces coated with three antifouling paints and a nontoxic primer in coastal marinas in queensland, australia. diversity and abundance of fouling taxa were compared between bryozoan colonies and adjacent toxic or nontoxic paint surfaces. after 16 weeks immersion, w. subtorquata covered up to 64% of the tile surfaces coated in antifouling paint. twenty-two taxa occurred exclusively on w. subtorquata and were not found on toxic surfaces. other fouling taxa present on toxic surfaces were up to 248 times more abundant on w. subtorquata. because biocides leach from the paint surface, we expected a positive relationship between the size of w. subtorquata colonies and the abundance and diversity of epibionts. to test this, we compared recruitment of fouling organisms to mimic w. subtorquata colonies of three different sizes that had the same total surface area. sec- ondary recruitment to mimic colonies was greater when the surrounding paint surface contained biocides. contrary to our predictions, epibionts were most abundant on small mimic colonies with a large total perimeter. this pattern was observed in encrusting and erect bryozoans, tubiculous amphipods, and serpulid and sabellid polychaetes, but only in the presence of toxic paint. our results show that w. subtorquata acts as a foundation species for fouling assemblages on ship hulls and facilitates the transport of other species at greater abundance and frequency than would otherwise be possible. invasion success may be increased by positive interactions between nis that enhance the delivery of prop- agules by human transport vectors.",
            "contribution_ids": [
                "R56564"
            ]
        },
        {
            "instance_id": "R56945xR56565",
            "comparison_id": "R56945",
            "paper_id": "R56565",
            "text": "Invasional meltdown potential: Facilitation between introduced plants and mammals on French Mediterranean islands abstract in the increasingly important domain of insular invasion ecology, the role of facilitation between different introduced taxa has been mentioned, but rarely studied. this paper outlines facilitation between introduced mammals and the invasive succulents carpobrotus edulis and c. aff. acinaciformis on offshore islands in southeast france. rats and rabbits are the primary seed dispersers of carpobrotus sp. on the islands studied. no such dispersal activity was detected on the adjacent mainland. seed digestion by rats and rabbits also enhanced percent seed germination and speed, in spite of an associated reduction in seed size. in return, carpobrotus provides a water/energy-rich food source during the dry summer season, thus demonstrating a clear case of mutualism between invaders.",
            "contribution_ids": [
                "R56566"
            ]
        },
        {
            "instance_id": "R56945xR56608",
            "comparison_id": "R56945",
            "paper_id": "R56608",
            "text": "Facilitation and interference underlying the association between the woody invaders Pyracantha angustifolia and Ligustrum lucidum abstract questions: 1. is there any post-dispersal positive effect of the exotic shrub pyracantha angustifolia on the success of ligustrum lucidum seedlings, as compared to the effect of the native condalia montana or the open herbaceous patches between shrubs? 2. is the possible facilitation by pyracantha and/or condalia related to differential emergence, growth, or survival of ligustrum seedlings under their canopies? location: c\u00f3rdoba, central argentina. methods: we designed three treatments, in which ten mature individuals of pyracantha, ten of the dominant native shrub condalia montana, and ten patches without shrub cover were involved. in each treatment we planted seeds and saplings of ligustrum collected from nearby natural populations. seedlings emerging from the planted seeds were harvested after one year to measure growth. survival of the transplanted saplings was recorded every two month during a year. half of the planted seeds and transplanted saplings were cage-protected from rodents. results: ligustrum seedling emergence did not differ among treatments while growth was significantly higher in the absence of shrub cover. sapling survival was significantly higher under the canopy of pyracantha, intermediate under condalia, and lowest in the absence of shrub cover. caging did not affect growth but enhanced seedling emergence and sapling survival. conclusion: the differential sapling survival in the shrub canopy treatments is consistent with natural sapling distribution. pyracantha and, less so, condalia, has a nurse-plant effect on ligustrum. this results from contrasting effects of the shrubs on different stages of the life cycle of ligustrum: no effect on seedling emergence, negative on seedling growth, and positive on sapling survival. this suggests that efforts to control the expansion of ligustrum over the landscape should tackle pyracantha as well. nomenclature: zuloaga & morrone (1996, 1999).",
            "contribution_ids": [
                "R56609"
            ]
        },
        {
            "instance_id": "R56945xR56680",
            "comparison_id": "R56945",
            "paper_id": "R56680",
            "text": "Intra-regional transportation of a tugboat fouling community between the ports of Recife and Natal, northeast Brazil \" this study aimed to identify the incrusting and sedentary animals associated with the hull of a tugboat active in the ports of pernambuco and later loaned to the port of natal, rio grande do norte. thus, areas with dense biofouling were scraped and the species then classified in terms of their bioinvasive status for the brazilian coast. six were native to brazil, two were cryptogenic and 16 nonindigenous; nine of the latter were classified as established (musculus lateralis, sphenia fragilis, balanus trigonus, biflustra savartii, botrylloides nigrum, didemnum psammatodes, herdmania pallida, microscosmus exasperatus, and symplegma rubra) and three as invasive (mytilopsis leucophaeta, amphibalanus reticulatus, and striatobalanus amaryllis). the presence of m. leucophaeata, amphibalanus eburneus and a. reticulatus on the boat's hull propitiated their introduction onto the natal coast. the occurrence of a great number of tunicate species in natal reflected the port area's benthic diversity and facilitated the inclusion of two bivalves - musculus lateralis and sphenia fragilis - found in their siphons and in the interstices between colonies or individuals, respectively. the results show the role of biofouling on boat hulls in the introduction of nonindigenous species and that the port of recife acts as a source of some species. \"",
            "contribution_ids": [
                "R56681"
            ]
        },
        {
            "instance_id": "R56945xR56732",
            "comparison_id": "R56945",
            "paper_id": "R56732",
            "text": "Identification of alien predators that should not be removed for controlling invasive crayfish threatening endangered odonates 1. \\nwhen multiple invasive species coexist in the same ecosystem and their diets change as they grow, determining whether to eradicate any particular invader is difficult because of complex predator\u2013prey interactions. \\n \\n2. \\na stable isotope food-web analysis was conducted to explore an appropriate management strategy for three potential alien predators (snakehead channa argus, bullfrog rana catesbeiana, red-eared slider turtle trachemys scripta elegans) of invasive crayfish procambarus clarkii that had severely reduced the densities of endangered odonates in a pond in japan. \\n \\n3. \\nthe stable isotope analysis demonstrated that medium- and small-sized snakeheads primarily depended on crayfish and stone moroko pseudorasbora parva. both adult and juvenile bullfrogs depended on terrestrial arthropods, and juveniles exhibited a moderate dependence on crayfish. the turtle showed little dependence on crayfish. \\n \\n4. \\nthese results suggest that eradication of snakeheads risks the possibility of mesopredator release, while such risk appears to be low in other alien predators. copyright \u00a9 2011 john wiley & sons, ltd.",
            "contribution_ids": [
                "R56733"
            ]
        },
        {
            "instance_id": "R56945xR56756",
            "comparison_id": "R56945",
            "paper_id": "R56756",
            "text": "Does mutualism drive the invasion of two alien species? The case of Solenopsis invicta and Phenacoccus solenopsis although mutualism between ants and honeydew-producing hemipterans has been extensively recognized in ecosystem biology, however few attempts to test the hypothesis that mutualism between two alien species leads to the facilitation of the invasion process. to address this problem, we focus on the conditional mutualism between s. invicta and p. solenopsis by field investigations and indoor experiments. in the laboratory, ant colony growth increased significantly when ants had access to p. solenopsis and animal-based food. honeydew produced by p. solenopsis also improved the survival of ant workers. in the field, colony density of p. solenopsis was significantly greater on plots with ants than on plots without ants. the number of mealybug mummies on plants without fire ants was almost three times that of plants with fire ants, indicating a strong effect of fire ants on mealybug survival. in addition, the presence of s. invicta successfully contributed to the spread of p. solenopsis. the quantity of honeydew consumption by s. invicta was significantly greater than that of a presumptive native ant, tapinoma melanocephalum. when compared with the case without ant tending, mealybugs tended by ants matured earlier and their lifespan and reproduction increased. t. melanocephalum workers arrived at honeydew more quickly than s. invicta workers, while the number of foraging s. invicta workers on plants steadily increased, eventually exceeding that number of t. melanocephalum foragers. overall, these results suggest that the conditional mutualism between s. invicta and p. solenopsis facilitates population growth and fitness of both species. s. invicta tends to acquire much more honeydew and drive away native ants, promoting their predominance. these results suggest that the higher foraging tempo of s. invicta may provide more effective protection of p. solenopsis than native ants. thus mutualism between these two alien species may facilitate the invasion success of both species.",
            "contribution_ids": [
                "R56757"
            ]
        },
        {
            "instance_id": "R56945xR56762",
            "comparison_id": "R56945",
            "paper_id": "R56762",
            "text": "An invasive tree alters the structure of seed dispersal networks between birds and plants in French Polynesia aim\\u2002 we studied how the abundance of the highly invasive fruit\u2010bearing tree miconia calvescens dc. influences seed dispersal networks and the foraging patterns of three avian frugivores.",
            "contribution_ids": [
                "R56763"
            ]
        },
        {
            "instance_id": "R56945xR56795",
            "comparison_id": "R56945",
            "paper_id": "R56795",
            "text": "Invasive parasites in multiple invasive hosts: the arrival of a new host revives a stalled prior parasite invasion \"the success of a biological invasion can depend upon other invasions; and in some cases, an earlier invader may fail to spread until facilitated by a second invader. our study documents a case whereby an invasive parasite has remained patchily distributed for decades due to the fragmented nature of available hosts; but the recent arrival of a broadly distributed alternative invasive host species provides an opportunity for the parasite to expand its range considerably. at least 20 years ago, endoparasitic pentastomids (raillietiella frenata) were brought with their native host, the invasive asian house gecko hemidactylus frenatus, to the port city of darwin in tropical australia. these geckos rarely disperse away from human habitation, restricting the transmission of their parasites to urban environments \u2013 and thus, their pentastomids have remained patchily distributed and have only been recorded in scant localities, primarily surrounding darwin. the recent range expansion of the invasive cane toad rhinella marina into the darwin area has provided an alternative host for this pentastomid. our results show that the cane toad is a competent host for ra. frenata\u2013 toads shed fully embryonated pentastomid eggs in their faeces \u2013 and that pentastomids are now common in cane toads near darwin. likely reflecting the tendency for the parasite's traditional definitive host (the asian house gecko) and only known intermediate host (the cockroach) to reside around buildings, we found the prevalence of this parasite follows an urban distribution. because cane toads are widely distributed through urban and rural habitat and can shed viable pentastomid eggs, the toad invasion is likely to facilitate the parasite's spread across the tropics, into areas (and additional susceptible hosts) that were previously inaccessible to it.\"",
            "contribution_ids": [
                "R56796"
            ]
        },
        {
            "instance_id": "R56945xR56849",
            "comparison_id": "R56945",
            "paper_id": "R56849",
            "text": "The effects of mice on stoats in southern beech forests introduced stoats (mustela erminea) are important invasive predators in southern beech (nothofagus sp.) forests in new zealand. in these forests, one of their primary prey species \u2013 introduced house mice (mus musculus), fluctuate dramatically between years, driven by the irregular heavy seed-fall (masting) of the beech trees. we examined the effects of mice on stoats in this system by comparing the weights, age structure and population densities of stoats caught on two large islands in fiordland, new zealand \u2013 one that has mice (resolution island) and one that does not (secretary island). on resolution island, the stoat population showed a history of recruitment spikes and troughs linked to beech masting, whereas the secretary island population had more constant recruitment, indicating that rodents are probably the primary cause for the \u2018boom and bust\u2019 population cycle of stoats in beech forests. resolutions island stoats were 10% heavier on average than secretary island stoats, supporting the hypothesis that the availability of larger prey (mice verses w\u0113t\u0101) leads to larger stoats. beech masting years on this island were also correlated with a higher weight for stoats born in the year of the masting event. the detailed demographic information on the stoat populations of these two islands supports previously suggested interactions among mice, stoats and beech masting. these interactions may have important consequences for the endemic species that interact with fluctuating populations of mice and stoats.",
            "contribution_ids": [
                "R56850"
            ]
        },
        {
            "instance_id": "R56945xR56907",
            "comparison_id": "R56945",
            "paper_id": "R56907",
            "text": "Novel species interactions in a highly modified estuary: association of largemouth bass with Brazilian waterweed Egeria densa abstractfrequent invasions in coastal ecosystems result in novel species interactions that have unknown ecological consequences. largemouth bass micropterus salmoides and brazilian waterweed egeria densa are introduced species in the sacramento\u2013san joaquin river delta (the delta) of california, a highly modified estuary. in this system, brazilian waterweed and largemouth bass have seen marked increases in distribution and abundance in recent decades, but their association has not been specifically studied until now. we conducted a 2-year, bimonthly electrofishing survey with simultaneous sampling of water quality and submerged aquatic vegetation (sav) biomass at 33 locations throughout the delta. we used generalized linear mixed models to assess the relative influences of water temperature, conductivity, secchi depth, and sav biomass density on the abundance of both juvenile-sized and larger largemouth bass. water temperature had a positive relationship with the abundance of both size-classes, but only ju...",
            "contribution_ids": [
                "R56908"
            ]
        },
        {
            "instance_id": "R56945xR56923",
            "comparison_id": "R56945",
            "paper_id": "R56923",
            "text": "Early life stages of exotic gobiids as new hosts for unionid glochidia summary \\nintroduction of an exotic species has the potential to alter interactions between fish and bivalves; yet our knowledge in this field is limited, not least by lack of studies involving fish early life stages (els). \\nhere, for the first time, we examine glochidial infection of fish els by native and exotic bivalves in a system recently colonised by two exotic gobiid species (round goby neogobius melanostomus, tubenose goby proterorhinus semilunaris) and the exotic chinese pond mussel anodonta woodiana. \\nthe els of native fish were only rarely infected by native glochidia. by contrast, exotic fish displayed significantly higher native glochidia prevalence and mean intensity of infection than native fish (17 versus 2% and 3.3 versus 1.4 respectively), inferring potential for a parasite spillback/dilution effect. exotic fish also displayed a higher parasitic load for exotic glochidia, inferring potential for invasional meltdown. compared to native fish, presence of gobiids increased the total number of glochidia transported downstream on drifting fish by approximately 900%. \\nwe show that gobiid els are a novel, numerous and \u2018attractive\u2019 resource for unionid glochidia. as such, unionids could negatively affect gobiid recruitment through infection-related mortality of gobiid els and/or reinforce downstream unionid populations through transport on drifting gobiid els. these implications go beyond what is suggested in studies of older life stages, thereby stressing the importance of an holistic ontogenetic approach in ecological studies.",
            "contribution_ids": [
                "R56924"
            ]
        },
        {
            "instance_id": "R56945xR56929",
            "comparison_id": "R56945",
            "paper_id": "R56929",
            "text": "Asiatic Callosciurus squirrels as seed dispersers of exotic plants in the Pampas abstract seed dispersal by exotic mammals exemplifies mutualistic interactions that can modify the habitat by facilitating the establishment of certain species. we examined the potential for endozoochoric dispersal of exotic plants by callosciurus erythraeus introduced in the pampas region of argentina. we identified and characterized entire and damaged seeds found in squirrel faeces and evaluated the germination capacity and viability of entire seeds in laboratory assays. we collected 120 samples of squirrel faeces that contained 883 pellets in seasonal surveys conducted between july 2011 and june 2012 at 3 study sites within the main invasion focus of c. erythraeus in argentina. we found 226 entire seeds in 21% of the samples belonging to 4 species of exotic trees and shrubs. germination in laboratory assays was recorded for morus alba and casuarina sp.; however, germination percentage and rate was higher for seeds obtained from the fruits than for seeds obtained from the faeces. the largest size of entire seeds found in the faeces was 4.2\\u2009\u00d7\\u20094.0\\u2009mm, whereas the damaged seeds had at least 1 dimension \u2265 4.7\\u2009mm. our results indicated that c. erythraeus can disperse viable seeds of at least 2 species of exotic trees. c. erythraeus predated seeds of other naturalized species in the region. the morphometric description suggested a restriction on the maximum size for the passage of entire seeds through the digestive tract of squirrels, which provides useful information to predict its role as a potential disperser or predator of other species in other invaded communities.",
            "contribution_ids": [
                "R56930"
            ]
        },
        {
            "instance_id": "R57101xR56949",
            "comparison_id": "R57101",
            "paper_id": "R56949",
            "text": "Biological control attempts by introductions against pest insects in the field in Canada abstract this is an analysis of the attempts to colonize at least 208 species of parasites and predators on about 75 species of pest insects in the field in canada. there was colonization by about 10% of the species that were introduced in totals of under 5,000 individuals, 40% of those introduced in totals of between 5,000 and 31,200, and 78% of those introduced in totals of over 31,200. indications exist that initial colonizations may be favoured by large releases and by selection of release sites that are semi-isolated and not ecologically complex but that colonizations are hindered when the target species differs taxonomically from the species from which introduced agents originated and when the release site lacks factors needed for introduced agents to survive or when it is subject to potentially-avoidable physical disruptions. there was no evidence that the probability of colonization was increased when the numbers of individuals released were increased by laboratory propagation. about 10% of the attempts were successful from the economic viewpoint. successes may be overestimated if the influence of causes of coincidental, actual, or supposed changes in pest abundance are overlooked. most of the successes were by two or more kinds of agents of which at least one attacked species additional to the target pests. unplanned consequences of colonization have not been sufficiently harmful to warrant precautions to the extent advocated by turnbull and chant but are sufficiently potentially dangerous to warrant the restriction of all colonization attempts to biological control experts. it is concluded that most failures were caused by inadequate procedures, rather than by any weaknesses inherent in the method, that those inadequacies can be avoided in the future, and therefore that biological control of pest insects has much unrealized potential for use in canada.",
            "contribution_ids": [
                "R56950"
            ]
        },
        {
            "instance_id": "R57101xR56951",
            "comparison_id": "R57101",
            "paper_id": "R56951",
            "text": "The potential impact of the New Zealand flatworm, a predator of earthworms, in western Europe \"the new zealand flatworm arthurdendyus triangulatus (=artioposthia triangulata) is an example of an invasive organism that, by reducing lumbricid earthworm populations, could have a major impact on soil ecosystems in britain and the faroe islands. how it was introduced into the british isles is not known, but like many invasive species, it is suspected that it was introduced by humans and was associated with the trade between new zealand and britain. once established in britain it found in the large, readily available earthworm population a niche that it could exploit. the microclimate of the forests in the center and south of the south island of new zealand from whence the flatworm came is similar to that in parts of the british isles and consequently conducive to its survival. although when compared with many other invertebrate introductions (e.g., insects) the flatworm's rate of increase has been slow, a retrospective study strongly suggested that, in scotland, they spread from botanic gardens to horti...\"",
            "contribution_ids": [
                "R56952"
            ]
        },
        {
            "instance_id": "R57101xR56959",
            "comparison_id": "R57101",
            "paper_id": "R56959",
            "text": "Interception frequency of exotic bark and ambrosia beetles (Coleoptera: Scolytinae) and relationship with establishment in New Zealand and worldwide \" scolytinae species are among the most damaging forest pests, and many of them are invasive. over 1500 scolytinae interceptions were recorded at new zealand's borders between 1950 and 2000. among the 103 species were dendroctonus ponderosae, ips typographus, and other high-risk species, but actual arrivals probably included many more species. interceptions were primarily associated with dunnage, casewood (crating), and sawn timber, and originated from 59 countries, mainly from europe, australasia, northern asia, and north america. new zealand and united states interception data were highly correlated, and 7 of the 10 most intercepted species were shared. interception frequency and establishment in new zealand were not clearly related. by combining new zealand and united states interceptions of true bark beetles we obtained data on species found in shipments from around the world. logistic regression analysis showed that frequently intercepted species were about four times as likely as rarely intercepted species to be established somewhere. interception records of wood and bark borers are valuable for the prediction of invaders and for our general understanding of invasions. the use of alternatives to solid wood packaging, such as processed wood, should be encouraged to reduce the spread of invasive wood and bark borers. \"",
            "contribution_ids": [
                "R56960"
            ]
        },
        {
            "instance_id": "R57101xR56990",
            "comparison_id": "R57101",
            "paper_id": "R56990",
            "text": "Alien aquatic plant species in European countries hussner a (2012). alien aquatic plant species in european countries. weed research52, 297\u2013306. \\n \\nsummary \\nalien aquatic plant species cause serious ecological and economic impacts to european freshwater ecosystems. this study presents a comprehensive overview of all alien aquatic plants in europe, their places of origin and their distribution within the 46 european countries. in total, 96 aquatic species from 30 families have been reported as aliens from at least one european country. most alien aquatic plants are native to northern america, followed by asia and southern america. elodea canadensis is the most widespread alien aquatic plant in europe, reported from 41 european countries. azolla filiculoides ranks second (25), followed by vallisneria spiralis (22) and elodea nuttallii (20). the highest number of alien aquatic plant species has been found in italy and france (34 species), followed by germany (27), belgium and hungary (both 26) and the netherlands (24). even though the number of alien aquatic plants seems relatively small, the european and mediterranean plant protection organization (eppo, http://www.eppo.org) has listed 18 of these species as invasive or potentially invasive within the eppo region. as ornamental trade has been regarded as the major pathway for the introduction of alien aquatic plants, trading bans seem to be the most effective option to reduce the risk of further unintended entry of alien aquatic plants into europe.",
            "contribution_ids": [
                "R56991"
            ]
        },
        {
            "instance_id": "R57101xR57000",
            "comparison_id": "R57101",
            "paper_id": "R57000",
            "text": "Ecological predictions and risk assessment for alien fishes in North America methods of risk assessment for alien species, especially for nonagricultural systems, are largely qualitative. using a generalizable risk assessment approach and statistical models of fish introductions into the great lakes, north america, we developed a quantitative approach to target prevention efforts on species most likely to cause damage. models correctly categorized established, quickly spreading, and nuisance fishes with 87 to 94% accuracy. we then identified fishes that pose a high risk to the great lakes if introduced from unintentional (ballast water) or intentional pathways (sport, pet, bait, and aquaculture industries).",
            "contribution_ids": [
                "R57001",
                "R57002"
            ]
        },
        {
            "instance_id": "R57101xR57028",
            "comparison_id": "R57101",
            "paper_id": "R57028",
            "text": "Accounting for differential success in the biological control of homopteran and lepidopteran pests one of the strongest patterns in the historical record of biological control is that programmes targeted against lepidopteran pests have been far less successful than those targeted against homopteran pests. despite fueling considerable interest in the theory of host-parasitoid interactions, biological control has few unifying principles and no theoretical basis for understanding the differential pattern of success against these two pest groups. potential explanations considered here include competitive limitation of natural enemy establishment, the influence of antagonistic parasitoid interactions, generation time ratio, and gregarious parasitoid development. an analysis of the biological control record showed that on average six natural enemies have been introduced per pest for both pest groups, providing no evidence of a differential intensity of competition. similarly, use of a discrete time host-parasitoid model showed that antagonistic interactions that are common among parasitoids of lepidoptera should not limit the success of biological control as such interactions can readily be counteracted by host refuge breaking. a similar model showed that a small generation time ratio (coupled with a broad window of host attack) and gregarious development can facilitate the suppression of pest abundance by parasitoids, and both were found to be positively associated with success in the biological control record. of the four explanations considered here, generation time ratio coupled with a broad window of host attack appears to provide the best explanation for the differential pattern of success.",
            "contribution_ids": [
                "R57029"
            ]
        },
        {
            "instance_id": "R57101xR57067",
            "comparison_id": "R57101",
            "paper_id": "R57067",
            "text": "The role of opportunity in the unintentional introduction of nonnative ants a longstanding goal in the study of biological invasions is to predict why some species are successful invaders, whereas others are not. to understand this process, detailed information is required concerning the pool of species that have the opportunity to become established. here we develop an extensive database of ant species unintentionally transported to the continental united states and use these data to test how opportunity and species-level ecological attributes affect the probability of establishment. this database includes an amount of information on failed introductions that may be unparalleled for any group of unintentionally introduced insects. we found a high diversity of species (232 species from 394 records), 12% of which have become established in the continental united states. the probability of establishment increased with the number of times a species was transported (propagule pressure) but was also influenced by nesting habit. ground nesting species were more likely to become established compared with arboreal species. these results highlight the value of developing similar databases for additional groups of organisms transported by humans to obtain quantitative data on the first stages of the invasion process: opportunity and transport.",
            "contribution_ids": [
                "R57068",
                "R57069"
            ]
        },
        {
            "instance_id": "R57101xR57070",
            "comparison_id": "R57101",
            "paper_id": "R57070",
            "text": "A global meta-analysis of the ecological impacts of nonnative crayfish abstract.\\u2003 nonnative crayfish have been widely introduced and are a major threat to freshwater biodiversity and ecosystem functioning. despite documentation of the ecological effects of nonnative crayfish from >3 decades of case studies, no comprehensive synthesis has been done to test quantitatively for their general or species-specific effects on recipient ecosystems. we provide the first global meta-analysis of the ecological effects of nonnative crayfish under experimental settings to compare effects among species and across levels of ecological organization. our meta-analysis revealed strong, but variable, negative ecological impacts of nonnative crayfish with strikingly consistent effects among introduced species. in experimental settings, nonnative crayfish generally affect all levels of freshwater food webs. nonnative crayfish reduce the abundance of basal resources like aquatic macrophytes, prey on invertebrates like snails and mayflies, and reduce abundances and growth of amphibians and fish, but they do not consistently increase algal biomass. nonnative crayfish tend to have larger positive effects on growth of algae and larger negative effects on invertebrates and fish than native crayfish, but effect sizes vary considerably. our study supports the assessment of crayfish as strong interactors in food webs that have significant effects across native taxa via polytrophic, generalist feeding habits. nonnative crayfish species identity may be less important than extrinsic attributes of the recipient ecosystems in determining effects of nonnative crayfish. we identify some understudied and emerging nonnative crayfish that should be studied further and suggest expanding research to encompass more comparisons of native vs nonnative crayfish and different geographic regions. the consistent and general negative effects of nonnative crayfish warrant efforts to discourage their introduction beyond native ranges.",
            "contribution_ids": [
                "R57071"
            ]
        },
        {
            "instance_id": "R57501xR57133",
            "comparison_id": "R57501",
            "paper_id": "R57133",
            "text": "Functional group diversity, resource preemption and the genesis of invasion resistance in a community of marine algae \"although many studies have investigated how community characteristics such as diversity and disturbance relate to invasibility, the mechanisms underlying biotic resistance to introduced species are not well understood. i manipulated the functional group composition of native algal communities and invaded them with the introduced, japanese seaweed sargassum muticum to understand how individual functional groups contributed to overall invasion resistance. the results suggested that space preemption by crustose and turfy algae inhibited s. muticum recruitment and that light preemption by canopy and understory algae reduced s. muticum survivorship. however, other mechanisms i did not investigate could have contributed to these two results. in this marine community the sequential preemption of key resources by different functional groups in different stages of the invasion generated resistance to invasion by s. muticum. rather than acting collectively on a single resource the functional groups in this system were important for preempting either space or light, but not both resources. my experiment has important implications for diversity-invasibility studies, which typically look for an effect of diversity on individual resources. overall invasion resistance will be due to the additive effects of individual functional groups (or species) summed over an invader's life cycle. therefore, the cumulative effect of multiple functional groups (or species) acting on multiple resources is an alternative mechanism that could generate negative relationships between diversity and invasibility in a variety of biological systems.\"",
            "contribution_ids": [
                "R57134"
            ]
        },
        {
            "instance_id": "R57501xR57137",
            "comparison_id": "R57501",
            "paper_id": "R57137",
            "text": "Control of plant species diversity and community invasibility by species immigration: seed richness versus seed density brown, r. l. and fridley, j. d. 2003. control of plant species diversity andcommunity invasibility by species immigration: seed richness versus seed density. \u2013oikos 102: 15\u201324.immigration rates of species into communities are widely understood to in\ufb02uencecommunity diversity, which in turn is widely expected to in\ufb02uence the susceptibilityof ecosystems to species invasion. for a given community, however, immigrationprocesses may impact diversity by means of two separable components: the numberof species represented in seed inputs and the density of seed per species. theindependent effects of these components on plant species diversity and consequentrates of invasion are poorly understood. we constructed experimental plant commu-nities through repeated seed additions to independently measure the effects of seedrichness and seed density on the trajectory of species diversity during the develop-ment of annual plant communities. because we sowed species not found in theimmediate study area, we were able to assess the invasibility of the resultingcommunities by recording the rate of establishment of species from adjacent vegeta-tion. early in community development when species only weakly interacted, seedrichness had a strong effect on community diversity whereas seed density had littleeffect. after the plants became established, the effect of seed richness on measureddiversity strongly depended on seed density, and disappeared at the highest level ofseed density. the ability of surrounding vegetation to invade the experimentalcommunities was decreased by seed density but not by seed richness, primarilybecause the individual effects of a few sown species could explain the observedinvasion rates. these results suggest that seed density is just as important as seedrichness in the control of species diversity, and perhaps a more important determi-nant of community invasibility than seed richness in dynamic plant assemblages.",
            "contribution_ids": [
                "R57138"
            ]
        },
        {
            "instance_id": "R57501xR57171",
            "comparison_id": "R57501",
            "paper_id": "R57171",
            "text": "Invasion of exotic plant species in tallgrass prairie fragments abstract: the tallgrass prairie is one of the most severely affected ecosystems in north america. as a result of extensive conversion to agriculture during the last century, as little as 1% of the original tallgrass prairie remains. the remaining fragments of tallgrass prairie communities have conservation significance, but questions remain about their viability and importance to conservation. we investigated the effects of fragment size, native plant species diversity, and location on invasion by exotic plant species at 25 tallgrass prairie sites in central north america at various geographic scales. we used exotic species richness and relative cover as measures of invasion. exotic species richness and cover were not related to area for all sites considered together. there were no significant relationships between native species richness and exotic species richness at the cluster and regional scale or for all sites considered together. at the local scale, exotic species richness was positively related to native species richness at four sites and negatively related at one. the 10 most frequently occurring and abundant exotic plant species in the prairie fragments were cool\u2010season, or c3, species, in contrast to the native plant community, which was dominated by warm\u2010season, or c4, species. this suggests that timing is important to the success of exotic species in the tallgrass prairie. our study indicates that some small fragments of tallgrass prairie are relatively intact and should not be overlooked as long\u2010term refuges for prairie species, sources of genetic variability, and material for restoration.",
            "contribution_ids": [
                "R57172"
            ]
        },
        {
            "instance_id": "R57501xR57219",
            "comparison_id": "R57501",
            "paper_id": "R57219",
            "text": "Ecological filtering of exotic plants in an Australian sub-alpine environment abstract we investigated some of the factors influencing exotic invasion of native sub-alpine plant communities at a site in southeast australia. structure, floristic composition and invasibility of the plant communities and attributes of the invasive species were studied. to determine the plant characteristics correlated with invasiveness, we distinguished between roadside invaders, native community invaders and non-invasive exotic species, and compared these groups across a range of traits including functional group, taxonomic affinity, life history, mating system and morphology. poa grasslands and eucalyptus-poa woodlands contained the largest number of exotic species, although all communities studied appeared resilient to invasion by most species. most community invaders were broad-leaved herbs while roadside invaders contained both herbs and a range of grass species. over the entire study area the richness and cover of native and exotic herbaceous species were positively related, but exotic herbs were more negatively related to cover of specific functional groups (e.g. trees) than native herbs. compared with the overall pool of exotic species, those capable of invading native plant communities were disproportionately polycarpic, asteracean and cross-pollinating. our data support the hypothesis that strong ecological filtering of exotic species generates an exotic assemblage containing few dominant species and which functionally converges on the native assemblage. these findings contrast with those observed in the majority of invaded natural systems. we conclude that the invasion of closed sub-alpine communities must be viewed in terms of the unique attributes of the invading species, the structure and composition of the invaded communities and the strong extrinsic physical and climatic factors typical of the sub-alpine environment. nomenclature: australian plant name index (apni); http://www.anbg.gov.au/cgi-bin/apni abbreviations: knp = kosciuszko national park; mrpp = multi response permutation procedure; ve = variance explained.",
            "contribution_ids": [
                "R57220"
            ]
        },
        {
            "instance_id": "R57501xR57227",
            "comparison_id": "R57501",
            "paper_id": "R57227",
            "text": "Native Predators Do Not Influence Invasion Success of Pacific Lionfish on Caribbean Reefs biotic resistance, the process by which new colonists are excluded from a community by predation from and/or competition with resident species, can prevent or limit species invasions. we examined whether biotic resistance by native predators on caribbean coral reefs has influenced the invasion success of red lionfishes (pterois volitans and pterois miles), piscivores from the indo-pacific. specifically, we surveyed the abundance (density and biomass) of lionfish and native predatory fishes that could interact with lionfish (either through predation or competition) on 71 reefs in three biogeographic regions of the caribbean. we recorded protection status of the reefs, and abiotic variables including depth, habitat type, and wind/wave exposure at each site. we found no relationship between the density or biomass of lionfish and that of native predators. however, lionfish densities were significantly lower on windward sites, potentially because of habitat preferences, and in marine protected areas, most likely because of ongoing removal efforts by reserve managers. our results suggest that interactions with native predators do not influence the colonization or post-establishment population density of invasive lionfish on caribbean reefs.",
            "contribution_ids": [
                "R57228"
            ]
        },
        {
            "instance_id": "R57501xR57258",
            "comparison_id": "R57501",
            "paper_id": "R57258",
            "text": "Resource availability and plant diversity explain patterns of invasion of an exotic grass aims in this study, we examine two common invasion biology hypotheses\u2014 biotic resistance and fluctuating resource availability\u2014to explain the patterns of invasion of an invasive grass, microstegium vimineum. methods we used 13-year-old deer exclosures in great smoky mountains national park, usa, to examine how chronic disturbance by deer browsing affects available resources, plant diversity, and invasion in an understory plant community. using two replicate 1 m 2 plots in each deer browsed and unbrowsed area, we recorded each plant species present, the abundance per species, and the fractional per cent cover of vegetation by the cover classes: herbaceous, woody, and graminoid. for each sample plot, we also estimated overstory canopy cover, soil moisture, total soil carbon and nitrogen, and soil ph as a measure of abiotic differences between plots. important\\xa0findings we found that plant community composition between chronically browsed and unbrowsed plots differed markedly. plant diversity was 40% lower in browsed than in unbrowsed plots. at our sites, diver sity explained 48% and woody plant cover 35% of the variation in m. vimineum abundance. in addition, we found 3.3 times less m. vimineum in the unbrowsed plots due to higher woody plant cover and plant diversity than in the browsed plots. a\\xa0parsimonious explanation of these results indicate that disturbances such as herbivory may elicit multiple conditions, namely releasing available resources such as open space, light, and decreasing plant diversity, which may facilitate the proliferation of an invasive species. finally, by testing two different hypotheses, this study addresses more recent calls to incorporate multiple hypotheses into research attempting to explain plant invasion.",
            "contribution_ids": [
                "R57259"
            ]
        },
        {
            "instance_id": "R57501xR57271",
            "comparison_id": "R57501",
            "paper_id": "R57271",
            "text": "Negative native-exotic diversity relationship in oak savannas explained by human influence and climate recent research has proposed a scale-dependence to relationships between native diversity and exotic invasions. at fine spatial scales, native-exotic richness relationships should be negative as higher native richness confers resistance to invasion. at broad scales, relationships should be positive if natives and exotics respond similarly to extrinsic factors. yet few studies have examined both native and exotic richness patterns across gradients of human influence, where impacts could affect native and exotic species differently. we examined native-exotic richness relationships and extrinsic drivers of plant species richness and distributions across an urban development gradient in remnant oak savanna patches. in sharp contrast to most reported results, we found a negative relationship at the regional scale, and no relationship at the local scale. the negative regional-scale relationship was best explained by extrinsic factors, surrounding road density and climate, affecting natives and exotics in opposite ways, rather than a direct effect of native on exotic richness, or vice versa. models of individual species distributions also support the result that road density and climate have largely opposite effects on native and exotic species, although simple life history traits (life form, dispersal mode) do not predict which habitat characteristics are important for particular species. roads likely influence distributions and species richness by increasing both exotic propagule pressure and disturbance to native species. climate may partially explain the negative relationship due to differing climatic preferences within the native and exotic species pools. as gradients of human influence are increasingly common, negative broad-scale native-exotic richness relationships may be frequent in such landscapes.",
            "contribution_ids": [
                "R57272"
            ]
        },
        {
            "instance_id": "R57501xR57279",
            "comparison_id": "R57501",
            "paper_id": "R57279",
            "text": "Effects of a directional abiotic gradient on plant community dynamics and invasion in a coastal dune system 1 local abiotic factors are likely to play a crucial role in modifying the relative abundance of native and exotic species in plant communities. natural gradients provide an ideal opportunity to test this hypothesis. 2 in a coastal dune system in northern california, we used comparative and experimental studies to evaluate how a wind and soil texture gradient influences the relative abundance of native and exotic plant species in this community. 3 we detected small\u2010scale spatial variation in soil texture along a 200\u2010m gradient from relatively sheltered to more exposed. sand coarseness significantly increased with exposure while soil nitrate levels significantly decreased. the more extreme end of the gradient was also subject to greater wind speeds and less soil moisture. 4 the plant community consistently responded to this gradient in the 7 years censused. species richness decreased with exposure, cover of natives decreased and cover of exotics increased at the more extreme end of the gradient. 5 a single\u2010season wind\u2010shelter experiment similarly shifted the balance between native and exotic species. shelters decreased the relative density of exotic species and increased the relative density of natives regardless of position on the gradient. 6 these comparative and manipulative findings both suggest that a single factor, wind, at least partially explains the success of exotic species in a coastal dune plant community. this supports the hypothesis that local abiotic conditions can explain differences in invasibility within a plant community.",
            "contribution_ids": [
                "R57280"
            ]
        },
        {
            "instance_id": "R57501xR57305",
            "comparison_id": "R57501",
            "paper_id": "R57305",
            "text": "Patterns of invasion of an urban remnant of a species-rich grassland in southeastern Australia by non-native plant species . the invasion by non-native plant species of an urban remnant of a species-rich themeda triandra grassland in southeastern australia was quantified and related to abiotic influences. richness and cover of non-native species were highest at the edges of the remnant and declined to relatively uniform levels within the remnant. native species richness and cover were lowest at the edge adjoining a roadside but then showed little relation to distance from edge. roadside edge quadrats were floristically distinct from most other quadrats when ordinated by detrended correspondence analysis. \\n \\n \\n \\nsoil phosphorus was significantly higher at the roadside edge but did not vary within the remnant itself. all other abiotic factors measured (nh4, no3, s, ph and % organic carbon) showed little variation across the remnant. non-native species richness and cover were strongly correlated with soil phosphorus levels. native species were negatively correlated with soil phosphorus levels. canonical correspondence analysis identified the perennial non-native grasses of high biomass as species most dependent on high soil nutrient levels. such species may be resource-limited in undisturbed soils. \\n \\n \\n \\nthree classes of non-native plants have invaded this species-rich grassland: (1) generalist species (> 50 % frequency), mostly therophytes with non-specialized habitat or germination requirements; (2) resource-limited species comprising perennial species of high biomass that are dependent on nutrient increases and/or soil disturbances before they can invade the community and; (3) species of intermediate frequency (1\u201330 %), of low to high biomass potential, that appear to have non-specialized habitat requirements but are currently limited by seed dispersal, seedling establishment or the current site management. native species richness and cover are most negatively affected by increases in non-native cover. declines are largely evident once the non-native cover exceeds 40 %. \\n \\n \\n \\nwidespread, generalist non-native species are numerous in intact sites and will have to be considered a permanent part of the flora of remnant grasslands. management must aim to minimize increases in cover of any non-native species or the disturbances that favour the establishment of competitive non-native grasses if the native grassland flora is to be conserved in small, fragmented remnants.",
            "contribution_ids": [
                "R57306"
            ]
        },
        {
            "instance_id": "R57501xR57311",
            "comparison_id": "R57501",
            "paper_id": "R57311",
            "text": "Native plant diversity increases herbivory to non-natives there is often an inverse relationship between the diversity of a plant community and the invasibility of that community by non-native plants. native herbivores that colonize novel plants may contribute to diversity\u2013invasibility relationships by limiting the relative success of non-native plants. here, we show that, in large collections of non-native oak trees at sites across the usa, non-native oaks introduced to regions with greater oak species richness accumulated greater leaf damage than in regions with low oak richness. underlying this trend was the ability of herbivores to exploit non-native plants that were close relatives to their native host. in diverse oak communities, non-native trees were on average more closely related to native trees and received greater leaf damage than those in depauperate oak communities. because insect herbivores colonize non-native plants that are similar to their native hosts, in communities with greater native plant diversity, non-natives experience greater herbivory.",
            "contribution_ids": [
                "R57312"
            ]
        },
        {
            "instance_id": "R57501xR57313",
            "comparison_id": "R57501",
            "paper_id": "R57313",
            "text": "Habitat stress, species pool size and biotic resistance influence exotic plant richness in the Flooding Pampa grasslands 1 theory and empirical evidence suggest that community invasibility is influenced by propagule pressure, physical stress and biotic resistance from resident species. we studied patterns of exotic and native species richness across the flooding pampas of argentina, and tested for exotic richness correlates with major environmental gradients, species pool size, and native richness, among and within different grassland habitat types. 2 native and exotic richness were positively correlated across grassland types, increasing from lowland meadows and halophyte steppes, through humid to mesophyte prairies in more elevated topographic positions. species pool size was positively correlated with local richness of native and exotic plants, being larger for mesophyte and humid prairies. localities in the more stressful meadow and halophyte steppe habitats contained smaller fractions of their landscape species pools. 3 native and exotic species numbers decreased along a gradient of increasing soil salinity and decreasing soil depth, and displayed a unimodal relationship with soil organic carbon. when covarying habitat factors were held constant, exotic and native richness residuals were still positively correlated across sites. within grassland habitat types, exotic and native species richness were positively associated in meadows and halophyte steppes but showed no consistent relationship in the least stressful, prairie habitat types. 4 functional group composition differed widely between native and exotic species pools. patterns suggesting biotic resistance to invasion emerged only within humid prairies, where exotic richness decreased with increasing richness of native warm\u2010season grasses. this negative relationship was observed for other descriptors of invasion such as richness and cover of annual cool\u2010season forbs, the commonest group of exotics. 5 our results support the view that ecological factors correlated with differences in invasion success change with the range of environmental heterogeneity encompassed by the analysis. within narrow habitat ranges, invasion resistance may be associated with either physical stress or resident native diversity. biotic resistance through native richness, however, appeared to be effective only at intermediate locations along a stress/fertility gradient. 6 we show that certain functional groups, not just total native richness, may be critical to community resistance to invasion. identifying such native species groups is important for directing management and conservation efforts.",
            "contribution_ids": [
                "R57314"
            ]
        },
        {
            "instance_id": "R57501xR57324",
            "comparison_id": "R57501",
            "paper_id": "R57324",
            "text": "Mechanisms of resistance of Mediterranean annual communities to invasion by Conyza bonariensis: effects of native functional composition \"recent studies have shown that a high species or functional group richness may not always lead to a greater resistance of plant communities to invasion, whereas species and/or functional group composition can more reliably predict invasion resistance. the aim of this study was to understand the mechanisms through which functional group composition can influence the resistance of mediterranean annual communities to invasion by the exotic conyza bonariensis. to analyse the effects of functional composition on the performance of individuals introduced as seedlings we first examined the relationships between the demographic and vegetative parameters of c. bonariensis and the biomass achieved by each functional group (grasses, legumes and asteraceae rosettes) in synthetic communities. as a further step to approach the mechanisms involved in community resistance to invasion, we included in the analyses measurements of functional variables taken within the synthetic communities. \\n \\n \\n \\nin agreement with earlier results and theory suggesting that high nutrient availability can favour invasions, an abundant legume biomass in communities increased the final biomass and net fecundity of c. bonariensis, due to positive effects on soil nitrate concentration. survival and establishment of c. bonariensis were mainly favoured by a high biomass of asteraceae. additional results from measurements of herbivory suggested that c. bonariensis survival wasn't related to abiotic conditions but may be owed to a protection against herbivores in plots with abundant asteraceae. establishment was on the other hand likely to be hindered by the effects of abundant grass and legume foliage on light quality, and therefore easier within an asteraceae canopy. \\n \\n \\n \\nwe conclude that invasion of mediterranean old fields by species with biologies similar to c. bonariensis could be limited by favouring communities dominated by annual grasses.\"",
            "contribution_ids": [
                "R57325"
            ]
        },
        {
            "instance_id": "R57501xR57336",
            "comparison_id": "R57501",
            "paper_id": "R57336",
            "text": "Biotic and abiotic constraints to a plant invasion in vegetation communities of Tierra del Fuego the biotic resistance theory relates invader success to species richness, and predicts that, as species richness increases, invasibility decreases. the relationship between invader success and richness, however, seems to be positive at large scales of analysis, determined by abiotic constraints, and it is to be expected that it is negative at small scales, because of biotic interactions. moreover, the negative relationship at small scales would be stronger within species of the same functional group, because of having similar resource exploitation mechanisms. we studied the relationship between the cover of a worldwide invader of grasslands, hieracium pilosella l., and species richness, species diversity and the cover of different growth forms at two different levels of analysis in 128 sites during the initial invasion process in the fuegian steppe, southern patagonia, argentina. at regional level, the invader was positively correlated to total (r\\xa0=\\xa00.28, p\\xa0=\\xa00.003), exotic (r\\xa0=\\xa00.273, p\\xa0=\\xa00.004), and native species richness (r\\xa0=\\xa00.210, p\\xa0=\\xa00.026), and to species diversity (r\\xa0=\\xa00.193, p\\xa0=\\xa00.041). at community level, we found only a weak negative correlation between h.\\xa0pilosella and total richness (r\\xa0=\\xa0\u22120.426, p\\xa0=\\xa00.079) and diversity (r\\xa0=\\xa0\u22120.658, p\\xa0=\\xa00.063). the relationship between the invader and other species of the same growth form was positive both at regional (r\\xa0=\\xa00.484, p\\xa0<\\xa00.001) and community (r\\xa0=\\xa00.593, p\\xa0=\\xa00.012) levels. consequently, in the period of establishment and initial expansion of this exotic species, our results support the idea that invader success is related to abiotic factors at large scales of analysis. also, we observed a possible sign of biotic constraint at community level, although this was not related to the abundance of species of the same growth form.",
            "contribution_ids": [
                "R57337"
            ]
        },
        {
            "instance_id": "R57501xR57341",
            "comparison_id": "R57501",
            "paper_id": "R57341",
            "text": "Ecological resistance to Acer negundo invasion in a European riparian forest: relative importance of environmental and biotic drivers question \\n \\nthe relative importance of environmental vs. biotic resistance of recipient ecological communities remains poorly understood in invasion ecology. acer negundo, a north american tree, has widely invaded riparian forests throughout europe at the ecotone between early- (salix spp. and populus spp.) and late-successional (fraxinus spp.) species. however, it is not present in the upper part of the rhone river, where native alnus incana occurs at an intermediate position along the successional riparian gradient. is this absence of the invasive tree due to environmental or biotic resistance of the recipient communities, and in particular due to the presence of alnus? \\n \\n \\n \\nlocation \\n \\nupper rhone river, france. \\n \\n \\n \\nmethods \\n \\nwe undertook a transplant experiment in an alnus-dominated community along the upper rhone river, where we compared acer negundo survival and growth, with and without biotic interactions (tree and herb layer effects), to those of four native tree species from differing successional positions in the upper rhone communities (p. alba, s. alba, f. excelsior and alnus incana). \\n \\n \\n \\nresults \\n \\nwithout biotic interactions acer negundo performed similarly to native species, suggesting that the upper rhone floodplain is not protected from acer invasion by a simple abiotic barrier. in contrast, this species performed less well than f. excelsior and alnus incana in environments with intact tree and/or herb layers. alnus showed the best growth rate in these conditions, indicating biotic resistance of the native plant community. \\n \\n \\n \\nconclusions \\n \\nwe did not find evidence for an abiotic barrier to acer negundo invasion of the upper rhone river floodplain communities, but our results suggest a biotic resistance. in particular, we demonstrated that (i) additive competitive effects of the tree and herb layer led to acer negundo suppression and (ii) alnus incana grew more rapidly than acer negundo in this intermediate successional niche.",
            "contribution_ids": [
                "R57342"
            ]
        },
        {
            "instance_id": "R57501xR57343",
            "comparison_id": "R57501",
            "paper_id": "R57343",
            "text": "Native and naturalized plant diversity are positively correlated in scrub communities of California and Chile abstract. an emerging body of literature suggests that the richness of native and naturalized plant species are often positively correlated. it is unclear, however, whether this relationship is robust across spatial scales, and how a disturbance regime may affect it. here, i examine the relationships of both richness and abundance between native and naturalized species of plants in two mediterranean scrub communities: coastal sage scrub (css) in california and xeric\u2010sloped matorral (xsm) in chile. in each vegetation type i surveyed multiple sites, where i identified vascular plant species and estimated their relative cover. herbaceous species richness was higher in xsm, while cover of woody species was higher in css, where woody species have a strong impact upon herbaceous species. as there were few naturalized species with a woody growth form, the analyses performed here relate primarily to herbaceous species. relationships between the herbaceous cover of native and naturalized species were not significant in css, but were nearly significant in xsm. the herbaceous species richness of native and naturalized plants were not significantly correlated on sites that had burned less than one year prior to sampling in css, and too few sites were available to examine this relationship in xsm. in post 1\u2010year burn sites, however, herbaceous richness of native and naturalized species were positively correlated in both css and xsm. this relationship occurred at all spatial scales, from 400 m2 to 1 m2 plots. the consistency of this relationship in this study, together with its reported occurrence in the literature, suggests that this relationship may be general. finally, the residuals from the correlations between native and naturalized species richness and cover, when plotted against site age (i.e. time since the last fire), show that richness and cover of naturalized species are strongly favoured on recently burned sites in xsm; this suggests that herbaceous species native to chile are relatively poorly adapted to fire.",
            "contribution_ids": [
                "R57344",
                "R57345"
            ]
        },
        {
            "instance_id": "R57501xR57346",
            "comparison_id": "R57501",
            "paper_id": "R57346",
            "text": "Realistic plant species losses reduce invasion resistance in a California serpentine grassland 1.\\u2002the majority of experiments examining effects of species diversity on ecosystem functioning have randomly manipulated species richness. more recent studies demonstrate that realistic species losses have dramatically different effects on ecosystem functioning than those of randomized losses, but these results are based primarily on microcosm experiments or modelling efforts.",
            "contribution_ids": [
                "R57347"
            ]
        },
        {
            "instance_id": "R57501xR57354",
            "comparison_id": "R57501",
            "paper_id": "R57354",
            "text": "Species diversity and invasion resistance in a marine ecosystem \" theory predicts that systems that are more diverse should be more resistant to exotic species, but experimental tests are needed to verify this. in experimental communities of sessile marine invertebrates, increased species richness significantly decreased invasion success, apparently because species-rich communities more completely and efficiently used available space, the limiting resource in this system. declining biodiversity thus facilitates invasion in this system, potentially accelerating the loss of biodiversity and the homogenization of the world's biota. \"",
            "contribution_ids": [
                "R57355"
            ]
        },
        {
            "instance_id": "R57501xR57356",
            "comparison_id": "R57501",
            "paper_id": "R57356",
            "text": "Biodiversity, invasion resistance, and marine ecosystem function: Reconciling pattern and process a venerable generalization about community resistance to invasions is that more diverse communities are more resistant to invasion. however, results of experimental and observational studies often conflict, leading to vigorous debate about the mechanistic importance of diversity in determining invasion success in the field, as well as other eco- system properties, such as productivity and stability. in this study, we employed both field experiments and observational approaches to assess the effects of diversity on the invasion of a subtidal marine invertebrate community by three species of nonindigenous ascidians (sea squirts). in experimentally assembled communities, decreasing native diversity in- creased the survival and final percent cover of invaders, whereas the abundance of individual species had no effect on these measures of invasion success. increasing native diversity also decreased the availability of open space, the limiting resource in this system, by buffering against fluctuations in the cover of individual species. this occurred because temporal patterns of abundance differed among species, so space was most consistently and completely occupied when more species were present. when we held diversity constant, but manipulated resource availability, we found that the settlement and recruitment of new invaders dramatically increased with increasing availability of open space. this suggests that the effect of diversity on invasion success is largely due to its effects on resource (space) availability. apart from invasion resistance, the increased temporal stability found in more diverse communities may itself be considered an enhancement of ecosystem func- tion. in field surveys, we found a strong negative correlation between native-species richness and the number and frequency of nonnative invaders at the scale of both a single quadrat (25 3 25 cm), and an entire site (50 3 50 m). such a pattern suggests that the means by which diversity affects invasion resistance in our experiments is important in determining the distribution of invasive species in the field. further synthesis of mechanistic and ob- servational approaches should be encouraged, as this will increase our understanding of the conditions under which diversity does (and does not) play an important role in deter- mining the distribution of invaders in the field.",
            "contribution_ids": [
                "R57357",
                "R57358"
            ]
        },
        {
            "instance_id": "R57501xR57365",
            "comparison_id": "R57501",
            "paper_id": "R57365",
            "text": "Plant species invasions along the latitudinal gradient in the United States it has been long established that the richness of vascular plant species and many animal taxa decreases with increasing latitude, a pattern that very generally follows declines in actual and potential evapotranspiration, solar radiation, temperature, and thus, total productivity. using county-level data on vascular plants from the united states (3000 counties in the conterminous 48 states), we used the akaike information criterion (aic) to evaluate competing models predicting native and nonnative plant species density (number of species per square kilometer in a county) from various combinations of biotic variables (e.g., native bird species density, vegetation carbon, normalized difference vegetation in- dex), environmental/topographic variables (elevation, variation in elevation, the number of land cover classes in the county, radiation, mean precipitation, actual evapotranspiration, and potential evapotranspiration), and human variables (human population density, crop- land, and percentage of disturbed lands in a county). we found no evidence of a latitudinal gradient for the density of native plant species and a significant, slightly positive latitudinal gradient for the density of nonnative plant species. we found stronger evidence of a sig- nificant, positive productivity gradient (vegetation carbon) for the density of native plant species and nonnative plant species. we found much stronger significant relationships when biotic, environmental/topographic, and human variables were used to predict native plant species density and nonnative plant species density. biotic variables generally had far greater influence in multivariate models than human or environmental/topographic variables. later, we found that the best, single, positive predictor of the density of nonnative plant species in a county was the density of native plant species in a county. while further study is needed, it may be that, while humans facilitate the initial establishment invasions of non- native plant species, the spread and subsequent distributions of nonnative species are con- trolled largely by biotic and environmental factors.",
            "contribution_ids": [
                "R57366"
            ]
        },
        {
            "instance_id": "R57501xR57393",
            "comparison_id": "R57501",
            "paper_id": "R57393",
            "text": "Diversity effects on invasion vary with life history stage in marine macroalgae most experimental studies of diversity effects on invasibility have reported negative relationships while observational studies have often found positive correlations between the numbers of exotic and native taxa. nearly all of these studies have been done with terrestrial plants or aquatic invertebrates. we investigated effects of native macroalgal diversity on invasion success of the introduced macroalga sargassum muticum (yendo) fensholt (phaeophyceae: fucales) on the west coast of vancouver island. we conducted both observational field surveys of the correlation between native diversity and exotic cover, and experimental manipulations of native diversity in constructed 25 \ufffd 25 cm communities. field surveys found higher cover of s. muticum in plots with low native diversity, suggesting a negative relationship between diversity and invasibility at the neighbourhood scale. the experiment found initial cover of s. muticum germlings was highest in plots with greater diversity. over the duration of the experiment cover of settled germlings increased fastest in the low diversity plots, so that there was a weak negative effect of diversity on final cover of the invader after 77 days. the slope of the relationship reversed over time, with field patterns and experimental results converging at the end of the experiment. our results suggest native diversity has contrasting effects on different stages of invasion. diversity facilitates invader recruitment of s. muticum but decreases growth and or survivorship.",
            "contribution_ids": [
                "R57394",
                "R57395"
            ]
        },
        {
            "instance_id": "R58002xR57596",
            "comparison_id": "R58002",
            "paper_id": "R57596",
            "text": "Post-dispersal losses to seed predators: an experimental comparison of native and exotic old field plants invasions by exotic plants may be more likely if exotics have low rates of attack by natural enemies, including post-dispersal seed predators (granivores). we investigated this idea with a field experiment conducted near newmarket, ontario, in which we experimentally excluded vertebrate and terrestrial insect seed predators from seeds of 43 native and exotic old-field plants. protection from vertebrates significantly increased recovery of seeds; vertebrate exclusion produced higher recovery than controls for 30 of the experimental species, increasing overall seed recovery from 38.2 to 45.6%. losses to vertebrates varied among species, significantly increasing with seed mass. in contrast, insect exclusion did not significantly improve seed recovery. there was no evidence that aliens benefitted from a reduced rate of post-dispersal seed predation. the impacts of seed predators did not differ significantly between natives and exotics, which instead showed very similar responses to predator exclusion treatments. these results indicate that while vertebrate granivores had important impacts, especially on large-seeded species, exotics did not generally benefit from reduced rates of seed predation. instead, differences between natives and exotics were small compared with interspecific variation within these groups.key words: aliens, exotics, granivores, invaders, old fields, seed predators.",
            "contribution_ids": [
                "R57597"
            ]
        },
        {
            "instance_id": "R58002xR57598",
            "comparison_id": "R58002",
            "paper_id": "R57598",
            "text": "Lack of pre-dispersal seed predators in introduced Asteraceae in New Zealand the idea that naturalised invading plants have fewer phytophagous insects associated with them in their new environment relative to their native range is often assumed, but quantitative data are few and mostly refer to pests on crop species. in this study, the incidence of seed-eating insect larvae in flowerheads of naturalised asteraceae in new zealand is compared with that in britain where the species are native. similar surveys were carried out in both countries by sampling 200 flowerheads of three populations of the same thirteen species. in the new zealand populations only one seed-eating insect larva was found in 7800 flowerheads (0.013% infected flowerheads, all species combined) in contrast with the british populations which had 487 (6.24%) flowerheads infested. possible reasons for the low colonization level of the introduced asteraceae by native insects in new zealand are 1) the relatively recent introduction of the plants (100-200 years), 2) their phylogenetic distance from the native flora, and 3) the specialised nature of the bud-infesting habit of the insects.",
            "contribution_ids": [
                "R57599"
            ]
        },
        {
            "instance_id": "R58002xR57600",
            "comparison_id": "R58002",
            "paper_id": "R57600",
            "text": "Impact of fire on leaf nutrients, arthropod fauna and herbivory of native and exotic eucalypts in Kings Park, Perth, Western Australia the vegetation of kings park, near the centre of perth, western australia, once had an overstorey of eucalyptus marginata (jarrah) or eucalyptus gomphocephala (tuart), and many trees still remain in the bushland parts of the park. avenues and roadsides have been planted with eastern australian species, including eucalyptus cladocalyx (sugar gum) and eucalyptus botryoides (southern mahogany), both of which have become invasive. the present study examined the effect of a recent burn on the level of herbivory on these native and exotic eucalypts. leaf damage, shoot extension and number of new leaves were measured on tagged shoots of saplings of each tree species in unburnt and burnt areas over an 8-month period. leaf macronutrient levels were quantified and the number of arthropods on saplings was measured at the end of the recording period by chemical knockdown. leaf macronutrients were mostly higher in all four species in the burnt area, and this was associated with generally higher numbers of canopy arthropods and greater levels of leaf damage. it is suggested that the pulse of soil nutrients after the fire resulted in more nutrient-rich foliage, which in turn was more palatable to arthropods. the resulting high levels of herbivory possibly led to reduced shoot extension of e. gomphocephala, e. botryoides and, to a lesser extent, e. cladocalyx. this acts as a negative feedback mechanism that lessens the tendency for lush, post-fire regrowth to outcompete other species of plants. there was no consistent difference in the levels of the various types of leaf damage or of arthropods on the native and the exotic eucalypts, suggesting that freedom from herbivory is not contributing to the invasiveness of the two exotic species.",
            "contribution_ids": [
                "R57601"
            ]
        },
        {
            "instance_id": "R58002xR57618",
            "comparison_id": "R58002",
            "paper_id": "R57618",
            "text": "Plant-soil biota interactions and spatial distribution of black cherry in its native and invasive ranges one explanation for the higher abundance of invasive species in their non-native than native ranges is the escape from natural enemies. but there are few experimental studies comparing the parallel impact of enemies (or competitors and mutualists) on a plant species in its native and invaded ranges, and release from soil pathogens has been rarely investigated. here we present evidence showing that the invasion of black cherry (prunus serotina) into north-western europe is facilitated by the soil community. in the native range in the usa, the soil community that develops near black cherry inhibits the establishment of neighbouring conspecifics and reduces seedling performance in the greenhouse. in contrast, in the non-native range, black cherry readily establishes in close proximity to conspecifics, and the soil community enhances the growth of its seedlings. understanding the effects of soil organisms on plant abundance will improve our ability to predict and counteract plant invasions.",
            "contribution_ids": [
                "R57619"
            ]
        },
        {
            "instance_id": "R58002xR57635",
            "comparison_id": "R58002",
            "paper_id": "R57635",
            "text": "Invasive exotic plants suffer less herbivory than non-invasive exotic plants we surveyed naturally occurring leaf herbivory in nine invasive and nine non-invasive exotic plant species sampled in natural areas in ontario, new york and massachusetts, and found that invasive plants experienced, on average, 96% less leaf damage than non-invasive species. invasive plants were also more taxonomically isolated than non-invasive plants, belonging to families with 75% fewer native north american genera. however, the relationship between taxonomic isolation at the family level and herbivory was weak. we suggest that invasive plants may possess novel phytochemicals with anti-herbivore properties in addition to allelopathic and anti-microbial characteristics. herbivory could be employed as an easily measured predictor of the likelihood that recently introduced exotic plants may become invasive.",
            "contribution_ids": [
                "R57636"
            ]
        },
        {
            "instance_id": "R58002xR57727",
            "comparison_id": "R58002",
            "paper_id": "R57727",
            "text": "Diversity and abundance of arthropod floral visitor and herbivore assemblages on exotic and native Senecio species the enemy release hypothesis predicts that native herbivores prefer native, rather than exotic plants, giving invaders a competitive advantage. in contrast, the biotic resistance hypothesis states that many invaders are prevented from establishing because of competitive interactions, including herbivory, with native fauna and flora. success or failure of spread and establishment might also be influenced by the presence or absence of mutualists, such as pollinators. senecio madagascariensis (fireweed), an annual weed from south africa, inhabits a similar range in australia to the related native s. pinnatifolius. the aim of this study was to determine, within the context of invasion biology theory, whether the two senecio species share insect fauna, including floral visitors and herbivores. surveys were carried out in south-east queensland on allopatric populations of the two senecio species, with collected insects identified to morphospecies. floral visitor assemblages were variable between populations. however, the two senecio species shared the two most abundant floral visitors, honeybees and hoverflies. herbivore assemblages, comprising mainly hemipterans of the families cicadellidae and miridae, were variable between sites and no patterns could be detected between senecio species at the morphospecies level. however, when insect assemblages were pooled (i.e. community level analysis), s. pinnatifolius was shown to host a greater total abundance and richness of herbivores. senecio madagascariensis is unlikely to be constrained by lack of pollinators in its new range and may benefit from lower levels of herbivory compared to its native congener s. pinnatifolius.",
            "contribution_ids": [
                "R57728"
            ]
        },
        {
            "instance_id": "R58002xR57753",
            "comparison_id": "R58002",
            "paper_id": "R57753",
            "text": "Release from soil pathogens plays an important role in the success of invasive Carpobrotus in the Mediterranean introduced plant species can become locally dominant and threaten native flora and fauna. this dominance is often thought to be a result of release from specialist enemies in the invaded range, or the evolution of increased competitive ability. soil borne microorganisms have often been overlooked as enemies in this context, but a less deleterious plant soil interaction in the invaded range could explain local dominance. two plant species, carpobrotus edulis and the hybrid carpobrotus x cf. acinaciformis, are considered major pests in the mediterranean basin. we tested if release from soil-borne enemies and/or evolution of increased competitive ability could explain this dominance. comparing biomass production in non-sterile soil with that in sterilized soil, we found that inoculation with rhizosphere soil from the native range reduced biomass production by 32% while inoculation with rhizosphere soil from the invaded range did not have a significant effect on plant biomass. genotypes from the invaded range, including a hybrid, did not perform better than plants from the native range in sterile soil. hence evolution of increased competitive ability and hybridization do not seem to play a major role. we conclude that the reduced negative net impact of the soil community in the invaded range may contribute to the success of carpobrotus species in the mediterranean basin. \u00a9 2008 saab. published by elsevier b.v. all rights reserved.",
            "contribution_ids": [
                "R57754"
            ]
        },
        {
            "instance_id": "R58002xR57774",
            "comparison_id": "R58002",
            "paper_id": "R57774",
            "text": "Effects of large enemies on success of exotic species in marine fouling communities of Washington, USA the enemy release hypothesis, which posits that exotic species are less regulated by enemies than native species, has been well-supported in terrestrial systems but rarely tested in marine systems. here, the enemy release hypothesis was tested in a marine system by excluding large enemies (>1.3 cm) in dock fouling communities in washington, usa. after documenting the distribution and abundance of potential enemies such as chitons, gastropods and flatworms at 4 study sites, exclusion experiments were conducted to test the hypotheses that large grazing ene- mies (1) reduced recruitment rates in the exotic ascidian botrylloides violaceus and native species, (2) reduced b. violaceus and native species abundance, and (3) altered fouling community struc- ture. experiments demonstrated that, as predicted by the enemy release hypothesis, exclusion of large enemies did not significantly alter b. violaceus recruitment or abundance and it did signifi- cantly increase abundance or recruitment of 2 common native species. however, large enemy exclusion had no significant effects on most native species or on overall fouling community struc- ture. furthermore, neither b. violaceus nor total exotic species abundance correlated positively with abundance of large enemies across sites. i therefore conclude that release from large ene- mies is likely not an important mechanism for the success of exotic species in washington fouling communities.",
            "contribution_ids": [
                "R57775"
            ]
        },
        {
            "instance_id": "R58002xR57799",
            "comparison_id": "R58002",
            "paper_id": "R57799",
            "text": "Associations of leaf miners and leaf gallers with island plants of different residency histories aim\\u2002 introduced plant species are less likely to be attacked by herbivores than are native plant species. isolated oceanic islands provide an excellent model system for comparing the associations between herbivore species and plant species of different residency histories, namely endemic, indigenous (non\u2010endemic) or introduced (naturalized or cultivated) species. my aim was to test the prediction that, on isolated oceanic islands, introduced plant species have a lower tendency to have an association with insect herbivores than do endemic and indigenous plant species.",
            "contribution_ids": [
                "R57800"
            ]
        },
        {
            "instance_id": "R58002xR57808",
            "comparison_id": "R58002",
            "paper_id": "R57808",
            "text": "Range-expanding populations of a globally introduced weed experience negative plant-soil feedbacks \"background biological invasions are fundamentally biogeographic processes that occur over large spatial scales. interactions with soil microbes can have strong impacts on plant invasions, but how these interactions vary among areas where introduced species are highly invasive vs. naturalized is still unknown. in this study, we examined biogeographic variation in plant-soil microbe interactions of a globally invasive weed, centaurea solstitialis (yellow starthistle). we addressed the following questions (1) is centaurea released from natural enemy pressure from soil microbes in introduced regions? and (2) is variation in plant-soil feedbacks associated with variation in centaurea's invasive success? methodology/principal findings we conducted greenhouse experiments using soils and seeds collected from native eurasian populations and introduced populations spanning north and south america where centaurea is highly invasive and noninvasive. soil microbes had pervasive negative effects in all regions, although the magnitude of their effect varied among regions. these patterns were not unequivocally congruent with the enemy release hypothesis. surprisingly, we also found that centaurea generated strong negative feedbacks in regions where it is the most invasive, while it generated neutral plant-soil feedbacks where it is noninvasive. conclusions/significance recent studies have found reduced below-ground enemy attack and more positive plant-soil feedbacks in range-expanding plant populations, but we found increased negative effects of soil microbes in range-expanding centaurea populations. while such negative feedbacks may limit the long-term persistence of invasive plants, such feedbacks may also contribute to the success of invasions, either by having disproportionately negative impacts on competing species, or by yielding relatively better growth in uncolonized areas that would encourage lateral spread. enemy release from soil-borne pathogens is not sufficient to explain the success of this weed in such different regions. the biogeographic variation in soil-microbe effects indicates that different mechanisms may operate on this species in different regions, thus establishing geographic mosaics of species interactions that contribute to variation in invasion success.\"",
            "contribution_ids": [
                "R57809",
                "R57810"
            ]
        },
        {
            "instance_id": "R58002xR57816",
            "comparison_id": "R58002",
            "paper_id": "R57816",
            "text": "Diversity, loss, and gain of malaria parasites in a globally invasive bird \"invasive species can displace natives, and thus identifying the traits that make aliens successful is crucial for predicting and preventing biodiversity loss. pathogens may play an important role in the invasive process, facilitating colonization of their hosts in new continents and islands. according to the novel weapon hypothesis, colonizers may out-compete local native species by bringing with them novel pathogens to which native species are not adapted. in contrast, the enemy release hypothesis suggests that flourishing colonizers are successful because they have left their pathogens behind. to assess the role of avian malaria and related haemosporidian parasites in the global spread of a common invasive bird, we examined the prevalence and genetic diversity of haemosporidian parasites (order haemosporida, genera plasmodium and haemoproteus) infecting house sparrows (passer domesticus). we sampled house sparrows (n\\u200a=\\u200a1820) from 58 locations on 6 continents. all the samples were tested using pcr-based methods; blood films from the pcr-positive birds were examined microscopically to identify parasite species. the results show that haemosporidian parasites in the house sparrows' native range are replaced by species from local host-generalist parasite fauna in the alien environments of north and south america. furthermore, sparrows in colonized regions displayed a lower diversity and prevalence of parasite infections. because the house sparrow lost its native parasites when colonizing the american continents, the release from these natural enemies may have facilitated its invasion in the last two centuries. our findings therefore reject the novel weapon hypothesis and are concordant with the enemy release hypothesis.\"",
            "contribution_ids": [
                "R57817"
            ]
        },
        {
            "instance_id": "R58002xR57900",
            "comparison_id": "R58002",
            "paper_id": "R57900",
            "text": "The herbivorous arthropods associated with the invasive alien plant, Arundo donax, and the native analogous plant, Phragmites australis, in the Free State Province, South Africa the enemy release hypothesis (erh) predicts that when plant species are introduced outside their native range there is a release from natural enemies resulting in the plants becoming problematic invasive alien species (lake & leishman 2004; puliafico et al. 2008). the release from natural enemies may benefit alien plants more than simply reducing herbivory because, according to the evolution of increased competitive ability (eica) hypothesis, without pressure from herbivores more resources that were previously allocated to defence can be allocated to reproduction (blossey & notzold 1995). alien invasive plants are therefore expected to have simpler herbivore communities with fewer specialist herbivores (frenzel & brandl 2003; heleno et al. 2008; heger & jeschke 2014).",
            "contribution_ids": [
                "R57901"
            ]
        },
        {
            "instance_id": "R58002xR57902",
            "comparison_id": "R58002",
            "paper_id": "R57902",
            "text": "Herbivores on native and exotic Senecio plants: is host switching related to plant novelty and insect diet breadth under field conditions? native herbivores can establish novel interactions with alien plants after invasion. nevertheless, it is unclear whether these new associations are quantitatively significant compared to the assemblages with native flora under natural conditions. herbivores associated with two exotic plants, namely senecio inaequidens and s. pterophorus, and two coexisting natives, namely s. vulgaris and s. lividus, were surveyed in a replicated long\u2010term field study to ascertain whether the plant\u2013herbivore assemblages in mixed communities are related to plant novelty and insect diet breadth. native herbivores used exotic senecio as their host plants. of the 19 species of lepidoptera, diptera, and hemiptera found in this survey, 14 were associated with the exotic senecio plants. most of these species were polyphagous, yet we found a higher number of individuals with a narrow diet breadth, which is contrary to the assumption that host switching mainly occurs in generalist herbivores. the senecio specialist sphenella marginata (diptera: tephritidae) was the most abundant and widely distributed insect species (ca. 80% of the identified specimens). sphenella was associated with s. lividus, s. vulgaris and s. inaequidens and was not found on s. pterophorus. the presence of native plant congeners in the invaded community did not ensure an instantaneous ecological fitting between insects and alien plants. we conclude that novel associations between native herbivores and introduced senecio plants are common under natural conditions. plant novelty is, however, not the only predictor of herbivore abundance due to the complexity of natural conditions.",
            "contribution_ids": [
                "R57903"
            ]
        },
        {
            "instance_id": "R58002xR57904",
            "comparison_id": "R58002",
            "paper_id": "R57904",
            "text": "Escape from parasitism by the invasive alien ladybird, Harmonia axyridis alien species are often reported to perform better than functionally similar species native to the invaded range, resulting in high population densities, and a tendency to become invasive. the enemy release hypothesis (erh) explains the success of invasive alien species (ias) as a consequence of reduced mortality from natural enemies (predators, parasites and pathogens) compared with native species. the harlequin ladybird, harmonia axyridis, a species alien to britain, provides a model system for testing the erh. pupae of h. axyridis and the native ladybird coccinella septempunctata were monitored for parasitism between 2008 and 2011, from populations across southern england in areas first invaded by h. axyridis between 2004 and 2009. in addition, a semi\u2010field experiment was established to investigate the incidence of parasitism of adult h. axyridis and c. septempunctata by dinocampus coccinellae. harmonia axyridis pupae were parasitised at a much lower rate than conspecifics in the native range, and both pupae and adults were parasitised at a considerably lower rate than c. septempunctata populations from the same place and time (h. axyridis: 1.67%; c. septempunctata: 18.02%) or in previous studies on asian h. axyridis (2\u20137%). we found no evidence that the presence of h. axyridis affected the parasitism rate of c. septempunctata by d. coccinellae. our results are consistent with the general prediction that the prevalence of natural enemies is lower for introduced species than for native species at early stages of invasion. this may partly explain why h. axyridis is such a successful ias.",
            "contribution_ids": [
                "R57905",
                "R57906"
            ]
        },
        {
            "instance_id": "R58002xR57943",
            "comparison_id": "R58002",
            "paper_id": "R57943",
            "text": "Comparison of invertebrate herbivores on native and non-native Senecio species: Implications for the enemy release hypothesis the enemy release hypothesis posits that non-native plant species may gain a competitive advantage over their native counterparts because they are liberated from co-evolved natural enemies from their native area. the phylogenetic relationship between a non-native plant and the native community may be important for understanding the success of some non-native plants, because host switching by insect herbivores is more likely to occur between closely related species. we tested the enemy release hypothesis by comparing leaf damage and herbivorous insect assemblages on the invasive species senecio madagascariensis\\u2005poir. to that on nine congeneric species, of which five are native to the study area, and four are non-native but considered non-invasive. non-native species had less leaf damage than natives overall, but we found no significant differences in the abundance, richness and shannon diversity of herbivores between native and non-native senecio\\u2005l. species. the herbivore assemblage and percentage abundance of herbivore guilds differed among all senecio species, but patterns were not related to whether the species was native or not. species-level differences indicate that s.\\u2009madagascariensis may have a greater proportion of generalist insect damage (represented by phytophagous leaf chewers) than the other senecio species. within a plant genus, escape from natural enemies may not be a sufficient explanation for why some non-native species become more invasive than others.",
            "contribution_ids": [
                "R57944",
                "R57945",
                "R57946",
                "R57947"
            ]
        },
        {
            "instance_id": "R58002xR57948",
            "comparison_id": "R58002",
            "paper_id": "R57948",
            "text": "The parasite community of gobiid fishes (Actinopterygii: Gobiidae) from the Lower Volga River region abstract the parasitic fauna in the lower volga river basin was investigated for four gobiid species: the nonindigenous monkey goby neogobius fluviatilis (pallas, 1814), the round goby n. melanostomus (pallas, 1814), the caspian bighead goby ponticola gorlap (iljin, 1949), and the tubenose goby proterorhinus cf. semipellucidus (kessler, 1877). in total, 19 species of goby parasites were identified, of which two - bothriocephalus opsariichthydis yamaguti, 1934 and nicolla skrjabini (iwanitzki, 1928) - appeared to have been introduced from other geographic regions. the monkey goby had significantly fewer parasitic species (6), but relatively high levels of infection, in comparison to the native species. parasitism of the caspian bighead goby, which is the only predatory fish among the studied gobies, differed from the others according to the results of discriminant analysis. the parasitic fauna of the tubenose goby more closely resembled those of caspian sea gobiids, rather than the black sea monkey goby.",
            "contribution_ids": [
                "R57949"
            ]
        },
        {
            "instance_id": "R58002xR57959",
            "comparison_id": "R58002",
            "paper_id": "R57959",
            "text": "No release for the wicked: enemy release is dynamic and not associated with invasiveness the enemy release hypothesis predicts that invasive species will receive less damage from enemies, compared to co-occurring native and noninvasive exotic species in their introduced range. however, release operating early in invasion could be lost over time and with increased range size as introduced species acquire new enemies. we used three years of data, from 61 plant species planted into common gardens, to determine whether (1) invasive, noninvasive exotic, and native species experience differential damage from insect herbivores. and mammalian browsers, and (2) enemy release is lost with increased residence time and geographic spread in the introduced range. we find no evidence suggesting enemy release is a general mechanism contributing to invasiveness in this region. invasive species received the most insect herbivory, and damage increased with longer residence times and larger range sizes at three spatial scales. our results show that invasive and exotic species fail to escape enemies, particularly over longer temporal and larger spatial scales.",
            "contribution_ids": [
                "R57960",
                "R57961"
            ]
        },
        {
            "instance_id": "R58002xR57964",
            "comparison_id": "R58002",
            "paper_id": "R57964",
            "text": "Natural selection on plant resistance to herbivores in the native and introduced range plants introduced into a new range are expected to harbour fewer specialized herbivores and to receive less damage than conspecifics in native ranges. datura stramonium was introduced in spain about five centuries ago. here, we compare damage by herbivores, plant size, and leaf trichomes between plants from non-native and native ranges and perform selection analyses. non-native plants experienced much less damage, were larger and less pubescent than plants of native populations. while plant size was related to fitness in both ranges, selection to increase resistance was only detected in the native region. we suggest this is a consequence of a release from enemies in this new environment.",
            "contribution_ids": [
                "R57965"
            ]
        },
        {
            "instance_id": "R58002xR57971",
            "comparison_id": "R58002",
            "paper_id": "R57971",
            "text": "Insect assemblages associated with the exotic riparian shrub Russian olive (Elaeagnaceae), and co-occurring native shrubs in British Columbia, Canada abstract russian olive ( elaeagnus angustifolia linnaeus; elaeagnaceae) is an exotic shrub/tree that has become invasive in many riparian ecosystems throughout semi-arid, western north america, including southern british columbia, canada. despite its prevalence and the potentially dramatic impacts it can have on riparian and aquatic ecosystems, little is known about the insect communities associated with russian olive within its invaded range. at six sites throughout the okanagan valley of southern british columbia, canada, we compared the diversity of insects associated with russian olive plants to that of insects associated with two commonly co-occurring native plant species: woods\u2019 rose ( rosa woodsii lindley; rosaceae) and saskatoon ( amelanchier alnifolia (nuttall) nuttall ex roemer; rosaceae). total abundance did not differ significantly among plant types. family richness and shannon diversity differed significantly between woods\u2019 rose and saskatoon, but not between either of these plant types and russian olive. an abundance of thripidae (thysanoptera) on russian olive and tingidae (hemiptera) on saskatoon contributed to significant compositional differences among plant types. the families chloropidae (diptera), heleomyzidae (diptera), and gryllidae (orthoptera) were uniquely associated with russian olive, albeit in low abundances. our study provides valuable and novel information about the diversity of insects associated with an emerging plant invader of western canada.",
            "contribution_ids": [
                "R57972"
            ]
        },
        {
            "instance_id": "R6757xR6268",
            "comparison_id": "R6757",
            "paper_id": "R6268",
            "text": "Intui2: a prototype system for question answering over linked data an ever increasing amount of linked data is made available every day. public triple stores offer the possibility of querying hundreds of millions of triples. but this information can only be retrieved using specialized query languages like sparql, so for the majority of internet users, it is still unavailable. this paper presents a prototype system aimed at streamlining the access to the information stored as rdf. the system takes as input a natural language question formulated in english and generates an equivalent sparql query. the mapping is based on the analysis of the syntactic patterns present in the input question. in the initial evaluation results, against the 99 questions in the qald-3 dbpedia test set, the system provides a correct answer to 30 questions and a partial answer for another 3 questions, achieving an f-measure of 0.32.",
            "contribution_ids": [
                "R6269"
            ]
        },
        {
            "instance_id": "R6757xR6271",
            "comparison_id": "R6757",
            "paper_id": "R6271",
            "text": "Answering natural language questions with Intui3 intui3 is one of the participating systems at the fourth evaluation campaign on multilingual question answering over linked data, qald4. the system accepts as input a question formulated in natural language (in english), and uses syntactic and semantic information to construct its interpretation with respect to a given database of rdf triples (in this case dbpedia 3.9). the interpretation is mapped to the corresponding sparql query, which is then run against a sparql endpoint to retrieve the answers to the initial question. intui3 competed in the challenge called task 1: multilingual question answering over linked data, which offered 200 training questions and 50 test questions in 7 different languages. it obtained an f-measure of 0.24 by providing a correct answer to 10 of the test questions and a partial answer to 4 of them.",
            "contribution_ids": [
                "R6272"
            ]
        },
        {
            "instance_id": "R6757xR6322",
            "comparison_id": "R6757",
            "paper_id": "R6322",
            "text": "ISOFT at QALD-4: semantic similarity-based question answering system over linked data we present a question answering system over linked data. we use natural language processing tools to extract slots and sparql templates from the question. then, we use semantic similarity to map a natural language question to a sparql query. we combine important words to avoid loss of meaning, and compare combined words with uniform resource identifiers (uris) from a knowledgebase (kb). this process is more powerful than comparing each word individually. using our method, the problem of mapping a phrase of a user question to uris from a kb can be more easily solved than without our method; this method improves the f-measure of the system.",
            "contribution_ids": [
                "R6323"
            ]
        },
        {
            "instance_id": "R68535xR54884",
            "comparison_id": "R68535",
            "paper_id": "R54884",
            "text": "Past warming trend constrains future warming in CMIP6 models strong future warming in some new climate models is less likely as their recent warming is inconsistent with observed trends.",
            "contribution_ids": [
                "R54890",
                "R54893",
                "R54896",
                "R54899",
                "R54901",
                "R54902",
                "R54903",
                "R54904",
                "R54905",
                "R54906",
                "R54907",
                "R54908",
                "R54909",
                "R54910",
                "R54911",
                "R54912",
                "R54913",
                "R54914",
                "R54915",
                "R54916",
                "R54917",
                "R54918",
                "R54919",
                "R54920",
                "R54921",
                "R54922",
                "R54923",
                "R54924",
                "R54925",
                "R54951"
            ]
        },
        {
            "instance_id": "R6947xR6693",
            "comparison_id": "R6947",
            "paper_id": "R6693",
            "text": "TEXT2TABLE: Medical Text Summarization System Based on Named Entity Recognition and Modality Identification \"with the rapidly growing use of electronic health records, the possibility of large-scale clinical information extraction has drawn much attention. it is not, however, easy to extract information because these reports are written in natural language. to address this problem, this paper presents a system that converts a medical text into a table structure. this system's core technologies are (1) medical event recognition modules and (2) a negative event identification module that judges whether an event actually occurred or not. regarding the latter module, this paper also proposes an svm-based classifier using syntactic information. experimental results demonstrate empirically that syntactic information can contribute to the method's accuracy.\"",
            "contribution_ids": [
                "R6694"
            ]
        },
        {
            "instance_id": "R6947xR6701",
            "comparison_id": "R6947",
            "paper_id": "R6701",
            "text": "Multi-document summarisation using generic relation extraction experiments are reported that investigate the effect of various source document representations on the accuracy of the sentence extraction phase of a multi-document summarisation task. a novel representation is introduced based on generic relation extraction (gre), which aims to build systems for relation identification and characterisation that can be transferred across domains and tasks without modification of model parameters. results demonstrate performance that is significantly higher than a non-trivial baseline that uses tf*idf-weighted words and at least as good as a comparable but less general approach from the literature. analysis shows that the representations compared are complementary, suggesting that extraction performance could be further improved through system combination.",
            "contribution_ids": [
                "R6702"
            ]
        },
        {
            "instance_id": "R6947xR6715",
            "comparison_id": "R6947",
            "paper_id": "R6715",
            "text": "Automatic Multi-document Summarization Based on Clustering and Nonnegative Matrix Factorization abstract in this paper, a novel summarization method that uses nonnegative matrix factorization (nmf) and the clustering method is introduced to extract meaningful sentences relevant to a given query. the proposed method decomposes a sentence into the linear combination of sparse nonnegative semantic features so that it can represent a sentence as the sum of a few semantic features that are comprehensible intuitively. it can improve the quality of document summaries because it can avoid extracting those sentences whose similarities with the query are high but that are meaningless by using the similarity between the query and the semantic features. in addition, the proposed approach uses the clustering method to remove noise and avoid the biased inherent semantics of the documents being reflected in summaries. the method can ensure the coherence of summaries by using the rank score of sentences with respect to semantic features. the experimental results demonstrate that the proposed method has better performance than other methods that use the thesaurus, the latent semantic analysis (lsa), the k-means, and the nmf.",
            "contribution_ids": [
                "R6716"
            ]
        },
        {
            "instance_id": "R6947xR6719",
            "comparison_id": "R6947",
            "paper_id": "R6719",
            "text": "ThemeCrowds: multiresolution summaries of twitter usage users of social media sites, such as twitter, rapidly generate large volumes of text content on a daily basis. visual summaries are needed to understand what groups of people are saying collectively in this unstructured text data. users will typically discuss a wide variety of topics, where the number of authors talking about a specific topic can quickly grow or diminish over time, and what the collective is saying about the subject can shift as a situation develops. in this paper, we present a technique that summarises what collections of twitter users are saying about certain topics over time. as the correct resolution for inspecting the data is unknown in advance, the users are clustered hierarchically over a fixed time interval based on the similarity of their posts. the visualisation technique takes this data structure as its input. given a topic, it finds the correct resolution of users at each time interval and provides tags to summarise what the collective is discussing. the technique is tested on a large microblogging corpus, consisting of millions of tweets and over a million users.",
            "contribution_ids": [
                "R6720"
            ]
        },
        {
            "instance_id": "R6947xR6697",
            "comparison_id": "R6947",
            "paper_id": "R6697",
            "text": "OHSU Summarization and Entity Linking Systems we present two distinct text analysis systems. we first present two supervised sentence ranking approaches for use in extractive update summarization. for the first, we use the same general machine learning approach described in fisher and roark (2008) for update summarization. in the second, we use a similar machine learning approach, but include sub-sentential units produced by our discourse segmenter, see fisher and roark (2007b), as possible units for inclusion in a summary. interestingly, we find that one approach performs significantly better in the production of the base summary, while the other approach performs significantly better in the update summary. we then present a large-corpus entity linking system. this system expands queries using internal links within wikipedia and link entities with minimum-spanning-tree clustering. we present and evaluate empirical results on the tac 2009 knowledge-base-population data, and demonstrate competitive results with a simple system.",
            "contribution_ids": [
                "R6698"
            ]
        },
        {
            "instance_id": "R6948xR6586",
            "comparison_id": "R6948",
            "paper_id": "R6586",
            "text": "A multilingual news summarizer huge multilingual news articles are reported and disseminated on the internet. how to extract the key information and save the reading time is a crucial issue. this paper proposes architecture of multilingual news summarizer, including monolingual and multilingual clustering, similarity measure among meaningful units, and presentation of summarization results. translation among news stories, idiosyncrasy among languages, implicit information, and user preference are addressed.",
            "contribution_ids": [
                "R6587"
            ]
        },
        {
            "instance_id": "R6948xR6575",
            "comparison_id": "R6948",
            "paper_id": "R6575",
            "text": "Generating Natural Language Summaries from Multiple On-Line Sources we present a methodology for summarization of news about current events in the form of briefings that include appropriate background (historical) information. the system that we developed, summons, uses the output of systems developed for the darpa message understanding conferences to generate summaries of multiple documents on the same or related events, presenting similarities and differences, contradictions, and generalizations among sources of information. we describe the various components of the system, showing how information from multiple articles is combined, organized into a paragraph, and finally, realized as english sentences. a feature of our work is the extraction of descriptions of entities such as people and places for reuse to enhance a briefing.",
            "contribution_ids": [
                "R6576"
            ]
        },
        {
            "instance_id": "R6948xR6607",
            "comparison_id": "R6948",
            "paper_id": "R6607",
            "text": "GLEANS: A Generator of Logical Extracts and Abstracts for Nice Summaries generator postprocessor abstract with headline o j n u j n \\x80 j z y u y \\x7f y l jwith headline o j n u j n \\x80 j z y u y \\x7f y l j",
            "contribution_ids": [
                "R6608"
            ]
        },
        {
            "instance_id": "R69680xR69558",
            "comparison_id": "R69680",
            "paper_id": "R69558",
            "text": "A framework for explainable deep neural models using external knowledge graphs deep neural networks (dnns) have become the gold standard for solving challenging classification problems, especially given complex sensor inputs (e.g., images and video). while dnns are powerful, they are also brittle, and their inner workings are not fully understood by humans, leading to their use as \u201cblack-box\u201d models. dnns often generalize poorly when provided new data sampled from slightly shifted distributions; dnns are easily manipulated by adversarial examples; and the decision-making process of dnns can be difficult for humans to interpret. to address these challenges, we propose integrating dnns with external sources of semantic knowledge. large quantities of meaningful, formalized knowledge are available in knowledge graphs and other databases, many of which are publicly obtainable. but at present, these sources are inaccessible to deep neural methods, which can only exploit patterns in the signals they are given to classify. in this work, we conduct experiments on the ade20k dataset, using scene classification as an example task where combining dnns with external knowledge graphs can result in more robust and explainable models. we align the atomic concepts present in ade20k (i.e., objects) to wordnet, a hierarchically-organized lexical database. using this knowledge graph, we expand the concept categories which can be identified in ade20k and relate these concepts in a hierarchical manner. the neural architecture we present performs scene classification using these concepts, illuminating a path toward dnns which can efficiently exploit high-level knowledge in place of excessive quantities of direct sensory input. we hypothesize and experimentally validate that incorporating background knowledge via an external knowledge graph into a deep learning-based model should improve the explainability and robustness of the model.",
            "contribution_ids": [
                "R69559"
            ]
        },
        {
            "instance_id": "R69680xR69568",
            "comparison_id": "R69680",
            "paper_id": "R69568",
            "text": "Zero-shot recognition via semantic embeddings and knowledge graphs we consider the problem of zero-shot recognition: learning a visual classifier for a category with zero training examples, just using the word embedding of the category and its relationship to other categories, which visual data are provided. the key to dealing with the unfamiliar or novel category is to transfer knowledge obtained from familiar classes to describe the unfamiliar class. in this paper, we build upon the recently introduced graph convolutional network (gcn) and propose an approach that uses both semantic embeddings and the categorical relationships to predict the classifiers. given a learned knowledge graph (kg), our approach takes as input semantic embeddings for each node (representing visual category). after a series of graph convolutions, we predict the visual classifier for each category. during training, the visual classifiers for a few categories are given to learn the gcn parameters. at test time, these filters are used to predict the visual classifiers of unseen categories. we show that our approach is robust to noise in the kg. more importantly, our approach provides significant improvement in performance compared to the current state-of-the-art results (from 2 ~ 3% on some metrics to whopping 20% on a few).",
            "contribution_ids": [
                "R69569"
            ]
        },
        {
            "instance_id": "R69680xR69577",
            "comparison_id": "R69680",
            "paper_id": "R69577",
            "text": "Knowledgeable reader: Enhancing cloze-style read- ing comprehension with external commonsense knowledge we introduce a neural reading comprehension model that integrates external commonsense knowledge, encoded as a key-value memory, in a cloze-style setting. instead of relying only on document-to-question interaction or discrete features as in prior work, our model attends to relevant external knowledge and combines this knowledge with the context representation before inferring the answer. this allows the model to attract and imply knowledge from an external knowledge source that is not explicitly stated in the text, but that is relevant for inferring the answer. our model improves results over a very strong baseline on a hard common nouns dataset, making it a strong competitor of much more complex models. by including knowledge explicitly, our model can also provide evidence about the background knowledge used in the rc process.",
            "contribution_ids": [
                "R69578"
            ]
        },
        {
            "instance_id": "R69680xR69584",
            "comparison_id": "R69680",
            "paper_id": "R69584",
            "text": "Exploring knowledge graphs in an interpretable composite approach for text entailment, recognizing textual entailment is a key task for many semantic applications, such as question answering, text summarization, and information extraction, among others. entailment scenarios can range from a simple syntactic variation to more complex semantic relationships between pieces of text, but most approaches try a one-size-fits-all solution that usually favors some scenario to the detriment of another. we propose a composite approach for recognizing text entailment which analyzes the entailment pair to decide whether it must be resolved syntactically or semantically. we also make the answer interpretable: whenever an entailment is solved semantically, we explore a knowledge base composed of structured lexical definitions to generate natural language humanlike justifications, explaining the semantic relationship holding between the pieces of text. besides outperforming wellestablished entailment algorithms, our composite approach gives an important step towards explainable ai, using world knowledge to make the semantic reasoning process explicit and understandable.",
            "contribution_ids": [
                "R69585"
            ]
        },
        {
            "instance_id": "R69680xR69592",
            "comparison_id": "R69680",
            "paper_id": "R69592",
            "text": "Conditional focused neural question answering with large-scale knowledge bases how can we enable computers to automatically answer questions like \"who created the character harry potter\"? carefully built knowledge bases provide rich sources of facts. however, it remains a challenge to answer factoid questions raised in natural language due to numerous expressions of one question. in particular, we focus on the most common questions --- ones that can be answered with a single fact in the knowledge base. we propose cfo, a conditional focused neural-network-based approach to answering factoid questions with knowledge bases. our approach first zooms in a question to find more probable candidate subject mentions, and infers the final answers with a unified conditional probabilistic framework. powered by deep recurrent neural networks and neural embeddings, our proposed cfo achieves an accuracy of 75.7% on a dataset of 108k questions - the largest public one to date. it outperforms the current state of the art by an absolute margin of 11.8%.",
            "contribution_ids": [
                "R69593"
            ]
        },
        {
            "instance_id": "R69680xR69599",
            "comparison_id": "R69680",
            "paper_id": "R69599",
            "text": "Explicit knowledge-based reasoning for visual question answering we describe a method for visual question answering which is capable of reasoning about an image on the basis of information extracted from a large-scale knowledge base. the method not only answers natural language questions using concepts not contained in the image, but can explain the reasoning by which it developed its answer. it is capable of answering far more complex questions than the predominant long short-term memory-based approach, and outperforms it significantly in testing. we also provide a dataset and a protocol by which to evaluate general visual question answering methods.",
            "contribution_ids": [
                "R69600"
            ]
        },
        {
            "instance_id": "R69680xR69619",
            "comparison_id": "R69680",
            "paper_id": "R69619",
            "text": "Knowledge-driven stock trend prediction and explanation via temporal convolutional network deep neural networks have achieved promising results in stock trend prediction. however, most of these models have two common drawbacks, including (i) current methods are not sensitive enough to abrupt changes of stock trend, and (ii) forecasting results are not interpretable for humans. to address these two problems, we propose a novel knowledge-driven temporal convolutional network (kdtcn) for stock trend prediction and explanation. firstly, we extract structured events from financial news, and utilize external knowledge from knowledge graph to obtain event embeddings. then, we combine event embeddings and price values together to forecast stock trend. we evaluate the prediction accuracy to show how knowledge-driven events work on abrupt changes. we also visualize the effect of events and linkage among events based on knowledge graph, to explain why knowledge-driven events are common sources of abrupt changes. experiments demonstrate that kdtcn can (i) react to abrupt changes much faster and outperform state-of-the-art methods on stock datasets, as well as (ii) facilitate the explanation of prediction particularly with abrupt changes.",
            "contribution_ids": [
                "R69620"
            ]
        },
        {
            "instance_id": "R69680xR69623",
            "comparison_id": "R69680",
            "paper_id": "R69623",
            "text": "Knowledge-based transfer learning explanation \"machine learning explanation can significantly boost machine learning's application in decision making, but the usability of current methods is limited in human-centric explanation, especially for transfer learning, an important machine learning branch that aims at utilizing knowledge from one learning domain (i.e., a pair of dataset and prediction task) to enhance prediction model training in another learning domain. in this paper , we propose an ontology-based approach for human-centric explanation of transfer learning. three kinds of knowledge-based explanatory evidence, with different granularities, including general factors, particular narrators and core contexts are first proposed and then inferred with both local ontologies and external knowledge bases. the evaluation with us flight data and db-pedia has presented their confidence and availability in explaining the transferability of feature representation in flight departure delay forecasting.\"",
            "contribution_ids": [
                "R69624"
            ]
        },
        {
            "instance_id": "R69680xR69626",
            "comparison_id": "R69680",
            "paper_id": "R69626",
            "text": "Semantic explanations of predictions the main objective of explanations is to transmit knowledge to humans. this work proposes to construct informative explanations for predictions made from machine learning models. motivated by the observations from social sciences, our approach selects data points from the training sample that exhibit special characteristics crucial for explanation, for instance, ones contrastive to the classification prediction and ones representative of the models. subsequently, semantic concepts are derived from the selected data points through the use of domain ontologies. these concepts are filtered and ranked to produce informative explanations that improves human understanding. the main features of our approach are that (1) knowledge about explanations is captured in the form of ontological concepts, (2) explanations include contrastive evidences in addition to normal evidences, and (3) explanations are user relevant.",
            "contribution_ids": [
                "R69627"
            ]
        },
        {
            "instance_id": "R69680xR69630",
            "comparison_id": "R69680",
            "paper_id": "R69630",
            "text": "Deep knowledge-aware network for news recommendation online news recommender systems aim to address the information explosion of news and make personalized recommendation for users. in general, news language is highly condensed, full of knowledge entities and common sense. however, existing methods are unaware of such external knowledge and cannot fully discover latent knowledge-level connections among news. the recommended results for a user are consequently limited to simple patterns and cannot be extended reasonably. to solve the above problem, in this paper, we propose a deep knowledge-aware network (dkn) that incorporates knowledge graph representation into news recommendation. dkn is a content-based deep recommendation framework for click-through rate prediction. the key component of dkn is a multi-channel and word-entity-aligned knowledge-aware convolutional neural network (kcnn) that fuses semantic-level and knowledge-level representations of news. kcnn treats words and entities as multiple channels, and explicitly keeps their alignment relationship during convolution. in addition, to address users\u00bb diverse interests, we also design an attention module in dkn to dynamically aggregate a user\u00bbs history with respect to current candidate news. through extensive experiments on a real online news platform, we demonstrate that dkn achieves substantial gains over state-of-the-art deep recommendation models. we also validate the efficacy of the usage of knowledge in dkn.",
            "contribution_ids": [
                "R69631"
            ]
        },
        {
            "instance_id": "R69680xR69641",
            "comparison_id": "R69680",
            "paper_id": "R69641",
            "text": "Explod: a framework for explaining recommendations based on the linked open data cloud in this paper we present explod, a framework which exploits the information available in the linked open data (lod) cloud to generate a natural language explanation of the suggestions produced by a recommendation algorithm. the methodology is based on building a graph in which the items liked by a user are connected to the items recommended through the properties available in the lod cloud. next, given this graph, we implemented some techniques to rank those properties and we used the most relevant ones to feed a module for generating explanations in natural language. in the experimental evaluation we performed a user study with 308 subjects aiming to investigate to what extent our explanation framework can lead to more transparent, trustful and engaging recommendations. the preliminary results provided us with encouraging findings, since our algorithm performed better than both a non-personalized explanation baseline and a popularity-based one.",
            "contribution_ids": [
                "R69642"
            ]
        },
        {
            "instance_id": "R70287xR69999",
            "comparison_id": "R70287",
            "paper_id": "R69999",
            "text": "Human organ chip-enabled pipeline to rapidly repurpose therapeutics during viral pandemics the rising threat of pandemic viruses, such as sars-cov-2, requires development of new preclinical discovery platforms that can more rapidly identify therapeutics that are active in vitro and also translate in vivo . here we show that human organ-on-a-chip (organ chip) microfluidic culture devices lined by highly differentiated human primary lung airway epithelium and endothelium can be used to model virus entry, replication, strain-dependent virulence, host cytokine production, and recruitment of circulating immune cells in response to infection by respiratory viruses with great pandemic potential. we provide a first demonstration of drug repurposing by using oseltamivir in influenza a virus-infected organ chip cultures and show that co-administration of the approved anticoagulant drug, nafamostat, can double oseltamivir\u2019s therapeutic time window. with the emergence of the covid-19 pandemic, the airway chips were used to assess the inhibitory activities of approved drugs that showed inhibition in traditional cell culture assays only to find that most failed when tested in the organ chip platform. when administered in human airway chips under flow at a clinically relevant dose, one drug \u2013 amodiaquine - significantly inhibited infection by a pseudotyped sars-cov-2 virus. proof of concept was provided by showing that amodiaquine and its active metabolite (desethylamodiaquine) also significantly reduce viral load in both direct infection and animal-to-animal transmission models of native sars-cov-2 infection in hamsters. these data highlight the value of organ chip technology as a more stringent and physiologically relevant platform for drug repurposing, and suggest that amodiaquine should be considered for future clinical testing.",
            "contribution_ids": [
                "R70000",
                "R70045"
            ]
        },
        {
            "instance_id": "R70287xR51231",
            "comparison_id": "R70287",
            "paper_id": "R51231",
            "text": "Broad anti-coronaviral activity of FDA approved drugs against SARS-CoV-2 in vitro and SARS-CoV in vivo abstract sars-cov-2 emerged in china at the end of 2019 and has rapidly become a pandemic with roughly 2.7 million recorded covid-19 cases and greater than 189,000 recorded deaths by april 23rd, 2020 ( www.who.org ). there are no fda approved antivirals or vaccines for any coronavirus, including sars-cov-2. current treatments for covid-19 are limited to supportive therapies and off-label use of fda approved drugs. rapid development and human testing of potential antivirals is greatly needed. a quick way to test compounds with potential antiviral activity is through drug repurposing. numerous drugs are already approved for human use and subsequently there is a good understanding of their safety profiles and potential side effects, making them easier to fast-track to clinical studies in covid-19 patients. here, we present data on the antiviral activity of 20 fda approved drugs against sars-cov-2 that also inhibit sars-cov and mers-cov. we found that 17 of these inhibit sars-cov-2 at a range of ic50 values at non-cytotoxic concentrations. we directly follow up with seven of these to demonstrate all are capable of inhibiting infectious sars-cov-2 production. moreover, we have evaluated two of these, chloroquine and chlorpromazine, in vivo using a mouse-adapted sars-cov model and found both drugs protect mice from clinical disease.",
            "contribution_ids": [
                "R70095",
                "R70138",
                "R70153",
                "R70172",
                "R51233",
                "R51413"
            ]
        },
        {
            "instance_id": "R70287xR51386",
            "comparison_id": "R70287",
            "paper_id": "R51386",
            "text": "In vitro screening of a FDA approved chemical library reveals potential inhibitors of SARS-CoV-2 replication abstract a novel coronavirus, named sars-cov-2, emerged in 2019 in china and rapidly spread worldwide. as no approved therapeutics exists to treat covid-19, the disease associated to sars-cov-2, there is an urgent need to propose molecules that could quickly enter into clinics. repurposing of approved drugs is a strategy that can bypass the time-consuming stages of drug development. in this study, we screened the prestwick chemical library composed of 1,520 approved drugs in an infected cell-based assay. the robustness of the screen was assessed by the identification of drugs that already demonstrated in vitro antiviral effect against sars-cov-2. thereby, 90 compounds were identified as positive hits from the screen and were grouped according to their chemical composition and their known therapeutic effect. then ec50 and cc50 were determined for a subset of 15 compounds from a panel of 23 selected drugs covering the different groups. eleven compounds such as macrolides antibiotics, proton pump inhibitors, antiarrhythmic agents or cns drugs emerged showing antiviral potency with 2\\u2009&lt;\\u2009ec50\\u2009\u2264\\u200920\\xa0\u00b5m. by providing new information on molecules inhibiting sars-cov-2 replication in vitro, this study provides information for the selection of drugs to be further validated in vivo. disclaimer: this study corresponds to the early stages of antiviral development and the results do not support by themselves the use of the selected drugs to treat sars-cov-2 infection.",
            "contribution_ids": [
                "R51388",
                "R51404"
            ]
        },
        {
            "instance_id": "R70584xR70554",
            "comparison_id": "R70584",
            "paper_id": "R70554",
            "text": "Prediction of Sepsis in the Intensive Care Unit With Minimal Electronic Health Record Data: A Machine Learning Approach background sepsis is one of the leading causes of mortality in hospitalized patients. despite this fact, a reliable means of predicting sepsis onset remains elusive. early and accurate sepsis onset predictions could allow more aggressive and targeted therapy while maintaining antimicrobial stewardship. existing detection methods suffer from low performance and often require time-consuming laboratory test results. objective to study and validate a sepsis prediction method, insight, for the new sepsis-3 definitions in retrospective data, make predictions using a minimal set of variables from within the electronic health record data, compare the performance of this approach with existing scoring systems, and investigate the effects of data sparsity on insight performance. methods we apply insight, a machine learning classification system that uses multivariable combinations of easily obtained patient data (vitals, peripheral capillary oxygen saturation, glasgow coma score, and age), to predict sepsis using the retrospective multiparameter intelligent monitoring in intensive care (mimic)-iii dataset, restricted to intensive care unit (icu) patients aged 15 years or more. following the sepsis-3 definitions of the sepsis syndrome, we compare the classification performance of insight versus quick sequential organ failure assessment (qsofa), modified early warning score (mews), systemic inflammatory response syndrome (sirs), simplified acute physiology score (saps) ii, and sequential organ failure assessment (sofa) to determine whether or not patients will become septic at a fixed period of time before onset. we also test the robustness of the insight system to random deletion of individual input observations. results in a test dataset with 11.3% sepsis prevalence, insight produced superior classification performance compared with the alternative scores as measured by area under the receiver operating characteristic curves (auroc) and area under precision-recall curves (apr). in detection of sepsis onset, insight attains auroc = 0.880 (sd 0.006) at onset time and apr = 0.595 (sd 0.016), both of which are superior to the performance attained by sirs (auroc: 0.609; apr: 0.160), qsofa (auroc: 0.772; apr: 0.277), and mews (auroc: 0.803; apr: 0.327) computed concurrently, as well as saps ii (auroc: 0.700; apr: 0.225) and sofa (auroc: 0.725; apr: 0.284) computed at admission (p<.001 for all comparisons). similar results are observed for 1-4 hours preceding sepsis onset. in experiments where approximately 60% of input data are deleted at random, insight attains an auroc of 0.781 (sd 0.013) and apr of 0.401 (sd 0.015) at sepsis onset time. even with 60% of data missing, insight remains superior to the corresponding sirs scores (auroc and apr, p<.001), qsofa scores (p=.0095; p<.001) and superior to sofa and saps ii computed at admission (auroc and apr, p<.001), where all of these comparison scores (except insight) are computed without data deletion. conclusions despite using little more than vitals, insight is an effective tool for predicting sepsis onset and performs well even with randomly missing data.",
            "contribution_ids": [
                "R70555",
                "R70577"
            ]
        },
        {
            "instance_id": "R70584xR70566",
            "comparison_id": "R70584",
            "paper_id": "R70566",
            "text": "From vital signs to clinical outcomes for patients with sepsis: a machine learning basis for a clinical decision support system \"objective\\nto develop a decision support system to identify patients at high risk for hyperlactatemia based upon routinely measured vital signs and laboratory studies.\\n\\n\\nmaterials and methods\\nelectronic health records of 741 adult patients at the university of california davis health system who met at least two systemic inflammatory response syndrome criteria were used to associate patients' vital signs, white blood cell count (wbc), with sepsis occurrence and mortality. generative and discriminative classification (na\u00efve bayes, support vector machines, gaussian mixture models, hidden markov models) were used to integrate heterogeneous patient data and form a predictive tool for the inference of lactate level and mortality risk.\\n\\n\\nresults\\nan accuracy of 0.99 and discriminability of 1.00 area under the receiver operating characteristic curve (auc) for lactate level prediction was obtained when the vital signs and wbc measurements were analysed in a 24 h time bin. an accuracy of 0.73 and discriminability of 0.73 auc for mortality prediction in patients with sepsis was achieved with only three features: median of lactate levels, mean arterial pressure, and median absolute deviation of the respiratory rate.\\n\\n\\ndiscussion\\nthis study introduces a new scheme for the prediction of lactate levels and mortality risk from patient vital signs and wbc. accurate prediction of both these variables can drive the appropriate response by clinical staff and thus may have important implications for patient health and treatment outcome.\\n\\n\\nconclusions\\neffective predictions of lactate levels and mortality risk can be provided with a few clinical variables when the temporal aspect and variability of patient data are considered.\"",
            "contribution_ids": [
                "R70567",
                "R70583"
            ]
        },
        {
            "instance_id": "R70630xR70616",
            "comparison_id": "R70630",
            "paper_id": "R70616",
            "text": "An Unsupervised Multivariate Time Series Kernel Approach for Identifying Patients with Surgical Site Infection from Blood Samples a large fraction of the electronic health records consists of clinical measurements collected over time, such as blood tests, which provide important information about the health status of a patient. these sequences of clinical measurements are naturally represented as time series, characterized by multiple variables and the presence of missing data, which complicate analysis. in this work, we propose a surgical site infection detection framework for patients undergoing colorectal cancer surgery that is completely unsupervised, hence alleviating the problem of getting access to labelled training data. the framework is based on powerful kernels for multivariate time series that account for missing data when computing similarities. our approach show superior performance compared to baselines that have to resort to imputation techniques and performs comparable to a supervised classification baseline.",
            "contribution_ids": [
                "R70617"
            ]
        },
        {
            "instance_id": "R70630xR70622",
            "comparison_id": "R70630",
            "paper_id": "R70622",
            "text": "Improving Prediction of Surgical Site Infection Risk with Multilevel Modeling background surgical site infection (ssi) surveillance is a key factor in the elaboration of strategies to reduce ssi occurrence and in providing surgeons with appropriate data feedback (risk indicators, clinical prediction rule). aim to improve the predictive performance of an individual-based ssi risk model by considering a multilevel hierarchical structure. patients and methods data were collected anonymously by the french ssi active surveillance system in 2011. an ssi diagnosis was made by the surgical teams and infection control practitioners following standardized criteria. a random 20% sample comprising 151 hospitals, 502 wards and 62280 patients was used. three-level (patient, ward, hospital) hierarchical logistic regression models were initially performed. parameters were estimated using the simulation-based markov chain monte carlo procedure. results a total of 623 ssi were diagnosed (1%). the hospital level was discarded from the analysis as it did not contribute to variability of ssi occurrence (p \\u200a=\\u200a0.32). established individual risk factors (patient history, surgical procedure and hospitalization characteristics) were identified. a significant heterogeneity in ssi occurrence between wards was found (median odds ratio [mor] 3.59, 95% credibility interval [ci] 3.03 to 4.33) after adjusting for patient-level variables. the effects of the follow-up duration varied between wards (p<10\u22129), with an increased heterogeneity when follow-up was <15 days (mor 6.92, 95% ci 5.31 to 9.07]). the final two-level model significantly improved the discriminative accuracy compared to the single level reference model (p<10\u22129), with an area under the roc curve of 0.84. conclusion this study sheds new light on the respective contribution of patient-, ward- and hospital-levels to ssi occurrence and demonstrates the significant impact of the ward level over and above risk factors present at patient level (i.e., independently from patient case-mix).",
            "contribution_ids": [
                "R70623"
            ]
        },
        {
            "instance_id": "R76783xR76754",
            "comparison_id": "R76783",
            "paper_id": "R76754",
            "text": "A Comprehensive Survey of Knowledge Graph Embeddings with Literals: Techniques and Applications knowledge graphs are organized to describe entities from any discipline and the interrelations between them. apart from facilitating the inter-connectivity of datasets in the lod cloud, kgs have been used in a variety of applications such as web search or entity linking, and recently are part of popular search systems and q&a applications etc. however, the kg applications suffer from high computational and storage cost. hence, there arises the necessity of having a representation learning of the high dimensional kgs into low dimensional spaces preserving structural as well as relational information. in this study, we conduct a comprehensive survey based on techniques of kg embedding models which consider the structured information of the graph as well as the unstructured information in form of literals such as text, numerical values etc. furthermore, we address the challenges in their embedding models followed by a discussion on different application scenarios.",
            "contribution_ids": [
                "R76756"
            ]
        },
        {
            "instance_id": "R76783xR75675",
            "comparison_id": "R76783",
            "paper_id": "R75675",
            "text": "Knowledge Graph Refinement: A Survey of Approaches and Evaluation Methods in the recent years, different web knowledge graphs, both free and commercial, have been created. while google coined the term \"knowledge graph\" in 2012, there are also a few openly available knowledge graphs, with dbpedia, yago, and freebase being among the most prominent ones. those graphs are often constructed from semi-structured knowledge, such as wikipedia, or harvested from the web with a combination of statistical and linguistic methods. the result are large-scale knowledge graphs that try to make a good trade-off between completeness and correctness. in order to further increase the utility of such knowledge graphs, various refinement methods have been proposed, which try to infer and add missing knowledge to the graph, or identify erroneous pieces of information. in this article, we provide a survey of such knowledge graph refinement approaches, with a dual look at both the methods being proposed as well as the evaluation methodologies used.",
            "contribution_ids": [
                "R75677"
            ]
        },
        {
            "instance_id": "R8342xR8330",
            "comparison_id": "R8342",
            "paper_id": "R8330",
            "text": "An ontology of scientific experiments the formal description of experiments for efficient analysis, annotation and sharing of results is a fundamental part of the practice of science. ontologies are required to achieve this objective. a few subject-specific ontologies of experiments currently exist. however, despite the unity of scientific experimentation, no general ontology of experiments exists. we propose the ontology expo to meet this need. expo links the sumo (the suggested upper merged ontology) with subject-specific ontologies of experiments by formalizing the generic concepts of experimental design, methodology and results representation. expo is expressed in the w3c standard ontology language owl-dl. we demonstrate the utility of expo and its ability to describe different experimental domains, by applying it to two experiments: one in high-energy physics and the other in phylogenetics. the use of expo made the goals and structure of these experiments more explicit, revealed ambiguities, and highlighted an unexpected similarity. we conclude that, expo is of general value in describing experiments and a step towards the formalization of science.",
            "contribution_ids": [
                "R8331"
            ]
        }
    ]
}