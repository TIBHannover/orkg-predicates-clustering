{
    "instances": [
        {
            "instance_id": "R108358xR108135",
            "comparison_id": "R108358",
            "paper_id": "R108135",
            "text": "Mapping of hydrothermally altered rocks by the EO-1 Hyperion sensor, Northern Danakil Depression, Eritrea \"an eo\u20101 hyperion scene was used to identify and map hydrothermally altered rocks and a precambrian metamorphic sequence at and around the alid volcanic dome, at the northern danakil depression, eritrea. mapping was coupled with laboratory analyses, including reflectance measurements, x\u2010ray diffraction, and petrographic examination of selected rock samples. thematic maps were compiled from the dataset, which was carefully pre\u2010processed to evaluate and to correct interferences in the data. despite the difficulties, lithological mapping using narrow spectral bands proved possible. a spectral signature attributed to ammonium was detected in the laboratory measurements of hydrothermally altered rocks from alid. this was expressed as spectral absorption clues in the atmospherically corrected cube, at the known hydrothermally altered areas. the existence of ammonium in hydrothermally altered rocks within the alid dome has been confirmed by previous studies. spectral information of endmember's mineralogy found in the area (e.g. dolomite) enables a surface mineral map to be produced that stands in good agreement with the known geology along the overpass. these maps are the first hyperspectral overview of the surface mineralogy in this arid terrain and may be used as a base for future studies of remote areas such as the danakil.\"",
            "contribution_ids": [
                "R108136"
            ]
        },
        {
            "instance_id": "R108358xR108144",
            "comparison_id": "R108358",
            "paper_id": "R108144",
            "text": "Mapping of Alteration Zones in Mineral Rich Belt of South-East Rajasthan Using Remote Sensing Techniques remote sensing techniques have emerged as an asset for various geological studies. satellite images obtained by different sensors contain plenty of information related to the terrain. digital image processing further helps in customized ways for the prospecting of minerals. in this study, an attempt has been made to map the hydrothermally altered zones using multispectral and hyperspectral datasets of south east rajasthan. advanced spaceborne thermal emission and reflection radiometer (aster) and hyperion (level1r) dataset have been processed to generate different band ratio composites (brcs). for this study, aster derived brcs were generated to delineate the alteration zones, gossans, abundant clays and host rocks. aster and hyperion images were further processed to extract mineral end members and classified mineral maps have been produced using spectral angle mapper (sam) method. results were validated with the geological map of the area which shows positive agreement with the image processing outputs. thus, this study concludes that the band ratios and image processing in combination play significant role in demarcation of alteration zones which may provide pathfinders for mineral prospecting studies. keywords\u2014advanced space-borne thermal emission and reflection radiometer, aster, hyperion, band ratios, alteration zones, spectral angle mapper.",
            "contribution_ids": [
                "R108145"
            ]
        },
        {
            "instance_id": "R109612xR109394",
            "comparison_id": "R109612",
            "paper_id": "R109394",
            "text": "Heterotrophic bacteria as major nitrogen fixers in the euphotic zone of the Indian Ocean diazotrophy in the indian ocean is poorly understood compared to that in the atlantic and pacific oceans. we first examined the basin\u2010scale community structure of diazotrophs and their nitrogen fixation activity within the euphotic zone during the northeast monsoon period along about 69\u00b0e from 17\u00b0n to 20\u00b0s in the oligotrophic indian ocean, where a shallow nitracline (49\u201359\\u2009m) prevailed widely and the sea surface temperature (sst) was above 25\u00b0c. phosphate was detectable at the surface throughout the study area. the dissolved iron concentration and the ratio of iron to nitrate\\u2009+\\u2009nitrite at the surface were significantly higher in the arabian sea than in the equatorial and southern indian ocean. nitrogen fixation in the arabian sea (24.6\u201347.1 \u03bcmoln m\u22122 d\u22121) was also significantly greater than that in the equatorial and southern indian ocean (6.27\u201316.6 \u03bcmoln m\u22122 d\u22121), indicating that iron could control diazotrophy in the indian ocean. phylogenetic analysis of nifh showed that most diazotrophs belonged to the proteobacteria and that cyanobacterial diazotrophs were absent in the study area except in the arabian sea. furthermore, nitrogen fixation was not associated with light intensity throughout the study area. these results are consistent with nitrogen fixation in the indian ocean, being largely performed by heterotrophic bacteria and not by cyanobacteria. the low cyanobacterial diazotrophy was attributed to the shallow nitracline, which is rarely observed in the pacific and atlantic oligotrophic oceans. because the shallower nitracline favored enhanced upward nitrate flux, the competitive advantage of cyanobacterial diazotrophs over nondiazotrophic phytoplankton was not as significant as it is in other oligotrophic oceans.",
            "contribution_ids": [
                "R109395",
                "R109572",
                "R109590"
            ]
        },
        {
            "instance_id": "R109612xR108803",
            "comparison_id": "R109612",
            "paper_id": "R108803",
            "text": "Dinitrogen fixation rates in the Bay of Bengal during summer monsoon abstract \\n biological dinitrogen (n 2 ) fixation exerts an important control on oceanic primary production by providing bioavailable form of nitrogen (such as ammonium) to photosynthetic microorganisms. n 2 fixation is dominant in nutrient poor and warm surface waters. the bay of bengal is one such region where no measurements of phototrophic n 2 fixation rates exist. the surface water of the bay of bengal is generally nitrate-poor and warm due to prevailing stratification and thus, could favour n 2 fixation. we commenced the first n 2 fixation study in the photic zone of the bay of bengal using 15 n 2 gas tracer incubation experiment during summer monsoon 2018. we collected seawater samples from four depths (covering the mixed layer depth of up to 75 m) at eight stations. n 2 fixation rates varied from 4 to 75 \u03bc mol n m \u22122 d \u22121 . the contribution of n 2 fixation to primary production was negligible (&lt;1%). however, the upper bound of observed n 2 fixation rates is higher than the rates measured in other oceanic regimes, such as the eastern tropical south pacific, the tropical northwest atlantic, and the equatorial and southern indian ocean.",
            "contribution_ids": [
                "R108807",
                "R109398",
                "R109582",
                "R109597",
                "R138414"
            ]
        },
        {
            "instance_id": "R109904xR109860",
            "comparison_id": "R109904",
            "paper_id": "R109860",
            "text": "Applying weighted PageRank to author citation networks this article aims to identify whether different weighted pagerank algorithms can be applied to author citation networks to measure the popularity and prestige of a scholar from a citation perspective. information retrieval (ir) was selected as a test field and data from 1956\u20132008 were collected from web of science. weighted pagerank with citation and publication as weighted vectors were calculated on author citation networks. the results indicate that both popularity rank and prestige rank were highly correlated with the weighted pagerank. principal component analysis was conducted to detect relationships among these different measures. for capturing prize winners within the ir field, prestige rank outperformed all the other measures. \u00a9 2011 wiley periodicals, inc.",
            "contribution_ids": [
                "R109862"
            ]
        },
        {
            "instance_id": "R109904xR109894",
            "comparison_id": "R109904",
            "paper_id": "R109894",
            "text": "A Hybrid Approach Toward Research Paper Recommendation Using Centrality Measures and Author Ranking the volume of research articles in digital repositories is increasing. this spectacular growth of repositories makes it rather difficult for researchers to obtain related research papers in response to their queries. the problem becomes worse when a researcher with insufficient knowledge of searching research articles uses these repositories. in the traditional recommendation approaches, the results of the query miss many high-quality papers, in the related work section, which are either published recently or have low citation count. to overcome this problem, there needs to be a solution which considers not only structural relationships between the papers but also inspects the quality of authors publishing those articles. many research paper recommendation approaches have been implemented which includes collaborative filtering-based, content-based, and citation analysis-based techniques. the collaborative filtering-based approaches primarily use paper-citation matrix for recommendations, whereas the content-based approaches only consider the content of the paper. the citation analysis considers the structure of the network and focuses on papers citing or cited by the paper of interest. it is therefore very difficult for a recommender system to recommend high-quality papers without a hybrid approach that incorporates multiple features, such as citation information and author information. the proposed method creates a multilevel citation and relationship network of authors in which the citation network uses the structural relationship between the papers to extract significant papers, and authors\u2019 collaboration network finds key authors from those papers. the papers selected by this hybrid approach are then recommended to the user. the results have shown that our proposed method performs exceedingly well as compared with the state-of-the-art existing systems, such as google scholar and multilevel simultaneous citation network.",
            "contribution_ids": [
                "R109899"
            ]
        },
        {
            "instance_id": "R111045xR110913",
            "comparison_id": "R111045",
            "paper_id": "R110913",
            "text": "Multinuclear Lanthanide-Implanted Tetrameric Dawson-Type Phosphotungstates with Switchable Luminescence Behaviors Induced by Fast Photochromism a series of benzoate-decorated lanthanide (ln)-containing tetrameric dawson-type phosphotungstates [n(ch3)4]6h20[{(p2w17o61)ln(h2o)3ln(c6h5coo)(h2o)6]}{[(p2w17o61)ln(h2o)3}]2cl2\u00b798h2o [ln = sm (1), eu (2), and gd (3)] were made using a facile one-step assembly strategy and characterized by several techniques. notably, the ln-containing tetrameric dawson-type polyoxoanions [{(p2w17o61)ln(h2o)3ln(c6h5coo)(h2o)6]}{[(p2w17o61)ln(h2o)3}]224- are all established by four monolacunary dawson-type [p2w17o61]10- segments, encapsulating a ln3+ ion with two benzoates coordinating to the ln3+ ions. 1-3 exhibit reversible photochromism, which can change from intrinsic white to blue for 6 min upon uv irradiation, and their colors gradually recover for 30 h in the dark. the solid-state photoluminescence spectra of 1 and 2 display characteristic emissions of ln components based on 4f-4f transitions. time-resolved emission spectra of 1 and 2 were also measured to authenticate the energy transfer from the phosphotungstate and organic chromophores to eu3+. in particular, 1 shows an effectively switchable luminescence behavior induced by its fast photochromism.",
            "contribution_ids": [
                "R110916"
            ]
        },
        {
            "instance_id": "R111045xR110993",
            "comparison_id": "R111045",
            "paper_id": "R110993",
            "text": "Anilido-oxazoline-ligated rare-earth metal complexes: synthesis, characterization and highly cis-1,4-selective polymerization of isoprene anilido-oxazoline-ligated rare-earth metal complexes show strong fluorescence emissions and good catalytic performance on isoprene polymerization with high cis -1,4-selectivity.",
            "contribution_ids": [
                "R110998"
            ]
        },
        {
            "instance_id": "R112387xR78371",
            "comparison_id": "R112387",
            "paper_id": "R78371",
            "text": "Automatic Classification of Non-Functional Requirements from Augmented App User Reviews \"context: the leading app distribution platforms, apple app store, google play, and windows phone store, have over 4 million apps. research shows that user reviews contain abundant useful information which may help developers to improve their apps. extracting and considering non-functional requirements (nfrs), which describe a set of quality attributes wanted for an app and are hidden in user reviews, can help developers to deliver a product which meets users' expectations. objective: developers need to be aware of the nfrs from massive user reviews during software maintenance and evolution. automatic user reviews classification based on an nfr standard provides a feasible way to achieve this goal. method: in this paper, user reviews were automatically classified into four types of nfrs (reliability, usability, portability, and performance), functional requirements (frs), and others. we combined four classification techniques bow, tf-idf, chi2, and aur-bow (proposed in this work) with three machine learning algorithms naive bayes, j48, and bagging to classify user reviews. we conducted experiments to compare the f-measures of the classification results through all the combinations of the techniques and algorithms. results: we found that the combination of aur-bow with bagging achieves the best result (a precision of 71.4%, a recall of 72.3%, and an f-measure of 71.8%) among all the combinations. conclusion: our finding shows that augmented user reviews can lead to better classification results, and the machine learning algorithm bagging is more suitable for nfrs classification from user reviews than na\u00efve bayes and j48.\"",
            "contribution_ids": [
                "R78373"
            ]
        },
        {
            "instance_id": "R112387xR78432",
            "comparison_id": "R112387",
            "paper_id": "R78432",
            "text": "Software Feature Request Detection in Issue Tracking Systems communication about requirements is often handled in issue tracking systems, especially in a distributed setting. as issue tracking systems also contain bug reports or programming tasks, the software feature requests of the users are often difficult to identify. this paper investigates natural language processing and machine learning features to detect software feature requests in natural language data of issue tracking systems. it compares traditional linguistic machine learning features, such as \"bag of words\", with more advanced features, such as subject-action-object, and evaluates combinations of machine learning features derived from the natural language and features taken from the issue tracking system meta-data. our investigation shows that some combinations of machine learning features derived from natural language and the issue tracking system meta-data outperform traditional approaches. we show that issues or data fields (e.g. descriptions or comments), which contain software feature requests, can be identified reasonably well, but hardly the exact sentence. finally, we show that the choice of machine learning algorithms should depend on the goal, e.g. maximization of the detection rate or balance between detection rate and precision. in addition, the paper contributes a double coded gold standard and an open-source implementation to further pursue this topic.",
            "contribution_ids": [
                "R78434",
                "R198935"
            ]
        },
        {
            "instance_id": "R112387xR108208",
            "comparison_id": "R112387",
            "paper_id": "R108208",
            "text": "Facilitating developer-user interactions with mobile app review digests \"as users are interacting with a large of mobile apps under various usage contexts, user involvements in an app design process has become a critical issue. despite this fact, existing apps or app store platforms only provide a limited form of user involvements such as posting app reviews and sending email reports. while building a unified platform for facilitating user involvements with various apps is our ultimate goal, we present our preliminary work on handling developers' information overload attributed to a large number of app comments. to address this issue, we first perform a simple content analysis on app reviews from the developer's standpoint. we then propose an algorithm that automatically identifies informative reviews reflecting user involvements. the preliminary evaluation results document the efficiency of our algorithm.\"",
            "contribution_ids": [
                "R108210"
            ]
        },
        {
            "instance_id": "R112387xR112033",
            "comparison_id": "R112387",
            "paper_id": "R112033",
            "text": "Listening to the Crowd for the Release Planning of Mobile Apps the market for mobile apps is getting bigger and bigger, and it is expected to be worth over 100 billion dollars in 2020. to have a chance to succeed in such a competitive environment, developers need to build and maintain high-quality apps, continuously astonishing their users with the coolest new features. mobile app marketplaces allow users to release reviews. despite reviews are aimed at recommending apps among users, they also contain precious information for developers, reporting bugs and suggesting new features. to exploit such a source of information, developers are supposed to manually read user reviews, something not doable when hundreds of them are collected per day. to help developers dealing with such a task, we developed clap (crowd listener for release planning), a web application able to (i) categorize user reviews based on the information they carry out, (ii) cluster together related reviews, and (iii) prioritize the clusters of reviews to be implemented when planning the subsequent app release. we evaluated all the steps behind clap, showing its high accuracy in categorizing and clustering reviews and the meaningfulness of the recommended prioritizations. also, given the availability of clap as a working tool, we assessed its applicability in industrial environments.",
            "contribution_ids": [
                "R112040"
            ]
        },
        {
            "instance_id": "R112387xR112044",
            "comparison_id": "R112387",
            "paper_id": "R112044",
            "text": "Can app changelogs improve requirements classification from app reviews?: an exploratory study [background] recent research on mining app reviews for software evolution indicated that the elicitation and analysis of user requirements can benefit from supplementing user reviews by data from other sources. however, only a few studies reported results of leveraging app changelogs together with app reviews. [aims] motivated by those findings, this exploratory experimental study looks into the role of app changelogs in the classification of requirements derived from app reviews. we aim at understanding if the use of app changelogs can lead to more accurate identification and classification of functional and non-functional requirements from app reviews. we also want to know which classification technique works better in this context. [method] we did a case study on the effect of app changelogs on automatic classification of app reviews. specifically, manual labeling, text preprocessing, and four supervised machine learning algorithms were applied to a series of experiments, varying in the number of app changelogs in the experimental data. [results] we compared the accuracy of requirements classification from app reviews, by training the four classifiers with varying combinations of app reviews and changelogs. among the four algorithms, na\u00efve bayes was found to be more accurate for categorizing app reviews. [conclusions] the results show that official app changelogs did not contribute to more accurate identification and classification of requirements from app reviews. in addition, na\u00efve bayes seems to be more suitable for our further research on this topic.",
            "contribution_ids": [
                "R112046"
            ]
        },
        {
            "instance_id": "R114155xR76123",
            "comparison_id": "R114155",
            "paper_id": "R76123",
            "text": "Crowdsourcing to elicit requirements for MyERP application crowdsourcing is an emerging method to collect requirements for software systems. applications seeking global acceptance need to meet the expectations of a wide range of users. collecting requirements and arriving at consensus with a wide range of users is difficult using traditional method of requirements elicitation. this paper presents crowdsourcing based approach for german medium-size software company myerp that might help the company to get access to requirements from non-german customers. we present the tasks involved in the proposed solution that would help the company meet the goal of eliciting requirements at a fast pace with non-german customers.",
            "contribution_ids": [
                "R76125"
            ]
        },
        {
            "instance_id": "R114155xR111441",
            "comparison_id": "R114155",
            "paper_id": "R111441",
            "text": "Crowd Out the Competition myerp is a fictional developer of an enterprise resource planning (erp) system. driven by the competition, they face the challenge of losing market share if they fail to de-ploy a software as a service (saas) erp system to the european market quickly, but with high quality product. this also means that the requirements engineering (re) activities will have to be performed efficiently and provide solid results. an additional problem they face is that their (potential) stakeholders are phys-ically distributed, it makes sense to consider them a \"crowd\". this competition paper suggests a crowd-based re approach that first identifies the crowd, then collects and analyzes their feedback to derive wishes and needs, and validate the results through prototyping. for this, techniques are introduced that have so far been rarely employed within re, but more \"traditional\" re techniques, will also be integrated and/or adapted to attain the best possible result in the case of myerp.",
            "contribution_ids": [
                "R111443"
            ]
        },
        {
            "instance_id": "R114155xR112407",
            "comparison_id": "R114155",
            "paper_id": "R112407",
            "text": "Which Feature is Unusable? Detecting Usability and User Experience Issues from User Reviews \"usability and user experience (uux) strongly affect software quality and success. user reviews allow software users to report uux issues. however, this information can be difficult to access due to the varying quality of the reviews, its large numbers and unstructured nature. in this work we propose an approach to automatically detect the uux strengths and issues of software features according to user reviews. we use a collocation algorithm for extracting the features, lexical sentiment analysis for uncovering users' satisfaction about a particular feature and machine learning for detecting the specific uux issues affecting the software application. additionally, we present two visualizations of the results. an initial evaluation of the approach against human judgement obtained mixed results.\"",
            "contribution_ids": [
                "R112409"
            ]
        },
        {
            "instance_id": "R114155xR112434",
            "comparison_id": "R114155",
            "paper_id": "R112434",
            "text": "Users \u00e2\u0080\u0094 The Hidden Software Product Quality Experts?: A Study on How App Users Report Quality Aspects in Online Reviews [context and motivation] research on eliciting requirements from a large number of online reviews using automated means has focused on functional aspects. assuring the quality of an app is vital for its success. this is why user feedback concerning quality issues should be considered as well [question/problem] but to what extent do online reviews of apps address quality characteristics? and how much potential is there to extract such knowledge through automation? [principal ideas/results] by tagging online reviews, we found that users mainly write about \"usability\" and \"reliability\", but the majority of statements are on a subcharacteristic level, most notably regarding \"operability\", \"adaptability\", \"fault tolerance\", and \"interoperability\". a set of 16 language patterns regarding \"usability\" correctly identified 1,528 statements from a large dataset far more efficiently than our manual analysis of a small subset. [contribution] we found that statements can especially be derived from online reviews about qualities by which users are directly affected, although with some ambiguity. language patterns can identify statements about qualities with high precision, though the recall is modest at this time. nevertheless, our results have shown that online reviews are an unused big data source for quality requirements.",
            "contribution_ids": [
                "R112436",
                "R195568"
            ]
        },
        {
            "instance_id": "R114155xR113008",
            "comparison_id": "R114155",
            "paper_id": "R113008",
            "text": "Canary: Extracting Requirements-Related Information from Online Discussions online discussions about software applications generate a large amount of requirements-related information. this information can potentially be usefully applied in requirements engineering; however currently, there are few systematic approaches for extracting such information. to address this gap, we propose canary, an approach for extracting and querying requirements-related information in online discussions. the highlight of our approach is a high-level query language that combines aspects of both requirements and discussion in online forums. we give the semantics of the query language in terms of relational databases and sql. we demonstrate the usefulness of the language using examples on real data extracted from online discussions. our approach relies on human annotations of online discussions. we highlight the subtleties involved in interpreting the content in online discussions and the assumptions and choices we made to effectively address them. we demonstrate the feasibility of generating high-quality annotations by obtaining them from lay amazon mechanical turk users.",
            "contribution_ids": [
                "R113010",
                "R195498"
            ]
        },
        {
            "instance_id": "R114155xR113030",
            "comparison_id": "R114155",
            "paper_id": "R113030",
            "text": "Conceptualising, extracting and analysing requirements arguments in users' forums: The CrowdRE\u00e2\u0080\u0090Arg framework \"due to the pervasive use of online forums and social media, users' feedback are more accessible today and can be used within a requirements engineering context. however, such information is often fragmented, with multiple perspectives from multiple parties involved during on\u2010going interactions. in this paper, the authors propose a crowd\u2010based requirements engineering approach by argumentation (crowdre\u2010arg). the framework is based on the analysis of the textual conversations found in user forums, identification of features, issues and the arguments that are in favour or opposing a given requirements statement. the analysis is to generate an argumentation model of the involved user statements, retrieve the conflicting\u2010viewpoints, reason about the winning\u2010arguments and present that to systems analysts to make informed\u2010requirements decisions. for this purpose, the authors adopted a bipolar argumentation framework and a coalition\u2010based meta\u2010argumentation framework as well as user voting techniques. the crowdre\u2010arg approach and its algorithms are illustrated through two sample conversations threads taken from the reddit forum. additionally, the authors devised algorithms that can identify conflict\u2010free features or issues based on their supporting and attacking arguments. the authors tested these machine learning algorithms on a set of 3,051 user comments, preprocessed using the content analysis technique. the results show that the proposed algorithms correctly and efficiently identify conflict\u2010free features and issues along with their winning arguments.\"",
            "contribution_ids": [
                "R113033"
            ]
        },
        {
            "instance_id": "R114155xR113173",
            "comparison_id": "R114155",
            "paper_id": "R113173",
            "text": "Software Feature Request Detection in Issue Tracking Systems communication about requirements is often handled in issue tracking systems, especially in a distributed setting. as issue tracking systems also contain bug reports or programming tasks, the software feature requests of the users are often difficult to identify. this paper investigates natural language processing and machine learning features to detect software feature requests in natural language data of issue tracking systems. it compares traditional linguistic machine learning features, such as \"bag of words\", with more advanced features, such as subject-action-object, and evaluates combinations of machine learning features derived from the natural language and features taken from the issue tracking system meta-data. our investigation shows that some combinations of machine learning features derived from natural language and the issue tracking system meta-data outperform traditional approaches. we show that issues or data fields (e.g. descriptions or comments), which contain software feature requests, can be identified reasonably well, but hardly the exact sentence. finally, we show that the choice of machine learning algorithms should depend on the goal, e.g. maximization of the detection rate or balance between detection rate and precision. in addition, the paper contributes a double coded gold standard and an open-source implementation to further pursue this topic.",
            "contribution_ids": [
                "R113175"
            ]
        },
        {
            "instance_id": "R114155xR113204",
            "comparison_id": "R114155",
            "paper_id": "R113204",
            "text": "Mining Android App Descriptions for Permission Requirements Recommendation \"during the development or maintenance of an android app, the app developer needs to determine the app's security and privacy requirements such as permission requirements. permission requirements include two folds. first, what permissions (i.e., access to sensitive resources, e.g., location or contact list) the app needs to request. second, how to explain the reason of permission usages to users. in this paper, we focus on the multiple challenges that developers face when creating permission-usage explanations. we propose a novel framework, clap, that mines potential explanations from the descriptions of similar apps. clap leverages information retrieval and text summarization techniques to find frequent permission usages. we evaluate clap on a large dataset containing 1.4 million android apps. the evaluation results outperform existing state-of-the-art approaches, showing great promise of clap as a tool for assisting developers and permission requirements discovery.\"",
            "contribution_ids": [
                "R113206",
                "R195127"
            ]
        },
        {
            "instance_id": "R12250xR12231",
            "comparison_id": "R12250",
            "paper_id": "R12231",
            "text": "Novel coronavirus 2019-nCoV: early estimation of epidemiological parameters and epidemic predictions abstract since first identified, the epidemic scale of the recently emerged novel coronavirus (2019-ncov) in wuhan, china, has increased rapidly, with cases arising across china and other countries and regions. using a transmission model, we estimate a basic reproductive number of 3.11 (95%ci, 2.39\u20134.13); 58\u201376% of transmissions must be prevented to stop increasing; wuhan case ascertainment of 5.0% (3.6\u20137.4); 21022 (11090\u201333490) total infections in wuhan 1 to 22 january. changes to previous version case data updated to include 22 jan 2020; we did not use cases reported after this period as cases were reported at the province level hereafter, and large-scale control interventions were initiated on 23 jan 2020; improved likelihood function, better accounting for first 41 confirmed cases, and now using all infections (rather than just cases detected) in wuhan for prediction of infection in international travellers; improved characterization of uncertainty in parameters, and calculation of epidemic trajectory confidence intervals using a more statistically rigorous method; extended range of latent period in sensitivity analysis to reflect reports of up to 6 day incubation period in household clusters; removed travel restriction analysis, as different modelling approaches (e.g. stochastic transmission, rather than deterministic transmission) are more appropriate to such analyses.",
            "contribution_ids": [
                "R12232"
            ]
        },
        {
            "instance_id": "R12251xR36109",
            "comparison_id": "R12251",
            "paper_id": "R36109",
            "text": "Transmission interval estimates suggest pre-symptomatic spread of COVID-19 abstract background as the covid-19 epidemic is spreading, incoming data allows us to quantify values of key variables that determine the transmission and the effort required to control the epidemic. we determine the incubation period and serial interval distribution for transmission clusters in singapore and in tianjin. we infer the basic reproduction number and identify the extent of pre-symptomatic transmission. methods we collected outbreak information from singapore and tianjin, china, reported from jan.19-feb.26 and jan.21-feb.27, respectively. we estimated incubation periods and serial intervals in both populations. results the mean incubation period was 7.1 (6.13, 8.25) days for singapore and 9 (7.92, 10.2) days for tianjin. both datasets had shorter incubation periods for earlier-occurring cases. the mean serial interval was 4.56 (2.69, 6.42) days for singapore and 4.22 (3.43, 5.01) for tianjin. we inferred that early in the outbreaks, infection was transmitted on average 2.55 and 2.89 days before symptom onset (singapore, tianjin). the estimated basic reproduction number for singapore was 1.97 (1.45, 2.48) secondary cases per infective; for tianjin it was 1.87 (1.65, 2.09) secondary cases per infective. conclusions estimated serial intervals are shorter than incubation periods in both singapore and tianjin, suggesting that pre-symptomatic transmission is occurring. shorter serial intervals lead to lower estimates of r0, which suggest that half of all secondary infections should be prevented to control spread.",
            "contribution_ids": [
                "R36110",
                "R36112"
            ]
        },
        {
            "instance_id": "R12251xR36138",
            "comparison_id": "R12251",
            "paper_id": "R36138",
            "text": "Estimating the generation interval for COVID-19 based on symptom onset data abstract background estimating key infectious disease parameters from the covid-19 outbreak is quintessential for modelling studies and guiding intervention strategies. whereas different estimates for the incubation period distribution and the serial interval distribution have been reported, estimates of the generation interval for covid-19 have not been provided. methods we used outbreak data from clusters in singapore and tianjin, china to estimate the generation interval from symptom onset data while acknowledging uncertainty about the incubation period distribution and the underlying transmission network. from those estimates we obtained the proportions pre-symptomatic transmission and reproduction numbers. results the mean generation interval was 5.20 (95%ci 3.78-6.78) days for singapore and 3.95 (95%ci 3.01-4.91) days for tianjin, china when relying on a previously reported incubation period with mean 5.2 and sd 2.8 days. the proportion of pre-symptomatic transmission was 48% (95%ci 32-67%) for singapore and 62% (95%ci 50-76%) for tianjin, china. estimates of the reproduction number based on the generation interval distribution were slightly higher than those based on the serial interval distribution. conclusions estimating generation and serial interval distributions from outbreak data requires careful investigation of the underlying transmission network. detailed contact tracing information is essential for correctly estimating these quantities.",
            "contribution_ids": [
                "R36139",
                "R36140",
                "R36141",
                "R36142"
            ]
        },
        {
            "instance_id": "R12251xR37003",
            "comparison_id": "R12251",
            "paper_id": "R37003",
            "text": "Real-Time Estimation of the Risk of Death from Novel Coronavirus (COVID-19) Infection: Inference Using Exported Cases the exported cases of 2019 novel coronavirus (covid-19) infection that were confirmed outside china provide an opportunity to estimate the cumulative incidence and confirmed case fatality risk (ccfr) in mainland china. knowledge of the ccfr is critical to characterize the severity and understand the pandemic potential of covid-19 in the early stage of the epidemic. using the exponential growth rate of the incidence, the present study statistically estimated the ccfr and the basic reproduction number\u2014the average number of secondary cases generated by a single primary case in a na\u00efve population. we modeled epidemic growth either from a single index case with illness onset on 8 december 2019 (scenario 1), or using the growth rate fitted along with the other parameters (scenario 2) based on data from 20 exported cases reported by 24 january 2020. the cumulative incidence in china by 24 january was estimated at 6924 cases (95% confidence interval [ci]: 4885, 9211) and 19,289 cases (95% ci: 10,901, 30,158), respectively. the latest estimated values of the ccfr were 5.3% (95% ci: 3.5%, 7.5%) for scenario 1 and 8.4% (95% ci: 5.3%, 12.3%) for scenario 2. the basic reproduction number was estimated to be 2.1 (95% ci: 2.0, 2.2) and 3.2 (95% ci: 2.7, 3.7) for scenarios 1 and 2, respectively. based on these results, we argued that the current covid-19 epidemic has a substantial potential for causing a pandemic. the proposed approach provides insights in early risk assessment using publicly available data.",
            "contribution_ids": [
                "R37004",
                "R37005",
                "R41002",
                "R41003"
            ]
        },
        {
            "instance_id": "R12251xR37008",
            "comparison_id": "R12251",
            "paper_id": "R37008",
            "text": "Estimation of the Transmission Risk of the 2019-nCoV and Its Implication for Public Health Interventions since the emergence of the first cases in wuhan, china, the novel coronavirus (2019-ncov) infection has been quickly spreading out to other provinces and neighboring countries. estimation of the basic reproduction number by means of mathematical modeling can be helpful for determining the potential and severity of an outbreak and providing critical information for identifying the type of disease interventions and intensity. a deterministic compartmental model was devised based on the clinical progression of the disease, epidemiological status of the individuals, and intervention measures. the estimations based on likelihood and model analysis show that the control reproduction number may be as high as 6.47 (95% ci 5.71\u20137.23). sensitivity analyses show that interventions, such as intensive contact tracing followed by quarantine and isolation, can effectively reduce the control reproduction number and transmission risk, with the effect of travel restriction adopted by wuhan on 2019-ncov infection in beijing being almost equivalent to increasing quarantine by a 100 thousand baseline value. it is essential to assess how the expensive, resource-intensive measures implemented by the chinese authorities can contribute to the prevention and control of the 2019-ncov infection, and how long they should be maintained. under the most restrictive measures, the outbreak is expected to peak within two weeks (since 23 january 2020) with a significant low peak value. with travel restriction (no imported exposed individuals to beijing), the number of infected individuals in seven days will decrease by 91.14% in beijing, compared with the scenario of no travel restriction.",
            "contribution_ids": [
                "R37009"
            ]
        },
        {
            "instance_id": "R137469xR137380",
            "comparison_id": "R137469",
            "paper_id": "R137380",
            "text": "Deposition of a TMDSO-Based Film by a Non-Equilibrium Atmospheric Pressure DC Plasma Jet: Deposition of a TMDSO-Based Film\u00e2\u0080\u00a6 this work deals with the deposition of thin films using an atmospheric pressure direct current nitrogen plasma jet with tetramethyldisiloxane as precursor. the effect of o-2 flow and plasma discharge power on film deposition rate and film chemical characteristics is investigated in detail by surface profilometry, fourier transform infrared spectroscopy, and x-ray photoelectron spectroscopy. it is found that a higher deposition rate is obtained at higher oxygen flow rates and higher discharge powers. increasing discharge power shows a certain amount of capability to transfer low oxygen content bonds to high oxygen content bonds. organic films can be deposited in a pure nitrogen atmosphere. the film chemical composition can be tuned to a more inorganic structure by admixture of o-2 leading to an increase in sio4 units at high oxygen flow rates.",
            "contribution_ids": [
                "R137382"
            ]
        },
        {
            "instance_id": "R137469xR137398",
            "comparison_id": "R137469",
            "paper_id": "R137398",
            "text": "Transitions Between and Control of Guided and Branching Streamers in DC Nanosecond Pulsed Excited Plasma Jets plasma bullets are ionization fronts created in atmospheric-pressure plasma jets. the propagation behavior of those bullets is, in the literature, explained by the formation of an interface between the inert gas and the ambient air created by the gas flow of the plasma jet, which guides these discharges in the formed gas channel. in this paper, we examine this ionization phenomenon in uniform gases at atmospheric pressure where this interface between two gases is not present. by changing electrical parameters and adding admixtures such as oxygen, nitrogen, and air to the gas flow, the conditions for which plasma bullets are present are investigated. nanosecond time-resolved images have been taken with an iccd camera to observe the propagation behavior of these discharges. it is argued that the inhomogeneous spatial concentration of metastable atoms and ions, due to the laminar gas flow and the operation frequency of the discharge in the range of a few kilohertz, is responsible for the guidance of the ionization fronts. furthermore, conditions have been observed at where the branching of the discharge is stable and reproducible over time in the case of a helium plasma by adding admixtures of oxygen. possible mechanisms for this phenomenon are discussed.",
            "contribution_ids": [
                "R137400"
            ]
        },
        {
            "instance_id": "R137469xR137410",
            "comparison_id": "R137469",
            "paper_id": "R137410",
            "text": "A brush-shaped air plasma jet operated in glow discharge mode at atmospheric pressure using ambient air as working gas, a direct-current plasma jet is developed to generate a brush-shaped plasma plume with fairly large volume. although a direct-current power supply is used, the discharge shows a pulsed characteristic. based on the voltage-current curve and fast photography, the brush-shaped plume, like the gliding arc plasma, is in fact a temporal superposition of a moving discharge filament in an arched shape. during it moves away from the nozzle, the discharge evolves from a low-current arc into a normal glow in one discharge cycle. the emission profile is explained qualitatively based on the dynamics of the plasma brush.",
            "contribution_ids": [
                "R137412"
            ]
        },
        {
            "instance_id": "R137469xR137416",
            "comparison_id": "R137469",
            "paper_id": "R137416",
            "text": "Flux of OH and O radicals onto a surface by an atmospheric-pressure helium plasma jet measured by laser-induced fluorescence the atmospheric-pressure helium plasma jet is of emerging interest as a cutting-edge biomedical device for cancer treatment, wound healing and sterilization. reactive oxygen species such as oh and o radicals are considered to be major factors in the application of biological plasma. in this study, density distribution, temporal behaviour and flux of oh and o radicals on a surface are measured using laser-induced fluorescence. a helium plasma jet is generated by applying pulsed high voltage of 8 kv with 10 khz using a quartz tube with an inner diameter of 4 mm. to evaluate the relation between the surface condition and active species production, three surfaces are used: dry, wet and rat skin. when the helium flow rate is 1.5 l min\u22121, radial distribution of oh density on the rat skin surface shows a maximum density of 1.2 \u00d7 1013 cm\u22123 at the centre of the plasma-mediated area, while o atom density shows a maximum of 1.0 \u00d7 1015 cm\u22123 at 2.0 mm radius from the centre of the plasma-mediated area. their densities in the effluent of the plasma jet are almost constant during the intervals of the discharge pulses because their lifetimes are longer than the pulse interval. their density distribution depends on the helium flow rate and the surface humidity. with these results, oh and o production mechanisms in the plasma jet and their flux onto the surface are discussed.",
            "contribution_ids": [
                "R137418"
            ]
        },
        {
            "instance_id": "R137469xR137422",
            "comparison_id": "R137469",
            "paper_id": "R137422",
            "text": "Phase-resolved measurement of electric charge deposited by an atmospheric pressure plasma jet on a dielectric surface the surface charge distribution deposited by the effluent of a dielectric barrier discharge driven atmospheric pressure plasma jet on a dielectric surface has been studied. for the first time, the deposition of charge was observed phase resolved. it takes place in either one or two events in each half cycle of the driving voltage. the charge transfer could also be detected in the electrode current of the jet. the periodic change of surface charge polarity has been found to correspond well with the appearance of ionized channels left behind by guided streamers (bullets) that have been identified in similar experimental situations. the distribution of negative surface charge turned out to be significantly broader than for positive charge. with increasing distance of the jet nozzle from the target surface, the charge transfer decreases until finally the effluent loses contact and the charge transfer stops.",
            "contribution_ids": [
                "R137424"
            ]
        },
        {
            "instance_id": "R137469xR137429",
            "comparison_id": "R137469",
            "paper_id": "R137429",
            "text": "Plasma Processes and Plasma Sources in Medicine the use of plasma for healthcare can be dated back as far as the middle of the 19th century. only the development of room temperature atmospheric pressure plasma sources in the past decade, however, has opened the new and fast growing interdisciplinary research field of plasma medicine. three main topics can be distinguished: plasma treated implants, plasma decontamination, and plasmas in medical therapy. understanding of the plasma sources and the plasma processes involved is still incomplete. with the aim of a more fundamental insight we investigate plasmas in a) functionalization of implants with antimicrobial as well as cell attachment enhancing surfaces b) atmospheric pressure plasmas (apps) in inactivation of bacteria, decontamination of bottles and food products, as well as medical equipment and c) apps in medical therapy and their effects on cell viability as a means to finding a plasma \u201cdosage\u201d. the possibilities of an application focused designing of plasma sources will be emphasized. on the example of feed gas humidity and its significant influence the importance of determining and controlling unobvious or hidden parameter is demonstrated (\u00a9 2012 wiley\u2010vch verlag gmbh & co. kgaa, weinheim)",
            "contribution_ids": [
                "R137431"
            ]
        },
        {
            "instance_id": "R137469xR137453",
            "comparison_id": "R137469",
            "paper_id": "R137453",
            "text": "Integrated Microwave Atmospheric Plasma Source (IMAPlaS): thermal and spectroscopic properties and antimicrobial effect onB. atrophaeusspores the integrated microwave atmospheric plasma source (imaplas) operating with a microwave resonator at 2.45 ghz driven by a solid-state transistor oscillator generates a core plasma of high temperature (t > 1000 k), therefore producing reactive species such as no very effectively. the effluent of the plasma source is much colder, which enables direct treatment of thermolabile materials or even living tissue. in this study the source was operated with argon, helium and nitrogen with gas flow rates between 0.3 and 1.0 slm. depending on working gas and distance, axial gas temperatures between 30 and 250 \u00b0c were determined in front of the nozzle. reactive species were identified by emission spectroscopy in the spectral range from vacuum ultraviolet to near infrared. the irradiance in the ultraviolet range was also measured. using b. atrophaeus spores to test antimicrobial efficiency, we determined log10-reduction rates of up to a factor of 4.",
            "contribution_ids": [
                "R137455"
            ]
        },
        {
            "instance_id": "R137469xR137456",
            "comparison_id": "R137469",
            "paper_id": "R137456",
            "text": "The antibacterial activity of a microwave argon plasma jet at atmospheric pressure relies mainly on UV-C radiations the main bactericidal sources produced by a microwave induced cold argon plasma jet in open air are identified and their relative proportion in the biocide efficiency of the jet is assessed on planktonic gram-negative bacteria (wild-type strains and deletion mutants of escherichia coli) diluted in water. in these conditions ultraviolet light (uv) most probably in the uv-c region of the electromagnetic spectrum, is responsible for 86.7 \u00b1 3.2% of the observed bactericidal efficiency of the jet whereas hydrogen peroxide represents 9.9 \u00b1 5.5% of it. the exposition level of the bacteria to uv-c radiations is estimated at 20 mj cm\u22122 using a specific photodiode and the influence of the initial bacteria concentration on the apparent antibacterial efficiency of the jet is highlighted.",
            "contribution_ids": [
                "R137458"
            ]
        },
        {
            "instance_id": "R138127xR138043",
            "comparison_id": "R138127",
            "paper_id": "R138043",
            "text": "Paclitaxel-loaded PLGA nanoparticles surface modified with transferrin and Pluronic\u00c2\u00aeP85, anin vitrocell line andin vivobiodistribution studies on rat model the development of multidrug resistance (due to drug efflux by p-glycoproteins) is a major drawback with the use of paclitaxel (ptx) in the treatment of cancer. the rationale behind this study is to prepare ptx nanoparticles (nps) for the reversal of multidrug resistance based on the fact that ptx loaded into nps is not recognized by p-glycoproteins and hence is not effluxed out of the cell. also, the intracellular penetration of the nps could be enhanced by anchoring transferrin (tf) on the ptx-plga-nps. ptx-loaded plga nps (ptx-plga-nps), pluronic\u00aep85-coated plga nps (p85-ptx-plga-nps), and tf-anchored plga nps (tf-ptx-plga-nps) were prepared and evaluted for cytotoxicity and intracellular uptake using c6 rat glioma cell line. a significant increase in cytotoxicity was observed in the order of tf-ptx-plga-nps > p85-ptx-plga-nps > ptx-plga-nps in comparison to drug solution. in vivo biodistribution on male sprague\u2013dawley rats bearing c6 glioma (subcutaneous) showed higher tumor ptx concentrations in animals administered with ptx-nps compared to drug solution.",
            "contribution_ids": [
                "R138045"
            ]
        },
        {
            "instance_id": "R139050xR138687",
            "comparison_id": "R139050",
            "paper_id": "R138687",
            "text": "Diagnosis of attention deficit hyperactivity disorder using deep belief network based on greedy approach attention deficit hyperactivity disorder creates conditions for the child as s/he cannot sit calm and still, control his/her behavior and focus his/her attention on a particular issue. five out of every hundred children are affected by the disease. boys are three times more than girls at risk for this complication. the disorder often begins before age seven, and parents may not realize their children problem until they get older. children with hyperactivity and attention deficit are at high risk of conduct disorder, antisocial personality, and drug abuse. most children suffering from the disease will develop a feeling of depression, anxiety and lack of self-confidence. given the importance of diagnosis the disease, deep belief networks (dbns) were used as a deep learning model to predict the disease. in this system, in addition to fmri images features, sophisticated features such as age and iq as well as functional characteristics, etc. were used. the proposed method was evaluated by two standard data sets of adhd-200 global competitions, including neuroimage and nyu data sets, and compared with state-of-the-art algorithms. the results showed the superiority of the proposed method rather than other systems. the prediction accuracy has improved respectively as +12.04 and +27.81 over neuroimage and nyu datasets compared to the best proposed method in the adhd-200 global competition.",
            "contribution_ids": [
                "R138689"
            ]
        },
        {
            "instance_id": "R139050xR138690",
            "comparison_id": "R139050",
            "paper_id": "R138690",
            "text": "Deep learning based automatic diagnoses of attention deficit hyperactive disorder in this paper, we aim to develop a deep learning based automatic attention deficit hyperactive disorder (adhd) diagnosis algorithm using resting state functional magnetic resonance imaging (rs-fmri) scans. however, relative to millions of parameters in deep neural networks (dnn), the number of fmri samples is still limited to learn discriminative features from the raw data. in light of this, we first encode our prior knowledge on 3d features voxel-wisely, including regional homogeneity (reho), fractional amplitude of low frequency fluctuations (falff) and voxel-mirrored homotopic connectivity (vmhc), and take these 3d images as the input to the dnn. inspired by the way that radiologists examine brain images, we further investigate a novel 3d convolutional neural network (cnn) architecture to learn 3d local patterns which may boost the diagnosis accuracy. investigation on the hold-out testing data of the adhd-200 global competition demonstrates that the proposed 3d cnn approach yields superior performances when compared to the reported classifiers in the literature, even with less training samples.",
            "contribution_ids": [
                "R138692"
            ]
        },
        {
            "instance_id": "R139050xR138710",
            "comparison_id": "R139050",
            "paper_id": "R138710",
            "text": "A general prediction model for the detection of ADHD and Autism using structural and functional MRI this work presents a novel method for learning a model that can diagnose attention deficit hyperactivity disorder (adhd), as well as autism, using structural texture and functional connectivity features obtained from 3-dimensional structural magnetic resonance imaging (mri) and 4-dimensional resting-state functional magnetic resonance imaging (fmri) scans of subjects. we explore a series of three learners: (1) the lefms learner first extracts features from the structural mri images using the texture-based filters produced by a sparse autoencoder. these filters are then convolved with the original mri image using an unsupervised convolutional network. the resulting features are used as input to a linear support vector machine (svm) classifier. (2) the lefmf learner produces a diagnostic model by first computing spatial non-stationary independent components of the fmri scans, which it uses to decompose each subject\u2019s fmri scan into the time courses of these common spatial components. these features can then be used with a learner by themselves or in combination with other features to produce the model. regardless of which approach is used, the final set of features are input to a linear support vector machine (svm) classifier. (3) finally, the overall lefmsf learner uses the combined features obtained from the two feature extraction processes in (1) and (2) above as input to an svm classifier, achieving an accuracy of 0.673 on the adhd-200 holdout data and 0.643 on the abide holdout data. both of these results, obtained with the same lefmsf framework, are the best known, over all hold-out accuracies on these datasets when only using imaging data\u2014exceeding previously-published results by 0.012 for adhd and 0.042 for autism. our results show that combining multi-modal features can yield good classification accuracy for diagnosis of adhd and autism, which is an important step towards computer-aided diagnosis of these psychiatric diseases and perhaps others as well.",
            "contribution_ids": [
                "R138713"
            ]
        },
        {
            "instance_id": "R139050xR138729",
            "comparison_id": "R139050",
            "paper_id": "R138729",
            "text": "fMRIPrep: a robust preprocessing pipeline for functional MRI preprocessing of functional mri (fmri) involves numerous steps to clean and standardize data before statistical analysis. generally, researchers create ad hoc preprocessing workflows for each new dataset, building upon a large inventory of tools available for each step. the complexity of these workflows has snowballed with rapid advances in mr data acquisition and image processing techniques. we introduce fmriprep , an analysis-agnostic tool that addresses the challenge of robust and reproducible preprocessing for task-based and resting fmri data. fmriprep automatically adapts a best-in-breed workflow to the idiosyncrasies of virtually any dataset, ensuring high-quality preprocessing with no manual intervention. by introducing visual assessment checkpoints into an iterative integration framework for software-testing, we show that fmriprep robustly produces high-quality results on a diverse fmri data collection comprising participants from 54 different studies in the openfmri repository. we review the distinctive features of fmriprep in a qualitative comparison to other preprocessing workflows. we demonstrate that fmriprep achieves higher spatial accuracy as it introduces less uncontrolled spatial smoothness than commonly used preprocessing tools. fmriprep has the potential to transform fmri research by equipping neuroscientists with a high-quality, robust, easy-to-use and transparent preprocessing workflow which can help ensure the validity of inference and the interpretability of their results.",
            "contribution_ids": [
                "R138740"
            ]
        },
        {
            "instance_id": "R139050xR138796",
            "comparison_id": "R139050",
            "paper_id": "R138796",
            "text": "A Deep Learning Approach for Predicting Antidepressant Response in Major Depression Using Clinical and Genetic Biomarkers in the wake of recent advances in scientific research, personalized medicine using deep learning techniques represents a new paradigm. in this work, our goal was to establish deep learning models which distinguish responders from non-responders, and also to predict possible antidepressant treatment outcomes in major depressive disorder (mdd). to uncover relationships between the responsiveness of antidepressant treatment and biomarkers, we developed a deep learning prediction approach resulting from the analysis of genetic and clinical factors such as single nucleotide polymorphisms (snps), age, sex, baseline hamilton rating scale for depression score, depressive episodes, marital status, and suicide attempt status of mdd patients. the cohort consisted of 455 patients who were treated with selective serotonin reuptake inhibitors (treatment-response rate = 61.0%; remission rate = 33.0%). by using the snp dataset that was original to a genome-wide association study, we selected 10 snps (including abca13 rs4917029, bnip3 rs9419139, cacna1e rs704329, exoc4 rs6978272, grin2b rs7954376, lhfpl3 rs4352778, nell1 rs2139423, nuak1 rs2956406, prex1 rs4810894, and slit3 rs139863958) which were associated with antidepressant treatment response. furthermore, we pinpointed 10 snps (including arntl rs11022778, camk1d rs2724812, gabrb3 rs12904459, grm8 rs35864549, naaladl2 rs9878985, ncald rs483986, pla2g4a rs12046378, prok2 rs73103153, rbfox1 rs17134927, and znf536 rs77554113) in relation to remission. then, we employed multilayer feedforward neural networks (mfnns) containing 1\u20133 hidden layers and compared mfnn models with logistic regression models. our analysis results revealed that the mfnn model with 2 hidden layers (area under the receiver operating characteristic curve (auc) = 0.8228 \u00b1 0.0571; sensitivity = 0.7546 \u00b1 0.0619; specificity = 0.6922 \u00b1 0.0765) performed maximally among predictive models to infer the complex relationship between antidepressant treatment response and biomarkers. in addition, the mfnn model with 3 hidden layers (auc = 0.8060 \u00b1 0.0722; sensitivity = 0.7732 \u00b1 0.0583; specificity = 0.6623 \u00b1 0.0853) achieved best among predictive models to predict remission. our study indicates that the deep mfnn framework may provide a suitable method to establish a tool for distinguishing treatment responders from non-responders prior to antidepressant therapy.",
            "contribution_ids": [
                "R138798"
            ]
        },
        {
            "instance_id": "R139050xR138825",
            "comparison_id": "R139050",
            "paper_id": "R138825",
            "text": "Comprehensive functional genomic resource and integrative model for the human brain \\n introduction \\n strong genetic associations have been found for a number of psychiatric disorders. however, understanding the underlying molecular mechanisms remains challenging. \\n \\n \\n rationale \\n to address this challenge, the psychencode consortium has developed a comprehensive online resource and integrative models for the functional genomics of the human brain. \\n \\n \\n results \\n the base of the pyramidal resource is the datasets generated by psychencode, including bulk transcriptome, chromatin, genotype, and hi-c datasets and single-cell transcriptomic data from ~32,000 cells for major brain regions. we have merged these with data from genotype-tissue expression (gtex), encode, roadmap epigenomics, and single-cell analyses. via uniform processing, we created a harmonized resource, allowing us to survey functional genomics data on the brain over a sample size of 1866 individuals. \\n from this uniformly processed dataset, we created derived data products. these include lists of brain-expressed genes, coexpression modules, and single-cell expression profiles for many brain cell types; ~79,000 brain-active enhancers with associated hi-c loops and topologically associating domains; and ~2.5 million expression quantitative-trait loci (qtls) comprising ~238,000 linkage-disequilibrium\u2013independent single-nucleotide polymorphisms and of other types of qtls associated with splice isoforms, cell fractions, and chromatin activity. by using these, we found that &gt;88% of the cross-population variation in brain gene expression can be accounted for by cell fraction changes. furthermore, a number of disorders and aging are associated with changes in cell-type proportions. the derived data also enable comparison between the brain and other tissues. in particular, by using spectral analyses, we found that the brain has distinct expression and epigenetic patterns, including a greater extent of noncoding transcription than other tissues. \\n the top level of the resource consists of integrative networks for regulation and machine-learning models for disease prediction. the networks include a full gene regulatory network (grn) for the brain, linking transcription factors, enhancers, and target genes from merging of the qtls, generalized element-activity correlations, and hi-c data. by using this network, we link disease genes to genome-wide association study (gwas) variants for psychiatric disorders. for schizophrenia, we linked 321 genes to the 142 reported gwas loci. we then embedded the regulatory network into a deep-learning model to predict psychiatric phenotypes from genotype and expression. our model gives a ~6-fold improvement in prediction over additive polygenic risk scores. moreover, it achieves a ~3-fold improvement over additive models, even when the gene expression data are imputed, highlighting the value of having just a small amount of transcriptome data for disease prediction. lastly, it highlights key genes and pathways associated with disorder prediction, including immunological, synaptic, and metabolic pathways, recapitulating de novo results from more targeted analyses. \\n \\n \\n conclusion \\n our resource and integrative analyses have uncovered genomic elements and networks in the brain, which in turn have provided insight into the molecular mechanisms underlying psychiatric disorders. our deep-learning model improves disease risk prediction over traditional approaches and can be extended with additional data types (e.g., microrna and neuroimaging). \\n \\n \\n a comprehensive functional genomic resource for the adult human brain. \\n the resource forms a three-layer pyramid. the bottom layer includes sequencing datasets for traits, such as schizophrenia. the middle layer represents derived datasets, including functional genomic elements and qtls. the top layer contains integrated models, which link genotypes to phenotypes. dspn, deep structured phenotype network; pc1 and pc2, principal components 1 and 2; ref, reference; alt, alternate; h3k27ac, histone h3 acetylation at lysine 27. \\n \\n \\n \\n",
            "contribution_ids": [
                "R138856"
            ]
        },
        {
            "instance_id": "R139050xR138876",
            "comparison_id": "R139050",
            "paper_id": "R138876",
            "text": "Mood disorder identification using deep bottleneck features of elicited speech in the diagnosis of mental health disorder, a large portion of the bipolar disorder (bd) patients is likely to be misdiagnosed as unipolar depression (ud) on initial presentation. as speech is the most natural way to express emotion, this work focuses on tracking emotion profile of elicited speech for short-term mood disorder identification. in this work, the deep scattering spectrum (dss) and low level descriptors (llds) of the elicited speech signals are extracted as the speech features. the hierarchical spectral clustering (hsc) algorithm is employed to adapt the emotion database to the mood disorder database to alleviate the data bias problem. the denoising autoencoder is then used to extract the bottleneck features of dss and llds for better representation. based on the bottleneck features, a long short term memory (lstm) is applied to generate the time-varying emotion profile sequence. finally, given the emotion profile sequence, the hmm-based identification and verification model is used to determine mood disorder. this work collected the elicited emotional speech data from 15 bds, 15 uds and 15 healthy controls for system training and evaluation. five-fold cross validation was employed for evaluation. experimental results show that the system using the bottleneck feature achieved an identification accuracy of 73.33%, improving by 8.89%, compared to that without bottleneck features. furthermore, the system with verification mechanism, improving by 4.44%, outperformed that without verification.",
            "contribution_ids": [
                "R138878"
            ]
        },
        {
            "instance_id": "R139050xR138931",
            "comparison_id": "R139050",
            "paper_id": "R138931",
            "text": "DCNN and DNN based multi-modal depression recognition \"in this paper, we propose an audio visual multimodal depression recognition framework composed of deep convolutional neural network (dcnn) and deep neural network (dnn) models. for each modality, corresponding feature descriptors are input into a dcnn to learn high-level global features with compact dynamic information, which are then fed into a dnn to predict the phq-8 score. for multi-modal depression recognition, the predicted phq-8 scores from each modality are integrated in a dnn for the final prediction. in addition, we propose the histogram of displacement range as a novel global visual descriptor to quantify the range and speed of the facial landmarks' displacements. experiments have been carried out on the distress analysis interview corpus-wizard of oz (daic-woz) dataset for the depression sub-challenge of the audio-visual emotion challenge (avec 2016), results show that the proposed multi-modal depression recognition framework obtains very promising results on both the development set and test set, which outperforms the state-of-the-art results.\"",
            "contribution_ids": [
                "R138933"
            ]
        },
        {
            "instance_id": "R139050xR138944",
            "comparison_id": "R139050",
            "paper_id": "R138944",
            "text": "Affective Computational Model to Extract Natural Affective States of Students With Asperger Syndrome (AS) in Computer-Based Learning Environment this paper was inspired by looking at the central role of emotion in the learning process, its impact on students\u2019 performance; as well as the lack of affective computing models to detect and infer affective-cognitive states in real time for students with and without asperger syndrome (as). this model overcomes gaps in other models that were designed for people with autism, which needed the use of sensors or physiological instrumentations to collect data. the model uses a webcam to capture students\u2019 affective-cognitive states of confidence, uncertainty, engagement, anxiety, and boredom. these states have a dominant effect on the learning process. the model was trained and tested on a natural-spontaneous affective dataset for students with and without as, which was collected for this purpose. the dataset was collected in an uncontrolled environment and included variations in culture, ethnicity, gender, facial and hairstyle, head movement, talking, glasses, illumination changes, and background variation. the model structure used deep learning (dl) techniques like convolutional neural network and long short-term memory. the dl is the-state-of-art tool that used to reduce data dimensionality and capturing non-linear complex features from simpler representations. the affective model provides reliable results with accuracy 90.06%. this model is the first model to detected affective states for adult students with as without physiological or wearable instruments. for the first time, the occlusions in this model, like hand over face or head were considered an important indicator for affective states like boredom, anxiety, and uncertainty. these occlusions have been ignored in most other affective models. the essential information channels in this model are facial expressions, head movement, and eye gaze. the model can serve as an aided-technology for tutors to monitor and detect the behaviors of all students at the same time and help in predicting negative affective states during learning process.",
            "contribution_ids": [
                "R138947"
            ]
        },
        {
            "instance_id": "R139050xR138992",
            "comparison_id": "R139050",
            "paper_id": "R138992",
            "text": "User-level psychological stress detection from social media using deep neural network \"it is of significant importance to detect and manage stress before it turns into severe problems. however, existing stress detection methods usually rely on psychological scales or physiological devices, making the detection complicated and costly. in this paper, we explore to automatically detect individuals' psychological stress via social media. employing real online micro-blog data, we first investigate the correlations between users' stress and their tweeting content, social engagement and behavior patterns. then we define two types of stress-related attributes: 1) low-level content attributes from a single tweet, including text, images and social interactions; 2) user-scope statistical attributes through their weekly micro-blog postings, leveraging information of tweeting time, tweeting types and linguistic styles. to combine content attributes with statistical attributes, we further design a convolutional neural network (cnn) with cross autoencoders to generate user-scope content attributes from low-level content attributes. finally, we propose a deep neural network (dnn) model to incorporate the two types of user-scope attributes to detect users' psychological stress. we test the trained model on four different datasets from major micro-blog platforms including sina weibo, tencent weibo and twitter. experimental results show that the proposed model is effective and efficient on detecting psychological stress from micro-blog data. we believe our model would be useful in developing stress detection tools for mental health agencies and individuals.\"",
            "contribution_ids": [
                "R138994"
            ]
        },
        {
            "instance_id": "R139050xR139004",
            "comparison_id": "R139050",
            "paper_id": "R139004",
            "text": "Characterisation of mental health conditions in social media using Informed Deep Learning abstract \\n the number of people affected by mental illness is on the increase and with it the burden on health and social care use, as well as the loss of both productivity and quality-adjusted life-years. natural language processing of electronic health records is increasingly used to study mental health conditions and risk behaviours on a large scale. however, narrative notes written by clinicians do not capture first-hand the patients\u2019 own experiences, and only record cross-sectional, professional impressions at the point of care. social media platforms have become a source of \u2018in the moment\u2019 daily exchange, with topics including well-being and mental health. in this study, we analysed posts from the social media platform reddit and developed classifiers to recognise and classify posts related to mental illness according to 11 disorder themes. using a neural network and deep learning approach, we could automatically recognise mental illness-related posts in our balenced dataset with an accuracy of 91.08% and select the correct theme with a weighted average accuracy of 71.37%. we believe that these results are a first step in developing methods to characterise large amounts of user-generated content that could support content curation and targeted interventions.",
            "contribution_ids": [
                "R139006"
            ]
        },
        {
            "instance_id": "R139050xR139014",
            "comparison_id": "R139050",
            "paper_id": "R139014",
            "text": "Detecting Stress Based on Social Interactions in Social Networks psychological stress is threatening people\u2019s health. it is non-trivial to detect stress timely for proactive care. with the popularity of social media, people are used to sharing their daily activities and interacting with friends on social media platforms, making it feasible to leverage online social network data for stress detection. in this paper, we find that users stress state is closely related to that of his/her friends in social media, and we employ a large-scale dataset from real-world social platforms to systematically study the correlation of users\u2019 stress states and social interactions. we first define a set of stress-related textual, visual, and social attributes from various aspects, and then propose a novel hybrid model - a factor graph model combined with convolutional neural network to leverage tweet content and social interaction information for stress detection. experimental results show that the proposed model can improve the detection performance by 6-9 percent in f1-score. by further analyzing the social interaction data, we also discover several intriguing phenomena, i.e., the number of social structures of sparse connections (i.e., with no delta connections) of stressed users is around 14 percent higher than that of non-stressed users, indicating that the social structure of stressed users\u2019 friends tend to be less connected and less complicated than that of non-stressed users.",
            "contribution_ids": [
                "R139016"
            ]
        },
        {
            "instance_id": "R139050xR139019",
            "comparison_id": "R139050",
            "paper_id": "R139019",
            "text": "UArizona at the CLEF eRisk 2017 Pilot Task: Linear and Recurrent Models for Early Depression Detection \"the 2017 clef erisk pilot task focuses on automatically detecting depression as early as possible from a users' posts to reddit. in this paper we present the techniques employed for the university of arizona team's participation in this early risk detection shared task. we leveraged external information beyond the small training set, including a preexisting depression lexicon and concepts from the unified medical language system as features. for prediction, we used both sequential (recurrent neural network) and non-sequential (support vector machine) models. our models perform decently on the test data, and the recurrent neural models perform better than the non-sequential support vector machines while using the same feature sets.\"",
            "contribution_ids": [
                "R139021"
            ]
        },
        {
            "instance_id": "R139190xR139077",
            "comparison_id": "R139190",
            "paper_id": "R139077",
            "text": "Spatially resolved diagnostics on a microscale atmospheric pressure plasma jet despite enormous potential for technological applications, fundamentals of stable non-equilibrium micro-plasmas at ambient pressure are still only partly understood. micro-plasma jets are one sub-group of these plasma sources. for an understanding it is particularly important to analyse transport phenomena of energy and particles within and between the core and effluent of the discharge. the complexity of the problem requires the combination and correlation of various highly sophisticated diagnostics yielding different information with an extremely high temporal and spatial resolution. a specially designed rf microscale atmospheric pressure plasma jet (\u03bc-appj) provides excellent access for optical diagnostics to the discharge volume and the effluent region. this allows detailed investigations of the discharge dynamics and energy transport mechanisms from the discharge to the effluent. here we present examples for diagnostics applicable to different regions and combine the results. the diagnostics applied are optical emission spectroscopy (oes) in the visible and ultraviolet and two-photon absorption laser-induced fluorescence spectroscopy. by the latter spatially resolved absolutely calibrated density maps of atomic oxygen have been determined for the effluent. oes yields an insight into energy transport mechanisms from the core into the effluent. the first results of spatially and phase-resolved oes measurements of the discharge dynamics of the core are presented.",
            "contribution_ids": [
                "R139169"
            ]
        },
        {
            "instance_id": "R139190xR139080",
            "comparison_id": "R139190",
            "paper_id": "R139080",
            "text": "Diagnostics on an atmospheric pressure plasma jet the atmospheric pressure plasma jet (appj) is a homogeneous non-equilibrium discharge at ambient pressure. it operates with a noble base gas and a percentage-volume admixture of a molecular gas. applications of the discharge are mainly based on reactive species in the effluent. the effluent region of a discharge operated in helium with an oxygen admixture has been investigated. the optical emission from atomic oxygen decreases with distance from the discharge but can still be observed several centimetres in the effluent. ground state atomic oxygen, measured using absolutely calibrated two-photon laser induced fluorescence spectroscopy, shows a similar behaviour. detailed understanding of energy transport mechanisms requires investigations of the discharge volume and the effluent region. an atmospheric pressure plasma jet has been designed providing excellent diagnostics access and a simple geometry ideally suited for modelling and simulation. laser spectroscopy and optical emission spectroscopy can be applied in the discharge volume and the effluent region.",
            "contribution_ids": [
                "R139170"
            ]
        },
        {
            "instance_id": "R139190xR139086",
            "comparison_id": "R139190",
            "paper_id": "R139086",
            "text": "Generation of atomic oxygen in the effluent of an atmospheric pressure plasma jet \"the planar 13.56\\u2009mhz rf-excited low temperature atmospheric pressure plasma jet (appj) investigated in this study is operated with helium feed gas and a small molecular oxygen admixture. the effluent leaving the discharge through the jet's nozzle contains very few charged particles and a high reactive oxygen species' density. as its main reactive radical, essential for numerous applications, the ground state atomic oxygen density in the appj's effluent is measured spatially resolved with two-photon absorption laser induced fluorescence spectroscopy. the atomic oxygen density at the nozzle reaches a value of \u223c1016\\u2009cm\u22123. even at several centimetres distance still 1% of this initial atomic oxygen density can be detected. optical emission spectroscopy (oes) reveals the presence of short living excited oxygen atoms up to 10\\u2009cm distance from the jet's nozzle. the measured high ground state atomic oxygen density and the unaccounted for presence of excited atomic oxygen require further investigations on a possible energy transfer from the appj's discharge region into the effluent: energetic vacuum ultraviolet radiation, measured by oes down to 110\\u2009nm, reaches far into the effluent where it is presumed to be responsible for the generation of atomic oxygen.4 this study forms part of: s reuter 2007 formation mechanisms of atomic oxygen in an atmospheric pressure plasma jet characterised by spectroscopic methods dissertation duisburg-essen university and was presented at the 59th gaseous electronics conference (gec) (columbus, oh).\"",
            "contribution_ids": [
                "R139172"
            ]
        },
        {
            "instance_id": "R139190xR139089",
            "comparison_id": "R139190",
            "paper_id": "R139089",
            "text": "The dynamics of radio-frequency driven atmospheric pressure plasma jets the complex dynamics of radio-frequency driven atmospheric pressure plasma jets is investigated using various optical diagnostic techniques and numerical simulations. absolute number densities of ground state atomic oxygen radicals in the plasma effluent are measured by two-photon absorption laser induced fluorescence spectroscopy (talif). spatial profiles are compared with (vacuum) ultra-violet radiation from excited states of atomic oxygen and molecular oxygen, respectively. the excitation and ionization dynamics in the plasma core are dominated by electron impact and observed by space and phase resolved optical emission spectroscopy (proes). the electron dynamics is governed through the motion of the plasma boundary sheaths in front of the electrodes as illustrated in numerical simulations using a hybrid code based on fluid equations and kinetic treatment of electrons.",
            "contribution_ids": [
                "R139173"
            ]
        },
        {
            "instance_id": "R139190xR139106",
            "comparison_id": "R139190",
            "paper_id": "R139106",
            "text": "Concepts and characteristics of the \u00e2\u0080\u0098COST Reference Microplasma Jet\u00e2\u0080\u0099 biomedical applications of non-equilibrium atmospheric pressure plasmas have attracted intense interest in the past few years. many plasma sources of diverse design have been proposed for these applications, but the relationship between source characteristics and application performance is not well-understood, and indeed many sources are poorly characterized. this circumstance is an impediment to progress in application development. a reference source with well-understood and highly reproducible characteristics may be an important tool in this context. researchers around the world should be able to compare the characteristics of their own sources and also their results with this device. in this paper, we describe such a reference source, developed from the simple and robust micro-scaled atmospheric pressure plasma jet (\u03bc-appj) concept. this development occurred under the auspices of cost action mp1101 \u2018biomedical applications of atmospheric pressure plasmas\u2019. gas contamination and power measurement are shown to be major causes of irreproducible results in earlier source designs. these problems are resolved in the reference source by refinement of the mechanical and electrical design and by specifying an operating protocol. these measures are shown to be absolutely necessary for reproducible operation. they include the integration of current and voltage probes into the jet. the usual combination of matching unit and power supply is replaced by an integrated lc power coupling circuit and a 5\\u2009w single frequency generator. the design specification and operating protocol for the reference source are being made freely available.",
            "contribution_ids": [
                "R139179"
            ]
        },
        {
            "instance_id": "R139190xR139115",
            "comparison_id": "R139190",
            "paper_id": "R139115",
            "text": "Chemical kinetics in an atmospheric pressure helium plasma containing humidity investigating the formation and kinetics of o and oh in a he\u2013h 2 o plasma jet using absorption spectroscopy and 0d modelling.",
            "contribution_ids": [
                "R139182"
            ]
        },
        {
            "instance_id": "R139190xR139132",
            "comparison_id": "R139190",
            "paper_id": "R139132",
            "text": "Characterization of an RF-driven argon plasma at atmospheric pressure using broadband absorption and optical emission spectroscopy atmospheric pressure plasmas in argon are of particular interest due to the production of highly excited and reactive species enabling numerous plasma-aided applications. in this contribution, we report on absolute optical emission and absorption spectroscopy of a radio frequency (rf) driven capacitively coupled argon glow discharge operated in a parallel-plate configuration. this enabled the study of all key parameters including electron density and temperature, gas temperature, and absolute densities of atoms in highly electronically excited states. space and time-averaged electron density and temperature were determined from the measurement of the absolute intensity of the electron-atom bremsstrahlung in the visible range. considering the non-maxwellian electron energy distribution function, an electron temperature ( t e) of 2.1\\u2009ev and an electron density ( n e) of 1.1 \u00d7 10 19 m \u2212 3 were obtained. the time-averaged and spatially resolved absolute densities of atoms in the metastable ( 1 s 5 and 1 s 3) and resonant ( 1 s 4 and 1 s 2) states of argon in the pure ar and ar/he mixture were obtained by broadband absorption spectroscopy. the 1 s 5 metastable atoms had the largest density near the sheath region with a maximum value of 8 \u00d7 10 17 m \u2212 3, while all other 1s states had densities of at most 2 \u00d7 10 17 m \u2212 3. the dominant production and loss mechanisms of these atoms were discussed, in particular, the role of radiation trapping. we conclude with comparison of the plasma properties of the argon rf glow discharges with the more common he equivalent and highlight their differences.",
            "contribution_ids": [
                "R139188"
            ]
        },
        {
            "instance_id": "R139526xR139469",
            "comparison_id": "R139526",
            "paper_id": "R139469",
            "text": "PENYELESAIAN MULTI-OBJECTIVE FLEXIBLE JOB SHOP SCHEDULING PROBLEM  MENGGUNAKAN  HYBRID ALGORITMA IMUN flexible job shop scheduling problem (fjssp) is one of scheduling problems with specification: there is a job to be done in a certain order, each job contains a number of operations and each operation is processed on a machine of some available machine. the purpose of this paper is to solve multi-objective flexible job shop scheduling problem with minimizing the makespan, the biggest workload and the total workload of all machines. because of complexity these problem, a integrated approach immune algorithm (ia) and simulated annealing (sa) algorithm are combined to solve the multi-objective fjssp. a clonal selection is a strategy for generating new antibody based on selecting the antibody for reproduction. sa is used as a local search search algorithm for enhancing the local ability with certain probability to avoid becoming trapped in a local optimum. the simulation result have proved that this hybrid immune algorithm is an efficient and effective approach to solve the multi-objective fjssp",
            "contribution_ids": [
                "R139471"
            ]
        },
        {
            "instance_id": "R139526xR139522",
            "comparison_id": "R139526",
            "paper_id": "R139522",
            "text": "Multisystem Optimization for an Integrated Production Scheduling with Resource Saving Problem in Textile Printing and Dyeing resource saving has become an integral aspect of manufacturing in industry 4.0. this paper proposes a multisystem optimization (mso) algorithm, inspired by implicit parallelism of heuristic methods, to solve an integrated production scheduling with resource saving problem in textile printing and dyeing. first, a real-world integrated production scheduling with resource saving is formulated as a multisystem optimization problem. then, the mso algorithm is proposed to solve multisystem optimization problems that consist of several coupled subsystems, and each of the subsystems may contain multiple objectives and multiple constraints. the proposed mso algorithm is composed of within-subsystem evolution and cross-subsystem migration operators, and the former is to optimize each subsystem by excellent evolution operators and the later is to complete information sharing between multiple subsystems, to accelerate the global optimization of the whole system. performance is tested on a set of multisystem benchmark functions and compared with improved nsga-ii and multiobjective multifactorial evolutionary algorithm (mo-mfea). simulation results show that the mso algorithm is better than compared algorithms for the benchmark functions studied in this paper. finally, the mso algorithm is successfully applied to the proposed integrated production scheduling with resource saving problem, and the results show that mso is a promising algorithm for the studied problem.",
            "contribution_ids": [
                "R139525"
            ]
        },
        {
            "instance_id": "R139567xR139313",
            "comparison_id": "R139567",
            "paper_id": "R139313",
            "text": "A hybrid Semantic driven recommender for services in the eGovernment domain in its way towards the maturity of egovernment solutions a number of paths are being explored. among them, one of the not fully explored mechanisms are the use of social features for a better provisioning of domain services. this paper explores how to provide support for the discovery of services from public administrations using folksonomies. taking advantage of these, authors develop a social site and they provide a complete mechanism to recommend new services to users using techniques from cf and cbf recommenders. also, some conclusions are presented to enlighten future practitioners and researchers.",
            "contribution_ids": [
                "R139315"
            ]
        },
        {
            "instance_id": "R139567xR138297",
            "comparison_id": "R139567",
            "paper_id": "R138297",
            "text": "A Multi-Agent System for the management of E-Government Services this paper aims at studying the exploitation of intelligent agents for supporting citizens to access e-government services. to this purpose, it proposes a multi-agent system capable of suggesting to the users the most interesting services for them; specifically, these suggestions are computed by taking into account both their exigencies/preferences and the capabilities of the devices they are currently exploiting. the paper first describes the proposed system and, then, reports various experimental results. finally, it presents a comparison between our system and other related ones already presented in the literature.",
            "contribution_ids": [
                "R138299"
            ]
        },
        {
            "instance_id": "R139642xR139605",
            "comparison_id": "R139642",
            "paper_id": "R139605",
            "text": "Device modeling of perovskite solar cells based on structural similarity with thin film inorganic semiconductor solar cells device modeling of ch3nh3pbi3\u2212xcl3 perovskite-based solar cells was performed. the perovskite solar cells employ a similar structure with inorganic semiconductor solar cells, such as cu(in,ga)se2, and the exciton in the perovskite is wannier-type. we, therefore, applied one-dimensional device simulator widely used in the cu(in,ga)se2 solar cells. a high open-circuit voltage of 1.0\\u2009v reported experimentally was successfully reproduced in the simulation, and also other solar cell parameters well consistent with real devices were obtained. in addition, the effect of carrier diffusion length of the absorber and interface defect densities at front and back sides and the optimum thickness of the absorber were analyzed. the results revealed that the diffusion length experimentally reported is long enough for high efficiency, and the defect density at the front interface is critical for high efficiency. also, the optimum absorber thickness well consistent with the thickness range of real devices was derived.",
            "contribution_ids": [
                "R139607"
            ]
        },
        {
            "instance_id": "R139642xR139614",
            "comparison_id": "R139642",
            "paper_id": "R139614",
            "text": "Highly Efficient and Stable Sn-Rich Perovskite Solar Cells by Introducing Bromine compositional engineering of recently arising methylammonium (ma) lead (pb) halide based perovskites is an essential approach for finding better perovskite compositions to resolve still remaining issues of toxic pb, long-term instability, etc. in this work, we carried out crystallographic, morphological, optical, and photovoltaic characterization of compositional masn0.6pb0.4i3-xbrx by gradually introducing bromine (br) into parental pb-sn binary perovskite (masn0.6pb0.4i3) to elucidate its function in sn-rich (sn:pb = 6:4) perovskites. we found significant advances in crystallinity and dense coverage of the perovskite films by inserting the br into sn-rich perovskite lattice. furthermore, light-intensity-dependent open circuit voltage (voc) measurement revealed much suppressed trap-assisted recombination for a proper br-added (x = 0.4) device. these contributed to attaining the unprecedented power conversion efficiency of 12.1% and voc of 0.78 v, which are, to the best of our knowledge, the highest performance in the sn-rich (\u226560%) perovskite solar cells reported so far. in addition, impressive enhancement of photocurrent-output stability and little hysteresis were found, which paves the way for the development of environmentally benign (pb reduction), stable monolithic tandem cells using the developed low band gap (1.24-1.26 ev) masn0.6pb0.4i3-xbrx with suggested composition (x = 0.2-0.4).",
            "contribution_ids": [
                "R139617"
            ]
        },
        {
            "instance_id": "R139642xR139634",
            "comparison_id": "R139642",
            "paper_id": "R139634",
            "text": "Highly Reproducible Sn-Based Hybrid Perovskite Solar Cells with 9% Efficiency the low power conversion efficiency (pce) of tin\u2010based hybrid perovskite solar cells (hpscs) is mainly attributed to the high background carrier density due to a high density of intrinsic defects such as sn vacancies and oxidized species (sn4+) that characterize sn\u2010based hpscs. herein, this study reports on the successful reduction of the background carrier density by more than one order of magnitude by depositing near\u2010single\u2010crystalline formamidinium tin iodide (fasni3) films with the orthorhombic a\u2010axis in the out\u2010of\u2010plane direction. using these highly crystalline films, obtained by mixing a very small amount (0.08 m) of layered (2d) sn perovskite with 0.92 m (3d) fasni3, for the first time a pce as high as 9.0% in a planar p\u2013i\u2013n device structure is achieved. these devices display negligible hysteresis and light soaking, as they benefit from very low trap\u2010assisted recombination, low shunt losses, and more efficient charge collection. this represents a 50% improvement in pce compared to the best reference cell based on a pure fasni3 film using snf2 as a reducing agent. moreover, the 2d/3d\u2010based hpscs show considerable improved stability due to the enhanced robustness of the perovskite film compared to the reference cell.",
            "contribution_ids": [
                "R139637"
            ]
        },
        {
            "instance_id": "R139972xR139938",
            "comparison_id": "R139972",
            "paper_id": "R139938",
            "text": "Micromachined accelerometer with no proof mass this paper describes a revolutionary micromachined accelerometer which is simple, reliable, and inexpensive to make. the operating principle of this accelerometer is based on free-convection heat transfer of a tiny hot air bubble in an enclosed chamber. an experimental device has demonstrated a 0.6 milli-g sensitivity which can theoretically be extended to sub-micro-g level.",
            "contribution_ids": [
                "R139940"
            ]
        },
        {
            "instance_id": "R139972xR139963",
            "comparison_id": "R139972",
            "paper_id": "R139963",
            "text": "Theoretical Modeling, Numerical Simulations and Experimental Study of Micro Thermal Convective Accelerometers we present a one-dimensional (1d) theoretical model for the design analysis of a micro thermal convective accelerometer (mtca). systematical design analysis was conducted on the sensor performance covering the sensor output, sensitivity, and power consumption. the sensor output was further normalized as a function of normalized input acceleration in terms of rayleigh number r $_{\\\\mathrm {a}}$ (the product of grashof number g $_{\\\\mathrm {r}}$ and prandtl number p $_{\\\\mathrm {r}}$ ) for different fluids. a critical rayleigh number ( r a c = 3,000) is founded, for the first time, to determine the boundary between the linear and nonlinear response regime of mtca. based on the proposed 1d model, key parameters, including the location of the detectors, sensor length, thin film thickness, cavity height, heater temperature, and fluid types, were optimized to improve sensor performance. accordingly, a cmos compatible mtca was designed and fabricated based on the theoretical analysis, which showed a high sensitivity of 1,289 mv/g. therefore, this efficient 1d model, one million times faster than cfd simulation, can be a promising tool for the system-level cmos mems design.",
            "contribution_ids": [
                "R139968"
            ]
        },
        {
            "instance_id": "R140131xR139853",
            "comparison_id": "R140131",
            "paper_id": "R139853",
            "text": "SMART CITIES AND HERITAGE CONSERVATION: DEVELOPING A SMARTHERITAGE AGENDA FOR SUSTAINABLE INCLUSIVE COMMUNITIES this paper discusses the potential of current advancements in information communication technologies (ict) for cultural heritage preservation, valorization and management within contemporary cities. the paper highlights the potential of virtual environments to assess the impacts of heritage policies on urban development. it does so by discussing the implications of virtual globes and crowdsourcing to support the participatory valuation and management of cultural heritage assets. to this purpose, a review of available valuation techniques is here presented together with a discussion on how these techniques might be coupled with ict tools to promote inclusive governance.\\xa0",
            "contribution_ids": [
                "R139855"
            ]
        },
        {
            "instance_id": "R140131xR139975",
            "comparison_id": "R140131",
            "paper_id": "R139975",
            "text": "CULTURAL HERITAGE IN SMART CITY ENVIRONMENTS: THE UPDATE abstract. in 2017 we published a seminal research study in the international archives of the photogrammetry, remote sensing &amp;amp; spatial information sciences about how smart city tools, solutions and applications underpinned historical and cultural heritage of cities at that time (angelidou et al. 2017). we now return to investigate the progress that has been made during the past three years, and specifically whether the weak substantiation of cultural heritage in smart city strategies that we observed in 2017 has been improved. the newest literature suggests that smart cities should capitalize on local strengths and give prominence to local culture and traditions and provides a handful of solutions to this end. however, a more thorough examination of what has been actually implemented reveals a (still) rather immature approach. the smart city cases that were selected for the purposes of this research include tarragona (spain), budapest (hungary) and karlsruhe (germany). for each one we collected information regarding the overarching structure of the initiative, the positioning of cultural heritage and the inclusion of heritage-related smart city applications. we then performed a comparative analysis based on a simplified version of the digital strategy canvas. our findings suggest that a rich cultural heritage and a broader strategic focus on touristic branding and promotion are key ingredients of smart city development in this domain; this is a commonality of all the investigated cities. moreover, three different strategy architectures emerge, representing the different interplays among the smart city, cultural heritage and sustainable urban development. we conclude that a new generation of smart city initiatives is emerging, in which cultural heritage is of increasing importance. this generation tends to associate cultural heritage with social and cultural values, liveability and sustainable urban development.\\n",
            "contribution_ids": [
                "R139978"
            ]
        },
        {
            "instance_id": "R140131xR140106",
            "comparison_id": "R140131",
            "paper_id": "R140106",
            "text": "Smart Cities in Europe \"urban performance currently depends not only on a city's endowment of hard infrastructure (physical capital), but also, and increasingly so, on the availability and quality of knowledge communication and social infrastructure (human and social capital). the latter form of capital is decisive for urban competitiveness. against this background, the concept of the \u201csmart city\u201d has recently been introduced as a strategic device to encompass modern urban production factors in a common framework and, in particular, to highlight the importance of information and communication technologies (icts) in the last 20 years for enhancing the competitive profile of a city. the present paper aims to shed light on the often elusive definition of the concept of the \u201csmart city.\u201d we provide a focused and operational definition of this construct and present consistent evidence on the geography of smart cities in the eu27. our statistical and graphical analyses exploit in depth, for the first time to our knowledge, the most recent version of the urban audit data set in order to analyze the factors determining the performance of smart cities. we find that the presence of a creative class, the quality of and dedicated attention to the urban environment, the level of education, and the accessibility to and use of icts for public administration are all positively correlated with urban wealth. this result prompts the formulation of a new strategic agenda for european cities that will allow them to achieve sustainable urban development and a better urban landscape.\"",
            "contribution_ids": [
                "R140108"
            ]
        },
        {
            "instance_id": "R140348xR140171",
            "comparison_id": "R140348",
            "paper_id": "R140171",
            "text": "On2vec: Embedding-based relation prediction for ontology population populating ontology graphs represents a long-standing problem for the semantic web community. recent advances in translation-based graph embedding methods for populating instance-level knowledge graphs lead to promising new approaching for the ontology population problem. however, unlike instance-level graphs, the majority of relation facts in ontology graphs come with comprehensive semantic relations, which often include the properties of transitivity and symmetry, as well as hierarchical relations. these comprehensive relations are often too complex for existing graph embedding methods, and direct application of such methods is not feasible. hence, we propose on2vec, a novel translation-based graph embedding method for ontology population. on2vec integrates two model components that effectively characterize comprehensive relation facts in ontology graphs. the first is the component-specific model that encodes concepts and relations into low-dimensional embedding spaces without a loss of relational properties; the second is the hierarchy model that performs focused learning of hierarchical relation facts. experiments on several well-known ontology graphs demonstrate the promising capabilities of on2vec in predicting and verifying new relation facts. these promising results also make possible significant improvements in related methods.",
            "contribution_ids": [
                "R140173"
            ]
        },
        {
            "instance_id": "R140348xR140164",
            "comparison_id": "R140348",
            "paper_id": "R140164",
            "text": "OPA2Vec: combining formal and informal content of biomedical ontologies to improve similarity-based prediction motivation\\nontologies are widely used in biology for data annotation, integration and analysis. in addition to formally structured axioms, ontologies contain meta-data in the form of annotation axioms which provide valuable pieces of information that characterize ontology classes. annotation axioms commonly used in ontologies include class labels, descriptions or synonyms. despite being a rich source of semantic information, the ontology meta-data are generally unexploited by ontology-based analysis methods such as semantic similarity measures.\\n\\n\\nresults\\nwe propose a novel method, opa2vec, to generate vector representations of biological entities in ontologies by combining formal ontology axioms and annotation axioms from the ontology meta-data. we apply a word2vec model that has been pre-trained on either a corpus or abstracts or full-text articles to produce feature vectors from our collected data. we validate our method in two different ways: first, we use the obtained vector representations of proteins in a similarity measure to predict protein-protein interaction on two different datasets. second, we evaluate our method on predicting gene-disease associations based on phenotype similarity by generating vector representations of genes and diseases using a phenotype ontology, and applying the obtained vectors to predict gene-disease associations using mouse model phenotypes. we demonstrate that opa2vec significantly outperforms existing methods for predicting gene-disease associations. using evidence from mouse models, we apply opa2vec to identify candidate genes for several thousand rare and orphan diseases. opa2vec can be used to produce vector representations of any biomedical entity given any type of biomedical ontology.\\n\\n\\navailability and implementation\\nhttps://github.com/bio-ontology-research-group/opa2vec.\\n\\n\\nsupplementary information\\nsupplementary data are available at bioinformatics online.",
            "contribution_ids": [
                "R140167"
            ]
        },
        {
            "instance_id": "R140348xR140183",
            "comparison_id": "R140348",
            "paper_id": "R140183",
            "text": "Bio-joie: Joint representation learning of biological knowledge bases abstract the widespread of coronavirus has led to a worldwide pandemic with a high mortality rate. currently, the knowledge accumulated from different studies about this virus is very limited. leveraging a wide-range of biological knowledge, such as gene on-tology and protein-protein interaction (ppi) networks from other closely related species presents a vital approach to infer the molecular impact of a new species. in this paper, we propose the transferred multi-relational embedding model bio-joie to capture the knowledge of gene ontology and ppi networks, which demonstrates superb capability in modeling the sars-cov-2-human protein interactions. bio-joie jointly trains two model components. the knowledge model encodes the relational facts from the protein and go domains into separated embedding spaces, using a hierarchy-aware encoding technique employed for the go terms. on top of that, the transfer model learns a non-linear transformation to transfer the knowledge of ppis and gene ontology annotations across their embedding spaces. by leveraging only structured knowledge, bio-joie significantly outperforms existing state-of-the-art methods in ppi type prediction on multiple species. furthermore, we also demonstrate the potential of leveraging the learned representations on clustering proteins with enzymatic function into enzyme commission families. finally, we show that bio-joie can accurately identify ppis between the sars-cov-2 proteins and human proteins, providing valuable insights for advancing research on this new disease.",
            "contribution_ids": [
                "R140185"
            ]
        },
        {
            "instance_id": "R140348xR140245",
            "comparison_id": "R140348",
            "paper_id": "R140245",
            "text": "Onto2vec: joint vector-based representation of biological entities and their ontology-based annotations motivation biological knowledge is widely represented in the form of ontology\u2010based annotations: ontologies describe the phenomena assumed to exist within a domain, and the annotations associate a (kind of) biological entity with a set of phenomena within the domain. the structure and information contained in ontologies and their annotations make them valuable for developing machine learning, data analysis and knowledge extraction algorithms; notably, semantic similarity is widely used to identify relations between biological entities, and ontology\u2010based annotations are frequently used as features in machine learning applications. results we propose the onto2vec method, an approach to learn feature vectors for biological entities based on their annotations to biomedical ontologies. our method can be applied to a wide range of bioinformatics research problems such as similarity\u2010based prediction of interactions between proteins, classification of interaction types using supervised learning, or clustering. to evaluate onto2vec, we use the gene ontology (go) and jointly produce dense vector representations of proteins, the go classes to which they are annotated, and the axioms in go that constrain these classes. first, we demonstrate that onto2vec\u2010generated feature vectors can significantly improve prediction of protein\u2010protein interactions in human and yeast. we then illustrate how onto2vec representations provide the means for constructing data\u2010driven, trainable semantic similarity measures that can be used to identify particular relations between proteins. finally, we use an unsupervised clustering approach to identify protein families based on their enzyme commission numbers. our results demonstrate that onto2vec can generate high quality feature vectors from biological entities and ontologies. onto2vec has the potential to significantly outperform the state\u2010of\u2010the\u2010art in several predictive applications in which ontologies are involved. availability and implementation https://github.com/bio\u2010ontology\u2010research\u2010group/onto2vec",
            "contribution_ids": [
                "R140247"
            ]
        },
        {
            "instance_id": "R140543xR140498",
            "comparison_id": "R140543",
            "paper_id": "R140498",
            "text": "Black Phosphorus Gas Sensors the utilization of black phosphorus and its monolayer (phosphorene) and few-layers in field-effect transistors has attracted a lot of attention to this elemental two-dimensional material. various studies on optimization of black phosphorus field-effect transistors, pn junctions, photodetectors, and other applications have been demonstrated. although chemical sensing based on black phosphorus devices was theoretically predicted, there is still no experimental verification of such an important study of this material. in this article, we report on chemical sensing of nitrogen dioxide (no2) using field-effect transistors based on multilayer black phosphorus. black phosphorus sensors exhibited increased conduction upon no2 exposure and excellent sensitivity for detection of no2 down to 5 ppb. moreover, when the multilayer black phosphorus field-effect transistor was exposed to no2 concentrations of 5, 10, 20, and 40 ppb, its relative conduction change followed the langmuir isotherm for molecules adsorbed on a surface. additionally, on the basis of an exponential conductance change, the rate constants for adsorption and desorption of no2 on black phosphorus were extracted for different no2 concentrations, and they were in the range of 130-840 s. these results shed light on important electronic and sensing characteristics of black phosphorus, which can be utilized in future studies and applications.",
            "contribution_ids": [
                "R140500"
            ]
        },
        {
            "instance_id": "R140543xR139343",
            "comparison_id": "R140543",
            "paper_id": "R139343",
            "text": "Exfoliated black phosphorus gas sensing properties at room temperature room temperature gas sensing properties of chemically exfoliated black phosphorus (bp) to oxidizing (no2, co2) and reducing (nh3, h2, co) gases in a dry air carrier have been reported. to study the gas sensing properties of bp, chemically exfoliated bp flakes have been drop casted on si3n4 substrates provided with pt comb-type interdigitated electrodes in n2 atmosphere. scanning electron microscopy and x-ray photoelectron spectroscopy characterizations show respectively the occurrence of a mixed structure, composed of bp coarse aggregates dispersed on bp exfoliated few layer flakes bridging the electrodes, and a clear 2p doublet belonging to bp, which excludes the occurrence of surface oxidation. room temperature electrical tests in dry air show a p-type response of multilayer bp with measured detection limits of 20 ppb and 10 ppm to no2 and nh3 respectively. no response to co and co2 has been detected, while a slight but steady sensitivity to h2 has been recorded. the reported results confirm, on an experimental basis, what was previously theoretically predicted, demonstrating the promising sensing properties of exfoliated bp.",
            "contribution_ids": [
                "R139345",
                "R140503"
            ]
        },
        {
            "instance_id": "R140543xR140539",
            "comparison_id": "R140543",
            "paper_id": "R140539",
            "text": "Porous ZnO Polygonal Nanoflakes: Synthesis, Use in High-Sensitivity NO2 Gas Sensor, and Proposed Mechanism of Gas Sensing unique porous zno polygonal nanoflakes were synthesized by the microwave hydrothermal method. the structural properties of the products were investigated by using x-ray diffraction, scanning electron microscopy, transmission electron microscopy (tem), and high-resolution tem techniques. in situ diffuse reflectance infrared fourier transform spectroscopy technique was employed to investigate the mechanism of no2 sensing. free nitrate ions, nitrate ions, and nitrite anions were the main adsorbed species. n2o was formed via no\u2013 and n2o2\u2013 that were stemmed from no. comparative tests for gas sensing between gas sensors based on the as-prepared porous zno nanoflakes and purchased zno nanoparticles clearly showed that the former exhibited more excellent no2 sensing performances. photoluminescence and x-ray photoelectron spectroscopy spectra further proved that the intensities of donors (oxygen vacancy (vo) and/or zinc interstitial (zni)) and surface oxygen species (o2\u2013 and o2), which were involved in the mechani...",
            "contribution_ids": [
                "R140541"
            ]
        },
        {
            "instance_id": "R141156xR141119",
            "comparison_id": "R141156",
            "paper_id": "R141119",
            "text": "High-isolation CPW MEMS shunt switches-part 1: modeling  this paper, the first of two parts, presents an electromagnetic model for membrane microelectromechanical systems (mems) shunt switches for microwave/millimeter-wave applications. the up-state capacitance can be accurately modeled using three-dimensional static solvers, and full-wave solvers are used to predict the current distribution and inductance of the switch. the loss in the up-state position is equivalent to the coplanar waveguide line loss and is 0.01-0.02 db at 10-30 ghz for a 2-/spl mu/m-thick au mems shunt switch. it is seen that the capacitance, inductance, and series resistance can be accurately extracted from dc-40 ghz s-parameter measurements. it is also shown that dramatic increase in the down-state isolation (20/sup +/ db) can be achieved with the choice of the correct lc series resonant frequency of the switch. in part 2 of this paper, the equivalent capacitor-inductor-resistor model is used in the design of tuned high isolation switches at 10 and 30 ghz.",
            "contribution_ids": [
                "R141121"
            ]
        },
        {
            "instance_id": "R141156xR141136",
            "comparison_id": "R141156",
            "paper_id": "R141136",
            "text": "A zipper RF MEMS tunable capacitor with interdigitated RF and actuation electrodes this paper presents a new rf mems tunable capacitor based on the zipper principle and with interdigitated rf and actuation electrodes. the electrode configuration prevents dielectric charging under high actuation voltages. it also increases the capacitance ratio and the tunable analog range. the effect of the residual stress on the capacitance tunability is also investigated. two devices with different interdigital rf and actuation electrodes are fabricated on an alumina substrate and result in a capacitance ratio around 3.0 (cmin = 70\u201390 ff, cmax = 240\u2013270 ff) and with a q > 100 at 3 ghz. this design can be used in wideband tunable filters and matching networks.",
            "contribution_ids": [
                "R141138"
            ]
        },
        {
            "instance_id": "R141156xR141150",
            "comparison_id": "R141156",
            "paper_id": "R141150",
            "text": "Investigation of Charge Injection and Relaxation in Multilayer Dielectric Stacks for Capacitive RF MEMS Switch Application this paper proposes a new approach to the problem of irreversible stiction of capacitive radio frequency (rf) microelectromechanical (mems) switch attributed to the dielectric charging. we investigate how charge accumulates in multi- and single-layer dielectric structures for a capacitive rf mems switch using metal-insulator-semiconductor (mis) capacitor structure. two multidielectric-layers are structured, which are sio2+si3n4 and sio2+si3n4+sio2 stack films. meanwhile, si3n4 single-layer dielectric structure is also fabricated for comparison. in the experiments, the space charges are first injected into the dielectric layers by stressing mis devices with a dc bias; then the injected charge kinetics are monitored by capacitance-voltage measurement before and after charge injection. we found that the polarity of charge accumulated in the dielectric is strongly influenced by the dielectric structure. when the metal electrode is positively biased, a negative charge accumulates in the single and triple-layer devices, while a positive charge accumulates in the double-layer devices. furthermore, the experiment results also show that the lowest charge accumulation can be achieved using double-layer dielectric structure even though the fastest relaxation process takes place in triple-layer dielectric structure.",
            "contribution_ids": [
                "R141152"
            ]
        },
        {
            "instance_id": "R141425xR141401",
            "comparison_id": "R141425",
            "paper_id": "R141401",
            "text": "Application of camelid heavy-chain variable domains (VHHs) in prevention and treatment of bacterial and viral infections abstract camelid heavy-chain variable domains (vhhs) are the smallest, intact, antigen-binding units to occur in nature. vhhs possess high degrees of solubility and robustness enabling generation of multivalent constructs with increased avidity \u2013 characteristics that mark their superiority to other antibody fragments and monoclonal antibodies. capable of effectively binding to molecular targets inaccessible to classical immunotherapeutic agents and easily produced in microbial culture, vhhs are considered promising tools for pharmaceutical biotechnology. with the aim to demonstrate the perspective and potential of vhhs for the development of prophylactic and therapeutic drugs to target diseases caused by bacterial and viral infections, this review article will initially describe the structural features that underlie the unique properties of vhhs and explain the methods currently used for the selection and recombinant production of pathogen-specific vhhs, and then thoroughly summarize the experimental findings of five distinct studies that employed vhhs as inhibitors of host\u2013pathogen interactions or neutralizers of infectious agents. past and recent studies suggest the potential of camelid heavy-chain variable domains as a novel modality of immunotherapeutic drugs and a promising alternative to monoclonal antibodies. vhhs demonstrate the ability to interfere with bacterial pathogenesis by preventing adhesion to host tissue and sequestering disease-causing bacterial toxins. to protect from viral infections, vhhs may be employed as inhibitors of viral entry by binding to viral coat proteins or blocking interactions with cell-surface receptors. the implementation of vhhs as immunotherapeutic agents for infectious diseases is of considerable potential and set to contribute to public health in the near future.",
            "contribution_ids": [
                "R141402"
            ]
        },
        {
            "instance_id": "R141425xR141413",
            "comparison_id": "R141425",
            "paper_id": "R141413",
            "text": "Novel coronavirus-like particles targeting cells lining the respiratory tract virus like particles (vlps) produced by the expression of viral structural proteins can serve as versatile nanovectors or potential vaccine candidates. in this study we describe for the first time the generation of hcov-nl63 vlps using baculovirus system. major structural proteins of hcov-nl63 have been expressed in tagged or native form, and their assembly to form vlps was evaluated. additionally, a novel procedure for chromatography purification of hcov-nl63 vlps was developed. interestingly, we show that these nanoparticles may deliver cargo and selectively transduce cells expressing the ace2 protein such as ciliated cells of the respiratory tract. production of a specific delivery vector is a major challenge for research concerning targeting molecules. the obtained results show that hcov-nl63 vlps may be efficiently produced, purified, modified and serve as a delivery platform. this study constitutes an important basis for further development of a promising viral vector displaying narrow tissue tropism.",
            "contribution_ids": [
                "R141414"
            ]
        },
        {
            "instance_id": "R141425xR141415",
            "comparison_id": "R141425",
            "paper_id": "R141415",
            "text": "Development of Label-Free Colorimetric Assay for MERS-CoV Using Gold Nanoparticles worldwide outbreaks of infectious diseases necessitate the development of rapid and accurate diagnostic methods. colorimetric assays are a representative tool to simply identify the target molecules in specimens through color changes of an indicator (e.g., nanosized metallic particle, and dye molecules). the detection method is used to confirm the presence of biomarkers visually and measure absorbance of the colored compounds at a specific wavelength. in this study, we propose a colorimetric assay based on an extended form of double-stranded dna (dsdna) self-assembly shielded gold nanoparticles (aunps) under positive electrolyte (e.g., 0.1 m mgcl2) for detection of middle east respiratory syndrome coronavirus (mers-cov). this platform is able to verify the existence of viral molecules through a localized surface plasmon resonance (lspr) shift and color changes of aunps in the uv\u2013vis wavelength range. we designed a pair of thiol-modified probes at either the 5\u2032 end or 3\u2032 end to organize complementary base pairs with upstream of the e protein gene (upe) and open reading frames (orf) 1a on mers-cov. the dsdna of the target and probes forms a disulfide-induced long self-assembled complex, which protects aunps from salt-induced aggregation and transition of optical properties. this colorimetric assay could discriminate down to 1 pmol/\u03bcl of 30 bp mers-cov and further be adapted for convenient on-site detection of other infectious diseases, especially in resource-limited settings.",
            "contribution_ids": [
                "R141416"
            ]
        },
        {
            "instance_id": "R141425xR141419",
            "comparison_id": "R141425",
            "paper_id": "R141419",
            "text": "Identification of sialic acid-binding function for the Middle East respiratory syndrome coronavirus spike glycoprotein significance \\n middle east respiratory syndrome coronavirus (mers-cov) recurrently infects humans from its dromedary camel reservoir, causing severe respiratory disease with an \u223c35% fatality rate. the virus binds to the dipeptidyl peptidase 4 (dpp4) entry receptor on respiratory epithelial cells via its spike protein. we here report that the mers-cov spike protein selectively binds to sialic acid (sia) and demonstrate that cell-surface sialoglycoconjugates can serve as an attachment factor. our observations warrant further research into the role of sia binding in the virus\u2019s host and tissue tropism and transmission, which may be influenced by the observed sia-binding fine specificity and by differences in sialoglycomes among host species.",
            "contribution_ids": [
                "R141420"
            ]
        },
        {
            "instance_id": "R141593xR108956",
            "comparison_id": "R141593",
            "paper_id": "R108956",
            "text": "VUV radiation flux from argon DC magnetron plasma vacuum ultraviolet (vuv) flux of argon plasma radiation in a dc magnetron discharge with a plane circular titanium cathode is measured. it is found that the intensity of vuv radiation, mainly indicated by the resonance lines of argon atoms at 104.8 and 106.7 nm and ions at 92 and 93.2 nm, is proportional to the discharge current and decreases with pressure. following the results of the measurements, a numerical model of resonance radiation transport is developed to determine the vuv flux to the substrate placed near the sputtering cathode where direct measurements are impossible due to the fast contamination of the detector by sputtered atoms. in the case of a substrate located 10 cm opposite the cathode surface, the upper limit of estimated vuv flux is of the order of 1015 photons\\u2009cm\u22122\\u2009s\u22121 at a coating deposition rate of 1.5 nm\\u2009s\u22121 for 2 and 12 mtorr gas pressures. based on the measurements, the damage to a porous low-k dielectric by vuv radiation during the deposition of barrier layers in the dc magnetron discharge is first estimated.",
            "contribution_ids": [
                "R141575",
                "R141762"
            ]
        },
        {
            "instance_id": "R141593xR141535",
            "comparison_id": "R141593",
            "paper_id": "R141535",
            "text": "In situmeasurement of VUV/UV radiation from low-pressure microwave-produced plasma in Ar/O2gas mixtures ultraviolet (uv) and vacuum ultraviolet (vuv) spectral irradiance is determined in low-pressure microwave-produced plasma, which is regularly used for polymer surface treatment. the re-emitted fluorescence in the uv/vis spectral range from a sodium salicylate layer is measured. this fluorescence is related to vuv/uv radiation in different spectral bands based on cut-off filters. the background produced by direct emitted radiation in the fluorescence spectral region is quantified using a specific background filter, thus enabling the use of the whole fluorescence spectral range. a novel procedure is applied to determine the absolute value of the vuv/uv irradiance on a substrate. for that, an independent measurement of the absolute spectral emissivity of the plasma in the uv is performed. the measured irradiances on a substrate from a 25 pa ar/o2-produced plasma are in the range of 1015\u20131016 (photon s\u22121cm\u22122). these values include the contribution from impurities present in the discharge.",
            "contribution_ids": [
                "R141578",
                "R141765"
            ]
        },
        {
            "instance_id": "R141593xR141538",
            "comparison_id": "R141593",
            "paper_id": "R141538",
            "text": "Multifold study of volume plasma chemistry in Ar/CF4and Ar/CHF3CCP discharges low-pressure rf plasma in fluorohydrocarbon gas mixtures is widely used in modern microelectronics, e.g. in the etching of materials with a low dielectric constant (low-k) materials). the multifold experimental and theoretical study of a radio frequency capacitively coupled plasma at 81 mhz in ar/cf4/chf3 has been carried out at 50 mtorr and 150 mtorr gas pressures. a wide set of experimental diagnostics together with hybrid pic mc model calculations were applied to a detailed study of the plasmas. measurements of the f atoms, hf molecules and cfx radicals, electron density, electronegativity and positive ion composition were performed. absolutely calibrated vuv spectrometry was carried out to measure the vuv photon fluence towards the electrode. this combined experimental and model approach allowed us to establish the fundamental mechanisms of the charged and neutral species elementary reactions. dissociative charge transfer reactions and fluoride transfer reactions influence the main ion (cf 3 + , chf 2 + ) composition in ar/cf4/chf3 plasma a lot. the mechanisms of heavy ion formation in ar/chf3 are also discussed. the important role of additional attachment mechanisms (besides dissociative attachment to the feedstock gases, cf4, chf3) was analyzed. the catalytic chain mechanism, including the hf molecules, which defines the cfx kinetics in ar/chf3 plasma, was validated. this multifold approach enabled us to determine the complicated plasma chemical composition of the active species as well as the fluxes of vuv photons at the surface of the processed material, and is a result that is important for understanding low-k damage.",
            "contribution_ids": [
                "R141579",
                "R141766"
            ]
        },
        {
            "instance_id": "R141593xR108942",
            "comparison_id": "R141593",
            "paper_id": "R108942",
            "text": "Comparison of surface vacuum ultraviolet emissions with resonance level number densities. I. Argon plasmas vacuum ultraviolet (vuv) photons emitted from excited atomic states are ubiquitous in material processing plasmas. the highly energetic photons can induce surface damage by driving surface reactions, disordering surface regions, and affecting bonds in the bulk material. in argon plasmas, the vuv emissions are due to the decay of the 1s4 and 1s2 principal resonance levels with emission wavelengths of 104.8 and 106.7\\u2009nm, respectively. the authors have measured the number densities of atoms in the two resonance levels using both white light optical absorption spectroscopy and radiation-trapping induced changes in the 3p54p\u21923p54s branching fractions measured via visible/near-infrared optical emission spectroscopy in an argon inductively coupled plasma as a function of both pressure and power. an emission model that takes into account radiation trapping was used to calculate the vuv emission rate. the model results were compared to experimental measurements made with a national institute of standards and techn...",
            "contribution_ids": [
                "R141585",
                "R141772"
            ]
        },
        {
            "instance_id": "R141699xR141621",
            "comparison_id": "R141699",
            "paper_id": "R141621",
            "text": "Probing the highly efficient room temperature ammonia gas sensing properties of a luminescent ZnO nanowire array prepared via an AAO-assisted template route a highly ordered luminescent zno nanowire array was synthesized which has excellent sensitivity and fast response to nh 3 gas.",
            "contribution_ids": [
                "R141623"
            ]
        },
        {
            "instance_id": "R141699xR141631",
            "comparison_id": "R141699",
            "paper_id": "R141631",
            "text": "Rice Husk Templated Mesoporous ZnO Nanostructures for Ethanol Sensing at Room Temperature mesoporous zinc oxide nanostructures are successfully synthesized via the sol-gel route by using a rice husk as the template for ethanol sensing at room temperature. the structure and morphology of the nanostructures are characterized by x-ray diffraction, scanning electron microscopy (sem), transmission electron microscopy (tem), and nitrogen adsorption\u2013desorption analyses. the mechanism for the growth of zinc oxide nanostructures over the biotemplate is proposed. sem and tem observations also reveal the formation of spherical zinc oxide nanoparticles over the interwoven fibrous network. multiple sized pores having pore diameter ranging from 10\u201340 nm is also evidenced from the pore size distribution plot. the larger surface area and porous nature of the material lead to high sensitivity (40.93% for 300 ppm of ethanol), quick response (42 s) and recovery (40 s) towards ethanol at 300 k. the porous nature of the interwoven fibre-like network affords mass transportation of ethanol vapor, which results in faster surface accessibility, and hence it acts as a potential candidate for ethanol sensing at room temperature.",
            "contribution_ids": [
                "R141633"
            ]
        },
        {
            "instance_id": "R141752xR141205",
            "comparison_id": "R141752",
            "paper_id": "R141205",
            "text": "Governance Infrastructures in 2020 a governance infrastructure is the collection of technologies and systems, people, policies, practices, and relationships that interact to support governing activities. information technology, especially communication and computational technologies, continues to augment society\u2019s ability to organize, interact, and govern. as we think about the future of governance, this article challenges us to move beyond questions of how to best manage government institutions to how to design smart governance systems with the appropriate incentives and rules to harness and coordinate the enthusiasm and capabilities of those governed. this article anticipates how the interaction of technology and society can be leveraged to mindfully design an interaction-defined, participation-based governance infrastructure to return power to the people while increasing accountability. supporting examples of such governance approaches already exist and are regularly emerging in distributed organizations, online communities, nonprofits, and governments.",
            "contribution_ids": [
                "R141207",
                "R142079"
            ]
        },
        {
            "instance_id": "R141752xR141214",
            "comparison_id": "R141752",
            "paper_id": "R141214",
            "text": "Conceptualizing smart city with dimensions of technology, people, and institutions this conceptual paper discusses how we can consider a particular city as a smart one, drawing on recent practices to make cities smart. a set of the common multidimensional components underlying the smart city concept and the core factors for a successful smart city initiative is identified by exploring current working definitions of smart city and a diversity of various conceptual relatives similar to smart city. the paper offers strategic principles aligning to the three main dimensions (technology, people, and institutions) of smart city: integration of infrastructures and technology-mediated services, social learning for strengthening human infrastructure, and governance for institutional improvement and citizen engagement.",
            "contribution_ids": [
                "R141216",
                "R142076"
            ]
        },
        {
            "instance_id": "R141752xR141250",
            "comparison_id": "R141752",
            "paper_id": "R141250",
            "text": "Aspirations and Realizations: The Smart City of Seattle smart city initiatives have been launched on every continent. that notwithstanding the concept of \u201csmart city\u201d has remained ambiguous. we systematically interviewed officials of an acclaimed smart city (seattle) and explicitly asked the officials for their own definitions of \u201csmart city,\u201d which we then compared to the respective projects run by that city. while the definitions given by the practitioners were found different from those in the literature, the smart city projects lived up and matched the practitioner definitions to a high degree. we document the projects and their expected and realized benefits, which illustrate where a leading city government is headed in terms of smart government. however, \u201csmart city\u201d initiatives in local government might be only a steppingstone in making the greater urban space a \u201csmart city,\u201d which appears to be a more challenging undertaking.",
            "contribution_ids": [
                "R141252",
                "R141757",
                "R142064"
            ]
        },
        {
            "instance_id": "R141780xR141661",
            "comparison_id": "R141780",
            "paper_id": "R141661",
            "text": "Fluorescent N-Doped Carbon Dots as in Vitro and in Vivo Nanothermometer the fluorescent n-doped carbon dots (n-cds) obtained from c3n4 emit strong blue fluorescence, which is stable with different ionic strengths and time. the fluorescence intensity of n-cds decreases with the temperature increasing, while it can recover to the initial one with the temperature decreasing. it is an accurate linear response of fluorescence intensity to temperature, which may be attributed to the synergistic effect of abundant oxygen-containing functional groups and hydrogen bonds. further experiments also demonstrate that n-cds can serve as effective in vitro and in vivo fluorescence-based nanothermometer.",
            "contribution_ids": [
                "R141663"
            ]
        },
        {
            "instance_id": "R141780xR141708",
            "comparison_id": "R141780",
            "paper_id": "R141708",
            "text": "N,S co-doped carbon dots as a stable bio-imaging probe for detection of intracellular temperature and tetracycline n,s-cds display an unambiguous bioimaging ability in the detection of intracellular temperature and tetracycline with satisfactory results.",
            "contribution_ids": [
                "R141713"
            ]
        },
        {
            "instance_id": "R142850xR142837",
            "comparison_id": "R142850",
            "paper_id": "R142837",
            "text": "New Method for Delivering a Hydrophobic Drug for Photodynamic Therapy Using Pure Nanocrystal Form of the Drug a carrier-free method for delivery of a hydrophobic drug in its pure form, using nanocrystals (nanosized crystals), is proposed. to demonstrate this technique, nanocrystals of a hydrophobic photosensitizing anticancer drug, 2-devinyl-2-(1-hexyloxyethyl)pyropheophorbide (hpph), have been synthesized using the reprecipitation method. the resulting drug nanocrystals were monodispersed and stable in aqueous dispersion, without the necessity of an additional stabilizer (surfactant). as shown by confocal microscopy, these pure drug nanocrystals were taken up by the cancer cells with high avidity. though the fluorescence and photodynamic activity of the drug were substantially quenched in the form of nanocrystals in aqueous suspension, both these characteristics were recovered under in vitro and in vivo conditions. this recovery of drug activity and fluorescence is possibly due to the interaction of nanocrystals with serum albumin, resulting in conversion of the drug nanocrystals into the molecular form. this was confirmed by demonstrating similar recovery in presence of fetal bovine serum (fbs) or bovine serum albumin (bsa). under similar treatment conditions, the hpph in nanocrystal form or in 1% tween-80/water formulation showed comparable in vitro and in vivo efficacy.",
            "contribution_ids": [
                "R142839"
            ]
        },
        {
            "instance_id": "R144121xR143919",
            "comparison_id": "R144121",
            "paper_id": "R143919",
            "text": "Enabling Folksonomies for Knowledge Extraction: A Semantic Grounding Approach folksonomies emerge as the result of the free tagging activity of a large number of users over a variety of resources. they can be considered as valuable sources from which it is possible to obtain emerging vocabularies that can be leveraged in knowledge extraction tasks. however, when it comes to understanding the meaning of tags in folksonomies, several problems mainly related to the appearance of synonymous and ambiguous tags arise, specifically in the context of multilinguality. the authors aim to turn folksonomies into knowledge structures where tag meanings are identified, and relations between them are asserted. for such purpose, they use dbpedia as a general knowledge base from which they leverage its multilingual capabilities.",
            "contribution_ids": [
                "R143921"
            ]
        },
        {
            "instance_id": "R144512xR144378",
            "comparison_id": "R144512",
            "paper_id": "R144378",
            "text": "In vivo biodistribution of venlafaxine-PLGA nanoparticles for brain delivery: plain vs. functionalized nanoparticles abstract background: actually, no drugs provide therapeutic benefit to approximately one-third of depressed patients. depression is predicted to become the first global disease by 2030. so, new therapeutic interventions are imperative. research design and methods: venlafaxine-loaded poly(lactic-co-glycolic acid) (plga) nanoparticles (nps) were surface functionalized with two ligands against transferrin receptor to enhance access to brain. an in vitro blood\u2013brain barrier model using hcmec/d3 cell line was developed to evaluate permeability. in vivo biodistribution studies were performed using c57/bl6 mice. particles were administered intranasal and main organs were analyzed. results: particles were obtained as a lyophilized powder easily to re-suspend. internalization and permeability studies showed the following cell association sequence: tfrp-nps>tf-nps>plain nps. permeability studies also showed that encapsulated vlf was not affected by p-gp pump efflux increasing its concentration in the basolateral side after 24 h. in vivo studies showed that 25% of plain nps reach the brain after 30 min of one intranasal administration while less than 5% of functionalized nps get the target. conclusions: plain nps showed the highest ability to reach the brain vs. functionalized nps after 30 min by intranasal administration. we suggest plain nps probably travel via direct nose-to-brian route whereas functionalized nps reach the brain by receptor-mediated endocytosis.",
            "contribution_ids": [
                "R144381",
                "R144382"
            ]
        },
        {
            "instance_id": "R144512xR144478",
            "comparison_id": "R144512",
            "paper_id": "R144478",
            "text": "Co-delivery of doxorubicin and siRNA for glioma therapy by a brain targeting system: angiopep-2-modified poly(lactic-co-glycolic acid) nanoparticles abstract it is very challenging to treat brain cancer because of the blood\u2013brain barrier (bbb) restricting therapeutic drug or gene to access the brain. in this research project, angiopep-2 (ang) was used as a brain-targeted peptide for preparing multifunctional ang-modified poly(lactic-co-glycolic acid) (plga) nanoparticles (nps), which encapsulated both doxorubicin (dox) and epidermal growth factor receptor (egfr) sirna, designated as ang/plga/dox/sirna. this system could efficiently deliver dox and sirna into u87mg cells leading to significant cell inhibition, apoptosis and egfr silencing in vitro. it demonstrated that this drug system was capable of penetrating the bbb in vivo, resulting in more drugs accumulation in the brain. the animal study using the brain orthotopic u87mg glioma xenograft model indicated that the ang-targeted co-delivery of dox and egfr sirna resulted in not only the prolongation of the life span of the glioma-bearing mice but also an obvious cell apoptosis in glioma tissue.",
            "contribution_ids": [
                "R144480"
            ]
        },
        {
            "instance_id": "R145685xR145174",
            "comparison_id": "R145685",
            "paper_id": "R145174",
            "text": "Theory of Line Broadening in Multiplet Spectra \"a theory of line broadening in the impect approximation is developed which includes the case of overlapping lines. it is assumed that the collisions which give rise to the broadening do not cause transitions between states with different principal quantam numbers. the theory was worked out in detail in two cases: (1) the broadening arises only from perturbations of the upper state with arbitrary splitting of the substates. this approximation may be used if the perturbations of the lower state are relatively unimportant (e.g.. the higher series members of the balmer lines), and is exact if the perturbations do not affect the lower state as in the case of the ground stute of hydrogen perturbed by electron collisions; (2) complete degeneracy of the initial and final states. this approximation is also valid on the far wing of the line if there is splitting, i.e.. for frequencies large compared to thc splitting, and is a generalization of anderson's theory. the formal theory is worked out by two different methods. the method of calculation for nearly degenerate initial and final states with splitting is indicated. method i is particularly suited for calculating the wing distribution while method ii is more suitable formore\\xa0\u00bb finding tbe intensity distribution at the line center for overlapping lines. the line profile is made up of a sum of dispersion profiles and asymmetric terms whicb arise from interferences when the transition operator is not diagonal. the shift and half-width parameters are found from the roots of a secular equation and depend on the splitting as well as the density. temperature. and the character of the perturbation. (auth)\u00ab\\xa0less\"",
            "contribution_ids": [
                "R145225"
            ]
        },
        {
            "instance_id": "R145685xR145180",
            "comparison_id": "R145685",
            "paper_id": "R145180",
            "text": "Stark Broadening of Neutral Helium Lines in a Plasma \"the frequency distributions of spectral lines of nonhydrogenic atoms broadened by local fields of both electrons and ions in a plasma are calculated in the classical path approximation. the electron collisions are treated by an impact theory which takes into account deviations from adiabaticity. for the ion effects, the adiabatic approximation can be used to describe the time-dependent wave functions. the various approximations employed were examined for self-consistency, and an accuracy of about 20% in the resulting line profiles is expected. good agreement with wulff's experimental helium line profiles was obtained while there are large deviations from the adiabatic theory, especially for the line shifts. asymptotic distributions for the line wings are given for astrophysical applications. here the ion effects can be as important as the electron effects and lead to large asymmetries, but near the line core electrons usually dominate. numerical results are tabulated for 24 neutral helium lines with principal quantum numbers up to five.\"",
            "contribution_ids": [
                "R145227"
            ]
        },
        {
            "instance_id": "R145685xR145210",
            "comparison_id": "R145685",
            "paper_id": "R145210",
            "text": "Stark broadening of the B III2s\u00e2\u0088\u00922plines we present a quantum-mechanical calculation of stark linewidths from electron-ion collisions for the 2s{sub 1/2}-2p{sub 1/2,3/2}, {lambda}=2066 and 2067 {angstrom}, resonance transitions in biii. the results confirm previous quantum-mechanical r-matrix calculations, but contradict recent measurements and semiclassical and some semiempirical calculations. the differences between the calculations can be attributed to the dominance of small l partial waves in the electron-atom scattering, while the large stark widths inferred from the measurements would be substantially reduced if allowance is made for hydrodynamic turbulence from high-reynolds-number flows and the associated doppler broadening. {copyright} {ital 1997} {ital the american physical society}",
            "contribution_ids": [
                "R145238"
            ]
        },
        {
            "instance_id": "R145685xR145213",
            "comparison_id": "R145685",
            "paper_id": "R145213",
            "text": "Electron impact broadening of spectral lines in Be-like ions: quantum calculations we present in this paper quantum mechanical calculations for the electron impact stark linewidths of the 2s3s\u20132s3p transitions for the four beryllium-like ions from n iv to ne vii. calculations are made in the frame of the impact approximation and intermediate coupling, taking into account fine-structure effects. a comparison between our calculations, experimental and other theoretical results, shows a good agreement. this is the first time that such a good agreement is found between quantum and experimental linewidths of highly charged ions.",
            "contribution_ids": [
                "R145239"
            ]
        },
        {
            "instance_id": "R146458xR146051",
            "comparison_id": "R146458",
            "paper_id": "R146051",
            "text": "Innovation Management in the Context of Smart Cities Digital Transformation the paper introduces important aspects of doctoral research concerning innovation management in the context of business management challenges posed by digital transformation. the research was conducted as part of the research centre of business administration in the bucharest university of economic studies, romania. the study aims to identify and display key components of innovation management \u2013 with a primary focus on topics spurred by the recent wave of digital evolution. against this background, the issue of smart city solutions makes for an interesting case \u2013 firstly, because it affects a large number of people and businesses around the globe and secondly, the complexity of the topic forces companies to pursue different innovation management approaches to successfully manage its associated challenges as well as opportunities. the paper consists of an overview on the existing literature and a concise outline of our research. both researches from professional associations as well as recognized publishers were considered. furthermore, market data were gathered and processed. more than 50 publications were analyzed to better understand trends in digital transformation and its impact on innovation management. our research revealed that in the light of the fundamental challenges posed by digitization, companies are required to take a structured approach towards their innovation management options. in the context of smart city solutions, the adoption of the \u201c4i solutions model\u201d enables businesses to choose the strategic option suitable to their individual case. concisely, this framework includes four different approaches ranging from initiating groundwork innovation internally to establishing partnerships with selected external parties.",
            "contribution_ids": [
                "R146053"
            ]
        },
        {
            "instance_id": "R146458xR146090",
            "comparison_id": "R146458",
            "paper_id": "R146090",
            "text": "Internet of Things, legal and regulatory framework in digital transformation from smart to intelligent cities \"digital transformation from \u201csmart\u201d to \u201cintelligent city\u201d is based on new information technologies and knowledge, as well as on organizational and security processes. the authors of this paper will present the legal and regulatory framework and challenges of internet of things in development of smart cities on the way to become intelligent cities. the special contribution of the paper will be an overview of new legal and regulatory framework general data protection regulation (gdpr) which is of great importance for european union legal and regulation framework and bringing novelties in citizen's privacy and protection of personal data.\"",
            "contribution_ids": [
                "R146092"
            ]
        },
        {
            "instance_id": "R146458xR146157",
            "comparison_id": "R146458",
            "paper_id": "R146157",
            "text": "The digital transformation and smart data analytics: An overview of enabling developments and application areas the digital transformation enables new business models and enhanced business processes by utilizing available data for analytics, prediction, and decision support. we give an overview of the enabling developments for the digital transformation, the areas of application, and concrete use case examples. we summarize our findings in a framework for the digital transformation and discuss the potential for new and adapted business models.",
            "contribution_ids": [
                "R146159"
            ]
        },
        {
            "instance_id": "R146851xR145085",
            "comparison_id": "R146851",
            "paper_id": "R145085",
            "text": "Developing open source, self-contained disease surveillance software applications for use in resource-limited settings abstract background emerging public health threats often originate in resource-limited countries. in recognition of this fact, the world health organization issued revised international health regulations in 2005, which call for significantly increased reporting and response capabilities for all signatory nations. electronic biosurveillance systems can improve the timeliness of public health data collection, aid in the early detection of and response to disease outbreaks, and enhance situational awareness. methods as components of its suite for automated global biosurveillance (sages) program, the johns hopkins university applied physics laboratory developed two open-source, electronic biosurveillance systems for use in resource-limited settings. openessence provides web-based data entry, analysis, and reporting. essence desktop edition provides similar capabilities for settings without internet access. both systems may be configured to collect data using locally available cell phone technologies. results essence desktop edition has been deployed for two years in the republic of the philippines. local health clinics have rapidly adopted the new technology to provide daily reporting, thus eliminating the two-to-three week data lag of the previous paper-based system. conclusions openessence and essence desktop edition are two open-source software products with the capability of significantly improving disease surveillance in a wide range of resource-limited settings. these products, and other emerging surveillance technologies, can assist resource-limited countries compliance with the revised international health regulations.",
            "contribution_ids": [
                "R145087",
                "R145088",
                "R145089"
            ]
        },
        {
            "instance_id": "R146851xR145318",
            "comparison_id": "R146851",
            "paper_id": "R145318",
            "text": "Electronic Surveillance System for the Early Notification of Community-Based Epidemics (ESSENCE): Overview, Components, and Public Health Applications \\n background \\n the electronic surveillance system for the early notification of community-based epidemics (essence) is a secure web-based tool that enables health care practitioners to monitor health indicators of public health importance for the detection and tracking of disease outbreaks, consequences of severe weather, and other events of concern. the essence concept began in an internally funded project at the johns hopkins university applied physics laboratory, advanced with funding from the state of maryland, and broadened in 1999 as a collaboration with the walter reed army institute for research. versions of the system have been further developed by johns hopkins university applied physics laboratory in multiple military and civilian programs for the timely detection and tracking of health threats. \\n \\n \\n objective \\n this study aims to describe the components and development of a biosurveillance system increasingly coordinating all-hazards health surveillance and infectious disease monitoring among large and small health departments, to list the key features and lessons learned in the growth of this system, and to describe the range of initiatives and accomplishments of local epidemiologists using it. \\n \\n \\n methods \\n the features of essence include spatial and temporal statistical alerting, custom querying, user-defined alert notifications, geographical mapping, remote data capture, and event communications. to expedite visualization, configurable and interactive modes of data stratification and filtering, graphical and tabular customization, user preference management, and sharing features allow users to query data and view geographic representations, time series and data details pages, and reports. these features allow essence users to gather and organize the resulting wealth of information into a coherent view of population health status and communicate findings among users. \\n \\n \\n results \\n the resulting broad utility, applicability, and adaptability of this system led to the adoption of essence by the centers for disease control and prevention, numerous state and local health departments, and the department of defense, both nationally and globally. the open-source version of suite for automated global electronic biosurveillance is available for global, resource-limited settings. resourceful users of the us national syndromic surveillance program essence have applied it to the surveillance of infectious diseases, severe weather and natural disaster events, mass gatherings, chronic diseases and mental health, and injury and substance abuse. \\n \\n \\n conclusions \\n with emerging high-consequence communicable diseases and other health conditions, the continued user requirement\u2013driven enhancements of essence demonstrate an adaptable disease surveillance capability focused on the everyday needs of public health. the challenge of a live system for widely distributed users with multiple different data sources and high throughput requirements has driven a novel, evolving architecture design. \\n",
            "contribution_ids": [
                "R145327"
            ]
        },
        {
            "instance_id": "R146851xR145901",
            "comparison_id": "R146851",
            "paper_id": "R145901",
            "text": "Evaluating the electronic tuberculosis register surveillance system in Eden District, Western Cape, South Africa, 2015 abstract background: tuberculosis (tb) surveillance data are crucial to the effectiveness of national tb control programs. in south africa, few surveillance system evaluations have been undertaken to provide a rigorous assessment of the platform from which the national and district health systems draws data to inform programs and policies. objective: evaluate the attributes of eden district\u2019s tb surveillance system, western cape province, south africa. methods: data quality, sensitivity and positive predictive value were assessed using secondary data from 40,033 tb cases entered in eden district\u2019s etr.net from 2007 to 2013, and 79 purposively selected tb blue cards (tbcs), a medical patient file and source document for data entered into etr.net. simplicity, flexibility, acceptability, stability and usefulness of the etr.net were assessed qualitatively through interviews with tb nurses, information health officers, sub-district and district coordinators involved in the tb surveillance. results: tb surveillance system stakeholders report that eden district\u2019s etr.net system was simple, acceptable, flexible and stable, and achieves its objective of informing tb control program, policies and activities. data were less complete in the etr.net (66\u2013100%) than in the tbcs (76\u2013100%), and concordant for most variables except pre-treatment smear results, antiretroviral therapy (art) and treatment outcome. the sensitivity of recorded variables in etr.net was 98% for gender, 97% for patient category, 93% for art, 92% for treatment outcome and 90% for pre-treatment smear grading. conclusions: our results reveal that the system provides useful information to guide tb control program activities in eden district. however, urgent attention is needed to address gaps in clinical recording on the tbc and data capturing into the etr.net system. we recommend continuous training and support of tb personnel involved with tb care, management and surveillance on tb data recording into the tbcs and etr.net as well as the implementation of a well-structured quality control and assurance system.",
            "contribution_ids": [
                "R145904",
                "R145914",
                "R145915"
            ]
        },
        {
            "instance_id": "R146851xR146256",
            "comparison_id": "R146851",
            "paper_id": "R146256",
            "text": "Improving national surveillance of Lyme neuroborreliosis in Denmark through electronic reporting of specific antibody index testing from 2010 to 2012 our aim was to evaluate the results of automated surveillance of lyme neuroborreliosis (lnb) in denmark using the national microbiology database (miba), and to describe the epidemiology of laboratory-confirmed lnb at a national level. miba-based surveillance includes electronic transfer of laboratory results, in contrast to the statutory surveillance based on manually processed notifications. antibody index (ai) testing is the recommend laboratory test to support the diagnosis of lnb in denmark. in the period from 2010 to 2012, 217 clinical cases of lnb were notified to the statutory surveillance system, while 533 cases were reported ai positive by the miba system. thirty-five unconfirmed cases (29 ai-negative and 6 not tested) were notified, but not captured by miba. using miba, the number of reported cases was increased almost 2.5 times. furthermore, the reporting was timelier (median lag time: 6 vs 58 days). average annual incidence of ai-confirmed lnb in denmark was 3.2/100,000 population and incidences stratified by municipality ranged from none to above 10/100,000. this is the first study reporting nationwide incidence of lnb using objective laboratory criteria. laboratory-based surveillance with electronic data-transfer was more accurate, complete and timely compared to the surveillance based on manually processed notifications. we propose using ai test results for lnb surveillance instead of clinical reporting.\\n",
            "contribution_ids": [
                "R146258"
            ]
        },
        {
            "instance_id": "R147040xR145437",
            "comparison_id": "R147040",
            "paper_id": "R145437",
            "text": "DNA Barcoding to Improve the Taxonomy of the Afrotropical Hoverflies (Insecta: Diptera: Syrphidae) the identification of afrotropical hoverflies is very difficult because of limited recent taxonomic revisions and the lack of comprehensive identification keys. in order to assist in their identification, and to improve the taxonomy of this group, we constructed a reference dataset of 513 coi barcodes of 90 of the more common nominal species from ghana, togo, benin and nigeria (w africa) and added ten publically available coi barcodes from nine nominal afrotropical species to this (total: 523 coi barcodes; 98 nominal species; 26 genera). the identification accuracy of this dataset was evaluated with three methods (k2p distance-based, neighbor-joining (nj) / maximum likelihood (ml) analysis, and using speciesidentifier). results of the three methods were highly congruent and showed a high identification success. nine species pairs showed a low ( 0.03) maximum intraspecific k2p distance was observed in eight species and barcodes of these species not always formed single clusters in the nj / ml analayses which may indicate the occurrence of cryptic species. optimal k2p thresholds to differentiate intra- from interspecific k2p divergence were highly different among the three subfamilies (eristalinae: 0.037, syrphinae: 0.06, microdontinae: 0.007\u20130.02), and among the different general suggesting that optimal thresholds are better defined at the genus level. in addition to providing an alternative identification tool, our study indicates that dna barcoding improves the taxonomy of afrotropical hoverflies by selecting (groups of) taxa that deserve further taxonomic study, and by attributing the unknown sex to species for which only one of the sexes is known.",
            "contribution_ids": [
                "R145438",
                "R155749"
            ]
        },
        {
            "instance_id": "R148381xR148267",
            "comparison_id": "R148381",
            "paper_id": "R148267",
            "text": "Enhanced delivery of etoposide across the blood\u00e2\u0080\u0093brain barrier to restrain brain tumor growth using melanotransferrin antibody- and tamoxifen-conjugated solid lipid nanoparticles abstract melanotransferrin antibody (ma) and tamoxifen (tx) were conjugated on etoposide (etp)-entrapped solid lipid nanoparticles (etp-slns) to target the blood\u2013brain barrier (bbb) and glioblastom multiforme (gbm). ma- and tx-conjugated etp-slns (ma\u2013tx\u2013etp\u2013slns) were used to infiltrate the bbb comprising a monolayer of human astrocyte-regulated human brain-microvascular endothelial cells (hbmecs) and to restrain the proliferation of malignant u87mg cells. tx-grafted etp-slns (tx\u2013etp\u2013slns) significantly enhanced the bbb permeability coefficient for etp and raised the fluorescent intensity of calcein-am when compared with etp-slns. in addition, surface ma could increase the bbb permeability coefficient for etp about twofold. the viability of hbmecs was higher than 86%, suggesting a high biocompatibility of ma\u2013tx\u2013etp-slns. moreover, the efficiency in antiproliferation against u87mg cells was in the order of ma\u2013tx\u2013etp-slns\\u2009\\u2009>\\u2009\\u2009tx\u2013etp-slns\\u2009\\u2009>\\u2009\\u2009etp-slns\\u2009\\u2009>\\u2009\\u2009slns. the capability of ma\u2013tx\u2013etp-slns to target hbmecs and u87mg cells during internalization was verified by immunochemical staining of expressed melanotransferrin. ma\u2013tx\u2013etp-slns can be a potent pharmacotherapy to deliver etp across the bbb to gbm.",
            "contribution_ids": [
                "R148269"
            ]
        },
        {
            "instance_id": "R148381xR148289",
            "comparison_id": "R148381",
            "paper_id": "R148289",
            "text": "Vincristine and temozolomide combined chemotherapy for the treatment of glioma: a comparison of solid lipid nanoparticles and nanostructured lipid carriers for dual drugs delivery abstract context: glioma is a common malignant brain tumor originating in the central nervous system. efficient delivery of therapeutic agents to the cells and tissues is a difficult challenge. co-delivery of anticancer drugs into the cancer cells or tissues by multifunctional nanocarriers may provide a new paradigm in cancer treatment. objective: in this study, solid lipid nanoparticles (slns) and nanostructured lipid carriers (nlcs) were constructed for co-delivery of vincristine (vcr) and temozolomide (tmz) to develop the synergetic therapeutic action of the two drugs. the antitumor effects of these two systems were compared to provide a better choice for gliomatosis cerebri treatment. methods: vcr- and tmz-loaded slns (vt-slns) and nlcs (vt-nlcs) were formulated. their particle size, zeta potential, drug encapsulation efficiency (ee) and drug loading capacity were evaluated. the single tmz-loaded slns and nlcs were also prepared as contrast. anti-tumor efficacies of the two kinds of carriers were evaluated on u87 malignant glioma cells and mice bearing malignant glioma model. results: significantly better glioma inhibition was observed on nlcs formulations than slns, and dual drugs displayed the highest antitumor efficacy in vivo and in vitro than all the other formulations used. conclusion: vt-nlcs can deliver vcr and tmz into u87mg cells more efficiently, and inhibition efficacy is higher than vt-slns. this dual drugs-loaded nlcs could be an outstanding drug delivery system to achieve excellent therapeutic efficiency for the treatment of malignant gliomatosis cerebri.",
            "contribution_ids": [
                "R148291",
                "R148292"
            ]
        },
        {
            "instance_id": "R150058xR145757",
            "comparison_id": "R150058",
            "paper_id": "R145757",
            "text": "SemEval-2018 Task 7: Semantic Relation Extraction and Classification in Scientific Papers this paper describes the first task on semantic relation extraction and classification in scientific paper abstracts at semeval 2018. the challenge focuses on domain-specific semantic relations and includes three different subtasks. the subtasks were designed so as to compare and quantify the effect of different pre-processing steps on the relation classification results. we expect the task to be relevant for a broad range of researchers working on extracting specialized knowledge from domain corpora, for example but not limited to scientific or bio-medical information extraction. the task attracted a total of 32 participants, with 158 submissions across different scenarios.",
            "contribution_ids": [
                "R145759",
                "R145770",
                "R145773"
            ]
        },
        {
            "instance_id": "R150058xR146853",
            "comparison_id": "R150058",
            "paper_id": "R146853",
            "text": "SciREX: A Challenge Dataset for Document-Level Information Extraction extracting information from full documents is an important problem in many domains, but most previous work focus on identifying relationships within a sentence or a paragraph. it is challenging to create a large-scale information extraction (ie) dataset at the document level since it requires an understanding of the whole document to annotate entities and their document-level relationships that usually span beyond sentences or even sections. in this paper, we introduce scirex, a document level ie dataset that encompasses multiple ie tasks, including salient entity identification and document level n-ary relation identification from scientific articles. we annotate our dataset by integrating automatic and human annotations, leveraging existing scientific knowledge resources. we develop a neural model as a strong baseline that extends previous state-of-the-art ie models to document-level ie. analyzing the model performance shows a significant gap between human performance and current baselines, inviting the community to use our dataset as a challenge to develop document-level ie models. our data and code are publicly available at https://github.com/allenai/scirex .",
            "contribution_ids": [
                "R146855"
            ]
        },
        {
            "instance_id": "R150058xR147638",
            "comparison_id": "R150058",
            "paper_id": "R147638",
            "text": "Identifying used methods and datasets in scientific publications although it has become common to assess publications and researchers by means of their citation count (e.g., using the h-index), measuring the impact of scientific methods and datasets (e.g., using an \u201ch-index for datasets\u201d) has been performed only to a limited extent. this is not surprising because the usage information of methods and datasets is typically not explicitly provided by the authors, but hidden in a publication\u2019s text. in this paper, we propose an approach to identifying methods and datasets in texts that have actually been used by the authors. our approach first recognizes datasets and methods in the text by means of a domain-specific named entity recognition method with minimal human interaction. it then classifies these mentions into used vs. non-used based on the textual contexts. the obtained labels are aggregated on the document level and integrated into the microsoft academic knowledge graph modeling publications\u2019 metadata. in experiments based on the microsoft academic graph, we show that both method and dataset mentions can be identified and correctly classified with respect to their usage to a high degree. overall, our approach facilitates method and dataset recommendation, enhanced paper recommendation, and scientific impact quantification. it can be extended in such a way that it can identify mentions of any entity type (e.g., task).",
            "contribution_ids": [
                "R147640"
            ]
        },
        {
            "instance_id": "R150058xR69282",
            "comparison_id": "R150058",
            "paper_id": "R69282",
            "text": "SemEval 2017 Task 10: ScienceIE - Extracting Keyphrases and Relations from Scientific Publications we describe the semeval task of extracting keyphrases and relations between them from scientific documents, which is crucial for understanding which publications describe which processes, tasks and materials. although this was a new task, we had a total of 26 submissions across 3 evaluation scenarios. we expect the task and the findings reported in this paper to be relevant for researchers working on understanding scientific content, as well as the broader knowledge base population and information extraction communities.",
            "contribution_ids": [
                "R69283"
            ]
        },
        {
            "instance_id": "R151435xR151352",
            "comparison_id": "R151435",
            "paper_id": "R151352",
            "text": "Enzymatic glucose biosensor based on ZnO nanorod array grown by hydrothermal decomposition we report herein a glucose biosensor based on glucose oxidase (gox) immobilized on zno nanorod array grown by hydrothermal decomposition. in a phosphate buffer solution with a ph value of 7.4, negatively charged gox was immobilized on positively charged zno nanorods through electrostatic interaction. at an applied potential of +0.8v versus ag\u2215agcl reference electrode, zno nanorods based biosensor presented a high and reproducible sensitivity of 23.1\u03bcacm\u22122mm\u22121 with a response time of less than 5s. the biosensor shows a linear range from 0.01to3.45mm and an experiment limit of detection of 0.01mm. an apparent michaelis-menten constant of 2.9mm shows a high affinity between glucose and gox immobilized on zno nanorods.",
            "contribution_ids": [
                "R151354"
            ]
        },
        {
            "instance_id": "R151435xR151376",
            "comparison_id": "R151435",
            "paper_id": "R151376",
            "text": "ZnO/Cu Nanocomposite: A Platform for Direct Electrochemistry of Enzymes and Biosensing Applications unique structured nanomaterials can facilitate the direct electron transfer between redox proteins and the electrodes. here, in situ directed growth on an electrode of a zno/cu nanocomposite was prepared by a simple corrosion approach, which enables robust mechanical adhesion and electrical contact between the nanostructured zno and the electrodes. this is great help to realize the direct electron transfer between the electrode surface and the redox protein. sem images demonstrate that the morphology of the zno/cu nanocomposite has a large specific surface area, which is favorable to immobilize the biomolecules and construct biosensors. using glucose oxidase (gox) as a model, this zno/cu nanocomposite is employed for immobilization of gox and the construction of the glucose biosensor. direct electron transfer of gox is achieved at zno/cu nanocomposite with a high heterogeneous electron transfer rate constant of 0.67 \u00b1 0.06 s(-1). such zno/cu nanocomposite provides a good matrix for direct electrochemistry of enzymes and mediator-free enzymatic biosensors.",
            "contribution_ids": [
                "R151378"
            ]
        },
        {
            "instance_id": "R152186xR151947",
            "comparison_id": "R152186",
            "paper_id": "R151947",
            "text": "Evidence of lasing on the Balmer-\u00ce\u00b1 line of OVIII in an ablative capillary discharge in a low-inductance ablative discharge through a capillary made of polyacetal (pom), lasing on the balmer-\u03b1 line of oviii at 10.24 nm is identified. in line with previous studies of lasing on cvi ions, it is argued to be the consequence of charge exchange collisions after a m=0 instability. lasing in both cases occurred at about the same time after beginning of the discharge, although lasing on the balmer-\u03b1 line of oviii was less frequently observed, i.e., in approximately one out of ten discharges. lasing on the cvi ion was seen in one out of three discharges. this is probably due to the need of reaching higher electron temperatures to completely strip oxygen ions simultaneously in the hot constrictions (necks) of the plasma instability.",
            "contribution_ids": [
                "R151949"
            ]
        },
        {
            "instance_id": "R152186xR152081",
            "comparison_id": "R152186",
            "paper_id": "R152081",
            "text": "Soft-x-ray amplification in a capillary discharge soft-x-ray amplification in the c vi balmer \\\\ensuremath{\\\\alpha} transition is observed in a capillary discharge. the capillary is made of polyethylene with a bore diameter of 1.2 mm. a hot and dense carbon plasma which is formed on the capillary axis region expands radially and collides with the wall where it undergoes a rapid cooling and subsequent recombination. the amplification takes place in this cool (${\\\\mathit{t}}_{\\\\mathit{e}}$\\\\ensuremath{\\\\sim}13 ev) plasma region, according to space-resolved spectral data obtained using a 2-m grazing incidence spectrograph. the gain coefficient is measured to be 2.8 ${\\\\mathrm{cm}}^{\\\\mathrm{\\\\ensuremath{-}}1}$.",
            "contribution_ids": [
                "R152083"
            ]
        },
        {
            "instance_id": "R152186xR152133",
            "comparison_id": "R152186",
            "paper_id": "R152133",
            "text": "High-power-density capillary discharge plasma columns for shorter wavelength discharge-pumped soft-x-ray lasers we report the generation of plasma columns in gas-filled capillary channels using discharge excitation powers that exceed those of previous studies by one to two orders of magnitude. current pulses up to 200 ka and 10-90 % rise time of about 10 ns (current increase rate equivalent to 1.5 x 10(13) a/s) were utilized to excite plasmas in 3.3 and 4 mm diameter channels. time resolved soft-x-ray spectra and pinhole images of the plasma were obtained. the experimental data and its comparison with model computations suggest that dense argon plasma columns 300 mum in diameter with electron temperatures >250 ev have been obtained. these characteristics make these plasmas of interest for extending discharge-pumped lasers to shorter wavelengths.",
            "contribution_ids": [
                "R152135"
            ]
        },
        {
            "instance_id": "R152282xR149037",
            "comparison_id": "R152282",
            "paper_id": "R149037",
            "text": "The Competent Boundary Spanner inter-organizational frameworks of intervention dominate the resolution of complex societal problems facing the uk and many other countries. strategic alliances, joint working arrangements, networks, partnerships and many other forms of collaboration across sectoral and organizational boundaries currently proliferate across the policy landscape. however, the discourse is positioned at an institutional and organizational level, and comparatively little attention is accorded to the pivotal role of individual actors in the management of inter-organizational relationships. this paper attempts to redress this balance by focusing on the skills, competencies and behaviour of boundary spanners. a critical review of the relevant literature, both from an institutional and relational perspective, is undertaken. this is complemented by some new empirical research that involves an engagement with groups of particular types of boundary spanner using a combination of surveys and in-depth interviews. finally, a discussion makes connections between the existing literature and the research findings and offers suggestions for future areas of enquiry.",
            "contribution_ids": [
                "R149039"
            ]
        },
        {
            "instance_id": "R152282xR149072",
            "comparison_id": "R152282",
            "paper_id": "R149072",
            "text": "Defining the Role of the Smart-City Manager: An Analysis of Responsibilities and Skills abstract increasing social problems are challenging public administrations to adopt new strategies in order to create smarter cities. with regard to this, some cities have created a dedicated organizational unit focused on planning and implementation of smart city (sc) projects, led by an sc manager. however, the sc manager\u2019s responsibilities and curricula remain overlooked. the objective of this paper is to theoretically explore the role of the sc manager in municipalities and to analyze their main responsibilities and skills. based on an empirical questionnaire administered to public managers and politicians, a responsibility index (ri) is defined to identify the domains under the responsibility of the newly-established role of sc manager. the questionnaire is also an opportunity for understanding the main competencies and skills required through a factor analysis and qualitative investigation of the responses.",
            "contribution_ids": [
                "R149074"
            ]
        },
        {
            "instance_id": "R152282xR149075",
            "comparison_id": "R152282",
            "paper_id": "R149075",
            "text": "Required competencies in public administration study programs in the evaluation of undergraduate and graduate study programs, there is an important issue about which competencies must be acquired by graduates. this study tested the importance of competencies in public administration study programs in the light of expectations of employers in slovenian public administration. the aim of the research was to find out how various competencies acquired in higher education (undergraduate and graduate study in public administration) are evaluated by employers in public administration. on the basis of analysis of findings of similar research projects, the competencies contained in programs by renowned universities and competencies defined for the work positions, a set of discipline-specific competencies (61) were designed. research was conducted in 2015 and involved 343 respondents. a qualitative research method (survey) was used to collect the data which were then analyzed with the spss statistical program and microsoft excel. the results show that the competencies related to ethics and ethical behavior were evaluated as the most important; generic competencies are better assessed than specific ones and on average the competencies received a higher assessment for graduates (compare to undergraduates) positions",
            "contribution_ids": [
                "R149077"
            ]
        },
        {
            "instance_id": "R152282xR149078",
            "comparison_id": "R152282",
            "paper_id": "R149078",
            "text": "Administrative Skills and Degrees: The \u00e2\u0080\u009cBest Place\u00e2\u0080\u009d Debate Rages On abstract what should human service administration students learn? where is the best place for them to receive their education? nonprofit administrators, government agency managers, social work professors and public administration educators exhibit considerable agreement regarding what should be taught but little agreement regarding which degree is best. thus, the widespread debate concerning the best degree for non-profit administrators will rage on, with most practitioners preferring the mba and mpa degrees at the top level and academics believing that \u201ctheir\u201d degree is best. despite the disagreement, the msw degree is perceived well at the entry and middle levels of management.",
            "contribution_ids": [
                "R149080"
            ]
        },
        {
            "instance_id": "R152282xR149207",
            "comparison_id": "R152282",
            "paper_id": "R149207",
            "text": "Changing competencies for human resource management: examining e-government scorecard and Federal Human Capital Survey evidence \"as of this writing, effective human capital management is one of the key provisions of the president's management agenda (pma), which is committed to improving management processes on the us federal level to achieve results. while us federal organisations have made significant strides in improving human capital management, a connected component of the pma, e-government, lags behind for several large federal organisations. the connection between human capital management and e-government is a recent one. this manuscript seeks to investigate the connection between these two key components of the president's management agenda to answer the question: 'how are human resource management competencies evolving to reflect changing technology and knowledge management needs?' using data from the president's management scorecard (between 2002 and 2006), and two federal human capital surveys (2004, 2006), this manuscript gives special attention to the association between leading and lagging federal e-government agencies and it and knowledge competence.\"",
            "contribution_ids": [
                "R149209"
            ]
        },
        {
            "instance_id": "R152282xR149211",
            "comparison_id": "R152282",
            "paper_id": "R149211",
            "text": "Identifying government chief information officer education and training needs: the case of Saudi Arabia this paper identifies education and training needs of government chief information officers (gcio) in the kingdom of saudi arabia (ksa). it aims to provide foundation that would assist the ksa national e-government program (yesser) in identifying and prioritizing initiatives oriented towards building the capacity of gcios. based on the results of a survey conducted among gcios and highest it officials of 30 government agencies and the results of four semi-structured interviews, the paper identifies the knowledge areas and skills that should be developed by gcio educational programs, the stages of public sector ict in which gcios are most involved, the preferred delivery modes for the training, the preferred institutions for hosting gcios education and training programs, and the prerequisites for those who should participate in gcio educational programs. in addition to the policy recommendations for the ksa government, the main contribution of the paper is the validation of a methodology that can be applied by any government for designing capacity-building programs for their it leaders.",
            "contribution_ids": [
                "R149213"
            ]
        },
        {
            "instance_id": "R152282xR149221",
            "comparison_id": "R152282",
            "paper_id": "R149221",
            "text": "Conceptualizing Electronic Governance Education responding to the issues of complexity, relevance, cost and risk of electronic governance (egov), we witness a specialization of the roles responsible for egov development and operation, professionalizationof the personnel playing such roles, and utilization of the egov services and information to fulfill citizen needs. in order to build competencies required by such(managerial, professional, technician and user) roles, education becomes a key success factor, and a growing variety of egov learning opportunities emerges. however, lacking conceptual underpinnings for ego education, the discovery, analysis and integration of such opportunities is difficult. to address this need, the paper develops a theoretical construct for ego education, applies six measures to this construct: who-- learners, why -- roles, what -- competencies, how --programs, where -- schools, and when -- prerequisites, and validates it through a landscaping exercise focusing on egov university programs.",
            "contribution_ids": [
                "R149223"
            ]
        },
        {
            "instance_id": "R152282xR149726",
            "comparison_id": "R152282",
            "paper_id": "R149726",
            "text": "Competency Frameworks in The Belgian Governments: Causes, Construction and Contents the belgian federal government and the belgian flemish government have picked up competency management as a multifaceted tool to suit their own visions of organizational change rather than simply responding to a new management trend in the private sector. both governments have used it to foster both vertical and horizontal integration in their fragmented administrations, and to deal with problems of recruitment and retention of qualified personnel. the analysis presented here also reveals that the seemingly uniform use of \u2018competency speak\u2019 hides multiple dimensions that provide several solutions to different organizational problems. at the same time, the cases examined demonstrate how the new tools both serve and disconcert the diverse bureau-political interests of top civil servants, trade unions and human resource management units. in addition, we examine how the new tools break with at least two traditional features of the highly formal and rigid career systems and the relatively low status of officials in the belgian administrations.",
            "contribution_ids": [
                "R149728"
            ]
        },
        {
            "instance_id": "R152282xR149740",
            "comparison_id": "R152282",
            "paper_id": "R149740",
            "text": "Requisite competencies for government Chief Information Officer in Sri Lanka \"developed countries such as usa, australia and eu have technology savvy executives in certain government sector organizations performing the cio\u2019s role. these countries have managed to improve their government sector delivery of services to citizens leveraging on it/is. however, in sri lanka there is very low recognition for the role of a cio in government sector organizations and even in private sector organizations. \\ndifferent cios may be equipped with their own set of different skills. however, it is undoubtedly important for cios to acquire the particularly necessary set of skills, knowledge and experience that would enable them to act as catalysts in strategically and efficiently using it to improve their organization's service delivery. \\nconsidering the above facts, the authors did an empirical research study based on an extensive literature review. the research goals were to, (1) evaluate the set of competencies required of sri lankan cios and, (2) provide an understanding of the way the cio role should be formulated, such that it will have an impact on the strategy of sri lankan organizations. it is envisioned that the recommendations of this study will provide the necessary information to it directors and senior executives in government organizations to develop the competencies required to enable them to effectively function as cios.\"",
            "contribution_ids": [
                "R149742"
            ]
        },
        {
            "instance_id": "R152282xR149772",
            "comparison_id": "R152282",
            "paper_id": "R149772",
            "text": "The Skill Set of the Successful Collaborator in this article, the authors focus on members of the u.s. senior executive service who choose collaboration as a management strategy to increase performance and, in particular, their views of the skill set of a successful collaborator. based on the current literature on collaboration and networks, these executives might be expected to identify strategic thinking and strategic management as the most important skills. contrary to expectations, the federal executives most frequently mentioned individual attributes and interpersonal skills as essential for successful collaboration, followed by group process skills, strategic leadership skills, and substantive/technical expertise. the article provides empirical substantiation of the previous literature, with one major difference: the strong reporting of the importance of individual attributes by federal executives (much more than previously reported by other scholars in the field). strategic leadership skills, strategic management skills, and technical skills matter, but they are not the most important factors behind successful collaborations, according to federal executives.",
            "contribution_ids": [
                "R149774"
            ]
        },
        {
            "instance_id": "R154289xR147129",
            "comparison_id": "R154289",
            "paper_id": "R147129",
            "text": "A Hierarchical Attention Retrieval Model for Healthcare Question Answering the growth of the web in recent years has resulted in the development of various online platforms that provide healthcare information services. these platforms contain an enormous amount of information, which could be beneficial for a large number of people. however, navigating through such knowledgebases to answer specific queries of healthcare consumers is a challenging task. a majority of such queries might be non-factoid in nature, and hence, traditional keyword-based retrieval models do not work well for such cases. furthermore, in many scenarios, it might be desirable to get a short answer that sufficiently answers the query, instead of a long document with only a small amount of useful information. in this paper, we propose a neural network model for ranking documents for question answering in the healthcare domain. the proposed model uses a deep attention mechanism at word, sentence, and document levels, for efficient retrieval for both factoid and non-factoid queries, on documents of varied lengths. specifically, the word-level cross-attention allows the model to identify words that might be most relevant for a query, and the hierarchical attention at sentence and document levels allows it to do effective retrieval on both long and short documents. we also construct a new large-scale healthcare question-answering dataset, which we use to evaluate our model. experimental evaluation results against several state-of-the-art baselines show that our model outperforms the existing retrieval techniques.",
            "contribution_ids": [
                "R147131"
            ]
        },
        {
            "instance_id": "R154289xR147992",
            "comparison_id": "R154289",
            "paper_id": "R147992",
            "text": "Large-scale semantic parsing via schema matching and lexicon extension supervised training procedures for semantic parsers produce high-quality semantic parsers, but they have difficulty scaling to large databases because of the sheer number of logical constants for which they must see labeled training data. we present a technique for developing semantic parsers for large databases based on a reduction to standard supervised training algorithms, schema matching, and pattern learning. leveraging techniques from each of these areas, we develop a semantic parser for freebase that is capable of parsing questions with an f1 that improves by 0.42 over a purely-supervised learning algorithm.",
            "contribution_ids": [
                "R147994"
            ]
        },
        {
            "instance_id": "R155101xR154337",
            "comparison_id": "R155101",
            "paper_id": "R154337",
            "text": "High-Repetition-Rate Grazing-Incidence Pumped X-Ray Laser Operating at 18.9\u00c2\u00a0nm we have demonstrated a 10 hz ni-like mo x-ray laser operating at 18.9 nm with 150 mj total pump energy by employing a novel pumping scheme. the grazing-incidence scheme is described, where a picosecond pulse is incident at a grazing angle to a mo plasma column produced by a slab target irradiated by a 200 ps laser pulse. this scheme uses refraction of the short pulse at a predetermined electron density to increase absorption to pump a specific gain region. the higher coupling efficiency inherent to this scheme allows a reduction in the pump energy where 70 mj long pulse energy and 80 mj short pulse energy are sufficient to produce lasing at a 10 hz repetition rate. under these conditions and by optimizing the delay between the pulses, we achieve strong amplification and close to saturation for 4 mm long targets.",
            "contribution_ids": [
                "R154338"
            ]
        },
        {
            "instance_id": "R155101xR154961",
            "comparison_id": "R155101",
            "paper_id": "R154961",
            "text": "High-average-power, 100-Hz-repetition-rate, tabletop soft-x-ray lasers at sub-15-nm wavelengths efficient excitation of dense plasma columns at 100-hz repetition rate using a tailored pump pulse profile produced a tabletop soft-x-ray laser average power of 0.1 mw at = 13.9 nm and 20 w at = 11.9 nm from transitions of ni-like ag and ni-like sn, respectively. lasing on several other transitions with wavelengths between 10.9 and 14.7 nm was also obtained using 0.9-j pump pulses of 5-ps duration from a compact diode-pumped chirped pulse amplification yb:yag laser. hydrodynamic and atomic plasma simulations show that the pump pulse profile, consisting of a nanosecond ramp followed by two peaks of picosecond duration, creates a plasma with an increased density of ni-like ions at the time of peak temperature that results in a larger gain coefficient over a temporally and spatially enlarged space leading to a threefold increase in the soft-x-ray laser output pulse energy. the high average power of these compact soft-x-ray lasers will enable applications requiring high photon flux. these results open the path to milliwatt-average-power tabletop soft-x-ray lasers.",
            "contribution_ids": [
                "R154962"
            ]
        },
        {
            "instance_id": "R155101xR155047",
            "comparison_id": "R155101",
            "paper_id": "R155047",
            "text": "Compact gain-saturated x-ray lasers down to 685\u00e2\u0080\u0089\u00e2\u0080\u0089nm and amplification down to 585\u00e2\u0080\u0089\u00e2\u0080\u0089nm plasma-based x-ray lasers allow single-shot nano-scale imaging and other experiments requiring a large number of photons per pulse to be conducted in compact facilities. however, compact repetitively fired gain-saturated x-ray lasers have been limited to wavelengths above \u03bb=8.85\\u2009\\u2009nm. here we extend their range to \u03bb=6.85\\u2009\\u2009nm by transient traveling wave excitation of ni-like gd ions in a plasma created with an optimized pre-pulse followed by rapid heating with an intense sub-picosecond pump pulse. isoelectronic scaling also produced strong lasing at 6.67\\xa0nm and 6.11\\xa0nm in ni-like tb and amplification at 6.41\\xa0nm and 5.85\\xa0nm in ni-like dy. this scaling to shorter wavelengths was obtained by progressively increasing the pump pulse grazing incidence angle to access increased plasma densities. we experimentally demonstrate that the optimum grazing incidence angle increases linearly with atomic number from 17\\xa0deg for z=42 (mo) to 43\\xa0deg for z=66 (dy). the results will enable applications of sub-7\\xa0nm lasers at compact facilities.",
            "contribution_ids": [
                "R155050"
            ]
        },
        {
            "instance_id": "R155621xR151517",
            "comparison_id": "R155621",
            "paper_id": "R151517",
            "text": "Cyclodextrins in eye drop formulations: enhanced topical delivery of corticosteroids to the eye: Acta\n Ophthalmologica\n Scandinavica\n 2002 \"cyclodextrins are cylindrical oligosaccharides with a lipophilic central cavity and hydrophilic outer surface. they can form water-soluble complexes with lipophilic drugs, which 'hide' in the cavity. cyclodextrins can be used to form aqueous eye drop solutions with lipophilic drugs, such as steroids and some carbonic anhydrase inhibitors. the cyclodextrins increase the water solubility of the drug, enhance drug absorption into the eye, improve aqueous stability and reduce local irritation. cyclodextrins are useful excipients in eye drop formulations of various drugs, including steroids of any kind, carbonic anhydrase inhibitors, pilocarpine, cyclosporins, etc. their use in ophthalmology has already begun and is likely to expand the selection of drugs available as eye drops. in this paper we review the properties of cyclodextrins and their application in eye drop formulations, of which their use in the formulation of dexamethasone eye drops is an example. cyclodextrins have been used to formulate eye drops containing corticosteroids, such as dexamethasone, with levels of concentration and ocular absorption which, according to human and animal studies, are many times those seen with presently available formulations. cyclodextrin-based dexamethasone eye drops are well tolerated in the eye and seem to provide a higher degree of bioavailability and clinical efficiency than the steroid eye drop formulations presently available. such formulations offer the possibility of once per day application of corticosteroid eye drops after eye surgery, and more intensive topical steroid treatment in severe inflammation. while cyclodextrins have been known for more than a century, their use in ophthalmology is just starting. cyclodextrins are useful excipients in eye drop formulations for a variety of lipophilic drugs. they will facilitate eye drop formulations for drugs that otherwise might not be available for topical use, while improving absorption and stability and decreasing local irritation.\"",
            "contribution_ids": [
                "R151519"
            ]
        },
        {
            "instance_id": "R155621xR151616",
            "comparison_id": "R155621",
            "paper_id": "R151616",
            "text": "Influence of Hydroxypropyl \u00ce\u00b2-Cyclodextrin on the Corneal Permeation of Pilocarpine abstract the influence of hydroxypropyl \u03b2-cyclodextrin (hp\u03b2cd) on the corneal permeation of pilocarpine nitrate was investigated by an in vitro permeability study using isolated rabbit cornea. pupillary-response pattern to pilocarpine nitrate with and without hp\u03b2cd was examined in rabbit eye. corneal permeation of pilocarpine nitrate was found to be four times higher after adding hp\u03b2cd into the formulation. the reduction of pupil diameter (miosis) by pilocarpine nitrate was significantly increased as a result of hp\u03b2cd addition into the simple aqueous solution of the active substance. the highest miotic response was obtained with the formulation prepared in a vehicle of carbopol\u00ae 940. it is suggested that ocular bioavailability of pilocarpine nitrate could be improved by the addition of hp\u03b2cd.",
            "contribution_ids": [
                "R151618"
            ]
        },
        {
            "instance_id": "R155621xR151628",
            "comparison_id": "R155621",
            "paper_id": "R151628",
            "text": "Improvement of Nasal Bioavailability of Luteinizing Hormone-Releasing Hormone Agonist, Buserelin, by Cyclodextrin Derivatives in Rats the effects of chemically modified cyclodextrins on the nasal absorption of buserelin, an agonist of luteinizing hormone-releasing hormone, were investigated in anesthetized rats. of the cyclodextrins tested, dimethyl-beta-cyclodextrin (dm-beta-cyd) was the most effective in improving the rate and extent of the nasal bioavailability of buserelin. fluorescence spectroscopic studies indicated that the cyclodextrins formed inclusion complexes with buserelin, which may reduce the diffusibility of buserelin across the nasal epithelium and may participate in the protection of the peptide against enzymatic degradation in the nasal mucosa. additionally, the cyclodextrins increased the permeability of the nasal mucosa, which was the primary determinant based on the multiple regression analysis of the nasal absorption enhancement of buserelin. scanning electron microscopic observations revealed that dm-beta-cyd induced no remarkable changes in the surface morphology of the nasal mucosa at a minimal concentration necessary to achieve substantial absorption enhancement. the present results suggest that dm-beta-cyd could improve the nasal bioavailability of buserelin and is well-tolerated by the nasal mucosa of the rat.",
            "contribution_ids": [
                "R151630"
            ]
        },
        {
            "instance_id": "R155621xR155590",
            "comparison_id": "R155621",
            "paper_id": "R155590",
            "text": "The Effect of Cyclodextrins on the In Vitro and In Vivo Properties of Insulin-Loaded Poly (D,L-Lactic-Co-Glycolic Acid) Microspheres: EFFECT OF CYCLODEXTRINS ON MICROSPHERES in this work we describe the development and characterization of a new formulation of insulin (ins). insulin was complexed with cyclodextrins (cd) in order to improve its solubility and stability being available as a dry powder, after encapsulation into poly (d,l-lactic-co-glycolic acid) (plga) microspheres. the complex ins : cd was encapsulated into microspheres in order to obtain particles with an average diameter between 2 and 6 microm. this system was able to induce significant reduction of the plasma glucose level in two rodent models, normal mice and diabetic rats, after intratracheal administration.",
            "contribution_ids": [
                "R155592"
            ]
        },
        {
            "instance_id": "R157326xR156333",
            "comparison_id": "R157326",
            "paper_id": "R156333",
            "text": "Demonstration of a Soft X-Ray Amplifier we report observations of amplified spontaneous emission at soft x-ray wavelengths. an optical laser ionized thin foils of selenium to produce a population inversion of the $2{p}^{5}3p$ and $2{p}^{5}3s$ levels of the neonlike ion. using three time-resolved, spectroscopic measurements we demonstrated gain-length products up to 6.5 and gain coefficients of 5.5\\\\ifmmode\\\\pm\\\\else\\\\textpm\\\\fi{}1.0 ${\\\\mathrm{cm}}^{\\\\ensuremath{-}1}$ for the $j=2 \\\\mathrm{to} 1$ lines at 206.3 and 209.6 \\\\aa{}. we also observed considerable amplification for the same transitions in yttrium at 155.0 and 157.1 \\\\aa{}.",
            "contribution_ids": [
                "R156334"
            ]
        },
        {
            "instance_id": "R157326xR156663",
            "comparison_id": "R157326",
            "paper_id": "R156663",
            "text": "Short wavelength x\u00e2\u0080\u0090ray laser research at the Lawrence Livermore National Laboratory laboratory x\u2010ray lasers are currently being studied by researchers worldwide. this paper reviews some of the recent work carried out at lawrence livermore national laboratory. laser action has been demonstrated at wavelengths as short as 35.6 a while saturation of the small signal gain has been observed with longer wavelength schemes. some of the most successful schemes to date have been collisionally pumped x\u2010ray lasers that use the thermal electron distribution within a laser\u2010produced plasma to excite electrons from closed shells in neon\u2010 and nickel\u2010like ions to metastable levels in the next shell. attempts to quantify and improve the longitudinal and transverse coherence of collisionally pumped x\u2010ray lasers are motivated by the desire to produce sources for specific applications. toward this goal there is a large effort underway to enhance the power output of the ni\u2010like ta x\u2010ray laser at 44.83 a as a source for x\u2010ray imaging of live cells. improving the efficiency of x\u2010ray lasers in order to produce s...",
            "contribution_ids": [
                "R156665"
            ]
        },
        {
            "instance_id": "R157326xR156908",
            "comparison_id": "R157326",
            "paper_id": "R156908",
            "text": "Saturated and Short Pulse Duration X-Ray Lasers the basis of a model of the relationship between gain and output laser intensity is reviewed and the measurement of the duration of x\u2010ray lasing with a streak camera with 700 fs temporal resolution is described. combined with a temporal smearing due to the spectrometer employed, we have measured x\u2010ray laser pulse durations for ni\u2010like silver at 13.9 nm and ne\u2010like nickel at 23.1 nm with a total time resolution of 1.1 ps. an extension of the model is shown to consistently relate the measured x\u2010ray laser pulse duration to estimates of the gain duration obtained by temporally resolving resonance line emission from states near in energy to the upper lasing level.",
            "contribution_ids": [
                "R156910"
            ]
        },
        {
            "instance_id": "R160742xR160723",
            "comparison_id": "R160742",
            "paper_id": "R160723",
            "text": "Ocean carbon cycling in the Indian Ocean: 1. Spatiotemporal variability of inorganic carbon and air-sea CO2gas exchange: INDIAN OCEAN CARBON CYCLE, 1 the spatiotemporal variability of upper ocean inorganic carbon parameters and air\u2010sea co2 exchange in the indian ocean was examined using inorganic carbon data collected as part of the world ocean circulation experiment (woce) cruises in 1995. multiple linear regression methods were used to interpolate and extrapolate the temporally and geographically limited inorganic carbon data set to the entire indian ocean basin using other climatological hydrographic and biogeochemical data. the spatiotemporal distributions of total carbon dioxide (tco2), alkalinity, and seawater pco2 were evaluated for the indian ocean and regions of interest including the arabian sea, bay of bengal, and 10\u00b0n\u201335\u00b0s zones. the indian ocean was a net source of co2 to the atmosphere, and a net sea\u2010to\u2010air co2 flux of +237 \u00b1 132 tg c yr\u22121 (+0.24 pg c yr\u22121) was estimated. regionally, the arabian sea, bay of bengal, and 10\u00b0n\u201310\u00b0s zones were perennial sources of co2 to the atmosphere. in the 10\u00b0s\u201335\u00b0s zone, the co2 sink or source status of the surface ocean shifts seasonally, although the region is a net oceanic sink of atmospheric co2.",
            "contribution_ids": [
                "R160724"
            ]
        },
        {
            "instance_id": "R160742xR160733",
            "comparison_id": "R160742",
            "paper_id": "R160733",
            "text": "Environmental controls on the seasonal carbon dioxide fluxes in the northeastern Indian Ocean total carbon dioxide (tco 2) and computations of partial pressure of carbon dioxide (pco 2) had been examined in northerneastern region of indian ocean. it exhibit seasonal and spatial variability. north-south gradients in the pco 2 levels were closely related to gradients in salinity caused by fresh water discharge received from rivers. eddies observed in this region helped to elevate the nutrients availability and the biological controls by increasing the productivity. these phenomena elevated the carbon dioxide draw down during the fair seasons. seasonal fluxes estimated from local wind speed and air-sea carbon dioxide difference indicate that during southwest monsoon, the northeastern indian ocean acts as a strong sink of carbon dioxide (-20.04 mmol m \u20132 d -1 ). also during fall intermonsoon the area acts as a weak sink of carbon dioxide (-4.69 mmol m \u20132 d -1 ). during winter monsoon, this region behaves as a weak carbon dioxide source with an average sea to air flux of 4.77 mmol m -2 d -1 . in the northern region, salinity levels in the surface level are high during winter compared to the other two seasons. northeastern indian ocean shows significant intraseasonal variability in carbon dioxide fluxes that are mediated by eddies which provide carbon dioxide and nutrients from the subsurface waters to the mixed layer.",
            "contribution_ids": [
                "R160734"
            ]
        },
        {
            "instance_id": "R160847xR160810",
            "comparison_id": "R160847",
            "paper_id": "R160810",
            "text": "Influence of Process and Formulation Parameters on Dissolution and Stability Characteristics of Kollidon\u00c2\u00ae VA 64 Hot-Melt Extrudates the objective of the present study was to investigate the effects of processing variables and formulation factors on the characteristics of hot-melt extrudates containing a copolymer (kollidon\u00ae va 64). nifedipine was used as a model drug in all of the extrudates. differential scanning calorimetry (dsc) was utilized on the physical mixtures and melts of varying drug\u2013polymer concentrations to study their miscibility. the drug\u2013polymer binary mixtures were studied for powder flow, drug release, and physical and chemical stabilities. the effects of moisture absorption on the content uniformity of the extrudates were also studied. processing the materials at lower barrel temperatures (115\u2013135\u00b0c) and higher screw speeds (50\u2013100\\xa0rpm) exhibited higher post-processing drug content (~99\u2013100%). dsc and x-ray diffraction studies confirmed that melt extrusion of drug\u2013polymer mixtures led to the formation of solid dispersions. interestingly, the extrusion process also enhanced the powder flow characteristics, which occurred irrespective of the drug load (up to 40% w/w). moreover, the content uniformity of the extrudates, unlike the physical mixtures, was not sensitive to the amount of moisture absorbed. the extrusion conditions did not influence drug release from the extrudates; however, release was greatly affected by the drug loading. additionally, the drug release from the physical mixture of nifedipine\u2013kollidon\u00ae va 64 was significantly different when compared to the corresponding extrudates (f2\\u2009=\\u200936.70). the extrudates exhibited both physical and chemical stabilities throughout the period of study. overall, hot-melt extrusion technology in combination with kollidon\u00ae va 64 produced extrudates capable of higher drug loading, with enhanced flow characteristics, and excellent stability.",
            "contribution_ids": [
                "R160812"
            ]
        },
        {
            "instance_id": "R160847xR160844",
            "comparison_id": "R160847",
            "paper_id": "R160844",
            "text": "Solid-state characterization of Felodipine\u00e2\u0080\u0093Soluplus amorphous solid dispersions abstract the aim of the current study is to develop amorphous solid dispersion (sd) via hot melt extrusion technology to improve the solubility of a water-insoluble compound, felodipine (fel). the solubility was dramatically increased by preparation of amorphous sds via hot-melt extrusion with an amphiphilic polymer, soluplus\u00ae (sol). fel was found to be miscible with sol by calculating the solubility parameters. the solubility of fel within sol was determined to be in the range of 6.2\u20139.9% (w/w). various techniques were applied to characterize the solid-state properties of the amorphous sds. these included fourier transform infrared spectrometry spectroscopy and raman spectroscopy to detect the formation of hydrogen bonding between the drug and the polymer. scanning electron microscopy was performed to study the morphology of the sds. among all the hot-melt extrudates, fel was found to be molecularly dispersed within the polymer matrix for the extrudates containing 10% drug, while few small crystals were detected in the 30 and 50% extrudates. in conclusion, solubility of fel was enhanced while a homogeneous sd was achieved for 10% drug loading.",
            "contribution_ids": [
                "R160846"
            ]
        },
        {
            "instance_id": "R161728xR160263",
            "comparison_id": "R161728",
            "paper_id": "R160263",
            "text": "Evaluation of Urban-Scale Building Energy-Use Models and Tools\u00e2\u0080\u0094Application for the City of Fribourg, Switzerland building energy-use models and tools can simulate and represent the distribution of energy consumption of buildings located in an urban area. the aim of these models is to simulate the energy performance of buildings at multiple temporal and spatial scales, taking into account both the building shape and the surrounding urban context. this paper investigates existing models by simulating the hourly space heating consumption of residential buildings in an urban environment. existing bottom-up urban-energy models were applied to the city of fribourg in order to evaluate the accuracy and flexibility of energy simulations. two common energy-use models\u2014a machine learning model and a gis-based engineering model\u2014were compared and evaluated against anonymized monitoring data. the study shows that the simulations were quite precise with an annual mean absolute percentage error of 12.8 and 19.3% for the machine learning and the gis-based engineering model, respectively, on residential buildings built in different periods of construction. moreover, a sensitivity analysis using the morris method was carried out on the gis-based engineering model in order to assess the impact of input variables on space heating consumption and to identify possible optimization opportunities of the existing model.",
            "contribution_ids": [
                "R160269"
            ]
        },
        {
            "instance_id": "R161728xR160298",
            "comparison_id": "R161728",
            "paper_id": "R160298",
            "text": "A Digital Twin of Bridges for Structural Health Monitoring \"\u00a9 international workshop on structural health monitoring. all rights reserved. bridges are critical infrastructure systems connecting different regions and providing widespread social and economic benefits. it is therefore essential that they are designed, constructed and maintained properly to adapt to changing conditions of use and climate-driven events. with the rapid development in capability of collecting bridge monitoring data, a data challenge emerges due to insufficient capability in managing, processing and interpreting large monitoring datasets to extract useful information which is of practical value to the industry. one emerging area of research which focuses on addressing this challenge is the creation of 'digital twins' for bridges. a digital twin serves as a virtual representation of the physical infrastructure (i.e. the physical twin), which can be updated in near real time as new data is collected, provide feedback into the physical twin and perform 'what-if scenarios for assessing asset risks and predicting asset performance. this paper presents and broadly discusses two years of exploratory study towards creating a digital twin of bridges for structural health monitoring purposes. in particular, it has involved an interdisciplinary collaboration between civil engineers at the cambridge centre for smart infrastructure and construction (csic) and statisticians at the alan turing institute (ati), using two monitored railway bridges in staffordshire, uk as a case study. four areas of research were investigated: (i) real-time data management using bim, (ii) physics-based approaches, (iii) data-driven approaches, and (iv) data-centric engineering approaches (i.e. synthesis of physics-based and data-driven approaches). a framework for creating a digital twin of bridges, particularly for structural health monitoring purposes, is proposed and briefly discussed.\"",
            "contribution_ids": [
                "R160300"
            ]
        },
        {
            "instance_id": "R161728xR160306",
            "comparison_id": "R161728",
            "paper_id": "R160306",
            "text": "Mobile Mapping, Machine Learning and Digital Twin for Road Infrastructure Monitoring and Maintenance: Case Study of Mohammed VI Bridge in Morocco the concepts of digital twin has been recently introduced, it refers to functional connections between a complex physical system and its high-fidelity digital replica. digital twin process workflow is proposed in case of mohammed vi bridge modeling in morocco. the current maintenance of a road infrastructure is based on a manual inspection and a system based on traditional tools. aging infrastructures require a new approach to maintenance in terms of inspection, bridge maintenance system, simulation and systematic evaluation. this system now exists and is called the digital twin. digital twin can be thought of as a virtual prototype in service that changes dynamically in near real time as its physical twin changes. an urban infrastructure digital twin is a virtual instance of his physical twin that is continuously updated with multisource, multisensor and multitemporal data that can be used for monitoring, simulating and forecasting any potential problem that may appear in the structure and proposing planning for repair and maintenance of health status throughout the life cycle of this infrastructure. this work presents a general vision and a justification for integrating dt technology with geospatial data. the paper examines the benefits of integrating 3d gis data acquired by automated mobile mapping (mms) workflows for modeling the reality of a major bridge infrastructure in morocco. this allowed to study the future performance of this bridge structure on virtual twin structures under different environmental conditions. cloud point data are acquired by a mobile mapping system on mohammed vi bridge and converted in bim model by a scan to bim process and is integrated in a gis and bim virtual environment and shows the efficiency of volumetric auscultation in terms of surface flatness and distortion inspection. this project provides a new bridge maintenance system using the concept of a digital twin. this digital model is a platform that allows to collect, organize and share the maintenance history of this important road infrastructure in morocco.",
            "contribution_ids": [
                "R160308"
            ]
        },
        {
            "instance_id": "R161728xR160363",
            "comparison_id": "R161728",
            "paper_id": "R160363",
            "text": "Beyond the State of the Art of Electric Vehicles: A Fact-Based Paper of the Current and Prospective Electric Vehicle Technologies today, there are many recent developments that focus on improving the electric vehicles and their components, particularly regarding advances in batteries, energy management systems, autonomous features and charging infrastructure. this plays an important role in developing next electric vehicle generations, and encourages more efficient and sustainable eco-system. this paper not only provides insights in the latest knowledge and developments of electric vehicles (evs), but also the new promising and novel ev technologies based on scientific facts and figures\u2014which could be from a technological point of view feasible by 2030. in this paper, potential design and modelling tools, such as digital twin with connected internet-of-things (iot), are addressed. furthermore, the potential technological challenges and research gaps in all ev aspects from hard-core battery material sciences, power electronics and powertrain engineering up to environmental assessments and market considerations are addressed. the paper is based on the knowledge of the 140+ fte counting multidisciplinary research centre mobi-vub, that has a 40-year track record in the field of electric vehicles and e-mobility.",
            "contribution_ids": [
                "R160373"
            ]
        },
        {
            "instance_id": "R161728xR159473",
            "comparison_id": "R161728",
            "paper_id": "R159473",
            "text": "Participatory Sensing and Digital Twin City: Updating Virtual City Models for Enhanced Risk-Informed Decision-Making abstractthe benefits of a digital twin city have been assessed based on real-time data collected from preinstalled internet of things (iot) sensors (e.g.,\\xa0traffic, energy use, air pollution, water ...",
            "contribution_ids": [
                "R159477",
                "R160389"
            ]
        },
        {
            "instance_id": "R161728xR159465",
            "comparison_id": "R161728",
            "paper_id": "R159465",
            "text": "A Socio-Technical Perspective on Urban Analytics: The Case of City-Scale Digital Twins abstract this paper demonstrates that a shift from a purely technical to a more socio-technical perspective has significant implications for the conceptualization, design, and implementation of smart city technologies. such implications are discussed and illustrated through the case of an emerging urban analytics tool, the city-scale digital twin. based on interdisciplinary insights and a participatory knowledge co-production and tool co-development process, including both researchers and prospective users, we conclude that in order to move beyond a mere \u201chype technology,\u201d city-scale digital twins must reflect the specifics of the urban and socio-political context.",
            "contribution_ids": [
                "R159469",
                "R160399"
            ]
        },
        {
            "instance_id": "R161728xR160402",
            "comparison_id": "R161728",
            "paper_id": "R160402",
            "text": "BIM and IoT: A Synopsis from GIS Perspective abstract. internet-of-things (iot) focuses on enabling communication between all devices, things that are existent in real life or that are virtual. building information models (bims) and building information modelling is a hype that has been the buzzword of the construction industry for last 15 years. bims emerged as a result of a push by the software companies, to tackle the problems of inefficient information exchange between different software and to enable true interoperability. in bim approach most up-to-date an accurate models of a building are stored in shared central databases during the design and the construction of a project and at post-construction stages. gis based city monitoring / city management applications require the fusion of information acquired from multiple resources, bims, city models and sensors. this paper focuses on providing a method for facilitating the gis based fusion of information residing in digital building \u201cmodels\u201d and information acquired from the city objects i.e. \u201cthings\u201d. once this information fusion is accomplished, many fields ranging from emergency response, urban surveillance, urban monitoring to smart buildings will have potential benefits.\\n",
            "contribution_ids": [
                "R160404"
            ]
        },
        {
            "instance_id": "R161728xR159481",
            "comparison_id": "R161728",
            "paper_id": "R159481",
            "text": "The Digital Twin of the City of Zurich for Urban Planning abstract population growth will confront the city of zurich with a variety of challenges in the coming years, as the increase in the number of inhabitants and jobs will lead to densification and competing land uses. the tasks for the city administration have become more complex, whereas tools and methods are often based on traditional, static approaches while involving a limited number of citizens and stakeholders in relevant decisions. the digital transformation of more and more\\xa0pieces of the planning and decision-making process will make both increasingly more illustrative, easier to understand and more comprehensible. an important data basis for these processes is the digital twin of the city of zurich. 3d spatial data and their models transform themes of the city, such as buildings, bridges, vegetation, etc., to the digital world, are being updated when required, and create advantages in digital space. these benefits need to be highlighted and published. an important step in public awareness is the release of 3d spatial data under open government data. this allows the development of applications, the promotion of understanding, and the simplification of the creation of different collaborative platforms. by\\xa0visualization and analysis of digital prototypes and the demonstration of interactions with the built environment, scenarios can be digitally developed and discussed in decision-making bodies. questions about the urban climate can be simulated with the help of the digital twin and results can be linked to the existing 3d spatial data. thus, the 3d spatial data set, the models and their descriptions through\\xa0metadata become the reference and must be updated according to the requirements. depending on requirements and questions, further 3d spatial data must be added. the description of the 3d spatial data and their models or the lifecycle management of the digital twin must be carried out with great care. only in this way, decision processes can be supported in a comprehensible way.",
            "contribution_ids": [
                "R159483",
                "R160407"
            ]
        },
        {
            "instance_id": "R161729xR160217",
            "comparison_id": "R161729",
            "paper_id": "R160217",
            "text": "Methodological Framework for Digital Transition and Performance Assessment of Smart Cities the ultimate goal of smart cities is to improve citizens\u2019 quality of life in a scenario where technological solutions challenge urban governance. however, the knowledge and framework for data use for smart cities remain relatively unknown. the actual translation of city problems into diverse actions requires specific methodologies to guide digital transitions of cities and to assess to what extent the smart cities\u2019 initiatives pursue sustainable development goals. this paper proposes a methodological framework for digital modelling of cities allowing assessment of their performance and supporting decision making. the city model adopts the concept of digital twin as a powerful tool for discussion between stakeholders, as well as citizens to find the smartest solutions and get valuable insight after their deployment. the methodological framework is presented as a set of digital twin concept, stages of digital twinning and implementation strategy. furthermore, the most common city information models, suitable for implementation of digital twins are summarized.",
            "contribution_ids": [
                "R160219"
            ]
        },
        {
            "instance_id": "R161729xR160253",
            "comparison_id": "R161729",
            "paper_id": "R160253",
            "text": "The Potential of Digital Twin Model Integrated With Artificial Intelligence Systems the paper explores the use of a \u201cdigital twin model\u201d applied to the case study of a residential district, and organized as a three-dimensional data system able to participate to the intelligent optimization and automation of the energy management and efficiency of the building system. the case study focuses on the area called rinascimento iii in rome, consisting of 16 eight-floor building hosting 216 apartment units with an overall percentage of self-renewable energy produced by the building complex equal to 70%. this already quite high percentage means that the building complex can be defined as a near zero energy building (nzeb), i.e. a building that has a very high energy performance, and the nearly-zero or very low amount of energy required should be covered to a very significant extent by energy from renewable sources, including energy from renewable source produced on-site or nearby.",
            "contribution_ids": [
                "R160255"
            ]
        },
        {
            "instance_id": "R162329xR162021",
            "comparison_id": "R162329",
            "paper_id": "R162021",
            "text": "Sub-38 nm resolution tabletop microscopy with 13 nm wavelength laser light we have acquired images with a spatial resolution better than 38 nm by using a tabletop microscope that combines 13 nm wavelength light from a high-brightness tabletop laser and fresnel zone plate optics. these results open a gateway to the development of compact and widely available extreme-ultraviolet imaging tools capable of inspecting samples in a variety of environments with a 15-20 nm spatial resolution and a picosecond time resolution.",
            "contribution_ids": [
                "R162023"
            ]
        },
        {
            "instance_id": "R162329xR162104",
            "comparison_id": "R162329",
            "paper_id": "R162104",
            "text": "Single-shot soft-x-ray digital holographic microscopy with an adjustable field of view and magnification single-shot digital holographic microscopy with an adjustable field of view and magnification was demonstrated by using a tabletop 32.8 nm soft-x-ray laser. the holographic images were reconstructed with a two-dimensional fast-fourier-transform algorithm, and a new configuration of imaging was developed to overcome the pixel-size limit of the recording device without reducing the effective na. the image of an atomic-force-microscope cantilever was reconstructed with a lateral resolution of 480 nm, and the phase contrast image of a 20 nm carbon mesh foil demonstrated that profiles of sample thickness can be reconstructed with few-nanometers uncertainty. the ultrashort x-ray pulse duration combined with single-shot capability offers great advantage for flash imaging of delicate samples.",
            "contribution_ids": [
                "R162106"
            ]
        },
        {
            "instance_id": "R162329xR162244",
            "comparison_id": "R162329",
            "paper_id": "R162244",
            "text": "Single-shot soft x-ray laser linewidth measurement using a grating interferometer the linewidth of a 14.7 nm wavelength ni-like pd soft x-ray laser was measured in a single shot using a soft x-ray diffraction grating interferometer. the instrument uses the time delay introduced by the gratings across the beam to measure the temporal coherence. the spectral linewidth of the 4d1s0-4p1p1 ni-like pd lasing line was measured to be \u03b4\u03bb/\u03bb=3\u00d710(-5) from the fourier transform of the fringe visibility. this single shot linewidth measurement technique provides a rapid and accurate way to determine the temporal coherence of soft x-ray lasers that can contribute to the development of femtosecond plasma-based soft x-ray lasers.",
            "contribution_ids": [
                "R162245"
            ]
        },
        {
            "instance_id": "R162329xR162271",
            "comparison_id": "R162329",
            "paper_id": "R162271",
            "text": "Tabletop single-shot extreme ultraviolet Fourier transform holography of an extended object we demonstrate single and multi-shot fourier transform holography with the use of a tabletop extreme ultraviolet laser. the reference wave was produced by a fresnel zone plate with a central opening that allowed the incident beam to illuminate the sample directly. the high reference wave intensity allows for larger objects to be imaged compared to mask-based lensless fourier transform holography techniques. we obtain a spatial resolution of 169 nm from a single laser pulse and a resolution of 128 nm from an accumulation of 20 laser pulses for an object ~11x11\u03bcm(2) in size. this experiment utilized a tabletop extreme ultraviolet laser that produces a highly coherent ~1.2 ns laser pulse at 46.9 nm wavelength.",
            "contribution_ids": [
                "R162273"
            ]
        },
        {
            "instance_id": "R162574xR162457",
            "comparison_id": "R162574",
            "paper_id": "R162457",
            "text": "Overview of the CHEMDNER patents task a considerable effort has been made to extract biological and chemical entities, as well as their relationships, from the scientific literature, either manually through traditional literature curation or by using information extraction and text mining technologies. medicinal chemistry patents contain a wealth of information, for instance to uncover potential biomarkers that might play a role in cancer treatment and prognosis. however, current biomedical annotation databases do not cover such information, partly due to limitations of publicly available biomedical patent mining software. as part of the biocreative v chemdner patents track, we present the results of the first named entity recognition (ner) assignment carried out to detect mentions of chemical compounds and genes/proteins in running patent text. more specifically, this task aimed to evaluate the performance of automatic name recognition strategies capable of isolating chemical names and gene and gene product mentions from surrounding text within patent titles and abstracts. a total of 22 unique teams submitted results for at least one of the three chemdner subtasks. the first subtask, called the cemp (chemical entity mention in patents) task, focused on the detection of chemical named entity mentions in patents, requesting teams to return the start and end indices corresponding to all the chemical entities found in a given record. a total of 21 teams submitted 93 runs, for this subtask. the top performing team reached an f-measure of 0.89 with a precision of 0.87 and a recall of 0.91. the cpd (chemical passage detection) task required the classification of patent titles and abstracts whether they do or do not contain chemical compound mentions. nine teams returned predictions for this task (40 runs). the top run in terms of matthew\u2019s correlation coefficient (mcc) had a score of 0.88, the highest sensitivity ? corresponding author",
            "contribution_ids": [
                "R162459",
                "R171956",
                "R171968",
                "R171966"
            ]
        },
        {
            "instance_id": "R163742xR163725",
            "comparison_id": "R163742",
            "paper_id": "R163725",
            "text": "RDoC Task at BioNLP-OST 2019 bionlp open shared tasks (bionlp-ost) is an international competition organized to facilitate development and sharing of computational tasks of biomedical text mining and solutions to them. for bionlp-ost 2019, we introduced a new mental health informatics task called \u201crdoc task\u201d, which is composed of two subtasks: information retrieval and sentence extraction through national institutes of mental health\u2019s research domain criteria framework. five and four teams around the world participated in the two tasks, respectively. according to the performance on the two tasks, we observe that there is room for improvement for text mining on brain research and mental illness.",
            "contribution_ids": [
                "R163727"
            ]
        },
        {
            "instance_id": "R164231xR163865",
            "comparison_id": "R164231",
            "paper_id": "R163865",
            "text": "Part-of-Speech Annotation of Biology Research Abstracts a part-of-speech (pos) tagged corpus was built on research abstracts in biomedical domain with the penn treebank scheme. as consistent annotation was difficult without domain-specific knowledge we made use of the existing term annotation of the genia corpus. a list of frequent terms annotated in the genia corpus was compiled and the pos of each constituent of those terms were determined with assistance from domain specialists. the pos of the terms in the list are pre-assigned, then a tagger assigns pos to remaining words preserving the pre-assigned pos, whose results are corrected by human annotators. we also modified the ptb scheme slightly. an inter-annotator agreement tested on new 50 abstracts was 98.5%. a pos tagger trained with the annotated abstracts was tested against a gold-standard set made from the interannotator agreement. the untrained tagger had the accuracy of 83.0%. trained with 2000 annotated abstracts the accuracy rose to 98.2%. the 2000 annotated abstracts are publicly available.",
            "contribution_ids": [
                "R163867"
            ]
        },
        {
            "instance_id": "R164231xR164050",
            "comparison_id": "R164231",
            "paper_id": "R164050",
            "text": "Static Relations: a Piece in the Biomedical Information Extraction Puzzle \"we propose a static relation extraction task to complement biomedical information extraction approaches. we argue that static relations such as part-whole are implicitly involved in many common extraction settings, define a task setting making them explicit, and discuss their integration into previously proposed tasks and extraction methods. we further identify a specific static relation extraction task motivated by the bionlp'09 shared task on event extraction, introduce an annotated corpus for the task, and demonstrate the feasibility of the task by experiments showing that the defined relations can be reliably extracted. the task setting and corpus can serve to support several forms of domain information extraction.\"",
            "contribution_ids": [
                "R164052"
            ]
        },
        {
            "instance_id": "R164670xR164455",
            "comparison_id": "R164670",
            "paper_id": "R164455",
            "text": "BioNLP Shared Task 2011 - Bacteria Biotope this paper presents the bacteria biotope task as part of the bionlp shared tasks 2011. the bacteria biotope task aims at extracting the location of bacteria from scientific web pages. bacteria location is a crucial knowledge in biology for phenotype studies. the paper details the corpus specification, the evaluation metrics, summarizes and discusses the participant results.",
            "contribution_ids": [
                "R164457",
                "R164467",
                "R165270",
                "R165466",
                "R165867",
                "R165893"
            ]
        },
        {
            "instance_id": "R166240xR163050",
            "comparison_id": "R166240",
            "paper_id": "R163050",
            "text": "Named Entity Recognition in Wikipedia \"named entity recognition (ner) is used in many domains beyond the newswire text that comprises current gold-standard corpora. recent work has used wikipedia's link structure to automatically generate near gold-standard annotations. until now, these resources have only been evaluated on newswire corpora or themselves. \\n \\nwe present the first ner evaluation on a wikipedia gold standard (wg) corpus. our analysis of cross-corpus performance on wg shows that wikipedia text may be a harder ner domain than newswire. we find that an automatic annotation of wikipedia has high agreement with wg and, when used as training data, outperforms newswire models by up to 7.7%.\"",
            "contribution_ids": [
                "R163052"
            ]
        },
        {
            "instance_id": "R166240xR163109",
            "comparison_id": "R166240",
            "paper_id": "R163109",
            "text": "WiNER: A Wikipedia Annotated Corpus for Named Entity Recognition we revisit the idea of mining wikipedia in order to generate named-entity annotations. we propose a new methodology that we applied to english wikipedia to build winer, a large, high quality, annotated corpus. we evaluate its usefulness on 6 ner tasks, comparing 4 popular state-of-the art approaches. we show that lstm-crf is the approach that benefits the most from our corpus. we report impressive gains with this model when using a small portion of winer on top of the conll training material. last, we propose a simple but efficient method for exploiting the full range of winer, leading to further improvements.",
            "contribution_ids": [
                "R163111"
            ]
        },
        {
            "instance_id": "R166240xR166178",
            "comparison_id": "R166240",
            "paper_id": "R166178",
            "text": "Exploiting Wikipedia as external knowledge for named entity recognition we explore the use of wikipedia as external knowledge to improve named entity recognition (ner). our method retrieves the corresponding wikipedia entry for each candidate word sequence and extracts a category label from the first sentence of the entry, which can be thought of as a definition part. these category labels are used as features in a crf-based ne tagger. we demonstrate using the conll 2003 dataset that the wikipedia category labels extracted by such a simple method actually improve the accuracy of ner.",
            "contribution_ids": [
                "R166180"
            ]
        },
        {
            "instance_id": "R172155xR171842",
            "comparison_id": "R172155",
            "paper_id": "R171842",
            "text": "BC4GO: a full-text corpus for the BioCreative IV GO task gene function curation via gene ontology (go) annotation is a common task among model organism database groups. owing to its manual nature, this task is considered one of the bottlenecks in literature curation. there have been many previous attempts at automatic identification of go terms and supporting information from full text. however, few systems have delivered an accuracy that is comparable with humans. one recognized challenge in developing such systems is the lack of marked sentence-level evidence text that provides the basis for making go annotations. we aim to create a corpus that includes the go evidence text along with the three core elements of go annotations: (i) a gene or gene product, (ii) a go term and (iii) a go evidence code. to ensure our results are consistent with real-life go data, we recruited eight professional go curators and asked them to follow their routine go annotation protocols. our annotators marked up more than 5000 text passages in 200 articles for 1356 distinct go terms. for evidence sentence selection, the inter-annotator agreement (iaa) results are 9.3% (strict) and 42.7% (relaxed) in f1-measures. for go term selection, the iaas are 47% (strict) and 62.9% (hierarchical). our corpus analysis further shows that abstracts contain \u223c10% of relevant evidence sentences and 30% distinct go terms, while the results/experiment section has nearly 60% relevant sentences and >70% go terms. further, of those evidence sentences found in abstracts, less than one-third contain enough experimental detail to fulfill the three core criteria of a go annotation. this result demonstrates the need of using full-text articles for text mining go annotations. through its use at the biocreative iv go (bc4go) task, we expect our corpus to become a valuable resource for the bionlp research community. database url: http://www.biocreative.org/resources/corpora/bc-iv-go-task-corpus/.",
            "contribution_ids": [
                "R171844",
                "R171845"
            ]
        },
        {
            "instance_id": "R182358xR182107",
            "comparison_id": "R182358",
            "paper_id": "R182107",
            "text": "Multi-Task Learning for Calorie Prediction on a Novel Large-Scale Recipe Dataset Enriched with Nutritional Information a rapidly growing amount of content posted online, such as food recipes, opens doors to new exciting applications at the intersection of vision and language. in this work, we aim to estimate the calorie amount of a meal directly from an image by learning from recipes people have published on the internet, thus skipping time-consuming manual data annotation. since there are few large-scale publicly available datasets captured in unconstrained environments, we propose the pic2kcal benchmark comprising 308 000 images from over 70 000 recipes including photographs, ingredients, and instructions. to obtain nutritional information of the ingredients and automatically determine the ground-truth calorie value, we match the items in the recipes with structured information from a food item database. we evaluate various neural networks for regression of the calorie quantity and extend them with the multi-task paradigm. our learning procedure combines the calorie estimation with prediction of proteins, carbohydrates, and fat amounts as well as a multi-label ingredient classification. our experiments demonstrate clear benefits of multi-task learning for calorie estimation, surpassing the single-task calorie regression by 9.9%. to encourage further research on this task, we make the code for generating the dataset and the models publicly available.",
            "contribution_ids": [
                "R182109",
                "R182111",
                "R182130",
                "R182145",
                "R182156",
                "R182171",
                "R182172",
                "R182174",
                "R182175",
                "R182176",
                "R182178",
                "R182179",
                "R182181",
                "R182182",
                "R182183",
                "R182185",
                "R182186",
                "R182187",
                "R182188",
                "R182189"
            ]
        },
        {
            "instance_id": "R182358xR182316",
            "comparison_id": "R182358",
            "paper_id": "R182316",
            "text": "Automatic Chinese food identification and quantity estimation computer-aided food identification and quantity estimation have caught more attention in recent years because of the growing concern of our health. the identification problem is usually defined as an image categorization or classification problem and several researches have been proposed. in this paper, we address the issues of feature descriptors in the food identification problem and introduce a preliminary approach for the quantity estimation using depth information. sparse coding is utilized in the sift and local binary pattern feature descriptors, and these features combined with gabor and color features are used to represent food items. a multi-label svm classifier is trained for each feature, and these classifiers are combined with multi-class adaboost algorithm. for evaluation, 50 categories of worldwide food are used, and each category contains 100 photographs from different sources, such as manually taken or from internet web albums. an overall accuracy of 68.3% is achieved, and success at top-n candidates achieved 80.6%, 84.8%, and 90.9% accuracy accordingly when n equals 2, 3, and 5, thus making mobile application practical. the experimental results show that the proposed methods greatly improve the performance of original sift and lbp feature descriptors. on the other hand, for quantity estimation using depth information, a straight forward method is proposed for certain food, while transparent food ingredients such as pure water and cooked rice are temporarily excluded.",
            "contribution_ids": [
                "R182318"
            ]
        },
        {
            "instance_id": "R182358xR182352",
            "comparison_id": "R182358",
            "paper_id": "R182352",
            "text": "Real-Time Mobile Food Recognition System \"we propose a mobile food recognition system the poses of which are estimating calorie and nutritious of foods and recording a user's eating habits. since all the processes on image recognition performed on a smart-phone, the system does not need to send images to a server and runs on an ordinary smartphone in a real-time way. to recognize food items, a user draws bounding boxes by touching the screen first, and then the system starts food item recognition within the indicated bounding boxes. to recognize them more accurately, we segment each food item region by grubcut, extract a color histogram and surf-based bag-of-features, and finally classify it into one of the fifty food categories with linear svm and fast 2 kernel. in addition, the system estimates the direction of food regions where the higher svm output score is expected to be obtained, show it as an arrow on the screen in order to ask a user to move a smartphone camera. this recognition process is performed repeatedly about once a second. we implemented this system as an android smartphone application so as to use multiple cpu cores effectively for real-time recognition. in the experiments, we have achieved the 81.55% classification rate for the top 5 category candidates when the ground-truth bounding boxes are given. in addition, we obtained positive evaluation by user study compared to the food recording system without object recognition.\"",
            "contribution_ids": [
                "R182354"
            ]
        },
        {
            "instance_id": "R184018xR182127",
            "comparison_id": "R184018",
            "paper_id": "R182127",
            "text": "Crop diversity is associated with higher child diet diversity in Ethiopia, particularly among low-income households, but not in Vietnam abstract objectives: to examine associations of household crop diversity with school-aged child dietary diversity in vietnam and ethiopia and mechanisms underlying these associations. design: we created a child diet diversity score (dds) using data on seven food groups consumed in the last 24 h. generalised estimating equations were used to model associations of household-level crop diversity, measured as a count of crop species richness (csr) and of plant crop nutritional functional richness (cnfr), with dds. we examined effect modification by household wealth and subsistence orientation, and mediation by the farm\u2019s market orientation. setting: two survey years of longitudinal data from the young lives cohort. participants: children (aged 5 years in 2006 and 8 years in 2009) from rural farming households in ethiopia ( n 1012) and vietnam ( n 1083). results: there was a small, positive association between household cnfr and dds in ethiopia (cnfr\u2013dds, \u03b2 = 0\u00b713; (95 % ci 0\u00b707, 0\u00b719)), but not in vietnam. associations of crop diversity and child diet diversity were strongest among poor households in ethiopia and among subsistence-oriented households in vietnam. agricultural earnings positively mediated the crop diversity\u2013diet diversity association in ethiopia. discussion: children from households that are poorer and those that rely more on their own agricultural production for food may benefit most from increased crop diversity.",
            "contribution_ids": [
                "R182129"
            ]
        },
        {
            "instance_id": "R184018xR182137",
            "comparison_id": "R184018",
            "paper_id": "R182137",
            "text": "Understanding the Linkages between Crop Diversity and Household Dietary Diversity in the Semi-Arid Regions of India agriculture is fundamental to achieving nutrition goals; it provides the food, energy, and nutrients essential \\nfor human health and well-being. this paper has examined crop diversity and dietary diversity in six \\nvillages using the icrisat village level studies (vls) data from the telangana and maharashtra states \\nof india. the study has used the data of cultivating households for constructing the crop diversity index \\nwhile dietary diversity data is from the special purpose nutritional surveys conducted by icrisat in the \\nsix villages. the study has revealed that the cropping pattern is not uniform across the six study villages \\nwith dominance of mono cropping in telangana villages and of mixed cropping in maharashtra villages. \\nthe analysis has indicated a positive and significant correlation between crop diversity and household \\ndietary diversity at the bivariate level. in multiple linear regression model, controlling for the other \\ncovariates, crop diversity has not shown a significant association with household dietary diversity. however, \\nother covariates have shown strong association with dietary diversity. the regression results have revealed \\nthat households which cultivated minimum one food crop in a single cropping year have a significant and \\npositive relationship with dietary diversity. from the study it can be inferred that crop diversity alone \\ndoes not affect the household dietary diversity in the semi-arid tropics. enhancing the evidence base and \\nfuture research, especially in the fragile environment of semi-arid tropics, is highly recommended.",
            "contribution_ids": [
                "R182139"
            ]
        },
        {
            "instance_id": "R184018xR182396",
            "comparison_id": "R184018",
            "paper_id": "R182396",
            "text": "The influence of crop production and socioeconomic factors on seasonal household dietary diversity in Burkina Faso households in low-income settings are vulnerable to seasonal changes in dietary diversity because of fluctuations in food availability and access. we assessed seasonal differences in household dietary diversity in burkina faso, and determined the extent to which household socioeconomic status and crop production diversity modify changes in dietary diversity across seasons, using data from the nationally representative 2014 burkina faso continuous multisectoral survey (emc). a household dietary diversity score based on nine food groups was created from household food consumption data collected during four rounds of the 2014 emc. plot-level crop production data, and data on household assets and education were used to create variables on crop diversity and household socioeconomic status, respectively. analyses included data for 10,790 households for which food consumption data were available for at least one round. accounting for repeated measurements and controlling for the complex survey design and confounding covariates using a weighted multi-level model, household dietary diversity was significantly higher during both lean seasons periods, and higher still during the harvest season as compared to the post-harvest season (mean: post-harvest: 4.76 (se 0.04); beginning of lean: 5.13 (se 0.05); end of lean: 5.21 (se 0.05); harvest: 5.72 (se 0.04)), but was not different between the beginning and the end of lean season. seasonal differences in household dietary diversity were greater among households with higher food expenditures, greater crop production, and greater monetary value of crops sale (p<0.05). seasonal changes in household dietary diversity in burkina faso may reflect nutritional differences among agricultural households, and may be modified both by households\u2019 socioeconomic status and agricultural characteristics.",
            "contribution_ids": [
                "R182397"
            ]
        },
        {
            "instance_id": "R184018xR184012",
            "comparison_id": "R184018",
            "paper_id": "R184012",
            "text": "If They Grow It, Will They Eat and Grow? Evidence from Zambia on Agricultural Diversity and Child Undernutrition abstract in this article we address a gap in our understanding of how household agricultural production diversity affects the diets and nutrition of young children living in rural farming communities in sub-saharan africa. the specific objectives of this article are to assess: (1) the association between household agricultural production diversity and child dietary diversity; and (2) the association between household agricultural production diversity and child nutritional status. we use household survey data collected from 3,040 households as part of the realigning agriculture for improved nutrition (rain) intervention in zambia. the data indicate low agricultural diversity, low dietary diversity and high levels of chronic malnutrition overall in this area. we find a strong positive association between production diversity and dietary diversity among younger children aged 6\u201323 months, and significant positive associations between production diversity and height for age z-scores and stunting among older children aged 24\u201359 months.",
            "contribution_ids": [
                "R184014"
            ]
        },
        {
            "instance_id": "R186048xR180001",
            "comparison_id": "R186048",
            "paper_id": "R180001",
            "text": "A Deep Learning based Approach for Precise Video Tagging with the increase in smart devices and abundance of video contents, efficient techniques for the indexing, analysis and retrieval of videos are becoming more and more desirable. improved indexing and automated analysis of millions of videos could be accomplished by getting videos tagged automatically. a lot of existing methods fail to precisely tag videos because of their lack of ability to capture the video context. the context in a video represents the interactions of objects in a scene and their overall meaning. in this work, we propose a novel approach that integrates the video scene ontology with cnn (convolutional neural network) for improved video tagging. our method captures the content of a video by extracting the information from individual key frames. the key frames are then fed to a cnn based deep learning model to train its parameters. the trained parameters are used to generate the most frequent tags. highly frequent tags are used to summarize the input video. the proposed technique is benchmarked on the most widely used dataset of video activities, namely, ucf-101. our method managed to achieve an overall accuracy of 99.8% with an f1- score of 96.2%.",
            "contribution_ids": [
                "R180003",
                "R180014",
                "R180016"
            ]
        },
        {
            "instance_id": "R186111xR186093",
            "comparison_id": "R186111",
            "paper_id": "R186093",
            "text": "Assessing Business-IT Allignment Maturity strategic alignment focuses on the activities that management performs to achieve cohesive goals across the it (information technology) and other functional organizations (e.g., finance, marketing, h/r, r&amp;d, manufacturing). therefore, alignment addresses both how it is in harmony with the business, and how the business should, or could, be in harmony with it. alignment evolves into a relationship where the function of it and other business functions adapt their strategies together. achieving alignment is evolutionary and dynamic. it requires strong support from senior management, good working relationships, strong leadership, appropriate prioritization, trust, and effective communication, as well as a thorough understanding of the business and technical environments. the strategic alignment maturity assessment provides organizations with a vehicle to evaluate these activities. knowing the maturity of its strategic choices and alignment practices make it possible for a firm to see where it stands and how it can improve. this chapter discusses an approach for assessing the maturity of the business-it alignment. once maturity is understood, an organization can identify opportunities for enhancing the harmonious relationship of business and it.",
            "contribution_ids": [
                "R186095"
            ]
        },
        {
            "instance_id": "R189691xR189572",
            "comparison_id": "R189691",
            "paper_id": "R189572",
            "text": "Ionic supramolecular bonds preserve mechanical properties and enable synergetic performance at high humidity in water-borne, self-assembled nacre-mimetics \"although tremendous effort has been focused on enhancing the mechanical properties of nacre-mimetic materials, conservation of high stiffness and strength against hydration-induced decay of mechanical properties at high humidity remains a fundamental challenge in such water-borne high-performance materials. herein, we demonstrate that ionic supramolecular bonds, introduced by infiltration of divalent cu(2+) ions, allow efficient stabilization of the mechanical properties of self-assembled water-borne nacre-mimetics based on sustainable sodium carboxymethylcellulose (na(+)cmc) and natural sodium montmorillonite nanoclay (na(+)mtm) against high humidity (95% rh). the mechanical properties in the highly hydrated state (young's modulus up to 13.5 gpa and tensile strength up to 125 mpa) are in fact comparable to a range of non-crosslinked nacre-mimetic materials in the dry state. moreover, the cu(2+)-treated nacre-inspired materials display synergetic mechanical properties as found in a simultaneous improvement of stiffness, strength and toughness, as compared to the pristine material. significant inelastic deformation takes place considering the highly reinforced state. this contrasts the typical behaviour of tight, covalent crosslinks and is suggested to originate from a sacrificial, dynamic breakage and rebinding of transient supramolecular ionic bonds. considering easy access to a large range of ionic interactions and alteration of counter-ion charge via external stimuli, we foresee responsive and adaptive mechanical properties in highly reinforced and stiff bio-inspired bulk nanocomposites and in other bio-inspired materials, e.g. nanocellulose papers and peptide-based materials.\"",
            "contribution_ids": [
                "R189574"
            ]
        },
        {
            "instance_id": "R189691xR189668",
            "comparison_id": "R189691",
            "paper_id": "R189668",
            "text": "Nacre-Mimetic Clay/Xyloglucan Bionanocomposites: A Chemical Modification Route for Hygromechanical Performance at High Humidity \"nacre-mimetic bionanocomposites of high montmorillonite (mtm) clay content, prepared from hydrocolloidal suspensions, suffer from reduced strength and stiffness at high relative humidity. we address this problem by chemical modification of xyloglucan in (xg)/mtm nacre-mimetic nanocomposites, by subjecting the xg to regioselective periodate oxidation of side chains to enable it to form covalent cross-links to hydroxyl groups in neighboring xg chains or to the mtm surface. the resulting materials are analyzed by ftir spectroscopy, thermogravimetric analysis, carbohydrate analysis, calorimetry, x-ray diffraction, scanning electron microscopy, tensile tests, and oxygen barrier properties. we compare the resulting mechanical properties at low and high relative humidity. the periodate oxidation leads to a strong increase in modulus and strength of the materials. a modulus of 30 gpa for cross-linked composite at 50% relative humidity compared with 13.7 gpa for neat xg/mtm demonstrates that periodate oxidation of the xg side chains leads to crucially improved stress transfer at the xg/mtm interface, possibly through covalent bond formation. this enhanced interfacial adhesion and internal cross-linking of the matrix moreover preserves the mechanical properties at high humidity condition and leads to a young's modulus of 21 gpa at 90%rh.\"",
            "contribution_ids": [
                "R189670"
            ]
        },
        {
            "instance_id": "R189691xR189677",
            "comparison_id": "R189691",
            "paper_id": "R189677",
            "text": "Multifunctional Nanoclay Hybrids of High Toughness, Thermal, and Barrier Performances to address brittleness of nanoclay hybrids of high inorganic content, ductile polymers (polyethylene oxide and hydroxyethyl cellulose) and montmorillonite (mtm) have been assembled into hybrid films using a water-based filtration process. nacre-mimetic layered films resulted and were characterized by fe-sem and xrd. mechanical properties at ambient condition were studied by tensile test, while performance at elevated temperature and moisture conditions were evaluated by tga, dynamic vapor sorption, and dynamic thermomechanical and hygromechanical analyses. antiflammability and barrier properties against oxygen and water vapor were also investigated. despite their high mtm content in the 60-85 wt % range, the hybrids exhibit remarkable ductility and a storage modulus above 2 gpa even in severe conditions (300\u00b0c or 94% rh). moreover, they present fire-shielding property and are amongst the best oxygen and water vapor barrier hybrids reported in the literature. this study thus demonstrates nanostructure property advantages for synergistic effects in hybrids combining inexpensive, available, and environmentally benign constituents.",
            "contribution_ids": [
                "R189678"
            ]
        },
        {
            "instance_id": "R189691xR189685",
            "comparison_id": "R189691",
            "paper_id": "R189685",
            "text": "Deoxyguanosine Phosphate Mediated Sacrificial Bonds Promote Synergistic Mechanical Properties in Nacre-Mimetic Nanocomposites \"we show that functionalizing polymer-coated colloidal nanoplatelets with guanosine groups allows synergistic increase of mechanical properties in nacre-mimetic lamellar self-assemblies. anionic montmorillonite (mtm) was first coated using cationic poly(diallyldimethylammonium chloride) (pdadmac) to prepare core-shell colloidal platelets, and subsequently the remaining chloride counterions allowed exchange to functional anionic 2'-deoxyguanosine 5'-monophosphate (dgmp) counterions, containing hydrogen bonding donors and acceptors. the compositions were studied using elemental analysis, scanning and transmission electron microscopy, wide-angle x-ray scattering, and tensile testing. the lamellar spacing between the clays increases from 1.85 to 2.14 nm upon addition of the dgmp. adding dgmp increases the elastic modulus, tensile strength, and strain 33.0%, 40.9%, and 5.6%, respectively, to 13.5 gpa, 67 mpa, and 1.24%, at 50% relative humidity. this leads to an improved toughness seen as a ca. 50% increase of the work-to-failure. this is noteworthy, as previously it has been observed that connecting the core-shell nanoclay platelets covalently or ionically leads to increase of the stiffness but to reduced strain. we suggest that the dynamic supramolecular bonds allow slippage and sacrificial bonds between the self-assembling nanoplatelets, thus promoting toughness, still providing dynamic interactions between the platelets.\"",
            "contribution_ids": [
                "R189688"
            ]
        },
        {
            "instance_id": "R190010xR189607",
            "comparison_id": "R190010",
            "paper_id": "R189607",
            "text": "Sliding Window Optimized Information Entropy Analysis Method for Intrusion Detection on In-Vehicle Networks with the considerable growth of cybersecurity risks in modern automobiles, cybersecurity issues in the in-vehicle network environment have attracted significant attention from security researchers in recent years. enhancing the cybersecurity ability of in-vehicle networks while considering the computing resource and cost constraints become an urgent issue. to address this problem, a novel information entropy-based method is proposed in this paper, which uses a fixed number of messages as sliding windows. by improving the sliding window strategy and optimizing the decision conditions, the detection accuracy is increased and the false positive rate is reduced. experimental results demonstrate that the proposed method can provide real-time response to attacks with a considerably improved detection precision for intrusion detection in the in-vehicle network environment.",
            "contribution_ids": [
                "R189611"
            ]
        },
        {
            "instance_id": "R191054xR190018",
            "comparison_id": "R191054",
            "paper_id": "R190018",
            "text": "Clinical Characteristics of COVID-19 Patients With Digestive Symptoms in Hubei, China: A Descriptive, Cross-Sectional, Multicenter Study objective: since the outbreak of coronavirus disease 2019 (covid-19) in december 2019, various digestive symptoms have been frequently reported in patients infected with the virus. in this study, we aimed to further investigate the prevalence and outcomes of covid-19 patients with digestive symptoms. methods: in this descriptive, cross-sectional, multicenter study, we enrolled confirmed patients with covid-19 who presented to 3 hospitals from january 18, 2020, to february 28, 2020. all patients were confirmed by real-time polymerase chain reaction and were analyzed for clinical characteristics, laboratory data, and treatment. data were followed up until march 18, 2020. results: in the present study, 204 patients with covid-19 and full laboratory, imaging, and historical data were analyzed. the average age was 52.9 years (sd \u00b1 16), including 107 men and 97 women. although most patients presented to the hospital with fever or respiratory symptoms, we found that 103 patients (50.5%) reported a digestive symptom, including lack of appetite (81 [78.6%] cases), diarrhea (35 [34%] cases), vomiting (4 [3.9%] cases), and abdominal pain (2 [1.9%] cases). if lack of appetite is excluded from the analysis (because it is less specific for the gastrointestinal tract), there were 38 total cases (18.6%) where patients presented with a gastrointestinal-specific symptom, including diarrhea, vomiting, or abdominal pain. patients with digestive symptoms had a significantly longer time from onset to admission than patients without digestive symptoms (9.0 days vs 7.3 days). in 6 cases, there were digestive symptoms, but no respiratory symptoms. as the severity of the disease increased, digestive symptoms became more pronounced. patients with digestive symptoms had higher mean liver enzyme levels, lower monocyte count, longer prothrombin time, and received more antimicrobial treatment than those without digestive symptoms. discussion: we found that digestive symptoms are common in patients with covid-19. moreover, these patients have a longer time from onset to admission, evidence of longer coagulation, and higher liver enzyme levels. clinicians should recognize that digestive symptoms, such as diarrhea, are commonly among the presenting features of covid-19 and that the index of suspicion may need to be raised earlier in at-risk patients presenting with digestive symptoms. however, further large sample studies are needed to confirm these findings.",
            "contribution_ids": [
                "R190020"
            ]
        },
        {
            "instance_id": "R191054xR190022",
            "comparison_id": "R191054",
            "paper_id": "R190022",
            "text": "Effect of Gastrointestinal Symptoms in Patients With COVID-19 because of accumulating evidence pointing to continuous person-to-person transmission of coronavirus disease 2019 (covid-19) in hospital and family settings,1,2 the world health organization has recently declared covid-19 a public health emergency of international concern. fever and respiratory symptoms tend to be initial and major, whereas gastrointestinal (gi) symptoms were also observed in a significant portion of patients.3 positive findings of reverse transcription polymerase chain reaction further showed that covid-19 may spread by fecal-oral transmission.",
            "contribution_ids": [
                "R190025"
            ]
        },
        {
            "instance_id": "R191054xR190053",
            "comparison_id": "R191054",
            "paper_id": "R190053",
            "text": "Association of Gastrointestinal System With Severity and Mortality of COVID-19: A Systematic Review and Meta-Analysis at present, the novel coronavirus disease (covid-19) is causing a major pandemic. covid-19 is caused by the severe acute respiratory syndrome coronavirus 2 (sars-cov-2). in covid-19, the patient usually presents with fever, dry cough, and respiratory manifestations. however, the involvement of other systems has also been reported in the literature. abdominal pain, diarrhea, vomiting, and nausea are the predominant gastrointestinal (gi) manifestations underlined in the literature. we conducted a literature search using four databases (pubmed, web of science, google scholar, and clinicaltrials.gov). our search strategy included medical subject headings (mesh) terms and keywords for covid-19, sars-cov-2, and gi system from inception to october 2020. after excluding duplicates, review articles, and non-relevant articles, we included 20 studies out of 842 articles reporting gi manifestations in covid-19 patients. using cochrane revman version 5.4 (cochrane, london, uk), a compute pooled analysis using a random-effect model was performed. our study included 6,022 patients with a median age of 49.5 years. pooled analysis via random effect model revealed an increased risk of severe covid-19 in patients manifesting gi symptoms with an odds ratio (or) of 2.07 (95% confidence interval [ci]: 1.34-3.18) with i2=41%). odds of mortality in covid-19 with gi manifestation and hepatic abnormalities included 0.92 (95% ci: 0.50-1.69) (i2=57%) and 1.26 (95% ci: 0.67-2.37) (i2=0%), respectively. severe covid-19 may have a strong association with gi manifestations and have a significant impact on gi practice. holistic knowledge of the spectrum of the gi consequences in covid-19 is crucial to get a hold of virus spread. in this article, we have summarized the association of gi manifestations in severe covid-19 patients.",
            "contribution_ids": [
                "R190055"
            ]
        },
        {
            "instance_id": "R191407xR191192",
            "comparison_id": "R191407",
            "paper_id": "R191192",
            "text": "Embracing Domain Differences in Fake News: Cross-domain Fake News Detection using Multi-modal Data with the rapid evolution of social media, fake news has become a significant social problem, which cannot be addressed in a timely manner using manual investigation. this has motivated numerous studies on automating fake news detection. most studies explore supervised training models with different modalities (e.g., text, images, and propagation networks) of news records to identify fake news. however, the performance of such techniques generally drops if news records are coming from different domains (e.g., politics, entertainment), especially for domains that are unseen or rarely-seen during training. as motivation, we empirically show that news records from different domains have significantly different word usage and propagation patterns. furthermore, due to the sheer volume of unlabelled news records, it is challenging to select news records for manual labelling so that the domain-coverage of the labelled dataset is maximized. hence, this work: (1) proposes a novel framework that jointly preserves domain-specific and cross-domain knowledge in news records to detect fake news from different domains; and (2) introduces an unsupervised technique to select a set of unlabelled informative news records for manual labelling, which can be ultimately used to train a fake news detection model that performs well for many domains while minimizing the labelling cost. our experiments show that the integration of the proposed fake news model and the selective annotation approach achieves state-of-the-art performance for cross-domain news datasets, while yielding notable improvements for rarely-appearing domains in news datasets.",
            "contribution_ids": [
                "R191194"
            ]
        },
        {
            "instance_id": "R191407xR191219",
            "comparison_id": "R191407",
            "paper_id": "R191219",
            "text": "Embedding Partial Propagation Network for Fake News Early Detection detecting fake news as early as possible has attracted growing attention due to its fast-spreading nature and the significant harm it can cause. as demonstrated in recent studies, the propagation pattern of fake news on social media differs from that of real news, and a number of works have extracted different types of features from the propagation pattern for detection. however, a major limitation of this approach is that the propagation network is not fully available in the early stages, and may take a long time to complete. as a result, existing network-based fake news detection methods yield low accuracy during the early stages of propagation. to bridge the research gap, in this work we: (1) propose a novel network embedding algorithm, based on the investigation of a wide range of features obtained from the propagation network, which are not well studied in previous work; and (2) design an autoencoder-based neural architecture to predict the embedding of the complete propagation network using the partially available network in the early stages of propagation. our experiments show that with the predicted embedding for the complete propagation network, our model can achieve state-of-the-art performance while only having access to the early stage propagation network.",
            "contribution_ids": [
                "R191221"
            ]
        },
        {
            "instance_id": "R191407xR191241",
            "comparison_id": "R191407",
            "paper_id": "R191241",
            "text": "dEFEND: Explainable Fake News Detection in recent years, to mitigate the problem of fake news, computational detection of fake news has been studied, producing some promising early results. while important, however, we argue that a critical missing piece of the study be the explainability of such detection, i.e., why a particular piece of news is detected as fake. in this paper, therefore, we study the explainable detection of fake news. we develop a sentence-comment co-attention sub-network to exploit both news contents and user comments to jointly capture explainable top-k check-worthy sentences and user comments for fake news detection. we conduct extensive experiments on real-world datasets and demonstrate that the proposed method not only significantly outperforms 7 state-of-the-art fake news detection methods by at least 5.33% in f1-score, but also (concurrently) identifies top-k user comments that explain why a news piece is fake, better than baselines by 28.2% in ndcg and 30.7% in precision.",
            "contribution_ids": [
                "R191243"
            ]
        },
        {
            "instance_id": "R191976xR189876",
            "comparison_id": "R191976",
            "paper_id": "R189876",
            "text": "Precision Wavelength Determination of 2^1P_1 - 1^1S_0 and 2^3P_1 - 1^1S_0 Transitions in Helium-Like Sulfur Ions transitions from the 21p1 - and 23p1 -state to the ground state 11s0 in helium-like sulphur ions have been measured with an accuracy of 4 \u00d7 10-5. energy calibration is described in detail and two reference wavelengths have been reevaluated. substantial line-blending was observed, due to long-lived spectator electrons. the two transition energies were corrected for doppler shift and compared with most refined theoretical calculations, including terms of order \u03b14z6 in the breit operator and terms of order \u03b15z6 in the quantum-electrodynamical corrections. the experimental contributions to the ground-state qed shifts agree within its error (\u223c 15%) with the theoretical values.",
            "contribution_ids": [
                "R189878"
            ]
        },
        {
            "instance_id": "R191976xR190068",
            "comparison_id": "R191976",
            "paper_id": "R190068",
            "text": "Precision X-ray wavelength measurements in helium-like argon recoil ions \"the authors report precise wavelength measurements of the 1s2 1s0-1s2p3p1,2,1p1 transitions in ar16+ produced by collisions of 5.9 mev amu-1 u66+ ions with an argon gas target. by use of this 'recoil source', the precision is not limited by doppler shifts while the influence of spectator electrons is minimised by observation of their relative importance as a function of gas pressure. the accuracy obtained is at the 12 p.p.m. level dominated by the x-ray calibration standard. the measurement is thus sensitive to quantum-electrodynamic (qed) and electron correlation effects.\"",
            "contribution_ids": [
                "R190070",
                "R190101",
                "R190133"
            ]
        },
        {
            "instance_id": "R191984xR191915",
            "comparison_id": "R191984",
            "paper_id": "R191915",
            "text": "A Methodology of CAN Communication Encryption Using a shuffling algorithm in-vehicle communication uses can bus, and for this, communication speed and security are important. since the current can communication is used without encryption, many cases have been reported of vehicle hacking over time. with the advent of autonomous driving and connected cars, vehicles no longer remain independent; they can be invaded from the outside and personal information such as vehicle location and driving habits can be accessed through the vehicle, which poses a serious threat to personal privacy and life. therefore, communication data must be encrypted in order to increase the security of the communication. in this paper, data frames are encrypted using a shuffling algorithm in the can communication system environment. to put it more precisely, the data frame is divided into bits and structured into blocks, which are then shuffled for data hiding. this method determines the level of obfuscation based on blockage and shuffle criteria. the encryption time was measured by changing both. this suggest ways to increase the security and communication speed in the vehicle.",
            "contribution_ids": [
                "R191917"
            ]
        },
        {
            "instance_id": "R191984xR191933",
            "comparison_id": "R191984",
            "paper_id": "R191933",
            "text": "A PUF Based CAN Security Framework we propose a method to include security and reliability to the messages sent over the can bus. our approach adheres to can standard iso 11898-1. a reliable puf response is used in key generation to create a unique shared aes-256 key between each ecu, allowing for all message paths to be encrypted. in addition, an hmac system with a counter is implemented to help protect against replay attacks and message tampering within the network.",
            "contribution_ids": [
                "R191935"
            ]
        },
        {
            "instance_id": "R191984xR191942",
            "comparison_id": "R191984",
            "paper_id": "R191942",
            "text": "Improving Timing Behavior on Encrypted CAN Buses \"can is probably the most successful bus in the automotive domain, especially, due to its low cost and robustness. however, with increasing connectivity, there is a need to encrypt data to avoid attacks such as spoofing and sniffing. this ends up exposing can's severe limitations. in particular, each encrypted message requires sending two frames due to its restrictive payload in can. moreover, each frame of an encrypted message undergoes a separate arbitration process which negatively impacts timing and makes it difficult to meet deadlines. in this paper, to work around this problem, we propose a technique that consists in assigning different priorities to encrypted can frames so as to compensate for increased delay. the basic idea is that, once the first frame of an encrypted can message wins arbitration, its second frame will always win arbitration within a specified scope and can be sent with lesser delay. we have conducted experiments on real hardware and performed extensive simulations indicating that the proposed technique reduces transmission delay to one half or even one third compared with the standard approach allowing us to still meet typical automotive deadlines on an encrypted can bus.\"",
            "contribution_ids": [
                "R191944"
            ]
        },
        {
            "instance_id": "R193278xR193173",
            "comparison_id": "R193278",
            "paper_id": "R193173",
            "text": "Representation of IP Routing Policies in a Routing Registry (ripe-81++) \"this document was originally published as a ripe document known as ripe-181 but is also being published as an informational rfc to reach a larger audience than its original scope. it has received community wide interest and acknowledgment throughout the internet service provider community and will be used as the basic starting point for future work on internet routing registries and routing policy representation. it can also be referred to as ripe-81++. this document is an update to the original `ripe-81'[1] proposal for representing and storing routing polices within the ripe database. it incorporates several extensions proposed by merit inc.[2] and gives details of a generalized ip routing policy representation to be used by all internet routing registries. it acts as both tutorial and provides details of database objects and attributes that use and make up a routing registry.\"",
            "contribution_ids": [
                "R193175"
            ]
        },
        {
            "instance_id": "R193278xR193197",
            "comparison_id": "R193278",
            "paper_id": "R193197",
            "text": "Origin authentication in interdomain routing attacks against internet routing are increasing in number and severity. contributing greatly to these attacks is the absence of origin authentication: there is no way to validate claims of address ownership or location. the lack of such services enables not only attacks by malicious entities, but indirectly allow seemingly inconsequential miconfigurations to disrupt large portions of the internet. this paper considers the semantics, design, and costs of origin authentication in interdomain routing. we formalize the semantics of address delegation and use on the internet, and develop and characterize broad classes of origin authentication proof systems. we estimate the address delegation graph representing the current use of ipv4 address space using available routing data. this effort reveals that current address delegation is dense and relatively static: as few as 16 entities perform 80% of the delegation on the internet. we conclude by evaluating the proposed services via traced based simulation. our simulation shows the enhanced proof systems can reduce significantly reduce resource costs associated with origin authentication.",
            "contribution_ids": [
                "R193199"
            ]
        },
        {
            "instance_id": "R193278xR193187",
            "comparison_id": "R193278",
            "paper_id": "R193187",
            "text": "Architecture and Deployment Considerations for Secure Origin BGP (soBGP) there is a great deal of concern over the security of internetworks\\nbuilt using the border gateway protocol to provide routing information\\nto autonomous systems connected to the internetwork. this draft\\nprovides an architecture for a secure distributed registry of routing\\ninformation to address these concerns. the draft begins with an\\noverview of the operation of this system, and then follows with\\nvarious deployment scenarios, starting with what we believe will be\\nthe most common deployment option.",
            "contribution_ids": [
                "R193189"
            ]
        },
        {
            "instance_id": "R193278xR193209",
            "comparison_id": "R193278",
            "paper_id": "R193209",
            "text": "Optimizing BGP security by exploiting path stability the border gateway protocol (bgp) is the de facto interdomain routing protocol on the internet. while the serious vulnerabilities of bgp are well known, no security solution has been widely deployed. the lack of adoption is largely caused by a failure to find a balance between deployability, cost, and security. in this paper, we consider the design and performance of bgp path authentication constructions that limit resource costs by exploiting route stability. based on a year-long study of bgp traffic and indirectly supported by findings within the networking community, we observe that routing paths are highly stable. this observation leads to comprehensive and efficient constructions for path authentication. we empirically analyze the resource consumption of the proposed constructions via trace-based simulations. this latter study indicates that our constructions can reduce validation costs by as much as 97.3% over existing proposals while requiring nominal storage resources. we conclude by considering operational issues related to incremental deployment of our solution.",
            "contribution_ids": [
                "R193211"
            ]
        },
        {
            "instance_id": "R193278xR193255",
            "comparison_id": "R193278",
            "paper_id": "R193255",
            "text": "An infrastructure to support secure internet routing this document describes an architecture for an infrastructure to\\nsupport secure internet routing. the foundation of this architecture\\nis a public key infrastructure (pki) that represents the allocation\\nhierarchy of ip address space and autonomous system numbers;\\ncertificates from this pki are used to verify signed objects that\\nauthorize autonomous systems to originate routes for specified ip\\naddress prefixes. the data objects that comprise the pki, as well as\\nother signed objects necessary for secure routing, are stored and\\ndisseminated through a distributed repository system. this document\\nalso describes at a high level how this architecture can be used to\\nadd security features to common operations such as ip address space\\nallocation and route filter construction.",
            "contribution_ids": [
                "R193257"
            ]
        },
        {
            "instance_id": "R193505xR178376",
            "comparison_id": "R193505",
            "paper_id": "R178376",
            "text": "SARS-CoV-2 viral load as a predictor for disease severity in outpatients and hospitalised patients with COVID-19: A prospective cohort study \\n introduction \\n we aimed to examine if severe acute respiratory syndrome coronavirus 2 (sars-cov-2) polymerase chain reaction (pcr) cycle quantification (c q ) value, as a surrogate for sars-cov-2 viral load, could predict hospitalisation and disease severity in adult patients with coronavirus disease 2019 (covid-19). \\n \\n \\n methods \\n we performed a prospective cohort study of adult patients with pcr positive sars-cov-2 airway samples including all out-patients registered at the department of infectious diseases, odense university hospital (ouh) march 9-march 17 2020, and all hospitalised patients at ouh march 10-april 21 2020. to identify associations between c q -values and a) hospital admission and b) a severe outcome, logistic regression analyses were used to compute odds ratios (or) and 95% confidence intervals (ci), adjusting for confounding factors (aor). \\n \\n \\n results \\n we included 87 non-hospitalised and 82 hospitalised patients. the median baseline c q -value was 25.5 (interquartile range 22.3\u201329.0). we found a significant association between increasing c q -value and hospital-admission in univariate analysis (or 1.11, 95% ci 1.04\u20131.19). however, this was due to an association between time from symptom onset to testing and c q -values, and no association was found in the adjusted analysis (aor 1.08, 95% ci 0.94\u20131.23). in hospitalised patients, a significant association between lower c q -values and higher risk of severe disease was found (aor 0.89, 95% ci 0.81\u20130.98), independent of timing of testing. \\n \\n \\n conclusions \\n sars-cov-2 pcr c q -values in outpatients correlated with time after symptom onset, but was not a predictor of hospitalisation. however, in hospitalised patients lower c q -values were associated with higher risk of severe disease. \\n",
            "contribution_ids": [
                "R178379",
                "R178429"
            ]
        },
        {
            "instance_id": "R193505xR191188",
            "comparison_id": "R193505",
            "paper_id": "R191188",
            "text": "Epidemiological Correlates of Polymerase Chain Reaction Cycle Threshold Values in the Detection of Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) abstract \\n \\n background \\n detection of severe acute respiratory syndrome coronavirus 2 (sars-cov-2) infection has principally been performed through the use of real-time reverse-transcription polymerase chain reaction testing. results of such tests can be reported as cycle threshold (ct) values, which may provide semi-quantitative or indirect measurements of viral load. previous reports have examined temporal trends in ct values over the course of a sars-cov-2 infection. \\n \\n \\n methods \\n using testing data collected during a prospective household transmission investigation of outpatient and mild coronavirus disease 2019 cases, we examined the relationships between ct values of the viral rna n1 target and demographic, clinical, and epidemiological characteristics collected through participant interviews and daily symptom diaries. \\n \\n \\n results \\n we found that ct values are lowest (corresponding to a higher viral rna concentration) soon after symptom onset and are significantly correlated with the time elapsed since onset (p\\u2005&amp;lt;\\u2005.001); within 7 days after symptom onset, the median ct value was 26.5, compared with a median ct value of 35.0 occurring 21 days after onset. ct values were significantly lower among participants under 18 years of age (p\\u2005=\\u2005.01) and those reporting upper respiratory symptoms at the time of sample collection (p\\u2005=\\u2005.001), and were higher among participants reporting no symptoms (p\\u2005=\\u2005.05). \\n \\n \\n conclusions \\n these results emphasize the importance of early testing for sars-cov-2 among individuals with symptoms of respiratory illness, and allow cases to be identified and isolated when their viral shedding may be highest. \\n",
            "contribution_ids": [
                "R191191"
            ]
        },
        {
            "instance_id": "R193505xR191238",
            "comparison_id": "R193505",
            "paper_id": "R191238",
            "text": "SARS-CoV-2 Viral Load on Admission Is Associated With 30-Day Mortality abstract \\n severe acute respiratory syndrome coronavirus 2 (sars-cov-2) viral load on admission was associated with a significantly increased 30-day mortality (odds ratio [or], 4.20; 95% ci, 1.62\u201310.86), and anti-sars-cov-2 nucleocapisid igg seropositivity on admission trended toward a reduced 30-day mortality (or, 0.43; 95% ci, 0.15\u20131.26). reporting of quantitative sars-cov-2 viral load and serologic assays may offer prognostic clinical information.",
            "contribution_ids": [
                "R191240"
            ]
        },
        {
            "instance_id": "R193505xR191301",
            "comparison_id": "R193505",
            "paper_id": "R191301",
            "text": "Impact of Severe Acute Respiratory Syndrome Coronavirus 2 Viral Load on Risk of Intubation and Mortality Among Hospitalized Patients With Coronavirus Disease 2019 abstract \\n \\n background \\n patients hospitalized with coronavirus disease 2019 (covid-19) frequently require mechanical ventilation and have high mortality rates. however, the impact of viral burden on these outcomes is unknown. \\n \\n \\n methods \\n we conducted a retrospective cohort study of patients hospitalized with covid-19 from 30 march 2020 to 30 april 2020 at 2 hospitals in new york city. severe acute respiratory syndrome coronavirus 2 (sars-cov-2) viral load was assessed using cycle threshold (ct) values from a reverse transcription-polymerase chain reaction assay applied to nasopharyngeal swab samples. we compared characteristics and outcomes of patients with high, medium, and low admission viral loads and assessed whether viral load was independently associated with intubation and in-hospital mortality. \\n \\n \\n results \\n we evaluated 678 patients with covid-19. higher viral load was associated with increased age, comorbidities, smoking status, and recent chemotherapy. in-hospital mortality was 35.0% (ct\\u2005&amp;lt;25; n\\u2005=\\u2005220), 17.6% (ct 25\u201330; n\\u2005=\\u2005216), and 6.2% (ct\\u2005&amp;gt;30; n\\u2005=\\u2005242) with high, medium, and low viral loads, respectively (p &amp;lt; .001). the risk of intubation was also higher in patients with a high viral load (29.1%) compared with those with a medium (20.8%) or low viral load (14.9%; p\\u2005&amp;lt;\\u2005.001). high viral load was independently associated with mortality (adjusted odds ratio [aor], 6.05; 95% confidence interval [ci], 2.92\u201312.52) and intubation (aor, 2.73; 95% ci, 1.68\u20134.44). \\n \\n \\n conclusions \\n admission sars-cov-2 viral load among hospitalized patients with covid-19 independently correlates with the risk of intubation and in-hospital mortality. providing this information to clinicians could potentially be used to guide patient care. \\n",
            "contribution_ids": [
                "R191303"
            ]
        },
        {
            "instance_id": "R193505xR191318",
            "comparison_id": "R193505",
            "paper_id": "R191318",
            "text": "Characteristics of viral specimens collected from asymptomatic and fatal cases of COVID-19 we sought to determine the characteristics of viral specimens associated with fatal cases, asymptomatic cases and non-fatal symptomatic cases of covid-19. this included the analysis of 1264 specimens found reactive for at least two sars-cov-2 specific loci from people screened for infection in northern nevada in march-may of 2020. of these, 30 were specimens from fatal cases, while 23 were from positive, asymptomatic cases. we assessed the relative amounts of sars-cov-2 rna from sample swabs by real-time pcr and use of the threshold crossing value (ct). moreover, we compared the amount of human rnase p found on the same swabs. a considerably higher viral load was found to be associated with swabs from cases involving fatality and the difference was found to be strongly statistically significant. noting this difference, we sought to assess whether any genetic correlation could be found in association with virus from fatal cases using whole genome sequencing. while no common genetic elements were discerned, one branch of epidemiologically linked fatal cases did have two point mutations, which no other of 156 sequenced cases from northern nevada had. the mutations caused amino acid changes in the 3\u2032-5\u2032 exonuclease protein, and the product of the gene, orf8.",
            "contribution_ids": [
                "R191320"
            ]
        },
        {
            "instance_id": "R193505xR191339",
            "comparison_id": "R193505",
            "paper_id": "R191339",
            "text": "SARS-CoV-2 viral load predicts COVID-19 mortality abstract the need for reliable and widely available sars-cov-2 testing is well recognized, but it will be equally necessary to develop quantitative methods that determine viral load in order to guide patient triage and medical decision making. we are the first to report that sars-cov-2 viral load at the time of presentation is an independent predictor of covid-19 mortality in a large patient cohort (n=1,145). viral loads should be used to identify higher-risk patients that may require more aggressive care and should be included as a key biomarker in the development of predictive algorithms.",
            "contribution_ids": [
                "R191341"
            ]
        },
        {
            "instance_id": "R193565xR192191",
            "comparison_id": "R193565",
            "paper_id": "R192191",
            "text": "Analysis of closed loop supply chain using genetic algorithm and particle swarm optimisation there are many reasons for the growing interest in reverse logistics. the most prominent reasons are the growing concern for the environment and cost reduction. next to environment, consumers demand for clean manufacturing and recycling. hence, customers and retailers expect original equipment manufacturers to set up a proper reverse logistics system and expect the returned products to be processed and recovered in an environmentally responsible way and another reason is cost reduction. a well-managed reverse logistics programme can provide important cost savings in procurement, disposal, inventory carrying and transportation. in this context, looking at the entire supply chain is the best starting point for solutions. supply chain management aims at the integration of traditional \u2018forward\u2019 supply chain processes, avoiding local optimisation by emphasising integrality. the main objective of this paper is to design an integrated forward logistics multi-echelon distribution inventory supply chain model (flmedim) and closed loop multi-echelon distribution inventory supply chain model (clmedim) for the built-to-order environment using genetic algorithm and particle swarm optimisation. in this paper, the proposed model is validated by considering two case studies: one for a tyre manufacturer and the other for a plastic goods manufacturer both located in the southern part of india. this paper utilises the multi-echelon distribution inventory supply chain model proposed by haq and kannan (2006a) for the flmedim. the software used was written in the java programming language.",
            "contribution_ids": [
                "R192193"
            ]
        },
        {
            "instance_id": "R193700xR193677",
            "comparison_id": "R193700",
            "paper_id": "R193677",
            "text": "Simulation analysis of supply chain risk management system based on IoT information platform abstract in this paper, iot (internet of things) information technology has been widely applied to the supply chain risk management (scrm). firstly, the source of risks has been sorted out, the external and internal risks have been described in detail with the risk management of supply chain system. secondly, the supply chain risk and case reasoning were mentioned. finally, the work actively explored the supply chain risk management by the iot information, such as 3g network, rfid and gps. the research on scrm based on iot information contributes to the construction and improvement of supply chain informatisation.",
            "contribution_ids": [
                "R193679"
            ]
        },
        {
            "instance_id": "R193700xR193694",
            "comparison_id": "R193700",
            "paper_id": "R193694",
            "text": "Assessing supply chain risk for apparel production in low cost countries using newsfeed analysis \\n purpose \\n with the growth of unstructured data, opportunities to generate insights into supply chain risks in low cost countries (lccs) are emerging. sourcing risk has primarily focused on short-term mitigation. this paper aims to offer an approach that uses newsfeed data to assess regional supply base risk in lcc\u2019s for the apparel sector, which managers can use to plan for future risk on a long-term planning horizon. \\n \\n \\n design/methodology/approach \\n this paper demonstrates that the bulk of supplier risk assessments focus on short-term responses to disruptions in developed countries, revealing a gap in assessments of long-term risks for supply base expansion in lccs. this paper develops an approach for predicting and planning for long-term supply base risk in lcc\u2019s to address this shortfall. a machine-based learning algorithm is developed that uses the analysis of competing hypotheses heuristic to convert data from multiple news feeds into numerical risk scores and visual maps of supply chain risk. this paper demonstrates the approach by converting large amounts of unstructured data into two measures, risk impact and risk probability, leading to visualization of country-level supply base risks for a global apparel company. \\n \\n \\n findings \\n this paper produced probability and impact scores for 23 distinct supply base risks across 10 countries in the apparel sector. the results suggest that the most significant long-term risks of supply disruption for apparel in lcc\u2019s are human resource regulatory risks, workplace issues, inflation costs, safety violations and social welfare violations. the results suggest that apparel brands seeking suppliers in the regions of cambodia, india, bangladesh, brazil and vietnam should be aware of the significant risks in these regions that may require mitigative action. \\n \\n \\n originality/value \\n this approach establishes a novel approach for objectively projecting future global sourcing risk, and yields visually mapped outcomes that can be applied in forecasting and planning for future risks when considering sourcing locations in lcc\u2019s. \\n",
            "contribution_ids": [
                "R193696"
            ]
        },
        {
            "instance_id": "R193700xR193697",
            "comparison_id": "R193700",
            "paper_id": "R193697",
            "text": "Extracting supply chain maps from news articles using deep neural networks \"supply chains are increasingly global, complex and multi-tiered. consequently, companies often struggle to maintain complete visibility of their supply network. this poses a problem as visibility of the network structure is required for tasks like effectively managing supply chain risk. in this paper, we discuss automated supply chain mapping as a means of maintaining structural visibility of a company's supply chain, and we use deep learning to automatically extract buyer\u2013supplier relations from natural language text. early results show that supply chain mapping solutions using natural language processing and deep learning could enable companies to (a) automatically generate rudimentary supply chain maps, (b) verify existing supply chain maps, or (c) augment existing maps with additional supplier information.\"",
            "contribution_ids": [
                "R193699"
            ]
        },
        {
            "instance_id": "R194697xR129608",
            "comparison_id": "R194697",
            "paper_id": "R129608",
            "text": "Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing \\n pretraining large neural language models, such as bert, has led to impressive gains on many natural language processing (nlp) tasks. however, most pretraining efforts focus on general domain corpora, such as newswire and web. a prevailing assumption is that even domain-specific pretraining can benefit by starting from general-domain language models. in this article, we challenge this assumption by showing that for domains with abundant unlabeled text, such as biomedicine, pretraining language models from scratch results in substantial gains over continual pretraining of general-domain language models. to facilitate this investigation, we compile a comprehensive biomedical nlp benchmark from publicly available datasets. our experiments show that domain-specific pretraining serves as a solid foundation for a wide range of biomedical nlp tasks, leading to new state-of-the-art results across the board. further, in conducting a thorough evaluation of modeling choices, both for pretraining and task-specific fine-tuning, we discover that some common practices are unnecessary with bert models, such as using complex tagging schemes in named entity recognition. to help accelerate research in biomedical nlp, we have released our state-of-the-art pretrained and task-specific models for the community, and created a leaderboard featuring our blurb benchmark (short for biomedical language understanding &amp; reasoning benchmark) at\\n https://aka.ms/blurb \\n .\\n",
            "contribution_ids": [
                "R129609",
                "R194667",
                "R194670",
                "R194681",
                "R194672",
                "R194674",
                "R194682",
                "R194683",
                "R194684",
                "R194685"
            ]
        },
        {
            "instance_id": "R196613xR196553",
            "comparison_id": "R196613",
            "paper_id": "R196553",
            "text": "Domain Independent Automatic Labeling system for Large-scale Social Data using Lexicon and Web-based Augmentation recently, with the large-scale adoption of social media, people have begun to express their opinion on these sites in the form of reviews. potential consumers often forced to wade through huge amount of reviews to make informed decision. sentiment analysis has become rapid and effective way to automatically gauge consumers\u2019 opinion. however, such analysis often requires tedious process of manual tagging of large training examples or manually building a lexicon for the purpose of classifying reviews as positive or negative. in this paper, we present a method to automate the tedious process of labeling large textual data in an unsupervised, domain independent and scalable manner. the proposed method combines the lexicon-based and web-based point wise mutual information (pmi) statistics to find the semantic orientation (so) of opinion expressed in a review.\\xa0 based on proposed methods a system called domain independent automatic labeling system (dials) has been implemented, which takes collection of text from any domain as input and generates fully labeled dataset in an unsupervised and scalable manner. the result generated can be used to track and summarize online discussion and/or use to train any classifier in the next stage of development. the effectiveness of system is tested by comparing it with baseline machine learning and lexicon-based methods. experiments on multi-domains dataset has shown that proposed method consistently shown improved recall and accuracy as compared to baseline machine learning and lexicon-based methods.\\xa0\\xa0\\xa0",
            "contribution_ids": [
                "R196555"
            ]
        },
        {
            "instance_id": "R196613xR196605",
            "comparison_id": "R196613",
            "paper_id": "R196605",
            "text": "Sentiment Analysis of Persian Movie Reviews Using Deep Learning sentiment analysis aims to automatically classify the subject\u2019s sentiment (e.g., positive, negative, or neutral) towards a particular aspect such as a topic, product, movie, news, etc. deep learning has recently emerged as a powerful machine learning technique to tackle the growing demand for accurate sentiment analysis. however, the majority of research efforts are devoted to english-language only, while information of great importance is also available in other languages. this paper presents a novel, context-aware, deep-learning-driven, persian sentiment analysis approach. specifically, the proposed deep-learning-driven automated feature-engineering approach classifies persian movie reviews as having positive or negative sentiments. two deep learning algorithms, convolutional neural networks (cnn) and long-short-term memory (lstm), are applied and compared with our previously proposed manual-feature-engineering-driven, svm-based approach. simulation results demonstrate that lstm obtained a better performance as compared to multilayer perceptron (mlp), autoencoder, support vector machine (svm), logistic regression and cnn algorithms.",
            "contribution_ids": [
                "R196608"
            ]
        },
        {
            "instance_id": "R197259xR196928",
            "comparison_id": "R197259",
            "paper_id": "R196928",
            "text": "Detection of human norovirus in intestinal biopsies from immunocompromised transplant patients human noroviruses (hunovs) can often cause chronic infections in solid organ and haematopoietic stem cell transplant (hsct) patients. based on histopathological changes observed during hunov infections, the intestine is the presumed site of virus replication in patients; however, the cell types infected by hunovs remain unknown. the objective of this study was to characterize histopathological changes during hunov infection and to determine the cell types that may be permissive for hunov replication in transplant patients. we analysed biopsies from hunov-infected and non-infected (control) transplant patients to assess histopathological changes in conjunction with detection of hunov antigens to identify the infected cell types. hunov infection in immunocompromised patients was associated with histopathological changes such as disorganization and flattening of the intestinal epithelium. the hunov major capsid protein, vp1, was detected in all segments of the small intestine, in areas of biopsies that showed histopathological changes. specifically, vp1 was detected in enterocytes, macrophages, t cells and dendritic cells. hunov replication was investigated by detecting the non-structural proteins, rdrp and vpg. we detected rdrp and vpg along with vp1 in duodenal and jejunal enterocytes. these results provide critical insights into histological changes due to hunov infection in immunocompromised patients and propose human enterocytes as a physiologically relevant cell type for hunov cultivation.",
            "contribution_ids": [
                "R196930",
                "R196956"
            ]
        },
        {
            "instance_id": "R197259xR196942",
            "comparison_id": "R197259",
            "paper_id": "R196942",
            "text": "Human norovirus targets enteroendocrine epithelial cells in the small intestine abstract human noroviruses are a major cause of diarrheal illness, but pathogenesis is poorly understood. here, we investigate the cellular tropism of norovirus in specimens from four immunocompromised patients. abundant norovirus antigen and rna are detected throughout the small intestinal tract in jejunal and ileal tissue from one pediatric intestinal transplant recipient with severe gastroenteritis. negative-sense viral rna, a marker of active viral replication, is found predominantly in intestinal epithelial cells, with chromogranin a-positive enteroendocrine cells (eecs) identified as a permissive cell type in this patient. these findings are consistent with the detection of norovirus-positive eecs in the other three immunocompromised patients. investigation of the signaling pathways induced in eecs that mediate communication between the gut and brain may clarify mechanisms of pathogenesis and lead to the development of in vitro model systems in which to evaluate norovirus vaccines and treatment.",
            "contribution_ids": [
                "R196946",
                "R196989"
            ]
        },
        {
            "instance_id": "R197259xR197081",
            "comparison_id": "R197259",
            "paper_id": "R197081",
            "text": "Chimpanzees as an animal model for human norovirus infection and vaccine development noroviruses are global agents of acute gastroenteritis, but the development of control strategies has been hampered by the absence of a robust animal model. studies in chimpanzees have played a key role in the characterization of several fastidious hepatitis viruses, and we investigated the feasibility of such studies for the noroviruses. seronegative chimpanzees inoculated i.v. with the human norovirus strain norwalk virus (nv) did not show clinical signs of gastroenteritis, but the onset and duration of virus shedding in stool and serum antibody responses were similar to that observed in humans. nv rna was detected in intestinal and liver biopsies concurrent with the detection of viral shedding in stool, and nv antigen expression was observed in cells of the small intestinal lamina propria. two infected chimpanzees rechallenged 4, 10, or 24 mo later with nv were resistant to reinfection, and the presence of nv-specific serum antibodies correlated with protection. we evaluated the immunogenicity and efficacy of virus-like particles (vlps) derived from nv (genogroup i, gi) and md145 (genogroup ii, gii) noroviruses as vaccines. chimpanzees vaccinated intramuscularly with gi vlps were protected from nv infection when challenged 2 and 18 mo after vaccination, whereas chimpanzees that received gii vlps vaccine or a placebo were not. this study establishes the chimpanzee as a viable animal model for the study of norovirus replication and immunity, and shows that nv vlp vaccines could induce protective homologous immunity even after extended periods of time.",
            "contribution_ids": [
                "R197083",
                "R197114"
            ]
        },
        {
            "instance_id": "R198562xR195616",
            "comparison_id": "R198562",
            "paper_id": "R195616",
            "text": "Emission Variations of Primary Air Pollutants from Highway Vehicles and Implications during the COVID-19 Pandemic in Beijing, China according to the traffic flow variation from january 2019 to august 2020, emissions of primary air pollutants from highway vehicles were calculated based on the emission factor method, which integrated the actual structure of on-road vehicles. the characteristics of on-highway traffic flow and pollution emissions were compared during various progression stages of coronavirus disease (covid-19). the results showed that the average daily traffic volume decreased by 38.2% in 2020, with a decrease of 62% during the strict lockdown due to the impact of covid-19. the daily emissions of primary atmospheric pollutants decreased by 29.2% in 2020 compared to the same period in 2019. as for the structure of on-highway vehicle types, the small and medium-sized passenger vehicles predominated, which accounted for 76.3% of traffic, while trucks and large passenger vehicles accounted for 19.7% and 4.0%, but contributed 58.4% and 33.9% of nitrogen oxide (nox) emissions, respectively. according to the simulation results of the adms model, the average concentrations of nox were reduced by 12.0 \u00b5g/m3 compared with the same period in 2019. as for the implication for future pollution control, it is necessary to further optimize the structure of on-highway and the road traffic vehicle types and increase the proportions of new-energy vehicles and vehicles with high emission standards.",
            "contribution_ids": [
                "R195619",
                "R200031"
            ]
        },
        {
            "instance_id": "R198562xR196747",
            "comparison_id": "R198562",
            "paper_id": "R196747",
            "text": "Differential Effects of the COVID-19 Lockdown and Regional Fire on the Air Quality of Medell\u00c3\u00adn, Colombia governments\u2019 responses to the covid-19 pandemic provide a unique opportunity to study the effects of restricted socioeconomic activity on air quality. here, we study the changes in air pollution levels during the lockdown in medell\u00edn and its metropolitan area, colombia, for periods with and without enhanced regional fire activity, considering the effects of meteorology using random forest and multiple linear regression methods. the lockdown measures, which reduced mean traffic volume by 70% compared to 2016\u20132019, resulted in reductions for pm2.5 (50\u201363%), pm10 (59\u201364%), no (75\u201376%), no2 (43\u201347%), and co (40\u201347%), while o3 concentration increased by 19\u201322%. in contrast, when fire activity was high, the effects of the lockdown on air quality were shadowed by the long-range transport of biomass burning emissions, increasing fine particulate matter and ozone. this study shows that healthier levels are achievable through significant efforts from decision-makers and society. the results highlight the need to develop integral measures that do not only consider reductions in the local emissions from transportation and industry, but also the role of fire activity in the region, as well as the difficulties of achieving reductions in ozone from measures that are effective at reducing primary pollutants.",
            "contribution_ids": [
                "R196748",
                "R200063",
                "R200087",
                "R200133",
                "R200136",
                "R200139",
                "R200142"
            ]
        },
        {
            "instance_id": "R199173xR197551",
            "comparison_id": "R199173",
            "paper_id": "R197551",
            "text": "Non-Uniform Adversarially Robust Pruning neural networks often are highly redundant and can thus be effectively compressed to a fraction of their initial size using model pruning techniques without harming the overall prediction accuracy. additionally, pruned networks need to maintain robustness against attacks such as adversarial examples. recent research on combining all these objectives has shown significant advances using uniform compression strategies, that is, all weights or channels are compressed equally according to a preset compression ratio. in this paper, we show that employing non-uniform compression strategies allows to significantly improve clean data accuracy as well as adversarial robustness under high overall compression. we leverage reinforcement learning for finding an optimal trade-off and demonstrate that the resulting compression strategy can be used as a plug-in replacement for uniform compression ratios of existing state-of-the-art approaches.",
            "contribution_ids": [
                "R197552"
            ]
        },
        {
            "instance_id": "R199173xR197592",
            "comparison_id": "R199173",
            "paper_id": "R197592",
            "text": "What to expect of hardware metric predictors in NAS modern neural architecture search (nas) focuses on finding the best performing architectures in hardware-aware settings; e.g., those with an optimal tradeoff of accuracy and latency. due to many advantages of prediction models over live measurements, the search process is often guided by estimates of how well each considered network architecture performs on the desired metrics. typical prediction models range from operation-wise lookup tables over gradient-boosted trees and neural networks, with little known information on how they compare. we evaluate 18 different performance predictors on ten combinations of metrics, devices, network types, and training tasks, and find that mlp models are the most promising. we then simulate and evaluate how the guidance of such prediction models affects the subsequent architecture selection. due to inaccurate predictions, the selected architectures are generally suboptimal, which we quantify as an expected reduction in accuracy and hypervolume. we show that simply verifying the predictions of just the selected architectures can lead to substantially improved results. under a time budget, we find it preferable to use a fast and inaccurate prediction model over accurate but slow live measurements. code and results are available at https://github.com/cogsys-tuebingen/naslib",
            "contribution_ids": [
                "R197593"
            ]
        },
        {
            "instance_id": "R199173xR197596",
            "comparison_id": "R199173",
            "paper_id": "R197596",
            "text": "Differentiable Architecture Search for Reinforcement Learning in this paper, we investigate the fundamental question: to what extent are gradient-based neural architecture search (nas) techniques applicable to rl? using the original darts as a convenient baseline, we discover that the discrete architectures found can achieve up to 250% performance compared to manual architecture designs on both discrete and continuous action space environments across o-policy and on-policy rl algorithms, at only 3x more computation time. furthermore, through numerous ablation studies, we systematically verify that not only does darts correctly upweight operations during its supernet phrase, but also gradually improves resulting discrete cells up to 30x more eciently than random search, suggesting darts is surprisingly an eective tool for improving architectures in rl.",
            "contribution_ids": [
                "R197597"
            ]
        },
        {
            "instance_id": "R199176xR198117",
            "comparison_id": "R199176",
            "paper_id": "R198117",
            "text": "FOODS: A Food-Oriented Ontology-Driven System in this paper the authors present the design and development of a counseling system for food or menu planning in a restaurant, clinic/hospital, or at home, the food-oriented ontology-driven system (foods). foods comprises (a) a food ontology, (b) an expert system using the ontology, and some knowledge about cooking methods and prices, and (c) a user interface suitable for novices in computers and diets as well as for experts. the ontology contains specifications of ingredients, substances, nutrition facts, recommended daily intakes for different regions, dishes, and menus. the expert system assists in finding the appropriate dish or menu for the consumer, client or customer, who use foods by entering their favorite ingredients, ingredients to avoid, favorite flavors, and so on. in the health section users can provide their gender, age, height and weight, which will be used to calculate such data as the body mass index. with foods enterprises can assist customers through an appropriate suggestion of dishes and meals with the help of individual nutritional profiles. smes that might be interested in using foods are institutions for training and instruction of cooking, restaurants, clinics, hospitals, together with clinical and therapeutical dietitians and nutritional therapists. in the long run such systems might become part of the emerging consumer health informatics portfolio.",
            "contribution_ids": [
                "R198119",
                "R198120",
                "R198121"
            ]
        },
        {
            "instance_id": "R200035xR199183",
            "comparison_id": "R200035",
            "paper_id": "R199183",
            "text": "Exposure to Human and Bovine Noroviruses in a Birth Cohort in Southern India from 2002 to 2006 abstract \\n human and bovine norovirus virus-like particles were used to evaluate antibodies in indian children at ages 6 and 36 months and their mothers. antibodies to genogroup ii viruses were acquired early and were more prevalent than antibodies to genogroup i. low levels of igg antibodies against bovine noroviruses indicate possible zoonotic transmission.",
            "contribution_ids": [
                "R199185",
                "R199194",
                "R199195"
            ]
        },
        {
            "instance_id": "R200035xR200014",
            "comparison_id": "R200035",
            "paper_id": "R200014",
            "text": "Presence of Antibodies against Genogroup VI Norovirus in Humans abstract \\n \\n background \\n noroviruses are important enteric pathogens in humans and animals. recently, we reported a novel canine norovirus (canov) in dogs with diarrhea belonging to a new genogroup (gvi). no data are available on exposure of humans to this virus. \\n \\n \\n methods \\n sera from 373 small animal veterinarians and 120 age-matched population controls were tested for igg antibodies to canov by a recombinant virus like particle based enzyme-linked immunosorbent assay. \\n \\n \\n results \\n antibodies to canov were found in 22.3% of the veterinarians and 5.8% of the control group (p\\u2009&lt;\\u20090.001). mean corrected od 450 values for canov antibodies were significantly higher in small animal veterinarians compared to the control group. \\n \\n \\n conclusions \\n these findings suggest that canov may infect humans and small animal veterinarians are at an increased risk for exposure to this virus. additional studies are needed to assess if this virus is able to cause disease in humans. \\n",
            "contribution_ids": [
                "R200016",
                "R200017"
            ]
        },
        {
            "instance_id": "R201263xR189415",
            "comparison_id": "R201263",
            "paper_id": "R189415",
            "text": "Byssal threads inspired ionic cross-linked narce-like graphene oxide paper with superior mechanical strength \"artificial nacre-like graphene oxide paper has sparked great excitement in the scientific community for its unique properties. the preparation of a bioinspired high-strength nanocomposite paper via a simple vacuum-assisted assembly technique from graphene oxide (go), tannic acid (ta) and fe3+ ions is reported in this article. the fabricated papers were characterized by x-ray diffraction (xrd), scanning electron microscopy (sem), thermogravimetric analysis (tga), fourier transformed infrared (ftir) spectroscopy, x-ray photoelectron spectroscopy (xps) and dynamic mechanical analysis (dma). we show that fe3+ ions only induce limited improvement in the mechanical properties of the graphene oxide paper, while the efficient cross-linking of neighboring sheets by fe3+\u2013ta complex network can significantly improve the fracture strength and young's modulus of graphene oxide paper by 150% and 521%, respectively, with an optimal content of 5.7 wt% fe3+. with general surface binding affinity, ta molecules can be adsorbed to go sheets and provide binding sites for fe3+. the fe3+\u2013ta coordinated compound serves as the \u201cmortar\u201d to stick the go \u201cbricks\u201d together. the mechanical properties of our paper can be simply varied by controlling the cross-linking condition. the obtained nacre-like ultrastrong go papers could find potential in energy and sustainability applications.\"",
            "contribution_ids": [
                "R189417"
            ]
        },
        {
            "instance_id": "R201263xR189421",
            "comparison_id": "R201263",
            "paper_id": "R189421",
            "text": "Bio-Inspired Borate Cross-Linking in Ultra-Stiff Graphene Oxide Thin Films adjacent graphene oxide nanosheets in a thin-film structure have been covalently cross-linked in a fashion similar to the cell walls of higher-order plants. the resulting ultra-stiff structure exhibits a maximum storage modulus of 127 gpa that can be tuned by varying borate concentration.",
            "contribution_ids": [
                "R189422"
            ]
        },
        {
            "instance_id": "R201263xR189429",
            "comparison_id": "R201263",
            "paper_id": "R189429",
            "text": "The Effect of Interlayer Adhesion on the Mechanical Behaviors of Macroscopic Graphene Oxide Papers \"high mechanical performances of macroscopic graphene oxide (go) papers are attracting great interest owing to their merits of lightweight and multiple functionalities. however, the loading role of individual nanosheets and its effect on the mechanical properties of the macroscopic go papers are not yet well understood. herein, we effectively tailored the interlayer adhesions of the go papers by introducing small molecules, that is, glutaraldehyde (ga) and water molecules, into the gallery regions. with the help of in situ raman spectroscopy, we compared the varied load-reinforcing roles of nanosheets, and further predicted the young's moduli of the go papers. systematic mechanical tests have proven that the enhancement of the tensile modulus and strength of the ga-treated go paper arose from the improved load-bearing capability of the nanosheets. on the basis of raman and macroscopic mechanical tests, the influences of interlayer adhesions on the fracture mechanisms of the strained go papers were inferred.\"",
            "contribution_ids": [
                "R189431"
            ]
        },
        {
            "instance_id": "R201972xR201885",
            "comparison_id": "R201972",
            "paper_id": "R201885",
            "text": "Upper limb joint angle measurement in occupational health usual human motion capture systems are designed to work in controlled laboratory conditions. for occupational health, instruments that can measure during normal daily life are essential, as the evaluation of the workers' movements is a key factor to reduce employee injury- and illness-related costs. in this paper, we present a method for joint angle measurement, combining inertial sensors (accelerometers and gyroscopes) and magnetic sensors. this method estimates wrist flexion, wrist lateral deviation, elbow flexion, elbow pronation, shoulder flexion, shoulder abduction and shoulder internal rotation. the algorithms avoid numerical integration of the signals, which allows for long-time estimations without angle estimation drift. the system has been tested both under laboratory and field conditions. controlled laboratory tests show mean estimation errors between 0.06\u00b0 and of 1.05\u00b0, and standard deviation between 2.18\u00b0 and 9.20\u00b0. field tests seem to confirm these results when no ferromagnetic materials are close to the measurement system.",
            "contribution_ids": [
                "R201887"
            ]
        },
        {
            "instance_id": "R201972xR201888",
            "comparison_id": "R201972",
            "paper_id": "R201888",
            "text": "A Novel Kalman Filter for Human Motion Tracking With an Inertial-Based Dynamic Inclinometer goal: design and development of a linear kalman filter to create an inertial-based inclinometer targeted to dynamic conditions of motion. methods: the estimation of the body attitude (i.e., the inclination with respect to the vertical) was treated as a source separation problem to discriminate the gravity and the body acceleration from the specific force measured by a triaxial accelerometer. the sensor fusion between triaxial gyroscope and triaxial accelerometer data was performed using a linear kalman filter. wrist-worn inertial measurement unit data from ten participants were acquired while performing two dynamic tasks: 60-s sequence of seven manual activities and 90 s of walking at natural speed. stereophotogrammetric data were used as a reference. a statistical analysis was performed to assess the significance of the accuracy improvement over state-of-the-art approaches. results: the proposed method achieved, on an average, a root mean square attitude error of 3.6\u00b0 and 1.8\u00b0 in manual activities and locomotion tasks (respectively). the statistical analysis showed that, when compared to few competing methods, the proposed method improved the attitude estimation accuracy. conclusion: a novel kalman filter for inertial-based attitude estimation was presented in this study. a significant accuracy improvement was achieved over state-of-the-art approaches, due to a filter design that better matched the basic optimality assumptions of kalman filtering. significance: human motion tracking is the main application field of the proposed method. accurately discriminating the two components present in the triaxial accelerometer signal is well suited for studying both the rotational and the linear body kinematics.",
            "contribution_ids": [
                "R201890"
            ]
        },
        {
            "instance_id": "R201972xR201900",
            "comparison_id": "R201972",
            "paper_id": "R201900",
            "text": "A wearable inertial-sensing-based body sensor network for shoulder range of motion assessment this paper presents a wearable inertial-sensing-based body sensor network (bsn) composed of two inertial modules that are placed on human upper limb for real-time human motion capture applications. each inertial module consists of an arm-based 32-bit microcontroller (mcu), a triaxial accelerometer, a triaxial gyroscope, and a triaxial magnetometer. to estimate shoulder range of motion (rom), the accelerations, angular velocities, and magnetic signals are collected and processed by a quaternion-based complementary nonlinear filter for minimizing the cumulative errors caused by the intrinsic noise/drift of the inertial sensors. the proposed bsn is a cost-effective tool and can be used anywhere without any external reference device for shoulder rom. the sensor fusion algorithm can reduce orientation error effectively and thus can assess shoulder joint motions accurately.",
            "contribution_ids": [
                "R201902"
            ]
        },
        {
            "instance_id": "R201972xR201909",
            "comparison_id": "R201972",
            "paper_id": "R201909",
            "text": "Ambulatory human upper limb joint motion monitoring in order to make an ergonomic analysis of laborer working conditions, we need to measure the different joint angles along the daily work. these angles will be used to define the requirements of each workstation. this information, together with the medical examination of each worker, is then used to determine whether a worker can develop a task, or if the task may have caused an occupational disease. usual human motion capture systems are designed to work in laboratory controlled conditions. this paper presents a method of angular joint measurement, combining inertial sensors (accelerometers and gyroscopes) and magnetic sensors, which allows the ambulatory estimation of the 7 degrees of freedom of the upper limb, for a long time, without problems due to time integration of the signal.",
            "contribution_ids": [
                "R201911"
            ]
        },
        {
            "instance_id": "R201972xR201921",
            "comparison_id": "R201972",
            "paper_id": "R201921",
            "text": "Towards Miniaturization of a MEMS-Based Wearable Motion Capture System this paper presents a modular architecture to develop a wearable system for real-time human motion capture. the system is based on a network of smart inertial measurement units (imus) distributed on the human body. each of these modules is provided with a 32-bit risc microcontroller (mcu) and miniaturized mems sensors: three-axis accelerometer, three-axis gyroscopes, and three-axis magnetometer. the mcu collects measurements from the sensors and implement the sensor fusion algorithm, a quaternion-based extended kalman filter to estimate the attitude and the gyroscope biases. the design of the proposed imu, in order to overcome the problems of the commercial solution, aims to improve performance and to reduce size and weight. in this way, it can be easily embedded in a tracksuit for total body motion reconstruction with considerable enhancement of the wearability and comfort. furthermore, the main achievements will be presented with a performance comparison between the proposed imu and some commercial platforms.",
            "contribution_ids": [
                "R201923"
            ]
        },
        {
            "instance_id": "R201972xR201933",
            "comparison_id": "R201972",
            "paper_id": "R201933",
            "text": "A Fast Quaternion-Based Orientation Optimizer via Virtual Rotation for Human Motion Tracking for real-time ambulatory human motion tracking with low-cost inertial/magnetic sensors, a computationally efficient and robust algorithm for estimating orientation is critical. this paper presents a quaternion-based orientation optimizer for tracking human body motion, using triaxis rate gyro, accelerometer, and magnetometer signals. the proposed optimizer uses a gauss-newton (g-n) method for finding the best-fit quaternion. in order to decrease the computing time, the optimizer is formulated using a virtual rotation concept that allows very fast quaternion updates compared to the conventional g-n method. in addition, to guard against the effects of fast body motions and temporary ferromagnetic disturbances, a situational measurement vector selection procedure is adopted in conjunction with the g-n optimizer. the accuracy of orientation estimates is validated experimentally, using arm motion trials.",
            "contribution_ids": [
                "R201935"
            ]
        },
        {
            "instance_id": "R202077xR201686",
            "comparison_id": "R202077",
            "paper_id": "R201686",
            "text": "Accuracy Assessment of Kriging, artificial neural network, and a hybrid approach integrating spatial and terrain data in estimating and mapping of soil organic carbon this study aimed to produce a soil organic carbon (soc) content map with high accuracy and spatial resolution using the most effective factors in the model. the spatial soc estimation success of inverse distance weighting (idw), ordinary kriging (ok), empirical bayesian kriging (ebk), multi-layered perception network (mlp) and mlp-ok hybrid models were compared to obtain the most reliable model in estimating the soc content. the study area was located in besni district in the southeastern anatolia region of turkey. total of 132 surface (0\u201330 cm) soil samples were collected from the covers 1330 km 2 land and analyzed for soc, lime, clay and sand content and soil reaction included in the estimation models. mean annual precipitation and temperature, elevation, compound topographic index, enhanced vegetation and normalized difference vegetation index, were also used as the inputs in the modelling. the spatial distribution of soc was determined using a mlp and a two-stage ensemble model (mlp-ok) combining the estimation of ok residuals. soil surveys and covariates were used to train and validate the mlp-ok hybrid model. the mlp-ok model provided a more accurate estimation of soc content with minimal estimation errors (me: -0.028, 45 mae: 0.042, rmse: 0.066) for validation points compared to the other models. the mlp-ok model outperformed other models by 75.09 to 77.92%. the mlp-ok model estimated the lower and upper limits of the estimated and the measured values in a consistent manner compared to the other models. the spatial distribution map of soc content obtained by ann-kriging approach was significantly affected by ancillary variables, and revealed more detail than other interpolation methods in the northern, central, southwestern and southeastern parts of the study area. the results revealed that the assembling of mlp with ok model can contribute to obtain more reliable regional, national and global spatial soil information.",
            "contribution_ids": [
                "R201688"
            ]
        },
        {
            "instance_id": "R202077xR201997",
            "comparison_id": "R202077",
            "paper_id": "R201997",
            "text": "Ensemble Machine Learning Approach Improves Predicted Spatial Variation of Surface Soil Organic Carbon Stocks in Data-Limited Northern Circumpolar Region various approaches of differing mathematical complexities are being applied for spatial prediction of soil properties. regression kriging is a widely used hybrid approach of spatial variation that combines correlation between soil properties and environmental factors with spatial autocorrelation between soil observations. in this study, we compared four machine learning approaches (gradient boosting machine, multinarrative adaptive regression spline, random forest, and support vector machine) with regression kriging to predict the spatial variation of surface (0\u201330 cm) soil organic carbon (soc) stocks at 250-m spatial resolution across the northern circumpolar permafrost region. we combined 2,374 soil profile observations (calibration datasets) with georeferenced datasets of environmental factors (climate, topography, land cover, bedrock geology, and soil types) to predict the spatial variation of surface soc stocks. we evaluated the prediction accuracy at randomly selected sites (validation datasets) across the study area. we found that different techniques inferred different numbers of environmental factors and their relative importance for prediction of soc stocks. regression kriging produced lower prediction errors in comparison to multinarrative adaptive regression spline and support vector machine, and comparable prediction accuracy to gradient boosting machine and random forest. however, the ensemble median prediction of soc stocks obtained from all four machine learning techniques showed highest prediction accuracy. although the use of different approaches in spatial prediction of soil properties will depend on the availability of soil and environmental datasets and computational resources, we conclude that the ensemble median prediction obtained from multiple machine learning approaches provides greater spatial details and produces the highest prediction accuracy. thus an ensemble prediction approach can be a better choice than any single prediction technique for predicting the spatial variation of soc stocks.",
            "contribution_ids": [
                "R201999"
            ]
        },
        {
            "instance_id": "R202360xR202272",
            "comparison_id": "R202360",
            "paper_id": "R202272",
            "text": "Cooperative Privacy Preservation for Wearable Devices in Hybrid Computing-Based Smart Health along with an integration of wearable devices, wireless communications and big data in the smart health, biomedical data is collected referring to multiple associated patients during interactions. due to communication channel openness and data sensibility, privacy preservation become increasingly noteworthy in the edge and cloud hybrid computing-based healthcare applications. in this paper, a cooperative privacy preservation scheme is designed for wearable devices with identity authentication and data access control considerations in the space-aware and time-aware contexts. in the space-aware edge computing mode, secret sharing and minhash-based authentication is designed to enhance privacy preservation along with similarity computing without revealing sensitive data. in the time-aware cloud computing mode, ciphertext policy attribute-based encryption is applied for fine-grained access control, and bloom filter is used to achieve efficient data structure without privacy exposure. the gny logic-based security formal analysis is performed to prove theoretical correctness, and the proposed scheme achieves cooperative privacy preservation for wearable devices in smart health with communication overhead and computation cost.",
            "contribution_ids": [
                "R202276"
            ]
        },
        {
            "instance_id": "R202360xR202265",
            "comparison_id": "R202360",
            "paper_id": "R202265",
            "text": "Multiauthority Access Control With Anonymous Authentication for Personal Health Record a personal health record (phr) system is a smart health system that serves patients and doctors. a phr is usually stored in a cloud and managed by a semitrusted cloud provider. however, there is still a possibility of the exposure of personal health information to semitrusted parties and unauthorized users. to protect the privacy of patients and ensure that patients can control their phrs, a patient-centric phr sharing framework is proposed in this article. in this framework, all phrs are protected with multiauthority attribute-based encryption before outsourcing, which solves the key hosting problem and achieves fine-grained access control to phrs. furthermore, an anonymous authentication between the cloud and the user is proposed to ensure data integrity on the cloud while not exposing the user\u2019s identity during authentication. the proposed authentication is issued from a new online\u2013offline attribute-based signature. it can make the encrypted phrs resist collusion attacks and not be forged during the period of sharing, which enhances patients\u2019 control of their phrs. online\u2013offline and outsourcing decryption also reduces calculation costs and improves operational efficiency. finally, comparisons are given based on numerical experiments.",
            "contribution_ids": [
                "R202270"
            ]
        },
        {
            "instance_id": "R203903xR203579",
            "comparison_id": "R203903",
            "paper_id": "R203579",
            "text": "Detection of sinkhole attack in wireless sensor networks generally wireless sensor networks rely of many-to-one communication approach for data gathering. this approach is extremely susceptible to sinkhole attack, where an intruder attracts surrounding nodes with unfaithful routing information, and subsequently presents selective forwarding or change the data that carry through it. a sinkhole attack causes an important threat to sensor networks and it should be considered that the sensor nodes are mostly spread out in open areas and of weak computation and battery power. in order to detect the intruder in a sinkhole attack this paper suggests an algorithm which firstly finds a group of suspected nodes by analyzing the consistency of data. then, the intruder is recognized efficiently in the group by checking the network flow information. the proposed algorithm's performance has been evaluated by using numerical analysis and simulations. therefore, accuracy and efficiency of algorithm would be verified.",
            "contribution_ids": [
                "R203581"
            ]
        },
        {
            "instance_id": "R204005xR201735",
            "comparison_id": "R204005",
            "paper_id": "R201735",
            "text": "Frequent Detection of Noroviruses and Sapoviruses in Swine and High Genetic Diversity of Porcine Sapovirus in Japan during Fiscal Year 2008 abstract a molecular biological survey on porcine norovirus (nov) and sapovirus (sav) was conducted in toyama prefecture, japan, during fiscal year 2008. both nov and sav were detected from swine fecal samples throughout the surveillance period, indicating that these viruses were circulating in this region. nov strains detected in this study belonged to three genotypes that are known as typical swine novs. although human novs were occasionally detected, it was unclear whether they replicated in pigs. as for sav, genogroup vii (gvii) and other divergent genogroups were identified in addition to the dominant genogroup, giii, which is the prototypic porcine sav. in addition, 3 strains genetically related to human sav were detected. two of these 3 strains were closely related to human sav gv. our study showed that genetic diversification of porcine sav is currently progressing in the swine population.",
            "contribution_ids": [
                "R201737"
            ]
        },
        {
            "instance_id": "R204005xR201760",
            "comparison_id": "R204005",
            "paper_id": "R201760",
            "text": "Human Noroviruses in Swine and Cattle detection of gii.4 norovirus sequences in animal fecal samples and retail meats demonstrates that noroviruses may be transmitted zoonotically.",
            "contribution_ids": [
                "R201762",
                "R201764"
            ]
        },
        {
            "instance_id": "R204005xR201779",
            "comparison_id": "R204005",
            "paper_id": "R201779",
            "text": "Natural Norovirus Infections in Rhesus Macaques using a recently developed real-time reverse transcription pcr, i retested 500 fecal samples from rhesus macaques collected in 2008. previous conventional reverse transcription pcr testing identified 1 isolate of gii norovirus; retesting found gi, gii, and possible giv noroviruses in the samples, indicating the natural circulation of noroviruses in nonhuman primate colonies.",
            "contribution_ids": [
                "R201781"
            ]
        },
        {
            "instance_id": "R204005xR201975",
            "comparison_id": "R204005",
            "paper_id": "R201975",
            "text": "Complete Genome Sequence of a GII.17 Norovirus Isolated from a Rhesus Monkey in China abstract the previously silent gii.17 norovirus was found to be the predominant genotype causing major epidemics in china in the 2014\u20132015 winter epidemic season. we report here the complete genomic sequence of a gii.17 norovirus (mky/gii.17/km1509/chn/2015) that infected rhesus monkeys at a monkey farm in southwestern china.",
            "contribution_ids": [
                "R201977"
            ]
        },
        {
            "instance_id": "R204005xR203981",
            "comparison_id": "R204005",
            "paper_id": "R203981",
            "text": "Evidence for Human Norovirus Infection of Dogs in the United Kingdom abstract human noroviruses (hunovs) are a major cause of viral gastroenteritis, with an estimated 3 million cases per year in the united kingdom. hunovs have recently been isolated from pet dogs in europe (m. summa, c.-h. von bonsdorff, and l. maunula, j clin virol 53:244\u2013247, 2012, http://dx.doi.org/10.1016/j.jcv.2011.12.014 ), raising concerns about potential zoonotic infections. with 31% of united kingdom households owning a dog, this could prove to be an important transmission route. to examine this risk, canine tissues were studied for their ability to bind to hunov in vitro . in addition, canine stool samples were analyzed for the presence of viral nucleic acid, and canine serum samples were tested for the presence of anti-hunov antibodies. the results showed that seven different genotypes of hunov virus-like particles (vlps) can bind to canine gastrointestinal tissue, suggesting that infection is at least theoretically possible. although hunov rna was not identified in stool samples from 248 dogs, serological evidence of previous exposure to hunov was obtained in 43/325 canine serum samples. remarkably, canine seroprevalence for different hunov genotypes mirrored the seroprevalence in the human population. though entry and replication within cells have not been demonstrated, the canine serological data indicate that dogs produce an immune response to hunov, implying productive infection. in conclusion, this study reveals zoonotic implications for hunov, and to elucidate the significance of this finding, further epidemiological and molecular investigations will be essential.",
            "contribution_ids": [
                "R203984",
                "R203985"
            ]
        },
        {
            "instance_id": "R204080xR204018",
            "comparison_id": "R204080",
            "paper_id": "R204018",
            "text": "Cryptodl: Deep neural networks over encrypted data machine learning algorithms based on deep neural networks have achieved remarkable results and are being extensively used in different domains. however, the machine learning algorithms requires access to raw data which is often privacy sensitive. to address this issue, we develop new techniques to provide solutions for running deep neural networks over encrypted data. in this paper, we develop new techniques to adopt deep neural networks within the practical limitation of current homomorphic encryption schemes. more specifically, we focus on classification of the well-known convolutional neural networks (cnn). first, we design methods for approximation of the activation functions commonly used in cnns (i.e. relu, sigmoid, and tanh) with low degree polynomials which is essential for efficient homomorphic encryption schemes. then, we train convolutional neural networks with the approximation polynomials instead of original activation functions and analyze the performance of the models. finally, we implement convolutional neural networks over encrypted data and measure performance of the models. our experimental results validate the soundness of our approach with several convolutional neural networks with varying number of layers and structures. when applied to the mnist optical character recognition tasks, our approach achieves 99.52\\% accuracy which significantly outperforms the state-of-the-art solutions and is very close to the accuracy of the best non-private version, 99.77\\%. also, it can make close to 164000 predictions per hour. we also applied our approach to cifar-10, which is much more complex compared to mnist, and were able to achieve 91.5\\% accuracy with approximation polynomials used as activation functions. these results show that cryptodl provides efficient, accurate and scalable privacy-preserving predictions.",
            "contribution_ids": [
                "R204020"
            ]
        },
        {
            "instance_id": "R204080xR204022",
            "comparison_id": "R204080",
            "paper_id": "R204022",
            "text": "TAPAS: Tricks to accelerate (encrypted) prediction as a service machine learning methods are widely used for a variety of prediction problems. \\emph{prediction as a service} is a paradigm in which service providers with technological expertise and computational resources may perform predictions for clients. however, data privacy severely restricts the applicability of such services, unless measures to keep client data private (even from the service provider) are designed. equally important is to minimize the amount of computation and communication required between client and server. fully homomorphic encryption offers a possible way out, whereby clients may encrypt their data, and on which the server may perform arithmetic computations. the main drawback of using fully homomorphic encryption is the amount of time required to evaluate large machine learning models on encrypted data. we combine ideas from the machine learning literature, particularly work on binarization and sparsification of neural networks, together with algorithmic tools to speed-up and parallelize computation using encrypted data.",
            "contribution_ids": [
                "R204024"
            ]
        },
        {
            "instance_id": "R204080xR204030",
            "comparison_id": "R204080",
            "paper_id": "R204030",
            "text": "Secure outsourced matrix computation and application to neural networks homomorphic encryption (he) is a powerful cryptographic primitive to address privacy and security issues in outsourcing computation on sensitive data to an untrusted computation environment. comparing to secure multi-party computation (mpc), he has advantages in supporting non-interactive operations and saving on communication costs. however, it has not come up with an optimal solution for modern learning frameworks, partially due to a lack of efficient matrix computation mechanisms. in this work, we present a practical solution to encrypt a matrix homomorphically and perform arithmetic operations on encrypted matrices. our solution includes a novel matrix encoding method and an efficient evaluation strategy for basic matrix operations such as addition, multiplication, and transposition. we also explain how to encrypt more than one matrix in a single ciphertext, yielding better amortized performance. our solution is generic in the sense that it can be applied to most of the existing he schemes. it also achieves reasonable performance for practical use; for example, our implementation takes 9.21 seconds to multiply two encrypted square matrices of order 64 and 2.56 seconds to transpose a square matrix of order 64. our secure matrix computation mechanism has a wide applicability to our new framework edm, which stands for encrypted data and encrypted model. to the best of our knowledge, this is the first work that supports secure evaluation of the prediction phase based on both encrypted data and encrypted model, whereas previous work only supported applying a plain model to encrypted data. as a benchmark, we report an experimental result to classify handwritten images using convolutional neural networks (cnn). our implementation on the mnist dataset takes 28.59 seconds to compute ten likelihoods of 64 input images simultaneously, yielding an amortized rate of 0.45 seconds per image.",
            "contribution_ids": [
                "R204032"
            ]
        },
        {
            "instance_id": "R204080xR204076",
            "comparison_id": "R204080",
            "paper_id": "R204076",
            "text": "Cryptflow: Secure tensorflow inference we present cryptflow, a first of its kind system that converts tensorflow inference code into secure multi-party computation (mpc) protocols at the push of a button. to do this, we build three components. our first component, athos, is an end-to-end compiler from tensorflow to a variety of semihonest mpc protocols. the second component, porthos, is an improved semi-honest 3-party protocol that provides significant speedups for tensorflow like applications. finally, to provide malicious secure mpc protocols, our third component, aramis, is a novel technique that uses hardware with integrity guarantees to convert any semi-honest mpc protocol into an mpc protocol that provides malicious security. the malicious security of the protocols output by aramis relies on integrity of the hardware and semi-honest security of mpc. moreover, our system matches the inference accuracy of plaintext tensorflow.we experimentally demonstrate the power of our system by showing the secure inference of real-world neural networks such as resnet50 and densenet121 over the imagenet dataset with running times of about 30 seconds for semi-honest security and under two minutes for malicious security. prior work in the area of secure inference has been limited to semi-honest security of small networks over tiny datasets such as mnist or cifar. even on mnist/cifar, cryptflow outperforms prior work.",
            "contribution_ids": [
                "R204078"
            ]
        },
        {
            "instance_id": "R204130xR204088",
            "comparison_id": "R204130",
            "paper_id": "R204088",
            "text": "FlowRanger: A request prioritizing algorithm for controller DoS attacks in Software Defined Networks software defined networking (sdn) introduces a new communication network management paradigm and has gained much attention from academia and industry. however, the centralized nature of sdn is a potential vulnerability to the system since attackers may launch denial of services (dos) attacks against the controller. existing solutions limit requests rate to the controller by dropping overflowed requests, but they also drop legitimate requests to the controller. to address this problem, we propose flowranger, a buffer prioritizing solution for controllers to handle routing requests based on their likelihood to be attacking requests, which derives the trust values of the requesting sources. based on their trust values, flowranger classifies routing requests into multiple buffer queues with different priorities. thus, attacking requests are served with a lower priority than regular requests. our simulation results demonstrates that flowranger can significantly enhance the request serving rate of regular users under dos attacks against the controller. to the best of our knowledge, our work is the first solution to battle against controller dos attacks on the controller side.",
            "contribution_ids": [
                "R204090"
            ]
        },
        {
            "instance_id": "R204130xR204101",
            "comparison_id": "R204130",
            "paper_id": "R204101",
            "text": "Tolerating SDN application failures with LegoSDN despite software defined network's (sdn) proven benefits, there remains significant reluctance in adopting it. among the issues that hamper sdn's adoption two stand out: reliability and fault tolerance. at the heart of these issues is a set of fate-sharing relationships: the first between the sdn-apps and controllers, where-in the crash of the former induces a crash of the latter, and thereby affecting availability; and, the second between the sdn-app and the network, where-in a byzantine failure e.g., black-holes and network-loops, induces a failure in the network, and thereby affecting network availability. the principal position of this paper is that availability is of utmost concern -- second only to security. to this end, we present a re-design of the controller architecture centering around a set of abstractions to eliminate these fate-sharing relationships, and make the controllers and network resilient to sdn-app failures. we illustrate how these abstractions can be used to improve the reliability of an sdn environment, thus eliminating one of the barriers to sdn's adoption.",
            "contribution_ids": [
                "R204103"
            ]
        },
        {
            "instance_id": "R204130xR204120",
            "comparison_id": "R204130",
            "paper_id": "R204120",
            "text": "Study on authentication protocol of SDN trusted domain currently software define network (sdn) architecture has become a hot topic. aiming at the authentication security issues of sdn network architecture, we introduce an authentication protocol based on sdn network architecture without any trusted third party between trusted domains. by applying avispa security analysis system of network interaction protocol, we can guarantee protocol security and provide complete safety tests. our work fill the gap of mutual trust between different trusted domains and provide security foundation for interaction between different trusted domains.",
            "contribution_ids": [
                "R204122"
            ]
        },
        {
            "instance_id": "R204130xR204124",
            "comparison_id": "R204130",
            "paper_id": "R204124",
            "text": "A secure northbound interface for SDN applications software-defined networking (sdn) promises to introduce flexibility and programmability into networks by offering a northbound interface (nbi) for developers to create sdn applications. however, current designs and implementations have several drawbacks, including the lack of extended security features. in this paper, we present a secure northbound interface, through which an sdn controller can offer network resources, such as statistics, flow information or topology data, via a rest-like api to registered sdn applications. a trust manager ensures that only authenticated and trusted applications can utilize the interface. furthermore, a permission system allows for fine-grained authorization and access control to the aforementioned resources. we present a prototypical implementation of our interface and developed example applications using our interface, including an sdn management dashboard.",
            "contribution_ids": [
                "R204126"
            ]
        },
        {
            "instance_id": "R204209xR204174",
            "comparison_id": "R204209",
            "paper_id": "R204174",
            "text": "Enigma: Decentralized computation platform with guaranteed privacy a peer-to-peer network, enabling different parties to jointly store and run computations on data while keeping the data completely private. enigma's computational model is based on a highly optimized version of secure multi-party computation, guaranteed by a verifiable secret-sharing scheme. for storage, we use a modified distributed hashtable for holding secret-shared data. an external blockchain is utilized as the controller of the network, manages access control, identities and serves as a tamper-proof log of events. security deposits and fees incentivize operation, correctness and fairness of the system. similar to bitcoin, enigma removes the need for a trusted third party, enabling autonomous control of personal data. for the first time, users are able to share their data with cryptographic guarantees regarding their privacy.",
            "contribution_ids": [
                "R204176"
            ]
        },
        {
            "instance_id": "R204209xR204183",
            "comparison_id": "R204209",
            "paper_id": "R204183",
            "text": "Provchain: A blockchain-based data provenance architecture in cloud environment with enhanced privacy and availability cloud data provenance is metadata that records the history of the creation and operations performed on a cloud data object. secure data provenance is crucial for data accountability, forensics and privacy. in this paper, we propose a decentralized and trusted cloud data provenance architecture using blockchain technology. blockchain-based data provenance can provide tamper-proof records, enable the transparency of data accountability in the cloud, and help to enhance the privacy and availability of the provenance data. we make use of the cloud storage scenario and choose the cloud file as a data unit to detect user operations for collecting provenance data. we design and implement provchain, an architecture to collect and verify cloud data provenance, by embedding the provenance data into blockchain transactions. provchain operates mainly in three phases: (1) provenance data collection, (2) provenance data storage, and (3) provenance data validation. results from performance evaluation demonstrate that provchain provides security features including tamper-proof provenance, user privacy and reliability with low overhead for the cloud storage applications.",
            "contribution_ids": [
                "R204185"
            ]
        },
        {
            "instance_id": "R204209xR204207",
            "comparison_id": "R204209",
            "paper_id": "R204207",
            "text": "A blockchain-based framework for data sharing with fine-grained access control in decentralized storage systems in traditional cloud storage systems, attribute-based encryption (abe) is regarded as an important technology for solving the problem of data privacy and fine-grained access control. however, in all abe schemes, the private key generator has the ability to decrypt all data stored in the cloud server, which may bring serious problems such as key abuse and privacy data leakage. meanwhile, the traditional cloud storage model runs in a centralized storage manner, so single point of failure may leads to the collapse of system. with the development of blockchain technology, decentralized storage mode has entered the public view. the decentralized storage approach can solve the problem of single point of failure in traditional cloud storage systems and enjoy a number of advantages over centralized storage, such as low price and high throughput. in this paper, we study the data storage and sharing scheme for decentralized storage systems and propose a framework that combines the decentralized storage system interplanetary file system, the ethereum blockchain, and abe technology. in this framework, the data owner has the ability to distribute secret key for data users and encrypt shared data by specifying access policy, and the scheme achieves fine-grained access control over data. at the same time, based on smart contract on the ethereum blockchain, the keyword search function on the cipher text of the decentralized storage systems is implemented, which solves the problem that the cloud server may not return all of the results searched or return wrong results in the traditional cloud storage systems. finally, we simulated the scheme in the linux system and the ethereum official test network rinkeby, and the experimental results show that our scheme is feasible.",
            "contribution_ids": [
                "R204208"
            ]
        },
        {
            "instance_id": "R206187xR206100",
            "comparison_id": "R206187",
            "paper_id": "R206100",
            "text": "A multi-objective optimization model for sustainable supply chain network with using genetic algorithm purpose the purpose of this paper is to design and optimize economic and environmental dimensions in a sustainable supply chain (ssc) network. this paper developed a mixed-integer linear programing (milp) model to incorporate economical and environmental data for multi-objective optimization of the ssc network. design/methodology/approach the overall objective of the present study is to use high-quality raw materials, at the same time the lowest amount of pollution emission and the highest profitability is achieved. the model in the problem is solved using two algorithms, namely, multi-objective genetic and multi-objective particle swarm. in this research, to integrate sustainable supplier selection and optimization of sustainability performance indicators in supply chain network design considering minimization of cost and time and maximization of sustainability indexes of the system. findings the differences found between the genetic algorithms (gas) and the milp approaches can be explained by handling the constraints and their various logics. the solutions are contrasted with the original crisp model based on either milp or ga, offering more robustness to the proposed approach. practical implications the model is applied to mega motor company to optimize the sustainability performance of the supply chain i.e. economic (cost), social (time) and environmental (pollution of raw material). the research method has two approaches, namely, applied and mathematical modeling. originality/value there is limited research designing and optimizing the ssc network. this study is among the first to integrate sustainable supplier selection and optimization of sustainability performance indicators in supply chain network design considering minimization of cost and time and maximization of sustainability indexes of the system.",
            "contribution_ids": [
                "R206103"
            ]
        },
        {
            "instance_id": "R206309xR206216",
            "comparison_id": "R206309",
            "paper_id": "R206216",
            "text": "Ambulatory Position and Orientation Tracking Fusing Magnetic and Inertial Sensing this paper presents the design and testing of a portable magnetic system combined with miniature inertial sensors for ambulatory 6 degrees of freedom ( dof) human motion tracking. the magnetic system consists of three orthogonal coils, the source, fixed to the body and 3-d magnetic sensors, fixed to remote body segments, which measure the fields generated by the source. based on the measured signals, a processor calculates the relative positions and orientations between source and sensor. magnetic actuation requires a substantial amount of energy which limits the update rate with a set of batteries. moreover, the magnetic field can easily be disturbed by ferromagnetic materials or other sources. inertial sensors can be sampled at high rates, require only little energy and do not suffer from magnetic interferences. however, accelerometers and gyroscopes can only measure changes in position and orientation and suffer from integration drift. by combing measurements from both systems in a complementary kalman filter structure, an optimal solution for position and orientation estimates is obtained. the magnetic system provides 6 dof measurements at a relatively low update rate while the inertial sensors track the changes position and orientation in between the magnetic updates. the implemented system is tested against a lab-bound camera tracking system for several functional body movements. the accuracy was about 5 mm for position and 3 degrees for orientation measurements. errors were higher during movements with high velocities due to relative movement between source and sensor within one cycle of magnetic actuation",
            "contribution_ids": [
                "R206218"
            ]
        },
        {
            "instance_id": "R206309xR206222",
            "comparison_id": "R206309",
            "paper_id": "R206222",
            "text": "Reducing Drifts in the Inertial Measurements of Wrist and Elbow Positions in this paper, we present an inertial-sensor-based monitoring system for measuring the movement of human upper limbs. two wearable inertial sensors are placed near the wrist and elbow joints, respectively. the measurement drift in segment orientation is dramatically reduced after a kalman filter is applied to estimate inclinations using accelerations and turning rates from gyroscopes. using premeasured lengths of the upper and lower arms, we compute the position of the wrist and elbow joints via a proposed kinematic model. experimental results demonstrate that this new motion capture system, in comparison to an optical motion tracker, possesses an rms position error of less than 0.009 m, with a drift of less than 0.005 ms-1 in five daily activities. in addition, the rms angle error is less than 3\u00b0. this indicates that the proposed approach has performed well in terms of accuracy and reliability.",
            "contribution_ids": [
                "R206224"
            ]
        },
        {
            "instance_id": "R207120xR206262",
            "comparison_id": "R207120",
            "paper_id": "R206262",
            "text": "A Deep Learning Framework for Detection of COVID-19 Fake News on Social Media Platforms the fast growth of technology in online communication and social media platforms alleviated numerous difficulties during the covid-19 epidemic. however, it was utilized to propagate falsehoods and misleading information about the disease and the vaccination. in this study, we investigate the ability of deep neural networks, namely, long short-term memory (lstm), bi-directional lstm, convolutional neural network (cnn), and a hybrid of cnn and lstm networks, to automatically classify and identify fake news content related to the covid-19 pandemic posted on social media platforms. these deep neural networks have been trained and tested using the \u201ccovid-19 fake news\u201d dataset, which contains 21,379 real and fake news instances for the covid-19 pandemic and its vaccines. the real news data were collected from independent and internationally reliable institutions on the web, such as the world health organization (who), the international committee of the red cross (icrc), the united nations (un), the united nations children\u2019s fund (unicef), and their official accounts on twitter. the fake news data were collected from different fact-checking websites (such as snopes, politifact, and factcheck). the evaluation results showed that the cnn model outperforms the other deep neural networks with the best accuracy of 94.2%.",
            "contribution_ids": [
                "R206265"
            ]
        },
        {
            "instance_id": "R207120xR206370",
            "comparison_id": "R207120",
            "paper_id": "R206370",
            "text": "FANG: Leveraging Social Context for Fake News Detection Using Graph Representation we propose factual news graph (fang), a novel graphical social context representation and learning framework for fake news detection. unlike previous contextual models that have targeted performance, our focus is on representation learning. compared to transductive models, fang is scalable in training as it does not have to maintain all nodes, and it is efficient at inference time, without the need to re-process the entire graph. our experimental results show that fang is better at capturing the social context into a high fidelity representation, compared to recent graphical and non-graphical models. in particular, fang yields significant improvements for the task of fake news detection, and it is robust in the case of limited training data. we further demonstrate that the representations learned by fang generalize to related tasks, such as predicting the factuality of reporting of a news medium.",
            "contribution_ids": [
                "R206372"
            ]
        },
        {
            "instance_id": "R207120xR207084",
            "comparison_id": "R207120",
            "paper_id": "R207084",
            "text": "exBAKE: Automatic Fake News Detection Model Based on Bidirectional Encoder Representations from Transformers (BERT) news currently spreads rapidly through the internet. because fake news stories are designed to attract readers, they tend to spread faster. for most readers, detecting fake news can be challenging and such readers usually end up believing that the fake news story is fact. because fake news can be socially problematic, a model that automatically detects such fake news is required. in this paper, we focus on data-driven automatic fake news detection methods. we first apply the bidirectional encoder representations from transformers model (bert) model to detect fake news by analyzing the relationship between the headline and the body text of news. to further improve performance, additional news data are gathered and used to pre-train this model. we determine that the deep-contextualizing nature of bert is best suited for this task and improves the 0.14 f-score over older state-of-the-art models.",
            "contribution_ids": [
                "R207086"
            ]
        },
        {
            "instance_id": "R209290xR209021",
            "comparison_id": "R209290",
            "paper_id": "R209021",
            "text": "A large-scale benchmark dataset for event recognition in surveillance video we introduce a new large-scale video dataset designed to assess the performance of diverse visual event recognition algorithms with a focus on continuous visual event recognition (cver) in outdoor areas with wide coverage. previous datasets for action recognition are unrealistic for real-world surveillance because they consist of short clips showing one action by one individual [15, 8]. datasets have been developed for movies [11] and sports [12], but, these actions and scene conditions do not apply effectively to surveillance videos. our dataset consists of many outdoor scenes with actions occurring naturally by non-actors in continuously captured videos of the real world. the dataset includes large numbers of instances for 23 event types distributed throughout 29 hours of video. this data is accompanied by detailed annotations which include both moving object tracks and event examples, which will provide solid basis for large-scale evaluation. additionally, we propose different types of evaluation modes for visual recognition tasks and evaluation metrics along with our preliminary experimental results. we believe that this dataset will stimulate diverse aspects of computer vision research and help us to advance the cver tasks in the years ahead.",
            "contribution_ids": [
                "R209023"
            ]
        },
        {
            "instance_id": "R209290xR209045",
            "comparison_id": "R209290",
            "paper_id": "R209045",
            "text": "The highD Dataset: A Drone Dataset of Naturalistic Vehicle Trajectories on German Highways for Validation of Highly Automated Driving Systems scenario-based testing for the safety validation of highly automated vehicles is a promising approach that is being examined in research and industry. this approach heavily relies on data from real-world scenarios to derive the necessary scenario information for testing. measurement data should be collected at a reasonable effort, contain naturalistic behavior of road users and include all data relevant for a description of the identified scenarios in sufficient quality. however, the current measurement methods fail to meet at least one of the requirements. thus, we propose a novel method to measure data from an aerial perspective for scenario-based validation fulfilling the mentioned requirements. furthermore, we provide a large-scale naturalistic vehicle trajectory dataset from german highways called highd. we evaluate the data in terms of quantity, variety and contained scenarios. our dataset consists of 16.5 hours of measurements from six locations with 110 000 vehicles, a total driven distance of 45 000 km and 5600 recorded complete lane changes. the highd dataset is available online at: http://www.highd-dataset.com",
            "contribution_ids": [
                "R209047"
            ]
        },
        {
            "instance_id": "R209290xR209016",
            "comparison_id": "R209290",
            "paper_id": "R209016",
            "text": "Statistical models of pedestrian behaviour in the Forum this dissertation describes an msc project for which the purpose was to develop a system that could be used for automated surveillance. the main novelty is the use of a vertical camera. the project investigates whether such a system can effectively detect moving objects, track their trajectories, and use these to recognise anomalous events.",
            "contribution_ids": [
                "R209017"
            ]
        },
        {
            "instance_id": "R209290xR209042",
            "comparison_id": "R209290",
            "paper_id": "R209042",
            "text": "An Evaluation of Trajectory Prediction Approaches and Notes on the TrajNet Benchmark in recent years, there is a shift from modeling the tracking problem based on bayesian formulation towards using deep neural networks. towards this end, in this paper the effectiveness of various deep neural networks for predicting future pedestrian paths are evaluated. the analyzed deep networks solely rely, like in the traditional approaches, on observed tracklets without human-human interaction information. the evaluation is done on the publicly available trajnet benchmark dataset, which builds up a repository of considerable and popular datasets for trajectory-based activity forecasting. we show that a recurrent-encoder with a dense layer stacked on top, referred to as red-predictor, is able to achieve sophisticated results compared to elaborated models in such scenarios. further, we investigate failure cases and give explanations for observed phenomena and give some recommendations for overcoming demonstrated shortcomings.",
            "contribution_ids": [
                "R209044"
            ]
        },
        {
            "instance_id": "R209929xR209892",
            "comparison_id": "R209929",
            "paper_id": "R209892",
            "text": "Advancements in Noncontact, Multiparameter Physiological Measurements Using a Webcam we present a simple, low-cost method for measuring multiple physiological parameters using a basic webcam. by applying independent component analysis on the color channels in video recordings, we extracted the blood volume pulse from the facial regions. heart rate (hr), respiratory rate, and hr variability (hrv, an index for cardiac autonomic activity) were subsequently quantified and compared to corresponding measurements using food and drug administration-approved sensors. high degrees of agreement were achieved between the measurements across all physiological parameters. this technology has significant potential for advancing personal health care and telemedicine.",
            "contribution_ids": [
                "R209894"
            ]
        },
        {
            "instance_id": "R209929xR209904",
            "comparison_id": "R209929",
            "paper_id": "R209904",
            "text": "Remote Heart Rate Measurement from Face Videos under Realistic Situations heart rate is an important indicator of people's physiological state. recently, several papers reported methods to measure heart rate remotely from face videos. those methods work well on stationary subjects under well controlled conditions, but their performance significantly degrades if the videos are recorded under more challenging conditions, specifically when subjects' motions and illumination variations are involved. we propose a framework which utilizes face tracking and normalized least mean square adaptive filtering methods to counter their influences. we test our framework on a large difficult and public database mahnob-hci and demonstrate that our method substantially outperforms all previous methods. we also use our method for long term heart rate monitoring in a game evaluation scenario and achieve promising results.",
            "contribution_ids": [
                "R209906"
            ]
        },
        {
            "instance_id": "R209929xR209913",
            "comparison_id": "R209929",
            "paper_id": "R209913",
            "text": "Remote PPG based vital sign measurement using adaptive facial regions this paper proposes a remote photoplethysmography measurement technique where human skin color variations are analysed for observing human vital signs including but not limited to average heart rate and variation. remote monitoring of the vital signs could be useful for non-contact physiological and psychological diagnosis. for this purpose, an off-the-self non-invasive video camera is used. facial appearance modelling is performed for stabilizing color variations in the selected facial region during the signal acquisition stage. the proposed method offers a novel signal processing approach for extracting the periodic component of the raw color signal for the heart rate and variation estimation. to this end, we have collected a ground truth dataset using a ppg instrument attached to the skin of the subject under observation. objective performance tests show strong correlation with the ground truth values for the estimated heart rate and variation.",
            "contribution_ids": [
                "R209915"
            ]
        },
        {
            "instance_id": "R210137xR210040",
            "comparison_id": "R210137",
            "paper_id": "R210040",
            "text": "High performance traffic shaping for DDoS mitigation distributed denial of service (ddos) attack mitigation systems usually generate a list of filter rules in order to block malicious traffic. in contrast to this binary decision we suggest to use traffic shaping whereas the bandwidth limit is defined by the probability of a source to be a legal user. as a proof of concept, we implemented a simple high performance linux kernel module nf-hishape which is able to shape thousands of source ip addresses at different bandwidth limits even under high packet rates. our shaping algorithm is comparable to random early detection (red) applied on every single source ip range. the evaluation shows, that our kernel module can handle up to 50,000 ip ranges at nearly constant throughput whereas linux tc already decreases throughput at about 200 ranges.",
            "contribution_ids": [
                "R210042"
            ]
        },
        {
            "instance_id": "R210410xR210339",
            "comparison_id": "R210410",
            "paper_id": "R210339",
            "text": "Lightweight DDoS flooding attack detection using NOX/OpenFlow distributed denial-of-service (ddos) attacks became one of the main internet security problems over the last decade, threatening public web servers in particular. although the ddos mechanism is widely understood, its detection is a very hard task because of the similarities between normal traffic and useless packets, sent by compromised hosts to their victims. this work presents a lightweight method for ddos attack detection based on traffic flow features, in which the extraction of such information is made with a very low overhead compared to traditional approaches. this is possible due to the use of the nox platform which provides a programmatic interface to facilitate the handling of switch information. other major contributions include the high rate of detection and very low rate of false alarms obtained by flow analysis using self organizing maps.",
            "contribution_ids": [
                "R210341"
            ]
        },
        {
            "instance_id": "R210410xR210357",
            "comparison_id": "R210410",
            "paper_id": "R210357",
            "text": "Mitigating DDoS attacks with transparent and intelligent fast-flux swarm network distributed denial of service attacks are a great threat to service availability in cloud computing. in recent years, ddos attacks have increased tremendously in bandwidth and technique. in this article, we propose a novel approach to mitigate ddos attacks using an intelligent fast-flux swarm network. an intelligent swarm network is required to ensure autonomous coordination and allocation of swarm nodes to perform its relaying operations. we adapted the intelligent water drop algorithm for distributed and parallel optimization. the fast-flux technique was used to maintain connectivity between swarm nodes, clients, and servers. fast-flux service networks also allow us to build a transparent service, which allows minimal modifications of existing cloud services (e.g. http, smtp). a software simulation consisting of 400,000 client nodes and 10,000 swarm nodes has shown that we can maintain 99.96 percent packet delivery ratio when the network is under attack from a similarly sized ddos network of 10,000 dedicated malicious nodes.",
            "contribution_ids": [
                "R210359"
            ]
        },
        {
            "instance_id": "R210471xR203125",
            "comparison_id": "R210471",
            "paper_id": "R203125",
            "text": "Fatigue Resistant Bioinspired Composite from Synergistic Two-Dimensional Nanocomponents portable and wearable electronics require much more flexible graphene-based electrode with high fatigue life, which could repeatedly bend, fold, or stretch without sacrificing its mechanical properties and electrical conductivity. herein, a kind of ultrahigh fatigue resistant graphene-based nanocomposite via tungsten disulfide (ws2) nanosheets is synthesized by introducing a synergistic effect with covalently cross-linking inspired by the orderly layered structure and abundant interfacial interactions of nacre. the fatigue life of resultant graphene-based nanocomposites is more than one million times at the stress level of 270 mpa, and the electrical conductivity can be kept as high as 197.1 s/cm after 1.0 \u00d7 105 tensile testing cycles. these outstanding properties are attributed to the synergistic effect from lubrication of ws2 nanosheets for deflecting crack propagation, and covalent bonding between adjacent go nanosheets for bridging crack, which is verified by the molecular dynamics (md) simulations. the ws2 induced synergistic effect with covalent bonding offers a guidance for constructing graphene-based nanocomposites with high fatigue life, which have great potential for applications in flexible and wearable electronic devices, etc.",
            "contribution_ids": [
                "R203388"
            ]
        },
        {
            "instance_id": "R210471xR210421",
            "comparison_id": "R210471",
            "paper_id": "R210421",
            "text": "Sequentially bridged graphene sheets with high strength, toughness, and electrical conductivity significance there is a continuing search for manufacturable sheets having high strength and toughness in all sheet directions for diverse applications, from airplanes to windmills. cross-plied carbon fibers in a polymer resin requiring high-temperature cure presently provide the common solution. we demonstrate cross-linked graphene sheets that are manufacturable from graphene platelets, which are resin-free, processable at low temperature, contain less than 10 wt % additives, and provide high strength and record toughness in all in-plane directions. this advance results from successive use of \u03c0\u2013\u03c0 and covalent cross-linking agents. simultaneous enhancement of strength, durability, and electrical conductivity are demonstrated. spectroscopic measurements, including raman studies of interplatelet stress transfer, elucidate the chemical nature and physical consequences of these dual cross-linking agents.",
            "contribution_ids": [
                "R210423"
            ]
        },
        {
            "instance_id": "R210471xR210433",
            "comparison_id": "R210471",
            "paper_id": "R210433",
            "text": "Ultratough Artificial Nacre Based on Conjugated Cross-linked Graphene Oxide as the water-soluble derivative of graphene,graphene oxide (go), with many functional groups on thesurface, is one of the best candidates for fabricating artificialnacre, because functional surface groups allow for chemicalcross-linking to improve the interfacial strength of theadjacent go layers. until now, several methods have beendeveloped to functionalize individual go sheets and enhancethe resultant mechanical properties, including divalent ion(mg",
            "contribution_ids": [
                "R210435"
            ]
        },
        {
            "instance_id": "R210471xR210439",
            "comparison_id": "R210471",
            "paper_id": "R210439",
            "text": "Ultratough, Ultrastrong, and Highly Conductive Graphene Films with Arbitrary Sizes freestanding, paper-like films of reduced graphene oxide (rgo) containing trace amounts of polymers are fabricated by an operationally simple, cost-effective, and environmentally friendly gel-film approach. the films, which can have a large area, display ultrahigh strengths and toughnesses as well as high electrical conductivities.",
            "contribution_ids": [
                "R210440"
            ]
        },
        {
            "instance_id": "R210471xR210457",
            "comparison_id": "R210471",
            "paper_id": "R210457",
            "text": "Topological Design of Ultrastrong and Highly Conductive Graphene Films nacre\u2010like graphene films are prepared by evaporation\u2010induced assembly of graphene oxide dispersions containing small amounts of cellulose nanocrystal (cnc), followed by chemical reduction with hydroiodic acid. cnc induces the formation of wrinkles on graphene sheets, greatly enhancing the mechanical properties of the resultant graphene films. the graphene films deliver an ultrahigh tensile strength of 765 \u00b1 43 mpa (up to 800 mpa in some cases), a large failure strain of 6.22 \u00b1 0.19%, and a superior toughness of 15.64 \u00b1 2.20 mj m\u22123, as well as a high electrical conductivity of 1105 \u00b1 17 s cm\u22121. they have a great potential for applications in flexible electronics because of their combined excellent mechanical and electrical properties.",
            "contribution_ids": [
                "R210459"
            ]
        },
        {
            "instance_id": "R210531xR210506",
            "comparison_id": "R210531",
            "paper_id": "R210506",
            "text": "Low-rate DoS attacks detection based on network multifractal low-rate denial of service (ldos) attacks send periodic pulse sequences with relative low rate to form aggregation flows at the victim end. ldos attack flows have the characteristics of low average rate and great concealment. it is hard to detect ldos attack flows from normal traffic due to low rate property. network traffic measurement shows that aggregate network traffic is multifractal. in order to characterize and analyze network traffic, researchers have developed concise mathematical models to explore complex multifractal structure. although the ldos attack flows are very small, it will inevitably lead to the change of multifractal characteristics of network traffic. this paper targets at exploiting and estimating the changes in multifractal characteristics of network traffic for detecting ldos attack flows. the algorithm of multifractal detrended fluctuation analysis (mf-dfa) is used to explore the change in terms of multifractal characteristics over a small scale of network traffic due to ldos attacks. through wavelet analysis, the singularity and bursty of network traffic under ldos attacks are estimated by using ho\u0308lder exponent. the difference values (d-value) of ho\u0308lder exponent of network traffic between normal and under ldos attack situations are calculated. the d-value is used as the basis to determine ldos attacks. a detection threshold is set based on the statistical results. the presence of ldos attacks can be confirmed through comparing d-value with detection threshold. experiments on detection performance have been performed in the test-bed network and simulation platform. the extensive experimental results are congruent with the theoretical analysis.",
            "contribution_ids": [
                "R210508"
            ]
        },
        {
            "instance_id": "R211056xR207034",
            "comparison_id": "R211056",
            "paper_id": "R207034",
            "text": "Postmortem examination of COVID\u00e2\u0080\u009019 patients reveals diffuse alveolar damage with severe capillary congestion and variegated findings in lungs and other organs suggesting vascular dysfunction coronavirus disease 2019 (covid\u201019), caused by severe acute respiratory syndrome coronavirus 2 (sars\u2010cov\u20102), has rapidly evolved into a sweeping pandemic. its major manifestation is in the respiratory tract, and the general extent of organ involvement and the microscopic changes in the lungs remain insufficiently characterised. autopsies are essential to elucidate covid\u201019\u2010associated organ alterations.",
            "contribution_ids": [
                "R207038",
                "R209149"
            ]
        },
        {
            "instance_id": "R211056xR209082",
            "comparison_id": "R211056",
            "paper_id": "R209082",
            "text": "Multiorgan and Renal Tropism of SARS-CoV-2 multiorgan and renal tropism of sars-cov-2 in this autopsy series, the authors found that sars-cov-2 has an organotropism beyond the respiratory tract, including the kidneys, heart, liver, and brai...",
            "contribution_ids": [
                "R209086",
                "R209126",
                "R209127",
                "R209128",
                "R209129"
            ]
        },
        {
            "instance_id": "R211056xR209933",
            "comparison_id": "R211056",
            "paper_id": "R209933",
            "text": "Pathology and Pathogenesis of SARS-CoV-2 Associated with Fatal Coronavirus Disease, United States an ongoing pandemic of coronavirus disease (covid-19) is caused by infection with severe acute respiratory syndrome coronavirus 2 (sars-cov-2). characterization of the histopathology and cellular localization of sars-cov-2 in the tissues of patients with fatal covid-19 is critical to further understand its pathogenesis and transmission and for public health prevention measures. we report clinicopathologic, immunohistochemical, and electron microscopic findings in tissues from 8 fatal laboratory-confirmed cases of sars-cov-2 infection in the united states. all cases except 1 were in residents of long-term care facilities. in these patients, sars-cov-2 infected epithelium of the upper and lower airways with diffuse alveolar damage as the predominant pulmonary pathology. sars-cov-2 was detectable by immunohistochemistry and electron microscopy in conducting airways, pneumocytes, alveolar macrophages, and a hilar lymph node but was not identified in other extrapulmonary tissues. respiratory viral co-infections were identified in 3 cases; 3 cases had evidence of bacterial co-infection.",
            "contribution_ids": [
                "R209935",
                "R209937"
            ]
        },
        {
            "instance_id": "R211056xR211000",
            "comparison_id": "R211056",
            "paper_id": "R211000",
            "text": "Insights into pathogenesis of fatal COVID\u00e2\u0080\u009019 pneumonia from histopathology with immunohistochemical and viral RNA studies we describe post\u2010mortem pulmonary histopathologic findings of covid\u201019 pneumonia in patients with a spectrum of disease course, from rapid demise to prolonged hospitalisation.",
            "contribution_ids": [
                "R211006"
            ]
        },
        {
            "instance_id": "R211056xR211009",
            "comparison_id": "R211056",
            "paper_id": "R211009",
            "text": "Postmortem Kidney Pathology Findings in Patients with COVID-19 background aki is common among hospitalized patients with coronavirus disease 2019 (covid-19) and is an independent risk factor for mortality. although there are numerous potential mechanisms underlying covid-19\u2013associated aki, our current knowledge of kidney pathologic findings in covid-19 is limited. methods we examined the postmortem kidneys from 42 patients who died of covid-19. we reviewed light microscopy findings in all autopsies and performed immunofluorescence, electron microscopy, and in situ hybridization studies for sars-cov-2 on a subset of samples. results the cohort had a median age of 71.5 years (range, 38\u201397 years); 69% were men, 57% were hispanic, and 73% had a history of hypertension. among patients with available data, aki developed in 31 of 33 patients (94%), including 6 with aki stage 1, 9 with stage 2, and 16 with stage 3. the predominant finding correlating with aki was acute tubular injury. however, the degree of acute tubular injury was often less severe than predicted for the degree of aki, suggesting a role for hemodynamic factors, such as aggressive fluid management. background changes of hypertensive arterionephrosclerosis and diabetic glomerulosclerosis were frequent but typically mild. we identified focal kidney fibrin thrombi in 6 of 42 (14%) autopsies. a single black patient had collapsing fsgs. immunofluorescence and electron microscopy were largely unrevealing, and in situ hybridization for sars-cov-2 showed no definitive positivity. conclusions among a cohort of 42 patients dying with covid-19, autopsy histologic evaluation revealed acute tubular injury, which was typically mild relative to the degree of creatinine elevation. these findings suggest potential for reversibility upon resolution of sars-cov-2 infection.",
            "contribution_ids": [
                "R211012"
            ]
        },
        {
            "instance_id": "R211935xR192386",
            "comparison_id": "R211935",
            "paper_id": "R192386",
            "text": "A Survey of Instructional Approaches in the Requirements Engineering Education Literature requirements engineering (re) has established itself as a core software engineering discipline. it is well acknowledged that good re leads to higher quality software and considerably reduces the risk of failure or exceeding budgets of software development projects. therefore, it is of vital importance to train future software engineers in re and educate future requirements engineers to adequately manage requirements in various projects. however, to date there exists no central concept of what the most useful educational approaches are in re education in order to best interweave theory with practice. to lay the foundation for this important mission, we conducted a systematic literature review. in this paper, we report on the results and provide a synthesis of instructional approaches in re education. findings show that experiential learning through projects, collaboration, and realistic stakeholder involvement are among the most promising trends to teach both re theory and develop student soft skills.",
            "contribution_ids": [
                "R192388"
            ]
        },
        {
            "instance_id": "R211935xR192398",
            "comparison_id": "R211935",
            "paper_id": "R192398",
            "text": "Agile Teams\u00e2\u0080\u0099 Perception in Privacy Requirements Elicitation: LGPD\u00e2\u0080\u0099s compliance in Brazil context: the implementation of the brazilian general data protection law (lgpd) may impact activities carried out by the software development teams. it is necessary for developers to know the existing techniques and tools to carry out privacy requirements elicitation. objectives: in this research, we investigated the perception of agile software development team members from different organizations, regarding the impact that lgpd will have on the activities of the software development process. methods: we conducted an online survey and a systematic literature review to identify the techniques, methodologies and tools used in the literature to perform privacy requirements elicitation in the context of agile software development (asd). in addition, we also investigated the perception of an agile team from a federal public administration organization regarding the impacts of the obligation to develop software in accordance with the lgpd. results: our findings reveal that agile teams know the concepts related to data privacy legislation, but they do not use the techniques proposed in the literature to perform privacy requirements elicitation. in addition, agile teams face problems with outdated software requirements specifications and stakeholders\u2019 lack of knowledge regarding data privacy. conclusions: agile teams need to improve their knowledge on privacy requirements.",
            "contribution_ids": [
                "R192400"
            ]
        },
        {
            "instance_id": "R211935xR192428",
            "comparison_id": "R211935",
            "paper_id": "R192428",
            "text": "Ambiguity and Generality in Natural Language Privacy Policies privacy policies are legal documents containing application data practices. these documents are well-established sources of requirements in software engineering. however, privacy policies are written in natural language, thus subject to ambiguity and abstraction. eliciting requirements from privacy policies is a challenging task as these ambiguities can result in more than one interpretation of a given information type (e.g., ambiguous information type \"device information\" in the statement \"we collect your device information\"). to address this challenge, we propose an automated approach to infer semantic relations among information types and construct an ontology to guide requirements authors in the selection of the most appropriate information type terms. our solution utilizes word embeddings and convolutional neural networks (cnn) to classify information type pairs as either hypernymy, synonymy, or unknown. we evaluate our model on a manually-built ontology, yielding predictions that identify hypernymy relations in information type pairs with 0.904 f-1 score, suggesting a large reduction in effort required for ontology construction.",
            "contribution_ids": [
                "R192430"
            ]
        },
        {
            "instance_id": "R211935xR193044",
            "comparison_id": "R211935",
            "paper_id": "R193044",
            "text": "From Ideas to Expressed Needs: an Empirical Study on the Evolution of Requirements during Elicitation requirements are elicited from the customer and other stakeholders through an iterative process of interviews, prototyping, and other interactive sessions. many communication phenomena may emerge in these early iterations, that lead initial ideas to be transformed, renegotiated, or reframed. understanding how this process takes place can help in solving possible communication issues as well as their consequences. in this work, we perform an exploratory study of descriptive nature to understand in which way requirements get transformed from initial ideas into documented needs. to this end, we select 30 subjects that act as requirements analysts, and we perform a set of elicitation sessions with a fictional customer. the customer is required to study a sample requirements document for a system beforehand and to answer the questions of the analysts about the system. after the elicitation sessions, the analysts produce user stories for the system. these are compared with the original ones by two researchers to assess to which extent and in which way the initial requirements evolved throughout the interactive sessions. our results show that between 30% and 38% of the produced user stories include content that can be fully traced to the initial ones, while the rest of the content is dedicated to new requirements. we also show what types of requirements are introduced through the elicitation process, and how they vary depending on the analyst. our work contributes to theory in requirements engineering, with empirically grounded, quantitative data, concerning the impact of elicitation activities with respect to initial ideas.",
            "contribution_ids": [
                "R193046"
            ]
        },
        {
            "instance_id": "R211935xR193308",
            "comparison_id": "R211935",
            "paper_id": "R193308",
            "text": "The Role of Linguistic Relativity on the Identification of Sustainability Requirements: An Empirical Study linguistic-relativity-theory states that language and its structure influence people\u2019s world view and cognition. we investigate how this theory impacts the identification of requirements in practice. to this end, we conducted two controlled experiments with 101 participants. we randomly showed participants a set of requirements dimensions (i.e. a language structure) either with a focus on software quality or on sustainability and asked them to identify the requirements for a grocery shopping app according to these dimensions. participants of the control group were not given any dimensions. the results show that the use of requirements dimensions significantly increases the number of identified requirements in comparison to the control group. furthermore, participants who were given the sustainability dimensions identified more sustainability requirements. in follow up interviews with 16 practitioners, the interviewees reported benefits of the dimensions such as a holistic guidance but were also concerned about the customers acceptance. furthermore, they stated challenges of implementing sustainability dimensions in the daily business but also suggested solutions like establishing sustainability as a common standard. our study indicates that carefully structuring requirements engineering along sustainability dimensions can guide development teams towards considering and ensuring software sustainability.",
            "contribution_ids": [
                "R193309"
            ]
        },
        {
            "instance_id": "R211935xR193341",
            "comparison_id": "R211935",
            "paper_id": "R193341",
            "text": "What can Open Domain Model Tell Us about the Missing Software Requirements: A Preliminary Study completeness is one of the most important attributes of software requirement specification. unfortunately, incompleteness is one of the most difficult violations to detect. some approaches have been proposed to detect missing requirements based on the requirement-oriented domain model. however, these kinds of models are actually lack for lots of domains. fortunately, the domain models constructed for different purposes can usually be found online. this raises a question: whether or not these domain models are useful for finding the missing functional information in requirement specification? to explore this question, we design and conduct a preliminary study by computing the overlapping rate between the entities in domain models and the concepts of natural language software requirements, and then digging into four regularities of the occurrence of these entities(concepts) based on two example domains. the usefulness of these regularities, especially the one based our proposed metric ahme (with 54% and 70% of f2 on the two domains), has been initially evaluated with an additional experiment.",
            "contribution_ids": [
                "R193342"
            ]
        },
        {
            "instance_id": "R211935xR193357",
            "comparison_id": "R211935",
            "paper_id": "R193357",
            "text": "What\u00e2\u0080\u0099s up with Requirements Engineering for Artificial Intelligence Systems? in traditional approaches to building software systems (that do not include an artificial intelligent (ai) or machine learning (ml) component), requirements engineering (re) activities are well-established and researched. however, building software systems with one or more ai components may depend heavily on data with limited or no insight into the system\u2019s workings. therefore, engineering such systems poses significant new challenges to re. our search showed that literature has focused on using ai to manage re activities, with limited research on re for ai (re4ai). our study\u2019s main objective was to investigate current approaches in writing requirements for ai/ml systems, identify available tools and techniques used to model requirements, and find existing challenges and limitations. we performed a systematic literature review (slr) of current re4ai methods and identified 27 primary studies. using these studies, we analysed the key tools and techniques used to specify and model requirements and found several challenges and limitations of existing re4ai practices. we further provide recommendations for future research, based on our analysis of the primary studies and mapping to industry guidelines in google pair). the slr findings highlighted that present re applications were not adaptive to manage most ai/ml systems and emphasised the need to provide new techniques and tools to support re4ai.",
            "contribution_ids": [
                "R193358"
            ]
        },
        {
            "instance_id": "R212405xR212217",
            "comparison_id": "R212405",
            "paper_id": "R212217",
            "text": "Toward Dynamic Resources Management for IoT-Based Manufacturing the cyber-physical production system (cpps), which combines information communication technology, cyberspace virtual technology, and intelligent equipment technology, is accelerating the path of industry 4.0 to transform manufacturing from traditional to intelligent. the industrial internet of things integrates the key technologies of industrial communication, computing, and control, and is providing a new way for a wide range of manufacturing resources to optimize management and dynamic scheduling. in this article, ole for process control technology, software defined industrial network, and device-to-device communication technology are proposed to achieve efficient dynamic resource interaction. additionally, the integration of ontology modeling with multiagent technology is introduced to achieve dynamic management of resources. we propose a load balancing mechanism based on jena reasoning and contract-net protocol technology that focuses on intelligent equipment in the smart factory. dynamic resources management for iot-based manufacturing provides a solution for complex resource allocation problems in current manufacturing scenarios, and provides a technical reference point for the implementation of intelligent manufacturing in industry 4.0.",
            "contribution_ids": [
                "R212219"
            ]
        },
        {
            "instance_id": "R212405xR212226",
            "comparison_id": "R212405",
            "paper_id": "R212226",
            "text": "Product, process and resource model coupling for knowledge-driven assembly automation abstract accommodating frequent product changes in a short period of time is a challenging task due to limitations of the contemporary engineering approach to design, build and reconfigure automation systems. in particular, the growing quantity and diversity of manufacturing information, and the increasing need to exchange and reuse this information in an efficient way has become a bottleneck. to improve the engineering process, digital manufacturing and product, process and resource (ppr) modelling are considered very promising to compress development time and engineering cost by enabling efficient design and reconfiguration of manufacturing resources. however, due to ineffective coupling of ppr data, design and reconfiguration of assembly systems are still challenging tasks due to the dependency on the knowledge and experience of engineers. this paper presents an approach for data models integration that can be employed for coupling the ppr domain models for matching the requirements of products for assembly automation. the approach presented in this paper can be used effectively to link data models from various engineering domains and engineering tools. for proof of concept, an example implementation of the approach for modelling and integration of ppr for a festo test rig is presented as a case study.",
            "contribution_ids": [
                "R212228"
            ]
        },
        {
            "instance_id": "R212405xR212234",
            "comparison_id": "R212405",
            "paper_id": "R212234",
            "text": "Ontology-driven approach for describing industrial socio-cyberphysical systems\u00e2\u0080\u0099 components nowadays, the concept of the industrial internet of things is considered by researchers as the basis of industry 4.0. its use is aimed at creating a single information space that allows to unite all the components of production, starting from the processed raw materials to the interaction with suppliers and users of completed goods. such a union will allow to change the established business processes of production to increase the customization of end products for the consumer and to reduce the costs for its producers. each of the components is described using a digital twin, showing their main characteristics, important for production. the heterogeneity of these characteristics for each of the production levels makes it very difficult to exchange information between them. to solve the problem of interaction between individual components this paper proposes to use the ontological approach to model the components of industrial socio-cyberphysical systems. the paper considers four scenarios of interaction in the industrial internet of things, based on which the upper-level ontology is formed, which describes the main components of industrial socio-cyberphysical systems and the connections between them.",
            "contribution_ids": [
                "R212236"
            ]
        },
        {
            "instance_id": "R212457xR209355",
            "comparison_id": "R212457",
            "paper_id": "R209355",
            "text": "Comparative environmental impacts of Internal Combustion Engine Vehicles with Hybrid Vehicles and Electric Vehicles in China\u00e2\u0080\u0094Based on Life Cycle Assessment in china, the growth of new energy vehicles is especially rapid and the explosive growth of the automobile brought an increasing impact on the environment. this paper selected electric vehicles, hybrid vehicles and internal combustion engine vehicles of the same model of byd as the object. we established a life cycle assessment with gabi6 software and cml2001 model. the results show that in the whole life cycle, the influences of adp, gwp and odp of electric vehicles are less than that of hybrid vehicles and internal combustion engine vehicles. the impact of electric vehicles are 39%, 50%, and 4% of the internal combustion engine vehicles and the hybrid vehicles\u2019 impact are 65%, 78% and 85% of the internal combustion engine vehicles. electric vehicles and hybrid vehicles have a clear improvement in these three types of impacts. the comparison results of ap, ep, faetp, maetp and pocp show that the potential impact of electric vehicles is greater than that of hybrid vehicles and internal combustion engine vehicles. at present, improving production technology and reducing the consumption of energy during production phase are effective measures to reduce the environmental impact of internal combustion engine vehicles and hybrid vehicles of china.",
            "contribution_ids": [
                "R209357"
            ]
        },
        {
            "instance_id": "R212544xR212266",
            "comparison_id": "R212544",
            "paper_id": "R212266",
            "text": "A credibility-constrained programming for reliable forward\u00e2\u0080\u0093reverse logistics network design under uncertainty and facility disruptions this paper offers a credibility-constrained programming model for reliable design of an integrated forward\u2013reverse logistics network with hybrid facilities under uncertainty and random facility disruptions. to tackle with this problem, a novel mathematical model is first developed that integrates the network design decisions in both forward and reverse flows and utilises reliability concepts to deal with facility disruptions. then, the developed model is enhanced based on the credibility-constrained programing to cope with the epistemic uncertainties embedded in the model parameters. since the hybrid distribution-collection facilities play an important role in both forward and reverse flows, it is supposed that they might be randomly disrupted. several effective reliability strategies are considered to hedge against random facility disruptions. first, locating two types of hybrid facilities, namely, reliable and unreliable, is taken into account in the concerned logistics network when disruptions strike. second, unreliable hybrid facilities are allowed to be partially disrupted, and thus a percentage of their capacities may be lost. however, they can still serve their customers with their remaining capacities. to compensate the lost capacity at unreliable hybrid facilities, a sharing strategy is also considered, in which goods can be shipped from reliable hybrid facilities to unreliable ones. finally, several numerical experiments along with a sensitivity analysis are conducted to illustrate the significance and applicability of the developed model as well as the effectiveness of the credibility-based solution approach.",
            "contribution_ids": [
                "R212268"
            ]
        },
        {
            "instance_id": "R212902xR209379",
            "comparison_id": "R212902",
            "paper_id": "R209379",
            "text": "BOnSAI: a smart building ontology for ambient intelligence this work introduces an ontology for incorporating ambient intelligence in smart buildings. the ontology extends and benefits from existing ontologies in the field, but also adds classes needed to sufficiently model every aspect of a service-oriented smart building system. namely, it includes concepts modeling all functionality (i.e. services, operations, inputs, outputs, logic, parameters and environmental conditions), qos (resources, qos parameters), hardware (smart devices, sensors and actuators, appliances, servers) users and context (user profiles, moods, location, rooms etc.). the ontology is instantiated and put to use at the smart building setting of the international hellenic university, enabling knowledge representation in machine-interpretable form and hence is expected to enhance service-based intelligent applications.",
            "contribution_ids": [
                "R209381"
            ]
        },
        {
            "instance_id": "R212902xR212469",
            "comparison_id": "R212902",
            "paper_id": "R212469",
            "text": "EEPSA as a core ontology for energy efficiency and thermal comfort in buildings achieving a comfortable thermal situation within buildings with an efficient use of energy remains still an open challenge for most buildings. in this regard, iot (internet of things) and kdd (knowledge discovery in databases) processes may be combined to address these problems, even though data analysts may feel overwhelmed by heterogeneity and volume of the data to be considered. data analysts could benefit from an application assistant that supports them throughout the kdd process and aids them to discover which are the relevant variables for the matter at hand, or informing about relationships among relevant data. in this article, the eepsa (energy efficiency prediction semantic assistant) ontology which supports such an assistant is presented. the ontology is developed on the basis that a proper axiomatization shapes the set of admitted models better, and therefore, establishes the ground for a better interoperability. on the contrary, underspecification facilitates the admission of non-isomorphic models to represent the same state which hampers interoperability. this ontology is developed on top of three odps (ontology design patterns) which include proper axioms in order to improve precedent proposals to represent features of interest and their respective qualities, as well as observations and actuations, the sensors and actuators that generate them, and the procedures used. moreover, the ontology introduces six domain ontology modules integrated with the odps in such a manner that a methodical customization is facilitated.",
            "contribution_ids": [
                "R212471"
            ]
        },
        {
            "instance_id": "R212903xR209363",
            "comparison_id": "R212903",
            "paper_id": "R209363",
            "text": "Debunking Fake News by Leveraging Speaker Credibility and BERT Based Model the exponential growth in fake news and its role in deteriorating general public trust and democratic standards certainly calls for some counter combat approaches. the prediction of chances of news to be fake is deemed to be hard task since most of the deceptive news has its roots in true news. with a minor fabrication in legitimate news, influential fake news can be created that can be used for political, entertainment, or business-related gains. this work provides a novel intuitive approach to exploit data from multiple sources to segregate news into real and fake. to efficiently capture the contextual information present in the data, bidirectional encoder representations from transformer (bert) have been deployed. it attempts to further enhance the performance of the deceptive news detection model by incorporating information about the speaker profile and the credibility associated with him/her. a hybrid sequence encoding model has been proposed to harvest the speaker profile and speaker credibility data which makes it useful for prediction. on evaluation over benchmark fake news dataset liar, our model outperformed the previous state-of-the-art works. this attests to the fact that the speaker\u2019s profile and credibility play a crucial role in predicting the validity of news.",
            "contribution_ids": [
                "R209365"
            ]
        },
        {
            "instance_id": "R212903xR212763",
            "comparison_id": "R212903",
            "paper_id": "R212763",
            "text": "COVID-19 Fake News Detection by Using BERT and RoBERTa models we live in a world where covid-19 news is an everyday occurrence with which we interact. we are receiving that information, either consciously or unconsciously, without fact-checking it. in this regard, it has become an enormous challenge to keep only true covid-19 news relevant. people are exposed to these stories on a daily basis, and not all of them are true and fact-checked reports on the covid-19 pandemic, which was the primary reason for our research. we accepted the challenge that fake news is extremely common and that some people take these news as they are. knowing the true power of the most recent nlp achievements, in this research we focus on detecting fake news regarding covid-19. our approach includes using pre-trained bert and roberta models, which we then fine-tune on real and fake news about the covid-19 pandemic. by using pre-trained bert and roberta models on tweet data, we explore their capabilities and compare them to previous research in regard to fine-tuned bert models for this task in which we achieve better accuracy, recall and f1 score.",
            "contribution_ids": [
                "R212765"
            ]
        },
        {
            "instance_id": "R213136xR210370",
            "comparison_id": "R213136",
            "paper_id": "R210370",
            "text": "Intrusion Detection for Water Distribution Systems based on an Hybrid Particle Swarm Optimization with Back Propagation Neural Network the increasing integration of advanced information and communication tools in industrial control systems (ics) has vastly increased the vulnerabilities and threats of intrusions into the various critical infrastructures which include the water distribution system, electrical power system, etc. that rely on the ics systems. currently, providing and ensuring adequate security for these ics infrastructures are major concerns globally. the quick and accurate detection of any intrusive action into the ics systems is highly important. traditional intrusion detection systems (ids) have exhibited worrying forms of limitations and shortcomings due to the heterogeneity of different cyberattacks and intrusions. thus, there are needs to devise effective security measures. this paper proposes an ids model based on the hybridization of particle swarm optimization (pso) with back-propagation neural network (bpnn) for classifying intrusions in water system infrastructure. the pso is used to optimize the parameters for the bpnn, thus improving the efficiency of classification. for the validation of the proposed method, the itrust lab's secure water treatment dataset was used for experimentation. using prominent classification metrics, the 97% accuracy and 98.7% precision results achieved using the developed bpnn-pso model is better compared to other methods including models from related works. thus, the proposed model can meet the requirements of cyberattacks and intrusions detection in practical water distribution infrastructure.",
            "contribution_ids": [
                "R210372"
            ]
        },
        {
            "instance_id": "R213136xR213000",
            "comparison_id": "R213136",
            "paper_id": "R213000",
            "text": "Digital Twin-based Anomaly Detection in Cyber-physical Systems cyber-physical systems (cps) are susceptible to various anomalies during their operations. thus, it is important to detect such anomalies. detecting such anomalies is challenging since it is uncertain when and where anomalies can happen. to this end, we present a novel approach called anomaly detection with digital twin (attain), which continuously and automatically builds a digital twin with live data obtained from a cps for anomaly detection. attain builds a timed automaton machine (tam) as the digital representation of the cps, and implements a generative adversarial network (gan) to detect anomalies. gan uses a gcn-lstm-based module as a generator, which can capture temporal and spatial characteristics of the input data and learn to produce realistic unlabeled adversarial samples. tam labels these adversarial samples, which are then fed into a discriminator along with real labeled samples. after training, the discriminator is capable of distinguishing anomalous data from normal data with a high f1 score. to evaluate our approach, we used three publicly available datasets collected from three cps testbeds. evaluation results show that attain improved the performance of two state-of-art anomaly detection methods by 2.413%, 8.487%, and 5.438% on average on the three datasets, respectively. moreover, attain achieved on average 8.39% increase in the anomaly detection capability with digital twins as compared with an approach of not using digital twins.",
            "contribution_ids": [
                "R213002"
            ]
        },
        {
            "instance_id": "R213136xR213020",
            "comparison_id": "R213136",
            "paper_id": "R213020",
            "text": "Ensemble Neuroevolution-Based Approach for Multivariate Time Series Anomaly Detection multivariate time series anomaly detection is a widespread problem in the field of failure prevention. fast prevention means lower repair costs and losses. the amount of sensors in novel industry systems makes the anomaly detection process quite difficult for humans. algorithms that automate the process of detecting anomalies are crucial in modern failure prevention systems. therefore, many machine learning models have been designed to address this problem. mostly, they are autoencoder-based architectures with some generative adversarial elements. this work shows a framework that incorporates neuroevolution methods to boost the anomaly detection scores of new and already known models. the presented approach adapts evolution strategies for evolving an ensemble model, in which every single model works on a subgroup of data sensors. the next goal of neuroevolution is to optimize the architecture and hyperparameters such as the window size, the number of layers, and the layer depths. the proposed framework shows that it is possible to boost most anomaly detection deep learning models in a reasonable time and a fully automated mode. we ran tests on the swat and wadi datasets. to the best of our knowledge, this is the first approach in which an ensemble deep learning anomaly detection model is built in a fully automatic way using a neuroevolution strategy.",
            "contribution_ids": [
                "R213025"
            ]
        },
        {
            "instance_id": "R213302xR213160",
            "comparison_id": "R213302",
            "paper_id": "R213160",
            "text": "Identification of Fake News Using Machine Learning fake news has been a problem ever since the internet boomed. the very network that allows us to know what is happening globally is the perfect breeding ground for malicious and fake news. combating this fake news is important because the world's view is shaped by information. people not only make important decisions based on information but also form their own opinions. if this information is false it can have devastating consequences. verifying each news one by one by a human being is completely unfeasible. this paper attempts to expedite the process of identification of fake news by proposing a system that can reliably classify fake news. machine learning algorithms such as naive bayes, passive aggressive classifier and deep neural networks have being used on eight different datasets acquired from various sources. the paper also includes the analysis and results of each model. the arduous task of detection of fake news can be made trivial with the usage of the right models with the right tools.",
            "contribution_ids": [
                "R213162"
            ]
        },
        {
            "instance_id": "R213302xR213183",
            "comparison_id": "R213302",
            "paper_id": "R213183",
            "text": "BiLSTM-Autoencoder Architecture for Stance Prediction the recent surge in the abundance of fake news appearing on social media and news websites poses a potential threat to high-quality journalism. misinformation hurts people, society, science, and democracy. this reason has led many researchers to develop techniques to identify fake news. in this paper, we discuss a stance prediction technique using the deep learning approach, which can be used as a factor to determine the authenticity of news articles. the fake news stance prediction is the process of automatically classifying the stance of a news article towards a target into one of the following classes: agree, disagree, discuss, unrelated. the stance prediction task\u2019s input is the news articles containing a pair: a headline as the target and a body as a claim. this paper proposes a deep learning architecture using bi-directional long short term memory and autoencoder for stance prediction. we illustrate, through empirical studies, that the method is reasonably accurate at predicting stance, achieving a classification accuracy as high as 94%. the proposed stance detection method would be useful for assessing the credibility of news articles.",
            "contribution_ids": [
                "R213185"
            ]
        },
        {
            "instance_id": "R213302xR213194",
            "comparison_id": "R213302",
            "paper_id": "R213194",
            "text": "Deep Structure Learning for Rumor Detection on Twitter with the development of social media and the popularity of mobile devices, it becomes increasingly easy to post rumors and spread rumors on social media. widespread rumors may cause public panic and negative impact on individuals, which makes the automatic detection of rumors become necessary. most existing methods for automatic rumor detection focus on modeling features related to contents, users and propagation patterns based on feature engineering, but few work consider the existence of graph structural information in the user behavior. in this paper, we propose a model that leverages graph convolutional networks to capture user behavior effectively for rumor detection. our model is composed of three modules: 1) a user encoder that models users attributes and behaviors based on graph convolutional networks to obtain user representation; 2) a propagation tree encoder, which encodes the structure of the rumor propagation tree as a vector with bridging the content semantics and propagation clues; 3) an integrator that integrates the output of the above modules to identify rumors. experimental results on two public twitter datasets show that our model achieves much better performance than the state-of-the-art methods.",
            "contribution_ids": [
                "R213196"
            ]
        },
        {
            "instance_id": "R214198xR214065",
            "comparison_id": "R214198",
            "paper_id": "R214065",
            "text": "Identity and Aggregate Signature-Based Authentication Protocol for IoD Deployment Military Drone with the rapid miniaturization in sensor technology, ruddervator, arduino, and multi-rotor system, drone technology has fascinated researchers in the field of network security. it is of critical significance given the advancement in modern strategic narratives. this has special relevance to drone-related operations. this technology can be controlled remotely by an invisible yet credible operator sitting to a powerful intelligence computer system (pics) or an airborne control and command platform (ac2p). the two types of drones (reconnaissance and attacking) can communicate with each other and with the pics or ac2p through wireless network channels referred to as flying ad hoc network or unmanned aerial vehicular network (fanet or uavn). this mode of communication is not without some inconvenience. for instance, when the line of sight is broken, communication is mainly carried out through satellite using gps (global positioning system) signals. both gps and uavn/fanet use open network channels for data broadcasting, which are exposed to several threats, thus making security risky and challenging. this risk is specifically eminent in monitoring data transmission traffic, espionage, troop movement, border surveillance, searching, and warfare battlefield phenomenon, etc. this issue of security risk can be minimized conspicuously by developing a robust authentication scheme for iod deployment military drones. therefore, this research illustrates the designing of two separate protocols based on the aggregate signature, identity, pairing cryptography, and computational diffie-hellman problem (cdhp) to guarantee data integrity, authorization, and confidentiality among drones and ac2p/pics. more importantly, the outdated data transmission flaw has also been tackled, which is of obvious concern to the past designed protocols. the security of the proposed designs is formally verified using a random oracle model (rom), a real-or-random (ror) model, and by informally using pragmatic illustration and mathematical lemmas. nonetheless, the performance analysis section will be executed using the algorithmic big-o notation. the results show that these protocols are verifiably protected in the rom and ror model using the cdhp.",
            "contribution_ids": [
                "R214066"
            ]
        },
        {
            "instance_id": "R214266xR213954",
            "comparison_id": "R214266",
            "paper_id": "R213954",
            "text": "AnCora: Multilevel Annotated Corpora for Catalan and Spanish this paper presents ancora, a multilingual corpus annotated at different linguistic levels consisting of 500,000 words in catalan (ancora-ca) and in spanish (ancora-es). at present ancora is the largest multilayer annotated corpus of these languages freely available from http://clic.ub.edu/ancora. the two corpora consist mainly of newspaper texts annotated at different levels of linguistic description: morphological (pos and lemmas), syntactic (constituents and functions), and semantic (argument structures, thematic roles, semantic verb classes, named entities, and wordnet nominal senses). all resulting layers are independent of each other, thus making easier the data management. the annotation was performed manually, semiautomatically, or fully automatically, depending on the encoded linguistic information. the development of these basic resources constituted a primary objective, since there was a lack of such resources for these languages. a second goal was the definition of a consistent methodology that can be followed in further annotations. the current versions of ancora have been used in several international evaluation competitions",
            "contribution_ids": [
                "R213958",
                "R213975"
            ]
        },
        {
            "instance_id": "R215025xR213602",
            "comparison_id": "R215025",
            "paper_id": "R213602",
            "text": "First detection and genome sequencing of SARS\u00e2\u0080\u0090CoV\u00e2\u0080\u00902 in an infected cat in France summary after its first description in wuhan (china), sars\u2010cov\u20102 the agent of coronavirus disease 2019 (covid\u201019) rapidly spread worldwide. previous studies suggested that pets could be susceptible to sars\u2010cov\u20102. here, we investigated the putative infection by sars\u2010cov\u20102 in 22 cats and 11 dogs from owners previously infected or suspected of being infected by sars\u2010cov\u20102. for each animal, rectal, nasopharyngeal swabs and serum were taken. swabs were submitted to rt\u2010qpcr assays targeting 2 genes of sars\u2010cov\u20102. all dogs were tested sars\u2010cov\u20102 negative. one cat was tested positive by rt\u2010qpcr on rectal swab. nasopharyngeal swabs from this animal were tested negative. this cat showed mild respiratory and digestive signs. serological analysis confirms the presence of antibodies against the sars\u2010cov\u20102 in the both serum samples taken 10 days apart. genome sequence analysis revealed that the cat sars\u2010cov\u20102 belongs to the phylogenetic clade a2a like most of the french human sars\u2010cov\u20102. this study reports for the first time the natural infection of a cat in france (near paris) probably through their owners. there is currently no evidence that cats can spread covid\u201019 and owners should not abandon their pets or compromise their welfare.",
            "contribution_ids": [
                "R213605",
                "R213611"
            ]
        },
        {
            "instance_id": "R215025xR213984",
            "comparison_id": "R215025",
            "paper_id": "R213984",
            "text": "SARS-CoV-2 Reverse Zoonoses to Pumas and Lions, South Africa reverse-zoonotic infections of severe acute respiratory syndrome-related coronavirus 2 (sars-cov-2) from humans to wildlife species internationally raise concern over the emergence of new variants in animals. a better understanding of the transmission dynamics and pathogenesis in susceptible species will mitigate the risk to humans and wildlife occurring in africa. here we report infection of an exotic puma (july 2020) and three african lions (july 2021) in the same private zoo in johannesburg, south africa. one health genomic surveillance identified transmission of a delta variant from a zookeeper to the three lions, similar to those circulating in humans in south africa. one lion developed pneumonia while the other cases had mild infection. both the puma and lions remained positive for sars-cov-2 rna for up to 7 weeks.",
            "contribution_ids": [
                "R213989",
                "R213990"
            ]
        },
        {
            "instance_id": "R215025xR214307",
            "comparison_id": "R215025",
            "paper_id": "R214307",
            "text": "Co-circulation of two SARS-CoV-2 variant strains within imported pet hamsters in Hong Kong abstract during the investigation of a pet shop outbreak of severe acute respiratory coronavirus 2 (sars-cov-2) with probable hamster-to-human transmission, the environmental and hamster samples in epidemiologically linked pet shops were found positive for sars-cov-2 delta variant ay.127 strains which are phylogenetically closely related to patients and reported european strains. this interspecies\u2019 spill-over has triggered transmission in 58 patients epidemiologically linked to three pet shops. incidentally, three dwarf hamsters imported from the netherlands and centralized in a warehouse distributing animals to pet shops were positive for sars-cov-2 spike variant phylogenetically related to european b.1.258 strains from march 2020. this b.1.258 strain almost disappeared in july 2021. while no hamster-to-human transmission of b.1.258-like strain was found in this outbreak, molecular docking showed that its spike receptor-binding domain (rbd) has a similar binding energy to human ace2 compared to that of delta variant ay.127. therefore, the potential of this b.1.258-related spike variant for interspecies jumping cannot be ignored. the co-circulation of b.1.258-related spike variants with delta ay.127, which originated in europe and was not previously found in hong kong, suggested that hamsters in our wholesale warehouse and retail pet shops more likely have acquired these viruses in the netherlands or stopovers during delivery by aviation than locally. the risk of human-to-hamster reverse zoonosis by multiple sars-cov-2 variants leading to further adaptive spike mutations with subsequent transmission back to humans cannot be underestimated as an outbreak source of covid-19. testing imported pet animals susceptible to sars-cov-2 is warranted to prevent future outbreaks.",
            "contribution_ids": [
                "R214312"
            ]
        },
        {
            "instance_id": "R25093xR25070",
            "comparison_id": "R25093",
            "paper_id": "R25070",
            "text": "Leveraging online social networks and external data sources to predict personality over the past decade, people have been expressing more and more of their personalities online. online social networks such as facebook.com capture much of individuals\\' personalities through their published interests, attributes and social interactions. knowledge of an individual\\'s personality can be of wide utility, either for social research, targeted marketing or a variety of other fields a key problem to predicting and utilizing personality information is the myriad of ways it is expressed across various people, locations and cultures. similarly, a model predicting personality based on online data which cannot be extrapolated to \"real world\" situations is of limited utility for researchers. this paper presents initial work done on generating a probabilistic model of personality which uses representations of people\\'s connections to other people, places, cultures, and ideas, as expressed through face book. to this end, personality was predicted using a machine learning method known as a bayesian network. the model was trained using face book data combined with external data sources to allow further inference. the results of this paper present one predictive model of personality that this project has produced. this model demonstrates the potential of this methodology in two ways: first, it is able to explain up to 56% of all variation in a personality trait from a sample of 615 individuals. second it is able to clearly present how this variability is explained through findings such as how to determine how agreeable a man is based on his age, number of face book wall posts, and his willingness to disclose his preference for music made by lady gaga.",
            "contribution_ids": [
                "R25071"
            ]
        },
        {
            "instance_id": "R25093xR25079",
            "comparison_id": "R25093",
            "paper_id": "R25079",
            "text": "Machine prediction of personality from Facebook profiles \"an increasing number of americans use social networking sites such as facebook, but few fully appreciate the amount of information they share with the world as a result. although studies exist on the sharing of specific types of information (photos, posts, etc.), one area that has been less explored is how facebook profiles can share personality information in a broad, machine-readable fashion. in this study, we apply data-mining and machine learning techniques to predict users' personality traits (specifically, the traits of the big five personality model) using only demographic and text-based attributes extracted from their profiles. we then use these predictions to rank individuals in terms of the five traits, predicting which users will appear in the top or bottom 5% or 10% of these traits. our results show that when using certain models, we can find the top 10% most open individuals with nearly 75% accuracy, and across all traits and directions, we can predict the top 10% with at least 34.5% accuracy (exceeding 21.8%, which is the best accuracy when using just the best-performing profile attribute). these results have privacy implications in terms of allowing advertisers and other groups to focus on a specific subset of individuals based on their personality traits.\"",
            "contribution_ids": [
                "R25080"
            ]
        },
        {
            "instance_id": "R25093xR25083",
            "comparison_id": "R25093",
            "paper_id": "R25083",
            "text": "Evaluating Content-Independent Features for Personality Recognition this paper describes our submission for the wcpr14 shared task on computational personality recognition. we have investigated whether the features proposed by soler and wanner (2014) for gender prediction might also be useful in personality recognition. we have compared these features with simple approaches using token unigrams, character trigrams and liwc features. although the newly investigated features seem to work quite well on certain personality traits, they do not outperform the simple approaches.",
            "contribution_ids": [
                "R25084"
            ]
        },
        {
            "instance_id": "R25093xR25085",
            "comparison_id": "R25093",
            "paper_id": "R25085",
            "text": "Recognising personality traits using facebook status updates \"gaining insight in a web user's personality is very valuable for applications that rely on personalisation, such as recommender systems and personalised advertising. in this paper we explore the use of machine learning techniques for inferring a user's personality traits from their facebook status updates. even with a small set of training examples we can outperform the majority class baseline algorithm. furthermore, the results are improved by adding training examples from another source. this is an interesting result because it indicates that personality trait recognition generalises across social media platforms.\"",
            "contribution_ids": [
                "R25086"
            ]
        },
        {
            "instance_id": "R25115xR25105",
            "comparison_id": "R25115",
            "paper_id": "R25105",
            "text": "User gains and PD aims \"we present a study of user gains from their participation in a participatory design (pd) project at danish primary schools. we explore user experiences and reported gains from the project in relation to the multiple aims of pd, based on a series of interviews with pupils, teachers, administrators, and consultants, conducted approximately three years after the end of the project. in particular, we reflect on how the pd initiatives were sustained after the project had ended. we propose that not only are ideas and initiatives disseminated directly within the organization, but also through networked relationships among people, stretching across organizations and project groups. moreover, we demonstrate how users' gains related to their acting within these networks. these results suggest a heightened focus on the indirect and distributed channels through which the long-term impact of pd emerges.\"",
            "contribution_ids": [
                "R25106"
            ]
        },
        {
            "instance_id": "R25115xR25107",
            "comparison_id": "R25115",
            "paper_id": "R25107",
            "text": "Participants' view on personal gains and PD process \"while it is commonly claimed that users of participatory design projects reap benefits from their participation, little research exists that shows if this truly occurs in the real world. in this paper, we introduce the method and results of assessing the participants' perception of their personal benefits and the degree of participation in a large project in the healthcare field. our research shows that a well-executed participatory design project can produce most of the benefits hypothesized in the literature but also highlights the challenges of assessing individual benefits and the pd process.\"",
            "contribution_ids": [
                "R25108"
            ]
        },
        {
            "instance_id": "R25160xR25124",
            "comparison_id": "R25160",
            "paper_id": "R25124",
            "text": "\"Should I stay or should I go?\" \"ambient lighting systems have been introduced by several manufacturers to increase the driver's comfort. also, some works proposed warning systems based on light displays. expanding on those works, we are searching for designs of lumicons (i.e. light patterns) that can not only warn drivers in critical situations but also keep them informed in a non-distracting way. we present first ideas for lumicons for a given scenario coming from a participatory design process.\"",
            "contribution_ids": [
                "R25125"
            ]
        },
        {
            "instance_id": "R25160xR25139",
            "comparison_id": "R25160",
            "paper_id": "R25139",
            "text": "LED-A-pillars as the chassis of cars become more robust, the pillars of a car become broader in order to increase driver safety. as a-pillars grow wider, so too does their negative affect on the panoramic view of the driver and with a smaller field of vision, the risk of overlooking a pedestrian or an object outside the car increases. in order to deal with a-pillar blind spots, this project examined how distances and directions of possible obstacles can be displayed and how different visualization types with led strips on the a-pillars can affect drivers perception. the result of this study shows that such a prototype improves the panoramic view for car drivers resulting in higher security for road users.",
            "contribution_ids": [
                "R25140"
            ]
        },
        {
            "instance_id": "R25160xR25144",
            "comparison_id": "R25160",
            "paper_id": "R25144",
            "text": "GPS enabled speed control embedded system speed limiting device with display and engine control interface \"in the past decade, there have been close to 350,000 fatal crashes in the united states [1]. with various improvements in traffic and vehicle safety, the number of such crashes is decreasing every year. one of the ways to reduce vehicle crashes is to prevent excessive speeding in the roads and highways. the paper aims to outline the design of an embedded system that will automatically control the speed of a motor vehicle based on its location determined by a gps device. the embedded system will make use of an avr atmega128 microcontroller connected to an em-406a gps receiver. the large amount of location input data justifies the use of an atmega128 microcontroller which has 128kb of programmable flash memory as well as 4kb sram, and a 4kb eeprom memory [2]. the output of the atmega128 will be a dogmi63w-a lcd module which will display information of the current and the set-point speed of the vehicle at the current position. a discrete indicator led will flash at a pre-determined frequency when the speed of the vehicle has exceeded the recommended speed limit. finally, the system will have outputs that will communicate with the engine control unit (ecu) of the vehicle. for the limited scope of this project, the ecu is simulated as an external device with two inputs that will acknowledge pulse-trains of particular frequencies to limit the speed of a vehicle. the speed control system will be programmed using mixed language c and assembly with the latter in use for some pre-written subroutines to drive the lcd module. the gps module will transmit national marine electronics association (nmea) data strings to the microcontroller (mcu) using serial peripheral interface (spi). the mcu will use the location coordinates (latitude and longitude) and the speed from the nmea rmc output string. the current speed is then compared against the recommended speed for the vehicle's location. the memory locations in the atmega128 can be used to store set-point speed values against a particular set of location co-ordinates. apart from its implementation in human operated vehicles, the project can be used to control speed of autonomous cars and to implement the idea of a variable speed limit on roads introduced by the department of transportation [3].\"",
            "contribution_ids": [
                "R25145"
            ]
        },
        {
            "instance_id": "R25160xR25146",
            "comparison_id": "R25160",
            "paper_id": "R25146",
            "text": "ChaseLight in order to support drivers to maintain a predefined driving speed, we introduce chaselight, an in-car system that uses a programmable led stripe mounted along the a-pillar of a car. the chase light (i.e., stripes of adjacent leds that are turned on and off frequently to give the illusion of lights moving along the stripe) provides ambient feedback to the driver about speed. we present a simulator based user study that uses three different types of feedback: (1) chase light with constant speed, (2) with proportional speed (i.e., chase light speed correlates with vehicle speed), and (3) with adaptive speed (i.e., chase light speed adapts to a target speed of the vehicle). our results show that the adaptive condition is suited best to help a driver to control driving speed. the proportional speed condition resulted in a significantly slower mean speed than the baseline condition (no chase light).",
            "contribution_ids": [
                "R25147"
            ]
        },
        {
            "instance_id": "R25160xR25156",
            "comparison_id": "R25160",
            "paper_id": "R25156",
            "text": "heart rate electric vehicles (evs) are an emerging technology and open up an exciting new space for designing in-car interfaces. this technology enhances driving experience by a strong acceleration, regenerative breaking and especially a reduced noise level. however, engine vibrations and sound transmit valuable feedback to drivers of conventional cars, e.g. signaling that the engine is running and ready to go. we address this lack of feedback with heartbeat, a multimodal electric vehicle information system. heartbeat communicates (1) the state of the electric drive including energy flow and (2) the energy level of the batteries in a natural and experienceable way. we enhance the underlying experience design process by formulating working principles derived from an experience story in order to transport its essence throughout the following design phases. this way, we support the design of a consistent experience and resolve the tension between implementation constraints (e.g., space) and the persistence of the underlying story while building prototypes and integrating them into a technical environment (e.g., a dashboard).",
            "contribution_ids": [
                "R25157"
            ]
        },
        {
            "instance_id": "R25160xR25158",
            "comparison_id": "R25160",
            "paper_id": "R25158",
            "text": "TactiCar while deciding if it is possible to overtake a slower car, drivers have to take several factors into account. accident statistics show that many drivers make mistakes in this sit-uation. we want to assist drivers during lane change deci-sion without raising his or her mental workload. since vision is already highly loaded to assess the situation, we address vibration in this work and investigated if it is possible to con-tinuously inform drivers about a closing car using a vibro-tactile belt. we developed two different tactile patterns and tested them in a driving simulator. both patterns achieved promising results regarding usability. in the future, we plan to refine the patterns and evaluate the impact on workload and safety.",
            "contribution_ids": [
                "R25159"
            ]
        },
        {
            "instance_id": "R25201xR25180",
            "comparison_id": "R25201",
            "paper_id": "R25180",
            "text": "Off-line English and Chinese Signature Identification Using Foreground and Background Features in the field of information security, the usage of biometrics is growing for user authentication. automatic signature recognition and verification is one of the biometric techniques, which is only one of several used to verify the identity of individuals. in this paper, a foreground and background based technique is proposed for identification of scripts from bi-lingual (english/roman and chinese) off-line signatures. this system will identify whether a claimed signature belongs to the group of english signatures or chinese signatures. the identification of signatures based on its script is a major contribution for multi-script signature verification. two background information extraction techniques are used to produce the background components of the signature images. gradient-based method was used to extract the features of the foreground as well as background components. zernike moment feature was also employed on signature samples. support vector machine (svm) is used as the classifier for signature identification in the proposed system. a database of 1120 (640 english+480 chinese) signature samples were used for training and 560 (320 english+240 chinese) signature samples were used for testing the proposed system. an encouraging identification accuracy of 97.70% was obtained using gradient feature from the experiment.",
            "contribution_ids": [
                "R25181"
            ]
        },
        {
            "instance_id": "R25201xR25191",
            "comparison_id": "R25201",
            "paper_id": "R25191",
            "text": "GMM For Offline Signature Forgery Detection as signature continues to play a crucial part in personal identification for number of applications including financial transaction, an efficient signature authentication system becomes more and more important. various researches in the field of signature authentication has been dynamically pursued for many years and its extent is still being explored. signature verification is the process which is carried out to determine whether a given signature is genuine or forged. it can be distinguished into two types such as the online and the offline. in this paper we presented the offline signature verification system and extracted some new local and geometric features like quadsurface feature, area ratio, distance ratio etc. for this we have taken some genuine signatures from 5 different persons and extracted the features from all of the samples after proper preprocessing steps. the training phase uses gaussian mixture model (gmm) technique to obtain a reference model for each signature sample of a particular user. by computing euclidian distance between reference signature and all the training sets of signatures, acceptance range is defined. if the euclidian distance of a query signature is within the acceptance range then it is detected as an authenticated signature else, a forged signature.",
            "contribution_ids": [
                "R25192"
            ]
        },
        {
            "instance_id": "R25201xR25193",
            "comparison_id": "R25201",
            "paper_id": "R25193",
            "text": "Discriminative DCT: An Efficient and Accurate Approach for Off-line Signature Verification in this paper, we proposed to combine the transform based approach with dimensionality reduction technique for off-line signature verification. the proposed approach has four major phases: preprocessing, feature extraction, feature reduction and classification. in the feature extraction phase, discrete cosine transform (dct) is employed on the signature image to obtain the upper-left corner block of size mx n as a representative feature vector. these features are subjected to linear discriminant analysis (lda) for further reduction and representing the signature with optimal set of features. thus obtained features from all the samples in the dataset form the knowledge base. the support vector machine (svm), a bilinear classifier is used for classification and the performance is measured through far/frr metric. experiments have been conducted on standard signature datasets namely cedar and gpds-160, and mukos, a regional language (kannada) dataset. the comparative study is also provided with the well known approaches to exhibit the performance of the proposed approach.",
            "contribution_ids": [
                "R25194"
            ]
        },
        {
            "instance_id": "R25223xR25209",
            "comparison_id": "R25223",
            "paper_id": "R25209",
            "text": "Distributed Selfish Replication a commonly employed abstraction for studying the object placement problem for the purpose of internet content distribution is that of a distributed replication group. in this work, the initial model of the distributed replication group of leff et al. [check end of sentence] is extended to the case that individual nodes act selfishly, i.e., cater to the optimization of their individual local utilities. our main contribution is the derivation of equilibrium object placement strategies that 1) can guarantee improved local utilities for all nodes concurrently as compared to the corresponding local utilities under greedy local object placement, 2) do not suffer from potential mistreatment problems, inherent to centralized strategies that aim at optimizing the social utility, and 3) do not require the existence of complete information at all nodes. we develop a baseline computationally efficient algorithm for obtaining the aforementioned equilibrium strategies and then extend it to improve its performance with respect to fairness. both algorithms are realizable, in practice, through a distributed protocol that requires only a limited exchange of information.",
            "contribution_ids": [
                "R25210"
            ]
        },
        {
            "instance_id": "R25223xR25215",
            "comparison_id": "R25223",
            "paper_id": "R25215",
            "text": "A Distributed Algorithm for Web content Replication web caching and replication techniques increase accessibility of web contents and reduce internet bandwidth requirements. in this paper, we are considering the replica placement problem in a distributed replication group. the replication group consists of servers dedicating certain amount of memory for replicating objects. the replica placement problem is to place the replica at the servers within the replication group such that the access time over all objects and servers is minimized. we design a distributed 2-approximation algorithm that solves this optimization problem. we show that the communication and computational complexity of the algorithm is polynomial in the number of servers and objects. we perform simulation experiments to investigate the performance of our algorithm.",
            "contribution_ids": [
                "R25216"
            ]
        },
        {
            "instance_id": "R25223xR25205",
            "comparison_id": "R25223",
            "paper_id": "R25205",
            "text": "A QOS-Aware Intelligent Replica Management Architecture for Content Distribution in Peer-to-Peer Overlay Networks the large scale content distribution systems were improved broadly using the replication techniques. the demanded contents can be brought closer to the clients by multiplying the source of information geographically, which in turn reduce both the access latency and the network traffic. the system scalability can be improved by distributing the load across multiple servers which is proposed by replication. if a copy of the requested object (e.g., a web page or an image) is located in its closer proximity then the clients would feel low access latency. depending on the position of the replicas, the effectiveness of replication tends to a large extent. a qos based overlay network architecture involving an intelligent replica placement algorithm is proposed in this paper. its main goal is to improve the network utilization and fault tolerance of the p2p system. in addition to the replica placement, it also has a caching technique, to reduce the search latency. we are able to show that our proposed architecture attains less latency and better throughput with reduced bandwidth usage, through the simulation results. keywords-clusters, content, overlay, qos, replica, routing",
            "contribution_ids": [
                "R25206"
            ]
        },
        {
            "instance_id": "R25255xR25245",
            "comparison_id": "R25255",
            "paper_id": "R25245",
            "text": "Automatic expandable large-scale sentiment lexicon of modern standard Arabic and colloquial in subjectivity and sentiment analysis (ssa), there are two main requirements are necessary to improve sentiment analysis effectively in any language and genres, first, high coverage sentiment lexicon - where entries are tagged with semantic orientation (positive, negative and neutral) - second, tagged corpora to train the sentiment classifier. much of research has been conducted in this area during the last decade, but the need of building these resources is still ongoing, especially for morphologically-rich language (mrl) such as arabic. in this paper, we present an automatic expandable wide coverage polarity lexicon of arabic sentiment words, this lexical resource explicitly devised for supporting arabic sentiment classification and opinion mining applications. the lexicon is built using a seed of gold-standard arabic sentiment words which are manually collected and annotated with semantic orientation (positive or negative), and automatically expanded with sentiment orientation detection of the new sentiment words by exploiting some lexical information such as part-of-speech (pos) tags and using synset aggregation techniques from free online arabic lexicons, thesauruses. we report efforts to expand a manually-built our polarity lexicon using different types of data. finally, we used various tagged data to evaluate the coverage and quality of our polarity lexicon, moreover, to evaluate the lexicon expansion and its effects on the sentiment analysis accuracy. our data focus on modern standard arabic (msa) and egyptian dialectal arabic tweets and arabic microblogs (hotel reservation, product reviews, and tv program comments).",
            "contribution_ids": [
                "R25246"
            ]
        },
        {
            "instance_id": "R25255xR25241",
            "comparison_id": "R25255",
            "paper_id": "R25241",
            "text": "SANA: A large scale multi-genre, multi-dialect lexicon for Arabic subjectivity and sentiment analysis the computational treatment of subjectivity and sentiment in natural language is usually significantly improved by applying features exploiting lexical resources where entries are tagged with semantic orientation (e.g., positive, negative values). in spite of the fair amount of work on arabic sentiment analysis over the past few years (e.g., (abbasi et al., 2008; abdul-mageed et al., 2014; abdul-mageed et al., 2012; abdul-mageed and diab, 2012a; abdul-mageed and diab, 2012b; abdul-mageed et al., 2011a; abdul-mageed and diab, 2011)), the language remains under-resourced as to these polarity repositories compared to the english language. in this paper, we report efforts to build and present sana, a large-scale, multi-genre, multi-dialect multi-lingual lexicon for the subjectivity and sentiment analysis of the arabic language and dialects.",
            "contribution_ids": [
                "R25242"
            ]
        },
        {
            "instance_id": "R25255xR25249",
            "comparison_id": "R25255",
            "paper_id": "R25249",
            "text": "NileULex: A phrase and word level sentiment lexicon for egyptian and modern standard Arabic this paper presents nileulex, which is an arabic sentiment lexicon containing close to six thousands arabic words and compound phrases. forty five percent of the terms and expressions in the lexicon are egyptian or colloquial while fifty five percent are modern standard arabic. while the collection of many of the terms included in the lexicon was done automatically, the actual addition of any term was done manually. one of the important criterions for adding terms to the lexicon, was that they be as unambiguous as possible. the result is a lexicon with a much higher quality than any translated variant or automatically constructed one. to demonstrate that a lexicon such as this can directly impact the task of sentiment analysis, a very basic machine learning based sentiment analyser that uses unigrams, bigrams, and lexicon based features was applied on two different twitter datasets. the obtained results were compared to a baseline system that only uses unigrams and bigrams. the same lexicon based features were also generated using a publicly available translation of a popular sentiment lexicon. the experiments show that usage of the developed lexicon improves the results over both the baseline and the publicly available lexicon.",
            "contribution_ids": [
                "R25250"
            ]
        },
        {
            "instance_id": "R25358xR25276",
            "comparison_id": "R25358",
            "paper_id": "R25276",
            "text": "Semantics-based composition-oriented discovery of Web services service discovery and service aggregation are two crucial issues in the emerging area of service-oriented computing (soc). we propose a new technique for the discovery of (web) services that accounts for the need of composing several services to satisfy a client query. the proposed algorithm makes use of owl-s ontologies, and explicitly returns the sequence of atomic process invocations that the client must perform in order to achieve the desired result. when no full match is possible, the algorithm features a flexible matching by returning partial matches and by suggesting additional inputs that would produce a full match.",
            "contribution_ids": [
                "R25277"
            ]
        },
        {
            "instance_id": "R25358xR25280",
            "comparison_id": "R25358",
            "paper_id": "R25280",
            "text": "Discovering semantic Web services via advanced graph-based matching one of the main advantages of web services is that they can be composed into more complex processes in order to achieve a given business goal. however, such potentiality cannot be fully exploited until suitable methods and techniques allowing us to enable automatic discovery of composed processes are provided. indeed, nowadays service discovery still focuses on matching atomic services by typically checking the similarity of functional parameters, such as inputs and outputs. however, a more profitable process discovering can be reached if both internal structure and component services are taken into account. based on this main intuition, in this paper we describe a method for discovering composite owl-s processes that founds on the following main contributions: (i) proposing a graph-based representation of composite owl-s processes; and (ii) introducing an algorithm that matches over such (graph-based) representations and computes their degree of matching via combining the similarity of the atomic services they comprise and the similarity of the control flow among them. finally, as another contribution of our research, we conducted a comprehensive experimental campaign where we tested our proposed algorithm by deriving insightful trade-offs of benefits and limitations of the overall framework for discovering semantic web services.",
            "contribution_ids": [
                "R25281"
            ]
        },
        {
            "instance_id": "R25358xR25285",
            "comparison_id": "R25358",
            "paper_id": "R25285",
            "text": "YASA-M: A Semantic Web Service Matchmaker in this paper, we present new algorithms for matching web services described in yasa4wsdl (yasa for short). we have already defined yasa, a semantic description of services that overcomes some issues in wsdl or sawsdl. in this paper, we continue on our contribution and show how yasa web services are matched based on the specificities of yasa descriptions. our matching algorithm consists of three variants based on three different semantic matching degree aggregations. this algorithm was implemented in yasa-m, a new web service matchmaker. yasa-m is evaluated and compared to well known approaches for service matching. experiments show that yasa-m provides better results, in terms of precision, response time, and scalability, than a well known matchmaker.",
            "contribution_ids": [
                "R25286"
            ]
        },
        {
            "instance_id": "R25358xR25290",
            "comparison_id": "R25358",
            "paper_id": "R25290",
            "text": "An abstract model of service discovery and binding abstract \\n we propose a formal operational semantics for service discovery and binding. this semantics is based on a graph-based representation of the configuration of global computers typed by business activities. business activities execute distributed workflows that can trigger, at run time, the discovery, ranking and selection of services to which they bind, thus reconfiguring the workflows that they execute. discovery, ranking and selection are based on compliance with required business and interaction protocols and optimisation of quality-of-service constraints. binding and reconfiguration are captured as algebraic operations on configuration graphs. we also discuss the methodological implications that this model framework has on software engineering using a typical travel-booking scenario. to the best of our knowledge, our approach is the first to provide a clear separation between service computation and discovery/instantiation/binding, and to offer a formal framework that is independent of the soa middleware components that act as service registries or brokers, and the protocols through which bindings and invocations are performed.",
            "contribution_ids": [
                "R25291"
            ]
        },
        {
            "instance_id": "R25358xR25311",
            "comparison_id": "R25358",
            "paper_id": "R25311",
            "text": "Web Service Matching by Ontology Instance Categorization identifying similar web services is becoming increasingly important to ensure the success of dynamically integrated web-service-based applications. we propose a categorization-based scheme to match equivalent web services that can operate on heterogeneous domain ontologies. given the upper ontology for services and domain ontologies, our service matching scheme determines whether a given web service is a possible replacement using a categorization utility called onexcat. onexcat categorizes ontology instances extracted from the service descriptions by a probabilistic categorization measurement that incorporates the concept relationships in the upper ontology for services. in addition to tackling the issue of heterogeneity of domain ontology in service descriptions using categorization, our matching scheme also adapts itself by enhancing the known ontologies with newly discovered ontology instances. experiments on service matching using our matching scheme based on the onexcat utility have been performed with promising results, a correct matching rate of over 85%.",
            "contribution_ids": [
                "R25312"
            ]
        },
        {
            "instance_id": "R25358xR25331",
            "comparison_id": "R25358",
            "paper_id": "R25331",
            "text": "Research on Fuzzy Matching Model for Semantic Web Services semantic descriptions of web services are necessary in order to enable their automatic discovery, composition and execution across heterogeneous users and domains on the basis of ontology. matching approach is considered as one of the crucial factors to ensure dynamic discovery and composition of web services. current matching methods such as uddi or larks are inadequate given their inability to abstract and classify web services. therefore proposes a novel matching model which exploits fuzzy logic in order to abstract and classify the underlying data of web services by fuzzy terms and rules. the aim is to make the match between service advertisement with service request more effective and allow vague terms in the search query and to provide more suited services for requesters.",
            "contribution_ids": [
                "R25332"
            ]
        },
        {
            "instance_id": "R25358xR25350",
            "comparison_id": "R25358",
            "paper_id": "R25350",
            "text": "A New Framework for Web Service Discovery Based on Behavior \"with the rapid expanse of the web service over the internet, discovering related web service is becoming the most urgent problem. traditional methods focus on the interfaces of service through using ontology without considering service behavior. in this paper, the calculus of communicating systems(ccs) is exploited to specify web service's behavior, weak equivalence on behavior is used for matchmaking between the advertised service and the requested service. then, the paper combines behavior matching with fuzzy similarity of ontological concept to propose a new matching algorithm for web service. therefore, a promising framework for web service discovery is proposed.\"",
            "contribution_ids": [
                "R25351"
            ]
        },
        {
            "instance_id": "R25400xR25367",
            "comparison_id": "R25400",
            "paper_id": "R25367",
            "text": "Evolving object oriented design to improve code traceability traceability is a key issue to ensure consistency among software artifacts of subsequent phases of the development cycle. however, few works have so far addressed the theme of tracing object oriented design into its implementation and evolving it. the paper presents an approach to checking the compliance of oo design with respect to source code and support its evolution. the process works on design artifacts expressed in the omt notation and accepts c++ source code. it recovers an \"as is\" design from the code, compares recovered design with the actual design and helps the user to deal with inconsistencies. the recovery process exploits the edit distance computation and the maximum match algorithm to determine traceability links between design and code. the output is a similarity measure associated to each matched class, plus a set of unmatched classes. a graphic display of the design with different colors associated to different levels of match is provided as a support to update the design and improve its traceability to the code.",
            "contribution_ids": [
                "R25368"
            ]
        },
        {
            "instance_id": "R25400xR25391",
            "comparison_id": "R25400",
            "paper_id": "R25391",
            "text": "The molhado hypertext versioning system \"this paper describes molhado, a hypertext versioning and software configuration management system that is distinguished from previous systems by its flexible product versioning and structural configuration management model. the model enables a unified versioning framework for atomic and composite software artifacts, and hypermedia structures among them in a fine-grained manner at the logical level. hypermedia structures are managed separately from documents' contents. molhado explicitly represents hyperlinks, allowing them to be browsed, visualized, and systematically analyzed. molhado not only versions complex hypermedia structures (e.g., multi links), but also supports versioning of individual hyperlinks. this paper focuses on molhado's hypertext versioning and its use in the software concordance environment to manage the evolution of a software project and hypermedia structures.\"",
            "contribution_ids": [
                "R25392"
            ]
        },
        {
            "instance_id": "R25400xR25398",
            "comparison_id": "R25400",
            "paper_id": "R25398",
            "text": "Architectural point mapping for design traceability aop can be applied to not only modularization of crosscutting concerns but also other kinds of software development processes. as one of the applications, this paper proposes a design traceability mechanism originating in join points and pointcuts. it is not easy to design software architecture reflecting the intention of developers and implement the result of design as a program while preserving the architectural correctness. to deal with this problem, we propose two novel ideas: archpoint (architectural point) and archmapping (archpoint mapping). archpoints are points for representing the essence of architectural design in terms of behavioral and structural aspects. by defining a set of archpoints, we can describe the inter-component structure and the message interaction among components. archmapping is a mechanism for checking the bidirectional traceability between design and code. the traceability can be verified by checking whether archpoints in design are consistently mapped to program points in code. for this checking, we use an smt (satisfiability modulo theories) solver, a tool for deciding the satisfiability of logical formulas. the idea of archpoints, program points, and their selection originates in aop.",
            "contribution_ids": [
                "R25399"
            ]
        },
        {
            "instance_id": "R25447xR25404",
            "comparison_id": "R25447",
            "paper_id": "R25404",
            "text": "A Reliability Evaluation Framework on Composite Web Service the composition of web-based services is a process that usually requires advanced programming skills and vast knowledge about specific technologies. how to carry out web service composition according to functional sufficiency and performance is widely studied. non-functional characteristics like reliability and security play an important role in the selection of web services composition process. this paper provides a web service reliability model for atomic web service without structural information and the composite web service consist of atomic web service and its redundant services. it outlines a framework based on client feedback to gather trustworthiness attributes to service registry for reliability evaluation.",
            "contribution_ids": [
                "R25405"
            ]
        },
        {
            "instance_id": "R25447xR25416",
            "comparison_id": "R25447",
            "paper_id": "R25416",
            "text": "Dependability and Rollback Recovery For Composite Web Services in this paper, we propose a service-oriented reliability model that dynamically calculates the reliability of composite web services with rollback recovery based on the real-time reliabilities of the atomic web services of the composition. our model is a hybrid reliability model based on both path-based and state-based models. many reliability models assume that failure or error arrival times are exponentially distributed. this is inappropriate for web services as error arrival times are dependent on the operating state including workload of servers where the web service resides. in this manuscript, we modify our previous model (for software based on the doubly stochastic model and renewal processes) to evaluate the reliability of atomic web services. in order to fix our idea, we developed the case of one simple web service which contains two states, i.e., idle and active states. in real-world applications, where web services could contain quite a large number of atomic services, the calculus as well as the computing complexity increases greatly. to limit our computing efforts and calculus, we chose the bounded set techniques that we apply using the previously developed stochastic model. as a first type of system combination, we proposed to study a scheme based on combining web services into parallel and serial configurations with centralized coordination. in this case, the broker has an acceptance testing mechanism that examines the results returned from a particular web service. if it was acceptable, then the computation continues to the next web service. otherwise, it involves rollback and invokes another web service already specified by a checkpoint algorithm. finally, the acceptance test is conducted using the broker. the broker can be considered as a single point of failure. to increase the reliability of the broker introduced in our systems and mask out errors at the broker level, we suggest a modified general scheme based on triple modular redundancy and n-version programming. to imitate a real scenario where errors could happen at any stage of our application and improve the quality of service qos of the proposed model, we introduce fault-tolerance techniques using an adaption of the recovery block technique.",
            "contribution_ids": [
                "R25417"
            ]
        },
        {
            "instance_id": "R25447xR25426",
            "comparison_id": "R25447",
            "paper_id": "R25426",
            "text": "An Enhance Approach For Web Services Discovery with QoS \"the quality of service for web services here mainly refers to the quality aspect of a web service. the qos for web services is becoming increasingly important to service providers and service requesters due to increasing use of web services. web services providing similar functionalities, more emphasis is being placed on how to find the service that best fits the consumer's requirements. in order to find services that best meet their qos requirements, the service consumers and/or discovery agents need to know both the qos information for the services and the reliability of this information. in this paper first of all we implement reputation-enhanced web services discovery protocol. and after implementation we enhance the protocol over memory used, time to discovery and response time of given web service.\"",
            "contribution_ids": [
                "R25427"
            ]
        },
        {
            "instance_id": "R25495xR25449",
            "comparison_id": "R25495",
            "paper_id": "R25449",
            "text": "Robust PBPK/PD-Based Model Predictive Control of Blood Glucose goal: automated glucose control (agc) has not yet reached the point where it can be applied clinically [3]. challenges are accuracy of subcutaneous (sc) glucose sensors, physiological lag times, and both inter- and intraindividual variability. to address above issues, we developed a novel scheme for mpc that can be applied to agc. results: an individualizable generic whole-body physiology-based pharmacokinetic and dynamics (pbpk/pd) model of the glucose, insulin, and glucagon metabolism has been used as the predictive kernel. the high level of mechanistic detail represented by the model takes full advantage of the potential of mpc and may make long-term prediction possible as it captures at least some relevant sources of variability [4]. robustness against uncertainties was increased by a control cascade relying on proportional-integrative derivative-based offset control. the performance of this agc scheme was evaluated in silico and retrospectively using data from clinical trials. this analysis revealed that our approach handles sensor noise with a mard of 10%-14%, and model uncertainties and disturbances. conclusion: the results suggest that pbpk/pd models are well suited for mpc in a glucose control setting, and that their predictive power in combination with the integrated database-driven (a priori individualizable) model framework will help overcome current challenges in the development of agc systems. significance: this study provides a new, generic, and robust mechanistic approach to agc using a pbpk platform with extensive a priori (database) knowledge for individualization.",
            "contribution_ids": [
                "R25450"
            ]
        },
        {
            "instance_id": "R25495xR25457",
            "comparison_id": "R25495",
            "paper_id": "R25457",
            "text": "Event-Triggered Model Predictive Control for Embedded Artificial Pancreas Systems objective: the development of artificial pancreas (ap) technology for deployment in low-energy, embedded devices is contingent upon selecting an efficient control algorithm for regulating glucose in people with type 1 diabetes mellitus. in this paper, we aim to lower the energy consumption of the ap by reducing controller updates, that is, the number of times the decision-making algorithm is invoked to compute an appropriate insulin dose. methods: physiological insights into glucose management are leveraged to design an event-triggered model predictive controller (mpc) that operates efficiently, without compromising patient safety. the proposed event-triggered mpc is deployed on a wearable platform. its robustness to latent hypoglycemia, model mismatch, and meal misinformation is tested, with and without meal announcement, on the full version of the us-fda accepted uva/padova metabolic simulator. results: the event-based controller remains on for 18\\xa0h of 41\\xa0h in closed loop with unannounced meals, while maintaining glucose in 70\u2013180\\xa0mg/dl for 25\\xa0h, compared to 27\\xa0h for a standard mpc controller. with meal announcement, the time in 70\u2013180\\xa0mg/dl is almost identical, with the controller operating a mere 25.88% of the time in comparison with a standard mpc. conclusion: a novel control architecture for ap systems enables safe glycemic regulation with reduced processor computations. significance: our proposed framework integrated seamlessly with a wide variety of popular mpc variants reported in ap research, customizes tradeoff between glycemic regulation and efficacy according to prior design specifications, and eliminates judicious prior selection of controller sampling times.",
            "contribution_ids": [
                "R25458"
            ]
        },
        {
            "instance_id": "R25495xR25475",
            "comparison_id": "R25495",
            "paper_id": "R25475",
            "text": "Modeling Day-to-Day Variability of Glucose\u00e2\u0080\u0093Insulin Regulation Over 12-Week Home Use of Closed-Loop Insulin Delivery parameters of physiological models of glucose\u2013insulin regulation in type 1 diabetes have previously been estimated using data collected over short periods of time and lack the quantification of day-to-day variability. we developed a new hierarchical model to relate subcutaneous insulin delivery and carbohydrate intake to continuous glucose monitoring over 12 weeks while describing day-to-day variability. sensor glucose data sampled every 10-min, insulin aspart delivery and meal intake were analyzed from eight adults with type 1 diabetes (male/female 5/3, age ${\\\\text{39.9}\\\\,\\\\pm \\\\,\\\\text{9.5}}$ years, bmi $\\\\text{25.4}\\\\,\\\\pm \\\\,\\\\text{4.4 kg/ m}^{2}$ , hba1c ${\\\\text{8.4}\\\\,\\\\pm \\\\,\\\\text{0.6}}$ %) who underwent a 12-week home study of closed-loop insulin delivery. a compartment model comprised of five linear differential equations; model parameters were estimated using the markov chain monte carlo approach within a hierarchical bayesian model framework. physiologically, plausible a posteriori distributions of model parameters including insulin sensitivity, time-to-peak insulin action, time-to-peak gut absorption, and carbohydrate bioavailability, and good model fit were observed. day-to-day variability of model parameters was estimated in the range of 38\u201379% for insulin sensitivity and 27\u201348% for time-to-peak of insulin action. in conclusion, a linear bayesian hierarchical approach is feasible to describe a 12-week glucose\u2013insulin relationship using conventional clinical data. the model may facilitate in silico testing to aid the development of closed-loop insulin delivery systems.",
            "contribution_ids": [
                "R25476"
            ]
        },
        {
            "instance_id": "R25529xR25507",
            "comparison_id": "R25529",
            "paper_id": "R25507",
            "text": "The formation and interplay of social capital in crowdfunded social ventures \"the multi-levelled processes taking place in crowdfunding (cf), when tapping a large heterogeneous crowd for resources, and the often fundamentally different intentions of individual crowd members in the case of highly desirable social ventures with little prospect for economic gains, may lead to a different logic and approach to how entrepreneurship develops. using this under-institutionalized sphere as both, context and subject, the author seeks evidence and a new understanding of entrepreneurial routes by using the sociological perspectives of bourdieus' four forms of capital as a lens on 36 cases of social ventures. in the cases, opportunity recognition, formation and exploitation could not be distinguished as separate processes. cf and sourcing help form the actual opportunity and disperse information at the same time. in addition, the \u2018nexus\u2019 of opportunity and entrepreneur is breached in cf of social causes through the constant exchange of ideas with the crowd, leading to norm-value pairs between the funders and the entrepreneurs. issues of identification and control are thus not based upon any formal relationship but based on perceived legitimization and offered democratic participation leading to the transformation of social capital (sc) into economic capital (ec). success is based upon the sc of the entrepreneurial teams, yet the actual resource exchange and transformation into ec is highly moderated by cultural and symbolic capital that is being built up through the process.\"",
            "contribution_ids": [
                "R25508"
            ]
        },
        {
            "instance_id": "R25529xR25509",
            "comparison_id": "R25529",
            "paper_id": "R25509",
            "text": "Entrepreneurial implications of crowdfunding as alternative funding source for innovations crowdfunding (cf) is a form of early-stage financing for innovative ventures, which has seen tremendous growth in the past few years \u2013 partly because it provides a desperately needed alternative to the scarcity of traditional sources of finance during the so called \u2018credit crunch\u2019. cf ranges from a simple form of pre-financing to full grown debt or equity investments, but they are typically small pledges that can add up to incredible amounts. scholarly literature has only started to examine cf and is still in an early stage when it comes to identifying implications for entrepreneurs apart from often over-simplified anecdotal evidence of success. the authors argue that cf can by no means be seen from a financial perspective only, rather it needs to be addressed as a bundle of processes leading to innovative entrepreneurial business-models. this qualitative study explores four extreme cases from the information and communications technology sphere to find out non-financial implications of cf as alternative funding source for innovative entrepreneurs and their business models.",
            "contribution_ids": [
                "R25510"
            ]
        },
        {
            "instance_id": "R25529xR25521",
            "comparison_id": "R25529",
            "paper_id": "R25521",
            "text": "The backer\u00e2\u0080\u0093developer connection: Exploring crowdfunding\u00e2\u0080\u0099s influence on video game production as video game development studios increasingly turn to digital crowdfunding platforms such as kickstarter for financing, this article explores the ways in which these processes shape production. it examines in particular the interactions that typically occur between studios and players as part of crowdfunded development, analysing the ways in which these activities inform aspects of video game design. by charting the implications of this burgeoning economic model, the article contributes to scholarship concerning video game production and intervenes within more specific discussions concerning the role of the player within development. the article\u2019s case study, which draws from evidence of production concerning multiple kickstarter projects, is organised into two sections. the first ascertains the degrees to which kickstarter users can influence the details of a proposed project during a crowdfunding campaign; the second looks at how developers involve crowdfunding communities within production once funding is secured.",
            "contribution_ids": [
                "R25522"
            ]
        },
        {
            "instance_id": "R25583xR25533",
            "comparison_id": "R25583",
            "paper_id": "R25533",
            "text": "A Flexible Model-Driven Game Development Approach game developers are facing an increasing demand for new games every year. game development tools can be of great help, but require highly specialized professionals. also, just as any software development effort, game development has some challenges. model-driven game development (mdgd) is suggested as a means to solve some of these challenges, but with a loss in flexibility. we propose a mdgd approach that combines multiple domain-specific languages (dsls) with design patterns to provide flexibility and allow generated code to be integrated with manual code. after experimentation, we observed that, with the approach, less experienced developers can create games faster and more easily, and the product of code generation can be customized with manually written code, providing flexibility. however, with mdgd, developers become less familiar with the code, making manual codification more difficult.",
            "contribution_ids": [
                "R25534"
            ]
        },
        {
            "instance_id": "R25583xR25535",
            "comparison_id": "R25583",
            "paper_id": "R25535",
            "text": "Automatic prototyping in model-driven game development model-driven game development (mdgd) is an emerging paradigm where models become first-order elements in game development, maintenance, and evolution. in this article, we present a first approach to 2d platform game prototyping automatization through the use of model-driven engineering (mde). platform-independent models (pim) define the structure and the behavior of the games and a platform-specific model (psm) describes the game control mapping. automatic mofscript transformations from these models generate the software prototype code in c++. as an example, bubble bobble has been prototyped in a few hours following the mdgd approach. the resulting code generation represents 93% of the game prototype.",
            "contribution_ids": [
                "R25536"
            ]
        },
        {
            "instance_id": "R25583xR25537",
            "comparison_id": "R25583",
            "paper_id": "R25537",
            "text": "Building a Game Engine: A Tale of Modern Model-Driven Engineering game engines enable developers to reuse assets from previously developed games, thus easing the software-engineering challenges around the video-game development experience and making the implementation of games less expensive, less technologically brittle, and more efficient. however, the construction of game engines is challenging in itself, it involves the specification of well defined architectures and typical game play behaviors, flexible enough to enable game designers to implement their vision, while, at the same time, simplifying the implementation through asset and code reuse. in this paper we present a set of lessons learned through the design and construction phydsl-2, a game engine for 2d physics-based games. our experience involves the active use of modern model-driven engineering technologies, to overcome the complexity of the engine design and to systematize its maintenance and evolution.",
            "contribution_ids": [
                "R25538"
            ]
        },
        {
            "instance_id": "R25583xR25551",
            "comparison_id": "R25583",
            "paper_id": "R25551",
            "text": "Model-driven development of interactive and integrated 2D and 3D user interfaces using mml while there is a lot of research done in the area of 2d or 3d user interfaces (uis) construction, comparatively little is known about systematic approaches to designing and developing integrated 2d/3d uis and applications. the previously developed multimedia modeling language (mml) provides a top down approach for a model driven development of 2d/3d uis and applications. the mml structure model and media components provide support for including x3d based content and automatic generation of application skeletons. we use a work instruction manual for a woodchipper as an example to illustrate how to apply mml. we discuss the ramifications of this approach and opportunities for some improvements.",
            "contribution_ids": [
                "R25552"
            ]
        },
        {
            "instance_id": "R25583xR25569",
            "comparison_id": "R25583",
            "paper_id": "R25569",
            "text": "Engine- Cooperative Game Modeling (ECGM) today game engines are popular in commercial game development, as they lower the threshold of game production by providing common technologies and convenient content-creation tools. game engine based development is therefore the mainstream methodology in the game industry. model-driven game development (mdgd) is an emerging game development methodology, which applies the model-driven software development (mdsd) method in the game development domain. this simplifies game development by reducing the gap between game design and implementation. mdgd has to take advantage of the existing game engines in order to be useful in commercial game development practice. however, none of the existing mdgd approaches in literature has convincingly demonstrated good integration of its tools with the game engine tool-chain. in this paper, we propose a hybrid approach named ecgm to address the integration challenges of two methodologies with a focus on the technical aspects. the approach makes a run-time engine the base of the domain framework, and uses the game engine tool-chain together with the mdgd tool-chain. ecgm minimizes the change to the existing workflow and technology, thus reducing the cost and risk of adopting mdgd in commercial game development. our contribution is one important step towards mdgd industrialization.",
            "contribution_ids": [
                "R25570"
            ]
        },
        {
            "instance_id": "R25583xR25571",
            "comparison_id": "R25583",
            "paper_id": "R25571",
            "text": "A Model-Based Approach for Designing Location-Based Games \"location-based games (lbgs) are a subclass of pervasive games that make use of location technologies to consider the players' geographic position in the game rules and mechanics. this research presents a model to describe and represent lbgs. the proposed model decouples location, mechanics, and game content from their implementation. we aim at allowing lbgs to be edited quickly and deployed on many platforms. the core model component is legal, a language derived from ncl (nested context language) to model and represented the game structure and its multimedia contents (e.g., video, audio, 3d objects, etc.). it allows the modelling of mission-based games by supporting spatial and temporal relationships between game elements and multimedia documents. we validated our approach by implementing a legal interpreter, which was coupled to an lbg authoring tool and a game server. these tools enabled us to reimplement a real lbg using the proposed model to attest its utility. we also edited the original game by using an external tool to showcase how simple is to transpose an lbg using the concepts introduced in this work. results indicate both the model and legal can be used to foster the design of lbgs.\"",
            "contribution_ids": [
                "R25572"
            ]
        },
        {
            "instance_id": "R25583xR25579",
            "comparison_id": "R25583",
            "paper_id": "R25579",
            "text": "Improving digital game development with software product lines \"introducing reuse and software product line (spl) concepts into digital game-development processes isn't a straightforward task. this work presents a systematic process for bridging spls to game development, culminating with domain-specific languages and generators streamlined for game subdomains. the authors present a game spl for arcade games as a case study to illustrate and evaluate their proposed guidelines. this article is part of a special issue on games.\"",
            "contribution_ids": [
                "R25580"
            ]
        },
        {
            "instance_id": "R25629xR25591",
            "comparison_id": "R25629",
            "paper_id": "R25591",
            "text": "Usage and Perceptions of Agile Software Development in an Industrial Context: An Exploratory Study agile development methodologies have been gaining acceptance in the mainstream software development community. while there are numerous studies of agile development in academic and educational settings, there has been little detailed reporting of the usage, penetration and success of agile methodologies in traditional, professional software development organizations. we report on the results of an empirical study conducted at microsoft to learn about agile development and its perception by people in development, testing, and management. we found that one-third of the study respondents use agile methodologies to varying degrees, and most view it favorably due to improved communication between team members, quick releases and the increased flexibility of agile designs. the scrum variant of agile methodologies is by far the most popular at microsoft. our findings also indicate that developers are most worried about scaling agile to larger projects (greater than twenty members), attending too many meetings and the coordinating agile and non-agile teams.",
            "contribution_ids": [
                "R25592"
            ]
        },
        {
            "instance_id": "R25629xR25597",
            "comparison_id": "R25629",
            "paper_id": "R25597",
            "text": "An empirical study on the relationship between the use of agile practices and the success of Scrum projects \"in this article, factors considered critical for the success of projects managed using scrum are correlated to the results of software projects in industry. using a set of 25 factors compiled in by other researchers, a cross section survey was conducted to evaluate the presence or application of these factors in 11 software projects that used scrum in 9 different software companies located in recife-pe, brazil. the questionnaire was applied to 65 developers and scrum masters, representing 75% (65/86) of the professionals that have participated in the projects. the result was correlated with the level of success achieved by the projects, measured by the subjective perception of the project participant, using spearman's rank correlation coefficient. the main finding is that only 32% (8/25) of the factors correlated positively with project success, raising the question of whether the factors hypothesized in the literature as being critical to the success of agile software projects indeed have an effect on project success. given the limitations regarding the generalization of this result, other forms of empirical results, in particular case-studies, are needed to test this question.\"",
            "contribution_ids": [
                "R25598"
            ]
        },
        {
            "instance_id": "R25629xR25605",
            "comparison_id": "R25629",
            "paper_id": "R25605",
            "text": "Agile Team Perceptions of Productivity Factors in this paper, we investigate agile team perceptions of factors impacting their productivity. within this overall goal, we also investigate which productivity concept was adopted by the agile teams studied. we here conducted two case studies in the industry and analyzed data from two projects that we followed for six months. from the perspective of agile team members, the three most perceived factors impacting on their productivity were appropriate team composition and allocation, external dependencies, and staff turnover. teams also mentioned pair programming and collocation as agile practices that impact productivity. as a secondary finding, most team members did not share the same understanding of the concept of productivity. while some known factors still impact agile team productivity, new factors emerged from the interviews as potential productivity factors impacting agile teams.",
            "contribution_ids": [
                "R25606"
            ]
        },
        {
            "instance_id": "R25629xR25612",
            "comparison_id": "R25629",
            "paper_id": "R25612",
            "text": "Investigating the Long-Term Acceptance of Agile Methodologies: An Empirical Study of Developer Perceptions in Scrum Projects agile development methodologies have gained great interest in research and practice. as their introduction considerably changes traditional working habits of developers, the long-term acceptance of agile methodologies becomes a critical success factor. yet, current studies primarily examine the early adoption stage of agile methodologies. to investigate the long-term acceptance, we conducted a study at a leading insurance company that introduced scrum in 2007. using a qualitative research design and the diffusion of innovations theory as a lens for analysis, we gained in-depth insights into factors influencing the acceptance of scrum. particularly, developers felt scrum to be more compatible to their actual working practices. moreover, they perceived the use of scrum to deliver numerous relative advantages. however, we also identified possible barriers to acceptance since developers felt both the complexity of scrum and the required discipline to be higher in comparison with traditional development methodologies.",
            "contribution_ids": [
                "R25613"
            ]
        },
        {
            "instance_id": "R25663xR25641",
            "comparison_id": "R25663",
            "paper_id": "R25641",
            "text": "An empirical task analysis of warehouse order picking using head-mounted displays evaluations of task guidance systems often focus on evaluations of new technologies rather than comparing the nuances of interaction across the various systems. one common domain for task guidance systems is warehouse order picking. we present a method involving an easily reproducible ecologically motivated order picking environment for quantitative user studies designed to reveal differences in interactions. using this environment, we perform a 12 participant within-subjects experiment demonstrating the advantages of a head-mounted display based picking chart over a traditional text-based pick list, a paper-based graphical pick chart, and a mobile pick-by-voice system. the test environment proved sufficiently sensitive, showing statistically significant results along several metrics with the head-mounted display system performing the best. we also provide a detailed analysis of the strategies adopted by our participants.",
            "contribution_ids": [
                "R25642"
            ]
        },
        {
            "instance_id": "R25663xR25653",
            "comparison_id": "R25663",
            "paper_id": "R25653",
            "text": "A comparison of order picking assisted by head-up display (HUD), cart-mounted display (CMD), light, and paper pick list wearable and contextually aware technologies have great applicability in task guidance systems. order picking is the task of collecting items from inventory in a warehouse and sorting them for distribution; this process accounts for about 60% of the total operational costs of these warehouses. current practice in industry includes paper pick lists and pick-by-light systems. we evaluated order picking assisted by four approaches: head-up display (hud); cart-mounted display (cmd); pick-by-light; and paper pick list. we report accuracy, error types, task time, subjective task load and user preferences for all four approaches. the findings suggest that pick-by-hud and pick-by-cmd are superior on all metrics to the current practices of pick-by-paper and pick-by-light.",
            "contribution_ids": [
                "R25654"
            ]
        },
        {
            "instance_id": "R25663xR25661",
            "comparison_id": "R25663",
            "paper_id": "R25661",
            "text": "A Comparative Study of an Assistance System for Manual Order Picking -- Called Pick-by-Projection -- with the Guiding Systems Pick-by-Paper, Pick-by-Light and Pick-by-Display changes and innovations are needed in the area of instruction and control of employees to perform reliably and cost effective in order picking. the information must be easily accessible - communicated in a succinct way to overcome intellectual, socio-educational as well as language barriers. this case mainly focuses on conducting, research in the field of technical support by assistance systems for impaired people and people with altered performance, but also for people without restrictions. this paper aims at presenting the prototype of a new assistance system for manual order picking. in addition, the prototype was evaluated in a user study involving 24 people with three other methods (pick-by-paper, pick-by-light, pick-by-display), which represent the current state of the art. we report about the number of errors, the task completion time and the cognitive workload for all four approaches. the results show that this new kind of assistance system can have benefits, particularly in the area of error prevention and workload.",
            "contribution_ids": [
                "R25662"
            ]
        },
        {
            "instance_id": "R25694xR25683",
            "comparison_id": "R25694",
            "paper_id": "R25683",
            "text": "Information content based ranking metric for linked open vocabularies it is widely accepted that by controlling metadata, it is easier to publish high quality data on the web. metadata, in the context of linked data, refers to vocabularies and ontologies used for describing data. with more and more data published on the web, the need for reusing controlled taxonomies and vocabularies is becoming more and more a necessity. catalogues of vocabularies are generally a starting point to search for vocabularies based on search terms. some recent studies recommend that it is better to reuse terms from \"popular\" vocabularies [4]. however, there is not yet an agreement on what makes a popular vocabulary since it depends on diverse criteria such as the number of properties, the number of datasets using part or the whole vocabulary, etc. in this paper, we propose a method for ranking vocabularies based on an information content metric which combines three features: (i) the datasets using the vocabulary, (ii) the outlinks from the vocabulary and (iii) the inlinks to the vocabulary. we applied this method to 366 vocabularies described in the lov catalogue. the results are then compared with other catalogues which provide alternative rankings.",
            "contribution_ids": [
                "R25684"
            ]
        },
        {
            "instance_id": "R25726xR25701",
            "comparison_id": "R25726",
            "paper_id": "R25701",
            "text": "GrOWL: A Tool for Visualization and Editing of OWL Ontologies in an effort to optimize visualization and editing of owl ontologies we have developed growl-a browser and visual editor for owl that accurately visualizes the underlying dl semantics of owl ontologies while avoiding the difficulties of the verbose owl syntax. in this paper, we discuss growl visualization model and the essential visualization techniques implemented in growl.",
            "contribution_ids": [
                "R25702"
            ]
        },
        {
            "instance_id": "R25726xR6457",
            "comparison_id": "R25726",
            "paper_id": "R6457",
            "text": "Using Hierarchical Edge Bundles to visualize complex ontologies in GLOW \"in the past decade, much effort has been put into the visual representation of ontologies. however, present visualization strategies are not equipped to handle complex ontologies with many relations, leading to visual clutter and inefficient use of space. in this paper, we propose glow, a method for ontology visualization based on hierarchical edge bundles. hierarchical edge bundles is a new visually attractive technique for displaying relations in hierarchical data, such as concept structures formed by 'subclass-of' and 'type-of' relations. we have developed a visualization library based on owl api, as well as a plug-in for prot\u00e9g\u00e9, a well-known ontology editor. the displayed adjacency relations can be selected from an ontology using a set of common configurations, allowing for intuitive discovery of information. our evaluation demonstrates that the glow visualization provides better visual clarity, and displays relations and complex ontologies better than the existing prot\u00e9g\u00e9 visualization plug-in jambalaya.\"",
            "contribution_ids": [
                "R25717",
                "R6458"
            ]
        },
        {
            "instance_id": "R25726xR25722",
            "comparison_id": "R25726",
            "paper_id": "R25722",
            "text": "Visualizing ontologies with VOWL the visual notation for owl ontologies (vowl) is a well-specified visual language for the user-oriented representation of ontologies. it defines graphical depictions for most elements of the web ontology language (owl) that are combined to a force-directed graph layout visualizing the ontology. in contrast to related work, vowl aims for an intuitive and comprehensive representation that is also understandable to users less familiar with ontologies. this article presents vowl in detail and describes its implementation in two different tools: protegevowl and webvowl. the first is a plugin for the ontology editor protege, the second a standalone web application. both tools demonstrate the applicability of vowl by means of various ontologies. in addition, the results of three user studies that evaluate the comprehensibility and usability of vowl are summarized. they are complemented by findings from an interview with experienced ontology users and from testing the visual scope and completeness of vowl with a benchmark ontology. the evaluations helped to improve vowl and confirm that it produces comparatively intuitive and comprehensible ontology visualizations.",
            "contribution_ids": [
                "R25723"
            ]
        },
        {
            "instance_id": "R25762xR25728",
            "comparison_id": "R25762",
            "paper_id": "R25728",
            "text": "A fast high utility itemsets mining algorithm association rule mining (arm) identifies frequent itemsets from databases and generates association rules by considering each item in equal value. however, items are actually different in many aspects in a number of real applications, such as retail marketing, network log, etc. the difference between items makes a strong impact on the decision making in these applications. therefore, traditional arm cannot meet the demands arising from these applications. by considering the different values of individual items as utilities, utility mining focuses on identifying the itemsets with high utilities. as \"downward closure property\" doesn\\'t apply to utility mining, the generation of candidate itemsets is the most costly in terms of time and memory space. in this paper, we present a two-phase algorithm to efficiently prune down the number of candidates and can precisely obtain the complete set of high utility itemsets. in the first phase, we propose a model that applies the \"transaction-weighted downward closure property\" on the search space to expedite the identification of candidates. in the second phase, one extra database scan is performed to identify the high utility itemsets. we also parallelize our algorithm on shared memory multi-process architecture using common count partitioned database (ccpd) strategy. we verify our algorithm by applying it to both synthetic and real databases. it performs very efficiently in terms of speed and memory cost, and shows good scalability on multiple processors, even on large databases that are difficult for existing algorithms to handle.",
            "contribution_ids": [
                "R25729"
            ]
        },
        {
            "instance_id": "R25762xR25756",
            "comparison_id": "R25762",
            "paper_id": "R25756",
            "text": "A trie-based APRIORI implementation for mining frequent item sequences \"in this paper we investigate a trie-based apriori algorithm for mining frequent item sequences in a transactional database. we examine the data structure, implementation and algorithmic features mainly focusing on those that also arise in frequent itemset mining. in our analysis we take into consideration modern processors' properties (memory hierarchies, prefetching, branch prediction, cache line size, etc.), in order to better understand the results of the experiments.\"",
            "contribution_ids": [
                "R25757"
            ]
        },
        {
            "instance_id": "R25762xR25732",
            "comparison_id": "R25762",
            "paper_id": "R25732",
            "text": "Fast Algorithms for Mining Association Rules we consider the problem of discovering association rules between items in a large database of sales transactions. we present two new algorithms for solving thii problem that are fundamentally different from the known algorithms. empirical evaluation shows that these algorithms outperform the known algorithms by factors ranging from three for small problems to more than an order of magnitude for large problems. we also show how the best features of the two proposed algorithms can be combined into a hybrid algorithm, called apriorihybrid. scale-up experiments show that apriorihybrid scales linearly with the number of transactions. apriorihybrid also has excellent scale-up properties with respect to the transaction size and the number of items in the database.",
            "contribution_ids": [
                "R25733"
            ]
        },
        {
            "instance_id": "R25857xR25783",
            "comparison_id": "R25857",
            "paper_id": "R25783",
            "text": "Pd@C core\u00e2\u0080\u0093shell nanoparticles on carbon nanotubes as highly stable and selective catalysts for hydrogenation of acetylene to ethylene highly stable and selective pd-based catalyst was synthesized by covering supported pd nanoparticles with an n-doped carbon shell for acetylene hydrogenation.",
            "contribution_ids": [
                "R25784"
            ]
        },
        {
            "instance_id": "R25857xR25789",
            "comparison_id": "R25857",
            "paper_id": "R25789",
            "text": "Ag Alloyed Pd Single-Atom Catalysts for Efficient Selective Hydrogenation of Acetylene to Ethylene in Excess Ethylene semihydrogenation of acetylene in an ethylene-rich stream is an industrially important process. conventional supported monometallic pd catalysts offer high acetylene conversion, but they suffer from very low selectivity to ethylene due to overhydrogenation and the formation of carbonaceous deposits. herein, a series of ag alloyed pd single-atom catalysts, possessing only ppm levels of pd, supported on silica gel were prepared by a simple incipient wetness coimpregnation method and applied to the selective hydrogenation of acetylene in an ethylene-rich stream under conditions close to the front-end employed by industry. high acetylene conversion and simultaneous selectivity to ethylene was attained over a wide temperature window, surpassing an analogous au alloyed pd single-atom system we previously reported. restructuring of agpd nanoparticles and electron transfer from ag to pd were evidenced by in situ ftir and in situ xps as a function of increasing reduction temperature. microcalorimetry and xanes measurements support both geometric and electronic synergetic effects between the alloyed pd and ag. kinetic studies provide valuable insight into the nature of the active sites within these agpd/sio2 catalysts, and hence, they provide evidence for the key factors underpinning the excellent performance of these bimetallic catalysts toward the selective hydrogenation of acetylene under ethylene-rich conditions while minimizing precious metal usage.",
            "contribution_ids": [
                "R25790"
            ]
        },
        {
            "instance_id": "R25857xR25807",
            "comparison_id": "R25857",
            "paper_id": "R25807",
            "text": "Nanosizing Intermetallic Compounds Onto Carbon Nanotubes: Active and Selective Hydrogenation Catalysts therefore, nanosizing andsupporting the annealed metal products remain challenges.another difficulty is in directly preparing supportedcatalysts while simultaneously obtaining good crystallite sizecontrol. a good catalyst support should be capable ofinhibiting sintering and loss of the catalyst during reaction.fabrication of supported intermetallics catalysts in nanoscaledimensionsrequiresareliablemethodthatfacilitatesnotonlysize control but a thermally stable phase under reactionconditions. since the work of iijima in 1991,",
            "contribution_ids": [
                "R25808"
            ]
        },
        {
            "instance_id": "R25857xR25820",
            "comparison_id": "R25857",
            "paper_id": "R25820",
            "text": "Atomically Dispersed Pd on Nanodiamond/Graphene Hybrid for Selective Hydrogenation of Acetylene we reported here a strategy to use a defective nanodiamond-graphene (nd@g) to prepare an atomically dispersed metal catalyst, i.e., in the current case atomically dispersed palladium catalyst which is used for selective hydrogenation of acetylene in the presence of abundant ethylene. the catalyst exhibits remarkable performance for the selective conversion of acetylene to ethylene: high conversion (100%), ethylene selectivity (90%), and good stability. the unique structure of the catalyst (i.e., atomically dispersion of pd atoms on graphene through pd-c bond anchoring) blocks the formation of unselective subsurface hydrogen species and ensures the facile desorption of ethylene against the overhydrogenation to undesired ethane, which is the key for the outstanding selectivity of the catalyst.",
            "contribution_ids": [
                "R25821"
            ]
        },
        {
            "instance_id": "R25857xR25853",
            "comparison_id": "R25857",
            "paper_id": "R25853",
            "text": "Semihydrogenation of Acetylene on Indium Oxide: Proposed Single-Ensemble Catalysis indium oxide catalyzes acetylene hydrogenation with high selectivity to ethylene (>85\\u2009%); even with a large excess of the alkene. in\\u2005situ characterization reveals the formation of oxygen vacancies under reaction conditions, while an in depth theoretical analysis links the surface reduction with the creation of well-defined vacancies and surrounding in3 o5 ensembles, which are considered responsible for this outstanding catalytic function. this behavior, which differs from that of other common reducible oxides, originates from the presence of four crystallographically inequivalent oxygen sites in the indium oxide surface. these resulting ensembles are 1)\\u2005stable against deactivation, 2)\\u2005homogeneously and densely distributed, and 3)\\u2005spatially isolated and confined against transport; thereby broadening the scope of oxides in hydrogenation catalysis.",
            "contribution_ids": [
                "R25854"
            ]
        },
        {
            "instance_id": "R25857xR25855",
            "comparison_id": "R25857",
            "paper_id": "R25855",
            "text": "Crystal-Facet Effect of \u00ce\u00b3-Al2O3 on Supporting CrOx for Catalytic Semihydrogenation of Acetylene with the successful preparation of \u03b3-alumina with high-energy external surfaces such as {111} facets, the crystal-facet effect of \u03b3-al2o3 on surface-loaded crox has been explored for semihydrogenation of acetylene. our results indeed demonstrate that the harmonious interaction of crox with traditional \u03b3-al2o3, the external surfaces of which are typically low-energy{110} facets, has caused a highly efficient performance for semihydrogenation of acetylene over crox/(110)\u03b3-al2o3 catalyst, whereas the activity of the crox/(111)\u03b3-al2o3 catalyst for acetylene hydrogenation is suppressed dramatically due to the limited formation of active cr species, restrained by the high-energy {111} facets of \u03b3-al2o3. furthermore, the use of inexpensive crox as the active component for semihydrogenation of acetylene is an economically friendly alternative relative to commercial precious pd catalysts. this work sheds light on a strategy for exploiting the crystal-facet effect of the supports to purposefully tailor the catalyti...",
            "contribution_ids": [
                "R25856"
            ]
        },
        {
            "instance_id": "R25900xR25865",
            "comparison_id": "R25900",
            "paper_id": "R25865",
            "text": "Pd-Pb Alloy Nanocrystals with Tailored Composition for Semihydrogenation: Taking Advantage of Catalyst Poisoning metallic nanocrystals (ncs) with well-defined sizes and shapes represent a new family of model systems for establishing structure-function relationships in heterogeneous catalysis. here in this study, we show that catalyst poisoning can be utilized as an efficient strategy for nanocrystals shape and composition control, as well as a way to tune the catalytic activity of catalysts. lead species, a well-known poison for noble-metal catalysts, was investigated in the growth of pd ncs. we discovered that pb atoms can be incorporated into the lattice of pd ncs and form pd-pb alloy ncs with tunable composition and crystal facets. as model catalysts, the alloy ncs with different compositions showed different selectivity in the semihydrogenation of phenylacetylene. pd-pb alloy ncs with better selectivity than that of the commercial lindlar catalyst were discovered. this study exemplified that the poisoning effect in catalysis can be explored as efficient shape-directing reagents in nc growth, and more importantly, as a strategy to tailor the performance of catalysts with high selectivity.",
            "contribution_ids": [
                "R25866",
                "R25867"
            ]
        },
        {
            "instance_id": "R25900xR25872",
            "comparison_id": "R25900",
            "paper_id": "R25872",
            "text": "Metal-Ligand Core-Shell Nanocomposite Catalysts for the Selective Semihydrogenation of Alkynes in recent years, hybrid nanocomposites with core\u2013shell structures have increasingly attracted enormous attention in many important research areas such as quantum dots, optical, magnetic, and electronic devices, and catalysts. in the catalytic applications of core\u2013shell materials, core-metals having magnetic properties enable easy separation of the catalysts from the reaction mixtures by a magnet. the core-metals can also affect the active shell-metals, delivering significant improvements in their activities and selectivities. however, it is difficult for core-metals to act directly as the catalytic active species because they are entirely covered by the shell. thus, few successful designs of core\u2013shell nanocomposite catalysts having active metal species in the core have appeared to date. recently, we have demonstrated the design of a core\u2013shell catalyst consisting of active metal nanoparticles (nps) in the core and closely assembled oxides with nano-gaps in the shell, allowing the access of substrates to the core-metal. the shell acted as a macro ligand (shell ligand) for the core-metal and the core\u2013shell structure maximized the metal\u2013ligand interaction (ligand effect), promoting highly selective reactions. the design concept of core\u2013shell catalysts having core-metal nps with a shell ligand is highly useful for selective organic transformations owing to the ideal structure of these catalysts for maximizing the ligand effect, leading to superior catalytic performances compared to those of conventional supported metal nps. semihydrogenation of alkynes is a powerful tool to synthesize (z)-alkenes which are important building blocks for fine chemicals, such as bioactive molecules, flavors, and natural products. in this context, the lindlar catalyst (pd/ caco3 treated with pb(oac)2) has been widely used. [13] unfortunately, the lindlar catalyst has serious drawbacks including the requirement of a toxic lead salt and the addition of large amounts of quinoline to suppress the over-hydrogenation of the product alkenes. furthermore, the lindlar catalyst has a limited substrate scope; terminal alkynes cannot be converted selectively into terminal alkenes because of the rapid over-hydrogenation of the resulting alkenes to alkanes. aiming at the development of environmentally benign catalyst systems, a number of alternative lead-free catalysts have been reported. 15] recently, we also developed a leadfree catalytic system for the selective semihydrogenation consisting of sio2-supported pd nanoparticles (pdnps) and dimethylsulfoxide (dmso), in which the addition of dmso drastically suppressed the over-hydrogenation and isomerization of the alkene products even after complete consumption of the alkynes. this effect is due to the coordination of dmso to the pdnps. dmso adsorbed on the surface of pdnps inhibits the coordination of alkenes to the pdnps, while alkynes can adsorb onto the pdnps surface because they have a higher coordination ability than dmso. this phenomenon inspired us to design pdnps coordinated with a dmso-like species in a solid matrix. if a core\u2013shell structured nanocomposite involving pdnps encapsulated by a shell having a dmso-like species could be constructed, it would act as an efficient and functional solid catalyst for the selective semihydrogenation of alkynes. herein, we successfully synthesized core\u2013shell nanocomposites of pdnps covered with a dmso-like matrix on the surface of sio2 (pd@mpso/sio2). the shell, consisting of an alkyl sulfoxide network, acted as a macroligand and allowed the selective access of alkynes to the active center of the pdnps, promoting the selective semihydrogenation of not only internal but also terminal alkynes without any additives. moreover, these catalysts were reusable while maintaining high activity and selectivity. pd@mpso/sio2 catalysts were synthesized as follows. pd/ sio2 prepared according to our procedure [16] was stirred in n-heptane with small amounts of 3,5-di-tert-butyl-4-hydroxytoluene (bht) and water at room temperature. next, methyl3-trimethoxysilylpropylsulfoxide (mpso) was added to the mixture and the mixture was heated. the slurry obtained was collected by filtration, washed, and dried in vacuo, affording pd@mpso/sio2 as a gray powder. altering the molar ratios of mpso to pd gave two kinds of catalysts: pd@mpso/sio21 (mpso:pd = 7:1), and pd@mpso/sio2-2 (mpso:pd = 100:1). [*] dr. t. mitsudome, y. takahashi, dr. t. mizugaki, prof. dr. k. jitsukawa, prof. dr. k. kaneda department of materials engineering science graduate school of engineering science, osaka university 1\u20133, machikaneyama, toyonaka, osaka 560-8531 (japan) e-mail: kaneda@cheng.es.osaka-u.ac.jp",
            "contribution_ids": [
                "R25873"
            ]
        },
        {
            "instance_id": "R25900xR25876",
            "comparison_id": "R25900",
            "paper_id": "R25876",
            "text": "A Pd- Cu2O nanocomposite as an effective synergistic catalyst for selective semi-hydrogenation of the terminal alkynes only a new type lead-free pd\u2013cu 2 o nanocomposite catalyst shows \u201cdouble\u201d selectivities for hydrogenation of alkynes: only terminal alkynes hydrogenated and only alkenes produced, i.e. no internal alkyne is hydrogenated.",
            "contribution_ids": [
                "R25877"
            ]
        },
        {
            "instance_id": "R25900xR25884",
            "comparison_id": "R25900",
            "paper_id": "R25884",
            "text": "Design of Core-Pd/Shell-Ag Nanocomposite Catalyst for Selective Semihydrogenation of Alkynes we designed core-pd/shell-ag nanocomposite catalyst (pd@ag) for highly selective semihydrogenation of alkynes. the construction of the core\u2013shell nanocomposite enables a significant improvement in the low activity of ag nps for the selective semihydrogenation of alkynes because hydrogen is supplied from the core-pd nps to the shell-ag nps in a synergistic manner. simultaneously, coating the core-pd nps with shell-ag nps results in efficient suppression of overhydrogenation of alkenes by the pd nps. this complementary action of core-pd and shell-ag provides high chemoselectivity toward a wide range of alkenes with high z-selectivity under mild reaction conditions (room temperature and 1 atm h2). moreover, pd@ag can be easily separated from the reaction mixture and is reusable without loss of catalytic activity or selectivity.",
            "contribution_ids": [
                "R25885"
            ]
        },
        {
            "instance_id": "R25900xR25888",
            "comparison_id": "R25900",
            "paper_id": "R25888",
            "text": "Formation and Characterization of PdZn Alloy: A Very Selective Catalyst for Alkyne Semihydrogenation the formation of a pdzn alloy from a 4.3% pd/zno catalyst was characterized by combined in situ high-resolution x-ray diffraction (hrxrd) and x-ray absorption spectroscopy (xas). alloy formation started already at around 100 \u00b0c, likely at the surface, and reached the bulk with increasing temperature. the structure of the catalyst was close to the bulk value of a 1:1 pdzn alloy with a l1o structure (rpd\u2212pd = 2.9 a, rpd\u2212zn = 2.6 a, cnpd\u2212zn = 8, cnpd\u2212pd = 4) after reduction at 300 \u00b0c and above. the activity of the gas-phase hydrogenation of 1-pentyne decreased with the formation of the pdzn alloy. in contrast to pd/sio2, no full hydrogenation occurred over pd/zno. over time, only slight decomposition of the alloy occurred under reaction conditions.",
            "contribution_ids": [
                "R25889"
            ]
        },
        {
            "instance_id": "R25900xR25898",
            "comparison_id": "R25900",
            "paper_id": "R25898",
            "text": "Merging Single-Atom-Dispersed Silver and Carbon Nitride to a Joint Electronic System via Copolymerization with Silver Tricyanomethanide herein, we present an approach to create a hybrid between single-atom-dispersed silver and a carbon nitride polymer. silver tricyanomethanide (agtcm) is used as a reactive comonomer during templated carbon nitride synthesis to introduce both negative charges and silver atoms/ions to the system. the successful introduction of the extra electron density under the formation of a delocalized joint electronic system is proven by photoluminescence measurements, x-ray photoelectron spectroscopy investigations, and measurements of surface \u03b6-potential. at the same time, the principal structure of the carbon nitride network is not disturbed, as shown by solid-state nuclear magnetic resonance spectroscopy and electrochemical impedance spectroscopy analysis. the synthesis also results in an improvement of the visible light absorption and the development of higher surface area in the final products. the atom-dispersed agtcm-doped carbon nitride shows an enhanced performance in the selective hydrogenation of alkynes in comparison with the performance of other conventional ag-based materials prepared by spray deposition and impregnation-reduction methods, here exemplified with 1-hexyne.",
            "contribution_ids": [
                "R25899"
            ]
        },
        {
            "instance_id": "R25999xR25995",
            "comparison_id": "R25999",
            "paper_id": "R25995",
            "text": "Information theoretic analysis of postal address fields for automatic address interpretation \"this paper concerns a study of information content in postal address fields for automatic address interpretation. information provided by a combination of address components and information interaction among components is characterized in terms of shannon's entropy. the efficiency of assignment strategies for determining a delivery point code can be compared by the propagation of uncertainty in address components. the quantity of redundancy between components can be computed from the information provided by these components. this information is useful in developing a strategy for selecting a useful component for recovering the value of an uncertain component. the uncertainty of a component based on another known component can be measured by conditional entropy. by ranking the uncertainty quantity, the effective processing flow for determining the value of a candidate component can be constructed.\"",
            "contribution_ids": [
                "R25996"
            ]
        },
        {
            "instance_id": "R25999xR25997",
            "comparison_id": "R25999",
            "paper_id": "R25997",
            "text": "Automated labeling in document images the national library of medicine (nlm) is developing an automated system to produce bibliographic records for its medliner database. this system, named medical article record system (mars), employs document image analysis and understanding techniques and optical character recognition (ocr). this paper describes a key module in mars called the automated labeling (al) module, which labels all zones of interest (title, author, affiliation, and abstract) automatically. the al algorithm is based on 120 rules that are derived from an analysis of journal page layouts and features extracted from ocr output. experiments carried out on more than 11,000 articles in over 1,000 biomedical journals show the accuracy of this rule-based algorithm to exceed 96%.",
            "contribution_ids": [
                "R25998",
                "R26016"
            ]
        },
        {
            "instance_id": "R26063xR26027",
            "comparison_id": "R26063",
            "paper_id": "R26027",
            "text": "The efficient design of adhesive bonded joints \"abstract a concise method of analysis is used to study the numerous parameters influencing the stress distribution within the adhesive of a single lap joint. the formulation includes transverse shear and normal strain deformations. both isotropic or anisotropic material systems of similar or dissimilar adherends are analysed. results indicate that the primary young's modulus of the adherend, the overlap length, and the adhesive's material properties are the parameters most influential in optimizing the design of a single lap joint.\"",
            "contribution_ids": [
                "R26028"
            ]
        },
        {
            "instance_id": "R26063xR26041",
            "comparison_id": "R26063",
            "paper_id": "R26041",
            "text": "Analysis of Adhesive\u00e2\u0080\u0090Bonded Joints with Nonidentical Adherends in this paper the effect of the deflected configuration of the joint on the static equilibrium of the jointed portion is considered and the two end-binding moments of the joint are deduced from classical beam-plate theory in closed forms. this simplifies the calculation of the stress distribution, and makes feasible closed form solutions of stress-intensity factors. by this method, all boundary stress conditions of the joint can be strictly satisfied and the effects of the bonding material and the physical and dimensional properties of the nonidentical adherents are taken into account. the study results show that the intensities of the normal stress and the shearing stress are always much greater in a small zone at both ends of the joint. it was also found that the maximum shearing stress and the maximum normal stress always occur at different end zones of the joint.",
            "contribution_ids": [
                "R26042"
            ]
        },
        {
            "instance_id": "R26063xR26059",
            "comparison_id": "R26063",
            "paper_id": "R26059",
            "text": "Strength of adhesive joints with adherend yielding: I. Analytical model a sandwich element can be isolated in all two-dimensional adhesive joints, thereby simplifying the analysis of strain and stress. an adhesive sandwich model has been developed that accommodates arbitrary loading, a bilinear adherend stress-strain response, and any form of nonlinear adhesive behavior. the model accounts for both the bending deformation and the shear deformation of the adherends. stress and strain distributions in the adhesive were obtained by solving a system of six differential equations using a finite-difference method. for a sample adhesive sandwich, the adhesive strains and stresses from the new model were compared with those of other models. finally, the model was coupled with an analytical solution for the detached section of an adhesive joint in peel. the stress and strain distributions in the adhesive and the root curvature of the peel adherend were then compared with finite element results. an accompanying article in this issue uses the model with experimental peel data to investigate the suitability of various adhesive failure criteria.",
            "contribution_ids": [
                "R26060"
            ]
        },
        {
            "instance_id": "R26107xR26099",
            "comparison_id": "R26107",
            "paper_id": "R26099",
            "text": "Linking indoor environment conditions to job satisfaction: a field study \"physical and questionnaire data were collected from 95 workstations at an open-plan office building in michigan, us. the physical measurements encompassed thermal, lighting, and acoustic variables, furniture dimensions, and an assessment of potential exterior view. occupants answered a detailed questionnaire concerning their environmental and job satisfaction, and aspects of well-being. these data were used to test, via mediated regression, a model linking the physical environment, through environmental satisfaction, to job satisfaction and other related measures. in particular, a significant link was demonstrated between overall environmental satisfaction and job satisfaction, mediated by satisfaction with management and with compensation. analysis of physical data was limited to the lighting domain. results confirmed the important role of window access at the desk in satisfaction with lighting, particularly through its effect on satisfaction with outside view. des donn\u00e9es physiques et des donn\u00e9es obtenues par questionnaire ont \u00e9t\u00e9 recueillies aupr\u00e8s de 95 postes de travail dans un immeuble de bureaux d\u00e9cloisonn\u00e9s du michigan, aux etats-unis. les mesures physiques comprenaient des variables thermiques, acoustiques et relatives \u00e0 l'\u00e9clairage, les dimensions des meubles, ainsi qu'une \u00e9valuation de la vue ext\u00e9rieure potentielle. les occupants ont r\u00e9pondu \u00e0 un questionnaire d\u00e9taill\u00e9 portant sur la satisfaction \u00e0 l'\u00e9gard de leur environnement et de leur travail, et sur des aspects relatifs au bien-\u00eatre. ces donn\u00e9es ont \u00e9t\u00e9 utilis\u00e9es pour tester, au moyen d'une r\u00e9gression m\u00e9diatis\u00e9e, un mod\u00e8le liant l'environnement physique, par la satisfaction \u00e0 l'\u00e9gard de l'environnement, \u00e0 la satisfaction dans le travail et aux autres mesures li\u00e9es. il a en particulier \u00e9t\u00e9 d\u00e9montr\u00e9 qu'il existe un lien important entre la satisfaction globale \u00e0 l'\u00e9gard de l'environnement et la satisfaction dans le travail, m\u00e9diatis\u00e9 par la satisfaction vis-\u00e0-vis de la direction et de la r\u00e9mun\u00e9ration. l'analyse des donn\u00e9es physiques a \u00e9t\u00e9 limit\u00e9e au domaine de l'\u00e9clairage. les r\u00e9sultats ont confirm\u00e9 que le fait de pouvoir acc\u00e9der \u00e0 une fen\u00eatre au bureau joue un r\u00f4le important dans la satisfaction \u00e0 l'\u00e9gard de l'\u00e9clairage, en particulier par son effet sur la satisfaction vis-\u00e0-vis de la vue ext\u00e9rieure. mots cl\u00e9s: satisfaction \u00e0 l'\u00e9gard de l'environnement, satisfaction dans le travail, \u00e9clairage, perception par les occupants, bureaux, productivit\u00e9 organisationnelle, vue, bien-\u00eatre\"",
            "contribution_ids": [
                "R26100"
            ]
        },
        {
            "instance_id": "R26107xR26101",
            "comparison_id": "R26107",
            "paper_id": "R26101",
            "text": "Subjective indoor air quality in schools- the influence of high room temperature, carpeting, fleecy wall materials and volatile organic compounds (VOC) subjective indoor air quality in schools-the influence of high room temperature,carpeting, fleecy materials and volatile organic compounds (voc)",
            "contribution_ids": [
                "R26102"
            ]
        },
        {
            "instance_id": "R26127xR26111",
            "comparison_id": "R26127",
            "paper_id": "R26111",
            "text": "Underground activity and institutional change: Productive, protective and predatory behavior in transition economies this paper examines why some transitions are more successful than others by focusing attention on the role of productive, protective and predatory behaviors from the perspective of the new institutional economics. many transition economies are characterized by a fundamental inconsistency between formal and informal institutions. when formal and informal rules clash, noncompliant behaviors proliferate, among them, tax evasion, corruption, bribery, organized criminality, and theft of government property. these wealth redistributing protective and predatory behaviors activities absorb resources that could otherwise be used for wealth production resulting in huge transition costs. noncompliant behaviors--evasion, avoidance, circumvention, abuse, and/or corruption of institutional rules--comprise what we can be termed underground economies. a variety of underground economies can be differentiated according to the types of rules violated by the noncompliant behaviors. the focus of the new institutional economics is on the consequences of institutions--the rules that structure and constrain economic activity--for economic outcomes. underground economics is concerned with instances in which the rules are evaded, circumvented, and violated. it seeks to determine the conditions likely to foster rule violations, and to understand the various consequences of noncompliance with institutional rules. noncompliance with \u2018bad\u201d rules may actually foster development whereas non compliance with \u201cgood\u201d rules will hinder development. since rules differ, both the nature and consequences of rule violations will therefore depend on the particular rules violated. institutional economics and underground economics are therefore highly complementary. the former examines the rules of the game, the latter the strategic responses of individuals and organizations to those rules. economic performance depends on both the nature of the rules and the extent of compliance with them. institutions therefore do affect economic performance, but it is not always obvious which institutional rules dominate. where formal and informal institutions are coherent and consistent, the incentives produced by the formal rules will affect economic outcomes. under these circumstances, the rule of law typically secures property rights, reduces uncertainty, and lowers transaction costs. in regimes of discretionary authority where formal institutions conflict with informal norms, noncompliance with the formal rules becomes pervasive, and underground economic activity is consequential for economic outcomes.",
            "contribution_ids": [
                "R26112",
                "R26122"
            ]
        },
        {
            "instance_id": "R26146xR26140",
            "comparison_id": "R26146",
            "paper_id": "R26140",
            "text": "Integrating the unofficial economy into the dynamics of post-socialist economies: A framework of analysis and evidence over a third of economic activity in theformer soviet countries was estimated to occur in the unofficial economy by the mid-1990s; in central and eastern europe, the average is close to one-quarter. intraregional variations are great: in some countries 10 to 15 percent of economic activity is unofficial, and in some more than half of it. the growth of unofficial activity in most post-socialist countries, and its mitigating effect on the decline in official output during the early stages of the transition, have been marked. in this paper, the authors challenge the conventional view of how post-socialist economies function by incorporating the unofficial economy into an analysis of the full economy. then they advance a simple framework for understanding the evolution of the unofficial economy, and the links between both economies, highlighting the main characteristics of\"officialdom,\"contrasting conventional notions of\"informal\"or\"shadow\"economies, and focusing on what determines the decision to cross over from one segment to another. the initial empirical results seem to support hypothetical explanations of what determines the dynamics of the unofficial economy. the authors emphasize the speedy liberalization of markets, macro stability, and a stable and moderate tax regime. although widespread, most\"unofficialdom\"in the region is found to be relatively shallow--subject to reversal by appropriate economic policies. the framework and evidence presented here have implications for measurement, forecasting, and policymaking--calling for even faster liberalization and privatization than already advocated. and the lessons in social protection and taxation policy differ from conventional advice.",
            "contribution_ids": [
                "R26141"
            ]
        },
        {
            "instance_id": "R26194xR26156",
            "comparison_id": "R26194",
            "paper_id": "R26156",
            "text": "A Combined Vehicle Routing and Inventory Allocation Problem we address the combined problem of allocating a scarce resource among several locations, and planning deliveries using a fleet of vehicles. demands are random, and holding and shortage costs must be considered in the decision along with transportation costs. we show how to extend some of the available methods for the deterministic vehicle routing problem to this case. computational results using one such adaptation show that the algorithm is fast enough for practical work, and that substantial cost savings can be achieved with this approach.",
            "contribution_ids": [
                "R26157"
            ]
        },
        {
            "instance_id": "R26194xR26167",
            "comparison_id": "R26194",
            "paper_id": "R26167",
            "text": "An Allocation and Distribution Model for Perishable Products this paper presents an allocation model for a perishable product, distributed from a regional center to a given set of locations with random demands. we consider the combined problem of allocating the available inventory at the center while deciding how these deliveries should be performed. two types of delivery patterns are analyzed: the first pattern assumes that all demand points receive individual deliveries; the second pattern subsumes the frequently occurring case in which deliveries are combined in multistop routes traveled by a fleet of vehicles. computational experience is reported.",
            "contribution_ids": [
                "R26168"
            ]
        },
        {
            "instance_id": "R26194xR26173",
            "comparison_id": "R26194",
            "paper_id": "R26173",
            "text": "An Integrated Inventory Allocation and Vehicle Routing Problem we address the problem of distributing a limited amount of inventory among customers using a fleet of vehicles so as to maximize profit. both the inventory allocation and the vehicle routing problems are important logistical decisions. in many practical situations, these two decisions are closely interrelated, and therefore, require a systematic approach to take into account both activities jointly. we formulate the integrated problem as a mixed integer program and develop a lagrangian-based procedure to generate both good upper bounds and heuristic solutions. computational results show that the procedure is able to generate solutions with small gaps between the upper and lower bounds for a wide range of cost structures.",
            "contribution_ids": [
                "R26174"
            ]
        },
        {
            "instance_id": "R26262xR26235",
            "comparison_id": "R26262",
            "paper_id": "R26235",
            "text": "A genetic algorithm approach to the integrated inventory-distribution problem we introduce a new genetic algorithm (ga) approach for the integrated inventory distribution problem (iidp). we present the developed genetic representation and use a randomized version of a previously developed construction heuristic to generate the initial random population. we design suitable crossover and mutation operators for the ga improvement phase. the comparison of results shows the significance of the designed ga over the construction heuristic and demonstrates the capability of reaching solutions within 20% of the optimum on sets of randomly generated test problems.",
            "contribution_ids": [
                "R26236"
            ]
        },
        {
            "instance_id": "R26352xR26279",
            "comparison_id": "R26352",
            "paper_id": "R26279",
            "text": "A Markov Decision Model and Decomposition Heuristic for Dynamic Vehicle Dispatching \" we describe a dynamic and stochastic vehicle dispatching problem called the delivery dispatching problem. this problem is modeled as a markov decision process. because exact solution of this model is impractical, we adopt a heuristic approach for handling the problem. the heuristic is based in part on a decomposition of the problem by customer, where customer subproblems generate penalty functions that are applied in a master dispatching problem. we describe how to compute bounds on the algorithm's performance, and apply it to several examples with good results. \"",
            "contribution_ids": [
                "R26280"
            ]
        },
        {
            "instance_id": "R26352xR26297",
            "comparison_id": "R26352",
            "paper_id": "R26297",
            "text": "Fully Loaded Direct Shipping Strategy in One Warehouse/NRetailer Systems without Central Inventories in this paper, we consider one warehouse/multiple retailer systems with transportation costs. the planning horizon is infinite and the warehouse keeps no central inventory. it is shown that the fully loaded direct shipping strategy is optimal among all possible shipping/allocation strategies if the truck capacity is smaller than a certain quantity, and a bound is provided for the general case.",
            "contribution_ids": [
                "R26298"
            ]
        },
        {
            "instance_id": "R26352xR26300",
            "comparison_id": "R26352",
            "paper_id": "R26300",
            "text": "Integrating Routing and Inventory Decisions in One-Warehouse Multiretailer Multiproduct Distribution Systems we consider distribution systems with a central warehouse and many retailers that stock a number of different products. deterministic demand occurs at the retailers for each product. the warehouse acts as a break-bulk center and does not keep any inventory. the products are delivered from the warehouse to the retailers by vehicles that combine the deliveries to several retailers into efficient vehicle routes. the objective is to determine replenishment policies that specify the delivery quantities and the vehicle routes used for the delivery, so as to minimize the long-run average inventory and transportation costs. a new heuristic that develops a stationary nested joint replenishment policy for the problem is presented in this paper. unlike existing methods, the proposed heuristic is capable of solving problems involving distribution systems with multiple products. results of a computational study on randomly generated single-product problems are also presented.",
            "contribution_ids": [
                "R26301"
            ]
        },
        {
            "instance_id": "R26352xR26317",
            "comparison_id": "R26352",
            "paper_id": "R26317",
            "text": "Price-Directed Replenishment of Subsets: Methodology and Its Application to Inventory Routing the idea of price-directed control is to use an operating policy that exploits optimal dual prices from a mathematical programming relaxation of the underlying control problem. we apply it to the problem of replenishing inventory to subsets of products/locations, such as in the distribution of industrial gases, so as to minimize long-run time average replenishment costs. given a marginal value for each product/location, whenever there is a stockout the dispatcher compares the total value of each feasible replenishment with its cost, and chooses one that maximizes the surplus. we derive this operating policy using a linear functional approximation to the optimal value function of a semi-markov decision process on continuous spaces. this approximation also leads to a math program whose optimal dual prices yield values and whose optimal objective value gives a lower bound on system performance. we use duality theory to show that optimal prices satisfy several structural properties and can be interpreted as estimates of lowest achievable marginal costs. on real-world instances, the price-directed policy achieves superior, near optimal performance as compared with other approaches.",
            "contribution_ids": [
                "R26318"
            ]
        },
        {
            "instance_id": "R26352xR26321",
            "comparison_id": "R26352",
            "paper_id": "R26321",
            "text": "Dynamic Programming Approximations for a Stochastic Inventory Routing Problem this work is motivated by the need to solve the inventory routing problem when implementing a business practice called vendor managed inventory replenishment (vmi). with vmi, vendors monitor their customers\u2032 inventories and decide when and how much inventory should be replenished at each customer. the inventory routing problem attempts to coordinate inventory replenishment and transportation in such a way that the cost is minimized over the long run. we formulate a markov decision process model of the stochastic inventory routing problem and propose approximation methods to find good solutions with reasonable computational effort. we indicate how the proposed approach can be used for other markov decision processes involving the control of multiple resources.",
            "contribution_ids": [
                "R26322"
            ]
        },
        {
            "instance_id": "R26352xR26326",
            "comparison_id": "R26352",
            "paper_id": "R26326",
            "text": "Redesigning distribution operations: a case study on integrating inventory management and vehicle routes design this paper describes a real-world application concerning the distribution in portugal of frozen products of a world-wide food and beverage company. its focus is the development of a model to support negotiations between a logistics operator and retailers, establishing a common basis for a co-operative scheme in supply chain management. a periodic review policy is adopted and an optimisation procedure based on the heuristic proposed by viswanathan and mathur (mgmnt sci., 1997, 43, 294\u2013312) is used to devise guidelines for inventory replenishment frequencies and for the design of routes to be used in the distribution process. this provides an integrated approach of the two logistics functions\u2014inventory management and routing\u2014with the objective of minimising long-term average costs, considering an infinite time horizon. a framework to estimate inventory levels, namely safety stocks, is also presented. the model provides full information concerning the expected performance of the proposed solution, which can be compared against the present situation, allowing each party to assess its benefits and drawbacks.",
            "contribution_ids": [
                "R26327",
                "R26369"
            ]
        },
        {
            "instance_id": "R26421xR26391",
            "comparison_id": "R26421",
            "paper_id": "R26391",
            "text": "Biochemical and Genetic Properties ofPaenibacillusGlycosyl Hydrolase Having Chitosanase Activity and Discoidin Domain cells of \u201cpaenibacillus fukuinensis\u201d d2 produced chitosanase into surrounding medium, in the presence of colloidal chitosan or glucosamine. the gene of this enzyme was cloned, sequenced, and subjected to site-directed mutation and deletion analyses. the nucleotide sequence indicated that the chitosanase was composed of 797 amino acids and its molecular weight was 85,610. unlike conventional family 46 chitosanases, the enzyme has family 8 glycosyl hydrolase catalytic domain, at the amino-terminal side, and discoidin domain at the carboxyl-terminal region. expression of the cloned gene in escherichia coli revealed \u03b2-1,4-glucanase function, besides chitosanase activity. analyses by zymography and immunoblotting suggested that the active enzyme was, after removal of signal peptide, produced from inactive 81-kda form by proteolysis at the carboxyl-terminal region. replacements of glu115 and asp176, highly conserved residues in the family 8 glycosylase region, with gln and asn caused simultaneous loss of chitosanase and glucanase activities, suggesting that these residues formed part of the catalytic site. truncation experiments demonstrated indispensability of an amino-terminal region spanning 425 residues adjacent to the signal peptide.",
            "contribution_ids": [
                "R26392"
            ]
        },
        {
            "instance_id": "R26421xR26413",
            "comparison_id": "R26421",
            "paper_id": "R26413",
            "text": "An Aspergillus chitosanase with potential for large-scale preparation of chitosan oligosaccharides a chitosan\u2010degrading fungus, designated aspergillus sp. y2k, was isolated from soil. the micro\u2010organism was used for producing chitosanase (ec 3.2.1.132) in a minimal medium containing chitosan as the sole carbon source. the induced chitosanase was purified to homogeneity from the culture filtrate by concentration and cationic sp\u2010sepharose chromatography. the purified enzyme is a monomer with an estimated molecular mass of 25 kda by sds/page and of 22 kda by gel\u2010filtration chromatography. pi, optimum ph and optimum temperature values were 8.4, 6.5 and 65\u201370 \u00b0c, respectively. the chitosanase is stable in the ph range from 4 to 7.5 at 55 \u00b0c. higher deacetylated chitosan is a better substrate. chitin, xylan, 6\u2010o \u2010sulphated chitosan and o \u2010carboxymethyl chitin were indigestible by the purified enzyme. by endo\u2010splitting activity, the chitosanase hydrolysed chitosan to form chitosan oligomers with chitotriose, chitotetraose and chitopentaose as the major products. the enzyme hydrolyses chitohexaose to form chitotriose, while the chitopentaose and shorter oligomers remain intact. the n\u2010terminal amino acid sequence of the enzyme was determined as ynlpnnlkqiyddhk, which provides useful information for further gene cloning of this enzyme. a 275 g\u2010scale hydrolysis of chitosan was performed. the product distribution was virtually identical to that of the small\u2010scale reaction. owing to the simple purification process and high stability of the enzyme, it is potentially valuable for industrial applications.",
            "contribution_ids": [
                "R26414"
            ]
        },
        {
            "instance_id": "R26421xR26417",
            "comparison_id": "R26421",
            "paper_id": "R26417",
            "text": "Purification and Mode of Action of a Chitosanase from Penicillium islandicum penicillium islandicum produced an inducible extracellular chitosanase when grown on chitosan. large-scale production of the enzyme was obtained using rhizopus rhizopodiformis hyphae as substrate. chitosanase was purified 38-fold to homogeneity by ammonium sulphate fractionation and sequential chromatography on deae-biogel a, biogel p60 and hydroxyl-apatite. crude enzyme was unstable at 370c, but was stabilized by 1\u00b70 mm-ca2+. the ph optimum for activity was broad and dependent on the solubility of the chitosan substrate. various physical and chemical properties of the purified enzyme were determined.\\npenicillium islandicum chitosanase cleaved chitosan in an endo-splitting manner with maximal activity on polymers of 30 to 60% acetylation. no activity was found on chitin (100% acetylated chitosan) or trimers and tetramers of n-acetylglucosamine. the latter two oligomers and all small oligomers of glucosamine inhibited the activity of chitosanase on 30% acetylated chitosan. the pentamer of n-acetylglucosamine and glucosamine oligomers were slowly cleaved by the enzyme. analysis of the reaction products from 30% acetylated chitosan indicated that the major oligomeric product was a trimer; with 60% acetylated chitosan as substrate a dimer was also found. the new terminal reducing groups produced by chitosanase hydrolysis of 30% acetylated chitosan were reduced by sodium boro[3h]hydride. the new end residues were found to be n-acetylglucosamine. the analyses strongly indicated that p. islandicum chitosanase cleaved chitosan between n-acetylglucosamine and glucosamine. both residues were needed for cleavage, and polymers containing equal proportions of acetylated and non-acetylated sugars were optimal for chitosanase activity. the products of reaction depended on the degree of acetylation of the polymer.",
            "contribution_ids": [
                "R26418"
            ]
        },
        {
            "instance_id": "R26421xR26419",
            "comparison_id": "R26421",
            "paper_id": "R26419",
            "text": "Characterization of Two Chitinase Genes and One Chitosanase Gene Encoded by Chlorella Virus PBCV-1 chlorella virus pbcv-1 encodes two putative chitinase genes, a181/182r and a260r, and one chitosanase gene, a292l. the three genes were cloned and expressed in escherichia coli. the recombinant a181/182r protein has endochitinase activity, recombinant a260r has both endochitinase and exochitinase activities, and recombinant a292l has chitosanase activity. transcription of a181/182r, a260r, and a292l genes begins at 30, 60, and 60 min p.i., respectively; transcription of all three genes continues until the cells lyse. a181/182r, a260r, and a292l proteins are first detected by western blots at 60, 90, and 120 min p.i., respectively. therefore, a181/182r is an early gene and a260r and a292l are late genes. all three genes are widespread in chlorella viruses. phylogenetic analyses indicate that the ancestral condition of the a181/182r gene arose from the most recent common ancestor of a gene found in tobacco, whereas the genealogical position of the a260r gene could not be unambiguously resolved.",
            "contribution_ids": [
                "R26420"
            ]
        },
        {
            "instance_id": "R26550xR26459",
            "comparison_id": "R26550",
            "paper_id": "R26459",
            "text": "Chitosan Nanoparticles for Non-Viral Gene Therapy orthopedic research laboratory hopital du sacre-c\u0153ur de montreal universite de montreal, montreal, que. h4j 1c5",
            "contribution_ids": [
                "R26460"
            ]
        },
        {
            "instance_id": "R26550xR26489",
            "comparison_id": "R26550",
            "paper_id": "R26489",
            "text": "EFFECTS OF SHRIMP (MACROBRACIUM ROSENBERGII)-DERIVED CHITOSAN ON PLASMA LIPID PROFILE AND LIVER LIPID PEROXIDE LEVELS IN NORMO- AND HYPERCHOLESTEROLAEMIC RATS 1 the effects of chitosan (cs) derived from the exoskeleton of the shrimp macrobracium rosenbergii on bodyweight, plasma lipid profile, fatty acid composition, liver lipid peroxide (lpo) levels and plasma levels of glutamate pyruvate transaminase (gpt) were determined in normocholesterolaemic (nc) and hypercholesterolaemic (hc) long evans rats. 2 the nc rats were fed a diet containing 2% cs and the hc rats were fed a diet containing 2 and 4% cs for 8 weeks. chitosan significantly reduced bodyweight gain only in hc + 4% cs rats compared with hc rats, but not in nc + 2% cs or hc + 2% cs rats. 3 chitosan reduced plasma total cholesterol in the hc + 2% cs, hc + 4% cs and nc + 2% cs rats; however, low density lipoprotein\u2013cholesterol decreased only in the first two groups. high\u2010density lipoprotein\u2013cholesterol (hdl\u2010c) increased in the hc + 4% cs rats by 24% compared with the hc + 2% cs group and by 30% compared with hc rats; however, hdl\u2010c did not increase in the nc + 2% cs group compared with nc rats. the level of plasma triglycerides decreased significantly only in hc + 2% cs rats compared with hc rats. 4 chitosan significantly decreased plasma levels of arachidonic acid in the hc + 2% cs and hc + 4% cs groups, with a concurrent increase in the molar ratio of total unsaturated fatty acid (tufa) to total saturated fatty acid (tsfa). 5 moreover, cs increased liver lpo levels without affecting plasma levels of gpt. liver lpo levels were positively correlated with the tufa/tsfa molar ratio. 6 the present study suggests that dietary cs decreases the atherogenic lipid profiles of both nc and hc rats and reduces the bodyweight gain of hc rats.",
            "contribution_ids": [
                "R26490"
            ]
        },
        {
            "instance_id": "R26550xR26492",
            "comparison_id": "R26550",
            "paper_id": "R26492",
            "text": "Control of wound infections using a bilayer chitosan wound dressing with sustainable antibiotic delivery a novel bilayer chitosan membrane was prepared by a combined wet/dry phase inversion method and evaluated as a wound dressing. this new type of bilayer chitosan wound dressing, consisting of a dense upper layer (skin layer) and a sponge-like lower layer (sublayer), is very suitable for use as a topical delivery of silver sulfadiazine (agsd) for the control of wound infections. physical characterization of the bilayer wound dressing showed that it has excellent oxygen permeability, that it controls the water vapor transmission rate, and that it promotes water uptake capability. agsd dissolved from bilayer chitosan dressings to release silver and sulfadiazine. the release of sulfadiazine from the bilayer chitosan dressing displayed a burst release on the first day and then tapered off to a much slower release. however, the release of silver from the bilayer chitosan dressing displayed a slow release profile with a sustained increase of silver concentration. the cultures of pseudomonas aeruginosa and staphylococcus aureus in agar plates showed effective antimicrobial activity for 1 week. in vivo antibacterial tests confirmed that this wound dressing is effective for long-term inhibition of the growth of pseudomonas aeruginosa and staphylococcus aureus at an infected wound site. the results in this study indicate that the agsd-incorporated bilayer chitosan wound dressing may be a material with potential antibacterial capability for the treatment of infected wounds.",
            "contribution_ids": [
                "R26493"
            ]
        },
        {
            "instance_id": "R26550xR26514",
            "comparison_id": "R26550",
            "paper_id": "R26514",
            "text": "Application of Glutaraldehyde-Crosslinked Chitosan as a Scaffold for Hepatocyte Attachment. the effectiveness of chitosan, a biocompatible polymer derived by the deacetylation of chitin, as a scaffold of hepatocyte attachment, was examined. since chitosan gel was too fragile to use for cell culture, its free amino groups were crosslinked by glutaraldehyde to increase its strength. rat hepatocytes seeded onto glutaraldehyde-crosslinked chitosan (ga-chitosan) gel could stably attach to the surface, retaining its spherical form, the same as in vivo, and then release a very small amount of lactate dehydrogenase during the 5 d culture period. by contrast, hepatocytes on a collagen-coated surface spread flat, and they released much more lactate dehydrogenase than those on the ga-chitosan gel. hepatocytes on ga-chitosan also retained higher urea synthesis activity, a liver-specific function, than those on the collagen-coated surface. these results indicate that chitosan is a promising biopolymer as a scaffold of hepatocyte attachment, which can be applied to an effective bioartificial liver support system.",
            "contribution_ids": [
                "R26515"
            ]
        },
        {
            "instance_id": "R26550xR26524",
            "comparison_id": "R26550",
            "paper_id": "R26524",
            "text": "Antimicrobial actions of degraded and native chitosan against spoilage organisms in laboratory media and foods abstract \\n the objective of this study was to determine whether chitosan (poly-\u03b2-1,4-glucosamine) and hydrolysates of chitosan can be used as novel preservatives in foods. chitosan was hydrolyzed by using oxidative-reductive degradation, crude papaya latex, and lysozyme. mild hydrolysis of chitosan resulted in improved microbial inactivation in saline and greater inhibition of growth of several spoilage yeasts in laboratory media, but highly degraded products of chitosan exhibited no antimicrobial activity. in pasteurized apple-elderflower juice stored at 7\u00b0c, addition of 0.3 g of chitosan per liter eliminated yeasts entirely for the duration of the experiment (13 days), while the total counts and the lactic acid bacterial counts increased at a slower rate than they increased in the control. addition of 0.3 or 1.0 g of chitosan per kg had no effect on the microbial flora of houmous, a chickpea dip; in the presence of 5.0 g of chitosan per kg, bacterial growth but not yeast growth was substantially reduced compared with growth in control dip stored at 7\u00b0c for 6 days. improved antimicrobial potency of chitosan hydrolysates like that observed in the saline and laboratory medium experiments was not observed in juice and dip experiments. we concluded that native chitosan has potential for use as a preservative in certain types of food but that the increase in antimicrobial activity that occurs following partial hydrolysis is too small to justify the extra processing involved.",
            "contribution_ids": [
                "R26525"
            ]
        },
        {
            "instance_id": "R26550xR26530",
            "comparison_id": "R26550",
            "paper_id": "R26530",
            "text": "Development and evaluation of an edible antimicrobial film based on yam starch and chitosan edible antimicrobial films are an innovation within the biodegradable active packaging concept. they have been developed in order to reduce and/or inhibit the growth of microorganisms on the surface of foods. this study developed an edible antimicrobial film based on yam starch (dioscorea alata) and chitosan and investigated its antimicrobial efficiency on salmonella enteritidis. a solution of yam starch (4%) and glycerol (2%) was gelatinized in a viscoamilograph and chitosan added at concentrations of 1%, 3% and 5%. films with and without chitosan were produced by the cast method. to evaluate the antimicrobial activity of the films, two suspensions of s. enteritidis were used in bhi medium, corresponding to counts of 2 \u00d7 108 and 1.1 \u00d7 106\\u2009cfu/ml. the suspensions (50\\u2009ml) were poured into flasks. the films were cut into 5 \u00d7 5 and 5 \u00d7 10\\u2009cm rectangles to be used at ratios of 1\\u2009:\\u20091 (1\\u2009cm2/ml microorganism suspension) and 2\\u2009:\\u20091 (2\\u2009cm2/ml). the film 30\\u2009\u00b5m thick on average. as a control, pure chitosan at an amount corresponding to that contained in the 3% and 5% films (5 \u00d7 10\\u2009cm) was added to flasks containing the microorganism suspension. also, flasks containing only a suspension of s. enteritidis were used as control. the suspensions, in flasks, were kept at 37\u00b0c in a waterbath with agitation. suspension aliquots were removed every hour for reading the optic density (od595) and plating onto pca medium. the results showed that chitosan has a bactericidal effect upon s. enteritidis. films treated with chitosan at different concentrations showed similar antimicrobial efficiency, in addition to being dependent on diffusion. the chitosan\u2010treated films caused a reduction of one to two log cycles in the number of microorganisms, whereas the pure chitosan presented a reduction of four to six log cycles compared with the control and starch film. the films showed good flexibility. copyright \u00a9 2005 john wiley & sons, ltd.",
            "contribution_ids": [
                "R26531"
            ]
        },
        {
            "instance_id": "R26654xR26628",
            "comparison_id": "R26654",
            "paper_id": "R26628",
            "text": "The Concentric Clustering Scheme for Efficient Energy Consumption in the PEGASIS \"the wireless sensor network is a type of the wireless ad-hoc networks. it is composed of a collection of sensor nodes. sensor nodes collect and deliver necessary data in response to user's specific requests. it is expected to apply the wireless sensor network technology to various application areas such as the health, military and home. however, because of several limitations of sensor nodes, the routing protocols used in the wireless ad-hoc network are not suitable for the wireless sensor networks. for this reasons, many novel routing protocols for the wireless sensor networks are proposed recently. one of these protocols, the pegasis (power-efficient gathering in sensor information systems) protocol is a chain-based protocol. in general, the pegasis protocol presents twice or more performance in comparison with the leach (low energy adaptive clustering hierarchy) protocol. however, the pegasis protocol causes the redundant data transmission since one of nodes on the chain is selected as the head node regardless of the base station's location. in this paper, we propose the enhanced pegasis protocol based on the concentric clustering scheme to solve this problem. the main idea of the concentric clustering scheme is to consider the location of the base station to enhance its performance and to prolong the lifetime of the wireless sensor networks. as simulation results, the enhanced pegasis protocol using the concentric clustering scheme performs better than the current pegasis protocol by about 35%.\"",
            "contribution_ids": [
                "R26629"
            ]
        },
        {
            "instance_id": "R26654xR26652",
            "comparison_id": "R26654",
            "paper_id": "R26652",
            "text": "Distance based thresholds for cluster head selection in wireless sensor networks central to the cluster-based routing protocols is the cluster head (ch) selection procedure that allows even distribution of energy consumption among the sensors, and therefore prolonging the lifespan of a sensor network. we propose a distributed ch selection algorithm that takes into account the distances from sensors to a base station that optimally balances the energy consumption among the sensors. ns-2 simulations show that our proposed scheme outperforms existing algorithms in terms of the average node lifespan and the time to first node death.",
            "contribution_ids": [
                "R26653"
            ]
        },
        {
            "instance_id": "R26729xR26672",
            "comparison_id": "R26729",
            "paper_id": "R26672",
            "text": "A probabilistic clustering algorithm in wireless sensor networks a wireless sensor network consists of nodes that can communicate with each other via wireless links. one way to support efficient communication between sensors is to organize the network into several groups, called clusters, with each cluster electing one node as the head of cluster. the paper describes a constant time clustering algorithm that can be applied on wireless sensor networks. this approach is an extension to the younis and fahmy method (1). the simulation results show that the extension can generate a small number of cluster heads in relatively few rounds, especially in sparse networks.",
            "contribution_ids": [
                "R26673"
            ]
        },
        {
            "instance_id": "R26729xR26687",
            "comparison_id": "R26729",
            "paper_id": "R26687",
            "text": "TASC: topology adaptive spatial clustering for sensor networks \"the ability to extract topological regularity out of large randomly deployed sensor networks holds the promise to maximally leverage correlation for data aggregation and also to assist with sensor localization and hierarchy creation. this paper focuses on extracting such regular structures from physical topology through the development of a distributed clustering scheme. the topology adaptive spatial clustering (tasc) algorithm presented here is a distributed algorithm that partitions the network into a set of locally isotropic, non-overlapping clusters without prior knowledge of the number of clusters, cluster size and node coordinates. this is achieved by deriving a set of weights that encode distance measurements, connectivity and density information within the locality of each node. the derived weights form the terrain for holding a coordinated leader election in which each node selects the node closer to the center of mass of its neighborhood to become its leader. the clustering algorithm also employs a dynamic density reachability criterion that groups nodes according to their neighborhood's density properties. our simulation results show that the proposed algorithm can trace locally isotropic structures in non-isotropic network and cluster the network with respect to local density attributes. we also found out that tasc exhibits consistent behavior in the presence of moderate measurement noise levels\"",
            "contribution_ids": [
                "R26688"
            ]
        },
        {
            "instance_id": "R26729xR26691",
            "comparison_id": "R26729",
            "paper_id": "R26691",
            "text": "Distributed Clustering-Based Aggregation Algorithm for Spatial Correlated Sensor Networks in wireless sensor networks, it is already noted that nearby sensor nodes monitoring an environmental feature typically register similar values. this kind of data redundancy due to the spatial correlation between sensor observations inspires the research of in-network data aggregation. in this paper, an \u03b1 -local spatial clustering algorithm for sensor networks is proposed. by measuring the spatial correlation between data sampled by different sensors, the algorithm constructs a dominating set as the sensor network backbone used to realize the data aggregation based on the information description/summarization performance of the dominators. in order to evaluate the performance of the algorithm a pattern recognition scenario over environmental data is presented. the evaluation shows that the resulting network achieved by our algorithm can provide environmental information at higher accuracy compared to other algorithms.",
            "contribution_ids": [
                "R26692"
            ]
        },
        {
            "instance_id": "R26729xR26704",
            "comparison_id": "R26729",
            "paper_id": "R26704",
            "text": "A centralized energy-efficient routing protocol for wireless sensor networks wireless sensor networks consist of small battery powered devices with limited energy resources. once deployed, the small sensor nodes are usually inaccessible to the user, and thus replacement of the energy source is not feasible. hence, energy efficiency is a key design issue that needs to be enhanced in order to improve the life span of the network. several network layer protocols have been proposed to improve the effective lifetime of a network with a limited energy supply. in this article we propose a centralized routing protocol called base-station controlled dynamic clustering protocol (bcdcp), which distributes the energy dissipation evenly among all sensor nodes to improve network lifetime and average energy savings. the performance of bcdcp is then compared to clustering-based schemes such as low-energy adaptive clustering hierarchy (leach), leach-centralized (leach-c), and power-efficient gathering in sensor information systems (pegasis). simulation results show that bcdcp reduces overall energy consumption and improves network lifetime over its comparatives.",
            "contribution_ids": [
                "R26705"
            ]
        },
        {
            "instance_id": "R26775xR26754",
            "comparison_id": "R26775",
            "paper_id": "R26754",
            "text": "An Energy-Aware Distributed Unequal Clustering Protocol for Wireless Sensor Networks due to the imbalance of energy consumption of nodes in wireless sensor networks (wsns), some local nodes die prematurely, which causes the network partitions and then shortens the lifetime of the network. the phenomenon is called \u201chot spot\u201d or \u201cenergy hole\u201d problem. for this problem, an energy-aware distributed unequal clustering protocol (eaduc) in multihop heterogeneous wsns is proposed. compared with the previous protocols, the cluster heads obtained by eaduc can achieve balanced energy, good distribution, and seamless coverage for all the nodes. moreover, the complexity of time and control message is low. simulation experiments show that eaduc can prolong the lifetime of the network significantly.",
            "contribution_ids": [
                "R26755"
            ]
        },
        {
            "instance_id": "R26775xR26766",
            "comparison_id": "R26775",
            "paper_id": "R26766",
            "text": "Multihop Routing Protocol with Unequal Clustering for Wireless Sensor Networks in order to prolong the lifetime of wireless sensor networks, this paper presents a multihop routing protocol with unequal clustering (mrpuc). on the one hand, cluster heads deliver the data to the base station with relay to reduce energy consumption. on the other hand, mrpuc uses many measures to balance the energy of nodes. first, it selects the nodes with more residual energy as cluster heads, and clusters closer to the base station have smaller sizes to preserve some energy during intra-cluster communication for inter-cluster packets forwarding. second, when regular nodes join clusters, they consider not only the distance to cluster heads but also the residual energy of cluster heads. third, cluster heads choose those nodes as relay nodes, which have minimum energy consumption for forwarding and maximum residual energy to avoid dying earlier. simulation results show that mrpuc performs much better than similar protocols.",
            "contribution_ids": [
                "R26767"
            ]
        },
        {
            "instance_id": "R26775xR26742",
            "comparison_id": "R26775",
            "paper_id": "R26742",
            "text": "An energy-efficient distributed unequal clustering protocol for wireless sensor networks due to the imbalance of energy consumption of nodes in wireless sensor networks (wsns), some local nodes die prematurely, which causes the network partitions and then shortens the lifetime of the network. the phenomenon is called \u201chot spot\u201d or \u201cenergy hole\u201d problem. for this problem, an energy-aware distributed unequal clustering protocol (eaduc) in multihop heterogeneous wsns is proposed. compared with the previous protocols, the cluster heads obtained by eaduc can achieve balanced energy, good distribution, and seamless coverage for all the nodes.moreover, the complexity of time and control message is low. simulation experiments show that eaduc can prolong the lifetime of the network significantly.",
            "contribution_ids": [
                "R26743"
            ]
        },
        {
            "instance_id": "R26850xR26797",
            "comparison_id": "R26850",
            "paper_id": "R26797",
            "text": "The mixed fleet stochastic vehicle routing problem the mixed fleet stochastic vehicle routing problem is considered in the paper. it is assumed that operations are performed by vehicles of different types. the model developed is based on the \u201croute first \u2014 cluster second\u201d approach. a heuristic algorithm based on space-filling curves is used to produce a giant travelling salesman tour. the giant tour is divided into smaller parts using the generalized floyd algorithm. the final set of routes may be chosen after making a suitable multi-attribute decision making analysis.",
            "contribution_ids": [
                "R26798"
            ]
        },
        {
            "instance_id": "R26850xR26839",
            "comparison_id": "R26850",
            "paper_id": "R26839",
            "text": "Valid inequalities for the fleet size and mix vehicle routing problem with fixed costs in the well\u2010known vehicle routing problem (vrp), a set of identical vehicles located at a central depot is to be optimally routed to supply customers with known demands subject to vehicle capacity constraints. an important variant of the vrp arises when a mixed fleet of vehicles, characterized by different capacities and costs, is available for distribution activities. the problem is known as fleet size and mix vrp with fixed costs fsmf and has several practical applications. in this article, we present a new mixed integer programming formulation for fsmf based on a two\u2010commodity network flow approach. new valid inequalities are proposed to strengthen the linear programming relaxation of the mathematical formulation. the effectiveness of the proposed cuts is extensively tested on benchmark instances. \u00a9 2009 wiley periodicals, inc. networks, 2009",
            "contribution_ids": [
                "R26840"
            ]
        },
        {
            "instance_id": "R26918xR26883",
            "comparison_id": "R26918",
            "paper_id": "R26883",
            "text": "Lagrangian Relaxation Methods for Solving the Minimum Fleet Size Multiple Traveling Salesman Problem with Time Windows we consider the problem of finding the minimum number of vehicles required to visit once a set of nodes subject to time window constraints, for a homogeneous fleet of vehicles located at a common depot. this problem can be formulated as a network flow problem with additional time constraints. the paper presents an optimal solution approach using the augmented lagrangian method. two lagrangian relaxations are studied. in the first one, the time constraints are relaxed producing network subproblems which are easy to solve, but the bound obtained is weak. in the second relaxation, constraints requiring that each node be visited are relaxed producing shortest path subproblems with time window constraints and integrality conditions. the bound produced is always excellent. numerical results for several actual school busing problems with up to 223 nodes are discussed. comparisons with a set partitioning formulation solved by column generation are given.",
            "contribution_ids": [
                "R26884"
            ]
        },
        {
            "instance_id": "R26918xR26893",
            "comparison_id": "R26918",
            "paper_id": "R26893",
            "text": "Minimum Vehicle Fleet Size Under Time-Window Constraints at a Container Terminal products can be transported in containers from one port to another. at a container terminal these containers are transshipped from one mode of transportation to another. cranes remove containers from a ship and put them at a certain time (i.e., release time) into a buffer area with limited capacity. a vehicle lifts a container from the buffer area before the buffer area is full (i.e., in due time) and transports the container from the buffer area to the storage area. at the storage area the container is placed in another buffer area. the advantage of using these buffer areas is the resultant decoupling of the unloading and transportation processes. we study the case in which each container has a time window [release time, due time] in which the transportation should start. the objective is to minimize the vehicle fleet size such that the transportation of each container starts within its time window. no literature has been found studying this relevant problem. we have developed an integer linear programming model to solve the problem of determining vehicle requirements under time-window constraints. we use simulation to validate the estimates of the vehicle fleet size by the analytical model. we test the ability of the model under various conditions. from these numerical experiments we conclude that the results of the analytical model are close to the results of the simulation model. furthermore, we conclude that the analytical model performs well in the context of a container terminal.",
            "contribution_ids": [
                "R26894"
            ]
        },
        {
            "instance_id": "R26982xR26966",
            "comparison_id": "R26982",
            "paper_id": "R26966",
            "text": "Fleet Size and Mix Optimization for Paratransit Services most paratransit agencies use a mix of different types of vehicles ranging from small sedans to large converted vans as a cost-effective way to meet the diverse travel needs and seating requirements of their clients. currently, decisions on what types of vehicles and how many vehicles to use are mostly made by service managers on an ad hoc basis without much systematic analysis and optimization. the objective of this research is to address the underlying fleet size and mix problem and to develop a practical procedure that can be used to determine the optimal fleet mix for a given application. a real-life example illustrates the relationship between the performance of a paratransit service system and the size of its service vehicles. a heuristic procedure identifies the optimal fleet mix that maximizes the operating efficiency of a service system. a set of recommendations is offered for future research; the most important is the need to incorporate a life-cycle cost framework into the paratransit service planning process.",
            "contribution_ids": [
                "R26967"
            ]
        },
        {
            "instance_id": "R26982xR26980",
            "comparison_id": "R26982",
            "paper_id": "R26980",
            "text": "Coca-Cola Enterprises Optimizes Vehicle Routes for Efficient Product Delivery \" in 2004 and 2005, coca-cola enterprises (cce)\u2014the world's largest bottler and distributor of coca-cola products\u2014implemented ortec's vehicle-routing software. today, over 300 cce dispatchers use this software daily to plan the routes of approximately 10,000 trucks. in addition to handling nonstandard constraints, the implementation is notable for its progressive transition from the prior business practice. cce has realized an annual cost saving of $45 million and major improvements in customer service. this approach has been so successful that coca-cola has extended it beyond cce to other coca-cola bottling companies and beer distributors. \"",
            "contribution_ids": [
                "R26981"
            ]
        },
        {
            "instance_id": "R27039xR27002",
            "comparison_id": "R27039",
            "paper_id": "R27002",
            "text": "Scheduling short-term marine transport of bulk products a multinational company uses a personal computer to schedule a fleet of coastal tankers and barges transporting liquid bulk products among plants, distribution centres (tank farms), and industrial customers. a simple spreadsheet interface cloaks a sophisticated optimization-based decision support system and makes this system useable via a varity of natural languages. the dispatchers, whose native language is not english, and some of whom presumably speak no english at all, communicate via the spreadsheet, and view recommended schedules displayed in gantt charts both internationally familiar tools. inside the spreadsheet, a highly detailed simulation can generate every feasible alternate vessel employment schedule, and an integer linear set partitioning model selects one schedule for each vessel so that all loads and deliveries are completed at minimal cost while satisfying all operational requirements. the optimized fleet employment schedule is displyed graphically with hourly time resolution over a planning horizon of 2-3 weeks. each vessel will customarily make several voyages and many port calls to load and unload products during this time.",
            "contribution_ids": [
                "R27003"
            ]
        },
        {
            "instance_id": "R27039xR27015",
            "comparison_id": "R27039",
            "paper_id": "R27015",
            "text": "Strategic fleet size planning for maritime refrigerated containers in the present economic climate, it is often the case that profits can only be improved, or for that matter maintained, by improving efficiency and cutting costs. this is particularly notorious in the shipping business, where it has been seen that the competition is getting tougher among carriers, thus alliances and partnerships are resulting for cost effective services in recent years. in this scenario, effective planning methods are important not only for strategic but also operating tasks, covering their entire transportation systems. container fleet size planning is an important part of the strategy of any shipping line. this paper addresses the problem of fleet size planning for refrigerated containers, to achieve cost-effective services in a competitive maritime shipping market. an analytical model is first discussed to determine the optimal size of an own dry container fleet. then, this is extended for an own refrigerated container fleet, which is the case when an extremely unbalanced trade represents one of the major investment decisions to be taken by liner operators. next, a simulation model is developed for fleet sizing in a more practical situation and, by using this, various scenarios are analysed to determine the most convenient composition of refrigerated fleet between own and leased containers for the transpacific cargo trade.",
            "contribution_ids": [
                "R27016"
            ]
        },
        {
            "instance_id": "R27039xR27018",
            "comparison_id": "R27039",
            "paper_id": "R27018",
            "text": "Robust ship scheduling with multiple time windows \"we present a ship scheduling problem concerned with the pickup and delivery of bulk cargoes within given time windows. as the ports are closed for service at night and during weekends, the wide time windows can be regarded as multiple time windows. another issue is that the loading/discharging times of cargoes may take several days. this means that a ship will stay idle much of the time in port, and the total time at port will depend on the ship's arrival time. ship scheduling is associated with uncertainty due to bad weather at sea and unpredictable service times in ports. our objective is to make robust schedules that are less likely to result in ships staying idle in ports during the weekend, and impose penalty costs for arrivals at risky times (i.e., close to weekends). a set partitioning approach is proposed to solve the problem. the columns correspond to feasible ship schedules that are found a priori. they are generated taking the uncertainty and multiple time windows into account. the computational results show that we can increase the robustness of the schedules at the sacrifice of increased transportation costs. \u00a9 2002 wiley periodicals, inc. naval research logistics 49: 611\u2013625, 2002; published online in wiley interscience (www.interscience.wiley.com). doi 10.1002/nav.10033\"",
            "contribution_ids": [
                "R27019"
            ]
        },
        {
            "instance_id": "R27039xR27027",
            "comparison_id": "R27039",
            "paper_id": "R27027",
            "text": "Ship Routing and Scheduling: Status and Perspectives the objective of this paper is to review the current status of ship routing and scheduling. we focus on literature published during the last decade. because routing and scheduling problems are closely related to many other fleet planning problems, we have divided this review into several parts. we start at the strategic fleet planning level and discuss the design of fleets and sea transport systems. we continue with the tactical and operational fleet planning level and consider problems that comprise various ship routing and scheduling aspects. here, we separately discuss the different modes of operations: industrial, tramp, and liner shipping. finally, we take a glimpse at naval applications and other related problems that do not naturally fall into these categories. the paper also presents some perspectives regarding future developments and use of optimization-based decision-support systems for ship routing and scheduling. several of the trends indicate both accelerating needs for and benefits from such systems and, hopefully, this paper will stimulate further research in this area.",
            "contribution_ids": [
                "R27028"
            ]
        },
        {
            "instance_id": "R27061xR27041",
            "comparison_id": "R27061",
            "paper_id": "R27041",
            "text": "Foundations for Smarter Cities this paper describes the information technology (it) foundation and principles for smarter cities\u2122. smarter cities are urban areas that exploit operational data, such as that arising from traffic congestion, power consumption statistics, and public safety events, to optimize the operation of city services. the foundational concepts are instrumented, interconnected, and intelligent. instrumented refers to sources of near-real-time real-world data from both physical and virtual sensors. interconnected means the integration of those data into an enterprise computing platform and the communication of such information among the various city services. intelligent refers to the inclusion of complex analytics, modeling, optimization, and visualization in the operational business processes to make better operational decisions. this approach enables the adaptation of city services to the behavior of the inhabitants, which permits the optimal use of the available physical infrastructure and resources, for example, in sensing and controlling consumption of energy and water, managing waste processing and transportation systems, and applying optimization to achieve new efficiencies among these resources. additional roles exist in intelligent interaction between the city and its inhabitants and further contribute to operational efficiency while maintaining or enhancing quality of life.",
            "contribution_ids": [
                "R27042"
            ]
        },
        {
            "instance_id": "R27061xR27059",
            "comparison_id": "R27061",
            "paper_id": "R27059",
            "text": "Using cloud technologies for large-scale house data in smart city in the smart city environment, a wide variety of data are collected from sensors and devices to achieve value-added services. in this paper, we especially focus on data taken from smart houses in the smart city, and propose a platform, called scallop4sc, that stores and processes the large-scale house data. the house data is classified into log data or configuration data. since the amount of the log is extremely large, we introduce the hadoop/mapreduce with a multi-node cluster. on top of this, we use hbase key-value store to manage heterogeneous log data in a schemaless manner. on the other hand, to manage the configuration data, we choose mysql to process various queries to the house data efficiently. we propose practical data models of the log data and the configuration data on hbase and mysql, respectively. we then show how scallop4sc works as a efficient data platform for smart city services. we implement a prototype with 12 linux servers. we conduct an experimental evaluation to calculate device-wise energy consumption, using actual house log recorded for one year in our smart house. based on the result, we discuss the applicability of scallop4sc to city-scale data processing.",
            "contribution_ids": [
                "R27060"
            ]
        },
        {
            "instance_id": "R27235xR27209",
            "comparison_id": "R27235",
            "paper_id": "R27209",
            "text": "Estimating the impact of exchange rate volatility on exports: evidence from Asian countries the paper examines the impact of exchange rate volatility on the exports of five asian countries. the countries are turkey, south korea, malaysia, indonesia and pakistan. the impact of a volatility term on exports is examined by using an engle-granger residual-based cointegrating technique. the results indicate that the exchange rate volatility reduced real exports for these countries. this might mean that producers in these countries are risk-averse. the producers will prefer to sell in domestic markets rather than foreign markets if the exchange rate volatility increases.",
            "contribution_ids": [
                "R27210"
            ]
        },
        {
            "instance_id": "R27235xR27217",
            "comparison_id": "R27235",
            "paper_id": "R27217",
            "text": "Exchange Rate Volatility and Trade among the Asia Pacific \"the purpose of this paper is to investigate the impact of exchange rate volatility on exports among 14 asia pacific countries, where various measures to raise the intra-region trade are being implemented. specifically, this paper estimates a gravity model, in which the dependent variable is the product of the exports of two trading countries. in addition, it also estimates a unilateral exports model, in which the dependent variable is not the product of the exports of two trading countries but the exports from one country to another. by doing this, the depreciation rate of the exporting country's currency value can be included as one of the explanatory variables affecting the volume of exports. as the explanatory variables of the export volume, the gravity model adopts the product of the gdps of two trading counties, their bilateral exchange rate volatility, their distance, a time trend and dummies for the share of the border line, the use of the same language, and the apec membership. in the case of the unilateral exports model, the product of the gdps is replaced by the gdp of the importing country, and the depreciation rate of the exporting country's currency value is dded. in addition, considering that the export volume will also depend on various onditions of the exporting country, dummies for exporting countries are also included as an explanatory variable. the empirical tests, using annual data for the period from 1980 to 2002, detect a significant negative impact of exchange rate volatility on the volume of exports. in addition, various tests using the data for sub-sample periods indicate that the negative impact had been weakened since 1989, when apec had launched, and surged again from 1997, when the asian financial crisis broke out. this finding implies that the impact of exchange rate volatility is time-dependent and that it is significantlynegative at least in the present time. this phenomenon is noticed regardless which estimation model is adopted. in addition, the test results show that the gdp of the importing country, the depreciation of the exporting country's currency value, the use of the same language and the membership of apec have positive impacts on exports, while the distance between trading countries have negative impacts. finally, it turns out that the negative impact of exchange rate volatility is much weaker among oecd countries than among non-oecd counties.\"",
            "contribution_ids": [
                "R27218"
            ]
        },
        {
            "instance_id": "R27235xR27220",
            "comparison_id": "R27235",
            "paper_id": "R27220",
            "text": "On the Trade Impact of Nominal Exchange Rate Volatility what is the effect of nominal exchange rate variability on trade? i argue that the methods conventionally used to answer this perennial question are plagued by a variety of sources of systematic bias. i propose a novel approach that simultaneously addresses all of these biases, and present new estimates from a broad sample of countries from 1970 to 1997. the answer to the question is: not much.",
            "contribution_ids": [
                "R27221"
            ]
        },
        {
            "instance_id": "R27235xR27230",
            "comparison_id": "R27235",
            "paper_id": "R27230",
            "text": "Exchange Rate Volatility and Trade Flows of the U.K. in 1990s this paper examines the impact of exchange rate volatility on trade flows in the u.k. over the period 1990\u20132000. according to the conventional approach, exchange rate volatility clamps down trade volumes. this paper, however, identifies the existence of a positive relationship between exchange rate volatility and imports in the u.k. in the 1990s by using a bivariate garch-in-mean model. it highlights a possible emergence of a polarized version with conventional proposition that erv works as an impediment factor on trade flows.",
            "contribution_ids": [
                "R27231"
            ]
        },
        {
            "instance_id": "R27264xR27238",
            "comparison_id": "R27264",
            "paper_id": "R27238",
            "text": "Middleware for Robotics: A Survey the field of robotics relies heavily on various technologies such as mechatronics, computing systems, and wireless communication. given the fast growing technological progress in these fields, robots can offer a wide range of applications. however real world integration and application development for such a distributed system composed of many robotic modules and networked robotic devices is very difficult. therefore, middleware services provide a novel approach offering many possibilities and drastically enhancing the application development for robots. this paper surveys the current state of middleware approaches in this domain. it discusses middleware challenges in these systems and presents some representative middleware solutions specifically designed for robots. the selection of the studied methods tries to cover most of the middleware platforms, objectives and approaches that have been proposed by researchers in this field.",
            "contribution_ids": [
                "R27239",
                "R27241",
                "R27243",
                "R27245",
                "R27247",
                "R27249"
            ]
        },
        {
            "instance_id": "R27380xR27297",
            "comparison_id": "R27380",
            "paper_id": "R27297",
            "text": "Relaxation of Shot Peening Induced Compressive Stress During Fatigue of Notched Steelsamples abstractthis paper presents an experimental investigation of the surface residual stress relaxation behaviour of a shot peened 0.4% carbon low alloy steel under fatigue loading. a round specimen with a circumferential notch and a notch factor kt = 1.75 was fatigue loaded in both shot peened and ground conditions. loading conditions included axial fatigue with stress ratio r = \u22121 and r = 0 and also r = \u22121 with an additional peak overload applied at 106 cycles. plain unnotched shot peened specimens were also fatigue loaded with stress ratio r = \u22121. the results show how the relaxation is dependent on load level, how the peak load changes the surface residual stress state, and that relaxation of the smooth and notched conditions is similar. two different shot peening conditions were used, one with almen intensity of 30\u201335a (mm/100) and another of 50\u201355 a (mm/l00).",
            "contribution_ids": [
                "R27298"
            ]
        },
        {
            "instance_id": "R27380xR27362",
            "comparison_id": "R27380",
            "paper_id": "R27362",
            "text": "Influence of Optimized Warm Peening on Residual Stress Stability and Fatigue Strength of AISI 4140 in Different Material States using a modified air blasting machine warm peening at 20 o c < t i 410 \"c was feasible. an optimized peening temperature of about 310 \"c was identified for a 450 \"c quenched and ternpered steel aisi 4140. warm peening was also investigated for a normalized, a 650 \"c quenched and tempered, and a martensitically hardened material state. the quasi static surface compressive yield strengths as well as the cyclic surface yield strengths were determined from residual stress relaxation tests conducted at different stress amplitudes and numbers of loading cycles. dynamic and static strain aging effects acting during and after warm peening clearly increased the residual stress stability and the alternating bending strength for all material states.",
            "contribution_ids": [
                "R27363"
            ]
        },
        {
            "instance_id": "R27380xR27374",
            "comparison_id": "R27380",
            "paper_id": "R27374",
            "text": "Relaxation of residual stresses induced by turning and shot peening on steels experiments on the relaxation of residual stresses in steels by fatigue loading are described. this question is of interest because it is well known that compressive residual stresses are often induced by special surface treatments (such as shot peening) to improve the fatigue life of metal parts; however, if cyclic relaxation occurs, the beneficial effects can, in part, vanish during service. two hardened and tempered steels of grade c45 and 39nicrmo3 were used in the tests. for both materials, different specimens were given two surface treatments: simple turning without successive surface treatment, inducing on the surface a moderate tensile residual stress state, and shot peening, inducing high residual compressive stresses. the specimens were submitted to constant-amplitude tension-compression fatigue loading, and the surface residual stresses were measured after 0, 1, 10 cycles and more. results show that relaxation occurs from the very first cycle; the amount of residual stress relaxation depends on many parameters and on the type of steel. the results are in agreement with data obtained by other researchers.",
            "contribution_ids": [
                "R27375"
            ]
        },
        {
            "instance_id": "R27380xR27347",
            "comparison_id": "R27380",
            "paper_id": "R27347",
            "text": "Influence of the shot peening temperature on the relaxation behaviour of residual stresses during cyclic bending shot peening of steels at elevated temperatures (warm peening) can improve the fatigue behaviour of workpieces. for the steel ai sf 4140 (german grade 42crm04) in a quenched and tempered condition, it is shown that this is not only caused by the higher compressive residual stresses induced but also due to an enlarged stability of these residual stresses during cyclic bending. this can be explained by strain aging effects during shot peening, which cause different and more stable dislocation structures.",
            "contribution_ids": [
                "R27348"
            ]
        },
        {
            "instance_id": "R27461xR27413",
            "comparison_id": "R27461",
            "paper_id": "R27413",
            "text": "Approximate Correlations for Chevron-Type Plate Heat Exchangers there exists very little useful data representing the performance of industrial plate heat exchangers (phes) in the open literature. as a result, it has been difficult to arrive at any generalized correlations. while every phe manufacturer is believed to have a comprehensive set of performance curves for their own designs, there exists the need to generate an approximate set of generalized correlations for the heat-transfer community. such correlations can be used for preliminary designs and analytical studies. this paper attempts to develop such a set of generalized correlations to quantify the heat-transfer and pressure-drop performance of chevron-type phes. for this purpose, the experimental data reported by heavner et al. were used for the turbulent region. for the laminar region, a semi-theoretical approach was used to express, for example, the friction factor as a function of the reynolds number and the chevron angle. asymptotic curves were used for the transitional region. physical explanations are provided for the trends shown by the generalized correlations. the correlations are compared against the open-literature data, where appropriate. these correlations are expected to be improved in the future when more data become available.",
            "contribution_ids": [
                "R27414"
            ]
        },
        {
            "instance_id": "R27620xR27505",
            "comparison_id": "R27620",
            "paper_id": "R27505",
            "text": "An investigation of cointegration and causality between energy consumption and economic growth this paper reexamines the causality between energy consumption and economic growth with both bivariate and multivariate models by applying the recently developed methods of cointegration and hsiao`s version of the granger causality to transformed u.s. data for the period 1947-1990. the phillips-perron (pp) tests reveal that the original series are not stationary and, therefore, a first differencing is performed to secure stationarity. the study finds no causal linkages between energy consumption and economic growth. energy and gross national product (gnp) each live a life of its own. the results of this article are consistent with some of the past studies that find no relationship between energy and gnp but are contrary to some other studies that find gnp unidirectionally causes energy consumption. both the bivariate and trivariate models produce the similar results. we also find that there is no causal relationship between energy consumption and industrial production. the united states is basically a service-oriented economy and changes in energy consumption can cause little or no changes in gnp. in other words, an implementation of energy conservation policy may not impair economic growth. 27 refs., 5 tabs.",
            "contribution_ids": [
                "R27506"
            ]
        },
        {
            "instance_id": "R27705xR27638",
            "comparison_id": "R27705",
            "paper_id": "R27638",
            "text": "Electricity consumption and economic growth: evidence from Korea th e paper investigates the relationship between electricity consumption and economic growth in poland for the period 2000 to 2012. understanding the behavior of electricity consumption in relation to the economy is very important for improve a stable economic growth and development. th e obtained results indicate that there is the causal relationship between electricity consumption and economic growth in poland and the relationship is bi-directional. we also discovered the bi-directional causality between capital and economic growth. on the basis of the causality results we estimated a one-sector aggregate production function, where the electricity consumption was one of the input variables. th e evaluated growth model showed that electricity consumption is a pro-growth variable, so the results indicate that economic growth of poland is electricity-dependent. th at\u2019s allows to state that electricity is a limiting factor to economic growth of poland.",
            "contribution_ids": [
                "R27639"
            ]
        },
        {
            "instance_id": "R27705xR27685",
            "comparison_id": "R27705",
            "paper_id": "R27685",
            "text": "Structural breaks, electricity consumption and economic growth: evidence from Turkey this study examines the causal relationship between electricity consumption and economic growth for ghana during the period 1970 to 2010. the study employed unit root and cointegration tests taking into account structural breaks. the following findings were made: first, a plot of the series indicated a trend pattern. the series also experienced structural breaks in 1979 and 1983 but after taking structural breaks into account they became stationary. second, the series exhibited one cointegration vector implying a long\u2013run relationship between them. third, the results revealed the presence of unidirectional granger causality running from economic growth to electricity consumption. in general, the study identified the presence of structural break dates which corresponded with the critical economic events in ghana. \\n \\n \\xa0 \\n \\n key\\xa0words:\\xa0electricity consumption, economic growth, structural break, vector error correction mode (vecm), causality.",
            "contribution_ids": [
                "R27686"
            ]
        },
        {
            "instance_id": "R27835xR27767",
            "comparison_id": "R27835",
            "paper_id": "R27767",
            "text": "What Do Students Learn When Collaboratively Using A Computer Game in the Study of Historical Disease Epidemics, and Why? the use of computer games and virtual environments has been shown to engage and motivate students and can provide opportunities to visualize the historical period and make sense of complex visual information. this article presents the results of a study in which university students were asked to collaboratively solve inquiry-based problems related to historical disease epidemics using game-based learning. a multimethod approach to the data collection was used. initial results indicated that students attended to visual information with more specificity than text-based information when using a virtual environment. models of student\u2019s decision-making processes when interacting with the world confirmed that students were making decisions related to these visual elements, and not the inquiry process. building on theories from the learning sciences, such as learning from animations/visualizations and computer-supported collaborative learning, in this article, the authors begin to answer the question of why students learned what they did about historical disease epidemics.",
            "contribution_ids": [
                "R27768"
            ]
        },
        {
            "instance_id": "R27835xR27790",
            "comparison_id": "R27835",
            "paper_id": "R27790",
            "text": "New Directions for Traditional Lessons\u00e2\u0080\u009d: Can Handheld Game Consoles Enhance Mental Mathematics Skills? this paper reports on a pilot study that compared the use of commercial off-the-shelf (cots) handheld game consoles (hgcs) with traditional teaching methods to develop the automaticity of mathematical calculations and self-concept towards mathematics for year 4 students in two metropolitan schools. one class conducted daily sessions using the hgcs and the dr kawashima\u2019s brain training software to enhance their mental maths skills while the comparison class engaged in mental maths lessons using more traditional classroom approaches. students were assessed using standardised tests at the beginning and completion of the term and findings indicated that students who undertook the brain training pilot study using the hgcs showed significant improvement in both the speed and accuracy of their mathematical calculations and selfconcept compared to students in the control school. an exploration of the intervention, discussion of methodology and the implications of the use of hgcs in the primary classroom are presented.",
            "contribution_ids": [
                "R27791"
            ]
        },
        {
            "instance_id": "R27835xR27810",
            "comparison_id": "R27835",
            "paper_id": "R27810",
            "text": "Developing and evaluating dialogue games for collaborative e-learning \"this paper argues that developments in collaborative e-learning dialogue should be based on pedagogically sound principles of discourse, and therefore, by implication, there is a need to develop methodologies which transpose \u2014 typically informal \u2014 models of educational dialogue into cognitive tools that are suitable for students. a methodology of 'investigation by design' is described which has been used to design computer-based dialogue games supporting conceptual change and development in science \u2014 based on the findings of empirical studies. an evaluation of two dialogue games for collaborative interaction, a facilitating game and an elicit-inform game, has shown that they produce significant improvements in students conceptual understanding, and they are differentially successful \u2014 depending on the nature of the conceptual difficulties experienced by the learners. the implications this study has for the role of collaborative dialogue in learning and designing computer- based and computer-mediated collaborative interaction are discussed.\"",
            "contribution_ids": [
                "R27811"
            ]
        },
        {
            "instance_id": "R27835xR27815",
            "comparison_id": "R27835",
            "paper_id": "R27815",
            "text": "Idea Storming Cube: A Game-based System to Support Creative Thinking this paper describes a collaborative game-based creativity support system, idea storming cube, in support of creative thinking. it aims to make people form a creative and perspective-shift thinking habit. the system acquires knowledge from domain expert, user inputs history, and individuals in the current brainstorming group, and then provides user-, goal- and context-sensitive supports. comparing to classic tutoring systems, it focuses more on stimulating divergent thinking. the system can be put into the basic mode or the idea generation mode in order to support different gaming objectives. a case study for preliminary evaluation of the proposed hci tool for collaborative idea generation is also reported in this paper.",
            "contribution_ids": [
                "R27816"
            ]
        },
        {
            "instance_id": "R27835xR27777",
            "comparison_id": "R27835",
            "paper_id": "R27777",
            "text": "Computer games for the math achievement of diverse students \"introduction as a way to improve student academic performance, educators have begun paying special attention to computer games (gee, 2005; oblinger, 2006). reflecting the interests of the educators, studies have been conducted to explore the effects of computer games on student achievement. however, there has been no consensus on the effects of computer games: some studies support computer games as educational resources to promote students' learning (annetta, mangrum, holmes, collazo, & cheng, 2009; vogel et al., 2006). other studies have found no significant effects on the students' performance in school, especially in math achievement of elementary school students (ke, 2008). researchers have also been interested in the differential effects of computer games between gender groups. while several studies have reported various gender differences in the preferences of computer games (agosto, 2004; kinzie & joseph, 2008), a few studies have indicated no significant differential effect of computer games between genders and asserted generic benefits for both genders (vogel et al., 2006). to date, the studies examining computer games and gender interaction are far from conclusive. moreover, there is a lack of empirical studies examining the differential effects of computer games on the academic performance of diverse learners. these learners included linguistic minority students who speak languages other than english. recent trends in the k-12 population feature the increasing enrollment of linguistic minority students, whose population reached almost four million (nces, 2004). these students have been a grieve concern for american educators because of their reported low performance. in response, this study empirically examined the effects of math computer games on the math performance of 4th-graders with focused attention on differential effects for gender and linguistic groups. to achieve greater generalizability of the study findings, the study utilized a us nationally representative database--the 2005 national assessment of educational progress (naep). the following research questions guided the current study: 1. are computer games in math classes associated with the 4th-grade students' math performance? 2. how does the relationship differ by linguistic group? 3. how does the association vary by gender? 4. is there an interaction effect of computer games on linguistic and gender groups? in other words, how does the effect of computer games on linguistic groups vary by gender group? literature review academic performance and computer games according debell and chapman (2004), of 58,273,000 students of nursery and k-12 school age in the usa, 56% of students played computer games. along with the popularity among students, computer games have received a lot of attention from educators as a potential way to provide learners with effective and fun learning environments (oblinger, 2006). gee (2005) agreed that a game would turn out to be good for learning when the game is built to incorporate learning principles. some researchers have also supported the potential of games for affective domains of learning and fostering a positive attitude towards learning (ke, 2008; ke & grabowski, 2007; vogel et al., 2006). for example, based on the study conducted on 1,274 1st- and 2nd-graders, rosas et al. (2003) found a positive effect of educational games on the motivation of students. although there is overall support for the idea that games have a positive effect on affective aspects of learning, there have been mixed research results regarding the role of games in promoting cognitive gains and academic achievement. in the meta-analysis, vogel et al. (2006) examined 32 empirical studies and concluded that the inclusion of games for students' learning resulted in significantly higher cognitive gains compared with traditional teaching methods without games. \u2026\"",
            "contribution_ids": [
                "R27778"
            ]
        },
        {
            "instance_id": "R27835xR27792",
            "comparison_id": "R27835",
            "paper_id": "R27792",
            "text": "A Study on Exploiting Commercial Digital Games into School Context digital game-based learning is a research field within the context of technology-enhanced learning that has attracted significant research interest. commercial off-the-shelf digital games have the potential to provide concrete learning experiences and allow for drawing links between abstract concepts and real-world situations. the aim of this paper is to provide evidence for the effect of a general-purpose commercial digital game (namely, the \u201csims 2-open for business\u201d) on the achievement of standard curriculum mathematics educational objectives as well as general educational objectives as defined by standard taxonomies. furthermore, students\u2019 opinions about their participation in the proposed game-supported educational scenario and potential changes in their attitudes toward math teaching and learning in junior high school are investigated. the results of the conducted research showed that: (i) students engaged in the game-supported educational activities achieved the same results with those who did not, with regard to the subject matter educational objectives, (ii) digital gamesupported educational activities resulted in better achievement of the general educational objectives, and (iii) no significant differences were observed with regard to students\u2019 attitudes towards math teaching and learning.",
            "contribution_ids": [
                "R27793"
            ]
        },
        {
            "instance_id": "R27835xR27804",
            "comparison_id": "R27835",
            "paper_id": "R27804",
            "text": "Outdoor natural science learning with an RFID-supported immersive ubiquitous learning environment despite their successful use in many conscientious studies involving outdoor learning applications, mobile learning systems still have certain limitations. for instance, because students cannot obtain real-time, contextaware content in outdoor locations such as historical sites, endangered animal habitats, and geological landscapes, they are unable to search, collect, share, and edit information by using information technology. to address such concerns, this work proposes an environment of ubiquitous learning with educational resources (euler) based on radio frequency identification (rfid), augmented reality (ar), the internet, ubiquitous computing, embedded systems, and database technologies. euler helps teachers deliver lessons on site and cultivate student competency in adopting information technology to improve learning. to evaluate its effectiveness, we used the proposed euler for natural science learning at the guandu nature park in taiwan. the participants were elementary school teachers and students. the analytical results revealed that the proposed euler improves student learning. moreover, the largely positive feedback from a post-study survey confirms the effectiveness of euler in supporting outdoor learning and its ability to attract the interest of students.",
            "contribution_ids": [
                "R27805"
            ]
        },
        {
            "instance_id": "R28099xR27870",
            "comparison_id": "R28099",
            "paper_id": "R27870",
            "text": "Stereo Processing by Semiglobal Matching and Mutual Information this paper describes the semi-global matching (sgm) stereo method. it uses a pixelwise, mutual information based matching cost for compensating radiometric differences of input images. pixelwise matching is supported by a smoothness constraint that is usually expressed as a global cost function. sgm performs a fast approximation by pathwise optimizations from all directions. the discussion also addresses occlusion detection, subpixel refinement and multi-baseline matching. additionally, postprocessing steps for removing outliers, recovering from specific problems of structured environments and the interpolation of gaps are presented. finally, strategies for processing almost arbitrarily large images and fusion of disparity images using orthographic projection are proposed.a comparison on standard stereo images shows that sgm is among the currently top-ranked algorithms and is best, if subpixel accuracy is considered. the complexity is linear to the number of pixels and disparity range, which results in a runtime of just 1-2s on typical test images. an in depth evaluation of the mutual information based matching cost demonstrates a tolerance against a wide range of radiometric transformations. finally, examples of reconstructions from huge aerial frame and pushbroom images demonstrate that the presented ideas are working well on practical problems.",
            "contribution_ids": [
                "R27871"
            ]
        },
        {
            "instance_id": "R28099xR27876",
            "comparison_id": "R28099",
            "paper_id": "R27876",
            "text": "Stereo matching with color-weighted correlation, hierarchical belief propagation, and occlusion handling in this paper, we formulate an algorithm for the stereo matching problem with careful handling of disparity, discontinuity and occlusion. the algorithm works with a global matching stereo model based on an energy- minimization framework. the global energy contains two terms, the data term and the smoothness term. the data term is first approximated by a color-weighted correlation, then refined in occluded and low-texture areas in a repeated application of a hierarchical loopy belief propagation algorithm. the experimental results are evaluated on the middlebury data set, showing that our algorithm is the top performer.",
            "contribution_ids": [
                "R27877"
            ]
        },
        {
            "instance_id": "R28099xR27896",
            "comparison_id": "R28099",
            "paper_id": "R27896",
            "text": "Real-time disparity estimation algorithm for stereo camera systems this paper proposes a real-time stereo matching algorithm using gpu programming. the likelihood model is implemented using gpu programming for real-time operation. and the prior model is proposed to improve the accuracy of disparity estimation. first, the likelihood matching based on rank transform is implemented in gpu programming. the shared memory handling in graphic hardware is introduced in calculating the likelihood model. the prior model considers the smoothness of disparity map and is defined as a pixel-wise energy function using adaptive interaction among neighboring disparities. the disparity is determined by minimizing the joint energy function which combines the likelihood model with prior model. these processes are performed in the multi-resolution approach. the disparity map is interpolated using the reliability of likelihood model and color-based similarity in the neighborhood. this paper evaluates the proposed approach with the middlebury stereo images. according to the experiments, the proposed algorithm shows good estimation accuracy over 30 frames/second for 640\u00d7480 image and 60 disparity range. the proposed disparity estimation algorithm is applied to real-time stereo camera system such as 3-d image display, depth-based object extraction, 3-d rendering, and so on.",
            "contribution_ids": [
                "R27897"
            ]
        },
        {
            "instance_id": "R28099xR27902",
            "comparison_id": "R28099",
            "paper_id": "R27902",
            "text": "On building an accurate stereo matching system on graphics hardware this paper presents a gpu-based stereo matching system with good performance in both accuracy and speed. the matching cost volume is initialized with an ad-census measure, aggregated in dynamic cross-based regions, and updated in a scanline optimization framework to produce the disparity results. various errors in the disparity results are effectively handled in a multi-step refinement process. each stage of the system is designed with parallelism considerations such that the computations can be accelerated with cuda implementations. experimental results demonstrate the accuracy and the efficiency of the system: currently it is the top performer in the middlebury benchmark, and the results are achieved on gpu within 0.1 seconds. we also provide extra examples on stereo video sequences and discuss the limitations of the system.",
            "contribution_ids": [
                "R27903"
            ]
        },
        {
            "instance_id": "R28099xR27906",
            "comparison_id": "R28099",
            "paper_id": "R27906",
            "text": "A revisit to cost aggregation in stereo matching: How far can we reduce its computational redundancy? this paper presents a novel method for performing an efficient cost aggregation in stereo matching. the cost aggregation problem is re-formulated with a perspective of a histogram, and it gives us a potential to reduce the complexity of the cost aggregation significantly. different from the previous methods which have tried to reduce the complexity in terms of the size of an image and a matching window, our approach focuses on reducing the computational redundancy which exists among the search range, caused by a repeated filtering for all disparity hypotheses. moreover, we also reduce the complexity of the window-based filtering through an efficient sampling scheme inside the matching window. the trade-off between accuracy and complexity is extensively investigated into parameters used in the proposed method. experimental results show that the proposed method provides high-quality disparity maps with low complexity. this work provides new insights into complexity-constrained stereo matching algorithm design.",
            "contribution_ids": [
                "R27907"
            ]
        },
        {
            "instance_id": "R28099xR27960",
            "comparison_id": "R28099",
            "paper_id": "R27960",
            "text": "Efficient Disparity Estimation Using Hierarchical Bilateral Disparity Structure Based Graph Cut Algorithm With a Foreground Boundary Refinement Mechanism the disparity estimation problem is commonly solved using graph cut (gc) methods, in which the disparity assignment problem is transformed to one of minimizing global energy function. although such an approach yields an accurate disparity map, the computational cost is relatively high. accordingly, this paper proposes a hierarchical bilateral disparity structure (hbds) algorithm in which the efficiency of the gc method is improved without any loss in the disparity estimation performance by dividing all the disparity levels within the stereo image hierarchically into a series of bilateral disparity structures of increasing fineness. to address the well-known foreground fattening effect, a disparity refinement process is proposed comprising a fattening foreground region detection procedure followed by a disparity recovery process. the efficiency and accuracy of the hbds-based gc algorithm are compared with those of the conventional gc method using benchmark stereo images selected from the middlebury dataset. in addition, the general applicability of the proposed approach is demonstrated using several real-world stereo images.",
            "contribution_ids": [
                "R27961"
            ]
        },
        {
            "instance_id": "R28099xR27975",
            "comparison_id": "R28099",
            "paper_id": "R27975",
            "text": "Effective stereo matching using reliable points based graph cut in this paper, we propose an effective stereo matching algorithm using reliable points and region-based graph cut. firstly, the initial disparity maps are calculated via local windowbased method. secondly, the unreliable points are detected according to the dsi(disparity space image) and the estimated disparity values of each unreliable point are obtained by considering its surrounding points. then, the scheme of reliable points is introduced in region-based graph cut framework to optimize the initial result. finally, remaining errors in the disparity results are effectively handled in a multi-step refinement process. experiment results show that the proposed algorithm achieves a significant reduction in computation cost and guarantee high matching quality.",
            "contribution_ids": [
                "R27976"
            ]
        },
        {
            "instance_id": "R28099xR27987",
            "comparison_id": "R28099",
            "paper_id": "R27987",
            "text": "Window-based approach for fast stereo correspondence in this study, the authors present a new area-based stereo matching algorithm that computes dense disparity maps for a real-time vision system. although many stereo matching algorithms have been proposed in recent years, correlation-based algorithms still have an edge because of speed and less memory requirements. the selection of appropriate shape and size of the matching window is a difficult problem for correlation-based algorithms. in the proposed approach, two correlation windows are used to improve the performance of the algorithm while maintaining its real-time suitability. the cpu implementation of the proposed algorithm computes more than 10 frame/s. unlike other area-based stereo matching algorithms, this method works very well at disparity boundaries as well as in low textured image areas and computes a dense and sharp disparity map. evaluations on the benchmark middlebury stereo datasets have been performed to demonstrate the qualitative and quantitative performance of the proposed algorithm.",
            "contribution_ids": [
                "R27988"
            ]
        },
        {
            "instance_id": "R28099xR28024",
            "comparison_id": "R28099",
            "paper_id": "R28024",
            "text": "Stereo matching by adaptive weighting selection based cost aggregation cost aggregation is the most essential step for dense stereo correspondence searching, which measures the similarity between pixels in the stereo images. in this paper, based on the analysis of the optimal adaptive weight, we propose a novel support aggregation strategy by adaptive weighting selection. the proposed method calculates the aggregation cost by the joint optimization of both left and right matching cost. by assigning more reasonable weighting coefficients, we exclude the occlusion pixels while preserving sufficient support region for accurate matching. the proposed optimal strategy can be integrated by any other adaptive weighting based cost aggregation method to generate more reasonable similarity measurement. experimental results show that, compare with traditional methods, our algorithm can reduce the foreground fatten phenomenon while increasing the accuracy in the high texture regions.",
            "contribution_ids": [
                "R28025"
            ]
        },
        {
            "instance_id": "R28099xR28041",
            "comparison_id": "R28099",
            "paper_id": "R28041",
            "text": "Real-time high-quality stereo vision system in FPGA stereo vision is a well-known technique for acquiring depth information. in this paper, we propose a real-time high-quality stereo vision system in field-programmable gate array (fpga). using absolute difference-census cost initialization, cross-based cost aggregation, and semiglobal optimization, the system provides high-quality depth results for high-definition images. this is the first complete real-time hardware system that supports both cost aggregation on variable support regions and semiglobal optimization in fpgas. furthermore, the system is designed to be scaled with image resolution, disparity range, and parallelism degree for maximum parallel efficiency. we present the depth map quality on the middlebury benchmark and some real-world scenarios with different image resolutions. the results show that our system performs the best among fpga-based stereo vision systems and its accuracy is comparable with those of current top-performing software implementations. the first version of the system was demonstrated on an altera stratix-iv fpga board, processing 1024 \u00d7 768 pixel images with 96 disparity levels at 67 frames/s. the system is then scaled up on a new altera stratix-v fpga and the processing ability is enhanced to 1600 \u00d7 1200 pixel images with 128 disparity levels at 42 frames/s.",
            "contribution_ids": [
                "R28042"
            ]
        },
        {
            "instance_id": "R28099xR28078",
            "comparison_id": "R28099",
            "paper_id": "R28078",
            "text": "High-speed segmentation-driven high-resolution matching this paper proposes a segmentation-based approach for matching of high-resolution stereo images in real time. the approach employs direct region matching in a raster scan fashion influenced by scanline approaches, but with pixel decoupling. to enable real-time performance it is implemented as a heterogeneous system of an fpga and a sequential processor. additionally, the approach is designed for low resource usage in order to qualify as part of unified image processing in an embedded system.",
            "contribution_ids": [
                "R28079"
            ]
        },
        {
            "instance_id": "R28099xR28097",
            "comparison_id": "R28099",
            "paper_id": "R28097",
            "text": "A fast trilateral filterbased adaptive support weight method for stereo matching adaptive support weight (asw) approach represents the state-of-the-art local stereo matching method. recent extensive evaluation studies on asw approaches show that the bilateral filter weight function enables outstanding performance on a large dataset in comparison with various weight functions. however, it does not resolve the ambiguity induced by nearby pixels at different disparities but with similar colors. in this paper, we propose a novel trilateral filter based asw method which remedies such ambiguities by considering disparity discontinuities through color discontinuity boundaries, i.e., the strength of the boundary between two pixels. the experimental evaluation on the middlebury benchmark shows that the proposed algorithm ranks 15th out of 150 submissions and is the current most accurate local stereo matching algorithm.",
            "contribution_ids": [
                "R28098"
            ]
        },
        {
            "instance_id": "R28099xR28012",
            "comparison_id": "R28099",
            "paper_id": "R28012",
            "text": "A near real-time color stereo matching method for GPU this paper presents a near real-time stereo matching method with acceptable matching results. this method consists of three important steps: sad-ald cost measure, cost aggregation in adaptive window in cross-based support regions and a refinement step. these three steps are well organized to be adopted by the gpu\u2019s parallel architecture. the parallelism brought by gpu and cuda implementations provides significant acceleration in running time. this method is tested on six pairs of images from middlebury dataset, each possibly declined within different sizes. for each pair of images it can generate acceptable matching results in roughly less than 100 milliseconds. the method is also compared with three gpu-based methods and one cpu-based method on increasing size image pairs.",
            "contribution_ids": [
                "R28013"
            ]
        },
        {
            "instance_id": "R28140xR28119",
            "comparison_id": "R28140",
            "paper_id": "R28119",
            "text": "Recurrent duodenal gangliocytic paraganglioma with lymph node metastases \"gangliocytic paraganglioma is a rare tumour which occurs almost exclusively in the second portion of the duodenum',2. histologically, it shows features reminiscent of paraganglioma, ganglioneuroma and carcinoid tumour. the lesion is composed of variable admixtures of three cell types: spindle cells with features of schwann cells, ganglion-like cells and epithelioid cells. gangliocytic paraganglioma is generally considered benign and most cases are cured by simple excision of the tumour mass. metastatic spread to regional lymph nodes has been reported in five cases3-5. no instances of systemic metastatic spread or patient death attributed to the tumour are known. here we report one additional case of duodenal gangliocytic paraganglioma which recurred in the mesentery 11 years following the original excision and also metastasized to the regional lymph nodes.\"",
            "contribution_ids": [
                "R28120"
            ]
        },
        {
            "instance_id": "R28140xR28124",
            "comparison_id": "R28140",
            "paper_id": "R28124",
            "text": "Paraganglioma of the ampulla of vater: a potentially malignant neoplasm paragangliomas are rare tumours originating from neuroectodermic remnants and are usually considered as benign. we present two cases of paraganglioma of the ampulla of vater that were treated surgically by pancreaticoduodenectomy. in one case, histopathology revealed malignant characteristics of the tumour with invasion of the pancreas and simultaneous duodenal lymph\u2010node metastases. both patients had a favourable outcome without disease recurrence at 40 and 44 months postoperatively. only 21 cases of ampullary paraganglioma have been reported in the literature, 7 of them with malignant characteristics. in conclusion, paragangliomas of the ampulla of vater have malignant potential. surgical therapy of these tumours should not be limited to local resection, as disease recurrence and lymph node involvement have been reported. we propose that paragangliomas of the ampulla of vater should be operated by cephalic pancreaticoduodenectomy, which allows long\u2010term and disease\u2010free survival.",
            "contribution_ids": [
                "R28125"
            ]
        },
        {
            "instance_id": "R28191xR28163",
            "comparison_id": "R28191",
            "paper_id": "R28163",
            "text": "Multicommodity network flow model for Asia's container ports \"this paper seeks to develop a multi-commodity network model to analyse the flow of containers within the asia pacific context. the model is used to evaluate the impact of container throughput in asia's port by varying terminal handling charges and turnaround time. the three main regions analysed are north-east asia, east asia (chinese port region) and south east asia. using the model, it could be shown that busan port, which is an important transhipment hub in north-east asia, could boost the container activities in the north-eastern part of china by improving its service quality. it is also found that the efficiency of the land link between hong kong and mainland china plays a crucial role for the future of hong kong port. while singapore port maintains its position as a transhipment hub in south-east asia, there would be expected competition from neighbouring low costs ports.\"",
            "contribution_ids": [
                "R28164"
            ]
        },
        {
            "instance_id": "R28191xR28166",
            "comparison_id": "R28191",
            "paper_id": "R28166",
            "text": "Seasonal slot allocation planning for a container liner shipping service this research addresses a slot allocation planning problem of the container shipping company for satisfying the estimated seasonal demands on a liner service. we explore in detail the influenced factors of planning and construct a quantitative model for the optimum allocation of the ship\u2019s slot spaces. an integer programming model is formulated to maximize the potential profits per round trip voyage for a liner company, and a real life example of an eastern asia short sea service has been studied. analysis results reveal that containers with the higher contributions like reefers and 40 feet dry containers have priorities to be allocated more than others, but not all because of satisfying necessary operational constraints. our model is not only providing a higher space utilization rate and more detailed allocation results, but also helpful for the ship size assessment in long-term planning.",
            "contribution_ids": [
                "R28167"
            ]
        },
        {
            "instance_id": "R28235xR28214",
            "comparison_id": "R28235",
            "paper_id": "R28214",
            "text": "Liner shipping cargo allocation with repositioning of empty containers abstract this paper is concerned with the cargo allocation problem considering empty repositioning of containers for a liner shipping company. the aim is to maximize the profit of transported cargo in a network, subject to the cost and availability of empty containers. the formulation is a multi-commodity flow problem with additional inter-balancing constraints to control repositioning of empty containers. in a study of the cost efficiency of the global container-shipping network, song et al. (2005) estimate that empty repositioning cost constitutes 27% of the total world fleet running cost. an arc-flow formulation is decomposed using the dantzig-wolfe principle to a path-flow formulation. a linear relaxation is solved with a delayed column generation algorithm. a feasible integer solution is found by rounding the fractional solution and adjusting flow balance constraints with leased containers. computational results are reported for seven instances based on real-life shipping networks. solving the relaxed linear path-flow model with a column generation algorithm outperforms solving the relaxed linear arc-flow model with the cplex barrier solver even for very small instances. the proposed algorithm is able to solve instances with 234 ports, 16,278 demands over 9 time periods in 34 min. the integer solutions found by rounding down are computed in less than 5 s and the gap is within 0.01% from the upper bound of the linear relaxation. the solved instances are quite large compared to those tested in the reviewed literature.",
            "contribution_ids": [
                "R28215"
            ]
        },
        {
            "instance_id": "R28333xR28247",
            "comparison_id": "R28333",
            "paper_id": "R28247",
            "text": "Liner shipping service optimisation with reefer containers capacity: an application to northern Europe\u00e2\u0080\u0093South America trade increasing the number of vessels in a container liner service while reducing speeds, known as slow steaming strategy, has been a short-term response since 2008 to the challenges of over-capacity and the rise in bunker prices faced by shipping lines. this strategy, which reduces the fuel cost per voyage but increases the operating costs as more vessels are added to the service, is difficult to sustain when the transit time significantly affects the transportation demand. this article proposes a model applied to this situation, referred to as a case of optimal speed under semi-elastic demand, for which containerised perishable product transport is sensitive to time, while frozen and dry products are not. it investigates if slow steaming is still optimal when working to maximise the total profit on the cycle. in order to demonstrate the proposed model, a numerical application is carried out for a direct northern europe to east coast of south america container service, a route selected due to the high volume of fresh products. for this application, the speed that maximises the total profit with inelastic and semi-elastic demand is then estimated for several bunker fuel prices.",
            "contribution_ids": [
                "R28248"
            ]
        },
        {
            "instance_id": "R28333xR28266",
            "comparison_id": "R28333",
            "paper_id": "R28266",
            "text": "Tactical planning models for managing container flow and ship deployment this paper addresses two practical problems from a liner shipping company, i.e. the container flow management problem and the ship deployment problem, at the tactical planning level. a sequential model and a joint optimisation model are formulated to solve the problems. our results show that the company should implement the joint optimisation model at the tactical planning level to improve the shipping capacity utilisation rather than the sequential model used in the current practice. repositioning empty containers also need to be considered jointly with the nonempty container flow at the tactical planning level. some important managerial insights into the operational and business processes are gained.",
            "contribution_ids": [
                "R28267"
            ]
        },
        {
            "instance_id": "R28333xR28307",
            "comparison_id": "R28333",
            "paper_id": "R28307",
            "text": "Schedule Design and Container Routing in Liner Shipping a liner shipping company seeks to provide liner services with shorter transit time compared with the benchmark of market-level transit time because of the ever-increasing competition. when the itineraries of its liner service routes are determined, the liner shipping company designs the schedules of the liner routes such that the wait time at transshipment ports is minimized. as a result of transshipment, multiple paths are available for delivering containers from the origin port to the destination port. therefore, the medium-term (3 to 6 months) schedule design problem and the operational-level container-routing problem must be investigated simultaneously. the schedule design and container-routing problems were formulated by minimization of the sum of the total transshipment cost and penalty cost associated with longer transit time than the market-level transit time, minus the bonus for shorter transit time. the formulation is nonlinear, noncontinuous, and nonconvex. a genetic local search approach was developed to find good solutions to the problem. the proposed solution method was applied to optimize the asia\u2013europe\u2013oceania liner shipping services of a global liner company.",
            "contribution_ids": [
                "R28308"
            ]
        },
        {
            "instance_id": "R28369xR28344",
            "comparison_id": "R28369",
            "paper_id": "R28344",
            "text": "Designing container shipping network under changing demand and freight rates this paper focuses on the optimization of container shipping network and its operations under changing cargo demand and freight rates. the problem is formulated as a mixed integer non-linear programming problem (minp) with an objective of maximizing the average unit ship-slot profit at three stages using analytical methodology. the issues such as empty container repositioning, ship-slot allocating, ship sizing, and container configuration are simultaneously considered based on a series of the matrices of demand for a year. to solve the model, a bi-level genetic algorithm based method is proposed. finally, numerical experiments are provided to illustrate the validity of the proposed model and algorithms. the obtained results show that the suggested model can provide a more realistic solution to the issues on the basis of changing demand and freight rates and arrange a more effective approach to the optimization of container shipping network structures and operations than does the model based on the average demand.",
            "contribution_ids": [
                "R28345"
            ]
        },
        {
            "instance_id": "R28407xR28372",
            "comparison_id": "R28407",
            "paper_id": "R28372",
            "text": "Ship Scheduling and Network Design for Cargo Routing in Liner Shipping \" acommon problem faced by carriers in liner shipping is the design of their service network. given a set of demands to be transported and a set of ports, a carrier wants to design service routes for its ships as efficiently as possible, using the underlying facilities. furthermore, the profitability of the service routes designed depends on the paths chosen to ship the cargo. we present an integrated model, a mixed-integer linear program, to solve the ship-scheduling and the cargo-routing problems, simultaneously. the proposed model incorporates relevant constraints, such as the weekly frequency constraint on the operated routes, and emerging trends, such as the transshipment of cargo between two or more service routes. to solve the mixed-integer program, we propose algorithms that exploit the separability of the problem. more specifically, a greedy heuristic, a column generation-based algorithm, and a two-phase benders decomposition-based algorithm are developed, and their computational efficiency in terms of the solution quality and the computational time taken is discussed. an efficient iterative search algorithm is proposed to generate schedules for ships. computational experiments are performed on randomly generated instances simulating real life with up to 20 ports and 100 ships. our results indicate high percentage utilization of ships' capacities and a significant number of transshipments in the final solution. \"",
            "contribution_ids": [
                "R28373"
            ]
        },
        {
            "instance_id": "R28407xR28383",
            "comparison_id": "R28407",
            "paper_id": "R28383",
            "text": "A Base Integer Programming Model and Benchmark Suite for Liner-Shipping Network Design the liner-shipping network design problem is to create a set of nonsimple cyclic sailing routes for a designated fleet of container vessels that jointly transports multiple commodities. the objective is to maximize the revenue of cargo transport while minimizing the costs of operation. the potential for making cost-effective and energy-efficient liner-shipping networks using operations research (or) is huge and neglected. the implementation of logistic planning tools based upon or has enhanced performance of airlines, railways, and general transportation companies, but within the field of liner shipping, applications of or are scarce. we believe that access to domain knowledge and data is a barrier for researchers to approach the important liner-shipping network design problem. the purpose of the benchmark suite and the paper at hand is to provide easy access to the domain and the data sources of liner shipping for or researchers in general. we describe and analyze the liner-shipping domain applied to network design and present a rich integer programming model based on services that constitute the fixed schedule of a liner shipping company. we prove the liner-shipping network design problem to be strongly np-hard. a benchmark suite of data instances to reflect the business structure of a global liner shipping network is presented. the design of the benchmark suite is discussed in relation to industry standards, business rules, and mathematical programming. the data are based on real-life data from the largest global liner-shipping company, maersk line, and supplemented by data from several industry and public stakeholders. computational results yielding the first best known solutions for six of the seven benchmark instances is provided using a heuristic combining tabu search and heuristic column generation.",
            "contribution_ids": [
                "R28384"
            ]
        },
        {
            "instance_id": "R28407xR28388",
            "comparison_id": "R28407",
            "paper_id": "R28388",
            "text": "A path based model for a green liner shipping network design problem abstract\u2014liner shipping networks are the backbone ofinternational trade providing low transportation cost, whichis a major driver of globalization. these networks are underconstant pressure to deliver capacity, cost effectiveness and envi-ronmentally conscious transport solutions. this article proposesa new path based mip model for the liner shipping networkdesign problem minimizing the cost of vessels and their fuelconsumption facilitating a green network. the proposed modelreduces problem size using a novel aggregation of demands.a decomposition method enabling delayed column generationis presented. the subproblems have similar structure to ve-hicle routing problems, which can be solved using dynamicprogramming.index terms\u2014liner shipping, network design, mathematicalprogramming, column generation, green logistics i. i ntroduction g lobal liner shipping companies provide port to porttransport of containers, on a network which representsa billion dollar investment in assets and operational costs.the liner shipping network can be viewed as a transporta-tion system for general cargo not unlike an urban mass transitsystem for commuters, where each route (service) providestransportation links between ports and the ports allow fortranshipment in between routes (services). the liner shippingindustry is distinct from other maritime transportation modesprimarily due to a \ufb01xed public schedule with weekly fre-quency of port calls as an industry standard (stopford 1997).the network consists of a set of services. a service connectsa sequence of ports in a cycle at a given frequency, usuallyweekly. in figure 1 a service connecting montreal-halifaxand europe is illustrated. the weekly frequency means thatseveral vessels are committed to the service as illustrated byfigure 1, where four vessels cover a round trip of 28 daysplaced with one week in between vessels. this roundtrip forthe vessel is referred to as a rotation. note that the montrealservice carries cargo to the mediterranean and asia. thisillustrates that transhipments to other connecting servicesis at the core of liner shipping. therefore, the design of aservice is complex, as the set of rotations and their interactionthrough transhipment is a transportation system extending thesupply chains of a multiplum of businesses. figure 2 illus-trates two services interacting in transporting goods betweenmontreal-halifax and the mediterranean, while individually",
            "contribution_ids": [
                "R28389"
            ]
        },
        {
            "instance_id": "R28487xR28464",
            "comparison_id": "R28487",
            "paper_id": "R28464",
            "text": "A Containerized Liner Routing in Eastern Asia new partnerships has been made in containerized liner services. this likely results in drastic changes in ship size and hub location in eastern asia. in this study we address strategies of the containerized liner services by using a mathematical programming with two objectives of shipping company and customer.",
            "contribution_ids": [
                "R28465"
            ]
        },
        {
            "instance_id": "R28614xR28532",
            "comparison_id": "R28614",
            "paper_id": "R28532",
            "text": "A Case of Primary Undifferentiated Sarcoma of the Liver: Diagnosed by Peritoneoscopy and Guided Biopsy the authors report a case of primary undifferentiated sarcoma of the liver, observed in a 36-year-old man. diagnosis was established at peritoneoscopy and guided biopsy, and confirmed by autopsy two months later.",
            "contribution_ids": [
                "R28533"
            ]
        },
        {
            "instance_id": "R28614xR28544",
            "comparison_id": "R28614",
            "paper_id": "R28544",
            "text": "Primary sarcoma of the liver in the adult primary undifferentiated saroma of the liver is a rare tumor, being documented primarily in the pediatric age group. this report describes the occurrence of such a tumor in a 55\u2010year\u2010old white woman with meyenburg\u2010s complexes of the liver and the crst syndrome. the clinicopathologic features of the tumor in the adult are characterized and the literature is reviewed.",
            "contribution_ids": [
                "R28545"
            ]
        },
        {
            "instance_id": "R28614xR28569",
            "comparison_id": "R28614",
            "paper_id": "R28569",
            "text": "Undifferentiated (embryonal) sarcoma of the liver: Pathologic findings and long-term survival after complete surgical resection undifferentiated (embryonal) sarcoma of liver is a rare tumor with a reputed poor prognosis. four patients with this tumor are reported, of whom three were alive without recurrence 1.5, 2.5, and 12 years after initial complete surgical resection, and two of whom received no adjuvant therapy. the fourth patient, in whom complete surgical resection of tumor was not achieved, died with recurrent tumor at 13 months. the latter tumor differed histologically and consisted mainly of closely packed smaller undifferentiated cells with a higher mitotic and apoptotic rate. eosinophilic globules, characteristic of embryonal sarcoma, were found in some cases to contain condensed nuclear chromatin, evidence of origin from tumor cells dying by apoptosis. one tumor mainly contained large cysts lined by biliary\u2010type epithelium; this suggested an origin from a multipotent precursor cell able to differentiate along both stromal and epithelial lines.",
            "contribution_ids": [
                "R28570",
                "R28571"
            ]
        },
        {
            "instance_id": "R28614xR28572",
            "comparison_id": "R28614",
            "paper_id": "R28572",
            "text": "Primary Gastrointestinal Sarcomas \u00e2\u0080\u0093 A Report of 21 Cases twenty-one patients with primary gastrointestinal sarcomas underwent surgery at the university clinics of hamburg from 1970 to 1990. main symptoms were gastrointestinal bleeding and abdominal pain. al",
            "contribution_ids": [
                "R28573"
            ]
        },
        {
            "instance_id": "R28614xR28583",
            "comparison_id": "R28614",
            "paper_id": "R28583",
            "text": "Hepatic Undifferentiated (Embryonal) Sarcoma Arising in a Mesenchymal Hamartoma we report the case of a hepatic undifferentiated (embryonal) sarcoma (ues) arising within a mesenchymal hamartoma (mh) in a 15-year-old girl. mapping of the tumor demonstrated a typical mh transforming gradually into a ues composed of anaplastic stromal cells. when evaluated by flow cytometry, the mh was diploid and the ues showed a prominent aneuploid peak. karyotypic analysis of the ues showed structural alterations of chromosome 19, which have been implicated as a potential genetic marker of mh. the histogenesis of mh and ues is still debated, and reports of a relationship between them, although suggested on the basis of histomorphologic similarities, have never been convincing. the histologic, flow cytometric, and cytogenetic evidence reported herein suggests a link between these two hepatic tumors of the pediatric population.",
            "contribution_ids": [
                "R28584"
            ]
        },
        {
            "instance_id": "R28614xR28593",
            "comparison_id": "R28614",
            "paper_id": "R28593",
            "text": "Undifferentiated (embryonal) sarcoma of the liver in middle-aged adults: Smooth muscle differentiation determined by immunohistochemistry and electron microscopy undifferentiated (embryonal) sarcoma of the liver (uesl) is a rare pediatric liver malignancy that is extremely uncommon in middle-aged individuals. we studied 2 cases of uesl in middle-aged adults (1 case in a 49-year-old woman and the other in a 62-year-old man) by histology, immunohistochemistry, and electron microscopy to clarify the cellular characteristics of this peculiar tumor. one tumor showed a mixture of spindle cells, polygonal cells, and multinucleated giant cells within a myxoid matrix and also revealed focal areas of a storiform pattern in a metastatic lesion. the other tumor was composed mainly of anaplastic large cells admixed with few fibrous or spindle-shaped components and many multinucleated giant cells. in both cases, some tumor cells contained eosinophilic hyaline globules that were diastase resistant and periodic acid-schiff positive. immunohistochemically, the tumor cells showed positive staining for smooth muscle markers, such as desmin, alpha-smooth muscle actin, and muscle-specific actin, and also for histiocytic markers, such as alpha-1-antitrypsin, alpha-1-antichymotrypsin, and cd68. electron microscope examination revealed thin myofilaments with focal densities and intermediate filaments in the cytoplasm of tumor cells. our studies suggest that uesl exhibits at least a partial smooth muscle phenotype in middle-aged adults, and this specific differentiation may be more common in this age group than in children. tumor cells of uesl with smooth muscle differentiation in middle-aged adults show phenotypic diversity comparable to those of malignant fibrous histiocytoma with myofibroblastic differentiation.",
            "contribution_ids": [
                "R28594",
                "R28595"
            ]
        },
        {
            "instance_id": "R28614xR28599",
            "comparison_id": "R28614",
            "paper_id": "R28599",
            "text": "Undifferentiated (embryonal) sarcoma of liver in adult: a case report we report a case of undifferentiated (embryonal) sarcoma of the liver (uesl), which showed cystic formation in a 20-year-old man with no prior history of any hepatitis or liver cirrhosis. he was admitted with abdominal pain and a palpable epigastric mass. the physical examination findings were unremarkable except for a tenderness mass and the results of routine laboratory studies were all within normal limits. abdominal ultrasound and computed tomography (ct) both showed a cystic mass in the left hepatic lobe. subsequently, the patient underwent a tumor excision and another two times of hepatectomy because of tumor recurrence. immunohistochemical study results showed that the tumor cells were positive for vimentin, alpha-1-antichymotrypsin (aact) and desmin staining, and negative for alpha-fetoprotein (afp), and eosinophilic hyaline globules in the cytoplasm of some giant cells were strongly positive for periodic acid-schiff (pas) staining. the pathological diagnosis was uesl. the patient is still alive with no tumor recurrence for four months.",
            "contribution_ids": [
                "R28600"
            ]
        },
        {
            "instance_id": "R28889xR28629",
            "comparison_id": "R28889",
            "paper_id": "R28629",
            "text": "Today/Future Importance Analysis sbse techniques have been widely applied to requirements selection and prioritization problems in order to ascertain a suitable set of requirements for the next release of a system. unfortunately, it has been widely observed that requirements tend to be changed as the development process proceeds and what is suitable for today, may not serve well into the future. though sbse has been widely applied to requirements analysis, there has been no previous work that seeks to balance the requirements needs of today with those of the future. this paper addresses this problem. it introduces a multi-objective formulation of the problem which is implemented using multi-objective pareto optimal evolutionary algorithms. the paper presents the results of experiments on both synthetic and real world data.",
            "contribution_ids": [
                "R28630",
                "R28777"
            ]
        },
        {
            "instance_id": "R28889xR28633",
            "comparison_id": "R28889",
            "paper_id": "R28633",
            "text": "A Multiobjective Optimization Approach to the Software Release Planning with Undefined Number of Releases and Interdependent Requirements release planning is an important and complex activity in software development. it involves several aspects related to which functionalities are going to be developed in each release of the system. consistent planning must meet the customers\u2019 needs and comply with existing constraints. optimization techniques have been successfully applied to solve problems in the software engineering field, including the software release planning problem. in this context, this work presents an approach based on multiobjective optimization for the problem when the number of releases is not known a priori or when the number of releases is a value expected by stakeholders. the strategy regards on the stakeholders\u2019 satisfaction, business value and risk management, as well as provides ways for handling requirements interdependencies. experiments show the feasibility of the proposed approach.",
            "contribution_ids": [
                "R28634",
                "R28779"
            ]
        },
        {
            "instance_id": "R28889xR28641",
            "comparison_id": "R28889",
            "paper_id": "R28641",
            "text": "Understanding Clusters of Optimal Solutions in Multi-Objective Decision Problems multi-objective decisions problems are ubiquitous in requirements engineering. a common approach to solve them is to apply search-based techniques to generate a set of non-dominated solutions, formally known as the pareto front, that characterizes all solutions for which no other solution performs better on all objectives simultaneously. analysing the shape of the pareto front helps decision makers understand the solution space and possible tradeoffs among the conflicting objectives. interpreting the optimal solutions, however, remains a significant challenge. it is in particular difficult to identify whether solutions that have similar levels of goals attainment correspond to minor variants within a same design or to very different designs involving completely different sets of decisions. our goal is to help decision makers identify groups of strongly related solutions in a pareto front so that they can understand more easily the range of design choices, identify areas where strongly different solutions achieve similar levels of objectives, and decide first between major groups of solutions before deciding for a particular variant within the chosen group. the benefits of the approach are illustrated on a small example and validated on a larger independently-produced example representative of industrial problems.",
            "contribution_ids": [
                "R28642",
                "R28781"
            ]
        },
        {
            "instance_id": "R28889xR28801",
            "comparison_id": "R28889",
            "paper_id": "R28801",
            "text": "Generating Software Architecture Spectrum with Multi-Objective Genetic Algorithms a possible approach to partly automated software architecture design is the application of heuristic search methods like genetic algorithms. however, traditional genetic algorithms use a single fitness function with weighted terms for different quality attributes. this is inadequate for software architecture design that has to satisfy multiple incomparable quality requirements simultaneously. to overcome this problem, the use of pareto optimality is proposed. this technique is studied in the presence of two central quality attributes of software architectures, modifiability and efficiency. the technique produces a spectrum of architecture proposals, ranging from highly modifiable (and less efficient) to highly efficient (and less modifiable). the technique has been implemented and evaluated using an example system. the results demonstrate that pareto optimality has potential for producing a sensible set of architectures in the efficiency-modifiability space.",
            "contribution_ids": [
                "R28802"
            ]
        },
        {
            "instance_id": "R28889xR28805",
            "comparison_id": "R28889",
            "paper_id": "R28805",
            "text": "Software Module Clustering as a Multi-Objective Search Problem software module clustering is the problem of automatically organizing software units into modules to improve program structure. there has been a great deal of recent interest in search-based formulations of this problem in which module boundaries are identified by automated search, guided by a fitness function that captures the twin objectives of high cohesion and low coupling in a single-objective fitness function. this paper introduces two novel multi-objective formulations of the software module clustering problem, in which several different objectives (including cohesion and coupling) are represented separately. in order to evaluate the effectiveness of the multi-objective approach, a set of experiments was performed on 17 real-world module clustering problems. the results of this empirical study provide strong evidence to support the claim that the multi-objective approach produces significantly better solutions than the existing single-objective approach.",
            "contribution_ids": [
                "R28806"
            ]
        },
        {
            "instance_id": "R28889xR28812",
            "comparison_id": "R28889",
            "paper_id": "R28812",
            "text": "Multi- objective Coevolutionary Automated Software Correction \"for a given program, testing, locating the errors identified, and correcting those errors is a critical, yet expensive process. the field of search based software engineering (sbse) addresses these phases by formulating them as search problems. the coevolutionary automated software correction (casc) system targets the correction phase by coevolving test cases and programs at the source code level. this paper presents the latest version of the casc system featuring multi-objective optimization and an enhanced representation language. results are presented demonstrating casc's ability to successfully correct five seeded bugs in two non-trivial programs from the siemens test suite. additionally, evidence is provided substantiating the hypothesis that multi-objective optimization is beneficial to sbse.\"",
            "contribution_ids": [
                "R28813"
            ]
        },
        {
            "instance_id": "R28889xR28817",
            "comparison_id": "R28889",
            "paper_id": "R28817",
            "text": "Search-based Genetic Optimization for Deployment and Reconfiguration of Software in the Cloud migrating existing enterprise software to cloud platforms involves the comparison of competing cloud deployment options (cdos). a cdo comprises a combination of a specific cloud environment, deployment architecture, and runtime reconfiguration rules for dynamic resource scaling. our simulator cdosim can evaluate cdos, e.g., regarding response times and costs. however, the design space to be searched for well-suited solutions is extremely huge. in this paper, we approach this optimization problem with the novel genetic algorithm cdoxplorer. it uses techniques of the search-based software engineering field and cdosim to assess the fitness of cdos. an experimental evaluation that employs, among others, the cloud environments amazon ec2 and microsoft windows azure, shows that cdoxplorer can find solutions that surpass those of other state-of-the-art techniques by up to 60%. our experiment code and data and an implementation of cdoxplorer are available as open source software.",
            "contribution_ids": [
                "R28818"
            ]
        },
        {
            "instance_id": "R28889xR28820",
            "comparison_id": "R28889",
            "paper_id": "R28820",
            "text": "Pareto efficient multi-objective test case selection previous work has treated test case selection as a single objective optimisation problem. this paper introduces the concept of pareto efficiency to test case selection. the pareto efficient approach takes multiple objectives such as code coverage, past fault-detection history and execution cost, and constructs a group of non-dominating, equivalently optimal test case subsets. the paper describes the potential bene?ts of pareto efficient multi-objective test case selection, illustrating with empirical studies of two and three objective formulations.",
            "contribution_ids": [
                "R28821"
            ]
        },
        {
            "instance_id": "R28889xR28823",
            "comparison_id": "R28889",
            "paper_id": "R28823",
            "text": "A Multi-Objective Approach to Search-based Test Data Generation there has been a considerable body of work on search-based test data generation for branch coverage. however, hitherto, there has been no work on multi-objective branch coverage. in many scenarios a single-objective formulation is unrealistic; testers will want to find test sets that meet several objectives simultaneously in order to maximize the value obtained from the inherently expensive process of running the test cases and examining the output they produce. this paper introduces multi-objective branch coverage.the paper presents results from a case study of the twin objectives of branch coverage and dynamic memory consumption for both real and synthetic programs. several multi-objective evolutionary algorithms are applied. the results show that multi-objective evolutionary algorithms are suitable for this problem, and illustrates the way in which a pareto optimal search can yield insights into the trade-offs between the two simultaneous objectives.",
            "contribution_ids": [
                "R28824"
            ]
        },
        {
            "instance_id": "R28889xR28833",
            "comparison_id": "R28889",
            "paper_id": "R28833",
            "text": "A Multi-Objective Genetic Algorithm to Test Data Generation evolutionary testing has successfully applied search based optimization algorithms to the test data generation problem. the existing works use different techniques and fitness functions. however, the used functions consider only one objective, which is, in general, related to the coverage of a testing criterion. but, in practice, there are many factors that can influence the generation of test data, such as memory consumption, execution time, revealed faults, and etc. considering this fact, this work explores a ultiobjective optimization approach for test data generation. a framework that implements a multi-objective genetic algorithm is described. two different representations for the population are used, which allows the test of procedural and object-oriented code. combinations of three objectives are experimentally evaluated: coverage of structural test criteria, ability to reveal faults, and execution time.",
            "contribution_ids": [
                "R28834"
            ]
        },
        {
            "instance_id": "R28889xR28851",
            "comparison_id": "R28889",
            "paper_id": "R28851",
            "text": "Establishing Integration Test Orders of Classes with Several Coupling Measures during the inter-class test, a common problem, named class integration and test order (cito) problem, involves the determination of a test class order that minimizes stub creation effort, and consequently test costs. the approach based on multi-objective evolutionary algorithms (moeas) has achieved promising results because it allows the use of different factors and measures that can affect the stubbing process. many times these factors are in conflict and usually there is no a single solution for the problem. existing works on moeas present some limitations. the approach was evaluated with only two coupling measures, based on the number of attributes and methods of the stubs to be created. other moeas can be explored and also other coupling measures. considering this fact, this paper investigates the performance of two evolutionary algorithms: nsga-ii and spea2, for the cito problem with four coupling measures (objectives) related to: attributes, methods, number of distinct return types and distinct parameter types. an experimental study was performed with four real systems developed in java. the obtained results point out that the moeas can be efficiently used to solve this problem with several objectives, achieving solutions with balanced compromise between the measures, and of minimal effort to test.",
            "contribution_ids": [
                "R28852"
            ]
        },
        {
            "instance_id": "R28889xR28880",
            "comparison_id": "R28889",
            "paper_id": "R28880",
            "text": "Single and Multi Objective Genetic Programming for Software Development Effort Estimation the idea of exploiting genetic programming (gp) to estimate software development effort is based on the observation that the effort estimation problem can be formulated as an optimization problem. indeed, among the possible models, we have to identify the one providing the most accurate estimates. to this end a suitable measure to evaluate and compare different models is needed. however, in the context of effort estimation there does not exist a unique measure that allows us to compare different models but several different criteria (e.g., mmre, pred(25), mdmre) have been proposed. aiming at getting an insight on the effects of using different measures as fitness function, in this paper we analyzed the performance of gp using each of the five most used evaluation criteria. moreover, we designed a multi-objective genetic programming (mogp) based on pareto optimality to simultaneously optimize the five evaluation measures and analyzed whether mogp is able to build estimation models more accurate than those obtained using gp. the results of the empirical analysis, carried out using three publicly available datasets, showed that the choice of the fitness function significantly affects the estimation accuracy of the models built with gp and the use of some fitness functions allowed gp to get estimation accuracy comparable with the ones provided by mogp.",
            "contribution_ids": [
                "R28881"
            ]
        },
        {
            "instance_id": "R28889xR28887",
            "comparison_id": "R28889",
            "paper_id": "R28887",
            "text": "The human competitiveness of search based software engineering this paper reports a comprehensive experimental study regarding the human competitiveness of search based software engineering (sbse). the experiments were performed over four well-known sbse problem formulations: next release problem, multi-objective next release problem, workgroup formation problem and the multi-objective test case selection problem. for each of these problems, two instances, with increasing sizes, were synthetically generated and solved by both metaheuristics and human subjects. a total of 63 professional software engineers participated in the experiment by solving some or all problem instances, producing together 128 responses. the comparison analysis strongly suggests that the results generated by search based software engineering can be said to be human competitive.",
            "contribution_ids": [
                "R28888"
            ]
        },
        {
            "instance_id": "R29012xR28984",
            "comparison_id": "R29012",
            "paper_id": "R28984",
            "text": "From few to many: illumination cone models for face recognition under variable lighting and pose we present a generative appearance-based method for recognizing human faces under variation in lighting and viewpoint. our method exploits the fact that the set of images of an object in fixed pose, but under all possible illumination conditions, is a convex cone in the space of images. using a small number of training images of each face taken with different lighting directions, the shape and albedo of the face can be reconstructed. in turn, this reconstruction serves as a generative model that can be used to render (or synthesize) images of the face under novel poses and illumination conditions. the pose space is then sampled and, for each pose, the corresponding illumination cone is approximated by a low-dimensional linear subspace whose basis vectors are estimated using the generative model. our recognition algorithm assigns to a test image the identity of the closest approximated illumination cone. test results show that the method performs almost without error, except on the most extreme lighting directions.",
            "contribution_ids": [
                "R28985"
            ]
        },
        {
            "instance_id": "R29012xR28996",
            "comparison_id": "R29012",
            "paper_id": "R28996",
            "text": "A high-resolution 3D dynamic facial expression database face information processing relies on the quality of data resource. from the data modality point of view, a face database can be 2d or 3d, and static or dynamic. from the task point of view, the data can be used for research of computer based automatic face recognition, face expression recognition, face detection, or cognitive and psychological investigation. with the advancement of 3d imaging technologies, 3d dynamic facial sequences (called 4d data) have been used for face information analysis. in this paper, we focus on the modality of 3d dynamic data for the task of facial expression recognition. we present a newly created high-resolution 3d dynamic facial expression database, which is made available to the scientific research community. the database contains 606 3d facial expression sequences captured from 101 subjects of various ethnic backgrounds. the database has been validated through our facial expression recognition experiment using an hmm based 3d spatio-temporal facial descriptor. it is expected that such a database shall be used to facilitate the facial expression analysis from a static 3d space to a dynamic 3d space, with a goal of scrutinizing facial behavior at a higher level of detail in a real 3d spatio-temporal domain.",
            "contribution_ids": [
                "R28997",
                "R29084"
            ]
        },
        {
            "instance_id": "R29012xR28998",
            "comparison_id": "R29012",
            "paper_id": "R28998",
            "text": "Annotated facial landmarks in the wild: A large-scale, real- world database for facial landmark localization face alignment is a crucial step in face recognition tasks. especially, using landmark localization for geometric face normalization has shown to be very effective, clearly improving the recognition results. however, no adequate databases exist that provide a sufficient number of annotated facial landmarks. the databases are either limited to frontal views, provide only a small number of annotated images or have been acquired under controlled conditions. hence, we introduce a novel database overcoming these limitations: annotated facial landmarks in the wild (aflw). aflw provides a large-scale collection of images gathered from flickr, exhibiting a large variety in face appearance (e.g., pose, expression, ethnicity, age, gender) as well as general imaging and environmental conditions. in total 25,993 faces in 21,997 real-world images are annotated with up to 21 landmarks per image. due to the comprehensive set of annotations aflw is well suited to train and test algorithms for multi-view face detection, facial landmark localization and face pose estimation. further, we offer a rich set of tools that ease the integration of other face databases and associated annotations into our joint framework.",
            "contribution_ids": [
                "R28999",
                "R29107"
            ]
        },
        {
            "instance_id": "R29012xR29008",
            "comparison_id": "R29012",
            "paper_id": "R29008",
            "text": "The First Facial Landmark Tracking in-the-Wild Challenge: Benchmark and Results \"detection and tracking of faces in image sequences is among the most well studied problems in the intersection of statistical machine learning and computer vision. often, tracking and detection methodologies use a rigid representation to describe the facial region 1, hence they can neither capture nor exploit the non-rigid facial deformations, which are crucial for countless of applications (e.g., facial expression analysis, facial motion capture, high-performance face recognition etc.). usually, the non-rigid deformations are captured by locating and tracking the position of a set of fiducial facial landmarks (e.g., eyes, nose, mouth etc.). recently, we witnessed a burst of research in automatic facial landmark localisation in static imagery. this is partly attributed to the availability of large amount of annotated data, many of which have been provided by the first facial landmark localisation challenge (also known as 300-w challenge). even though now well established benchmarks exist for facial landmark localisation in static imagery, to the best of our knowledge, there is no established benchmark for assessing the performance of facial landmark tracking methodologies, containing an adequate number of annotated face videos. in conjunction with iccv'2015 we run the first competition/challenge on facial landmark tracking in long-term videos. in this paper, we present the first benchmark for long-term facial landmark tracking, containing currently over 110 annotated videos, and we summarise the results of the competition.\"",
            "contribution_ids": [
                "R29009"
            ]
        },
        {
            "instance_id": "R29034xR29021",
            "comparison_id": "R29034",
            "paper_id": "R29021",
            "text": "Face alignment by coarse-to-fine shape searching we present a novel face alignment framework based on coarse-to-fine shape searching. unlike the conventional cascaded regression approaches that start with an initial shape and refine the shape in a cascaded manner, our approach begins with a coarse search over a shape space that contains diverse shapes, and employs the coarse solution to constrain subsequent finer search of shapes. the unique stage-by-stage progressive and adaptive search i) prevents the final solution from being trapped in local optima due to poor initialisation, a common problem encountered by cascaded regression approaches; and ii) improves the robustness in coping with large pose variations. the framework demonstrates real-time performance and state-of-the-art results on various benchmarks including the challenging 300-w dataset.",
            "contribution_ids": [
                "R29022"
            ]
        },
        {
            "instance_id": "R29034xR29030",
            "comparison_id": "R29034",
            "paper_id": "R29030",
            "text": "One millisecond face alignment with an ensemble of regression trees \"this paper addresses the problem of face alignment for a single image. we show how an ensemble of regression trees can be used to estimate the face's landmark positions directly from a sparse subset of pixel intensities, achieving super-realtime performance with high quality predictions. we present a general framework based on gradient boosting for learning an ensemble of regression trees that optimizes the sum of square error loss and naturally handles missing or partially labelled data. we show how using appropriate priors exploiting the structure of image data helps with efficient feature selection. different regularization strategies and its importance to combat overfitting are also investigated. in addition, we analyse the effect of the quantity of training data on the accuracy of the predictions and explore the effect of data augmentation using synthesized data.\"",
            "contribution_ids": [
                "R29031",
                "R29065"
            ]
        },
        {
            "instance_id": "R29080xR29042",
            "comparison_id": "R29080",
            "paper_id": "R29042",
            "text": "Optimization Problems for Fast AAM Fitting in-the-Wild we describe a very simple framework for deriving the most-well known optimization problems in active appearance models (aams), and most importantly for providing efficient solutions. our formulation results in two optimization problems for fast and exact aam fitting, and one new algorithm which has the important advantage of being applicable to 3d. we show that the dominant cost for both forward and inverse algorithms is a few times mn which is the cost of projecting an image onto the appearance subspace. this makes both algorithms not only computationally realizable but also very attractive speed-wise for most current systems. because exact aam fitting is no longer computationally prohibitive, we trained aams in-the-wild with the goal of investigating whether aams benefit from such a training process. our results show that although we did not use sophisticated shape priors, robust features or robust norms for improving performance, aams perform notably well and in some cases comparably with current state-of-the-art methods. we provide matlab source code for training, fitting and reproducing the results presented in this paper at http://ibug.doc.ic.ac.uk/resources.",
            "contribution_ids": [
                "R29043"
            ]
        },
        {
            "instance_id": "R29080xR29050",
            "comparison_id": "R29080",
            "paper_id": "R29050",
            "text": "Detector of facial landmarks learned by the structured output SVM in this paper we describe a detector of facial landmarks based on the deformable part models. we treat the task of landmark detection as an instance of the structured output classification problem. we propose to learn the parameters of the detector from data by the structured output support vector machines algorithm. in contrast to the previous works, the objective function of the learning algorithm is directly related to the performance of the resulting detector which is controlled by a user-defined loss function. the resulting detector is real-time on a standard pc, simple to implement and it can be easily modified for detection of a different set of landmarks. we evaluate performance of the proposed landmark detector on a challenging \u201clabeled faces in the wild\u201d (lfw) database. the empirical results demonstrate that the proposed detector is consistently more accurate than two public domain implementations based on the active appearance models and the deformable part models. we provide an open-source implementation of the proposed detector and the manual annotation of the facial landmarks for all images in the lfw database.",
            "contribution_ids": [
                "R29051"
            ]
        },
        {
            "instance_id": "R29080xR29069",
            "comparison_id": "R29080",
            "paper_id": "R29069",
            "text": "Incremental Face Alignment in the Wild \"the development of facial databases with an abundance of annotated facial data captured under unconstrained 'in-the-wild' conditions have made discriminative facial deformable models the de facto choice for generic facial landmark localization. even though very good performance for the facial landmark localization has been shown by many recently proposed discriminative techniques, when it comes to the applications that require excellent accuracy, such as facial behaviour analysis and facial motion capture, the semi-automatic person-specific or even tedious manual tracking is still the preferred choice. one way to construct a person-specific model automatically is through incremental updating of the generic model. this paper deals with the problem of updating a discriminative facial deformable model, a problem that has not been thoroughly studied in the literature. in particular, we study for the first time, to the best of our knowledge, the strategies to update a discriminative model that is trained by a cascade of regressors. we propose very efficient strategies to update the model and we show that is possible to automatically construct robust discriminative person and imaging condition specific models 'in-the-wild' that outperform state-of-the-art generic face alignment strategies.\"",
            "contribution_ids": [
                "R29070"
            ]
        },
        {
            "instance_id": "R29153xR29114",
            "comparison_id": "R29153",
            "paper_id": "R29114",
            "text": "Enterprise Resource Planning Systems Research: An Annotated Bibliography despite growing interest, publications on erp systems within the academic information systems community, as reflected by contributions to journals and international conferences, is only now emerging. this article provides an annotated bibliography of the erp publications published in the main information systems journals and conferences and reviews the state of the erp art. the publications surveyed are categorized through a framework that is structured in phases that correspond to the different stages of an erp system lifecycle within an organization. we also present topics for further research in each phase. .",
            "contribution_ids": [
                "R29115"
            ]
        },
        {
            "instance_id": "R29153xR29123",
            "comparison_id": "R29153",
            "paper_id": "R29123",
            "text": "The emergence of enterprise systems management: a challenge to the IS curriculum this paper proposes four cornerstones of a future information systems (is) curriculum. it analyses the challenges of the is curriculum based on the development of enterprise systems, and further argues that the practice and the research into enterprise systems have progressed to a new stage resulting in the emergence of enterprise systems management (esm). esm calls for new competences and consequently represents new challenges to the is curriculum. the paper outlines potential teaching issues and discusses the impact on the is curriculum. finally the paper suggests ways of approaching the challenges.",
            "contribution_ids": [
                "R29124"
            ]
        },
        {
            "instance_id": "R29153xR29151",
            "comparison_id": "R29153",
            "paper_id": "R29151",
            "text": "Sustaining the Momentum: Archival Analysis of Enterprise Resource Planning Systems (2006\u00e2\u0080\u00932012) here",
            "contribution_ids": [
                "R29152"
            ]
        },
        {
            "instance_id": "R29153xR29133",
            "comparison_id": "R29153",
            "paper_id": "R29133",
            "text": "Enterprise resource planning research: where are we now and where should we go from here? abstract the research related to enterprise resource planning (erp) has grown over the past several years. this growing body of erp research results in an increased need to review this extant literature with the intent of identifying gaps and thus motivate researchers to close this breach. therefore, this research was intended to critique, synthesize and analyze both the content (e.g., topics, focus) and processes (i.e., methods) of the erp literature, and then enumerates and discusses an agenda for future research efforts. to accomplish this, we analyzed 49 erp articles published (1999-2004) in top information systems (is) and operations management (om) journals. we found an increasing level of activity during the 5-year period and a slightly biased distribution of erp articles targeted at is journals compared to om. we also found several research methods either underrepresented or absent from the pool of erp research. we identified several areas of need within the erp literature, none more prevalent than the need to analyze erp within the context of the supply chain. introduction davenport (1998) described the strengths and weaknesses of using enterprise resource planning (erp). he called attention to the growth of vendors like sap, baan, oracle, and people-soft, and defined this software as, \"...the seamless integration of all the information flowing through a companyfinancial and accounting information, human resource information, supply chain information, and customer information.\" (davenport, 1998). since the time of that article, there has been a growing interest among researchers and practitioners in how organization implement and use erp systems (amoako-gyampah and salam, 2004; bendoly and jacobs, 2004; gattiker and goodhue, 2004; lander, purvis, mccray and leigh, 2004; luo and strong, 2004; somers and nelson, 2004; zoryk-schalla, fransoo and de kok, 2004). this interest is a natural continuation of trends in information technology (it), such as mrp ii, (olson, 2004; teltumbde, 2000; toh and harding, 1999) and in business practice improvement research, such as continuous process improvement and business process reengineering (markus and tanis, 2000; ng, ip and lee, 1999; reijers, limam and van der aalst, 2003; toh and harding, 1999). this growing body of erp research results in an increased need to review this extant literature with the intent of \"identifying critical knowledge gaps and thus motivate researchers to close this breach\" (webster and watson, 2002). also, as noted by scandura & williams (2000), in order for research to advance, the methods used by researchers must periodically be evaluated to provide insights into the methods utilized and thus the areas of need. these two interrelated needs provide the motivation for this paper. in essence, this research critiques, synthesizes and analyzes both the content (e.g., topics, focus) and processes (i.e., methods) of the erp literature and then enumerates and discusses an agenda for future research efforts. the remainder of the paper is organized as follows: section 2 describes the approach to the analysis of the erp research. section 3 contains the results and a review of the literature. section 4 discusses our findings and the needs relative to future erp research efforts. finally, section 5 summarizes the research. research study we captured the trends pertaining to (1) the number and distribution of erp articles published in the leading journals, (2) methodologies employed in erp research, and (3) emphasis relative to topic of erp research. during the analysis of the erp literature, we identified gaps and needs in the research and therefore enumerate and discuss a research agenda which allows the progression of research (webster and watson, 2002). in short, we sought to paint a representative landscape of the current erp literature base in order to influence the direction of future research efforts relative to erp. \u2026",
            "contribution_ids": [
                "R29134"
            ]
        },
        {
            "instance_id": "R29184xR29156",
            "comparison_id": "R29184",
            "paper_id": "R29156",
            "text": "Process orientation through enterprise resource planning (ERP): a review of critical issues the significant development in global information technologies and the ever-intensifying competitive market climate have both pushed many companies to transform their businesses. enterprise resource planning (erp) is seen as one of the most recently emerging process-orientation tools that can enable such a transformation. its development has presented both researchers and practitioners with new challenges and opportunities. this paper provides a comprehensive review of the state of research in the erp field relating to process management, organizational change and knowledge management. it surveys current practices, research and development, and suggests several directions for future investigation. copyright \u00a9 2001 john wiley & sons, ltd.",
            "contribution_ids": [
                "R29157"
            ]
        },
        {
            "instance_id": "R29184xR29161",
            "comparison_id": "R29184",
            "paper_id": "R29161",
            "text": "Enterprise resource planning (ERP) systems: a research agenda the continuing development of enterprise resource planning (erp) systems has been considered by many researchers and practitioners as one of the major it innovations in this decade. erp solutions seek to integrate and streamline business processes and their associated information and work flows. what makes this technology more appealing to organizations is increasing capability to integrate with the most advanced electronic and mobile commerce technologies. however, as is the case with any new it field, research in the erp area is still lacking and the gap in the erp literature is huge. attempts to fill this gap by proposing a novel taxonomy for erp research. also presents the current status with some major themes of erp research relating to erp adoption, technical aspects of erp and erp in is curricula. the discussion presented on these issues should be of value to researchers and practitioners. future research work will continue to survey other major areas presented in the taxonomy framework.",
            "contribution_ids": [
                "R29162"
            ]
        },
        {
            "instance_id": "R29240xR29210",
            "comparison_id": "R29240",
            "paper_id": "R29210",
            "text": "Identification and assessment of risks associated with ERP post-implementation in China purpose \u2013 the purpose of this paper is to identify, assess and explore potential risks that chinese companies may encounter when using, maintaining and enhancing their enterprise resource planning (erp) systems in the post\u2010implementation phase.design/methodology/approach \u2013 the study adopts a deductive research design based on a cross\u2010sectional questionnaire survey. this survey is preceded by a political, economic, social and technological analysis and a set of strength, weakness, opportunity and threat analyses, from which the researchers refine the research context and select state\u2010owned enterprises (soes) in the electronic and telecommunications industry in guangdong province as target companies to carry out the research. the questionnaire design is based on a theoretical risk ontology drawn from a critical literature review process. the questionnaire is sent to 118 selected chinese soes, from which 42 (84 questionnaires) valid and usable responses are received and analysed.findings \u2013 the findings ident...",
            "contribution_ids": [
                "R29211"
            ]
        },
        {
            "instance_id": "R29240xR29217",
            "comparison_id": "R29240",
            "paper_id": "R29217",
            "text": "The Core Critical Success Factors in Implementation of Enterprise Resource Planning Systems the implementation of enterprise resource planning (erp) systems require huge investments while ineffective implementations of such projects are commonly observed. a considerable number of these projects have been reported to fail or take longer than it was initially planned, while previous studies show that the aim of rapid implementation of such projects has not been successful and the failure of the fundamental goals in these projects have imposed huge amounts of costs on investors. some of the major consequences are the reduction in demand for such products and the introduction of further skepticism to the managers and investors of erp systems. in this regard, it is important to understand the factors determining success or failure of erp implementation. the aim of this paper is to study the critical success factors (csfs) in implementing erp systems and to develop a conceptual model which can serve as a basis for erp project managers. these critical success factors that are called \u201ccore critical success factors\u201d are extracted from 62 published papers using the content analysis and the entropy method. the proposed conceptual model has been verified in the context of five multinational companies.",
            "contribution_ids": [
                "R29218"
            ]
        },
        {
            "instance_id": "R29240xR29226",
            "comparison_id": "R29240",
            "paper_id": "R29226",
            "text": "A FRAMEWORK FOR CLASSIFYING RISKS IN ERP MAINTENANCE PROJECTS enterprise resource planning (erp) is one the most common applications implemented by firms around the world. these systems cannot remain static after their implementation, they need maintenance. this process is required by the rapidly-changing business environment and the usual software maintenance needs. however, these projects are highly complex and risky. so, the risks management associated with erp maintenance projects is crucial to attain a satisfactory performance. unfortunately, erp maintenance risks have not been studied in depth. for this reason, this paper presents a framework, which gathers together the risks affecting the performance of erp maintenance.",
            "contribution_ids": [
                "R29227"
            ]
        },
        {
            "instance_id": "R29240xR29231",
            "comparison_id": "R29240",
            "paper_id": "R29231",
            "text": "Evaluation of Key Success Factors Influencing ERP Implementation Success \"enterprise resource planning (erp) application is often viewed as a strategic investment that can provide significant competitive advantage with positive return thus contributing to the firms' revenue and growth. despite such strategic importance given to erp the implementation success to achieve the desired goal has been viewed disappointing. there have been numerous industry stories about failures of erp initiatives. there have also been stories reporting on the significant benefits achieved from successful erp initiatives. this study review the industry and academic literature on erp results and identify possible trends or factors which may help future erp initiatives achieve greater success and less failure. the purpose of this study is to review the industry and academic literature on erp results, identify and discuss critical success factors which may help future erp initiatives achieve greater success and less failure.\"",
            "contribution_ids": [
                "R29232"
            ]
        },
        {
            "instance_id": "R29240xR29194",
            "comparison_id": "R29240",
            "paper_id": "R29194",
            "text": "Critical successful factors of ERP implementation: a review recently e -business has become the focus of management interest both in academics and in business. among the major components of e -business, erp (enterprise resource planning) is the backbone of other applications. therefore more and more enterprises attempt to adopt this new application in order to improve their business competitiveness. owing to the specific characteristics of erp, its implementation is more difficult than that of traditional information systems. for this reason, how to implement erp successfully becomes an important issue for both academics and practitioners. in this paper, a review on critical successful factors of erp in important mis publications will be presented. additionally traditional is implementatio n and erp implementation will be compared and the findings will be served as the basis for further research.",
            "contribution_ids": [
                "R29195"
            ]
        },
        {
            "instance_id": "R29240xR29233",
            "comparison_id": "R29240",
            "paper_id": "R29233",
            "text": "A new framework of effective external and internal factors on the success of enterprise resource planning (ERP) true understanding of the managers of the organizations that implement the system of the success factors and conditions and their fulfillment is very helpful. many researches are done regarding the identification of key factors of this system but most of them had one-dimensional view to the subject or they only studied internal organizational factors so, the lack of a multi-purpose and coherent framework is evident. the researcher by a deep review on review of literature separated the success factors of erp in 7 factors of country environment, erp vendors\u2019 environment, software package environment, leadership and strategic criterions, organizational environment variables, organization users environment, it environment in the organization in the form of two external and internal set and finally attempted to present a coherent framework.",
            "contribution_ids": [
                "R29234"
            ]
        },
        {
            "instance_id": "R29351xR29304",
            "comparison_id": "R29351",
            "paper_id": "R29304",
            "text": "Deconstructing information packages: organizational and behavioural implications of ERP systems argues that the organizational involvement of large scale information technology packages, such as those known as enterprise resource planning (erp), has important implications that go far beyond the acknowledged effects of keeping the organizational operations accountable and integrated across functions and production sites. claims that erp packages are predicated on an understanding of human agency as a procedural affair and of organizations as an extended series of functional or cross\u2010functional transactions. accordingly, the massive introduction of erp packages to organizations is bound to have serious implications that precisely recount the procedural forms by which such packages instrument organizational operations and fashion organizational roles. the conception of human agency and organizational operations in procedural terms may seem reasonable yet it recounts a very specific and, in a sense, limited understanding of humans and organizations. the distinctive status of framing human agency and organizations in procedural terms becomes evident in its juxtaposition with other forms of human action like improvisation, exploration or playing. these latter forms of human involvement stand out against the serial fragmentation underlying procedural action. they imply acting on the world on loose premises that trade off a variety of forms of knowledge and courses of action in attempts to explore and discover alternative ways of coping with reality.",
            "contribution_ids": [
                "R29305"
            ]
        },
        {
            "instance_id": "R29351xR29306",
            "comparison_id": "R29351",
            "paper_id": "R29306",
            "text": "Developing a cultural perspective on ERP purpose to develop an analytical framework through which the organizational cultural dimension of enterprise resource planning (erp) implementations can be analyzed. design/methodology/approach this paper is primarily based on a review of the literature. findings erp is an enterprise system that offers, to a certain extent, standard business solutions. this standardization is reinforced by two processes: erp systems are generally implemented by intermediary it organizations, mediating between the development of erp\u2010standard software packages and specific business domains of application; and erp systems integrate complex networks of production divisions, suppliers and customers. originality/value in this paper, erp itself is presented as problematic, laying heavy burdens on organizations \u2013 erp is a demanding technology. while in some cases recognizing the mutual shaping of technology and organization, research into erp mainly addresses the economic\u2010technological rationality of erp (i.e. matters of effectiveness and efficiency). we want to supplement and complement this perspective with a cultural approach. how do individuals in organizations define and experience erp\u2010standards? how and to what extent are management and working positions redefined in the process of developing and implementing erp? in the paper, we highlight three perspectives from which erp systems can be experienced, defined and analyzed. these perspectives are specified as the \u201cconstitution\u201d of erp, erp as a \u201ccondition\u201d of organizations, and the (unintended) \u201cconsequences\u201d of erp.",
            "contribution_ids": [
                "R29307"
            ]
        },
        {
            "instance_id": "R29351xR29312",
            "comparison_id": "R29351",
            "paper_id": "R29312",
            "text": "Extended-enterprise systems\u00e2\u0080\u0099 impact on enterprise risk management\u00e2\u0080\u009d \" purpose \u2013 this article aims to focus on raising awareness of the limitations of traditional \u201centerprise\u2010centric\u201d views of enterprise risk management that ignore the risks that are inherited from key business and supply chain partners. in essence, enterprise systems implementations have allowed organizations to couple their operations more tightly with other business partners, particularly in the area of supply chain management, and in the process enterprise systems applications are redefining the boundaries of the entity in terms of risk management concerns and the scope of financial audits. design/methodology/approach \u2013 the prior literature that has begun to explore aspects of assessing key risk components in these relationships is reviewed with an eye to highlighting the limitations of what is understood about risk in interorganizational relationships. this analysis of the prior research establishes the basis for the logical formation of a framework for future enterprise risk management research in the area of e\u2010commerce relationships. findings \u2013 conclusions focus on the overall framework of risks that should be considered when interorganizational relationships are critical to an enterprise's operations and advocate an \u201cextended\u2010enterprise\u201d view of enterprise risk management. research limitations/implications \u2013 the framework introduced in this paper provides guidance for future research in the area of interorganizational systems control and risk assessment. practical implications \u2013 the framework further highlights areas of risk that auditors and corporate risk managers should consider in assessing the risk inherited through interorganizational relationships. originality/value \u2013 the paper highlights the need to shift from an enterprise\u2010centric view of risk management to an extended\u2010enterprise risk management view. \"",
            "contribution_ids": [
                "R29313"
            ]
        },
        {
            "instance_id": "R29351xR29342",
            "comparison_id": "R29351",
            "paper_id": "R29342",
            "text": "ERP measure success model: a new perspective this paper addresses the problem of defining and evaluating the success of erp throughout the life cycle of the information system. in order to solve this problem, many of the theoretical and empirical contributions on the success of the information system are analysed and discussed.\\n this approach allows the development of a new model; especially in delone & mclean supported research.\\n this work will try to establish a different perspective on the success of the erp and can be an encouragement to some organizations or the many researchers that will be engaging in these areas, in order to help achieve more clearly the expected performance in the acquisition phase of erps. many times that performance does not always happen [1].",
            "contribution_ids": [
                "R29343"
            ]
        },
        {
            "instance_id": "R29351xR29295",
            "comparison_id": "R29351",
            "paper_id": "R29295",
            "text": "Limits to using ERP systems the paper examines limitations that restrict the potential benefits from the use of enterprise resource planning (erp) systems in business firms. in the first part we discuss a limitation that arises from the strategic decision of top managers for mergers, acquisitions and divestitures as well as outsourcing. managers tend to treat their companies like component-based business units, which are to be arranged and re-arranged to yet higher market values. outsourcing of in-house activities to suppliers means disintegrating processes and information. such consequences of strategic business decisions impose severe restrictions on what business organizations can benefit from erp systems. the second part of the paper reflects upon the possibility of imbedding best practice business processes in erp systems. we critically review the process of capturing and transferring best practices with a particular focus on context-dependence and nature of it innovations.",
            "contribution_ids": [
                "R29296"
            ]
        },
        {
            "instance_id": "R29351xR29334",
            "comparison_id": "R29351",
            "paper_id": "R29334",
            "text": "The role and impact of project management in ERP project implementation life cycle recent advancement of information technology in business management processes has flourished erp as one of the most widely implemented business software systems in variety of industries and organizations. this paper presents review on the impact of project management in erp project life cycle by studying various project management methodologies. also the role and critical activities of project manager, project team and hence project management is explored in erp projects implementation in organization of different sizes and culture.",
            "contribution_ids": [
                "R29335"
            ]
        },
        {
            "instance_id": "R30476xR29422",
            "comparison_id": "R30476",
            "paper_id": "R29422",
            "text": "Growth and the Environment in Canada: An Empirical Analysis standard reduced form models are estimated for canada to examine the relationships between real per capita gdp and four measures of environmental degradation. of the four chosen measures of environmental degradation, only concentrations of carbon monoxide appear to decline in the long run with increases in real per capita income. the data used in the reduced form models are also tested for the presence of unit roots and for the existence of cointegration between each of the measures of environmental degradation and per capita income. unit root tests indicate nonstationarity in logs of the measures of environmental degradation and per capita income. the engle-granger test and the maximum eigenvalue test suggest that per capita income and the measures of environmental degradation are not cointegrated, or that a long-term relationship between the variables does not exist. causality tests also indicate a bi-directional causality, rather than a uni-directional causality, from income to the environment. the results suggest that canada does not have the luxury of being able to grow out of its environmental problems. the implication is that to prevent further environmental degradation, canada requires concerted policies and incentives to reduce pollution intensity per unit of output across sectors, to shift from more to less pollution-producing-outputs and to lower the environmental damage associated with aggregate consumption.",
            "contribution_ids": [
                "R29423"
            ]
        },
        {
            "instance_id": "R30476xR29587",
            "comparison_id": "R30476",
            "paper_id": "R29587",
            "text": "Does One Size Fit All? A Reexamination of the Environmental Kuznets Curve Using the Dynamic Panel Data Approach this article applies the dynamic panel generalized method of moments technique to reexamine the environmental kuznets curve (ekc) hypothesis for carbon dioxide (co_2) emissions and asks two critical questions: \"does the global data set fit the ekc hypothesis?\" and \"do different income levels or regions influence the results of the ekc?\" we find evidence of the ekc hypothesis for co_2 emissions in a global data set, middle-income, and american and european countries, but not in other income levels and regions. thus, the hypothesis that one size fits all cannot be supported for the ekc, and even more importantly, results, robustness checking, and implications emerge. copyright 2009 agricultural and applied economics association",
            "contribution_ids": [
                "R29588"
            ]
        },
        {
            "instance_id": "R30476xR29637",
            "comparison_id": "R30476",
            "paper_id": "R29637",
            "text": "Environmental Kuznets curve for CO2 in Canada the environmental kuznets curve hypothesis is a theory by which the relationship between per capita gdp and per capita pollutant emissions has an inverted u shape. this implies that, past a certain point, economic growth may actually be profitable for environmental quality. most studies on this subject are based on estimating fully parametric quadratic or cubic regression models. while this is not technhically wrong, such an approach somewhat lacks flexibility since it may fail to detect the true shape of the relationship if it happens not to be of the specified form. we use semiparametric and flexible nonlinear parametric modelling methods in an attempt to provide more robust inferences. we find little evidence in favour of the environmental kuznets curve hypothesis. our main results could be interpreted as indicating that the oil shock of the 1970s has had an important impact on progress towards less polluting technology and production.",
            "contribution_ids": [
                "R29638"
            ]
        },
        {
            "instance_id": "R30476xR29881",
            "comparison_id": "R30476",
            "paper_id": "R29881",
            "text": "Environmental Kuznets curve: evidences from developed and developing economies previous studies show that the environmental quality and economic growth can be represented by the inverted u curve called environmental kuznets curve (ekc). in this study, we conduct empirical analyses on detecting the existence of ekc using the five common pollutants emissions (i.e. co2, so2, bod, spm10, and ghg) as proxy for environmental quality. the data spanning from year 1961 to 2009 and cover 40 countries. we seek to investigate if the ekc hypothesis holds in two groups of economies, i.e. developed versus developing economies. applying panel data approach, our results show that the ekc does not hold in all countries. we also detect the existence of u shape and increasing trend in other cases. the results reveal that co2 and spm10 are good data to proxy for environmental pollutant and they can be explained well by gdp. also, it is observed that the developed countries have higher turning points than the developing countries. higher economic growth may lead to different impacts on environmental quality in different economies.",
            "contribution_ids": [
                "R29882"
            ]
        },
        {
            "instance_id": "R30476xR29970",
            "comparison_id": "R30476",
            "paper_id": "R29970",
            "text": "The potential of renewable energy: using the environmental Kuznets curve model this study examines the potential of renewable energy sources (res) in reducing the impact of carbon emission in malaysia and the greenhouse gas (ghg) emissions, which leads to global warming. using the environmental kuznets curve (ekc) hypothesis, this study analyses the impact of electricity generated using res on the environment and trade openness for the period 1980-2009. using the autoregressive distributed lag (ardl) approach the results show that the elasticities of electricity production from renewable sources with respect to co2 emissions are negative and significant in both the short and long-run. this implies the potential of renewable energy in controlling co2 emissions in both short and long-run in malaysia. renewable energy can ensure sustainability of electricity supply and at the same time can reduce co2 emissions. trade openness has a significant negative effect on co2 emissions in the long-run. the granger causality test based on vector error correction mode (vecm) indicates that there is an evidence of positive bi-directional granger causality relationship between economic growth and co2 emissions in the short and long-run suggesting that carbon emissions and economic growth are interrelated to each other. furthermore, there is a negative long-run bi-directional granger causality relationship between electricity production from renewable sources and co2 emissions. the short-run granger causality shows a negative uni-directional causality for electricity production from renewable sources to co2 emissions. this result suggests that there is an inverted u-shaped relationship between co2 emissions and economic growth.",
            "contribution_ids": [
                "R29971"
            ]
        },
        {
            "instance_id": "R30476xR29973",
            "comparison_id": "R30476",
            "paper_id": "R29973",
            "text": "The environmental Kuznets curve in Asia: the case of sulphur and carbon emissions\u00e2\u0080\u009d the present study examines whether the race to the bottom and revised ekc scenarios presented by dasgupta and others (2002) are, with regard to the analytical framework of the environmental kuznets curve (ekc), applicable in asia to representative environmental indices, such as sulphur emissions and carbon emissions. to carry out this study, a generalized method of moments (gmm) estimation was made, using panel data of 19 economies for the period 1950-2009. the main findings of the analysis on the validity of ekc indicate that sulphur emissions follow the expected inverted u-shape pattern, while carbon emissions tend to increase in line with per capita income in the observed range. as for the race to the bottom and revised ekc scenarios, the latter was verified in sulphur emissions, as their ekc trajectories represent a linkage of the later development of the economy with the lower level of emissions while the former one was not present in neither sulphur nor carbon emissions.",
            "contribution_ids": [
                "R29974"
            ]
        },
        {
            "instance_id": "R30476xR30076",
            "comparison_id": "R30476",
            "paper_id": "R30076",
            "text": "Beyond the Environmental Kuznets Curve in Africa: Evidence from Panel Cointegration abstract the main objective of this study is to establish the applicability of the environmental kuznets curve (ekc) hypothesis in explaining the relationship between environmental pollution and development in africa. the ekc has been used to explain such relationships in a variety of contexts, yet rarely applied in africa, despite it hosting both the poorest countries in the world, 60% of those with extreme environmental pollution vulnerability and having a distinct socio-economic and institutional profile that tests the validity of such a model. this paper describes an empirical model that applies the ekc hypothesis and its modifications to 50 african countries, using data from 1995\u20132010. the empirical analysis suggests that there is a long-term relationship between co2 and particulate matter emissions with per capita income and other variables, including institutional factors and trade, leading to specific recommendations on future strategies for sustainable development in an african context.",
            "contribution_ids": [
                "R30077"
            ]
        },
        {
            "instance_id": "R30476xR30088",
            "comparison_id": "R30476",
            "paper_id": "R30088",
            "text": "Environmental Kuznets curve in an open economy: a bounds testing and causality analysis for Tunisia the aim of this paper is to investigate the existence of environmental kuznets curve (ekc) in an open economy like tunisia using annual time series data for the period of 1971-2010. the ardl bounds testing approach to cointegration is applied to test long run relationship in the presence of structural breaks and vector error correction model (vecm) to detect the causality among the variables. the robustness of causality analysis has been tested by applying the innovative accounting approach (iaa). the findings of this paper confirmed the long run relationship between economic growth, energy consumption, trade openness and co2 emissions in tunisian economy. the results also indicated the existence of ekc confirmed by the vecm and iaa approaches. the study has significant contribution for policy implications to curtail energy pollutants by implementing environment friendly regulations to sustain the economic development in tunisia.",
            "contribution_ids": [
                "R30089"
            ]
        },
        {
            "instance_id": "R30476xR30175",
            "comparison_id": "R30476",
            "paper_id": "R30175",
            "text": "Emissions and trade in Southeast and East Asian countries: a panel co-integration analysis \\n purpose \\n \u2013 the purpose of this paper is to analyse the implication of trade on carbon emissions in a panel of eight highly trading southeast and east asian countries, namely, china, indonesia, south korea, malaysia, hong kong, the philippines, singapore and thailand. \\n \\n \\n design/methodology/approach \\n \u2013 the analysis relies on the standard quadratic environmental kuznets curve (ekc) extended to include energy consumption and international trade. a battery of panel unit root and co-integration tests is applied to establish the variables\u2019 stochastic properties and their long-run relations. then, the specified ekc is estimated using the panel dynamic ordinary least square (ols) estimation technique. \\n \\n \\n findings \\n \u2013 the panel co-integration statistics verifies the validity of the extended ekc for the countries under study. estimation of the long-run ekc via the dynamic ols estimation method reveals the environmentally degrading effects of trade in these countries, especially in asean and plus south korea and hong kong. \\n \\n \\n practical implications \\n \u2013 these countries are heavily dependent on trade for their development processes, and as such, their impacts on co 2 emissions would be highly relevant for assessing their trade policies, along the line of the gain-from-trade hypothesis, the race-to-the-bottom hypothesis and the pollution-safe-haven hypothesis. \\n \\n \\n originality/value \\n \u2013 the analysis adds to existing literature by focusing on the highly trading nations of southeast and east asian countries. the results suggest that reassessment of trade policies in these countries is much needed and it must go beyond the sole pursuit of economic development via trade. \\n",
            "contribution_ids": [
                "R30176"
            ]
        },
        {
            "instance_id": "R30476xR30284",
            "comparison_id": "R30476",
            "paper_id": "R30284",
            "text": "The Relationship between CO2 Emission, Energy Consumption, Urbanization and Trade Openness for Selected CEECs this paper investigates the relationship between co2 emission, real gdp, energy consumption, urbanization and trade openness for 10 for selected central and eastern european countries (ceecs), including, albania, bulgaria, croatia, czech republic, macedonia, hungary, poland, romania, slovak republic and slovenia for the period of 1991\u20132011. the results show that the environmental kuznets curve (ekc) hypothesis holds for these countries. the fully modified ordinary least squares (fmols) results reveal that a 1% increase in energy consumption leads to a %1.0863 increase in co2 emissions. results for the existence and direction of panel vector error correction model (vecm) granger causality method show that there is bidirectional causal relationship between co2 emissions - real gdp and energy consumption-real gdp as well.",
            "contribution_ids": [
                "R30285"
            ]
        },
        {
            "instance_id": "R30476xR30373",
            "comparison_id": "R30476",
            "paper_id": "R30373",
            "text": "CO2emissions in Australia: economic and non-economic drivers in the long-run abstract australia has sustained a relatively high economic growth rate since the 1980s compared to other developed countries. per capita co2 emissions tend to be highest amongst oecd countries, creating new challenges to cut back emissions towards international standards. this research explores the long-run dynamics of co2 emissions, economic and population growth along with the effects of globalization tested as contributing factors. we find economic growth is not emission-intensive in australia, while energy consumption is emissions intensive. second, in an environment of increasing population, our findings suggest australia needs to be energy efficient at the household level, creating appropriate infrastructure for sustainable population growth. high population growth and open migration policy can be detrimental in reducing co2 emissions. finally, we establish globalized environment has been conducive in combating emissions. in this respect, we establish the beneficial effect of economic globalization compared to social and political dimensions of globalization in curbing emissions.",
            "contribution_ids": [
                "R30374"
            ]
        },
        {
            "instance_id": "R30476xR29741",
            "comparison_id": "R30476",
            "paper_id": "R29741",
            "text": "Economic Development and Environmental Quality in Nigeria: Is There an Environmental Kuznets Curve? this study utilizes standard- and nested-ekc models to investigate the income-environment relation for nigeria, between 1960 and 2008. the results from the standard-ekc model provides weak evidence of an inverted-u shaped relationship with turning point (t.p) around $280.84, while the nested model presents strong evidence of an n-shaped relationship between income and emissions in nigeria, with a t.p around $237.23. tests for structural breaks caused by the 1973 oil price shocks and 1986 structural adjustment are not rejected, implying that these factors have not significantly affected the income-environment relationship in nigeria. further, results from the rolling interdecadal analysis shows that the observed relationship is stable and insensitive to the sample interval chosen. overall, our findings imply that economic development is compatible with environmental improvements in nigeria. however, tighter and concentrated environmental policy regimes will be required to ensure that the relationship is maintained around the first two-strands of the n-shape",
            "contribution_ids": [
                "R29742"
            ]
        },
        {
            "instance_id": "R30476xR30390",
            "comparison_id": "R30476",
            "paper_id": "R30390",
            "text": "Relationship between economic growth and environmental degradation: is there evidence of an environmental Kuznets curve for Brazil? this study investigates the relationship between co2 emissions, economic growth, energy use and electricity production by hydroelectric sources in brazil. to verify the environmental kuznets curve (ekc) hypothesis we use time-series data for the period 1971-2011. the autoregressive distributed lag methodology was used to test for cointegration in the long run. additionally, the vector error correction model granger causality test was applied to verify the predictive value of independent variables. empirical results find that there is a quadratic long run relationship between co2emissions and economic growth, confirming the existence of an ekc for brazil. furthermore, energy use shows increasing effects on emissions, while electricity production by hydropower sources has an inverse relationship with environmental degradation. the short run model does not provide evidence for the ekc theory. the differences between the results in the long and short run models can be considered for establishing environmental policies. this suggests that special attention to both variables-energy use and the electricity production by hydroelectric sources- could be an effective way to mitigate co2 emissions in brazil",
            "contribution_ids": [
                "R30391"
            ]
        },
        {
            "instance_id": "R30512xR30488",
            "comparison_id": "R30512",
            "paper_id": "R30488",
            "text": "Harnessing Different Motivational Frames via Mobile Phones to Promote Daily Physical Activity and Reduce Sedentary Behavior in Aging Adults \"mobile devices are a promising channel for delivering just-in-time guidance and support for improving key daily health behaviors. despite an explosion of mobile phone applications aimed at physical activity and other health behaviors, few have been based on theoretically derived constructs and empirical evidence. eighty adults ages 45 years and older who were insufficiently physically active, engaged in prolonged daily sitting, and were new to smartphone technology, participated in iterative design development and feasibility testing of three daily activity smartphone applications based on motivational frames drawn from behavioral science theory and evidence. an \u201canalytically\u201d framed custom application focused on personalized goal setting, self-monitoring, and active problem solving around barriers to behavior change. a \u201csocially\u201d framed custom application focused on social comparisons, norms, and support. an \u201caffectively\u201d framed custom application focused on operant conditioning principles of reinforcement scheduling and emotional transference to an avatar, whose movements and behaviors reflected the physical activity and sedentary levels of the user. to explore the applications' initial efficacy in changing regular physical activity and leisure-time sitting, behavioral changes were assessed across eight weeks in 68 participants using the champs physical activity questionnaire and the australian sedentary behavior questionnaire. user acceptability of and satisfaction with the applications was explored via a post-intervention user survey. the results indicated that the three applications were sufficiently robust to significantly improve regular moderate-to-vigorous intensity physical activity and decrease leisure-time sitting during the 8-week behavioral adoption period. acceptability of the applications was confirmed in the post-intervention surveys for this sample of midlife and older adults new to smartphone technology. preliminary data exploring sustained use of the applications across a longer time period yielded promising results. the results support further systematic investigation of the efficacy of the applications for changing these key health-promoting behaviors.\"",
            "contribution_ids": [
                "R30489"
            ]
        },
        {
            "instance_id": "R30512xR30490",
            "comparison_id": "R30512",
            "paper_id": "R30490",
            "text": "Activity sensing in the wild \"recent advances in small inexpensive sensors, low-power processing, and activity modeling have enabled applications that use on-body sensing and machine learning to infer people's activities throughout everyday life. to address the growing rate of sedentary lifestyles, we have developed a system, ubifit garden, which uses these technologies and a personal, mobile display to encourage physical activity. we conducted a 3-week field trial in which 12 participants used the system and report findings focusing on their experiences with the sensing and activity inference. we discuss key implications for systems that use on-body sensing and activity inference to encourage physical activity.\"",
            "contribution_ids": [
                "R30491"
            ]
        },
        {
            "instance_id": "R30512xR30504",
            "comparison_id": "R30512",
            "paper_id": "R30504",
            "text": "TripleBeat \"we present triplebeat, a mobile phone based system that assists runners in achieving predefined exercise goals via musical feedback and two persuasive techniques: a glanceable interface for increased personal awareness and a virtual competition. triplebeat is based on a previous system named mptrain. first, we describe triplebeat's hardware and software, emphasizing how it differs from its predecessor mptrain. then, we present the results of a runner study with 10 runners. the study compared the runners efficacy and enjoyment in achieving predefined workout goals when running with mptrain and triplebeat. the conclusions from the study include: (1) significantly higher efficacy and enjoyment with triplebeat, and (2) a unanimous preference for triplebeat over mptrain. the glanceable interface and the virtual competition are the two main reasons for the improvements in the running experience. we believe that systems like triplebeat will play an important role in enhancing the exercise experience and in assisting users towards more active lifestyles.\"",
            "contribution_ids": [
                "R30505"
            ]
        },
        {
            "instance_id": "R30512xR30506",
            "comparison_id": "R30512",
            "paper_id": "R30506",
            "text": "MPTrain \"we present mptrain, a mobile phone based system that takes advantage of the influence of music in exercise performance, enabling users to more easily achieve their exercise goals. mptrain is designed as a mobile and personal system (hardware and software) that users wear while exercising (walking, jogging or running). mptrain's hardware includes a set of physiological sensors wirelessly connected to a mobile phone carried by the user. mptrain's software allows the user to enter a desired exercise pattern (in terms of desired heart-rate over time) and assists the user in achieving his/her exercising goals by: (1) constantly monitoring the user's physiology (heart-rate in number of beats per minute) and movement (speed in number of steps per minute); and (2) selecting and playing music with specific features that will encourage the user to speed up, slow down or keep the pace to be on track with his/her exercise goals.we describe the hardware and software components of the mptrain system, and present some preliminary results when using mptrain while jogging.\"",
            "contribution_ids": [
                "R30507"
            ]
        },
        {
            "instance_id": "R30512xR30510",
            "comparison_id": "R30512",
            "paper_id": "R30510",
            "text": "Self-setting of physical activity goals and effects on perceived difficulty, importance and competence goal setting can be a powerful method for persuading individuals to adopt an active lifestyle. in order for this to be the case, it is important to set concrete and challenging goals, and to strongly commit to them. in this study, we explored how people set goals for physical activity and how these goals were reflected in self-regulatory mechanisms to drive goal attainment. our approach is novel in two ways: first, we used an unobtrusive wearable sensor to accurately measure physical activity throughout the day rather than rely on self-report, and second, we provided individuals with feedback about the contribution of their common daily activities (e.g., household activities) to their physical activity level. our results showed that on the basis of this feedback, participants were able to indicate to what degree they intended to change their behavior. nevertheless, they failed to set concrete goals that matched their intentions precisely. in particular, we observed that overall the set goals were in accordance with intentions (i.e., goals were set in the desired direction), but we saw a strong tendency to focus on enhancing vigorous activity at the cost of moderate intensity activity. this suggests that many individuals have intentions to change and goal setting support is needed to compose goals that accurately reflect these intentions. technology-mediated interventions might be ideal to support individuals along that path.",
            "contribution_ids": [
                "R30511"
            ]
        },
        {
            "instance_id": "R30579xR30551",
            "comparison_id": "R30579",
            "paper_id": "R30551",
            "text": "Outlier detection in ad hoc networks using dempster-shafer theory mobile ad-hoc networks (manets) are known to be vulnerable to a variety of attacks due to lack of central authority or fixed network infrastructure. many security schemes have been proposed to identify misbehaving nodes. most of these security schemes rely on either a predefined threshold, or a set of well-defined training data to build up the detection mechanism before effectively identifying the malicious peers. however, it is generally difficult to set appropriate thresholds, and collecting training datasets representative of an attack ahead of time is also problematic. we observe that the malicious peers generally demonstrate behavioral patterns different from all the other normal peers, and argue that outlier detection techniques can be used to detect malicious peers in ad hoc networks. a problem with this approach is combining evidence from potentially untrustworthy peers to detect the outliers. in this paper, an outlier detection algorithm is proposed that applies the dempster-shafer theory to combine observation results from multiple nodes because it can appropriately reflect uncertainty as well as unreliability of the observations. the simulation results show that the proposed scheme is highly resilient to attackers and it can converge stably to a common outlier view amongst distributed nodes with a limited communication overhead.",
            "contribution_ids": [
                "R30552"
            ]
        },
        {
            "instance_id": "R30579xR30567",
            "comparison_id": "R30579",
            "paper_id": "R30567",
            "text": "A distributed key management framework with cooperative message authentication in VANETs in this paper, we propose a distributed key management framework based on group signature to provision privacy in vehicular ad hoc networks (vanets). distributed key management is expected to facilitate the revocation of malicious vehicles, maintenance of the system, and heterogeneous security policies, compared with the centralized key management assumed by the existing group signature schemes. in our framework, each road side unit (rsu) acts as the key distributor for the group, where a new issue incurred is that the semi-trust rsus may be compromised. thus, we develop security protocols for the scheme which are able to detect compromised rsus and their colluding malicious vehicles. moreover, we address the issue of large computation overhead due to the group signature implementation. a practical cooperative message authentication protocol is thus proposed to alleviate the verification burden, where each vehicle just needs to verify a small amount of messages. details of possible attacks and the corresponding solutions are discussed. we further develop a medium access control (mac) layer analytical model and carry out ns2 simulations to examine the key distribution delay and missed detection ratio of malicious messages, with the proposed key management framework being implemented over 802.11 based vanets.",
            "contribution_ids": [
                "R30568"
            ]
        },
        {
            "instance_id": "R30579xR30575",
            "comparison_id": "R30579",
            "paper_id": "R30575",
            "text": "Distributed Misbehavior Detection in VANETs in any vehicular adhoc network, there is always a possibility of incorrect messages being transmitted either due to faulty sensors and/or intentional malicious activities. detecting and evicting sources of such misbehavior is an important problem. we observe that the performance of misbehavior detection schemes will depend on the application under consideration and the mobility dynamics of the detecting vehicle. further, the underlying tradeoff in any such detection algorithm is the balance between false positives and false negatives; one would like to detect as many misbehaviors as possible, while at the same time ensuring that the genuine vehicles are not wrongly accused. \\n \\nin this work we propose and analyze (via simulations) the performance of a misbehavior detection scheme (mds) for post crash notification (pcn) application. we observe that the performance of this proposed scheme is not very sensitive to the exact dynamics of the vehicle on small scales, so that slight error in estimating the dynamics of the detecting vehicle does not degrade the performance of the mds.",
            "contribution_ids": [
                "R30576"
            ]
        },
        {
            "instance_id": "R30646xR30590",
            "comparison_id": "R30646",
            "paper_id": "R30590",
            "text": "Average of Synthetic Exact Filters this paper introduces a class of correlation filters called average of synthetic exact filters (asef). for asef, the correlation output is completely specified for each training image. this is in marked contrast to prior methods such as synthetic discriminant functions (sdfs) which only specify a single output value per training image. advantages of asef training include: insensitivity to over-fitting, greater flexibility with regard to training images, and more robust behavior in the presence of structured backgrounds. the theory and design of asef filters is presented using eye localization on the feret database as an example task. asef is compared to other popular correlation filters including sdf, mace, otf, and umace, and with other eye localization methods including gabor jets and the opencv cascade classifier. asef is shown to outperform all these methods, locating the eye to within the radius of the iris approximately 98.5% of the time.",
            "contribution_ids": [
                "R30591"
            ]
        },
        {
            "instance_id": "R30646xR30594",
            "comparison_id": "R30646",
            "paper_id": "R30594",
            "text": "Eye Localization based on Multi-Scale Gabor Feature Vector Model eye localization is necessary for face recognition and related application areas. most of eye localization algorithms reported thus far still need to be improved about precision and computational time for successful applications. in this paper, we propose an improved eye localization method based on multi-scale gator feature vector models. the proposed method first tries to locate eyes in the downscaled face image by utilizing gabor jet similarity between gabor feature vector at an initial eye coordinates and the eye model bunch of the corresponding scale. the proposed method finally locates eyes in the original input face image after it processes in the same way recursively in each scaled face image by using the eye coordinates localized in the downscaled image as initial eye coordinates. experiments verify that our proposed method improves the precision rate without causing much computational overhead compared with other eye localization methods reported in the previous researches.",
            "contribution_ids": [
                "R30595",
                "R30610",
                "R30624"
            ]
        },
        {
            "instance_id": "R30646xR30596",
            "comparison_id": "R30646",
            "paper_id": "R30596",
            "text": "Combining Face and Eye Detectors in a High- Performance Face-Detection System a combined face and eye detector system based on multiresolution local ternary patterns and local phase quantization descriptors can achieve noticeable performance improvements by extracting features locally.",
            "contribution_ids": [
                "R30597",
                "R30625"
            ]
        },
        {
            "instance_id": "R30646xR30629",
            "comparison_id": "R30646",
            "paper_id": "R30629",
            "text": "Enhanced Pictorial Structures for precise eye localization under incontrolled conditions in this paper, we present an enhanced pictorial structure (ps) model for precise eye localization, a fundamental problem involved in many face processing tasks. ps is a computationally efficient framework for part-based object modelling. for face images taken under uncontrolled conditions, however, the traditional ps model is not flexible enough for handling the complicated appearance and structural variations. to extend ps, we 1) propose a discriminative ps model for a more accurate part localization when appearance changes seriously, 2) introduce a series of global constraints to improve the robustness against scale, rotation and translation, and 3) adopt a heuristic prediction method to address the difficulty of eye localization with partial occlusion. experimental results on the challenging lfw (labeled face in the wild) database show that our model can locate eyes accurately and efficiently under a broad range of uncontrolled variations involving poses, expressions, lightings, camera qualities, occlusions, etc.",
            "contribution_ids": [
                "R30630"
            ]
        },
        {
            "instance_id": "R30646xR30634",
            "comparison_id": "R30646",
            "paper_id": "R30634",
            "text": "For your eyes only in this paper, we take a look at an enhanced approach for eye detection under difficult acquisition circumstances such as low-light, distance, pose variation, and blur. we present a novel correlation filter based eye detection pipeline that is specifically designed to reduce face alignment errors, thereby increasing eye localization accuracy and ultimately face recognition accuracy. the accuracy of our eye detector is validated using data derived from the labeled faces in the wild (lfw) and the face detection on hard datasets competition 2011 (fdhd) sets. the results on the lfw dataset also show that the proposed algorithm exhibits enhanced performance, compared to another correlation filter based detector, and that a considerable increase in face recognition accuracy may be achieved by focusing more effort on the eye localization stage of the face recognition process. our results on the fdhd dataset show that our eye detector exhibits superior performance, compared to 11 different state-of-the-art algorithms, on the entire set of difficult data without any per set modifications to our detection or preprocessing algorithms. the immediate application of eye detection is automatic face recognition, though many good applications exist in other areas, including medical research, training simulators, communication systems for the disabled, and automotive engineering.",
            "contribution_ids": [
                "R30635"
            ]
        },
        {
            "instance_id": "R30698xR30658",
            "comparison_id": "R30698",
            "paper_id": "R30658",
            "text": "Dental erosion in 12-year-old schoolchildren: A cross- sectional study in Southern Brazil \"objective\\nthe aim of this study was to assess the prevalence and severity of dental erosion among 12-year-old schoolchildren in joa\u00e7aba, southern brazil, and to compare prevalence between boys and girls, and between public and private school students.\\n\\n\\nmethods\\na cross-sectional study was carried out involving all of the municipality's 499, 12-year-old schoolchildren. the dental erosion index proposed by o'sullivan was used for the four maxillary incisors. data analysis included descriptive statistics, location, distribution, and extension of affected area and severity of dental erosion.\\n\\n\\nresults\\nthe prevalence of dental erosion was 13.0% (95% confidence interval = 9.0-17.0). there was no statistically significant difference in prevalence between boys and girls, but prevalence was higher in private schools (21.1%) than in public schools (9.7%) (p < 0.001). labial surfaces were less often affected than palatal surfaces. enamel loss was the most prevalent type of dental erosion (4.86 of 100 incisors). sixty-three per cent of affected teeth showed more than a half of their surface affected.\\n\\n\\nconclusion\\nthe prevalence of dental erosion in 12-year-old schoolchildren living in a small city in southern brazil appears to be lower than that seen in most of epidemiological studies carried out in different parts of the world. further longitudinal studies should be conducted in brazil in order to measure the incidence of dental erosion and its impact on children's quality of life.\"",
            "contribution_ids": [
                "R30659"
            ]
        },
        {
            "instance_id": "R30698xR30673",
            "comparison_id": "R30698",
            "paper_id": "R30673",
            "text": "Smile aesthetics and malocclusion in UK teenage magazines assessed using the Index of Orthodontic Treatment Need (IOTN) \"objective there is a significant demand for orthodontic treatment within the uk from adolescent girls, a group known to be influenced by the media portrayal of body form and body image, which may extend to the presentation of malocclusions. this study examined the portrayal of malocclusion in a media type that targets teenage girls under 16 years of age. materials and methods a representative selection of 1 month's magazines targeting this group were investigated, and the frequency and severity of malocclusions displayed were assessed. two calibrated examiners viewed all the smiles (on two occasions) using a modification of index of orthodontic treatment need (iotn) and assigned an aesthetic component score to each smile. results it was found that the aesthetic score is low (less than 7) for the majority of models (92.8%) indicating no need or a borderline need for treatment. only 7.2% of models exhibited a definite need for treatment. conclusion it appears that the portrayal of malocclusion in teenage magazines does not reflect the general treatment need of the adolescent population.\"",
            "contribution_ids": [
                "R30674"
            ]
        },
        {
            "instance_id": "R30698xR30693",
            "comparison_id": "R30698",
            "paper_id": "R30693",
            "text": "The oral health of children with clefts of the lip, palate, or both \" objective: the purpose of this study was to assess the prevalence of dental caries, developmental defects of enamel, and related factors in children with clefts. design: this cross-sectional prevalence study used standard dental indices for assessment. setting: children underwent a dental examination under standard conditions of seating and lighting in the outpatient department of a dental hospital as part of an ongoing audit to monitor clinical outcomes. participants: ninety-one children aged 4, 8, and 12 years were included in the study. outcome measurements dental caries were assessed by use of the decayed, missing, and filled index for primary teeth (dmft); decayed, missing, and filled index for permanent teeth (dmft) according to the criteria as used in the national survey of children's dental health in the united kingdom (o'brien, 1994). developmental defects were assessed using the modified developmental defects of enamel index (clarkson and o'mullane, 1989). dental erosion was assessed using the criteria derived for the national survey of children's dental health (o'brien, 1994). results: caries prevalence increased with age; 63% of patients at 4 years and 34% at 12 years were caries free. the mean dmft for the 4-year-olds was 1.3 with a mean dmft for the 12-year-olds of 1.8. all the 4-year-olds had evidence of erosion of enamel in the primary teeth (incisors and first molars) and 56% of the 12-year-olds had erosion of permanent teeth (incisors and first permanent molars). developmental defects of enamel became more prevalent with age, with at least one opacity in 56% of 4-year-olds and 100% of 12-year-olds. hypoplasia was not found in the primary dentition but affected permanent teeth in 38% of 8-year-olds and 23% of the 12-year-olds. conclusion: this study has shown that dental disease is prevalent in these patients. these assessments not only provide a baseline on oral health parameters in young people with clefts but underline the need for a more aggressive approach to prevention of oral disease to optimize clinical outcome. \"",
            "contribution_ids": [
                "R30694"
            ]
        },
        {
            "instance_id": "R30739xR30700",
            "comparison_id": "R30739",
            "paper_id": "R30700",
            "text": "Tooth surface loss in adult subjects attending a university dental clinic in Trinidad objectives\\nto determine the prevalence of tooth surface loss (tsl) in a sample of subjects attending a university dental clinic in trinidad and to investigate the relationship to tooth brushing, medical history, parafunction and dietary habits.\\n\\n\\ndesign\\ntooth surface loss was measured clinically by the index used in the 1998 uk, adult dental health survey.\\n\\n\\nsetting\\ntrinidad, west indies.\\n\\n\\nparticipants\\nconvenience sample of adult subjects attending the university of the west indies dental school polyclinic, mount hope.\\n\\n\\nmethods\\na questionnaire was administered and tooth surface loss measured clinically.\\n\\n\\nmain outcome measures\\nmild, moderate and severe tooth surface loss.\\n\\n\\nresults\\n155 subjects were examined (mean age 40.6 years) of whom 72% had some degree of tsl with the majority (52%), exhibiting mild, 16% with moderate and 4% with severe tsl. there were associations found between tsl and age (or=3.14), reflux (or=1.37), parafunction (or=1.06), weekly consumption of citrus fruits (or=1.31) and soft drinks (or=1.78), daily consumption of alcohol (or=1.40) and a vegetarian diet (or=2.79).\\n\\n\\nconclusions\\ntooth surface loss in this trinidadian population group appears to be common. data supports an association between tsl and age, reflux parafunction and certain dietary patterns.",
            "contribution_ids": [
                "R30701"
            ]
        },
        {
            "instance_id": "R30739xR30717",
            "comparison_id": "R30739",
            "paper_id": "R30717",
            "text": "The prevalence of non-carious cervical lesions in permanent dentition a non-carious cervical lesion (nccl) is the loss of hard dental tissue on the neck of the tooth, most frequently located on the vestibular plane. causal agents are diverse and mutually interrelated. in the present study all vestibular nccl were observed and recorded by the tooth wear index (twi). the aim of the study was to determine the prevalence and severity of nccl. for this purpose, 18555 teeth from the permanent dentition were examined in a population from the city of rijeka, croatia. subjects were divided into six age groups. the teeth with most nccl were the lower premolars, which also had the largest percentage of higher index levels, indicating the greater severity of the lesions. the most frequent index level was 1, and the prevalence and severity of the lesions increased with age.",
            "contribution_ids": [
                "R30718"
            ]
        },
        {
            "instance_id": "R30739xR30728",
            "comparison_id": "R30739",
            "paper_id": "R30728",
            "text": "The prevalence, aetiology and clinical appearance of tooth wear: the Nigerian experience \"objective\\nto establish the prevalence and severity of tooth wear among nigerians and to compare the pattern and aetiology with findings of earlier studies in western populations.\\n\\n\\ndesign\\nclinical examinations for tooth wear using the tooth wear index (twi).\\n\\n\\nsetting\\nthe federal republic of nigeria.\\n\\n\\nparticipants\\npatients attending the dental hospital, obafemi awolowo university teaching hospital's complex ile-ife.\\n\\n\\noutcome measures\\nattrition, abrasion and erosion.\\n\\n\\nresults\\nof the 126 patients with tooth wear 81 had attrition, 20 had abrasion, 9 had erosion and 16 had attrition and abrasion combined. a total of 15,480 tooth surfaces were examined. 2,229 (14.4%) surfaces had tooth wear out of which 1,007 (6.5%) were pathologically worn down. the frequency of tooth wear increased with the age of patients. most of the pathologically worn surfaces were just one point above maximum acceptable value.\\n\\n\\nconclusions\\nthe aetiological factors associated with tooth wear are not different from those encountered in western cultures but the pattern of wear differs. pathological tooth wear presents as an age related phenomenon and is probably more severe in nigerians.\"",
            "contribution_ids": [
                "R30729"
            ]
        },
        {
            "instance_id": "R31214xR31208",
            "comparison_id": "R31214",
            "paper_id": "R31208",
            "text": "Cheating for problem solving: a genetic algorithm with social interactions \"we propose a variation of the standard genetic algorithm that incorporates social interaction between the individuals in the population. our goal is to understand the evolutionary role of social systems and its possible application as a non-genetic new step in evolutionary algorithms. in biological populations, i.e. animals, even human beings and microorganisms, social interactions often affect the fitness of individuals. it is conceivable that the perturbation of the fitness via social interactions is an evolutionary strategy to avoid trapping into local optimum, thus avoiding a fast convergence of the population. we model the social interactions according to game theory. the population is, therefore, composed by cooperator and defector individuals whose interactions produce payoffs according to well known game models (prisoner's dilemma, chicken game, and others). our results on knapsack problems show, for some game models, a significant performance improvement as compared to a standard genetic algorithm.\"",
            "contribution_ids": [
                "R31209"
            ]
        },
        {
            "instance_id": "R31214xR31185",
            "comparison_id": "R31214",
            "paper_id": "R31185",
            "text": "Terrain-based genetic algorithm (TBGA): modeling parameter space as terrain the terrain-based genetic algorithm (tbga) is a self-tuning version of the traditional cellular genetic algorithm (cga). in a tbga, various combinations of parameter values appear in different physical locations of the population, forming a sort of terrain in which individual solutions evolve. we compare the performance of the tbga against that of the cga on a known suite of problems. our results indicate that the tbga performs better than the cga on the test suite, with less parameter tuning, when the cga is set to parameter values thought in prior studies to be good. while we had hoped that good solutions would cluster around the best parameter settings, this was not observed. however, we were able to use the tbga to automatically determine better parameter settings for the cga. the resulting cga produced even better results than were achieved by the tbga which found those parameter settings.",
            "contribution_ids": [
                "R31186"
            ]
        },
        {
            "instance_id": "R31281xR31217",
            "comparison_id": "R31281",
            "paper_id": "R31217",
            "text": "When Fast-Growing Economies Slow Down: International Evidence and Implications for China using international data starting in 1957, we construct a sample of cases where fast-growing economies slow down. the evidence suggests that rapidly growing economies slow down significantly, in the sense that the growth rate downshifts by at least 2 percentage points, when their per capita incomes reach around us$ 17,000 in year-2005 constant international prices, a level that china should achieve by or soon after 2015. among our more provocative findings is that growth slowdowns are more likely in countries that maintain undervalued real exchange rates.",
            "contribution_ids": [
                "R31218",
                "R31263"
            ]
        },
        {
            "instance_id": "R31281xR31224",
            "comparison_id": "R31281",
            "paper_id": "R31224",
            "text": "Tracking the Middle-Income Trap: What is it, Who is in it, and Why? this paper provides a working definition of what the middle-income trap is. we start by defining four income groups of gdp per capita in 1990 ppp dollars: low-income below $2,000; lower-middle-income between $2,000 and $7,250; upper-middle-income between $7,250 and $11,750; and high-income above $11,750. we then classify 124 countries for which we have consistent data for 1950\u20132010. in 2010, there were 40 low-income countries in the world, 38 lower-middle-income, 14 upper-middle-income, and 32 high-income countries. then we calculate the threshold number of years for a country to be in the middle-income trap: a country that becomes lower-middle-income (i.e., that reaches $2,000 per capita income) has to attain an average growth rate of per capita income of at least 4.7 percent per annum to avoid falling into the lower-middle-income trap (i.e., to reach $7,250, the upper-middle-income threshold); and a country that becomes upper-middle-income (i.e., that reaches $7,250 per capita income) has to attain an average growth rate of per capita income of at least 3.5 percent per annum to avoid falling into the upper-middle-income trap (i.e., to reach $11,750, the high-income level threshold). avoiding the middle-income trap is, therefore, a question of how to grow fast enough so as to cross the lower-middle-income segment in at most 28 years, and the upper-middle-income segment in at most 14 years. finally, the paper proposes and analyzes one possible reason why some countries get stuck in the middle-income trap: the role played by the changing structure of the economy (from low-productivity activities into high-productivity activities), the types of products exported (not all products have the same consequences for growth and development), and the diversification of the economy. we compare the exports of countries in the middle-income trap with those of countries that graduated from it, across eight dimensions that capture different aspects of a country\u2019s capabilities to undergo structural transformation, and test whether they are different. results indicate that, in general, they are different. we also compare korea, malaysia, and the philippines according to the number of products that each exports with revealed comparative advantage. we find that while korea was able to gain comparative advantage in a significant number of sophisticated products and was well connected, malaysia and the philippines were able to gain comparative advantage in electronics only.",
            "contribution_ids": [
                "R31225",
                "R31267"
            ]
        },
        {
            "instance_id": "R31669xR31536",
            "comparison_id": "R31669",
            "paper_id": "R31536",
            "text": "Application of fuzzy logic for state estimation of a microbial fermentation with dual inhibition and variable product kinetics. Food and Bioproducts Processing fuzzy logic has been applied to a batch microbial fermentation described by a model with two adjustable parameters which associate product formation with the increasing and/or stationary phases of cell growth. the fermentation is inhibited by its product and, beyond a critical concentration, also by the substrate. to mimic an industrial condition, gaussian noise was added and the resulting performance was simulated by fuzzy estimation systems. simple rules with a few membership functions were able to portray bioreactor performance and the feedback interactions between cell growth and the concentrations of substrate and product. through careful choices of the membership functions and the fuzzy logic, accuracies better than previously reported for ideal fermentations could be obtained, suggesting the suitability of fuzzy estimations for on-line applications.",
            "contribution_ids": [
                "R31537"
            ]
        },
        {
            "instance_id": "R31669xR31580",
            "comparison_id": "R31669",
            "paper_id": "R31580",
            "text": "Temperature control of a pilot plant reactor system using a genetic algorithm model-based control approach the work described in this paper aims at exploring the use of an artificial intelligence technique, i.e. genetic algorithm (ga), for designing an optimal model-based controller to regulate the temperature of a reactor. ga is utilized to identify the best control action for the system by creating possible solutions and thereby to propose the correct control action to the reactor system. this value is then used as the set point for the closed loop control system of the heat exchanger. a continuous stirred tank reactor is chosen as a case study, where the controller is then tested with multiple set-point tracking and changes in its parameters. the ga model-based control (gambc) is then implemented experimentally to control the reactor temperature of a pilot plant, where an irreversible exothermic chemical reaction is simulated by using the calculated steam flow rate. the dynamic behavior of the pilot plant reactor during the online control studies is highlighted, and comparison with the conventional tuned proportional integral derivative (pid) is presented. it is found that both controllers are able to control the process with comparable performance. copyright \u00a9 2007 curtin university of technology and john wiley & sons, ltd.",
            "contribution_ids": [
                "R31581"
            ]
        },
        {
            "instance_id": "R31669xR31599",
            "comparison_id": "R31669",
            "paper_id": "R31599",
            "text": "Melt index prediction based on fuzzy neural networks and PSO algorithm with online correction strategy a black-box modeling scheme to predict melt index (mi) in the industrial propylene polymerization process is presented. mi is one of the most important quality variables determining product specification, and is influenced by a large number of process variables. considering it is costly and time consuming to measure mi in laboratory, a much cheaper and faster statistical modeling method is presented here to predicting mi online, which involves technologies of fuzzy neural network, particle swarm optimization (pso) algorithm, and online correction strategy (ocs). the learning efficiency and prediction precision of the proposed model are checked based on real plant history data, and the comparison between different learning algorithms is carried out in detail to reveal the advantage of the proposed best-neighbor pso (bnpso) algorithm with ocs. \u00a9 2011 american institute of chemical engineers aiche j, 2012",
            "contribution_ids": [
                "R31600"
            ]
        },
        {
            "instance_id": "R31669xR31602",
            "comparison_id": "R31669",
            "paper_id": "R31602",
            "text": "Neural-fuzzy modelling of polymer quality in batch polymerization reactors the estimation of parameters and obtaining an accurate and comprehensive mathematical model of the polymerization process is of strategic importance to the control engineering purposes in the polymerization industry. it is characteristic for these processes a grate non-linearity and many difficulties applying traditional estimation techniques. this paper describes an approach based upon neural-fuzzy representation of the model. a concrete model is constructed with the sugeno fuzzy inference technique and a fuzzy-neural network is used to model the dynamic behavior of the polymer process. such neural-fuzzy models of polymer quality could be used successfully for optimization and control of polymerization processes. short example for such implementation is included with additional results for modeling of mn and mw.",
            "contribution_ids": [
                "R31603"
            ]
        },
        {
            "instance_id": "R31669xR31662",
            "comparison_id": "R31669",
            "paper_id": "R31662",
            "text": "A Fuzzy-based Adaptive Genetic Algorithm and Its Case Study in Chemical Engineering \u8003\u8651\u5230\u4e00\u4e2a\u57fa\u56e0\u7b97\u6cd5( ga )\u7684\u8868\u6f14\u88ab\u8bb8\u591a\u56e0\u7d20\u548c\u4ed6\u4eec\u7684\u5173\u7cfb\u5f71\u54cd\uff0c\u8fd9\u590d\u6742\u3001\u96be\u88ab\u63cf\u8ff0\uff0c\u4e00\u4e2a\u65b0\u5947\u6a21\u7cca\u5e95\u7684\u9002\u5e94\u57fa\u56e0\u7b97\u6cd5( faga )\u628a\u4e00\u4e2a\u65b0\u4eba\u5de5\u7684\u514d\u75ab\u7cfb\u7edf\u4e0e\u6a21\u7cca\u7cfb\u7edf\u7406\u8bba\u76f8\u7ed3\u5408\u7531\u4e8e\u6a21\u7cca\u7406\u8bba\u80fd\u63cf\u8ff0\u9ad8\u590d\u6742\u7684\u95ee\u9898\u7684\u4e8b\u5b9e\u88ab\u5efa\u8bae\u3002\u5728 faga\uff0c\u6709\u514d\u75ab\u529b\u7684\u7406\u8bba\u88ab\u7528\u6765\u6539\u8fdb\u9009\u62e9\u64cd\u4f5c\u7684\u8868\u6f14\u3002\u5e76\u4e14\uff0c\u8f6c\u7ebf\u8def\u6982\u7387\u548c\u53d8\u5316\u6982\u7387\u88ab\u6a21\u7cca\u63a8\u8bba\u52a8\u6001\u5730\u8c03\u6574\uff0c\u5b83\u6839\u636e\u5728\u7b97\u6cd5\u8868\u6f14\u548c\u63a7\u5236\u53c2\u6570\u4e4b\u95f4\u7684\u542f\u53d1\u5f0f\u7684\u6a21\u7cca\u5173\u7cfb\u88ab\u5f00\u53d1\u3002\u5b9e\u9a8c\u8bc1\u660e faga \u80fd\u9ad8\u6548\u5730\u514b\u670d ga \u7684\u7f3a\u70b9\uff0c\u5373\uff0c\u65e9\u719f\u5e76\u4e14\u6bd4\u4e8c\u5178\u578b\u6a21\u7cca\u6c14\u4f53\u51cf\u7f13\uff0c\u5e76\u4e14\u83b7\u5f97\u66f4\u597d\u7684\u7ed3\u679c\u3002\u6700\u540e\uff0c faga \u88ab\u7528\u4e8e\u53cd\u5e94\u52a8\u529b\u5b66\u6a21\u578b\u7684\u53c2\u6570\u8bc4\u4ef7\uff0c\u4ee4\u4eba\u6ee1\u610f\u7684\u7ed3\u679c\u88ab\u83b7\u5f97\u3002",
            "contribution_ids": [
                "R31663"
            ]
        },
        {
            "instance_id": "R31689xR31683",
            "comparison_id": "R31689",
            "paper_id": "R31683",
            "text": "A probabilistic active support vector learning algorithm the paper describes a probabilistic active learning strategy for support vector machine (svm) design in large data applications. the learning strategy is motivated by the statistical query model. while most existing methods of active svm learning query for points based on their proximity to the current separating hyperplane, the proposed method queries for a set of points according to a distribution as determined by the current separating hyperplane and a newly defined concept of an adaptive confidence factor. this enables the algorithm to have more robust and efficient learning capabilities. the confidence factor is estimated from local information using the k nearest neighbor principle. the effectiveness of the method is demonstrated on real-life data sets both in terms of generalization performance, query complexity, and training time.",
            "contribution_ids": [
                "R31684"
            ]
        },
        {
            "instance_id": "R31689xR31685",
            "comparison_id": "R31689",
            "paper_id": "R31685",
            "text": "Active learning using pre-clustering the paper is concerned with two-class active learning. while the common approach for collecting data in active learning is to select samples close to the classification boundary, better performance can be achieved by taking into account the prior data distribution. the main contribution of the paper is a formal framework that incorporates clustering into active learning. the algorithm first constructs a classifier on the set of the cluster representatives, and then propagates the classification decision to the other samples via a local noise model. the proposed model allows to select the most representative samples as well as to avoid repeatedly labeling samples in the same cluster. during the active learning process, the clustering is adjusted using the coarse-to-fine strategy in order to balance between the advantage of large clusters and the accuracy of the data representation. the results of experiments in image databases show a better performance of our algorithm compared to the current methods.",
            "contribution_ids": [
                "R31686"
            ]
        },
        {
            "instance_id": "R31689xR31672",
            "comparison_id": "R31689",
            "paper_id": "R31672",
            "text": "Support vector machine active learning with applications to text classification support vector machines have met with significant success in numerous real-world learning tasks. however, like most machine learning algorithms, they are generally applied using a randomly selected training set classified in advance. in many settings, we also have the option of using pool-based active learning. instead of using a randomly selected training set, the learner has access to a pool of unlabeled instances and can request the labels for some number of them. we introduce a new algorithm for performing active learning with support vector machines, i.e., an algorithm for choosing which instances to request next. we provide a theoretical motivation for the algorithm using the notion of a version space. we present experimental results showing that employing our active learning method can significantly reduce the need for labeled training instances in both the standard inductive and transductive settings.",
            "contribution_ids": [
                "R31673"
            ]
        },
        {
            "instance_id": "R31725xR31695",
            "comparison_id": "R31725",
            "paper_id": "R31695",
            "text": "Design Patterns in Software Maintenance: An Experiment Replication at Freie Universit\u00e4t Berlin \"an article published in 2001 reported a controlled experiment that compared maintenance of small programs using design patterns with maintenance of equivalent programs using simplified design solutions. a replication of that experiment was published in 2004. in 2010, a group of researchers from multiple countries picked this experiment as the subject of an attempt to perform a joint replication: many groups performing an experiment using the same setup, each contributing a few data points to a larger overall data set. this article reports on one of those sub-replications. only one of the results is statistically significant; it confirms the result of the original experiment stating that the simplified version of the gr program could be extended more quickly than the pattern version which used the abstract factory and composite patterns. the article's main contributions, however, are (a) its description of the peculiarities of this particular subdataset and (b) its (implicit) suggestions for possible evaluation methods.\"",
            "contribution_ids": [
                "R31696"
            ]
        },
        {
            "instance_id": "R31725xR31699",
            "comparison_id": "R31725",
            "paper_id": "R31699",
            "text": "Design Patterns in Software Maintenance: An Experiment Replication at University of Alabama design patterns are widely used within the software engineer community. researchers claim that design patterns improve software quality. in this paper, we describe two experiments, using graduate student participants, to study whether design patterns improve the software quality, specifically maintainability and understandability. we replicated a controlled experiment to compare the maintainability of two implementations of an application, one using a design pattern and the other using a simpler alternative. the maintenance tasks in this replication experiment required the participants to answer questions about a java program and then modify that program. prior to the replication, we performed a preliminary exercise to investigate whether design patterns improve the understandability of software designs. we gave the participants the graphical design of the systems that would be used in the replication study. the participant received either the version of the design containing the design pattern or the version containing the simpler alternative. we asked the participants a series of questions to see how well they understood the given design. the results of two experiments revealed that the design patterns did not improve either the maintainability or the understandability of the software. we found that there was no significant correlation between the maintainability and the understandability of the software even though the participants had received the design of the systems before they performed the maintenance tasks.",
            "contribution_ids": [
                "R31700"
            ]
        },
        {
            "instance_id": "R31725xR31705",
            "comparison_id": "R31725",
            "paper_id": "R31705",
            "text": "Impact of the visitor pattern on program comprehension and maintenance in the software engineering literature, many works claim that the use of design patterns improves the comprehensibility of programs and, more generally, their maintainability. yet, little work attempted to study the impact of design patterns on the developers' tasks of program comprehension and modification. we design and perform an experiment to collect data on the impact of the visitor pattern on comprehension and modification tasks with class diagrams. we use an eye-tracker to register saccades and fixations, the latter representing the focus of the developers' attention. collected data show that the visitor pattern plays a role in maintenance tasks: class diagrams with its canonical representation requires less efforts from developers.",
            "contribution_ids": [
                "R31706"
            ]
        },
        {
            "instance_id": "R31725xR31723",
            "comparison_id": "R31725",
            "paper_id": "R31723",
            "text": "Design patterns and fault-proneness a study of commercial C# software in this paper, we document a study of design patterns in commercial, proprietary software and determine whether design pattern participants (i.e. the constituent classes of a pattern) had a greater propensity for faults than non-participants. we studied a commercial software system for a 24 month period and identified design pattern participants by inspecting the design documentation and source code; we also extracted fault data for the same period to determine whether those participant classes were more fault-prone than non-participant classes. results showed that design pattern participant classes were marginally more fault-prone than non-participant classes, the adaptor, method and singleton patterns were found to be the most fault-prone of thirteen patterns explored. however, the primary reason for this fault-proneness was the propensity of design classes to be changed more often than non-design pattern classes.",
            "contribution_ids": [
                "R31724"
            ]
        },
        {
            "instance_id": "R31768xR31749",
            "comparison_id": "R31768",
            "paper_id": "R31749",
            "text": "Survival of Campylobacter jejuni in Frozen Chicken Meat and Genetic Analysis of Isolates by Pulsed-Field Gel Electrophoresis \u5e02\u8ca9\u9d8f\u8089\u306e\u30ab\u30f3\u30d4\u30ed\u30d0\u30af\u30bf\u30fc\u6c5a\u67d3\u8abf\u67fb\u3092\u884c\u3063\u305f\u3068\u3053\u308d, 100\u691c\u4f53\u4e2d49\u691c\u4f53 (49.0%) \u304ccampylobacter jejuni\u967d\u6027\u3067\u3042\u3063\u305f.\u305d\u306e49\u691c\u4f53\u306b\u3064\u3044\u3066, \u51b7\u51cd\u4fdd\u5b58\u306b\u3088\u308b\u9d8f\u8089\u4e2d\u306ecampylobacter\u83cc\u6570\u306e\u5909\u5316\u3092mpn\u6cd5\u306b\u3088\u308a\u8abf\u67fb\u3057\u305f\u3068\u3053\u308d, -20\u2103, 7\u65e5\u9593\u4fdd\u5b58\u5f8c\u306e\u83cc\u6570\u306f\u4fdd\u5b58\u524d\u306e\u691c\u4f53\u306b\u6bd4\u3079\u30661/10\uff5e1/100\u306b\u6e1b\u5c11\u3057, 25/49\u691c\u4f53 (51.0%) \u3067\u306f\u691c\u51fa\u9650\u754c\u672a\u6e80 (mpn\u5024<15/100g) \u3068\u306a\u3063\u305f.pfge\u6cd5\u306b\u3088\u308a\u5206\u96e2\u83cc\u682a\u306e\u907a\u4f1d\u5b50\u89e3\u6790\u3092\u884c\u3063\u305f\u3068\u3053\u308d, \u5e02\u8ca9\u9d8f\u8089\u306f\u5358\u4e00\u3067\u306f\u306a\u304f\u8907\u6570\u306e\u907a\u4f1d\u5b50\u578b\u306e\u83cc\u306b\u3088\u3063\u3066\u6c5a\u67d3\u3055\u308c\u3066\u3044\u308b\u3053\u3068\u304c\u793a\u5506\u3055\u308c, \u307e\u305f, 8/24\u691c\u4f53 (33.3%) \u306b\u304a\u3044\u3066, \u51b7\u51cd\u4fdd\u5b58\u524d\u5f8c\u3067\u7570\u306a\u308b\u907a\u4f1d\u5b50\u578b\u306e\u83cc\u304c\u5206\u96e2\u3055\u308c\u305f.\u3053\u306e\u305f\u3081, \u98df\u4e2d\u6bd2\u4e8b\u4ef6\u306e\u539f\u56e0\u7a76\u660e\u306e\u305f\u3081\u306b\u306f, \u98df\u54c1\u691c\u4f53\u304b\u3089\u3067\u304d\u308b\u3060\u3051\u591a\u304f\u306e\u83cc\u682a\u3092\u5206\u96e2\u3057, \u907a\u4f1d\u5b50\u89e3\u6790\u3092\u884c\u3046\u5fc5\u8981\u6027\u304c\u3042\u308b\u3053\u3068\u304c\u8003\u3048\u3089\u308c\u305f.\u9d8f\u8089\u3078\u306ec. jejuni\u63a5\u7a2e\u8a66\u9a13\u3067\u306f, \u89e3\u51cd\u305b\u305a\u306b\u51cd\u7d50\u72b6\u614b\u3067\u4fdd\u5b58\u3057\u305f\u691c\u4f53\u3067\u306f, \u51cd\u7d50\u30fb\u89e3\u51cd\u3092\u7e70\u308a\u8fd4\u3057\u305f\u3082\u306e\u3088\u308a\u3082\u83cc\u6570\u306e\u6e1b\u5c11\u304c\u308f\u305a\u304b\u3067\u3042\u3063\u305f\u3053\u3068\u304b\u3089, \u83cc\u306e\u6b7b\u6ec5\u306f\u4e3b\u306b\u51cd\u7d50\u6642\u3042\u308b\u3044\u306f\u89e3\u51cd\u6642\u306b\u8d77\u3053\u308b\u3053\u3068\u304c\u793a\u5506\u3055\u308c\u305f.",
            "contribution_ids": [
                "R31750"
            ]
        },
        {
            "instance_id": "R31809xR31771",
            "comparison_id": "R31809",
            "paper_id": "R31771",
            "text": "MSAP markers and global cytosine methylation in plants: a literature survey and comparative analysis for a wild-growing species methylation of dna cytosines affects whether transposons are silenced and genes are expressed, and is a major epigenetic mechanism whereby plants respond to environmental change. analyses of methylation\u2010sensitive amplification polymorphism (ms\u2010aflp or msap) have been often used to assess methyl\u2010cytosine changes in response to stress treatments and, more recently, in ecological studies of wild plant populations. msap technique does not require a sequenced reference genome and provides many anonymous loci randomly distributed over the genome for which the methylation status can be ascertained. scoring of msap data, however, is not straightforward, and efforts are still required to standardize this step to make use of the potential to distinguish between methylation at different nucleotide contexts. furthermore, it is not known how accurately msap infers genome\u2010wide cytosine methylation levels in plants. here, we analyse the relationship between msap results and the percentage of global cytosine methylation in genomic dna obtained by hplc analysis. a screening of literature revealed that methylation of cytosines at cleavage sites assayed by msap was greater than genome\u2010wide estimates obtained by hplc, and percentages of methylation at different nucleotide contexts varied within and across species. concurrent hplc and msap analyses of dna from 200 individuals of the perennial herb helleborus foetidus confirmed that methyl\u2010cytosine was more frequent in ccgg contexts than in the genome as a whole. in this species, global methylation was unrelated to methylation at the inner cg site. we suggest that global hplc and context\u2010specific msap methylation estimates provide complementary information whose combination can improve our current understanding of methylation\u2010based epigenetic processes in nonmodel plants.",
            "contribution_ids": [
                "R31772"
            ]
        },
        {
            "instance_id": "R31809xR31776",
            "comparison_id": "R31809",
            "paper_id": "R31776",
            "text": "Genetic and DNA methylation changes in cotton (Gossypium) genotypes and tissues in plants, epigenetic regulation is important in normal development and in modulating some agronomic traits. the potential contribution of dna methylation mediated gene regulation to phenotypic diversity and development in cotton was investigated between cotton genotypes and various tissues. dna methylation diversity, genetic diversity, and changes in methylation context were investigated using methylation-sensitive amplified polymorphism (msap) assays including a methylation insensitive enzyme (bsisi), and the total dna methylation level was measured by high-performance liquid chromatography (hplc). dna methylation diversity was greater than the genetic diversity in the selected cotton genotypes and significantly different levels of dna methylation were identified between tissues, including fibre. the higher dna methylation diversity (chg methylation being more diverse than cg methylation) in cotton genotypes suggest epigenetic regulation may be important for cotton, and the change in dna methylation between fibre and other tissues hints that some genes may be epigenetically regulated for fibre development. the novel approach using bsisi allowed direct comparison between genetic and epigenetic diversity, and also measured cc methylation level that cannot be detected by conventional msap.",
            "contribution_ids": [
                "R31777",
                "R31779"
            ]
        },
        {
            "instance_id": "R31878xR31819",
            "comparison_id": "R31878",
            "paper_id": "R31819",
            "text": "Large-scale gasification-based coproduction of fuels and electricity from switchgrass large\u2010scale gasification\u2010based systems for producing fischer\u2010tropsch (f\u2010t) fuels (diesel and gasoline blendstocks), dimethyl ether (dme), or hydrogen from switchgrass \u2013 with electricity as a coproduct in each case are assessed using a self\u2010consistent design, simulation, and cost analysis framework. we provide an overview of alternative process designs for coproducing these fuels and power assuming commercially mature technology performance and discuss the commercial status of key component technologies. overall efficiencies (lower\u2010heating\u2010value basis) of producing fuels plus electricity in these designs ranges from 57% for f\u2010t fuels, 55\u201361% for dme, and 58\u201364% for hydrogen. detailed capital cost estimates for each design are developed, on the basis of which prospective commercial economics of future large\u2010scale facilities that coproduce fuels and power are evaluated. \u00a9 2009 society of chemical industry and john wiley & sons, ltd",
            "contribution_ids": [
                "R31820"
            ]
        },
        {
            "instance_id": "R31928xR31921",
            "comparison_id": "R31928",
            "paper_id": "R31921",
            "text": "Technoeconomic analysis of a lignocellulosic biomass indirect gasification process to make ethanol via mixed alcohols synthesis a technoeconomic analysis of a 2000 tonne/day lignocellulosic biomass conversion process to make mixed alcohols via gasification and catalytic synthesis was completed. the process, modeled using aspen plus process modeling software for mass and energy calculations, included all major process steps to convert biomass into liquid fuels, including gasification, gas cleanup and conditioning, synthesis conversion to mixed alcohols, and product separation. the gas cleanup area features a catalytic fluidized-bed steam reformer to convert tars and hydrocarbons into syngas. conversions for both the reformer and the synthesis catalysts were based on research targets expected to be achieved by 2012 through ongoing research. the mass and energy calculations were used to estimate capital and operating costs that were used in a discounted cash flow rate of return analysis for the process to calculate a minimum ethanol selling price of $0.267/l ($1.01/gal) ethanol (u.s.$2005).",
            "contribution_ids": [
                "R31922"
            ]
        },
        {
            "instance_id": "R32025xR31995",
            "comparison_id": "R32025",
            "paper_id": "R31995",
            "text": "Comparative analysis of the production costs and life-cycle GHG emissions of FT liquid fuels from coal and natural Gas liquid transportation fuels derived from coal and natural gas could helpthe united states reduce its dependence on petroleum. the fuels could be produced domestically or imported from fossil fuel-rich countries. the goal of this paper is to determine the life-cycle ghg emissions of coal- and natural gas-based fischer-tropsch (ft) liquids, as well as to compare production costs. the results show that the use of coal- or natural gas-based ft liquids will likely lead to significant increases in greenhouse gas (ghg) emissions compared to petroleum-based fuels. in a best-case scenario, coal- or natural gas-based ft-liquids have emissions only comparable to petroleum-based fuels. in addition, the economic advantages of gas-to-liquid (gtl) fuels are not obvious: there is a narrow range of petroleum and natural gas prices at which gtl fuels would be competitive with petroleum-based fuels. ctlfuels are generally cheaper than petroleum-based fuels. however, recent reports suggest there is uncertainty about the availability of economically viable coal resources in the united states. if the u.s. has a goal of increasing its energy security, and at the same time significantly reducing its ghg emissions, neither ctl nor gtl consumption seem a reasonable path to follow.",
            "contribution_ids": [
                "R31996"
            ]
        },
        {
            "instance_id": "R32061xR32046",
            "comparison_id": "R32061",
            "paper_id": "R32046",
            "text": "Topic-bridged PLSA for cross-domain text classification in many web applications, such as blog classification and new-sgroup classification, labeled data are in short supply. it often happens that obtaining labeled data in a new domain is expensive and time consuming, while there may be plenty of labeled data in a related but different domain. traditional text classification ap-proaches are not able to cope well with learning across different domains. in this paper, we propose a novel cross-domain text classification algorithm which extends the traditional probabilistic latent semantic analysis (plsa) algorithm to integrate labeled and unlabeled data, which come from different but related domains, into a unified probabilistic model. we call this new model topic-bridged plsa, or tplsa. by exploiting the common topics between two domains, we transfer knowledge across different domains through a topic-bridge to help the text classification in the target domain. a unique advantage of our method is its ability to maximally mine knowledge that can be transferred between domains, resulting in superior performance when compared to other state-of-the-art text classification approaches. experimental eval-uation on different kinds of datasets shows that our proposed algorithm can improve the performance of cross-domain text classification significantly.",
            "contribution_ids": [
                "R32047"
            ]
        },
        {
            "instance_id": "R32061xR32052",
            "comparison_id": "R32061",
            "paper_id": "R32052",
            "text": "Estimating class priors in domain adaptation for word sense disambiguation instances of a word drawn from different domains may have different sense priors (the proportions of the different senses of a word). this in turn affects the accuracy of word sense disambiguation (wsd) systems trained and applied on different domains. this paper presents a method to estimate the sense priors of words drawn from a new domain, and highlights the importance of using well calibrated probabilities when performing these estimations. by using well calibrated probabilities, we are able to estimate the sense priors effectively to achieve significant improvements in wsd accuracy.",
            "contribution_ids": [
                "R32053"
            ]
        },
        {
            "instance_id": "R32061xR32055",
            "comparison_id": "R32061",
            "paper_id": "R32055",
            "text": "Domain adaptation via pseudo in-domain data selection we explore efficient domain adaptation for the task of statistical machine translation based on extracting sentences from a large general-domain parallel corpus that are most relevant to the target domain. these sentences may be selected with simple cross-entropy based methods, of which we present three. as these sentences are not themselves identical to the in-domain data, we call them pseudo in-domain subcorpora. these subcorpora -- 1% the size of the original -- can then used to train small domain-adapted statistical machine translation (smt) systems which outperform systems trained on the entire corpus. performance is further improved when we use these domain-adapted models in combination with a true in-domain model. the results show that more training data is not always better, and that best results are attained via proper domain-relevant data selection, as well as combining in- and general-domain systems during decoding.",
            "contribution_ids": [
                "R32056"
            ]
        },
        {
            "instance_id": "R32189xR32073",
            "comparison_id": "R32189",
            "paper_id": "R32073",
            "text": "A Genetics-based hybrid scheduler for generating static schedules in flexible manufacturing contexts \"existing computerized systems that support scheduling decisions for flexible manufacturing systems (fms's) rely largely on knowledge acquired through rote learning for schedule generation. in a few instances, the systems also possess some ability to learn using deduction or supervised induction. we introduce a novel ai-based system for generating static schedules that makes heavy use of an unsupervised learning module in acquiring significant portions of the requisite problem processing knowledge. this scheduler pursues a hybrid schedule generation strategy wherein it effectively combines knowledge acquired via genetics-based unsupervised induction with rote-learned knowledge in generating high-quality schedules in an efficient manner. through a series of experiments conducted on a randomly generated problem of practical complexity, we show that the hybrid scheduler strategy is viable, promising, and, worthy of more in-depth investigations. >\"",
            "contribution_ids": [
                "R32074"
            ]
        },
        {
            "instance_id": "R32189xR32091",
            "comparison_id": "R32189",
            "paper_id": "R32091",
            "text": "Genetically tuned fuzzy scheduling for flexible manufacturing systems this paper focuses on the development and implementation of a genetically tuned fuzzy scheduler (gtfs) for heterogeneous fms under uncertainty. the scheduling system takes input from a table and creates an optimum master schedule. the gtfs uses fuzzy rulebase and inferencing where fuzzy sets are generated by a genetic algorithm to tune the optimization. the fuzzy optimization is based on time criticality in deadline and machine need, taking into account machine availability, uniformity, process time and selectability.",
            "contribution_ids": [
                "R32092"
            ]
        },
        {
            "instance_id": "R32189xR32101",
            "comparison_id": "R32189",
            "paper_id": "R32101",
            "text": "Petri Net based modeling and GA based scheduling for a flexible manufacturing system in this paper, a genetic algorithm (ga) embedded adaptive scheduling over a timed place petri net (tppn) model provides a new method for a flexible manufacturing system (fms). the chromosome representation of the search nodes is constructed directly from the tppn model of an fms. a tppn based schedule builder receives a chromosome and an initial marking as input, and then produces a near-optimal schedule.",
            "contribution_ids": [
                "R32102"
            ]
        },
        {
            "instance_id": "R32189xR32105",
            "comparison_id": "R32189",
            "paper_id": "R32105",
            "text": "Dynamic scheduling of FMS using a real-time genetic algorithm the paper presents a genetic algorithm capable of generating optimised production plans in flexible manufacturing systems. the ability of the system to generate alternative plans following part-flow changes and unforeseen situations is particularly stressed (dynamic scheduling). two contrasting objectives represented by the reduction of machine idle-times, thanks to dynamic scheduling computation and the reduction of the makespan, are taken into account by the proposed system. the key-point is the real-time response obtained by an optimised evolutionary strategy capable of minimising the number of genetic operations needed to reach the optimal schedule in complex manufacturing systems.",
            "contribution_ids": [
                "R32106"
            ]
        },
        {
            "instance_id": "R32189xR32142",
            "comparison_id": "R32189",
            "paper_id": "R32142",
            "text": "A pareto based multi-objective genetic algorithm for scheduling of FMS many real-world engineering and scientific problems involve simultaneous optimization of multiple objectives that often are competing. in this work, we have addressed issues relating to scheduling with multiple (and competing) objectives of flexible manufacturing system (fms) and have developed a mechanism by employing a pareto based ga to generate nearer optimal schedules. in the proposed method we have applied pareto ranking to identify the elite solutions and their fitness values are derated using fitness sharing method. the procedure is evaluated with sample problem environment found in literature and results are compared with other available heuristics found in literature. the proposed niched pareto genetic algorithm (npga) exhibits a superiority over the other heuristics and scheduling rules",
            "contribution_ids": [
                "R32143"
            ]
        },
        {
            "instance_id": "R32189xR32160",
            "comparison_id": "R32189",
            "paper_id": "R32160",
            "text": "Application of genetic algorithms with dominant genes in a distributed scheduling problem in flexible manufacturing systems multi-factory production networks have increased in recent years. with the factories located in different geographic areas, companies can benefit from various advantages, such as closeness to their customers, and can respond faster to market changes. products (jobs) in the network can usually be produced in more than one factory. however, each factory has its operations efficiency, capacity, and utilization level. allocation of jobs inappropriately in a factory will produce high cost, long lead time, overloading or idling resources, etc. this makes distributed scheduling more complicated than classical production scheduling problems because it has to determine how to allocate the jobs into suitable factories, and simultaneously determine the production scheduling in each factory as well. the problem is even more complicated when alternative production routing is allowed in the factories. this paper proposed a genetic algorithm with dominant genes to deal with distributed scheduling problems, especially in a flexible manufacturing system (fms) environment. the idea of dominant genes is to identify and record the critical genes in the chromosome and to enhance the performance of genetic search. to testify and benchmark the optimization reliability, the proposed algorithm has been compared with other approaches on several distributed scheduling problems. these comparisons demonstrate the importance of distributed scheduling and indicate the optimization reliability of the proposed algorithm.",
            "contribution_ids": [
                "R32161"
            ]
        },
        {
            "instance_id": "R32189xR32168",
            "comparison_id": "R32189",
            "paper_id": "R32168",
            "text": "Multi-objective Genetic Algorithm for Multistage-based Job Processing Schedules in FMS Environment in this paper, we propose a multi-objective genetic algorithm for effectively solving multistage-based job processing schedules in fms environment. the proposed method is random-weight approach to obtaining a variable search direction toward pareto solution. the objectives are to minimize the makespan and the total flow time, simultaneously. the feasibility and adaptability of the proposed moga are investigated through experimental results.",
            "contribution_ids": [
                "R32169"
            ]
        },
        {
            "instance_id": "R32189xR32182",
            "comparison_id": "R32189",
            "paper_id": "R32182",
            "text": "Appropriate evolutionary algorithm for scheduling in FMS the diffusion of flexible manufacturing systems (fms) has not only invigorated production systems, but has also given considerable impetus to relevant analytical fields like scheduling theory and adaptive controls. depending on the demand of the job there can be variation in batch size. the change in the jobs depends upon the renewal rate. but this does not involve much change in the fms setup. this paper obtains an optimal schedule of operations to minimize the total processing time in a modular fms. the fms setup considered here consists of four numbers of machines to accomplish the desired machining operations. the scheduling deals with optimizing the cost function in terms of machining time. the powers evolutionary algorithms, like genetic algorithm (ga) and simulated annealing (sa), can be beneficially utilized for optimization of scheduling fms. the present work utilizes these powerful approaches and finds out their appropriateness for planning and scheduling of fms producing variety of parts in batch mode.",
            "contribution_ids": [
                "R32183"
            ]
        },
        {
            "instance_id": "R32424xR32210",
            "comparison_id": "R32424",
            "paper_id": "R32210",
            "text": "Extraction by Steam Distillation ofArtemisia herba-albsEssential Oil from Algeria: Kinetic Study and Optimization of the Operating Conditions abstract in order to study the extraction process of essential oil from artemisia herba-alba, kinetic studies as well as an optimization of the operating conditions were achieved. the optimization was carried out by a parametric study and experiments planning method. three operational parameters were chosen: artemisia mass to be treated, steam flow rate and extraction time. the optimal extraction conditions obtained by the parametric study correspond to: a mass of 30 g, a steam flow rate of 1.65 ml.min\u22121 and the extraction time of 60 min. the results reveal that the combined effects of two parameters, the steam water flow rate and the extraction time, are the most significant. the yield is also affected by the interaction of the three parameters. the essential oil obtained with optimal conditions was analyzed by gc-ms and a kinetic study was realised.",
            "contribution_ids": [
                "R32211"
            ]
        },
        {
            "instance_id": "R32424xR32233",
            "comparison_id": "R32424",
            "paper_id": "R32233",
            "text": "Fungicidal Activity of Artemisia herba alba Asso (Asteraceae) the antifungal activity of artemisia herba alba was found to be associated with two major volatile compounds isolated from the fresh leaves of the plant. carvone and piperitone were isolated and identified by gc/ms, gc/ir, and nmr spectroscopy. antifungal activity was measured against penicillium citrinum (atcc 10499) and mucora rouxii (atcc 24905). the antifungal activity (ic50) of the purified compounds was estimated to be 5 \u03bc g/ml, 2 \u03bc g/ml against penicillium citrinum and 7 \u03bc g/ml, 1.5 \u03bc g/ml against mucora rouxii carvone and piperitone, respectively.",
            "contribution_ids": [
                "R32234"
            ]
        },
        {
            "instance_id": "R32424xR32258",
            "comparison_id": "R32424",
            "paper_id": "R32258",
            "text": "Chemovariation ofArtemisia herba albaAsso. Aromatic Plants of the Holy Land and the Sinai. Part XVI. abstract in continuation of our investigation of aromatic flora of the holy land, the systematic study of artemisia herba alba essential oils has been conducted. the detailed composition of five relatively rare chemotypes of a. herba alba obtained through gc and gc/ms analysis are presented. to ensure the integrity of each chemotype the volatiles were extracted from individual plant specimens and bulked only if the gc profiles were substantially similar. the major constituents were: type 1: 1,8 cineole (10.8%), \u03b1-thujone (40.9%) and \u03b2-thujone (34.9%); type 2: 1,8 cineole (26.0%) and camphor (42.1%); type 3; 1,8 cineole (26.6%) and \u03b2-thujone (44.0%); type 4: cis-chrysanthenyl acetate (8.9%) and cis-chrysanthenol (30.0%); type 5: cis-chysanthenol (6.8%) and cis-chrysanthenyl acetate (69.0%). this study showed that the population of a. herba alba in israel consists of a much greater number of chemovarieties than was previously believed. though chemovarieties are unevenly distributed in different geographic areas, no clear relation between the plant type and environmental conditions could be established.",
            "contribution_ids": [
                "R32259"
            ]
        },
        {
            "instance_id": "R32424xR32277",
            "comparison_id": "R32424",
            "paper_id": "R32277",
            "text": "APPLICATION OF ESSENTIAL OIL OF ARTEMISIA HERBA ALBA AS GREEN CORROSION INHIBITOR FOR STEEL IN 0.5 M H2SO4 essential oil from artemisia herba alba (art) was hydrodistilled and tested as corrosion inhibitor of steel in 0.5 m h 2 so 4 using weight loss measurements and electrochemical polarization methods. results gathered show that this natural oil reduced the corrosion rate by the cathodic action. its inhibition efficiency attains the maximum (74%) at 1 g/l. the inhibition efficiency of arm oil increases with the rise of temperature. the adsorption isotherm of natural product on the steel has been determined. a. herba alba essential oil was obtained by hydrodistillation and its chemical composition oil was investigated by capillary gc and gc/ms. the major components were chrysanthenone (30.6%) and camphor (24.4%).",
            "contribution_ids": [
                "R32278"
            ]
        },
        {
            "instance_id": "R32424xR32330",
            "comparison_id": "R32424",
            "paper_id": "R32330",
            "text": "Chemical composition, mutagenic and antimutagenic activities of essential oils from (Tunisian) Artemisia campestris and Artemisia herba-alba abstract the essential oil composition from the aerial parts of artemisia campestris var. glutinosa gay ex bess and artemisia herba-alba asso (asteraceae) of tunisian origin has been studied by gc and gc/ms. the main constituents of the oil from a. campestris collected in benguerdane (south of tunisia) were found to be \u03b2-pinene (41.0%), p-cymene (9.9%), \u03b1-terpinene (7.9%), limonene (6.5%), myrcene (4.1%), \u03b2-phellandrene (3.4%) and a-pinene (3.2%). whereas the oil from a. herba-alba collected in tataouine (south of tunisia) showed, pinocarvone (38.3%), a-copaene (12.18%), limonene (11.0%), isoamyl2-methylbutyrate (19.5%) as major compounds. the mutagenic and antimutagenic activities of the two oils were investigated by the salmonella typhimurium/microsome assay, with and without addition of an extrinsic metabolic activation system. the oils showed no mutagenicity when tested with salmonella typhimurium strains ta98 and ta97. on the other hand, we showed that each oil had antimutagenic activity against the carcinogen benzo (a) pyrene (b[a] p) when tested with ta97 and ta98 assay systems.",
            "contribution_ids": [
                "R32331"
            ]
        },
        {
            "instance_id": "R32424xR32361",
            "comparison_id": "R32424",
            "paper_id": "R32361",
            "text": "Influence of drying time and process on Artemisia herba-alba Asso essential oil yield and composition abstract the essential oil content of artemisia herba-alba asso decreased along the drying period from 2.5 % to 1.8 %. conversely, the composition of the essential oil was not qualitatively affected by the drying process. the same principle components were found in all essential analyzed such as \u03b1-thujone (13.0 \u2013 22.7 %), \u03b2-thujone (18.0 \u2013 25.0 %), camphor (8.6 - 13 %), 1,8-cineole (7.1 \u2013 9.4 %), chrysanthenone (6.7 \u2013 10.9 %), terpinen-4-ol (3.4 \u2013 4.7 %). quantitatively, during the air-drying process, the content of some components decreased slightly such as \u03b1-thujone (from 22.7 to 15.9 %) and 1,8-cineole (from 9.4 to 7.1 %), while the amount of other compounds increased such as chrysanthenone (from 6.7 to 10.9 %), borneol (from 0.8 to 1.5 %), germacrene-d (from 1.0 to 2.4 %) and spathulenol (from 0.8 to 1.5 %). the chemical composition of the oil was more affected by oven-drying the plant material at 35\u00b0c. \u03b1-thujone and \u03b2-thujone decreased to 13.0 %and 18.0 %respectively, while the percentage of camphor, germacrene-d and spathulenol increased to 13.0 %, 5.5 %and 3.7 %, respectively.",
            "contribution_ids": [
                "R32362"
            ]
        },
        {
            "instance_id": "R32541xR32446",
            "comparison_id": "R32541",
            "paper_id": "R32446",
            "text": "\u00c2\u00abOvereducation, Undereducation, and the Theory of Career Mobility the theory of career mobility (sicherman and galor, journal of political economy, 98(1), 169\u201392, 1990) claims that wage penalties for overeducated workers are compensated by better promotion prospects. sicherman (journal of labour economics, 9(2), 101\u201322, 1991) was able to confirm this theory in an empirical study using panel data. however, the only retest using panel data so far (robst, eastern economic journal, 21, 539\u201350, 1995) produced rather ambiguous results. in the present paper, random effects models to analyse relative wage growth are estimated using data from the german socio-economic panel. it is found that overeducated workers in germany have markedly lower relative wage growth rates than adequately educated workers. the results cast serious doubt on whether the career mobility model is able to explain overeducation in germany. the plausibility of the results is supported by the finding that overeducated workers have less access to formal and informal on-the-job training, which is usually found to be positively correlated with wage growth even when controlling for selectivity effects (pischke, journal of population economics, 14, 523\u201348, 2001).",
            "contribution_ids": [
                "R32447"
            ]
        },
        {
            "instance_id": "R32541xR32451",
            "comparison_id": "R32541",
            "paper_id": "R32451",
            "text": "The Social and Political Consequences of Overeducation this study employs national survey data to estimate the extent of overeducation in the u.s. labor force and its impact on a variety of worker attitudes. estimates are made of the extent of overeducation and its distribution among different categories of workers, according to sex, race, age, and class background. the effects of overeducation are examined in four areas of worker attitudes: job satisfaction, political leftism, political alienation, and stratification ideology. evidence is found of significant effects of overeducation on job satisfaction and several aspects of stratification ideology. the magnitude of these effects is small, however, and they are concentrated almost exclusively among very highly overeducated workers. no evidence is found of generalized political effects of overeducation, either in the form of increased political leftism or in the form of increased political alienation. these findings fail to support the common prediction of major political repercussions of overeducation and suggest the likelihood of alternative forms of adaptation among overeducated workers.",
            "contribution_ids": [
                "R32452"
            ]
        },
        {
            "instance_id": "R32541xR32502",
            "comparison_id": "R32541",
            "paper_id": "R32502",
            "text": "OPTIMAL \u00e2\u0080\u0098MISMATCH\u00e2\u0080\u0099 AND PROMOTIONS \"seeming 'mismatches,' in which workers are either under- or overqualified, are shown to be optimal. from the firm's point of view, although turnover will be positively related to overqualification, training costs will be inversely related to overqualification. further, overqualified workers constitute a pool from which promotions are made. workers enter seeming mismatches due to search and mobility costs and because of opportunities for promotion. estimates using a unique data set indicate that workers who are overqualified at hire receive less training and more promotions and that workers overqualified for their current job are more likely to quit. copyright 1995 by oxford university press.\"",
            "contribution_ids": [
                "R32503"
            ]
        },
        {
            "instance_id": "R32541xR32524",
            "comparison_id": "R32541",
            "paper_id": "R32524",
            "text": "The Impact of Surplus Schooling on Productivity and Earnings \"this article examines the impact of surplus schooling on individual productivity and earnings. it proposes a model that divides workers' education into two components: education that is required and thus fully utilized in the job, and education that exceeds the amount required and thus may be underutilized in the job. the model is tested with data from the 1969, 1973, and 1977 quality of working life surveys (quinn and staines 1979). required schooling for each occupation is derived from estimates by job incumbents and by the dictionary of occupational titles. the results show that surplus or underutilized education is rewarded at a lower rate than required education, with the actual return dependent on the type of job.\"",
            "contribution_ids": [
                "R32525"
            ]
        },
        {
            "instance_id": "R32541xR32526",
            "comparison_id": "R32541",
            "paper_id": "R32526",
            "text": "A Theory of Career Mobility \"this paper analyzes theoretically and empirically the role and significance of occupational mobility in the labor market focusing on individuals' careers. it provides additional dimensions to the analysis of investment in human capital, wage differences across individuals, and the relationships among promotions, quits, and interfirm occupational mobility. it is shown that part of the returns to education is in the form of higher probabilities of occupational upgrading, within or across firms. given an origin occupation, schooling increases the likelihood of occupational upgrading. furthermore, workers who are not promoted despite a high probability of promotion are more likely to quit.\"",
            "contribution_ids": [
                "R32527"
            ]
        },
        {
            "instance_id": "R32541xR32535",
            "comparison_id": "R32541",
            "paper_id": "R32535",
            "text": "The Impact of Surplus Schooling on Worker Productivity \"human capital theory suggests that education enhances worker productivity and is reflected in higher individual earnings. we use data from the 1969 survey of working conditions and the 1973 and 1977 quality of employment surveys, and a model derived from the industrial psychology literature, to test the proposition that workers' education in excess of what their jobs require can have adverse effects on job satisfaction and other correlates of worker productivity. our results support earlier studies that have found surplus schooling has a negative effect on job satisfaction. our findings also indicate that the negative impact of surplus schooling on job satisfaction and turnover is more significant for workers with a higher level of surplus education. finally, the negative effects of surplus schooling appear to change over time.\"",
            "contribution_ids": [
                "R32536"
            ]
        },
        {
            "instance_id": "R32871xR32575",
            "comparison_id": "R32871",
            "paper_id": "R32575",
            "text": "Enhanced ship detection from overhead imagery \"in the authors' previous work, a sequence of image-processing algorithms was developed that was suitable for detecting and classifying ships from panchromatic quickbird electro-optical satellite imagery. presented in this paper are several new algorithms, which improve the performance and enhance the capabilities of the ship detection software, as well as an overview on how land masking is performed. specifically, this paper describes the new algorithms for enhanced detection including for the reduction of false detects such as glint and clouds. improved cloud detection and filtering algorithms are described as well as several texture classification algorithms are used to characterize the background statistics of the ocean texture. these detection algorithms employ both cloud and glint removal techniques, which we describe. results comparing ship detection with and without these false detect reduction algorithms are provided. these are components of a larger effort to develop a low-cost solution for detecting the presence of ships from readily-available overhead commercial imagery and comparing this information against various open-source ship-registry databases to categorize contacts for follow-on analysis.\"",
            "contribution_ids": [
                "R32576"
            ]
        },
        {
            "instance_id": "R32871xR32580",
            "comparison_id": "R32871",
            "paper_id": "R32580",
            "text": "Fully automated procedure for ship detection using optical satellite imagery ship detection from remote sensing imagery is a crucial application for maritime security which includes among others traffic surveillance, protection against illegal fisheries, oil discharge control and sea pollution monitoring. in the framework of a european integrated project gmes-security/limes, we developed an operational ship detection algorithm using high spatial resolution optical imagery to complement existing regulations, in particular the fishing control system. the automatic detection model is based on statistical methods, mathematical morphology and other signal processing techniques such as the wavelet analysis and radon transform. this paper presents current progress made on the detection model and describes the prototype designed to classify small targets. the prototype was tested on panchromatic spot 5 imagery taking into account the environmental and fishing context in french guiana. in terms of automatic detection of small ship targets, the proposed algorithm performs well. its advantages are manifold: it is simple and robust, but most of all, it is efficient and fast, which is a crucial point in performance evaluation of advanced ship detection strategies.",
            "contribution_ids": [
                "R32581"
            ]
        },
        {
            "instance_id": "R32871xR32591",
            "comparison_id": "R32871",
            "paper_id": "R32591",
            "text": "Ship detection and recognitionin high-resolution satellite images nowadays, the availability of high-resolution images taken from satellites, like quickbird, orbview, and others, offers the remote sensing community the possibility of monitoring and surveying vast areas of the earth for different purposes, e.g. monitoring forest regions for ecological reasons. a particular application is the use of satellite images to survey the bottom of the seas around the iberian peninsula which is flooded with innumerable treasures that are being plundered by specialized ships. in this paper we present a gis-based application aimed to catalog areas of the sea with archeological interest and to monitor the risk of plundering of ships that stay within such areas during a suspicious period of time.",
            "contribution_ids": [
                "R32592"
            ]
        },
        {
            "instance_id": "R32871xR32608",
            "comparison_id": "R32871",
            "paper_id": "R32608",
            "text": "A complete processing chain for ship detection using optical satellite imagery \"ship detection from remote sensing imagery is a crucial application for maritime security, which includes among others traffic surveillance, protection against illegal fisheries, oil discharge control and sea pollution monitoring. in the framework of a european integrated project global monitoring for environment and security (gmes) security/land and sea integrated monitoring for european security (limes), we developed an operational ship detection algorithm using high spatial resolution optical imagery to complement existing regulations, in particular the fishing control system. the automatic detection model is based on statistical methods, mathematical morphology and other signal-processing techniques such as the wavelet analysis and radon transform. this article presents current progress made on the detection model and describes the prototype designed to classify small targets. the prototype was tested on panchromatic satellite pour l'observation de la terre (spot) 5 imagery taking into account the environmental and fishing context in french guiana. in terms of automatic detection of small ship targets, the proposed algorithm performs well. its advantages are manifold: it is simple and robust, but most of all, it is efficient and fast, which is a crucial point in performance evaluation of advanced ship detection strategies.\"",
            "contribution_ids": [
                "R32609"
            ]
        },
        {
            "instance_id": "R32871xR32610",
            "comparison_id": "R32871",
            "paper_id": "R32610",
            "text": "Ship detection in satellite imagery using rank-order grayscale hit-or-miss transforms \"ship detection from satellite imagery is something that has great utility in various communities. knowing where ships are and their types provides useful intelligence information. however, detecting and recognizing ships is a difficult problem. existing techniques suffer from too many false-alarms. we describe approaches we have taken in trying to build ship detection algorithms that have reduced false alarms. our approach uses a version of the grayscale morphological hit-or-miss transform. while this is well known and used in its standard form, we use a version in which we use a rank-order selection for the dilation and erosion parts of the transform, instead of the standard maximum and minimum operators. this provides some slack in the fitting that the algorithm employs and provides a method for tuning the algorithm's performance for particular detection problems. we describe our algorithms, show the effect of the rank-order parameter on the algorithm's performance and illustrate the use of this approach for real ship detection problems with panchromatic satellite imagery.\"",
            "contribution_ids": [
                "R32611"
            ]
        },
        {
            "instance_id": "R32871xR32619",
            "comparison_id": "R32871",
            "paper_id": "R32619",
            "text": "A Novel Hierarchical Method of Ship Detection from Spaceborne Optical Image Based on Shape and Texture Features \"ship detection from remote sensing imagery is very important, with a wide array of applications in areas such as fishery management, vessel traffic services, and naval warfare. this paper focuses on the issue of ship detection from spaceborne optical images (sdsoi). although advantages of synthetic-aperture radar (sar) result in that most of current ship detection approaches are based on sar images, disadvantages of sar still exist, such as the limited number of sar sensors, the relatively long revisit cycle, and the relatively lower resolution. with the increasing number of and the resulting improvement in continuous coverage of the optical sensors, sdsoi can partly overcome the shortcomings of sar-based approaches and should be investigated to help satisfy the requirements of real-time ship monitoring. in sdsoi, several factors such as clouds, ocean waves, and small islands affect the performance of ship detection. this paper proposes a novel hierarchical complete and operational sdsoi approach based on shape and texture features, which is considered a sequential coarse-to-fine elimination process of false alarms. first, simple shape analysis is adopted to eliminate evident false candidates generated by image segmentation with global and local information and to extract ship candidates with missing alarms as low as possible. second, a novel semisupervised hierarchical classification approach based on various features is presented to distinguish between ships and nonships to remove most false alarms. besides a complete and operational sdsoi approach, the other contributions of our approach include the following three aspects: 1) it classifies ship candidates by using their class probability distributions rather than the direct extracted features; 2) the relevant classes are automatically built by the samples' appearances and their feature attribute in a semisupervised mode; and 3) besides commonly used shape and texture features, a new texture operator, i.e., local multiple patterns, is introduced to enhance the representation ability of the feature set in feature extraction. experimental results of sdsoi on a large image set captured by optical sensors from multiple satellites show that our approach is effective in distinguishing between ships and nonships, and obtains a satisfactory ship detection performance.\"",
            "contribution_ids": [
                "R32620"
            ]
        },
        {
            "instance_id": "R32871xR32630",
            "comparison_id": "R32871",
            "paper_id": "R32630",
            "text": "Ship Detection Using Texture Statistics from Optical Satellite Images this paper presents a method for ship detection using texture statistics from optical satellite images. the proposed method focuses on the extraction of ship candidates. first, a structural texture descriptor derived from local multiple patterns is introduced to describe image texture features, and then two statistical histograms are generated by quantizing texture features to describe the texture difference between sea and ships. second, corresponding confidence maps representing the probabilities of ship candidates are created based on back projection of the statistical histograms, and ship candidates are extracted according to the confidence maps. finally, the prior knowledge of ship shapes is employed to remove the false ship candidates. as using texture features, the proposed method is insensitive to different waves, illumination changes, ships with different sizes and bright/dark intensities. experimental results demonstrate the method has good performance in both precision and recall.",
            "contribution_ids": [
                "R32631"
            ]
        },
        {
            "instance_id": "R32871xR32646",
            "comparison_id": "R32871",
            "paper_id": "R32646",
            "text": "An Auto-Adapt Multi-Level Threshold Segmentation Method of Ships Detection in Remote Sensing Images with Complex Sea Surface Background \"a new multi-level threshold segmentation approach proposed for ship detection. this method is designed to detect targets in remote sensing images, especially for which with complex sea surface background image. an experiment over 1104 ship samples and 11600 no-ship samples, those from spot, quickbird, ikonos, landsat, shows that the target detection rate of the new method can be as high as 99.5% and the false alarm rate is low. experiments over images with various content and from different aircraft testify to the new method's robustness.\"",
            "contribution_ids": [
                "R32647"
            ]
        },
        {
            "instance_id": "R32871xR32651",
            "comparison_id": "R32871",
            "paper_id": "R32651",
            "text": "A Novel Algorithm for Ship Detection Based on Dynamic Fusion Model of Multi-feature and Support Vector Machine ship detection is one of the most important applications of target recognition based on optical remote sensing images. in this paper, we propose an uncertain ship target extraction algorithm based on dynamic fusion model of multi-feature and variance feature of optical remote sensing image. we choose several geometrical features, such as length, wide, rectangular ratio, tightness ratio and so on, using svm to train and predict the uncertain ship targets extracted by our algorithm automatically. experiments show that our algorithm is very robust, and the recognition rate of our algorithm can reach or even better than 95%, with the false alarm rate is kept at 3%.",
            "contribution_ids": [
                "R32652"
            ]
        },
        {
            "instance_id": "R32871xR32660",
            "comparison_id": "R32871",
            "paper_id": "R32660",
            "text": "A visual search inspired computational model for ship detection in optical satellite images in this letter, we propose a novel computational model for automatic ship detection in optical satellite images. the model first selects salient candidate regions across entire detection scene by using a bottom-up visual attention mechanism. then, two complementary types of top-down cues are employed to discriminate the selected ship candidates. specifically, in addition to the detailed appearance analysis of candidates, a neighborhood similarity-based method is further exploited to characterize their local context interactions. furthermore, the framework of our model is designed in a multiscale and hierarchical manner which provides a plausible approximation to a visual search process and reasonably distributes the computational resources. experiments over panchromatic spot5 data prove the effectiveness and computational efficiency of the proposed model.",
            "contribution_ids": [
                "R32661"
            ]
        },
        {
            "instance_id": "R32871xR32665",
            "comparison_id": "R32871",
            "paper_id": "R32665",
            "text": "A novel method of ship detection from spaceborne optical image based on spatial pyramid matching in this paper we propose an automatic ship detection method in high resolution optical satellite images based on neighbor context information. first, a pre-detection of targets gives us candidates. for each candidate, we choose an extended region called candidate with neighborhood which comprises candidate and its neighbor area. second, the patches of candidate with neighborhood are got by a regular grid, and their sift(scale invariant feature transform) features are extracted. then the sift features of training images are clustered with the k-means algorithm to form a codebook of the patches. we quantize the patches of candidate with neighborhood according to this codebook and get the visual word representation. finally by applying spatial pyramid matching, the candidates are classified with svm (support vector machine). experiment results are given for a set of images show that our method has got predominant performance.",
            "contribution_ids": [
                "R32666"
            ]
        },
        {
            "instance_id": "R32871xR32691",
            "comparison_id": "R32871",
            "paper_id": "R32691",
            "text": "Object Detection in Image with Complex Background abstr act. object detection is the key technology in computer vision, with broad application prospects. object detection has great research value and practical significance as a hot spot of video surveillance in recent years. this paper proposes an algorithm for ship detection in image with complex harbor background. we test the performance of several texture descriptors, and a region growing method based on contrast texture feature is proposed to implement sea-land separation. then, we apply a method combined with adaptive threshold segmentation and shape analysis for offshore ship detection. furthermore, the salient boundary template matching in the sea-land border area is used for docked ship detection. the experimental results show that our algorithm is able to implement ship object detection in complex image with good robustness and real-time performance.",
            "contribution_ids": [
                "R32692"
            ]
        },
        {
            "instance_id": "R32871xR32694",
            "comparison_id": "R32871",
            "paper_id": "R32694",
            "text": "NEAR REAL-TIME AUTOMATIC MARINE VESSEL DETECTION ON OPTICAL SATELLITE IMAGES abstract. vessel monitoring and surveillance is important for maritime safety and security, environment protection and border control. ship monitoring systems based on synthetic-aperture radar (sar) satellite images are operational. on sar images the ships made of metal with sharp edges appear as bright dots and edges, therefore they can be well distinguished from the water. since the radar is independent from the sun light and can acquire images also by cloudy weather and rain, it provides a reliable service. vessel detection from spaceborne optical images (vdsoi) can extend the sar based systems by providing more frequent revisit times and overcoming some drawbacks of the sar images (e.g. lower spatial resolution, difficult human interpretation). optical satellite images (osi) can have a higher spatial resolution thus enabling the detection of smaller vessels and enhancing the vessel type classification. the human interpretation of an optical image is also easier than as of sar image. in this paper i present a rapid automatic vessel detection method which uses pattern recognition methods, originally developed in the computer vision field. in the first step i train a binary classifier from image samples of vessels and background. the classifier uses simple features which can be calculated very fast. for the detection the classifier is slided along the image in various directions and scales. the detector has a cascade structure which rejects most of the background in the early stages which leads to faster execution. the detections are grouped together to avoid multiple detections. finally the position, size(i.e. length and width) and heading of the vessels is extracted from the contours of the vessel. the presented method is parallelized, thus it runs fast (in minutes for 16000 \u00d7 16000 pixels image) on a multicore computer, enabling near real-time applications, e.g. one hour from image acquisition to end user.\\n",
            "contribution_ids": [
                "R32695"
            ]
        },
        {
            "instance_id": "R32871xR32704",
            "comparison_id": "R32871",
            "paper_id": "R32704",
            "text": "A unified algorithm for ship detection on optical and SAR spaceborne images synthetic aperture radar (sar) is the most widely used sensor for ship detection from space but optical sensors are increasingly used in addition of these. the combined use of these sensors in an operational framework becomes a major stake of the efficiency of the current systems. it becomes also a source of the increased complexity of these systems. optical and sar signals of a maritime scene have many similarities. these similarities allow us to define a common detection approach presented in this paper. beyond the definition of a single algorithm for both types of data, this study aims to define an algorithm for the detection of vessels of any size in any resolution images. after studying the signatures of vessels, this second goal leads us to define a detection strategy based on multi-scale processes. it has been implemented in a processing chain into two major steps: first targets that are potentially vessels are identified using a discrete wavelet transform (dwt) and constant false alarm rate (cfar) detector. second among these targets, false alarms are rejected using a multi-scale reasoning on the contours of the targets. the definition of this processing chain is made with respect to three constraints: the detection rate should be 100%, the false alarm rate should be as low as possible and finally the processing time must be compatible with operations at sea. the method was developed and tested on the basis of a very large data set containing real images and associated detections. the obtained results validate this approach but with limitations mainly related to the sea state.",
            "contribution_ids": [
                "R32705"
            ]
        },
        {
            "instance_id": "R32871xR32718",
            "comparison_id": "R32871",
            "paper_id": "R32718",
            "text": "A Novel Sea-Land Segmentation Algorithm Based on Local Binary Patterns for Ship Detection ship detection is an important application of optical remote sensing image processing. sea-land segmentation is the key step in ship detection. traditional sea-land segment methods only based on the gray-level information of an image to choose a gray threshold to segment the image; however, it is very difficult to establish a self-adapting mechanism to select a suitable threshold for different images. thus, the segmentation result is greatly influenced by the threshold chosen for sea-land segmentation. in this paper, we are integrating the lbp feature information to propose a novel sea-land segmentation algorithm. moreover, a new ship detection method based on our sea-land segmentation algorithm is proposed for optical remote sensing images. the performance of ship detection is measured in terms of precision and false-alarm-rate. experimental results show that, as compared to minimum error method, the proposed algorithm can decrease the false-alarm-rate from 23.2% to 9.24%. and compared to otsu method, the proposed algorithm improve the precision from 82.9% to 90.2%.",
            "contribution_ids": [
                "R32719"
            ]
        },
        {
            "instance_id": "R32871xR32729",
            "comparison_id": "R32871",
            "paper_id": "R32729",
            "text": "Inshore ship detection in high-resolution satellite images: approximation of harbors using sea-land segmentation this paper proposes a novel inshore ship detection method that is based on the approximation of harbour area with piecewise linear line segments. the method heavily depends on a very fine sea-land segmentation, which is realized in two steps in this work. first, an initial mask is generated by thresholding the normalized difference water index (ndwi) using the zero-level of available global elevation data. in the second step, border of the segmentation result is further enhanced via graph-cut algorithm since spectral characteristics of sea close to sea-land border may differ from the ones of deep parts of the sea. the resultant borderline is used for finding line segments that are assumed to represent the man-made harbours. after being merged and eliminated properly, these line segments are used to extract harbour area so that the remaining connected components of the binary mask can be tested for being ship according to their shapes. test results show that the proposed method is capable of detecting different kinds of ships in a variety of sea states.",
            "contribution_ids": [
                "R32730"
            ]
        },
        {
            "instance_id": "R32871xR32745",
            "comparison_id": "R32871",
            "paper_id": "R32745",
            "text": "Ship detection for high resolution optical imagery with adaptive target filter ship detection is important due to both its civil and military use. in this paper, we propose a novel ship detection method, adaptive target filter (atf), for high resolution optical imagery. the proposed framework can be grouped into two stages, where in the first stage, a test image is densely divided into different detection windows and each window is transformed to a feature vector in its feature space. the histograms of oriented gradients (hog) is accumulated as a basic feature descriptor. in the second stage, the proposed atf highlights all the ship regions and suppresses the undesired backgrounds adaptively. each detection window is assigned a score, which represents the degree of the window belonging to a certain ship category. the atf can be adaptively obtained by the weighted logistic regression (wlr) according to the distribution of backgrounds and targets of the input image. the main innovation of our method is that we only need to collect positive training samples to build the filter, while the negative training samples are adaptively generated by the input image. this is different to other classification method such as support vector machine (svm) and logistic regression (lr), which need to collect both positive and negative training samples. the experimental result on 1-m high resolution optical images shows the proposed method achieves a desired ship detection performance with higher quality and robustness than other methods, e.g., svm and lr.",
            "contribution_ids": [
                "R32746"
            ]
        },
        {
            "instance_id": "R32871xR32760",
            "comparison_id": "R32871",
            "paper_id": "R32760",
            "text": "Combined use of optical imaging satellite data and electronic intelligence satellite data for large scale ship group surveillance we propose a novel framework for large-scale maritime ship group surveillance using spaceborne optical imaging satellite data and electronic intelligence (elint) satellite data. considering that the size of a ship is usually less than the distance between different ships for large-scale maritime surveillance, we treat each ship as a mass point and ship groups are modelled as point sets. motivated by the observation that ship groups performing tactical or strategic operations often have a stable topology and their attributes remain unchanged, we combine both topological features and attributive features within the framework of dempster-shafer (d-s) theory for coherent ship group analysis. our method has been tested using different sets of simulated data and recorded data. experimental results demonstrate our method is robust and efficient for large-scale maritime surveillance.",
            "contribution_ids": [
                "R32761"
            ]
        },
        {
            "instance_id": "R32871xR32769",
            "comparison_id": "R32871",
            "paper_id": "R32769",
            "text": "Salient target detection in remote sensing image via cellular automata in order to detect salient target in remote sensing images effectively and accurately, this paper propose a target segmentation method based on cellular automata which is usually used as a dynamic evolution model. first, we introduce the background based map to obtain saliency map with the help of a widely used superpixel segmentation method named simple linear iterative clustering. secondly, cellular automata are employed to produce the elementary saliency map. then enhanced saliency map can be obtained by maximum contrast of image patch method. adaptive threshold is calculated to segment the enhanced saliency map. consequently, the salient target detection and segmentation result can be obtained. experiments on optical remote sensing images and synthetic aperture radar (sar) images demonstrate that the proposed algorithm outperforms other methods such as k-means, otsu and region growing method.",
            "contribution_ids": [
                "R32770"
            ]
        },
        {
            "instance_id": "R32871xR32789",
            "comparison_id": "R32871",
            "paper_id": "R32789",
            "text": "OBIA ship detection with multispectral and SAR images: A simulation for Copernicus security applications every day, ships of different type, size and origin cross the world seas. not only for commerce and transport, but also for illegal activities. in addition to conventional positioning and tracking systems, detection with earth observation satellites is an effective means to monitor human movements across the sea. the european copernicus programme operates towards this goal, through the definition of border and maritime surveillance as one of its main tasks. this paper describes an object based image analysis (obia) workflow developed for ship detection, monitoring and tracking with high-resolution satellite images. here, it has been used to simulated medium-resolution multispectral (ms) and synthetic aperture radar (sar) images representative of the sentinel components of copernicus. first results confirm that the method proposed can be efficiently used by european agencies for monitoring the explosive growth of illegal flows in the mediterranean sea.",
            "contribution_ids": [
                "R32790"
            ]
        },
        {
            "instance_id": "R32871xR32791",
            "comparison_id": "R32871",
            "paper_id": "R32791",
            "text": "A NOVEL SHIP DETECTION METHOD FOR LARGE-SCALE OPTICAL SATELLITE IMAGES BASED ON VISUAL LBP FEATURE AND VISUAL ATTENTION MODEL abstract. reliably ship detection in optical satellite images has a wide application in both military and civil fields. however, this problem is very difficult in complex backgrounds, such as waves, clouds, and small islands. aiming at these issues, this paper explores an automatic and robust model for ship detection in large-scale optical satellite images, which relies on detecting statistical signatures of ship targets, in terms of biologically-inspired visual features. this model first selects salient candidate regions across large-scale images by using a mechanism based on biologically-inspired visual features, combined with visual attention model with local binary pattern (cvlbp). different from traditional studies, the proposed algorithm is high-speed and helpful to focus on the suspected ship areas avoiding the separation step of land and sea. largearea images are cut into small image chips and analyzed in two complementary ways: sparse saliency using visual attention model and detail signatures using lbp features, thus accordant with sparseness of ship distribution on images. then these features are employed to classify each chip as containing ship targets or not, using a support vector machine (svm). after getting the suspicious areas, there are still some false alarms such as microwaves and small ribbon clouds, thus simple shape and texture analysis are adopted to distinguish between ships and nonships in suspicious areas. experimental results show the proposed method is insensitive to waves, clouds, illumination and ship size.\\n",
            "contribution_ids": [
                "R32792"
            ]
        },
        {
            "instance_id": "R32871xR32794",
            "comparison_id": "R32871",
            "paper_id": "R32794",
            "text": "A Direct and Fast Methodology for Ship Recognition in Sentinel-2 Multispectral Imagery the european space agency satellite sentinel-2 provides multispectral images with pixel sizes down to 10 m. this high resolution allows for ship detection and recognition by determining a number of important ship parameters. we are able to show how a ship position, its heading, length and breadth can be determined down to a subpixel resolution. if the ship is moving, its velocity can also be determined from its kelvin waves. the 13 spectrally different visual and infrared images taken using multispectral imagery (msi) are \u201cfingerprints\u201d that allow for the recognition and identification of ships. furthermore, the multispectral image profiles along the ship allow for discrimination between the ship, its turbulent wakes, and the kelvin waves, such that the ship\u2019s length and breadth can be determined more accurately even when sailing. the ship\u2019s parameters are determined by using satellite imagery taken from several ships, which are then compared to known values from the automatic identification system. the agreement is on the order of the pixel resolution or better.",
            "contribution_ids": [
                "R32795"
            ]
        },
        {
            "instance_id": "R32871xR32804",
            "comparison_id": "R32871",
            "paper_id": "R32804",
            "text": "On-board ship targets detection method based on multi-scale salience enhancement for remote sensing image a on-board ship targets detection method based on multi-scale salience enhancement is proposed. unlike the traditional wavelet filter enhancement methods, the proposed utilizes the wavelet decomposition to obtain the high-low frequency parts, and estimate the salience feature with both parts, which enhance the ship targets efficiently. first, decompose the remote sensing image by 2-d dwt, and obtain the low-frequency part, high-frequency part of horizontal, vertical and diagonal; then, compute the ostu threshold, which is subtracted by the low-frequency coefficients to get the low-frequency salience image; and, the high-frequency parts are used to compose the high-frequency salience image; finally, the high-low parts are fused by addition and normalized to obtain the salience map. the original data of multi sets of remote sensing images are experimented, and the results are compared with the method without the proposed salience enhancement. the proposed shows obvious salience enhancement for the low-resolution, high-noise remote sensing images.",
            "contribution_ids": [
                "R32805"
            ]
        },
        {
            "instance_id": "R32871xR32811",
            "comparison_id": "R32871",
            "paper_id": "R32811",
            "text": "Ship detection in high spatial resolution remote sensing image based on improved sea-land segmentation a new method to detect ship target at sea based on improved segmentation algorithm is proposed in this paper, in which the improved segmentation algorithm is applied to precisely segment land and sea. firstly, mean value is replaced instead of average variance value in otsu method in order to improve the adaptability. secondly, mean shift algorithm is performed to separate the original high spatial resolution remote sensing image into several homogeneous regions. at last, the final sea-land segmentation result can be located combined with the regions in preliminary sea-land segmentation result. the proposed segmentation algorithm performs well on the segment between water and land with affluent texture features and background noise, and produces a result that can be well used in shape and context analyses. ships are detected with settled shape characteristics, including width, length and its compactness. mean shift algorithm can smooth the background noise, utilize the wave\u2019s texture features and helps highlight offshore ships. mean shift algorithm is combined with improved otsu threshold method in order to maximizes their advantages. experimental results show that the improved sea-land segmentation algorithm on high spatial resolution remote sensing image with complex texture and background noise performs well in sea-land segmentation, not only enhances the accuracy of land and sea boarder, but also preserves detail characteristic of ships. compared with traditional methods, this method can achieve accuracy over 90 percent. experiments on worldview images show the superior, robustness and precision of the proposed method.",
            "contribution_ids": [
                "R32812"
            ]
        },
        {
            "instance_id": "R32871xR32836",
            "comparison_id": "R32871",
            "paper_id": "R32836",
            "text": "A ship target automatic recognition method for sub-meter remote sensing images the spatial resolution is increasingly high as development of optical remote sensing, and more and more optical sensors can achieve the detection ability of sub meter, which lays down the data foundation for automatic recognition of ship targets. however, mature technology is lacked to identify the ship models automatically with remote sensing images. in this study, an automatic recognition method for ship targets is proposed based on the local invariant feature extraction algorithm sift (scale invariant feature transform), which is consist of feature extraction and description, feature matching and target recognition. the model of unknown target is identified based on the target library using the matching difference of targets with the same model and different models. the experiment results show that this automatic recognition flow is effective to identify the ship targets of interest based on the target library, and the total correct recognition rate is 92%. this method provides a new flow for automatic model recognition of ship targets, and has considerable potential for wide applications.",
            "contribution_ids": [
                "R32837"
            ]
        },
        {
            "instance_id": "R32871xR32843",
            "comparison_id": "R32871",
            "paper_id": "R32843",
            "text": "Multi-class remote sensing object recognition based on discriminative sparse representation the automatic recognition of multi-class objects with various backgrounds is a big challenge in the field of remote sensing (rs) image analysis. in this paper, we propose a novel recognition framework for multi-class rs objects based on the discriminative sparse representation. in this framework, the recognition problem is implemented in two stages. in the first, or discriminative dictionary learning stage, considering the characterization of remote sensing objects, the scale-invariant feature transform descriptor is first combined with an improved bag-of-words model for multi-class objects feature extraction and representation. then, information about each class of training samples is fused into the dictionary learning process; by using the k-singular value decomposition algorithm, a discriminative dictionary can be learned for sparse coding. in the second, or recognition, stage, to improve the computational efficiency, the phase spectrum of a quaternion fourier transform model is applied to the test image to predict a small set of object candidate locations. then, a multi-scale sliding window mechanism is utilized to scan the image over those candidate locations to obtain the object candidates (or objects of interest). subsequently, the sparse coding coefficients of these candidates under the discriminative dictionary are mapped to the discriminative vectors that have a good ability to distinguish different classes of objects. finally, multi-class object recognition can be accomplished by analyzing these vectors. the experimental results show that the proposed work outperforms a number of state-of-the-art methods for multi-class remote sensing object recognition.",
            "contribution_ids": [
                "R32844"
            ]
        },
        {
            "instance_id": "R32871xR32851",
            "comparison_id": "R32871",
            "paper_id": "R32851",
            "text": "Ship detection in panchromatic images: a new method and its DSP implementation in this paper, a new ship detection method is proposed after analyzing the characteristics of panchromatic remote sensing images and ship targets. firstly, adaboost(adaptive boosting) classifiers trained by haar features are utilized to make coarse detection of ship targets. then lsd (line segment detector) is adopted to extract the line features in target slices to make fine detection. experimental results on a dataset of panchromatic remote sensing images with a spatial resolution of 2m show that the proposed algorithm can achieve high detection rate and low false alarm rate. meanwhile, the algorithm can meet the needs of practical applications on dsp (digital signal processor).",
            "contribution_ids": [
                "R32852"
            ]
        },
        {
            "instance_id": "R32871xR32863",
            "comparison_id": "R32871",
            "paper_id": "R32863",
            "text": "Inshore Ship Detection in Remote Sensing Images via Weighted Pose Voting inshore ship detection from high-resolution satellite images is a useful yet challenging task in remote surveillance and military reconnaissance. it is difficult to detect the inshore ships with high precision because various interferences are present in the harbor scene. an inshore ship detection method based on the weighted voting and rotation\u2013scale-invariant pose is proposed to improve the detection performance. the proposed method defines the rotation angle pose and the scaling factor of the detected ship to detect the ship with different directions and different sizes. for each pixel on the ship template, the possible poses of a detection window are estimated according to all possible pose-related pixels. to improve robustness to the shape-similar distractor and various interferences, the score of the detection window is obtained by designing a pose weighted voting method. moreover, the values of some parameters such as similarity threshold and the weight of \u201cv\u201d are investigated. the experimental results on actual satellite images demonstrate that the proposed method is invariant to rotation and scale and robust in the inshore ship detection. in addition, better detection performance is observed in comparison with the existing inshore ship detection algorithms in terms of precision rate and recall rate. the target pose of the detected ship can also be obtained as a byproduct of the ship detection.",
            "contribution_ids": [
                "R32864"
            ]
        },
        {
            "instance_id": "R32871xR32553",
            "comparison_id": "R32871",
            "paper_id": "R32553",
            "text": "Automatic ship detection in satellite multispectral imagery in recent years, very little attention in the literature has been given to the task of automatically detecting shipping vessels in optical satellite imagery. a method for achieving this goal is described for both spot multispectral and landsat thematic mapper data. essentially a task in pattern recognition, the method utilizes masking, filtering, and shape analysis techniques. results showing a high degree of accuracy have been obtained with test data.",
            "contribution_ids": [
                "R32554"
            ]
        },
        {
            "instance_id": "R32871xR32669",
            "comparison_id": "R32871",
            "paper_id": "R32669",
            "text": "A method of ship detection from spaceborne optical image operational sdsoi and novel hierarchical complete approach based on shape and texture properties, whic h is considered a sequential coarse-to-fine deleting pro cess of fake alarms. simple shape analysis is adopt ed to delete evident fake candidates generated by image segmentation with world and local information and to extrac t ship candidates with missing alarms as low as possible a nd a novel semi supervised hierarchical classificat ion approach based on different features is presented to disting uish between ships and non ships besides a complete and operational sdsoi approach, the other contributions of our approach include the following three aspect s: 1) it identify ship candidates by using their class proba bility distributions rather than the extracted feat ures; 2) the related classes are automatically built by the samples\u2019 app earances and their feature attribute in a semi supe rvised mode; and 3) besides commonly used shape and texture features, a new texture operator, i.e., local multiple patterns, is introduced to enhance the representation ability of the feature set in feature extraction. experimenta l results of sdsoi on a big image set captured by optical sensor s from multiple satellites show that our approach i s effective in distinguishing between ships and non ships, and obt ains a well ship detection performance.",
            "contribution_ids": [
                "R32670"
            ]
        },
        {
            "instance_id": "R32914xR32875",
            "comparison_id": "R32914",
            "paper_id": "R32875",
            "text": "Determinants of web site information by Spanish city councils purpose the purpose of this research is to analyse the web sites of large spanish city councils with the objective of assessing the extent of information disseminated on the internet and determining what factors are affecting the observed levels of information disclosure. design/methodology/approach the study takes as its reference point the existing literature on the examination of the quality of web sites, in particular the provisions of the web quality model (wqm) and the importance of content as a key variable in determining web site quality. in order to quantify the information on city council web sites, a disclosure index has been designed which takes into account the content, navigability and presentation of the web sites. in order to contrast which variables determine the information provided on the web sites, our investigation bases itself on the studies about voluntary disclosure in the public sector, and six lineal regressions models have been performed. findings the empirical evidence obtained reveals low disclosure levels among spanish city council web sites. in spite of this, almost 50 per cent of the city councils have reached the \u201capproved\u201d level and of these, around a quarter obtained good marks. our results show that disclosure levels depend on political competition, public media visibility and the access to technology and educational levels of the citizens. practical implications the strategy of communication on the internet by local spanish authorities is limited in general to an ornamental web presence but one that does not respond efficiently to the requirements of the digital society. during the coming years, local spanish politicians will have to strive to take advantage of the opportunities that the internet offers to increase both the relational and informational capacity of municipal web sites as well as the digital information transparency of their public management. originality/value the internet is a potent channel of communication that is modifying the way in which people access and relate to information and each other. the public sector is not unaware of these changes and is incorporating itself gradually into the new network society. this study systematises the analysis of local administration web sites, showing the lack of digital transparency, and orients politicians in the direction to follow in order to introduce improvements in their electronic relationships with the public.",
            "contribution_ids": [
                "R32876"
            ]
        },
        {
            "instance_id": "R32914xR32883",
            "comparison_id": "R32914",
            "paper_id": "R32883",
            "text": "Cultural contexts and governmental digital reporting the way in which public sector entities disseminate information publicly is affected by the degree of transparency adopted, and the construction and management of websites are increasingly essential elements of modern public administration. nonetheless, differences in this process exist among governments worldwide, probably due to different contextual factors. this article examines and discusses the approach of anglo-saxon, south american and continental european central governments to the use of the web as a means of making financial disclosures. to measure the disclosure of governmental financial information on the internet, an index has been defined, taking into consideration the data considered to be relevant for a potential user, gathering the data visiting their websites. the results show that the way different countries use the web for financial disclosure is deeply rooted in and follows from their administrative culture. in conclusion, the continental european and south american governments should improve their digital reporting.",
            "contribution_ids": [
                "R32884"
            ]
        },
        {
            "instance_id": "R32914xR32897",
            "comparison_id": "R32914",
            "paper_id": "R32897",
            "text": "Municipal Government Financial Reporting: Administrative and Ethical Climate \"this article examines financial disclosure in u.s. cities. it considers factors that affect the level of municipal financial disclosure, in particular the effect of administrative factors. it finds that participation in the government finance officers association certificate of excellence in financial reporting program, and the chief financial officer's familiarity with the activities of the governmental accounting standards board are positively associated with more disclosure. these latter factors are interpreted as measures of professionalism and are furthered by the adoption of municipal codes of ethics which stress openness and responsiveness to stakeholder interests. such general policies are indirectly associated with heightened levels of financial disclosure. financial disclosure is also associated with city size and demands from capital markets.\"",
            "contribution_ids": [
                "R32898"
            ]
        },
        {
            "instance_id": "R32940xR32926",
            "comparison_id": "R32940",
            "paper_id": "R32926",
            "text": "Error in Byline in: Long-term and Perioperative Corticosteroids in Anastomotic Leakage: A Prospective Study of 259 Left-Sided Colorectal Anastomoses prediction model based on the anatomic injury scale. ann surg. 2008;247(6): 1041-1048. 13. van buuren s, boshuizen hc, knook dl. multiple imputation of missing blood pressure covariates in survival analysis. stat med. 1999;18(6):681-694. 14. white h. a heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity. econometrica. 1980;48(4):817-838. 15. davidson gh, hamlat ca, rivara fp, koepsell td, jurkovich gj, arbabi s. longterm survival of adult trauma patients. jama. 2011;305(10):1001-1007. 16. dutton rp, stansbury lg, leone s, kramer e, hess jr, scalea tm. trauma mortality in mature trauma systems: are we doing better? an analysis of trauma mortality patterns, 1997-2008. j trauma. 2010;69(3):620-626. 17. nathens ab, jurkovich gj, cummings p, rivara fp, maier rv. the effect of organized systems of trauma care on motor vehicle crash mortality. jama. 2000; 283(15):1990-1994. 18. mackenzie ej, rivara fp, jurkovich gj, et al. a national evaluation of the effect of trauma-center care on mortality. n engl j med. 2006;354(4):366-378. 19. acute respiratory distress syndrome network. ventilation with lower tidal volumes as compared with traditional tidal volumes for acute lung injury and the acute respiratory distress syndrome. n engl j med. 2000;342(18):1301-1308. 20. moore fa, feliciano dv, andrassy rj, et al. early enteral feeding, compared with parenteral, reduces postoperative septic complications: the results of a meta-analysis. ann surg. 1992;216(2):172-183. 21. rotondo mf, zonies dh. the damage control sequence and underlying logic. surg clin north am. 1997;77(4):761-777. 22. holcomb jb, jenkins d, rhee p, et al. damage control resuscitation: directly addressing the early coagulopathy of trauma. j trauma. 2007;62(2):307-310. 23. nathens ab, jurkovich gj, mackenzie ej, rivara fp. a resource-based assessment of trauma care in the united states. j trauma. 2004;56(1):173-178. 24. hsiary,shenyc.risingclosuresofhospital traumacentersdisproportionatelyburden vulnerable populations. health aff (millwood). 2011;30(10):1912-1920. 25. mullins rj, mann nc, hedges jr, et al. adequacy of hospital discharge status as a measure of outcome among injured patients. jama. 1998;279(21):17271731. 26. shafi s, friese r, gentilello lm. moving beyond personnel and process: a case for incorporating outcome measures in the trauma center designation process. arch surg. 2008;143(2):115-120. 27. glance lg, dick aw, osler tm, meredith w, mukamel db. the association between cost and quality in trauma: is greater spending associated with higherquality care? ann surg. 2010;252(2):217-222. 28. eddy dm, billings j. the quality of medical evidence: implications for quality of care. health aff (millwood). 1988;7(1):19-32. 29. glance lg, dick aw, mukamel db, osler tm. association between trauma quality indicators and outcomes for injured patients. arch surg. 2012;147(4):308315.",
            "contribution_ids": [
                "R32927"
            ]
        },
        {
            "instance_id": "R32940xR32928",
            "comparison_id": "R32940",
            "paper_id": "R32928",
            "text": "Risk Factors for Anastomotic Leak and Mortality in Diabetic Patients Undergoing Colectomy objectives\\nto determine the risk factors in diabetic patients that are associated with increased postcolectomy mortality and anastomotic leak.\\n\\n\\ndesign\\na prospectively acquired statewide database of patients who underwent colectomy was reviewed. primary risk factors were diabetes mellitus, hyperglycemia (glucose level \u2265 140 mg/dl), steroid use, and emergency surgery. categorical analysis, univariate logistic regression, and multivariate regression were used to evaluate the effects of these risk factors on outcomes.\\n\\n\\nsetting\\nparticipating hospitals within the michigan surgical quality collaborative.\\n\\n\\npatients\\ndatabase review of patients from hospitals within the michigan surgical quality collaborative.\\n\\n\\nmain outcome measures\\nanastomotic leak and 30- day mortality rate.\\n\\n\\nresults\\nof 5123 patients, 153 (3.0%) had leaks and 153 (3.0%) died. preoperative hyperglycemia occurred in 15.6% of patients, only 54% of whom were known to have diabetes. multivariate analysis showed that the risk of leak for patients with and without diabetes increased only by preoperative steroid use (p<.05). mortality among diabetic patients was associated with emergency surgery (p<.01) and anastomotic leak (p<.05); it was not associated with hyperglycemia. mortality among nondiabetic patients was associated with hyperglycemia (p<.005). the presence of an anastomotic leak was associated with increased mortality among diabetic patients (26.3% vs 4.5%; p<.001) compared with nondiabetic patients (6.0% vs 2.5%; p<.05).\\n\\n\\nconclusions\\nthe presence of diabetes did not have an effect on the presence of an anastomotic leak, but diabetic patients who had a leak had more than a 4-fold higher mortality compared with nondiabetic patients. preoperative steroid use led to increased rates of anastomotic leak in diabetic patients. mortality was associated with hyperglycemia for nondiabetic patients only. improved screening may identify high-risk patients who would benefit from perioperative intervention.",
            "contribution_ids": [
                "R32929"
            ]
        },
        {
            "instance_id": "R33008xR32967",
            "comparison_id": "R33008",
            "paper_id": "R32967",
            "text": "Exploring polycythaemia vera with fluorescence in situ hybridization: additional cryptic 9p is the most frequent abnormality detected summary. between 1986 and 2001, 220 patients with polycythaemia vera (pv) were studied using conventional cytogenetics. of 204 evaluable patients, 52 (25\u00b74%) had clonal abnormalities. the recurrent chromosomal rearrangements were those of chromosome 9 (21\u00b71%), del(20q) (19\u00b72%), trisomy 8 (19\u00b72%), rearrangements of 13q (13\u00b74%), abnormalities of 1q (11\u00b75%), and of chromosomes 5 and 7 (9\u00b76%). subsequent analysis of 32 patients, performed at follow\u2010up of up to 14\u00b78\\u2003years, revealed new clonal abnormalities in five patients and the disappearance of an abnormal clone in four. eleven patients remained normal up to 11\u00b75\\u2003years and seven patients maintained an abnormality for over 10\\u2003years. fifty\u2010three patients were studied retrospectively using interphase fluorescence in\\u2003situ hybridization (i\u2010fish), utilizing probes for centromere enumeration of chromosomes 8 and 9, and for 13q14 and 20q12 loci. conventional cytogenetics demonstrated clonal chromosome abnormalities in 23% of these 53 patients. the addition of i\u2010fish increased the detection of abnormalities to 29% and permitted clarification of chromosome 9 rearrangements in an additional 5\u00b76% of patients. fish uncovered rearrangements of chromosome 9 in 53% of patients with an abnormal fish pattern, which represented the most frequent genomic alteration in this series.",
            "contribution_ids": [
                "R32968",
                "R33077"
            ]
        },
        {
            "instance_id": "R33008xR32984",
            "comparison_id": "R33008",
            "paper_id": "R32984",
            "text": "The importance of diagnostic cytogenetics on outcome in AML: analysis of 1,612 patients entered into the MRC AML 10 trial abstract \\n cytogenetics is considered one of the most valuable prognostic determinants in acute myeloid leukemia (aml). however, many studies on which this assertion is based were limited by relatively small sample sizes or varying treatment approach, leading to conflicting data regarding the prognostic implications of specific cytogenetic abnormalities. the medical research council (mrc) aml 10 trial, which included children and adults up to 55 years of age, not only affords the opportunity to determine the independent prognostic significance of pretreatment cytogenetics in the context of large patient groups receiving comparable therapy, but also to address their impact on the outcome of subsequent transplantation procedures performed in first complete remission (cr). on the basis of response to induction treatment, relapse risk, and overall survival, three prognostic groups could be defined by cytogenetic abnormalities detected at presentation in comparison with the outcome of patients with normal karyotype. aml associated with t(8;21), t(15;17) or inv(16) predicted a relatively favorable outcome. whereas in patients lacking these favorable changes, the presence of a complex karyotype, \u22125, del(5q), \u22127, or abnormalities of 3q defined a group with relatively poor prognosis. the remaining group of patients including those with 11q23 abnormalities, +8, +21, +22, del(9q), del(7q) or other miscellaneous structural or numerical defects not encompassed by the favorable or adverse risk groups were found to have an intermediate prognosis. the presence of additional cytogenetic abnormalities did not modify the outcome of patients with favorable cytogenetics. subgroup analysis demonstrated that the three cytogenetically defined prognostic groups retained their predictive value in the context of secondary as well as de novo aml, within the pediatric age group and furthermore were found to be a key determinant of outcome from autologous or allogeneic bone marrow transplantation (bmt) in first cr. this study highlights the importance of diagnostic cytogenetics as an independent prognostic factor in aml, providing the framework for a stratified treatment approach of this disease, which has been adopted in the current mrc aml 12 trial.",
            "contribution_ids": [
                "R32985"
            ]
        },
        {
            "instance_id": "R33008xR33001",
            "comparison_id": "R33008",
            "paper_id": "R33001",
            "text": "Prognos- tic and biologic significance of chromosomal imbalances assessed by comparative genomic hybridization in multiple myeloma abstract \\n cytogenetic abnormalities, evaluated either by karyotype or by fluorescence in situ hybridization (fish), are considered the most important prognostic factor in multiple myeloma (mm). however, there is no information about the prognostic impact of genomic changes detected by comparative genomic hybridization (cgh). we have analyzed the frequency and prognostic impact of genetic changes as detected by cgh and evaluated the relationship between these chromosomal imbalances and igh translocation, analyzed by fish, in 74 patients with newly diagnosed mm. genomic changes were identified in 51 (69%) of the 74 mm patients. the most recurrent abnormalities among the cases with genomic changes were gains on chromosome regions 1q (45%), 5q (24%), 9q (24%), 11q (22%), 15q (22%), 3q (16%), and 7q (14%), while losses mainly involved chromosomes 13 (39%), 16q (18%), 6q (10%), and 8p (10%). remarkably, the 6 patients with gains on 11q had igh translocations. multivariate analysis selected chromosomal losses, 11q gains, age, and type of treatment (conventional chemotherapy vs autologous transplantation) as independent parameters for predicting survival. genomic losses retained the prognostic value irrespective of treatment approach. according to these results, losses of chromosomal material evaluated by cgh represent a powerful prognostic factor in mm patients. (blood. 2004;104:2661-2666)",
            "contribution_ids": [
                "R33002"
            ]
        },
        {
            "instance_id": "R33008xR33003",
            "comparison_id": "R33008",
            "paper_id": "R33003",
            "text": "Abnormalities of chromosome 1p \u00e2\u0081\u0084 q are highly associated with chromosome 13 \u00e2\u0081\u0084 13q deletions and are an adverse prognostic factor for the outcome of high-dose chemotherapy in patients with multiple myeloma the prognostic value of chromosomal abnormalities was studied in untreated multiple myeloma patients who were registered into a prospective randomised multicentre phase 3 study for intensified treatment (hovon24). a total of 453 patients aged less than 66\\u2003years with stage ii and iii a/b disease were registered in the clinical study. cytogenetic analysis was introduced as a standard diagnostic assay in 1998. it was performed at diagnosis in 160 patients and was successful in 137/160 patients (86%). an abnormal karyotype was observed in 53/137 (39%) of the patients. abnormalities of chromosome 1p and 1q were found in 19 (36% of patients with an abnormal karyotype) and 21 patients (40%). there was a strong association between chromosome 1p and/or 1q abnormalities and deletion of chromosome 13 or 13q (n\\u2003=\\u200327, p\\u2003<\\u20030\u00b7001). patients with karyotypic abnormalities had a significantly shorter overall survival (os) than patients with normal karyotypes. complex abnormalities, hypodiploidy, chromosome 1p abnormalities, chromosome 1q abnormalities, and chromosome 13 abnormalities were associated with inferior os on univariate analysis, as well as after adjustment for other prognostic factors. in conclusion, chromosome 13 abnormalities and chromosome 1p and/or 1q abnormalities were highly associated, and are risk factors for poor outcome after intensive therapy in multiple myeloma.",
            "contribution_ids": [
                "R33004"
            ]
        },
        {
            "instance_id": "R33091xR33009",
            "comparison_id": "R33091",
            "paper_id": "R33009",
            "text": "Partial trisomy of the long arm of chromosome 1 in myelofibrosis and polycythemia vera we have identified partial trisomy 1q in 2 patients with different hematologic disorders. the first patient was a 55\u2010year\u2010old female with myelosclerosis and myeloid metaplasia diagnosed at age 38 years presenting with anemia, fatigue, bruising, fever, and splenomegaly. at age 56, she had 50\u201395% myeloblast cells and 95\u2013100 nucleated rbc precursors per 100 wbc. chromosome analysis of unstimulated leukocytes with q, g, and c banding showed 46,xx,\u20106,+t(1;6) (q25;p22) in all metaphase cells. in vitro incorporation of fe55 was demonstrated in 90% of metaphases by autoradiography. the second patient, a 49\u2010year\u2010old male, was diagnosed as having polycythemia vera at age 30 during a regular checkup. he since developed hepatosplenomegaly. chromosome analysis from a direct bone marrow preparation at age 44 and 45 showed grossly normal karyotypes. at age 49, his marrow by q and g banding showed almost 100% of cells with 46,xy,\u201313,+t(1;13) (q12;p12). eleven cases of trisomy of 1q have been reported in various hematologic disorders. it is apparent that partial trisomy 1q represents another nonrandom chromosomal abnormality, in addition to the most common nonrandom chromosomal aberrations, such as the philadelphia chromosome, trisomy 8, trisomy 9, and monosomy 7 in hematologic disorders.",
            "contribution_ids": [
                "R33010"
            ]
        },
        {
            "instance_id": "R33091xR33072",
            "comparison_id": "R33091",
            "paper_id": "R33072",
            "text": "Compari- son of peripheral blood interphase cytogenetics with bone marrow karyotype analysis in myelofibrosis with myeloid metaplasia in a prospective study of 42 patients with myelofibrosis with myeloid metaplasia (mmm), peripheral blood (pb) and bone marrow (bm) interphase cytogenetics and pb cd34 enumeration were performed concomitantly with bm karyotype analysis. interphase cytogenetics was performed with a panel of fluorescence in situ hybridization (fish) probes that were capable of detecting most of the known recurrent cytogenetic lesions in mmm. there was a close concordance in the results of interphase cytogenetics between pb and bm, regardless of the pb cd34 count. in general, fish\u2010detectable abnormalities were also detected by bm karyotype. although complementary, interphase cytogenetics may not always provide the necessary karyotypic information in mmm.",
            "contribution_ids": [
                "R33073"
            ]
        },
        {
            "instance_id": "R33091xR33080",
            "comparison_id": "R33091",
            "paper_id": "R33080",
            "text": "Prognostic diver- sity among cytogenetic abnormalities in myelofibrosis with myeloid metaplasia approximately 30\u201350% of patients with myelofibrosis with myeloid metaplasia (mmm) demonstrate detectable cytogenetic abnormalities, the prognostic value of which has not been completely defined by previous retrospective studies. the current prospective study addresses this issue in the context of currently accepted independent prognostic variables.",
            "contribution_ids": [
                "R33081"
            ]
        },
        {
            "instance_id": "R33091xR33082",
            "comparison_id": "R33091",
            "paper_id": "R33082",
            "text": "Der(6)t(1;6)(q21-23;p21.3): a specific cytogenetic abnormality in myelofibrosis with myeloid metaplasia chromosome anomalies are detected in approximately half of patients with myelofibrosis with myeloid metaplasia (mmm) although none of the most prevalent lesions are specific to the disease. in a prospective cytogenetic study of 81 patients with mmm, we encountered three with an unbalanced translocation between chromosomes 1 and 6 with specific breakpoints; der(6)t(1;6)(q21\u201323;p21.3). a subsequent mayo clinic cytogenetic database search identified 12 patients with this chromosome anomaly among 17\\u2003791 consecutive patients. a similar database search from royal hallamshire hospital in sheffield, uk revealed two additional patients among 8000 cases. the clinical phenotype and survival for each of these 14 patients was typical of mmm. these findings suggested that der(6)t(1;6)(q21\u201323;p21.3) is a highly specific cytogenetic anomaly that may harbour gene(s) specifically associated with mmm. in a preliminary fluorescence in situ hybridization study, the breakpoints on chromosome 6 in two additional cases were found to be telomeric to the gene for 51\\u2003kda fk506\u2010binding protein (fkbp51).",
            "contribution_ids": [
                "R33083"
            ]
        },
        {
            "instance_id": "R33091xR33088",
            "comparison_id": "R33091",
            "paper_id": "R33088",
            "text": "The role of cytogenetic abnormalities as a prognostic marker in primary myelofibrosis: applicability at the time of diagnosis and later during disease course abstract \\n although cytogenetic abnormalities are important prognostic factors in myeloid malignancies, they are not included in current prognostic scores for primary myelofibrosis (pmf). to determine their relevance in pmf, we retrospectively examined the impact of cytogenetic abnormalities and karyotypic evolution on the outcome of 256 patients. baseline cytogenetic status impacted significantly on survival: patients with favorable abnormalities (sole deletions in 13q or 20q, or trisomy 9 \u00b1 one other abnormality) had survivals similar to those with normal diploid karyotypes (median, 63 and 46 months, respectively), whereas patients with unfavorable abnormalities (rearrangement of chromosome 5 or 7, or \u2265 3 abnormalities) had a poor median survival of 15 months. patients with abnormalities of chromosome 17 had a median survival of only 5 months. a model containing karyotypic abnormalities, hemoglobin, platelet count, and performance status effectively risk-stratified patients at initial evaluation. among 73 patients assessable for clonal evolution during stable chronic phase, those who developed unfavorable or chromosome 17 abnormalities had median survivals of 18 and 9 months, respectively, suggesting the potential role of cytogenetics as a risk factor applicable at any time in the disease course. dynamic prognostic significance of cytogenetic abnormalities in pmf should be further prospectively evaluated.",
            "contribution_ids": [
                "R33089"
            ]
        },
        {
            "instance_id": "R33581xR33153",
            "comparison_id": "R33581",
            "paper_id": "R33153",
            "text": "Strategic Alliance Success Factors \"summary \\nthere is recognition that competition is shifting from a \u201cfirm versus firm perspective\u201d to a \u201csupply chain versus supply chain perspective.\u201d in response to this shift, firms seeking competitive advantage are participating in cooperative supply chain arrangements, such as strategic alliances, which combine their individual strengths and unique resources. buyer-supplier sourcing relationships are a primary focus of alliance improvement efforts. while interest in such arrangements remains strong, it is well accepted that creating, developing, and maintaining a successful alliance is a very daunting task. this research addresses several critical issues regarding that challenge. first, what factors contribute most to long-term alliance success? second, what conditions define the presence of those success factors? third, do buyers and suppliers in an alliance agree on those success factors and defining conditions? the research results demonstrate a remarkably consistent perspective among alliance partners regarding key success factors, despite the acknowledgment that the resultant success is based on a relatively even, but not equal, exchange of benefits and resources. additionally, within an alliance's intended \u201cwin-win\u201d foundation, suppliers must recognize their innate dependence on customers. finally, significant opportunities for improvement exist with respect to alliance goal clarification, communication, and performance evaluation.\"",
            "contribution_ids": [
                "R33154"
            ]
        },
        {
            "instance_id": "R33581xR33171",
            "comparison_id": "R33581",
            "paper_id": "R33171",
            "text": "The successful management of a small logistics company \" in this paper, a case study conducted on a small third\u2010party logistics (3pl) company in hong kong is presented. this company is interesting in that it has been designated as the \u201cking\u201d of hong kong's 3pl (in\u2010bound) logistics companies. the company has been successful in its overall business performance and in satisfying customers. this company's strategic alliances with both clients and customers have helped to improve the utilization of its resources, such as warehouse space and transportation fleets. also, the company is in the process of expanding its operations across greater china, with the objective of becoming a full\u2010pledged 3pl company. the analysis of this case focuses on the critical success factors (strategies and technologies) that have allowed a small company started only in 1996 to become so successful in its operations. also, a framework has been provided for the company to develop its logistics operations as a full\u2010pledged 3pl company. \"",
            "contribution_ids": [
                "R33172"
            ]
        },
        {
            "instance_id": "R33581xR33205",
            "comparison_id": "R33581",
            "paper_id": "R33205",
            "text": "An Exploratory Study of the Success Factors for Extranet Adoption in E-Supply Chain extranet is an enabler/system that enriches the information service quality in e-supply chain. this paper uses factor analysis to determine four extranet success factors: system quality, information quality, service quality, and work performance quality. a critical analysis of areas that require improvement is also conducted.",
            "contribution_ids": [
                "R33206"
            ]
        },
        {
            "instance_id": "R33581xR33223",
            "comparison_id": "R33581",
            "paper_id": "R33223",
            "text": "Successful use of e\u00e2\u0080\u0090procurement in supply chains purpose electronic support of internal supply chains for direct or production goods has been a major element during the implementation of enterprise resource planning (erp) systems that has taken place since the late 1980s. however, supply chains to indirect material suppliers were not usually included due to low transaction volumes, low product values and low strategic importance of these goods. dedicated information systems for streamlining indirect goods supply chains have emerged since the late 1990s and subsequently have faced a broad diffusion in practice. the concept of these e\u2010procurement solutions has also been described broadly in the literature. however, studies on how companies use these e\u2010procurement solutions and what factors are critical to their implementation are only emerging. this research aims to explore the introduction of e\u2010procurement systems and their contribution to the management of indirect goods supply chain. design/methodology/approach chooses a two\u2010part qualitative approach. first, summarizes the results of a benchmarking study that was conducted by a consortium of 12 multinational companies. during the benchmarking process 120 questionnaires were distributed, ten phone\u2010based interviews were conducted, and finally five successful practice companies were selected and analyzed in detail. second, draws together the success factors identified in the benchmarking study and maps them against the successful practice companies. findings although e\u2010procurement has substantially streamlined the procurement and coordination processes for indirect goods, many companies operate multiple e\u2010procurement solutions. for integrated procurement solutions, the paper recognizes the need of an overall procurement strategy and organization, an alignment of various e\u2010procurement solutions along the procurement process and the need for integrated system architectures. companies also have to realize that a no standardized e\u2010procurement solutions exists and that important success factors are \u201cnon\u2010technical\u201d in nature. originality/value this paper presents a first step towards a systematic analysis of factors that may guide companies in the implementation of e\u2010procurement solutions. besides providing a direct contribution to the project work in companies it may stimulate further research in e\u2010procurement success factors.",
            "contribution_ids": [
                "R33224"
            ]
        },
        {
            "instance_id": "R33581xR33261",
            "comparison_id": "R33581",
            "paper_id": "R33261",
            "text": "Supply Base Reduction: An Empirical Study of Critical Success Factors \"summary \\none important factor in the design of an organization's supply chain is the number of suppliers used for a given product or service. supply base reduction is one option useful in managing the supply base. the current paper reports the results of case studies in 10 organizations that recently implemented supply base reduction activities. specifically, the paper identifies the key success factors in supply base reduction efforts and prescribes processes to capture the benefits of supply base reduction.\"",
            "contribution_ids": [
                "R33262"
            ]
        },
        {
            "instance_id": "R33581xR33321",
            "comparison_id": "R33581",
            "paper_id": "R33321",
            "text": "Drivers and impacts of ICT adoption on transport and logistics services summary the availability of high\u2010quality transport and logistics services (tls) is of paramount importance for the growth and competitiveness of an economy. the objective of this paper is to describe how european companies in this industry use information and communication technology (ict) for conducting business and to assess the impact of this development for firms and the industry as a whole. a comparison with some important asia pacific economies is also presented, indicating that some of these countries (singapore, hong kong, japan, taiwan, and korea) boast very good transport infrastructure compared with the most developed european economies. using the structure\u2010conduct\u2010performance (scp) model and the bi\u2010directional relationships of its elements, the paper identifies the links between ict adoption and market structure, innovation dynamics, and firm performance. a set of recommendations on how to further improve the actual scenario of e\u2010business in the tls industry is also presented. the model could also be implemented in asian countries.",
            "contribution_ids": [
                "R33322"
            ]
        },
        {
            "instance_id": "R33581xR33328",
            "comparison_id": "R33581",
            "paper_id": "R33328",
            "text": "Critical success factors in the context of humanitarian aid supply chains purpose critical success factors (csfs) have been widely used in the context of commercial supply chains. however, in the context of humanitarian aid (ha) this is a poorly addressed area and this paper therefore aims to set out the key areas for research. design/methodology/approach this paper is based on a conceptual discussion of csfs as applied to the ha sector. a detailed literature review is undertaken to identify csfs in a commercial context and to consider their applicability to the ha sector. findings csfs have not previously been identified for the ha sector, an issue addressed in this paper. research limitations/implications the main constraint on this paper is that csfs have not been previously considered in the literature as applied to ha. the relevance of csfs will therefore need to be tested in the ha environment and qualitative research is needed to inform further work. practical implications this paper informs the ha community of key areas of activity which have not been fully addressed and offers. originality/value this paper contributes to the understanding of supply chain management in an ha context.",
            "contribution_ids": [
                "R33329"
            ]
        },
        {
            "instance_id": "R33581xR33348",
            "comparison_id": "R33581",
            "paper_id": "R33348",
            "text": "Critical success factors for B2B e\u00e2\u0080\u0090commerce use within the UK NHS pharmaceutical supply chain purpose the purpose of this paper is to determine those factors perceived by users to influence the successful on\u2010going use of e\u2010commerce systems in business\u2010to\u2010business (b2b) buying and selling transactions through examination of the views of individuals acting in both purchasing and selling roles within the uk national health service (nhs) pharmaceutical supply chain. design/methodology/approach literature from the fields of operations and supply chain management (scm) and information systems (is) is used to determine candidate factors that might influence the success of the use of e\u2010commerce. a questionnaire based on these is used for primary data collection in the uk nhs pharmaceutical supply chain. factor analysis is used to analyse the data. findings the paper yields five composite factors that are perceived by users to influence successful e\u2010commerce use. \u201csystem quality,\u201d \u201cinformation quality,\u201d \u201cmanagement and use,\u201d \u201cworld wide web \u2013 assurance and empathy,\u201d and \u201ctrust\u201d are proposed as potential critical success factors. of these, all respondents ranked information quality, system quality, and trust as being of most importance, but differences in the rankings between purchasing and selling respondents are evident. research limitations/implications the empirical study is limited to a single supply network, and although the findings seem intuitively to be of relevance to other sectors and supply contexts, there remains an opportunity to test this through further research. there is also an opportunity to extend the survey research, particularly into the wholesaler organisations that operate in the sector of study. practical implications the managerial implications that result from this research provide practical guidance to organisations in this sector on how to ensure that e\u2010commerce systems for b2b buying and selling are used successfully. originality/value this paper furthers knowledge and understanding in the fields of operations management, is, and scm, by suggesting potential determinants of successful e\u2010commerce use in both buying and selling organisations within supply networks.",
            "contribution_ids": [
                "R33349"
            ]
        },
        {
            "instance_id": "R33581xR33375",
            "comparison_id": "R33581",
            "paper_id": "R33375",
            "text": "Critical factors for implementing green supply chain management practice purpose the purpose of this paper is to explore critical factors for implementing green supply chain management (gscm) practice in the taiwanese electrical and electronics industries relative to european union directives. design/methodology/approach a tentative list of critical factors of gscm was developed based on a thorough and detailed analysis of the pertinent literature. the survey questionnaire contained 25 items, developed based on the literature and interviews with three industry experts, specifically quality and product assurance representatives. a total of 300 questionnaires were mailed out, and 87 were returned, of which 84 were valid, representing a response rate of 28 percent. using the data collected, the identified critical factors were performed via factor analysis to establish reliability and validity. findings the results show that 20 critical factors were extracted into four dimensions, which denominated supplier management, product recycling, organization involvement and life cycle management. research limitations/implications this study obtained 84 valid responses from the taiwanese electrical and electronics industries, the limitation of the study is the insufficient sampling. future researches need to be performed using a larger sample and studying more countries. practical implications the taiwanese electrical and electronics industry plays a decisive role in the global information and communications technology (ict) industry. consequently, the validated instrument enables decision makers at ict manufacturers to evaluate the perceptions of gscm in their organizations. in addition, the critical factors of implementing gscm practices validated in this work can help enterprises identify those areas of gscm where acceptance and improvements will be made, and in prioritizing gscm efforts. originality/value this study presents an empirical investigation of gscm practices, and fills a gap in the literature on the identification and establishment of critical factors for gscm implementation in electrical and electronics industries.",
            "contribution_ids": [
                "R33376"
            ]
        },
        {
            "instance_id": "R33581xR33406",
            "comparison_id": "R33581",
            "paper_id": "R33406",
            "text": "A study of supplier selection factors for high-tech industries in the supply chain amid the intensive competition among global industries, the relationship between manufacturers and suppliers has turned from antagonist to cooperative. through partnerships, both parties can be mutually benefited, and the key factor that maintains such relationship lies in how manufacturers select proper suppliers. the purpose of this study is to explore the key factors considered by manufacturers in supplier selection and the relationships between these factors. through a literature review, eight supplier selection factors, comprising price response capability, quality management capability, technological capability, delivery capability, flexible capability, management capability, commercial image, and financial capability are derived. based on the theoretic foundation proposed by previous researchers, a causal model of supplier selection factors is further constructed. the results of a survey on high-tech industries are used to verify the relationships between the eight factors using structural equation modelling (sem). based on the empirical results, conclusions and suggestions are finally proposed as a reference for manufacturers and suppliers.",
            "contribution_ids": [
                "R33407"
            ]
        },
        {
            "instance_id": "R33581xR33436",
            "comparison_id": "R33581",
            "paper_id": "R33436",
            "text": "A Study of Key Success Factors for Supply Chain Management System in Semiconductor Industry \"developing a supply chain management (scm) system is costly, but important. however, because of its complicated nature, not many of such projects are considered successful. few research publications directly relate to key success factors (ksfs) for implementing and operating a scm system. motivated by the above, this research proposes two hierarchies of ksfs for scm system implementation and operation phase respectively in the semiconductor industry by using a two-step approach. first, a literature review indicates the initial hierarchy. the second step includes a focus group approach to finalize the proposed ksf hierarchies by extracting valuable experiences from executives and managers that actively participated in a project, which successfully establish a seamless scm integration between the world's largest semiconductor foundry manufacturing company and the world's largest assembly and testing company. finally, this research compared the ksf's between the two phases and made a conclusion. future project executives may refer the resulting ksf hierarchies as a checklist for scm system implementation and operation in semiconductor or related industries.\"",
            "contribution_ids": [
                "R33437"
            ]
        },
        {
            "instance_id": "R33581xR33482",
            "comparison_id": "R33581",
            "paper_id": "R33482",
            "text": "Key success factors and their performance implications in the Indian third-party logistics (3PL) industry this paper uses the extant literature to identify the key success factors that are associated with performance in the indian third-party logistics service providers (3pl) sector. we contribute to the sparse literature that has examined the relationship between key success factors and performance in the indian 3pl context. this study offers new insights and isolates key success factors that vary in their impact on operations and financial performance measures. specifically, we found that the key success factor of relationship with customers significantly influenced the operations measures of on-time delivery performance and customer satisfaction and the financial measure of profit growth. similarly, the key success factor of skilled logistics professionals improved the operational measure of customer satisfaction and the financial measure of profit growth. the key success factor of breadth of service significantly affected the financial measure of revenue growth, but did not affect any operational measure. to further unravel the patterns of these results, a contingency analysis of these relationships according to firm size was also conducted. relationship with 3pls was significant irrespective of firm size. our findings contribute to academic theory and managerial practice by offering context-specific suggestions on the usefulness of specific key success factors based on their potential influence on operational and financial performance in the indian 3pl industry.",
            "contribution_ids": [
                "R33483"
            ]
        },
        {
            "instance_id": "R33581xR33486",
            "comparison_id": "R33581",
            "paper_id": "R33486",
            "text": "Understanding the Success Factors of Sustainable Supply Chain Management: Empirical Evidence from the Electrics and Electronics Industry recent studies have reported that organizations are often unable to identify the key success factors of sustainable supply chain management (sscm) and to understand their implications for management practice. for this reason, the implementation of sscm often does not result in noticeable benefits. so far, research has failed to offer any explanations for this discrepancy. in view of this fact, our study aims at identifying and analyzing the factors that underlie successful sscm. success factors are identified by means of a systematic literature review and are then integrated into an explanatory model. consequently, the proposed success factor model is tested on the basis of an empirical study focusing on recycling networks of the electrics and electronics industry. we found that signaling, information provision and the adoption of standards are crucial preconditions for strategy commitment, mutual learning, the establishment of ecological cycles and hence for the overall success of sscm. copyright \u00a9 2011 john wiley & sons, ltd and erp environment.",
            "contribution_ids": [
                "R33487"
            ]
        },
        {
            "instance_id": "R33581xR33489",
            "comparison_id": "R33581",
            "paper_id": "R33489",
            "text": "Identifying critical enablers and pathways to high performance supply chain quality management purpose the aim of this paper is threefold: first, to examine the content of supply chain quality management (scqm); second, to identify the structure of scqm; and third, to show ways for finding improvement opportunities and organizing individual institution\\'s resources/actions into collective performance outcomes. design/methodology/approach to meet the goals of this work, the paper uses abductive reasoning and two qualitative methods: content analysis and formal concept analysis (fca). primary data were collected from both original design manufacturers (odms) and original equipment manufacturers (oems) in taiwan. findings according to the qualitative empirical study, modern enterprises need to pay immediate attention to the following two pathways: a compliance approach and a voluntary approach. for the former, three strategic content variables are identified: training programs, iso, and supplier quality audit programs. as for initiating a voluntary effort, modern lead firms need to instill \u201cmotivation\u201d into a supply chain quality system. practical implications the findings based on the abductive model reveal numerous strategic and tactical enablers, key sequences to move firms from their current situation to their preferred one, and critical opportunities for supply chain\u2010wide quality system designs. originality/value this study will be of great value to supply chain policy makers, supply chain operators, and decision makers in lead firms in a supply chain setting and their channel partners. the proactive use of the authors\\' proposed research procedure is indispensable to effective supply chain quality planning.",
            "contribution_ids": [
                "R33490"
            ]
        },
        {
            "instance_id": "R33581xR33564",
            "comparison_id": "R33581",
            "paper_id": "R33564",
            "text": "Identification of critical success factors 261 to achieve high green supply chain management performances in Indian automobile industry\u00e2\u0080\u009d \"green supply chain management (gscm) has been receiving the spotlight in last few years. the study aims to identify critical success factors (csfs) to achieve high gscm performances from three perspectives i.e., environmental, social and economic performance. csfs to achieve high gscm performances relevant to indian automobile industry have been identified and categorised according to three perspectives from the literature review and experts' opinions. conceptual models also have been put forward. this paper may play vital role to understand csfs to achieve gscm performances in indian automobile industry and help the supply chain managers to understand how they may improve environmental, social and economic performance.\"",
            "contribution_ids": [
                "R33565"
            ]
        },
        {
            "instance_id": "R33783xR33637",
            "comparison_id": "R33783",
            "paper_id": "R33637",
            "text": "Harmonic content extraction in converter waveforms using radial basis function neural networks (RBFNN) and p-q power theory in this paper radial basis function neural network (rbfnn) is used to extract total harmonics in converter waveforms. the methodology is based on p-q (real power-imaginary power) theory. the converter waveforms are analyzed and the harmonics over a wide operating range are extracted. the proposed rbfnn filtering training algorithms are based on an efficient training method called hybrid learning method \u2014 computation is systematic. the method requires small size network, very robust, and the proposed algorithms are very effective. the analysis is verified using matlab/simulink simulation.",
            "contribution_ids": [
                "R33638",
                "R33732"
            ]
        },
        {
            "instance_id": "R33783xR33641",
            "comparison_id": "R33783",
            "paper_id": "R33641",
            "text": "A Comparative Experimental Study of Neural and Conventional Controllers for an Active Power Filter \"this paper will consider the benefits of neural controllers over model-based current regulators to supervise the current generation of a shunt active power filter. the task consists in generating appropriate compensation currents with a system composed of a voltage source inverter and a low-pass filter. these currents cancel the harmonic terms introduced by nonlinear loads in a power distribution grid. the performances of conventional controllers such as a pi and resonant current regulators are confronted to neural controllers. if conventional regulators present some advantages in terms of engineering specifications, their tuning remains difficult and their design relies on a rough linearization of the system. their performances are acceptable without perturbations. however, fast changes of nonlinear loads lead to different operating points of the system. furthermore, the inverter's nonlinearities and low-pass filter parameters have to be considered for generating precise currents. two neural approaches have therefore been proposed, one which estimates the input-output relationship of the system, and one which relies on a state-space representation of the system. these approaches combine learning capabilities with a priori knowledge of the system. the benefits of the neural approaches are discussed and illustrated by simulations and by experimental tests with real-time implementations on a digital signal processing board.\"",
            "contribution_ids": [
                "R33642",
                "R33734"
            ]
        },
        {
            "instance_id": "R33783xR33649",
            "comparison_id": "R33783",
            "paper_id": "R33649",
            "text": "A Novel Hysteresis Current Control Strategy Based on Neural Network the relationship among principle of variable-band hysteresis current control, compensation capacity of hysteresis and switching frequency is dissertated in this paper. aimed at changing the disadvantages of variable-band current control strategy resulted from the fuzzy controller, a control strategy based on command current and current error is proposed and realized by neural network. power electronics model is built by matlab and psim and logical control circuit is built according to the fuzzy rules and neural network respectively. co-simulation results indicate that the hysteresis based on neural network controller has better compensation capacity than the hysteresis based on fuzzy controller and reduces switching frequency.",
            "contribution_ids": [
                "R33650",
                "R33738"
            ]
        },
        {
            "instance_id": "R33783xR33657",
            "comparison_id": "R33783",
            "paper_id": "R33657",
            "text": "Study on Improved Neural Network PID Control of APF DC Voltage according to the active power balance principle, the paper analyzed the approximate mathematical model of apf. in order to optimize the control effect of dc bus voltage in apf, pid control method based on improved bp neural network is adopted to do closed-loop control to the system. the two strategies, adding momentum method and adaptive learning rate adjustment, are combined to improve bp network, which can not only effectively suppress the network appearing local minimum but also good to shorten learning time and improve stability of the network furthermore. the improved bp network adjusted the parameters such as kp and ki of pid controller according to the operation state of the system and realized optimum pid control. the experiment studies show that on condition of load power and harmonic content changing, apf system, controlled by pid control method based on improved bp network, can assure the harmonic distortion keeps in an allowed range and the dc side voltage becomes stable in a short time.",
            "contribution_ids": [
                "R33658",
                "R33742"
            ]
        },
        {
            "instance_id": "R33783xR33669",
            "comparison_id": "R33783",
            "paper_id": "R33669",
            "text": "Harmonic elimination and reactive power compensation through a shunt active power filter by twin neural networks with predictive and adaptive properties a method for controlling an active power filter using artificial neural network(ann) is presented in this paper. this paper applies ann based predictive and adaptive reference generation technique. predictive scheme extracts the information of the fundamental component through an ann that replaces a low pass filter. this ann based low pass-filter is trained offline with large number of training set to predict the fundamental magnitude of load current. this predictive reference generation technique works well for clean source voltage. however, the performance deteriorates in case of distortion in source voltage and also with noise. to overcome this, an adaline based ann is applied after the operation of the predictive algorithm. it has been shown that the combined predictive-adaptive approach offers better performance. simulation results and experimental results are presented to confirm the usefulness of the proposed technique..",
            "contribution_ids": [
                "R33670",
                "R33748"
            ]
        },
        {
            "instance_id": "R33783xR33673",
            "comparison_id": "R33783",
            "paper_id": "R33673",
            "text": "Neural Network and Bandless Hysteresis Approach to Control Switched Capacitor Active Power Filter for Reduction of Harmonics \"this paper proposes a combination of neural network and a bandless hysteresis controller, for a switched capacitor active power filter (scapf), to improve line power factor and to reduce line current harmonics. the proposed active power filter controller forces the supply current to be sinusoidal, in phase with line voltage, and has low current harmonics. two main controls are proposed for it: neural network detection of harmonics and bandless digital hysteresis switching algorithm. a mathematical algorithm and a suitable learning rate determine the filter's optimal operation. a digital signal controller (tms320f2812) verifies the proposed scapf, implementing the neural network and bandless hysteresis algorithms. a laboratory scapf system is built to test its feasibility. simulation and experimental results are provided to verify performance of the proposed scapf system.\"",
            "contribution_ids": [
                "R33674",
                "R33750"
            ]
        },
        {
            "instance_id": "R33783xR33675",
            "comparison_id": "R33783",
            "paper_id": "R33675",
            "text": "Predictive and Adaptive ANN (Adaline) Based Harmonic Compensation for Shunt Active Power Filter estimation of the current-reference to compensate for the harmonic and reactive component of the load current is important in a shunt type active power filter. this paper applies ann based predictive and adaptive reference generation technique. predictive scheme extracts the information of the fundamental component through an ann that replaces a low pass filter. this ann based low pass-filter is trained offline with large number of training set to predict the fundamental magnitude of load current. these predictive reference generation techniques work well for load change pattern closer to the trained data and for clean source voltage. however, the performance deteriorates in case of distortion in source voltage and also if training data drifts quite significantly from test data. to overcome this, an adaline based ann is applied after the operation of the predictive algorithm. it has been shown that the combined predictive adaptive approach offers better performance. extensive results from simulation have confirmed the usefulness of the proposed technique.",
            "contribution_ids": [
                "R33676",
                "R33751"
            ]
        },
        {
            "instance_id": "R33783xR33681",
            "comparison_id": "R33783",
            "paper_id": "R33681",
            "text": "A Neural Networks-Based Method for Single-Phase Harmonic Content Identification a neural method is presented in this paper to identify the harmonic components of an ac controller. the components are identified by analyzing the single-phase current waveform. the method effectiveness is verified by applying it to an active power filter (apf) model dedicated to the selective harmonic compensation. simulation results using theoretical and experimental data are presented to validate the proposed approach.",
            "contribution_ids": [
                "R33682",
                "R33754"
            ]
        },
        {
            "instance_id": "R33783xR33683",
            "comparison_id": "R33783",
            "paper_id": "R33683",
            "text": "An ANN based Digital Controller for a Three-phase Active Power Filter three-phase shunt active power filters are designed to effectively compensate for the current harmonics and reactive power requirements in a three-phase system with harmonic loads. an ann (artificial neural network) based controller selects the amount of harmonic current injection based on the percentage of harmonic distortion present in the source current and also on the reactive power requirement of the load. the selection is done by the ann with the help of a properly tuned knowledge base.",
            "contribution_ids": [
                "R33684",
                "R33755"
            ]
        },
        {
            "instance_id": "R33783xR33691",
            "comparison_id": "R33783",
            "paper_id": "R33691",
            "text": "Intelligent Control and Application of All-Function Active Power Filter an all-function active power filter which can compensate harmonics inter-harmonics, asymmetries, fundamental sequence reactive powers and so on is introduced in this paper. its basic concept and main features working process are illuminated briefly. to solve the difficulty problem of control for all-function active power filter, its intelligent control strategy and working process based on bp neural network are expounded. first, basic theory of bp neural network to control all-function active power is analyzed. then, the basic configuration and working process of an all-function active power filter based on bp neural network control strategy is detailed. finally, simulations and simulative results are given. theory analysis and the simulative results show that the intelligent control strategy based on bp neural network can make all-function active power filter in possession of full function and predominant working characteristics.",
            "contribution_ids": [
                "R33692",
                "R33759"
            ]
        },
        {
            "instance_id": "R33783xR33705",
            "comparison_id": "R33783",
            "paper_id": "R33705",
            "text": "Single-Phase Shunt Hybrid Active Power Filter Based on ANN in this paper, a single-phase shunt hybrid active power filter (apf) is presented to compensate reactive power and eliminate harmonics in power system. the hybrid active filter consists of one active filter and one passive filter connected in series. by controlling the equivalent output voltage of active filter, the harmonic currents generated by the nonlinear load are blocked and flowed into the passive filter. sensing load current, dc bus voltage, dc bus reference voltage and source voltage compute reference voltage of apf through modified adaptive artificial neural network (ann). and a voltage controller is used to generate the firing pulses of the voltage source inverter. the proposed system is implemented using digital signal processor (dsp). simulating results are presented to confirm the validity of the scheme.",
            "contribution_ids": [
                "R33706",
                "R33766"
            ]
        },
        {
            "instance_id": "R33783xR33711",
            "comparison_id": "R33783",
            "paper_id": "R33711",
            "text": "A Unified Artificial Neural Network Architecture for Active Power Filters in this paper, an efficient and reliable neural active power filter (apf) to estimate and compensate for harmonic distortions from an ac line is proposed. the proposed filter is completely based on adaline neural networks which are organized in different independent blocks. we introduce a neural method based on adalines for the online extraction of the voltage components to recover a balanced and equilibrated voltage system, and three different methods for harmonic filtering. these three methods efficiently separate the fundamental harmonic from the distortion harmonics of the measured currents. according to either the instantaneous power theory or to the fourier series analysis of the currents, each of these methods are based on a specific decomposition. the original decomposition of the currents or of the powers then allows defining the architecture and the inputs of adaline neural networks. different learning schemes are then used to control the inverter to inject elaborated reference currents in the power system. results obtained by simulation and their real-time validation in experiments are presented to compare the compensation methods. by their learning capabilities, artificial neural networks are able to take into account time-varying parameters, and thus appreciably improve the performance of traditional compensating methods. the effectiveness of the algorithms is demonstrated in their application to harmonics compensation in power systems",
            "contribution_ids": [
                "R33712",
                "R33769"
            ]
        },
        {
            "instance_id": "R33783xR33717",
            "comparison_id": "R33783",
            "paper_id": "R33717",
            "text": "Adaptive Filtering for Unstable Power System Harmonics using Artificial Network conventional approaches for harmonics filtering usually employ either passive, active filtering techniques or hybrid filters. this paper proposes an adaptive harmonic filtering approach using a modified discrete hopfield network model. the advantage of the scheme is that it can extract the fundamental component of the distorted current and provide a suitable compensation current as the power harmonics may vary in amplitude and frequency from time to time. therefore, the time-variant harmonic environments in real-time machine systems can be adapted successfully. real-time performance experiments verify that the proposed scheme is feasible in term of real-time tracking, adaptive low frequency harmonics filtering, fast training and convergence speed.",
            "contribution_ids": [
                "R33718",
                "R33772"
            ]
        },
        {
            "instance_id": "R33783xR33719",
            "comparison_id": "R33783",
            "paper_id": "R33719",
            "text": "Synchronous Reference Frame Based Active Filter Current Reference Generation Using Neural Networks \"the increased use of nonlinear devices in industry has resulted in direct increase of harmonic distortion in the industrial power system in recent years. the significant harmonics are almost always 5th, 7th, 11th and the 13th with the 5th harmonic being the largest in most instances. active filter systems have been proposed to mitigate harmonic currents of the industrial loads. the most important requirement for any active filter is the precise detection of the individual harmonic component's amplitude and phase. fourier transform based techniques provide an excellent method for individual harmonic isolation, but it requires a minimum of two cycles of data for the analysis, does not perform well in the presence of subharmonics which are not integral multiples of the fundamental frequency and most importantly introduces phase shifts. to overcome these difficulties, this paper proposes a multilayer perceptron neural network trained with back-propagation training algorithm to identify the harmonic characteristics of the nonlinear load. the operation principle of the synchronous-reference-frame-based harmonic isolation is discussed. this proposed method is applied to a thyristor controlled dc drive to obtain the accurate amplitude and phase of the dominant harmonics. this technique can be integrated with any active filter control algorithm for reference generation\"",
            "contribution_ids": [
                "R33720",
                "R33773"
            ]
        },
        {
            "instance_id": "R33783xR33727",
            "comparison_id": "R33783",
            "paper_id": "R33727",
            "text": "Artificial Neural Network Controlled Shunt Active Power Filter this paper presents neural based proportional integral (pi) control applicable for active power filters for single-phase system, which are comprised of multiple nonlinear loads. the system consists of an uncontrolled rectifier and ac controller as the non-linear loads, with an active filter to compensate for the harmonic current injected by the load. the active filter is based on a single-phase inverter with four controllable switches, a standard h-bridge inverter. the ac side of the inverter is connected in parallel with the other nonlinear loads through a filter inductance. the dc side of the inverter is connected to a filter capacitor. the neural pi controller is used to shape the current through the filter inductor such that the line current is in phase with and of the same shape as the input voltage. the spectral analysis of the supply current shows the harmonics produced by the load has been successfully compensated by the active filter. the system is modeled in matlab simulink and simulation results prove that the injected harmonics are greatly reduced and system efficiency and power factor are improved",
            "contribution_ids": [
                "R33728",
                "R33777"
            ]
        },
        {
            "instance_id": "R33851xR33802",
            "comparison_id": "R33851",
            "paper_id": "R33802",
            "text": "Assessment of algorithms for high throughput detection of genomic copy number variation in oligonucleotide microarray data abstract \\n \\n background \\n genomic deletions and duplications are important in the pathogenesis of diseases, such as cancer and mental retardation, and have recently been shown to occur frequently in unaffected individuals as polymorphisms. affymetrix genechip whole genome sampling analysis (wgsa) combined with 100 k single nucleotide polymorphism (snp) genotyping arrays is one of several microarray-based approaches that are now being used to detect such structural genomic changes. the popularity of this technology and its associated open source data format have resulted in the development of an increasing number of software packages for the analysis of copy number changes using these snp arrays. \\n \\n \\n results \\n we evaluated four publicly available software packages for high throughput copy number analysis using synthetic and empirical 100 k snp array data sets, the latter obtained from 107 mental retardation (mr) patients and their unaffected parents and siblings. we evaluated the software with regards to overall suitability for high-throughput 100 k snp array data analysis, as well as effectiveness of normalization, scaling with various reference sets and feature extraction, as well as true and false positive rates of genomic copy number variant (cnv) detection. \\n \\n \\n conclusion \\n we observed considerable variation among the numbers and types of candidate cnvs detected by different analysis approaches, and found that multiple programs were needed to find all real aberrations in our test set. the frequency of false positive deletions was substantial, but could be greatly reduced by using the snp genotype information to confirm loss of heterozygosity. \\n",
            "contribution_ids": [
                "R33803"
            ]
        },
        {
            "instance_id": "R33851xR33808",
            "comparison_id": "R33851",
            "paper_id": "R33808",
            "text": "Comparing CNV detection methods for SNP arrays data from whole genome association studies can now be used for dual purposes, genotyping and copy number detection. in this review we discuss some of the methods for using snp data to detect copy number events. we examine a number of algorithms designed to detect copy number changes through the use of signal-intensity data and consider methods to evaluate the changes found. we describe the use of several statistical models in copy number detection in germline samples. we also present a comparison of data using these methods to assess accuracy of prediction and detection of changes in copy number.",
            "contribution_ids": [
                "R33809"
            ]
        },
        {
            "instance_id": "R33851xR33819",
            "comparison_id": "R33851",
            "paper_id": "R33819",
            "text": "The Effect of Algorithms on Copy Number Variant Detection background the detection of copy number variants (cnvs) and the results of cnv-disease association studies rely on how cnvs are defined, and because array-based technologies can only infer cnvs, cnv-calling algorithms can produce vastly different findings. several authors have noted the large-scale variability between cnv-detection methods, as well as the substantial false positive and false negative rates associated with those methods. in this study, we use variations of four common algorithms for cnv detection (penncnv, quantisnp, hmmseg, and cnvpartition) and two definitions of overlap (any overlap and an overlap of at least 40% of the smaller cnv) to illustrate the effects of varying algorithms and definitions of overlap on cnv discovery. methodology and principal findings we used a 56 k illumina genotyping array enriched for cnv regions to generate hybridization intensities and allele frequencies for 48 caucasian schizophrenia cases and 48 age-, ethnicity-, and gender-matched control subjects. no algorithm found a difference in cnv burden between the two groups. however, the total number of cnvs called ranged from 102 to 3,765 across algorithms. the mean cnv size ranged from 46 kb to 787 kb, and the average number of cnvs per subject ranged from 1 to 39. the number of novel cnvs not previously reported in normal subjects ranged from 0 to 212. conclusions and significance motivated by the availability of multiple publicly available genome-wide snp arrays, investigators are conducting numerous analyses to identify putative additional cnvs in complex genetic disorders. however, the number of cnvs identified in array-based studies, and whether these cnvs are novel or valid, will depend on the algorithm(s) used. thus, given the variety of methods used, there will be many false positives and false negatives. both guidelines for the identification of cnvs inferred from high-density arrays and the establishment of a gold standard for validation of cnvs are needed.",
            "contribution_ids": [
                "R33820"
            ]
        },
        {
            "instance_id": "R33953xR33888",
            "comparison_id": "R33953",
            "paper_id": "R33888",
            "text": "A Non- Pheromone based Intelligent Swarm Optimization Technique in Software Test Suite Optimization in our paper, we applied a non-pheromone based intelligent swarm optimization technique namely artificial bee colony optimization (abc) for test suite optimization. our approach is a population based algorithm, in which each test case represents a possible solution in the optimization problem and happiness value which is a heuristic introduced to each test case corresponds to the quality or fitness of the associated solution. the functionalities of three groups of bees are extended to three agents namely search agent, selector agent and optimizer agent to select efficient test cases among near infinite number of test cases. because of the parallel behavior of these agents, the solution generation becomes faster and makes the approach an efficient one. since, the test adequacy criterion we used is path coverage; the quality of the test cases is improved during each iteration to cover the paths in the software. finally, we compared our approach with ant colony optimization (aco), a pheromone based optimization technique in test suite optimization and finalized that, abc based approach has several advantages over aco based optimization.",
            "contribution_ids": [
                "R33889"
            ]
        },
        {
            "instance_id": "R33953xR33907",
            "comparison_id": "R33953",
            "paper_id": "R33907",
            "text": "An approach of optimal path generation using ant colony optimization software testing is one of the indispensable parts of the software development lifecycle and structural testing is one of the most widely used testing paradigms to test various software. structural testing relies on code path identification, which in turn leads to identification of effective paths. aim of the current paper is to present a simple and novel algorithm with the help of an ant colony optimization, for the optimal path identification by using the basic property and behavior of the ants. this novel approach uses certain set of rules to find out all the effective/optimal paths via ant colony optimization (aco) principle. the method concentrates on generation of paths, equal to the cyclomatic complexity. this algorithm guarantees full path coverage.",
            "contribution_ids": [
                "R33908"
            ]
        },
        {
            "instance_id": "R33953xR33918",
            "comparison_id": "R33953",
            "paper_id": "R33918",
            "text": "Automated Software Testing Using Metaheuristic Technique Based on an Ant Colony Optimization software testing is an important and valuable part of the software development life cycle. due to time, cost and other circumstances, exhaustive testing is not feasible that\u2019s why there is a need to automate the testing process. testing effectiveness can be achieved by the state transition testing (stt) which is commonly used in real time, embedded and web-based kinds of software systems. the tester\u2019s main job to test all the possible transitions in the system. this paper proposed an ant colony optimization (aco) technique for the automated and full coverage of all state-transitions in the system. present paper approach generates test sequence in order to obtain the complete software coverage. this paper also discusses the comparison between two metaheuristic techniques (genetic algorithm and ant colony optimization) for transition based testing.",
            "contribution_ids": [
                "R33919"
            ]
        },
        {
            "instance_id": "R33953xR33931",
            "comparison_id": "R33953",
            "paper_id": "R33931",
            "text": "Generation of test data using Meta heuristic approach software testing is of huge importance to development of any software. the prime focus is to minimize the expenses on the testing. in software testing the major problem is generation of test data. several metaheuristic approaches in this field have become very popular. the aim is to generate the optimum set of test data, which would still not compromise on exhaustive testing of software. our objective is to generate such efficient test data using genetic algorithm and ant colony optimization for a given software. we have also compared the two approaches of software testing to determine which of these are effective towards generation of test data and constraints if any.",
            "contribution_ids": [
                "R33932"
            ]
        },
        {
            "instance_id": "R33953xR33939",
            "comparison_id": "R33953",
            "paper_id": "R33939",
            "text": "An Optimization Method of Test Suite in Regression Test Model original test cases should be reused and new ones should be supplemented in regression test. for optimizing test suite, pair-wise combination test cases generating method is adopted in this paper, which was realized by ant colony algorithm with monolepsis diagnostic. when original and new generated test suite was united, improved greedy arithmetic was adopted to reduce test suite and random off-trap strategy was introduced. the test case study result shows the method can reduce the scale of test suite effectively and decrease the regression test cost.",
            "contribution_ids": [
                "R33940"
            ]
        },
        {
            "instance_id": "R33953xR34961",
            "comparison_id": "R33953",
            "paper_id": "R34961",
            "text": "Introduction: A Survey of the Evolutionary Computation Techniques for Software Engineering this chapter aims to present a part of the computer science literature in which the evolutionary computation techniques, optimization techniques and other bio-inspired techniques are used to solve different search and optimization problems in the area of software engineering.",
            "contribution_ids": [
                "R33948",
                "R34963"
            ]
        },
        {
            "instance_id": "R34099xR33991",
            "comparison_id": "R34099",
            "paper_id": "R33991",
            "text": "Facultative catadromy of the eel Anguilla japonica between freshwater and seawater habitats \"to confirm the occurrence of marine residents of the japanese eel, anguilla japonica, which have never entered freshwater ('sea eels'), we measured sr and ca concentrations by x-ray electron microprobe analysis of the otoliths of 69 yellow and silver eels, collected from 10 localities in seawater and freshwater habitats around japan, and classified their migratory histories. two-dimen- sional images of the sr concentration in the otoliths showed that all specimens generally had a high sr core at the center of their otolith, which corresponded to a period of their leptocephalus and early glass eel stages in the ocean, but there were a variety of different patterns of sr concentration and concentric rings outside the central core. line analysis of sr/ca ratios along the radius of each otolith showed peaks (ca 15 \u00d7 10 -3 ) between the core and out to about 150 \u00b5m (elver mark). the pattern change of the sr/ca ratio outside of 150 \u00b5m indicated 3 general categories of migratory history: 'river eels', 'estuarine eels' and 'sea eels'. these 3 categories corresponded to mean values of sr/ca ratios of \u2265 6.0 \u00d7 10 -3 for sea eels, which spent most of their life in the sea and did not enter freshwater, of 2.5 to 6.0 \u00d7 10 -3 for estuarine eels, which inhabited estuaries or switched between different habitats, and of <2.5 \u00d7 10 -3 for river eels, which entered and remained in freshwater river habitats after arrival in the estuary. the occurrence of sea eels was 20% of all specimens examined and that of river eels, 23%, while estuarine eels were the most prevalent (57%). the occurrence of sea eels was confirmed at 4 localities in japanese coastal waters, including offshore islands, a small bay and an estuary. the finding of estuarine eels as an intermediate type, which appear to frequently move between different habitats, and their presence at almost all localities, suggested that a. japonica has a flexible pattern of migration, with an ability to adapt to various habitats and salinities. thus, anguillid eel migrations into freshwater are clearly not an obligatory migratory pathway, and this form of diadromy should be defined as facultative catadromy, with the sea eel as one of several ecophenotypes. furthermore, this study indicates that eels which utilize the marine environment to various degrees during their juve- nile growth phase may make a substantial contribution to the spawning stock each year.\"",
            "contribution_ids": [
                "R33992"
            ]
        },
        {
            "instance_id": "R34099xR34053",
            "comparison_id": "R34099",
            "paper_id": "R34053",
            "text": "Coexistence of anadromous and lacustrine life histories of the shirauo, Sala- nichthys microdon the environmental history of the shirauo, salangichthys microdon, was examined in terms of strontium (sr) and calcium (ca) uptake in the otolith, by means of wavelength dispersive x-ray spectrometry on an electron microprobe. anadromous and lacustrine type of the shirauo were found to occur sympatric. otolith sr concentration or sr\\xa0:\\xa0ca ratios of anadromous shirauo fluctuated strongly along the life-history transect in accordance with the migration (habitat) pattern from sea to freshwater. in contrast, the sr concentration or the sr\\xa0:\\xa0ca ratios of lacustrine shirauo remained at consistently low levels throughout the otolith. the higher ratios in anadromous shirauo, in the otolith region from the core to 90\u2013230\\xa0\u03bcm, corresponded to the initial sea-going period, probably reflecting the ambient salinity or the seawater\u2013freshwater gradient in sr concentration. the findings clearly indicated that otolith sr\\xa0:\\xa0ca ratios reflected individual life histories, enabling these anadromous shirauo to be distinguished from lacustrine shirauo.",
            "contribution_ids": [
                "R34054"
            ]
        },
        {
            "instance_id": "R34099xR34060",
            "comparison_id": "R34099",
            "paper_id": "R34060",
            "text": "Population structure of sympatric anadromous and nonanadromous Oncorhynchus mykiss: evidence from spawning surveys and otolith microchemistry reproductive isolation between steelhead and resident rainbow trout (oncorhynchus mykiss) was examined in the deschutes river, oregon, through surveys of spawning timing and location. otolith microchemistry was used to determine the occurrence of steelhead and resident rainbow trout progeny in the adult populations of steelhead and resident rainbow trout in the deschutes river and in the babine river, british columbia. in the 3 years studied, steelhead spawning occurred from mid march through may and resident rainbow trout spawning occurred from mid march through august. the timing of 50% spawning was 9-10 weeks earlier for steelhead than for resident rainbow trout. spawning sites selected by steelhead were in deeper water and had larger substrate than those selected by resident rainbow trout. maternal origin was identified by comparing sr/ca ratios in the primordia and freshwater growth regions of the otolith with a wavelength-dispersive electron microprobe. in the deschutes river, only steelhead of steelhead maternal origin and resident rainbow trout of resident rainbow trout origin were observed. in the babine river, steelhead of resident rainbow trout origin and resident rainbow trout of steelhead maternal origin were also observed. based on these findings, we suggest that steelhead and resident rainbow trout in the deschutes river may constitute reproductively isolated populations.",
            "contribution_ids": [
                "R34061"
            ]
        },
        {
            "instance_id": "R34099xR34063",
            "comparison_id": "R34099",
            "paper_id": "R34063",
            "text": "Evidence of different habitat use by New Zealand freshwater eels Anguilla australis and A. dieffenbachii, as revealed by otolith microchemistry the apparent use of marine and freshwater habitats by anguilla australis and a. dieffenbachii was examined by analyzing the strontium (sr) and calcium (ca) concentrations in otoliths of silver eels collected from lake ellesmere, which is a shallow brackish-water coastal lagoon in new zealand. the age and growth of these eels was also examined using their otolith annuli. size and ages of females were greater than those of males for both species. growth rates were similar among sex and species, but the highest growth rates were observed in eels that experienced saline environments. line analyses of sr:ca ratios along a life-history transect in each otolith showed peaks (ca. 15 to 21 \u00d7 10 -3 in a. australis, 14 to 20 \u00d7 10 -3 in a. dieffenbachii) between the core and elver mark, which corresponded to the period of their leptocephalus and early glass eel stage in the ocean. out- side the elver mark, the sr:ca ratios indicated that eels had remained in different habitats that included freshwater (average sr:ca ratios, 1.8 to 2.4 \u00d7 10 -3 ), areas with relatively high salinities (aver- age sr:ca ratios, 3.0 to 7.4 \u00d7 10 -3 ), and in some cases individuals showed clear evidence of shifts in the salinity of their environments. these shifts either indicated movements between different loca- tions, or changes in the salinity of the lake. there were more individuals of a. australis that used areas with intermediate or high salinities, at least for a short time (85% of individuals), than a. dief- fenbachii (30%). these findings suggest that these 2 southern temperate species may have the same behavioral plasticity regarding whether or not to enter freshwater or remain in marine environments, as has been recently documented in several northern temperate anguillid species.",
            "contribution_ids": [
                "R34064",
                "R34065"
            ]
        },
        {
            "instance_id": "R34099xR34072",
            "comparison_id": "R34099",
            "paper_id": "R34072",
            "text": "Migratory environmental history of the grey mullet Mugil cephalus as revealed by otolith Sr:Ca ratios we used an electron probe microanalyzer (epma) to determine the migratory environ- mental history of the catadromous grey mullet mugil cephalus from the sr:ca ratios in otoliths of 10 newly recruited juveniles collected from estuaries and 30 adults collected from estuaries, nearshore (coastal waters and bay) and offshore, in the adjacent waters off taiwan. mean (\u00b1sd) sr:ca ratios at the edges of adult otoliths increased significantly from 6.5 \u00b1 0.9 \u00d7 10 -3 in estuaries and nearshore waters to 8.9 \u00b1 1.4 \u00d7 10 -3 in offshore waters (p < 0.01), corresponding to increasing ambi- ent salinity from estuaries and nearshore to offshore waters. the mean sr:ca ratios decreased sig- nificantly from the core (11.2 \u00b1 1.2 \u00d7 10 -3 ) to the otolith edge (6.2 \u00b1 1.4 \u00d7 10 -3 ) in juvenile otoliths (p < 0.001). the mullet generally spawned offshore and recruited to the estuary at the juvenile stage; therefore, these data support the use of sr:ca ratios in otoliths to reconstruct the past salinity history of the mullet. a life-history scan of the otolith sr:ca ratios indicated that the migratory environmen- tal history of the mullet beyond the juvenile stage consists of 2 types. in type 1 mullet, sr:ca ratios range between 4.0 \u00d7 10 -3 and 13.9 \u00d7 10 -3 , indicating that they migrated between estuary and offshore waters but rarely entered the freshwater habitat. in type 2 mullet, the sr:ca ratios decreased to a minimum value of 0.4 \u00d7 10 -3 , indicating that the mullet migrated to a freshwater habitat. most mullet beyond the juvenile stage migrated from estuary to offshore waters, but a few mullet less than 2 yr old may have migrated into a freshwater habitat. most mullet collected nearshore and offshore were of type 1, while those collected from the estuaries were a mixture of types 1 and 2. the mullet spawning stock consisted mainly of type 1 fish. the growth rates of the mullet were similar for types 1 and 2. the migratory patterns of the mullet were more divergent than indicated by previous reports of their catadromous behavior.",
            "contribution_ids": [
                "R34073"
            ]
        },
        {
            "instance_id": "R34126xR34102",
            "comparison_id": "R34126",
            "paper_id": "R34102",
            "text": "Optic neuritis: oligoclo- nal bands increase the risk of multiple sclerosis abstract\u2010 in 1974 we examined 30 patients 0.5\u201314 (mean 5) years after acute unilateral optic neuritis (on), when no clinical signs of multiple sclerosis (ms) were discernable. 11 of the patients had oligoclonal bands in the cerebrospinal fluid (csf). re\u2010examination after an additional 6 years revealed that 9 of the 11 on patients with oligoclonal bands (but only 1 of the 19 without this csf abnormality) had developed ms. the occurrence of oligoclonal bands in csf in a patient with on is \u2010 within the limits of the present observation time \u2010 accompanied by a significantly increased risk of the future development of ms. recurrent on also occurred significantly more often in those on patients who later developed ms.",
            "contribution_ids": [
                "R34103"
            ]
        },
        {
            "instance_id": "R34126xR34108",
            "comparison_id": "R34126",
            "paper_id": "R34108",
            "text": "Optic neuritis: Prognosis for multiple sclerosis from MRI, CSF, and HLA findings we investigated the paraclinical profile of monosymptomatic optic neuritis(on) and its prognosis for multiple sclerosis (ms). the correct identification of patients with very early ms carrying a high risk for conversion to clinically definite ms is important when new treatments are emerging that hopefully will prevent or at least delay future ms. we conducted a prospective single observer and population-based study of 147 consecutive patients (118 women, 80%) with acute monosymptomatic on referred from a catchment area of 1.6 million inhabitants between january 1, 1990 and december 31, 1995. of 116 patients examined with brain mri, 64 (55%) had three or more high signal lesions, 11 (9%) had one to two high signal lesions, and 41 (35%) had a normal brain mri. among 143 patients examined, oligoclonal igg (ob) bands in csf only were demonstrated in 103 patients (72%). of 146 patients analyzed, 68 (47%) carried the dr15,dq6,dw2 haplotype. during the study period, 53 patients (36%) developed clinically definite ms. the presence of three or more ms-like mri lesions as well as the presence of ob were strongly associated with the development of ms (p < 0.001). also, dw2 phenotype was related to the development of ms (p = 0.046). mri and csf studies in patients with on give clinically important information regarding the risk for future ms.",
            "contribution_ids": [
                "R34109"
            ]
        },
        {
            "instance_id": "R34126xR34122",
            "comparison_id": "R34126",
            "paper_id": "R34122",
            "text": "Uncomplicated retrobul- bar neuritis and the development of multiple sclerosis abstract a retrospective study of 30 patients hospitalized with a diagnosis of uncomplicated retrobulbar neuritis was carried out. the follow\u2010up period was 2\u201311 years; 57% developed multiple sclerosis. when the initial examination revealed oligoclonal bands in the cerebrospinal fluid, the risk of developing multiple sclerosis increased to 79%. with normal cerebrospinal fluid the risk decreased to only 10%. in the majority of cases, the diagnosis of ms was made during the first 3 years after retrobulbar neuritis.",
            "contribution_ids": [
                "R34123"
            ]
        },
        {
            "instance_id": "R34183xR34130",
            "comparison_id": "R34183",
            "paper_id": "R34130",
            "text": "First impact of biotechnology in the EU: Bt maize adoption in Spain summary in the present paper we build a bio-economic model to estimate the impact of a biotechnology innovation in eu agriculture. transgenic bt maize offers the potential to efficiently control corn borers, that cause economically important losses in maize growing in spain. since 1998, syngenta has commercialised the variety compa cb, equivalent to an annual maize area of about 25,000 ha. during the six-year period 1998-2003 a total welfare gain of \u20ac15.5 million is estimated from the adoption of bt maize, of which spanish farmers captured two thirds, the rest accruing to the seed industry.",
            "contribution_ids": [
                "R34131"
            ]
        },
        {
            "instance_id": "R34183xR34136",
            "comparison_id": "R34183",
            "paper_id": "R34136",
            "text": "Case study in benefits and risks of agricultural biotechnology: Roundup Ready soybeans. abstract this case study describes the us regulatory process governing agricultural biotechnology and traces the approval of roundup ready soyabeans (with transgenic tolerance of the herbicide glyphosate), summarizing the information that was submitted to us regulatory agencies by monsanto. estimates of the impact that the adoption of roundup ready soyabeans has had on us agriculture are also provided. the us regulatory structure for agricultural biotechnology has evolved over the past 25 years, as technology allowing for genetic modification developed. the system continues to evolve as new and different applications of the technology emerge. in reviewing the studies that were conducted on the safety of roundup ready soyabeans, no indication of greater health or environmental risks were found compared with conventional varieties. the benefits of the introduction of roundup ready soyabeans include cost savings of us$216 million in annual weed control and 19 million fewer soyabean herbicide applications per year.",
            "contribution_ids": [
                "R34137",
                "R34150",
                "R34170"
            ]
        },
        {
            "instance_id": "R34183xR34153",
            "comparison_id": "R34183",
            "paper_id": "R34153",
            "text": "Five years of Bt cotton in China - the benefits continue bt cotton is spreading very rapidly in china, in response to demand from farmers for technology that will reduce both the cost of pesticide applications and exposure to pesticides, and will free up time for other tasks. based on surveys of hundreds of farmers in the yellow river cotton-growing region in northern china in 1999, 2000 and 2001, over 4 million smallholders have been able to increase yield per hectare, and reduce pesticide costs, time spent spraying dangerous pesticides, and illnesses due to pesticide poisoning. the expansion of this cost-saving technology is increasing the supply of cotton and pushing down the price, but prices are still sufficiently high for adopters of bt cotton to make substantial gains in net income.",
            "contribution_ids": [
                "R34154"
            ]
        },
        {
            "instance_id": "R34183xR34173",
            "comparison_id": "R34183",
            "paper_id": "R34173",
            "text": "Rent creation and distribution from biotechnology innovation: the case of Bt cotton and herbicide-tolerant soybeans in 1997 \"we examine the distribution of welfare from the second-year planting of bt cotton in the united states in 1997. we also provide preliminary estimates of the planting of herbicide-tolerant soybeans in 1997. for bt cotton, total increase in world surplus was $190.1 million and us farmer share of total surplus was 42%. the gene developer, monsanto, received 35% and the rest of the world 6% of the total world surplus. delta and pine land received 9%, whereas us consumers received 7%. for herbicide-tolerant soybeans, total world surplus was $1,061.7 million. us farmers' surplus was 76%, monsanto's was 7%, us consumers received 4%, and seed companies captured 3% of total surplus. leconolit: q120, d600, o330r \u00a9 2000 john wiley & sons, inc.\"",
            "contribution_ids": [
                "R34174"
            ]
        },
        {
            "instance_id": "R34183xR34140",
            "comparison_id": "R34183",
            "paper_id": "R34140",
            "text": "A critical assessment of methods for analysis of social welfare impacts of genetically modified crops: A literature survey this paper is a review of existing literature on economic and environmental costs and benefits of genetically modified (gm) crops focusing on methodological issues arising from this literature. particular attention is given to the production function framework commonly used to quantify costs and benefits of gm crops at the farm level and to equilibrium displacement models used to quantify impacts of gm crops on social welfare. methods are discussed with respect to their sensitivity to specific parameter values and key areas are identified for further research.",
            "contribution_ids": [
                "R34141",
                "R34142"
            ]
        },
        {
            "instance_id": "R34251xR34190",
            "comparison_id": "R34251",
            "paper_id": "R34190",
            "text": "Monetary union in West Africa: who might gain, who might lose, and why? \"we develop a model in which governments' financing needs exceed the socially optimal level because public resources are diverted to serve the narrow interests of the group in power. from a social welfare perspective, this results in undue pressure on the central bank to extract seigniorage. monetary policy also suffers from an expansive bias, owing to the authorities' inability to precommit to price stability. such a conjecture about the fiscal-monetary policy mix appears quite relevant in africa, with deep implications for the incentives of fiscally heterogeneous countries to form a currency union. we calibrate the model to data for west africa and use it to assess proposed ecowas monetary unions. fiscal heterogeneity indeed appears critical in shaping regional currency blocs that would be mutually beneficial for all their members. in particular, nigeria's membership in the configurations currently envisaged would not be in the interests of other ecowas countries unless it were accompanied by effective containment on nigeria's financing needs.\"",
            "contribution_ids": [
                "R34191"
            ]
        },
        {
            "instance_id": "R34251xR34234",
            "comparison_id": "R34251",
            "paper_id": "R34234",
            "text": "A Short-Run Schumpeterian Trip to Embryonic African Monetary Zones with the spectre of the euro crisis looming substantially large and scaring potential monetary unions, this study is a short-run trip to embryonic african monetary zones to assess the schumpeterian thesis for positive spillovers of financial services on growth. causality analysis is performed with seven financial development and three growth indicators in the proposed west african monetary zone (wamz) and east african monetary zone (eamz). the journey is promising for the eamz and lamentable for the wamz. results of the eamz are broadly consistent with the traditional discretionary monetary policy arrangements while those of the wamz are in line with the non-traditional strand of regimes in which, policy instruments in the short-run cannot be used to offset adverse shocks to output. policy implications are discussed.",
            "contribution_ids": [
                "R34235",
                "R34274"
            ]
        },
        {
            "instance_id": "R34282xR34266",
            "comparison_id": "R34282",
            "paper_id": "R34266",
            "text": "Business Cycle Synchronization in the Proposed East African Monetary Union: An Unobserved Component Approach this paper uses the business cycle synchronization criteria of the theory of optimum currency area (oca) to examine the feasibility of the east african community (eac) as a monetary union. we also investigate whether the degree of business cycle synchronization has increased after the 1999 eac treaty. we use an unobserved component model to measure business cycle synchronization as the proportion of structural shocks that are common across different countries, and a time-varying parameter model to examine the dynamics of synchronization over time. we find that although the degree of synchronization has increased since 2000 when the eac treaty came into force, the proportion of shocks that is common across different countries is still small implying weak synchronization. this evidence casts doubt on the feasibility of a monetary union for the eac as scheduled by 2012.",
            "contribution_ids": [
                "R34267"
            ]
        },
        {
            "instance_id": "R34282xR34270",
            "comparison_id": "R34282",
            "paper_id": "R34270",
            "text": "Design and implementation of a common currency area in the East African community the east african community (eac) has fast-tracked its plans to create a single currency for the five countries making up the region, and hopes to conclude negotiations on a monetary union protocol by the end of 2012. while the benefits of lower transactions costs from a common currency may be significant, countries will also lose the ability to use monetary policy to respond to different shocks. evidence presented shows that the countries differ in a number of respects, facing asymmetric shocks and different production structures. countries have had difficulty meeting convergence criteria, most seriously as concerns fiscal deficits. preparation for monetary union will require effective institutions for macroeconomic surveillance and enforcing fiscal discipline, and euro zone experience indicates that these institutions will be difficult to design and take a considerable time to become effective. this suggests that a timetable for monetary union in the eac should allow for a substantial initial period of institution building. in order to have some visible evidence of the commitment to monetary union, in the meantime the eac may want to consider introducing a common basket currency in the form of notes and coin, to circulate in parallel with national currencies.",
            "contribution_ids": [
                "R34271"
            ]
        },
        {
            "instance_id": "R34282xR34272",
            "comparison_id": "R34282",
            "paper_id": "R34272",
            "text": "Monetary Transmission Mechanism in the East African Community: An Empirical Investigation do changes in monetary policy affect inflation and output in the east african community (eac)? we find that (i) monetary transmission mechanism (mtm) tends to be generally weak when using standard statistical inferences, but somewhat strong when using non-standard inference methods; (ii) when mtm is present, the precise transmission channels and their importance differ across countries; and (iii) reserve money and the policy rate, two frequently used instruments of monetary policy, sometimes move in directions that exert offsetting expansionary and contractionary effects on inflation - posing challenges to harmonization of monetary policies across the eac and transition to a future east african monetary union. the paper offers some suggestions for strengthening the mtm in the eac.",
            "contribution_ids": [
                "R34273"
            ]
        },
        {
            "instance_id": "R34316xR34308",
            "comparison_id": "R34316",
            "paper_id": "R34308",
            "text": "On the feasibility of a monetary union in the Southern Africa Development Community this paper investigates the feasibility of a monetary union in southern africa development community (sadc) by looking at evidence of nominal exchange rate and inflation convergence. using a methodology based on estimating time-varying parameters, the evidence suggests non-convergence. the non-convergence of nominal exchange rate and consumer price inflation suggests that presently the chances of sadc member countries satisfying some form of maastricht-type criteria is quite low. copyright \u00a9 2007 john wiley & sons, ltd.",
            "contribution_ids": [
                "R34309"
            ]
        },
        {
            "instance_id": "R34316xR34310",
            "comparison_id": "R34316",
            "paper_id": "R34310",
            "text": "Modelling Monetary Union in Southern Africa: Welfare Evaluation for the CMA and SADC this paper proposes a quantitative assessment of the welfare effects arising from the common monetary area (cma) and an array of broader groupings among southern african development community (sadc) countries. model simulations suggest that (i) participating in the cma benefits all members; (ii) joining the cma individually is beneficial for all sadc members except angola, mauritius and tanzania; (iii) creating a symmetric cma-wide monetary union with a regional central bank carries some costs in terms of foregone anti-inflationary credibility; and (iv) sadc-wide symmetric monetary union continues to be beneficial for all except mauritius, although the gains for existing cma members are likely to be limited.",
            "contribution_ids": [
                "R34311"
            ]
        },
        {
            "instance_id": "R34316xR34314",
            "comparison_id": "R34316",
            "paper_id": "R34314",
            "text": "Assessment of monetary union in SADC: evidence from cointegration and panel unit root tests in this paper we investigate the likelihood of a proposed monetary union in the southern african development community (sadc) being successful from the viewpoint of the generalised purchasing power parity (gppp) hypothesis and optimum currency area (oca) theory. we apply johansen\u2019s multivariate co-integration technique, panel unit root tests, pedroni\u2019s residual cointegration test and error correction based panel cointegration tests. the findings from this study confirm that gppp holds among sadc member countries included in this study on account of cointegration and stationarity in real exchange rate series. the south african rand normalised long run beta coefficients of all the real exchange rates are below one except in the case of the mauritian rupee and all bear negative signs except in the case of the angolan new kwanza and mauritian rupee. this evidence support monetary union in the region except for angola and mauritius. however, the absolute magnitudes of the short run adjustment coefficients of sadc countries\u2019 real exchange rates are low and bear positive signs in some cases. this finding implies that the observed slow speed of adjustment for the (log) real exchange rate of sadc member states might constrain the effectiveness of stabilization policies in the wake of external shocks, rendering sadc countries vulnerable to macroeconomic instability in the region. this result has important policy implications for the proposed monetary union in sadc.",
            "contribution_ids": [
                "R34315"
            ]
        },
        {
            "instance_id": "R34411xR34382",
            "comparison_id": "R34411",
            "paper_id": "R34382",
            "text": "Extracolonic manifestations of Clostridium difficile infections: presentation of 2 cases and review of the literature \"clostridium difficile is most commonly associated with colonic infection. it may, however, also cause disease in a variety of other organ systems. small bowel involvement is often associated with previous surgical procedures on the small intestine and is associated with a significant mortality rate (4 of 7 patients). when associated with bacteremia, the infection is, as expected, frequently polymicrobial in association with usual colonic flora. the mortality rate among patients with c. difficile bacteremia is 2 of 10 reported patients. visceral abscess formation involves mainly the spleen, with 1 reported case of pancreatic abscess formation. frequently these abscesses are only recognized weeks to months after the onset of diarrhea or other colonic symptoms. c. difficile-related reactive arthritis is frequently polyarticular in nature and is not related to the patient's underlying hla-b27 status. fever is not universally present. the most commonly involved joints are the knee and wrist (involved in 18 of 36 cases). reactive arthritis begins an average of 11.3 days after the onset of diarrhea and is a prolonged illness, taking an average of 68 days to resolve. other entities, such as cellulitis, necrotizing fasciitis, osteomyelitis, and prosthetic device infections, can also occur. localized skin and bone infections frequently follow traumatic injury, implying the implantation of either environmental or the patient's own c. difficile spores with the subsequent development of clinical infection. it is noteworthy that except for cases involving the small intestine and reactive arthritis, most of the cases of extracolonic c. difficile disease do not appear to be strongly related to previous antibiotic exposure. the reason for this is unclear. we hope that clinicians will become more aware of these extracolonic manifestations of infection, so that they may be recognized and treated promptly and appropriately. such early diagnosis may also serve to prevent extensive and perhaps unnecessary patient evaluations, thus improving resource utilization and shortening length of hospital stay.\"",
            "contribution_ids": [
                "R34383"
            ]
        },
        {
            "instance_id": "R34411xR34394",
            "comparison_id": "R34411",
            "paper_id": "R34394",
            "text": "Fulminant small bowel enteritis: a rare complication of Clostridium difficile-associated disease to the editor: a 54-year-old male was admitted to a community hospital with a 3-month history of diarrhea up to 8 times a day associated with bloody bowel motions and weight loss of 6 kg. he had no past medical history or family history of note. a clinical diagnosis of colitis was made and the patient underwent a limited colonoscopy which demonstrated continuous mucosal inflammation and ulceration that was most marked in the rectum. the clinical and endoscopic findings were suggestive of acute ulcerative colitis (uc), which was subsequently supported by histopathology. the patient was managed with bowel rest and intravenous steroids. however, he developed toxic megacolon on day 4 of his admission and underwent a total colectomy with end ileostomy. on the third postoperative day the patient developed a pyrexia of 39\u00b0c, a septic screen was performed, and the central venous line (cvp) was changed with the tip culturing methicillin-resistant staphylococcus aureus (mrsa). intravenous gentamycin was commenced and discontinued after 5 days, with the patient remaining afebrile and stable. on the tenth postoperative day the patient became tachycardic (pulse 110/min), diaphoretic (temperature of 39.4\u00b0c), hypotensive (diastolic of 60 mm hg), and with a high volume nasogastric aspirates noted (2000 ml). a diagnosis of septic shock was considered although the etiology was unclear. the patient was resuscitated with intravenous fluids and transferred to the regional surgical unit for intensive care unit monitoring and management. a computed tomography (ct) of the abdomen showed a marked inflammatory process with bowel wall thickening along the entire small bowel with possible intramural air, raising the suggestion of ischemic bowel (fig. 1). however, on clinical assessment the patient elicited no signs of peritonism, his vitals were stable, he was not acidotic (ph 7.40), urine output was adequate, and his blood pressure was being maintained without inotropic support. furthermore, his ileostomy appeared healthy and well perfused, although a high volume (2500 ml in the previous 18 hours), malodorous output was noted. a sample of the stoma output was sent for microbiological analysis. given that the patient was not exhibiting evidence of peritonitis with normal vital signs, a conservative policy of fluid resuscitation was pursued with plans for exploratory laparotomy if he disimproved. ileostomy output sent for microbiology assessment was positive for clostridium difficile toxin a and b utilizing culture and enzyme immunoassays (eia). intravenous vancomycin, metronidazole, and rifampicin via a nasogastric tube were commenced in conjunction with bowel rest and total parenteral nutrition. the ileostomy output reduced markedly within 2 days and the patient\u2019s clinical condition improved. follow-up culture of the ileostomy output was negative for c. difficile toxins. the patient was discharged in good health on full oral diet 12 days following transfer. review of histopathology relating to the resected colon and subsequent endoscopic assessment of the retained rectum confirmed the initial diagnosis of uc, rather than a primary diagnosis of pseudomembranous colitis. clostridium difficile is the leading cause of nosocomial diarrhea associated with antibiotic therapy and is almost always limited to the colonic mucosa.1 small bowel enteritis secondary to c. difficile is exceedingly rare, with only 21 previous cases cited in the literature.2,3 of this cohort, 18 patients had a surgical procedure at some timepoint prior to the development of c. difficile enteritis, while the remaining 3 patients had no surgical procedure prior to the infection. the time span between surgery and the development of enteritis ranged from 4 days to 31 years. antibiotic therapy predisposed to the development of c. difficile enteritis in 20 of the cases. a majority of the patients (n 11) had a history of inflammatory bowel disease (ibd), with 8 having uc similar to our patient and the remaining 3 patients having a history of crohn\u2019s disease. the etiology of small bowel enteritis remains unclear. c. difficile has been successfully isolated from the small bowel in both autopsy specimens and from jejunal aspirate of patients with chronic diarrhea, suggesting that the small bowel may act as a reservoir for c. difficile.4 this would suggest that c. difficile could become pathogenic in the small bowel following a disruption in the small bowel flora in the setting of antibiotic therapy. this would be supported by the observation that the majority of cases reported occurred within 90 days of surgery with attendant disruption of bowel function. the prevalence of c. difficile-associated disease (cdad) in patients with ibd is increasing. issa et al5 examined the impact of cdad in a cohort of patients with ibd. they found that more than half of the patients with a positive culture for c. difficile were admitted and 20% required a colectomy. they reported that maintenance immunomodulator use and colonic involvement were independent risk factors for c. difficile infection in patients with ibd. the rising incidence of c. difficile in patients with ibd coupled with the use of increasingly potent immunomodulatory therapies means that clinicians must have a high index of suspicopyright \u00a9 2008 crohn\u2019s & colitis foundation of america, inc. doi 10.1002/ibd.20758 published online 22 october 2008 in wiley interscience (www.interscience.wiley.com).",
            "contribution_ids": [
                "R34395"
            ]
        },
        {
            "instance_id": "R34411xR34405",
            "comparison_id": "R34411",
            "paper_id": "R34405",
            "text": "Enteral Clostrid- ium difficile, an emerging cause for high-output ileostomy the loss of fluid and electrolytes from a high-output ileostomy (&gt;1200 ml/day) can quickly result in dehydration and if not properly managed may cause acute renal failure. the management of a high-output ileostomy is based upon three principles: correction of electrolyte disturbance and fluid balance, pharmacological reduction of ileostomy output, and treatment of any underlying identifiable cause. there is an increasing body of evidence to suggest that clostridium difficile may behave pathologically in the small intestine producing a spectrum of enteritis that mirrors the well-recognised colonic disease manifestation. clinically this can range from high-output ileostomy to fulminant enteritis. this report describes two cases of high-output ileostomy associated with enteric c difficile infection and proposes that the management algorithm of a high-output ileostomy should include exclusion of small bowel c difficile .",
            "contribution_ids": [
                "R34406"
            ]
        },
        {
            "instance_id": "R34454xR34438",
            "comparison_id": "R34454",
            "paper_id": "R34438",
            "text": "A Region Based Methodology for Facial Expression Recognition this work investigates the use of a point distribution model to detect prominent features in a face (eyes, brows, mouth, etc) and the subsequent facial feature extraction and facial expression classification into seven categories (anger, fear, surprise, happiness, disgust, neutral and sadness). a multi-scale and multi-orientation gabor filter bank, designed in such a way so as to avoid redundant information, is used to extract facial features at selected locations of the prominent features of a face (fiducial points). a region based approach is employed at the location of the fiducial points using different region sizes to allow some degree of flexibility and avoid artefacts due to incorrect automatic discovery of these points. a feed forward back propagation artificial neural network is employed to classify the extracted feature vectors. the methodology is evaluated by forming 7 different regions and the feature vector is extracted at the location of 20 fiducial points.",
            "contribution_ids": [
                "R34439"
            ]
        },
        {
            "instance_id": "R34454xR34444",
            "comparison_id": "R34454",
            "paper_id": "R34444",
            "text": "Facial Expression Recognition from Line-Based Caricatures the automatic recognition of facial expression presents a significant challenge to the pattern analysis and man-machine interaction research community. recognition from a single static image is particularly a difficult task. in this paper, we present a methodology for facial expression recognition from a single static image using line-based caricatures. the recognition process is completely automatic. it also addresses the computational expensive problem and is thus suitable for real-time applications. the proposed approach uses structural and geometrical features of a user sketched expression model to match the line edge map (lem) descriptor of an input face image. a disparity measure that is robust to expression variations is defined. the effectiveness of the proposed technique has been evaluated and promising results are obtained. this work has proven the proposed idea that facial expressions can be characterized and recognized by caricatures.",
            "contribution_ids": [
                "R34445"
            ]
        },
        {
            "instance_id": "R34454xR34446",
            "comparison_id": "R34454",
            "paper_id": "R34446",
            "text": "Robust Facial Expression Recognition Using Local Binary Patterns a novel low-computation discriminative feature space is introduced for facial expression recognition capable of robust performance over a rang of image resolutions. our approach is based on the simple local binary patterns (lbp) for representing salient micro-patterns of face images. compared to gabor wavelets, the lbp features can be extracted faster in a single scan through the raw image and lie in a lower dimensional space, whilst still retaining facial information efficiently. template matching with weighted chi square statistic and support vector machine are adopted to classify facial expressions. extensive experiments on the cohn-kanade database illustrate that the lbp features are effective and efficient for facial expression discrimination. additionally, experiments on face images with different resolutions show that the lbp features are robust to low-resolution images, which is critical in real-world applications where only low-resolution video input is available.",
            "contribution_ids": [
                "R34447"
            ]
        },
        {
            "instance_id": "R34605xR34529",
            "comparison_id": "R34605",
            "paper_id": "R34529",
            "text": "Preservation of Privacy in Publishing Social Network Data \"this paper consider the privacy disclosure in social network data publishing. we assume that adversaries know the degree of a target individual and the target's immediate neighbors, and identify an essential type of privacy attacks: background knowledge attacks. we propose a practical solution to defend against background knowledge attacks. the experimental results confirm that the anonymized social networks obtained by our method can still be used to answer aggregate network queries with high accuracy.\"",
            "contribution_ids": [
                "R34530"
            ]
        },
        {
            "instance_id": "R34605xR34533",
            "comparison_id": "R34605",
            "paper_id": "R34533",
            "text": "Comparisons of randomization and K-degree anonymization schemes for privacy preserving social network publishing many applications of social networks require identity and/or relationship anonymity due to the sensitive, stigmatizing, or confidential nature of user identities and their behaviors. recent work showed that the simple technique of anonymizing graphs by replacing the identifying information of the nodes with random ids does not guarantee privacy since the identification of the nodes can be seriously jeopardized by applying background based attacks. in this paper, we investigate how well an edge based graph randomization approach can protect node identities and sensitive links. we quantify both identity disclosure and link disclosure when adversaries have one specific type of background knowledge (i.e., knowing the degrees of target individuals). we also conduct empirical comparisons with the recently proposed k-degree anonymization schemes in terms of both utility and risks of privacy disclosures.",
            "contribution_ids": [
                "R34534",
                "R34583"
            ]
        },
        {
            "instance_id": "R34605xR34958",
            "comparison_id": "R34605",
            "paper_id": "R34958",
            "text": "K-isomorphism: privacy preserving network publication against structural attacks serious concerns on privacy protection in social networks have been raised in recent years; however, research in this area is still in its infancy. the problem is challenging due to the diversity and complexity of graph data, on which an adversary can use many types of background knowledge to conduct an attack. one popular type of attacks as studied by pioneer work [2] is the use of embedding subgraphs. we follow this line of work and identify two realistic targets of attacks, namely, nodeinfo and linkinfo. our investigations show that k-isomorphism, or anonymization by forming k pairwise isomorphic subgraphs, is both sufficient and necessary for the protection. the problem is shown to be np-hard. we devise a number of techniques to enhance the anonymization efficiency while retaining the data utility. a compound vertex id mechanism is also introduced for privacy preservation over multiple data releases. the satisfactory performance on a number of real datasets, including hep-th, euemail and livejournal, illustrates that the high symmetry of social networks is very helpful in mitigating the difficulty of the problem.",
            "contribution_ids": [
                "R34543",
                "R34587",
                "R34960"
            ]
        },
        {
            "instance_id": "R34605xR34556",
            "comparison_id": "R34605",
            "paper_id": "R34556",
            "text": "A New Approach to Manage Security against Neighborhood Attacks in Social Networks now a days, more and more of social network data are being published in one way or other. so, preserving privacy in publishing social network data has become an important concern. with some local knowledge about individuals in a social network, an adversary may attack the privacy of some victims easily. most of the work done so far towards privacy preservation can deal with relational data only. however, bin zhou and jian pei [11] proposed a scheme for anonymization of social networks, which is an initiative in this direction and provides a partial solution to this problem. in fact, their algorithm cannot handle the situations in which an adversary has knowledge about vertices in the second or higher hops of a vertex, in addition to its immediate neighbors. in this paper, we propose a modification to their algorithm for the network anonymization which can handle such situations. in doing so, we use an algorithm for graph isomorphism based on adjacency matrix instead of their approach using dfs technique [11]. more importantly, the time complexity of our algorithm is less than that of zhou and pei.",
            "contribution_ids": [
                "R34557"
            ]
        },
        {
            "instance_id": "R34605xR34574",
            "comparison_id": "R34605",
            "paper_id": "R34574",
            "text": "Randomizing Social Networks: a Spectrum Preserving Approach understanding the general properties of real social networks has gained much attention due to the proliferation of networked data. the nodes in the network are the individuals and the links among them denote their relationships. many applications of networks such as anonymous web browsing require relationship anonymity due to the sensitive, stigmatizing, or confidential nature of the relationship. one general approach for this problem is to randomize the edges in true networks, and only disclose the randomized networks. in this paper, we investigate how various properties of networks may be affected due to randomization. specifically, we focus on the spectrum since the eigenvalues of a network are intimately connected to many important topological features. we also conduct theoretical analysis on the extent to which edge anonymity can be achieved. a spectrum preserving graph randomization method, which can better preserve network properties while protecting edge anonymity, is then presented and empirically evaluated.",
            "contribution_ids": [
                "R34575"
            ]
        },
        {
            "instance_id": "R34605xR34584",
            "comparison_id": "R34605",
            "paper_id": "R34584",
            "text": "Supervised random walks: predicting and recommending links in social networks predicting the occurrence of links is a fundamental problem in networks. in the link prediction problem we are given a snapshot of a network and would like to infer which interactions among existing members are likely to occur in the near future or which existing interactions are we missing. although this problem has been extensively studied, the challenge of how to effectively combine the information from the network structure with rich node and edge attribute data remains largely open.\\n we develop an algorithm based on supervised random walks that naturally combines the information from the network structure with node and edge level attributes. we achieve this by using these attributes to guide a random walk on the graph. we formulate a supervised learning task where the goal is to learn a function that assigns strengths to edges in the network such that a random walker is more likely to visit the nodes to which new links will be created in the future. we develop an efficient training algorithm to directly learn the edge strength estimation function.\\n our experiments on the facebook social graph and large collaboration networks show that our approach outperforms state-of-the-art unsupervised approaches as well as approaches that are based on feature extraction.",
            "contribution_ids": [
                "R34585",
                "R34586"
            ]
        },
        {
            "instance_id": "R34663xR34622",
            "comparison_id": "R34663",
            "paper_id": "R34622",
            "text": "Optimizing Medical Data Quality Based on Multiagent Web Service Framework one of the most important issues in e-healthcare information systems is to optimize the medical data quality extracted from distributed and heterogeneous environments, which can extremely improve diagnostic and treatment decision making. this paper proposes a multiagent web service framework based on service-oriented architecture for the optimization of medical data quality in the e-healthcare information system. based on the design of the multiagent web service framework, an evolutionary algorithm (ea) for the dynamic optimization of the medical data quality is proposed. the framework consists of two main components; first, an ea will be used to dynamically optimize the composition of medical processes into optimal task sequence according to specific quality attributes. second, a multiagent framework will be proposed to discover, monitor, and report any inconstancy between the optimized task sequence and the actual medical records. to demonstrate the proposed framework, experimental results for a breast cancer case study are provided. furthermore, to show the unique performance of our algorithm, a comparison with other works in the literature review will be presented.",
            "contribution_ids": [
                "R34623"
            ]
        },
        {
            "instance_id": "R34706xR34678",
            "comparison_id": "R34706",
            "paper_id": "R34678",
            "text": "A Lock-Free Solution for Load Balancing in Multi-Core Environment load balancing device is an important part of cloud platform. one of the most common applications of load balancing is to provide a single powerful virtual machine from multiple servers. in multi-core environment, the load balancing device can run multiple physically parallel load-balancing processes to increase overall performance. an important issue when operating a load-balanced service is how to send all requests in a user session consistently to the same backend server, i.e. session maintaining. most of multiprocessing load balancing solutions use shared memory and lock when manage session. by modifying linux kernel, we avoid using shared memory and implement a lock-free multiprocessing load balancing solution.",
            "contribution_ids": [
                "R34679"
            ]
        },
        {
            "instance_id": "R34706xR34701",
            "comparison_id": "R34706",
            "paper_id": "R34701",
            "text": "Performance evaluation of web servers using central load balancing policy over virtual machines on cloud cloud computing adds more power to the existing internet technologies. virtualization harnesses the power of the existing infrastructure and resources. with virtualization we can simultaneously run multiple instances of different commodity operating systems. since we have limited processors and jobs work in concurrent fashion, overload situations can occur. things become even more challenging in distributed environment. we propose central load balancing policy for virtual machines (clbvm) to balance the load evenly in a distributed virtual machine/cloud computing environment. this work tries to compare the performance of web servers based on our clbvm policy and independent virtual machine(vm) running on a single physical server using xen virtualizaion. the paper discusses the efficacy and feasibility of using this kind of policy for overall performance improvement.",
            "contribution_ids": [
                "R34702"
            ]
        },
        {
            "instance_id": "R34706xR34704",
            "comparison_id": "R34706",
            "paper_id": "R34704",
            "text": "A Min-Min Max-Min selective algorihtm for grid task scheduling today, the high cost of supercomputers in the one hand and the need for large-scale computational resources on the other hand, has led to use network of computational resources known as grid. numerous research groups in universities, research labs, and industries around the world are now working on a type of grid called computational grids that enable aggregation of distributed resources for solving large-scale data intensive problems in science, engineering, and commerce. several institutions and universities have started research and teaching programs on grid computing as part of their parallel and distributed computing curriculum. to better use tremendous capabilities of this distributed system, effective and efficient scheduling algorithms are needed. in this paper, we introduce a new scheduling algorithm based on two conventional scheduling algorithms, min-min and max-min, to use their cons and at the same time, cover their pros. it selects between the two algorithms based on standard deviation of the expected completion time of tasks on resources. we evaluate our scheduling heuristic, the selective algorithm, within a grid simulator called gridsim. we also compared our approach to its two basic heuristics. the experimental results show that the new heuristic can lead to significant performance gain for a variety of scenarios.",
            "contribution_ids": [
                "R34705"
            ]
        },
        {
            "instance_id": "R34845xR34773",
            "comparison_id": "R34845",
            "paper_id": "R34773",
            "text": "The Effect of Embryonic Development on the Thickness of the Egg Shells of Coturnix Quail abstract the average thickness of the shells from 75 unincubated coturnix quail eggs was found to be 0.193 mm. this was 7.3 percent greater than the average thickness (0.179 mm.) of the shells from 60 fully incubated eggs from the same hens. the two sets of eggs were collected simultaneously. this thickness difference was statistically significant (t-test:p",
            "contribution_ids": [
                "R34774"
            ]
        },
        {
            "instance_id": "R34845xR34791",
            "comparison_id": "R34845",
            "paper_id": "R34791",
            "text": "Clutch Size, Hatching Success, and Eggshell-Thinning in Western Gulls author(s): hunt, gl; hunt, mw | abstract: average clutch size for large larus gulls is close to three eggs, and the production of a clutch of four is uncommon (keith 1966; paludan 1951; vermeer 1963). we report here on a colony of western gulls (larms occidentalis) in which many clutches containing four and five eggs were found. it is of particular interest that in these large clutches not only was hatching success low but also eggshell thickness was reduced.",
            "contribution_ids": [
                "R34792"
            ]
        },
        {
            "instance_id": "R34845xR34796",
            "comparison_id": "R34845",
            "paper_id": "R34796",
            "text": "Avian embryonic development does not change the stable isotope composition of the calcite eggshell the avian embryo resorbs most of the calcium for bone formation from the calcite eggshell but the exact mechanisms of the resorption are unknown. the present study tested whether this process results in variable fractionation of the oxygen and carbon isotopes in shell calcium carbonate, which could provide a detailed insight into the temporal and spatial use of the eggshell by the developing embryo. despite the uncertainty regarding changes in stable isotope composition of the eggshell across developmental stages or regions of the shell, eggshells are a popular resource for the analysis of historic and extant trophic relationships. to clarify how the stable isotope composition varies with embryonic development, the \u03b413c and \u03b418o content of the carbonate fraction in shells of black-headed gull (larus ridibundus) eggs were sampled at four different stages of embryonic development and at five eggshell regions. no consistent relationship between the stable isotope composition of the eggshell and embryonic development, shell region or maculation was observed, although shell thickness decreased with development in all shell regions. by contrast, individual eggs differed significantly in isotope composition. these results establish that eggshells can be used to investigate a species\u2019 carbon and oxygen sources, regardless of the egg\u2019s developmental stage.",
            "contribution_ids": [
                "R34797"
            ]
        },
        {
            "instance_id": "R34845xR34824",
            "comparison_id": "R34845",
            "paper_id": "R34824",
            "text": "California Condors and DDE: a re-evaluation \"eggshells of wild california condors gymnogyps californianus were much thinner in the 1960s, when ddt was used heavily, than during earlier pre-ddt and later reduced-ddt periods. however, eggshell thickness was more strongly linked to egg size (mass) than to measured levels of p,p\u2032dde (the primary metabolite of ddt). egg size was consistent within individual females and yielded correlation coefficients with shell thickness ranging from 0.49 to 0.97, depending on the period and the analysis assumptions used. measured dde levels, although often substantial, provided only a weak correlation (r\\xa0=\\xa0\u22120.33) with shell thickness. in part, the absence of a strong dde/thickness correlation may have been an artefact of losses of dde from fragment membranes over time. nevertheless, the extreme (28\u201329%) shell thinning of the 1960s was not linked with clearly increased egg-breakage or nest-failure rates, and one female of the 1980s with 25.6% shell thinning was the most productive female of her era. some eggs with over 30% shell thinning hatched successfully, and broken eggs closely resembled hatched eggs in shell thickness, strongly suggesting that shell thinning was not an important cause of breakage. the apparent absence of harmful effects from the extreme shell thinning of the 1960s may have resulted from (1) the fact that historic pre-ddt condor eggs were on average 16.7% thicker shelled for their mass than predicted by the overall egg mass/shell thickness curve for birds, and (2) a possible egg-size decline or sampling bias toward small-egged females in the 1960s. that dde was an important cause of the condor's decline appears unlikely from overall available data.\"",
            "contribution_ids": [
                "R34825"
            ]
        },
        {
            "instance_id": "R36153xR36132",
            "comparison_id": "R36153",
            "paper_id": "R36132",
            "text": "Lessons drawn from China and South Korea for managing COVID-19 epidemic: insights from a comparative modeling study abstract we conducted a comparative study of covid-19 epidemic in three different settings: mainland china, the guangdong province of china and south korea, by formulating two disease transmission dynamics models incorporating epidemic characteristics and setting-specific interventions, and fitting the models to multi-source data to identify initial and effective reproduction numbers and evaluate effectiveness of interventions. we estimated the initial basic reproduction number for south korea, the guangdong province and mainland china as 2.6 (95% confidence interval (ci): (2.5, 2.7)), 3.0 (95%ci: (2.6, 3.3)) and 3.8 (95%ci: (3.5,4.2)), respectively, given a serial interval with mean of 5 days with standard deviation of 3 days. we found that the effective reproduction number for the guangdong province and mainland china has fallen below the threshold 1 since february 8 th and 18 th respectively, while the effective reproduction number for south korea remains high, suggesting that the interventions implemented need to be enhanced in order to halt further infections. we also project the epidemic trend in south korea under different scenarios where a portion or the entirety of the integrated package of interventions in china is used. we show that a coherent and integrated approach with stringent public health interventions is the key to the success of containing the epidemic in china and specially its provinces outside its epicenter, and we show that this approach can also be effective to mitigate the burden of the covid-19 epidemic in south korea. the experience of outbreak control in mainland china should be a guiding reference for the rest of the world including south korea.",
            "contribution_ids": [
                "R36133",
                "R36135",
                "R36137"
            ]
        },
        {
            "instance_id": "R38484xR23312",
            "comparison_id": "R38484",
            "paper_id": "R23312",
            "text": "GFDL's CM2 Global Coupled Climate Models. Part I: Formulation and Simulation Characteristics \" abstract \\n the formulation and simulation characteristics of two new global coupled climate models developed at noaa's geophysical fluid dynamics laboratory (gfdl) are described. the models were designed to simulate atmospheric and oceanic climate and variability from the diurnal time scale through multicentury climate change, given our computational constraints. in particular, an important goal was to use the same model for both experimental seasonal to interannual forecasting and the study of multicentury global climate change, and this goal has been achieved. \\n two versions of the coupled model are described, called cm2.0 and cm2.1. the versions differ primarily in the dynamical core used in the atmospheric component, along with the cloud tuning and some details of the land and ocean components. for both coupled models, the resolution of the land and atmospheric components is 2\u00b0 latitude \u00d7 2.5\u00b0 longitude; the atmospheric model has 24 vertical levels. the ocean resolution is 1\u00b0 in latitude and longitude, with meridional resolution equatorward of 30\u00b0 becoming progressively finer, such that the meridional resolution is 1/3\u00b0 at the equator. there are 50 vertical levels in the ocean, with 22 evenly spaced levels within the top 220 m. the ocean component has poles over north america and eurasia to avoid polar filtering. neither coupled model employs flux adjustments. \\n the control simulations have stable, realistic climates when integrated over multiple centuries. both models have simulations of enso that are substantially improved relative to previous gfdl coupled models. the cm2.0 model has been further evaluated as an enso forecast model and has good skill (cm2.1 has not been evaluated as an enso forecast model). generally reduced temperature and salinity biases exist in cm2.1 relative to cm2.0. these reductions are associated with 1) improved simulations of surface wind stress in cm2.1 and associated changes in oceanic gyre circulations; 2) changes in cloud tuning and the land model, both of which act to increase the net surface shortwave radiation in cm2.1, thereby reducing an overall cold bias present in cm2.0; and 3) a reduction of ocean lateral viscosity in the extratropics in cm2.1, which reduces sea ice biases in the north atlantic. \\n both models have been used to conduct a suite of climate change simulations for the 2007 intergovernmental panel on climate change (ipcc) assessment report and are able to simulate the main features of the observed warming of the twentieth century. the climate sensitivities of the cm2.0 and cm2.1 models are 2.9 and 3.4 k, respectively. these sensitivities are defined by coupling the atmospheric components of cm2.0 and cm2.1 to a slab ocean model and allowing the model to come into equilibrium with a doubling of atmospheric co2. the output from a suite of integrations conducted with these models is freely available online (see http://nomads.gfdl.noaa.gov/). \"",
            "contribution_ids": [
                "R23313"
            ]
        },
        {
            "instance_id": "R38484xR23443",
            "comparison_id": "R38484",
            "paper_id": "R23443",
            "text": "The Norwegian Earth System Model, NorESM1-M \u00e2\u0080\u0093 Part 1: Description and basic evaluation of the physical climate \" abstract. the core version of the norwegian climate center's earth system model, named noresm1-m, is presented. the noresm family of models are based on the community climate system model version 4 (ccsm4) of the university corporation for atmospheric research, but differs from the latter by, in particular, an isopycnic coordinate ocean model and advanced chemistry\u2013aerosol\u2013cloud\u2013radiation interaction schemes. noresm1-m has a horizontal resolution of approximately 2\u00b0 for the atmosphere and land components and 1\u00b0 for the ocean and ice components. noresm is also available in a lower resolution version (noresm1-l) and a version that includes prognostic biogeochemical cycling (noresm1-me). the latter two model configurations are not part of this paper. here, a first-order assessment of the model stability, the mean model state and the internal variability based on the model experiments made available to cmip5 are presented. further analysis of the model performance is provided in an accompanying paper (iversen et al., 2013), presenting the corresponding climate response and scenario projections made with noresm1-m.\\n \"",
            "contribution_ids": [
                "R23444"
            ]
        },
        {
            "instance_id": "R41148xR41136",
            "comparison_id": "R41148",
            "paper_id": "R41136",
            "text": "Toward cost-effective manufacturing of silicon solar cells: electrodeposition of high-quality Si films in a CaCl 2 -based molten salt electrodeposition of si films from a si-containing electrolyte is a cost-effective approach for the manufacturing of solar cells. proposals relying on fluoride-based molten salts have suffered from low product quality due to difficulties in impurity control. here we demonstrate the successful electrodeposition of high-quality si films from a cacl2 -based molten salt. soluble siiv -o anions generated from solid sio2 are electrodeposited onto a graphite substrate to form a dense film of crystalline si. impurities in the deposited si film are controlled at low concentrations (both b and p are less than 1\\u2005ppm). in the photoelectrochemical measurements, the film shows p-type semiconductor character and large photocurrent. a p-n junction fabricated from the deposited si film exhibits clear photovoltaic effects. this study represents the first step to the ultimate goal of developing a cost-effective manufacturing process for si solar cells based on electrodeposition.",
            "contribution_ids": [
                "R41137"
            ]
        },
        {
            "instance_id": "R41148xR41142",
            "comparison_id": "R41148",
            "paper_id": "R41142",
            "text": "Electrochemical formation of a p\u00e2\u0088\u0092n junction of thin film silicon deposited in molten salt herein we report the demonstration of electrochemical deposition of silicon p-n junctions all in molten salt. the results show that a dense robust silicon thin film with embedded junction formation can be produced directly from inexpensive silicates/silicon oxide precursors by a two-step electrodeposition process. the fabricated silicon p-n junction exhibits clear diode rectification behavior and photovoltaic effects, indicating promise for application in low-cost silicon thin film solar cells.",
            "contribution_ids": [
                "R41143"
            ]
        },
        {
            "instance_id": "R41148xR41144",
            "comparison_id": "R41148",
            "paper_id": "R41144",
            "text": "Up-scalable and controllable electrolytic production of photo-responsive nanostructured silicon the electrochemical reduction of solid silica has been investigated in molten cacl2 at 900 \u00b0c for the one-step, up-scalable, controllable and affordable production of nanostructured silicon with promising photo-responsive properties. cyclic voltammetry of the metallic cavity electrode loaded with fine silica powder was performed to elaborate the electrochemical reduction mechanism. potentiostatic electrolysis of porous and dense silica pellets was carried out at different potentials, focusing on the influences of the electrolysis potential and the microstructure of the precursory silica on the product purity and microstructure. the findings suggest a potential range between \u22120.60 and \u22120.95 v (vs. ag/agcl) for the production of nanostructured silicon with high purity (>99 wt%). according to the elucidated mechanism on the electro-growth of the silicon nanostructures, optimal process parameters for the controllable preparation of high-purity silicon nanoparticles and nanowires were identified. scaling-up the optimal electrolysis was successful at the gram-scale for the preparation of high-purity silicon nanowires which exhibited promising photo-responsive properties.",
            "contribution_ids": [
                "R41145"
            ]
        },
        {
            "instance_id": "R44930xR44743",
            "comparison_id": "R44930",
            "paper_id": "R44743",
            "text": "Estimation of the epidemic properties of the 2019 novel coronavirus: A mathematical modeling study abstract background the 2019 novel coronavirus (covid-19) emerged in wuhan, china in december 2019 and has been spreading rapidly in china. decisions about its pandemic threat and the appropriate level of public health response depend heavily on estimates of its basic reproduction number and assessments of interventions conducted in the early stages of the epidemic. methods we conducted a mathematical modeling study using five independent methods to assess the basic reproduction number (r0) of covid-19, using data on confirmed cases obtained from the china national health commission for the period 10 th january \u2013 8 th february. we analyzed the data for the period before the closure of wuhan city (10 th january \u2013 23 rd january) and the post-closure period (23 rd january \u2013 8 th february) and for the whole period, to assess both the epidemic risk of the virus and the effectiveness of the closure of wuhan city on spread of covid-19. findings before the closure of wuhan city the basic reproduction number of covid-19 was 4.38 (95% ci: 3.63 \u2013 5.13), dropping to 3.41 (95% ci: 3.16 \u2013 3.65) after the closure of wuhan city. over the entire epidemic period covid-19 had a basic reproduction number of 3.39 (95% ci: 3.09 \u2013 3.70), indicating it has a very high transmissibility. interpretation covid-19 is a highly transmissible virus with a very high risk of epidemic outbreak once it emerges in metropolitan areas. the closure of wuhan city was effective in reducing the severity of the epidemic, but even after closure of the city and the subsequent expansion of that closure to other parts of hubei the virus remained extremely infectious. emergency planners in other cities should consider this high infectiousness when considering responses to this virus. funding national natural science foundation of china, china medical board, national science and technology major project of china",
            "contribution_ids": [
                "R44744",
                "R44749",
                "R44754"
            ]
        },
        {
            "instance_id": "R44930xR44759",
            "comparison_id": "R44930",
            "paper_id": "R44759",
            "text": "Transmission potential of COVID-19 in Iran abstract we estimated the reproduction number of 2020 iranian covid-19 epidemic using two different methods: r 0 was estimated at 4.4 (95% ci, 3.9, 4.9) (generalized growth model) and 3.50 (1.28, 8.14) (epidemic doubling time) (february 19 - march 1) while the effective r was estimated at 1.55 (1.06, 2.57) (march 6-19).",
            "contribution_ids": [
                "R44766",
                "R44771"
            ]
        },
        {
            "instance_id": "R44930xR44812",
            "comparison_id": "R44930",
            "paper_id": "R44812",
            "text": "Pattern of early human-to-human transmission of Wuhan 2019-nCoV abstract on december 31, 2019, the world health organization was notified about a cluster of pneumonia of unknown aetiology in the city of wuhan, china. chinese authorities later identified a new coronavirus (2019-ncov) as the causative agent of the outbreak. as of january 23, 2020, 655 cases have been confirmed in china and several other countries. understanding the transmission characteristics and the potential for sustained human-to-human transmission of 2019-ncov is critically important for coordinating current screening and containment strategies, and determining whether the outbreak constitutes a public health emergency of international concern (pheic). we performed stochastic simulations of early outbreak trajectories that are consistent with the epidemiological findings to date. we found the basic reproduction number, r 0 , to be around 2.2 (90% high density interval 1.4\u20143.8), indicating the potential for sustained human-to-human transmission. transmission characteristics appear to be of a similar magnitude to severe acute respiratory syndrome-related coronavirus (sars-cov) and the 1918 pandemic influenza. these findings underline the importance of heightened screening, surveillance and control efforts, particularly at airports and other travel hubs, in order to prevent further international spread of 2019-ncov.",
            "contribution_ids": [
                "R44815"
            ]
        },
        {
            "instance_id": "R44930xR44865",
            "comparison_id": "R44930",
            "paper_id": "R44865",
            "text": "Modelling the epidemic trend of the 2019 novel coronavirus outbreak in China we present a timely evaluation of the chinese 2019-ncov epidemic in its initial phase, where 2019-ncov demonstrates comparable transmissibility but lower fatality rates than sars and mers. a quick diagnosis that leads to case isolation and integrated interventions will have a major impact on its future trend. nevertheless, as china is facing its spring festival travel rush and the epidemic has spread beyond its borders, further investigation on its potential spatiotemporal transmission pattern and novel intervention strategies are warranted.",
            "contribution_ids": [
                "R44866"
            ]
        },
        {
            "instance_id": "R44930xR44901",
            "comparison_id": "R44930",
            "paper_id": "R44901",
            "text": "Real-Time Estimation of the Risk of Death from Novel Coronavirus (COVID-19) Infection: Inference Using Exported Cases the exported cases of 2019 novel coronavirus (covid-19) infection that were confirmed outside china provide an opportunity to estimate the cumulative incidence and confirmed case fatality risk (ccfr) in mainland china. knowledge of the ccfr is critical to characterize the severity and understand the pandemic potential of covid-19 in the early stage of the epidemic. using the exponential growth rate of the incidence, the present study statistically estimated the ccfr and the basic reproduction number\u2014the average number of secondary cases generated by a single primary case in a na\u00efve population. we modeled epidemic growth either from a single index case with illness onset on 8 december 2019 (scenario 1), or using the growth rate fitted along with the other parameters (scenario 2) based on data from 20 exported cases reported by 24 january 2020. the cumulative incidence in china by 24 january was estimated at 6924 cases (95% confidence interval [ci]: 4885, 9211) and 19,289 cases (95% ci: 10,901, 30,158), respectively. the latest estimated values of the ccfr were 5.3% (95% ci: 3.5%, 7.5%) for scenario 1 and 8.4% (95% ci: 5.3%, 12.3%) for scenario 2. the basic reproduction number was estimated to be 2.1 (95% ci: 2.0, 2.2) and 3.2 (95% ci: 2.7, 3.7) for scenarios 1 and 2, respectively. based on these results, we argued that the current covid-19 epidemic has a substantial potential for causing a pandemic. the proposed approach provides insights in early risk assessment using publicly available data.",
            "contribution_ids": [
                "R44902",
                "R44906"
            ]
        },
        {
            "instance_id": "R44930xR44726",
            "comparison_id": "R44930",
            "paper_id": "R44726",
            "text": "The early phase of the COVID-19 outbreak in Lombardy, Italy in the night of february 20, 2020, the first case of novel coronavirus disease (covid-19) was confirmed in the lombardy region, italy. in the week that followed, lombardy experienced a very rapid increase in the number of cases. we analyzed the first 5,830 laboratory-confirmed cases to provide the first epidemiological characterization of a covid-19 outbreak in a western country. epidemiological data were collected through standardized interviews of confirmed cases and their close contacts. we collected demographic backgrounds, dates of symptom onset, clinical features, respiratory tract specimen results, hospitalization, contact tracing. we provide estimates of the reproduction number and serial interval. the epidemic in italy started much earlier than february 20, 2020. at the time of detection of the first covid-19 case, the epidemic had already spread in most municipalities of southern-lombardy. the median age for of cases is 69 years (range, 1 month to 101 years). 47% of positive subjects were hospitalized. among these, 18% required intensive care. the mean serial interval is estimated to be 6.6 days (95% ci, 0.7 to 19). we estimate the basic reproduction number at 3.1 (95% ci, 2.9 to 3.2). we estimated a decreasing trend in the net reproduction number starting around february 20, 2020. we did not observe significantly different viral loads in nasal swabs between symptomatic and asymptomatic. the transmission potential of covid-19 is very high and the number of critical cases may become largely unsustainable for the healthcare system in a very short-time horizon. we observed a slight decrease of the reproduction number, possibly connected with an increased population awareness and early effect of interventions. aggressive containment strategies are required to control covid-19 spread and catastrophic outcomes for the healthcare system.",
            "contribution_ids": [
                "R44727"
            ]
        },
        {
            "instance_id": "R44978xR44689",
            "comparison_id": "R44978",
            "paper_id": "R44689",
            "text": "Problem solving treatment and group psychoeducation for depression: multicentre randomised controlled trial. Outcomes of Depression International Network (ODIN) Group abstract objectives: to determine the acceptability of two psychological interventions for depressed adults in the community and their effect on caseness, symptoms, and subjective function. design: a pragmatic multicentre randomised controlled trial, stratified by centre. setting: nine urban and rural communities in finland, republic of ireland, norway, spain, and the united kingdom. participants: 452 participants aged 18 to 65, identified through a community survey with depressive or adjustment disorders according to the international classification of diseases, 10th revision or diagnostic and statistical manual of mental disorders, fourth edition. interventions: six individual sessions of problem solving treatment (n=128), eight group sessions of the course on prevention of depression (n=108), and controls (n=189). main outcome measures: completion rates for each intervention, diagnosis of depression, and depressive symptoms and subjective function. results: 63% of participants assigned to problem solving and 44% assigned to prevention of depression completed their intervention. the proportion of problem solving participants depressed at six months was 17% less than that for controls, giving a number needed to treat of 6; the mean difference in beck depression inventory score was \u22122.63 (95% confidence interval \u22124.95 to \u22120.32), and there were significant improvements in sf-36 scores. for depression prevention, the difference in proportions of depressed participants was 14% (number needed to treat of 7); the mean difference in beck depression inventory score was \u22121.50 (\u22124.16 to 1.17), and there were significant improvements in sf-36 scores. such differences were not observed at 12 months. neither specific diagnosis nor treatment with antidepressants affected outcome. conclusions: when offered to adults with depressive disorders in the community, problem solving treatment was more acceptable than the course on prevention of depression. both interventions reduced caseness and improved subjective function.",
            "contribution_ids": [
                "R44690"
            ]
        },
        {
            "instance_id": "R44978xR44702",
            "comparison_id": "R44978",
            "paper_id": "R44702",
            "text": "Randomised controlled trial comparing problem solving treatment with amitriptyline and placebo for major depression in primary care abstract objective: to determine whether, in the treatment of major depression in primary care, a brief psychological treatment (problem solving) was (a) as effective as antidepressant drugs and more effective than placebo; (b) feasible in practice; and (c) acceptable to patients. design: randomised controlled trial of problem solving treatment, amitriptyline plus standard clinical management, and drug placebo plus standard clinical management. each treatment was delivered in six sessions over 12 weeks. setting: primary care in oxfordshire. subjects: 91 patients in primary care who had major depression. main outcome measures: observer and self reported measures of severity of depression, self reported measure of social outcome, and observer measure of psychological symptoms at six and 12 weeks; self reported measure of patient satisfaction at 12 weeks. numbers of patients recovered at six and 12 weeks. results: at six and 12 weeks the difference in score on the hamilton rating scale for depression between problem solving and placebo treatments was significant (5.3 (95% confidence interval 1.6 to 9.0) and 4.7 (0.4 to 9.0) respectively), but the difference between problem solving and amitriptyline was not significant (1.8 (\u22121.8 to 5.5) and 0.9 (\u22123.3 to 5.2) respectively). at 12 weeks 60% (18/30) of patients given problem solving treatment had recovered on the hamilton scale compared with 52% (16/31) given amitriptyline and 27% (8/30) given placebo. patients were satisfied with problem solving treatment; all patients who completed treatment (28/30) rated the treatment as helpful or very helpful. the six sessions of problem solving treatment totalled a mean therapy time of 3 1/2 hours. conclusions: as a treatment for major depression in primary care, problem solving treatment is effective, feasible, and acceptable to patients. key messages key messages patient compliance with antidepressant treatment is often poor, so there is a need for a psychological treatment this study found that problem solving is an effective psychological treatment for major depression in primary care\u2014as effective as amitriptyline and more effective than placebo problem solving is a feasible treatment in primary care, being effective when given over six sessions by a general practitioner problem solving treatment is acceptable to patients",
            "contribution_ids": [
                "R44703"
            ]
        },
        {
            "instance_id": "R44978xR44716",
            "comparison_id": "R44978",
            "paper_id": "R44716",
            "text": "Randomised controlled trial of non-directive counselling, cognitive-behaviour therapy, and usual general practitioner care for patients with depression abstract objective: to compare the clinical effectiveness of general practitioner care and two general practice based psychological therapies for depressed patients. design: prospective, controlled trial with randomised and patient preference allocation arms. setting: general practices in london and greater manchester. participants: 464 of 627 patients presenting with depression or mixed anxiety and depression were suitable for inclusion. interventions: usual general practitioner care or up to 12 sessions of non-directive counselling or cognitive-behaviour therapy provided by therapists. main outcome measures: beck depression inventory scores, other psychiatric symptoms, social functioning, and satisfaction with treatment measured at baseline and at 4 and 12 months. results: 197 patients were randomly assigned to treatment, 137 chose their treatment, and 130 were randomised only between the two psychological therapies. all groups improved significantly over time. at four months, patients randomised to non-directive counselling or cognitive-behaviour therapy improved more in terms of the beck depression inventory (mean (sd) scores 12.9 (9.3) and 14.3 (10.8) respectively) than those randomised to usual general practitioner care (18.3 (12.4)). however, there was no significant difference between the two therapies. there were no significant differences between the three treatment groups at 12 months (beck depression scores 11.8 (9.6), 11.4 (10.8), and 12.1 (10.3) for non-directive counselling, cognitive-behaviour therapy, and general practitioner care). conclusions: psychological therapy was a more effective treatment for depression than usual general practitioner care in the short term, but after one year there was no difference in outcome.",
            "contribution_ids": [
                "R44717"
            ]
        },
        {
            "instance_id": "R46295xR45098",
            "comparison_id": "R46295",
            "paper_id": "R45098",
            "text": "Flash photolysis observation of the absorption spectra of trapped positive holes and electrons in colloidal titanium dioxide \"photolyse laser eclair a 347 nm d'un sol de tio 2 contenant un intercepteur d'electron adsorbe (pt ou mv 2+ ). etude par spectres d'absorption des especes piegees. a \u03bb max =475 nm observation de \u00abtrous\u00bb h + . vitesses de declin de h + en solutions acide et alcaline. trous h + en exces. avec un sol de tio 2 contenant un intercepteur de trous (alcool polyvinylique ou thiocyanate), observation d'un spectre a \u03bb max =650 nm attribue aux electrons pieges en exces, proches de la surface des particules colloidales\"",
            "contribution_ids": [
                "R45099"
            ]
        },
        {
            "instance_id": "R46295xR45104",
            "comparison_id": "R46295",
            "paper_id": "R45104",
            "text": "Charge Carrier Dynamics at TiO2 Particles:\u00e2\u0080\u0089 Reactivity of Free and Trapped Holes details of the mechanism of the photocatalytic oxidation of the model compounds dichloroacetate, dca-, and thiocyanate, scn-, have been investigated employing time-resolved laser flash photolysis. nanosized colloidal titanium dioxide (tio2, anatase) particles with a mean diameter of 24 a were used as photocatalysts in optically transparent aqueous suspensions. detailed spectroscopic investigations of the processes occurring upon band gap irradiation in these colloidal aqueous tio2 suspensions in the absence of any hole scavengers showed that while electrons are trapped instantaneously, i.e., within the duration of the laser flash (20 ns), at least two different types of traps have to be considered for the remaining holes. deeply trapped holes, h+tr, are rather long-lived and unreactive, i.e., they are transferred neither to dca- nor to scn- ions. shallowly trapped holes, h+tr*, on the other hand, are in a thermally activated equilibrium with free holes which exhibit a very high oxidation potential. the ov...",
            "contribution_ids": [
                "R45105"
            ]
        },
        {
            "instance_id": "R46295xR45106",
            "comparison_id": "R46295",
            "paper_id": "R45106",
            "text": "How fast is interfacial hole transfer? In situ monitoring of carrier dynamics in anatase TiO 2 nanoparticles by femtosecond laser spectroscopy by comparing the transient absorption spectra of nanosized anatase tio2 colloidal systems with and without scn\u2212, the broad absorption band around 520 nm observed immediately after band-gap excitation for the system without scn\u2212 has been assigned to shallowly trapped holes. in the presence of scn\u2212, the absorption from the trapped holes at 520 nm cannot be observed because of the ultrafast interfacial hole transfer between tio2 nanoparticles and scn\u2212. the hole and electron trapping times were estimated to be <50 and 260 fs, respectively, by the analysis of rise and decay dynamics of transient absorption spectra. the rate of the hole transfer from nanosized tio2 colloid to scn\u2212 is comparable to that of the hole trapping and the time of formation of a weakly coupled (scn\u00b7\u00b7\u00b7scn)\u2022\u2212 is estimated to be \u223d2.3 ps with 0.3 m kscn. a further \\n structural change to form a stable (scn)2\u2022\u2212 is observed in a timescale of 100\u223d150 ps, which is almost independent of the concentration of scn\u2212.",
            "contribution_ids": [
                "R45107"
            ]
        },
        {
            "instance_id": "R46295xR45112",
            "comparison_id": "R46295",
            "paper_id": "R45112",
            "text": "Photochemical Reduction of Oxygen Adsorbed to Nanocrystalline TiO2 Films:\u00e2\u0080\u0089 A Transient Absorption and Oxygen Scavenging Study of Different TiO2 Preparations transient absorption spectroscopy (tas) has been used to study the interfacial electron-transfer reaction between photogenerated electrons in nanocrystalline titanium dioxide (tio(2)) films and molecular oxygen. tio(2) films from three different starting materials (tio(2) anatase colloidal paste and commercial anatase/rutile powders degussa tio(2) p25 and vp tio(2) p90) have been investigated in the presence of ethanol as a hole scavenger. separate investigations on the photocatalytic oxygen consumption by the films have also been performed with an oxygen membrane polarographic detector. results show that a correlation exists between the electron dynamics of oxygen consumption observed by tas and the rate of oxygen consumption through the photocatalytic process. the highest activity and the fastest oxygen reduction dynamics were observed with films fabricated from anatase tio(2) colloidal paste. the use of tas as a tool for the prediction of the photocatalytic activities of the materials is discussed. tas studies indicate that the rate of reduction of molecular oxygen is limited by interfacial electron-transfer kinetics rather than by the electron trapping/detrapping dynamics within the tio(2) particles.",
            "contribution_ids": [
                "R45113"
            ]
        },
        {
            "instance_id": "R46296xR46082",
            "comparison_id": "R46296",
            "paper_id": "R46082",
            "text": "Formation of New Structures and Their Synergistic Effects in Boron and Nitrogen Codoped TiO2 for Enhancement of Photocatalytic Performance a novel double hydrothermal method to prepare the boron and nitrogen codoped tio2 is developed. two different ways have been used for the synthesis of the catalysts, one through the addition of boron followed by nitrogen, and the other through the addition of nitrogen first and then by boron. the x-ray photoelectron spectroscopy analysis indicates the synergistic effect of boron and nitrogen with the formation of ti\u2212b\u2212n\u2212ti and ti\u2212n\u2212b\u2212o compounds on the surface of catalysts when nitrogen is introduced to the materials first. when the boron is added first, only ti\u2212n\u2212b\u2212o species occurs on the surface of catalysts. the above two compounds are all thought to enhance the photocatalytic activities of codoped tio2. density functional theory simulations are also performed to investigate the b\u2212n synergistic effect. for the (101) surface, the formation of ti\u2212b\u2212n\u2212ti structures gives rise to the localized states within the tio2 band gap.",
            "contribution_ids": [
                "R46083"
            ]
        },
        {
            "instance_id": "R46296xR46091",
            "comparison_id": "R46296",
            "paper_id": "R46091",
            "text": "Synthesis and Characterization of Nitrogen-Doped TiO2 Nanophotocatalyst with High Visible Light Activity nitrogen-doped tio2 nanocatalysts with a homogeneous anatase structure were successfully synthesized through a microemulsion\u2212hydrothermal method by using some organic compounds such as triethylamine, urea, thiourea, and hydrazine hydrate. analysis by raman and x-ray photoemission spectroscopy indicated that nitrogen was doped effectively and most nitrogen dopants might be present in the chemical environment of ti\u2212o\u2212n and o\u2212ti\u2212n. a shift of the absorption edge to a lower energy and a stronger absorption in the visible light region were observed. the results of photodegradation or the organic pollutant rhodamine b in the visible light irradiation (\u03bb > 420 nm) suggested that the tio2 photocatalysts after nitrogen doping were greatly improved compared with the undoped tio2 photocatalysts and degussa p-25; especially the nitrogen-doped tio2 using triathylamine as the nitrogen source showed the highest photocatalytic activity, which also showed a higher efficiency for photodecomposition of 2,4-dichlorophenol. t...",
            "contribution_ids": [
                "R46092"
            ]
        },
        {
            "instance_id": "R46296xR46111",
            "comparison_id": "R46296",
            "paper_id": "R46111",
            "text": "Photocatalytic Performance of N-Doped TiO2 Adsorbed with Fe3+ Ions under Visible Light by a Redox Treatment a simple method to prepare the n\u2212tio2 adsorbed with fe3+ ions only on the surface of catalysts and modify the catalysts by a redox treatment (nabh4 reduction and air oxidation treatment) was proposed. the samples were characterized by x-ray diffraction (xrd), uv\u2212vis diffuse reflectance spectroscopy, ftir, x-ray photoelectron spectroscopy (xps), and high-resolution transmission electron micrograph (hrtem). the photocatalytic activities of the samples were evaluated for degradation of methylene blue (mb) in aqueous solutions under visible light (\u03bb > 420 nm). the results of xrd, ftir, xps, and hrtem analysis indicated that the structure of fe compounds changed from fe2o3 to \u03b3-feooh after redox treatment. compared to n\u2212tio2 with fe3+ ions, the catalysts after redox treatment showed higher photoactivity under visible light, and the formation of \u03b3-feooh was responsible for the improvement of photocatalytic activity. furthermore, to the catalysts after redox treatment, the mechanism for degradation of mb under v...",
            "contribution_ids": [
                "R46112"
            ]
        },
        {
            "instance_id": "R46296xR46113",
            "comparison_id": "R46296",
            "paper_id": "R46113",
            "text": "Preparation of Polycrystalline TiO2 Photocatalysts Impregnated with Various Transition Metal Ions: Characterization and Photocatalytic Activity for the Degradation of 4-Nitrophenol a set of polycrystalline tio2 photocatalysts loaded with various ions of transition metals (co, cr, cu, fe, mo, v, and w) were prepared by using the wet impregnation method. the samples were characterized by using some bulk and surface techniques, namely x-ray diffraction, bet specific surface area determination, scanning electron microscopy, point of zero charge determination, and femtosecond pump\u2212probe diffuse reflectance spectroscopy (pp-drs). the samples were employed as catalysts for 4-nitrophenol photodegradation in aqueous suspension, used as a probe reaction. the characterization results have confirmed the difficulty to find a straightforward correlation between photoactivity and single specific properties of the powders. diffuse reflectance measurements showed a slight shift in the band gap transition to longer wavelengths and an extension of the absorption in the visible region for almost all the doped samples. sem observation and edx measurements indicated a similar morphology for all the parti...",
            "contribution_ids": [
                "R46114"
            ]
        },
        {
            "instance_id": "R46296xR46125",
            "comparison_id": "R46296",
            "paper_id": "R46125",
            "text": "A Facile Method to Improve the Photocatalytic and Lithium\u00e2\u0080\u0090Ion Rechargeable Battery Performance of TiO2 Nanocrystals tio2 has been well studied as an ultraviolet (uv) photocatalyst and electrode material for lithium\u2010ion rechargeable batteries. recent studies have shown that hydrogenated tio2 displayed better photocatalytic and lithium ion battery performances. here it is demonstrated that the photocatalytic and battery performances of tio2 nanocrystals can be successfully improved with a facile low\u2010temperature vacuum process. these tio2 nanocrystals extend their optical absorption far into the visible\u2010light region, display nanometer\u2010scale surface atomic rearrangement, possess superoxide ion characteristics at room temperature without light irradiation, show a 4\u2010fold improvement in photocatalytic activity, and has 30% better performance in capacity and charge/discharge rates for lithium ion battery. this facile method could provide an alternative and effective approach to improve the performance of tio2 and other materials towards their practical applications.",
            "contribution_ids": [
                "R46126"
            ]
        },
        {
            "instance_id": "R46299xR46221",
            "comparison_id": "R46299",
            "paper_id": "R46221",
            "text": "CO2 reduction over NaNbO3 and NaTaO3 perovskite photocatalysts both nanbo 3 and natao 3 exhibit interesting intrinsic photocatalytic activities for co 2 reduction in terms of conversion and selectivity.",
            "contribution_ids": [
                "R46222"
            ]
        },
        {
            "instance_id": "R46299xR46235",
            "comparison_id": "R46299",
            "paper_id": "R46235",
            "text": "Photocatalytic CO2 Reduction by Re(I) Polypyridyl Complexes Immobilized on Niobates Nanoscrolls \"immobilization of re(i) co2 reduction photocatalysts on metal oxide surfaces is an interesting approach to improve their stability and recyclability. in this work, we describe the photocatalytic activity of two re(i) complexes (fac-[re(nn)(co)3(cl)], nn = 4,4'-dicarboxylic acid-2,2'-bipyridine, 1, or 5,6-dione-1,10-phenantroline, 2) on the surface of hexaniobate nanoscrolls. after adsorption, the turnover number for co production (tonco) in dmf/teoa of 1 was increased from 9 to 58, which is 20% higher than that observed on tio2, being among the highest reported values for a re(i)-based photocatalyst under visible light irradiation without any sensitizer. the complex 2 is inactive in solution under visible-light irradiation, but it has a tonco of 35 when immobilized on hexaniobate nanoscrolls. transient absorption spectroscopy studies reveal that the slow back-electron transfer and the higher reducing power of the hexaniobate conduction-band electrons play a major role for the photocatalytic process. the r...\"",
            "contribution_ids": [
                "R46236"
            ]
        },
        {
            "instance_id": "R48103xR46656",
            "comparison_id": "R48103",
            "paper_id": "R46656",
            "text": "CRFS-based Chinese named entity recognition with improved tag set chinese named entity recognition is one of the most important tasks in nlp. the paper mainly describes our work on ner tasks. the paper built up a system under the framework of conditional random fields (crfs) model. with an improved tag set the system gets an f-value of 93.49 using sighan2007 msra corpus.",
            "contribution_ids": [
                "R46657"
            ]
        },
        {
            "instance_id": "R48392xR48367",
            "comparison_id": "R48392",
            "paper_id": "R48367",
            "text": "Linking sea level rise and socioeconomic indicators underthe Shared Socioeconomic Pathways in order to assess future sea level rise and its societal impacts, we need to study climate change pathways combined with different scenarios of socioeconomic development. here, we present sea level rise (slr) projections for the shared socioeconomic pathway (ssp) storylines and different year-2100 radiative forcing targets (fts). future slr is estimated with a comprehensive slr emulator that accounts for antarctic rapid discharge from hydrofracturing and ice cliff instability. across all baseline scenario realizations (no dedicated climate mitigation), we find 2100 median slr relative to 1986\u20132005 of 89\\u2009cm (likely range: 57\u2013130\\u2009cm) for ssp1, 105\\u2009cm (73\u2013150\\u2009cm) for ssp2, 105\\u2009cm (75\u2013147\\u2009cm) for ssp3, 93\\u2009cm (63\u2013133\\u2009cm) for ssp4, and 132\\u2009cm (95\u2013189\\u2009cm) for ssp5. the 2100 sea level responses for combined ssp-ft scenarios are dominated by the mitigation targets and yield median estimates of 52\\u2009cm (34\u201375\\u2009cm) for ft 2.6\\u2009wm\u22122, 62\\u2009cm (40\u201396\\u2009cm) for ft 3.4\\u2009wm\u22122, 75\\u2009cm (47\u2013113\\u2009cm) for ft 4.5\\u2009wm\u22122, and 91\\u2009cm (61\u2013132\\u2009cm) for ft 6.0\\u2009wm\u22122. average 2081\u20132100 annual slr rates are 5 mm yr\u22121 and 19 mm yr\u22121 for ft 2.6\\u2009wm\u22122 and the baseline scenarios, respectively. our model setup allows linking scenario-specific emission and socioeconomic indicators to projected slr. we find that 2100 median ssp slr projections could be limited to around 50\\u2009cm if 2050 cumulative co2 emissions since pre-industrial stay below 850 gtc, with a global coal phase-out nearly completed by that time. for ssp mitigation scenarios, a 2050 carbon price of 100 us$2005 tco2\u22121 would correspond to a median 2100 slr of around 65 cm. our results confirm that rapid and early emission reductions are essential for limiting 2100 slr.",
            "contribution_ids": [
                "R48369",
                "R48371",
                "R48373",
                "R48375",
                "R48377",
                "R48379",
                "R175307",
                "R175310",
                "R175313",
                "R175316"
            ]
        },
        {
            "instance_id": "R52143xR52071",
            "comparison_id": "R52143",
            "paper_id": "R52071",
            "text": "Identifying Native Vegetation for Reducing Exotic Species during the Restoration of Desert Ecosystems \"there is currently much interest in restoration ecology in identifying native vegetation that can decrease the invasibility by exotic species of environments undergoing restoration. however, uncertainty remains about restoration's ability to limit exotic species, particularly in deserts where facilitative interactions between plants are prevalent. using candidate native species for restoration in the mojave desert of the southwestern u.s.a., we experimentally assembled a range of plant communities from early successional forbs to late\u2010successional shrubs and assessed which vegetation types reduced the establishment of the priority invasive annuals bromus rubens (red brome) and schismus spp. (mediterranean grass) in control and n\u2010enriched soils. compared to early successional grass and shrub and late\u2010successional shrub communities, an early forb community best resisted invasion, reducing exotic species biomass by 88% (n added) and 97% (no n added) relative to controls (no native plants). in native species monocultures, sphaeralcea ambigua (desert globemallow), an early successional forb, was the least invasible, reducing exotic biomass by 91%. however, the least\u2010invaded vegetation types did not reduce soil n or p relative to other vegetation types nor was native plant cover linked to invasibility, suggesting that other traits influenced native\u2010exotic species interactions. this study provides experimental field evidence that native vegetation types exist that may reduce exotic grass establishment in the mojave desert, and that these candidates for restoration are not necessarily late\u2010successional communities. more generally, results indicate the importance of careful native species selection when exotic species invasions must be constrained for restoration to be successful.\"",
            "contribution_ids": [
                "R52072"
            ]
        },
        {
            "instance_id": "R52143xR52073",
            "comparison_id": "R52143",
            "paper_id": "R52073",
            "text": "Using ecological restoration to constrain biological invasion summary \\n \\n \\n1 \\nbiological invasion can permanently alter ecosystem structure and function. invasive species are difficult to eradicate, so methods for constraining invasions would be ecologically valuable. we examined the potential of ecological restoration to constrain invasion of an old field by agropyron cristatum, an introduced c3 grass. \\n \\n2 \\na field experiment was conducted in the northern great plains of north america. one-hundred and forty restored plots were planted in 1994\u201396 with a mixture of c3 and c4 native grass seed, while 100 unrestored plots were not. vegetation on the plots was measured periodically between 1994 and 2002. \\n \\n3 \\nagropyron cristatum invaded the old field between 1994 and 2002, occurring in 5% of plots in 1994 and 66% of plots in 2002, and increasing in mean cover from 0\u00b72% in 1994 to 17\u00b71% in 2002. however, a. cristatum invaded one-third fewer restored than unrestored plots between 1997 and 2002, suggesting that restoration constrained invasion. further, a. cristatum cover in restored plots decreased with increasing planted grass cover. stepwise regression indicated that a. cristatum cover was more strongly correlated with planted grass cover than with distance from the a. cristatum source, species richness, percentage bare ground or percentage litter. \\n \\n4 \\nthe strength of the negative relationship between a. cristatum and planted native grasses varied among functional groups: the correlation was stronger with species with phenology and physiology similar to a. cristatum (i.e. c3 grasses) than with dissimilar species (c4 grasses). \\n \\n5 \\nrichness and cover of naturally establishing native species decreased with increasing a. cristatum cover. in contrast, restoration had little effect on the establishment and colonization of naturally establishing native species. thus, a. cristatum hindered colonization by native species while planted native grasses did not. \\n \\n6 \\nsynthesis and applications. to our knowledge, this study provides the first indication that restoration can act as a filter, constraining invasive species while allowing colonization by native species. these results suggest that resistance to invasion depends on the identity of species in the community and that restoration seed mixes might be tailored to constrain selected invaders. restoring areas before invasive species become established can reduce the magnitude of biological invasion.",
            "contribution_ids": [
                "R52074"
            ]
        },
        {
            "instance_id": "R52143xR52079",
            "comparison_id": "R52143",
            "paper_id": "R52079",
            "text": "Patterns of trait convergence and divergence among native and exotic species in herbaceous plant communities are not modified by nitrogen enrichment 1.\\u2002community assembly theories predict that the success of invading species into a new community should be predictable by functional traits. environmental filters could constrain the number of successful ecological strategies in a habitat, resulting in similar suites of traits between native and successfully invading species (convergence). conversely, concepts of limiting similarity and competitive exclusion predict native species will prevent invasion by functionally similar exotic species, resulting in trait divergence between the two species pools. nutrient availability may further alter the strength of convergent or divergent forces in community assembly, by relaxing environmental constraints and/or influencing competitive interactions.",
            "contribution_ids": [
                "R52080"
            ]
        },
        {
            "instance_id": "R52143xR52088",
            "comparison_id": "R52143",
            "paper_id": "R52088",
            "text": "Evidence of deterministic assembly according to flowering time in an old-field plant community summary 1. theory has produced contrasting predictions related to flowering time overlap among coexisting plant species largely because of the diversity of potential influences on flowering time. in this study, we use a trait-based null modelling approach to test for evidence of deterministic assembly of species according to flowering time in an old-field plant community. 2. plant species coexisting in one-metre-square plots overlapped in flowering time significantly more than expected. this flowering synchrony was more pronounced when analyses focused on bee-pollinated species. flowering synchrony was also observed for wind-pollinated species, although for only one of our two null model tests, highlighting the sensitivity of some results to different randomization methods. in general, these patterns suggest that relationships between pollinators and plants can influence community assembly processes. 3. because our study community is composed of approximately 43% native plant species and 57% exotic species, and because the arrival of new species may complicate plant\u2013pollinator interactions, we tested whether flowering time overlap was altered by introduced species. flowering synchrony was greater in plots with a higher proportion of introduced species. this pattern held for both null model tests, but was slightly stronger when analyses focused on beepollinated species. these results indicate that introduced species alter community flowering distributions and in so doing will inevitably affect pollinator\u2013plant interactions. 4. finally, we tested whether our results were influenced by variation among study plots in above-ground biomass production, which some theory predicts will be related to the importance of competition. our results were not influenced by this variation, suggesting that resource variation among our plots did not contribute to observed patterns. 5. synthesis: our results provide support for predictions that coexisting species should display flowering synchrony, and provide no support for species coexistence via temporal niche partitioning at this scale in this study community. our results also indicate that introduced species significantly alter the community assembly process such that flowering synchrony is more pronounced in plots with a greater proportion of introduced plant species.",
            "contribution_ids": [
                "R52089"
            ]
        },
        {
            "instance_id": "R52143xR52090",
            "comparison_id": "R52143",
            "paper_id": "R52090",
            "text": "Variation in resource acquisition and utilization traits between native and invasive perennial forbs understanding the functional traits that allow invasives to outperform natives is a necessary first step in improving our ability to predict and manage the spread of invaders. in nutrient-limited systems, plant competitive ability is expected to be closely tied to the ability of a plant to exploit nutrient-rich microsites and use these captured nutrients efficiently. the broad objective of this work was to compare the ability of native and invasive perennial forbs to acquire and use nutrients from nutrient-rich microsites. we evaluated morphological and physiological responses among four native and four invasive species exposed to heterogeneous (patch) or homogeneous (control) nutrient distribution. invasives, on average, allocated more biomass to roots and allocated proportionately more root length to nutrient-rich microsites than did natives. invasives also had higher leaf n, photosynthetic rates, and photosynthetic nitrogen use efficiency than natives, regardless of treatment. while these results suggest multiple traits may contribute to the success of invasive forbs in low-nutrient environments, we also observed large variation in these traits among native forbs. these observations support the idea that functional trait variation in the plant community may be a better predictor of invasion resistance than the functional group composition of the plant community.",
            "contribution_ids": [
                "R52091"
            ]
        },
        {
            "instance_id": "R52143xR52118",
            "comparison_id": "R52143",
            "paper_id": "R52118",
            "text": "OVERLAP OF FOOD AND MICROHABITAT PREFERENCES AMONG SOME NATIVE AND NONNATIVE SLUGS IN MID-ATLANTIC FORESTS OF EASTERN NORTH AMERICA introduced competitors do not share an evolutionary history that would promote coexistence mechanisms, i.e. niche partitioning. thus, nonnative species can harm a trophically similar native species by competing with them more intensely than other native species. however, nonnative species may only be able initially to invade habitats in which resource overlap with native species is small. the nonnative slug arion subfuscus exists in close sympatry with the native philomycid slugs philomycus carolinianus and megapallifera mutabilis in central maryland forests. resource use by most terrestrial gastropods is poorly known, but seems to suggest high dietary and macrohabitat overlap, potentially placing native gastropod species at high risk of competitive pressure from invading species. however, a. subfuscus was introduced to north america 150 years ago, supporting the possibility that a. subfuscus initially entered an empty niche. we tested the hypothesis that p. carolinianus and m. mutabilis would exhibit greater overlap in food and microhabitat use with a. subfuscus than they would with each other. we established food preferences by examining the faecal material of wild-caught slugs, distinguishing food types and quantifying them by volume on a microgrid. we determined microhabitat preferences by surveying the substrates of slugs in the field. the overlap in substrate and food resources was greater between a. subfuscus and p. carolinianus than between the two native species. however, substrate choice was correlated with local substrate availability for p. carolinianus, suggesting flexibility in habitat use, and the slight overlap in food use between a. subfuscus and p. carolinianus may be low enough to minimize competition.",
            "contribution_ids": [
                "R52119"
            ]
        },
        {
            "instance_id": "R52143xR52135",
            "comparison_id": "R52143",
            "paper_id": "R52135",
            "text": "Testing Fox's assembly rule: does plant invasion depend on recipient community structure? \"fox's assembly rule, that relative dearth of certain functional groups in a community will facilitate invasion of that particular functional group, serves as the basis for investigation into the functional group effects of invasion resistance. we explored resistance to plant invaders by eliminating or decreasing the number of understory plant species in particular functional groups from plots at a riparian site in southwestern virginia, usa. our functional groups comprise combinations of aboveground biomass and rooting structure type. manipulated plots were planted with 10 randomly chosen species from widespread native and introduced plants commonly found throughout the floodplains of big stony creek. we assessed success of an invasion by plant survivorship and growth. we analyzed survivorship of functional groups with loglinear models for the analysis of categorical data in a 4-way table. there was a significant interaction between functional groups removed in a plot and survivorship in the functional groups added to that plot. however, survivorship of species in functional groups introduced into plots with their respective functional group removed did not differ from survivorship when any other functional group was removed. additionally, growth of each of the most abundant species did not differ significantly among plots with different functional groups manipulated. specifically, species did not fare better in those plots that had representatives of their own functional group removed. fox's assembly rule does not hold for these functional groups in this plant community; however, composition of the recipient community is a significant factor in community assembly.\"",
            "contribution_ids": [
                "R52136",
                "R52137"
            ]
        },
        {
            "instance_id": "R53407xR53258",
            "comparison_id": "R53407",
            "paper_id": "R53258",
            "text": "Patterns of phylogenetic diversity are linked to invasion impacts- not invasion resistance- in a native grassland question: there are often more invasive species in communities that are less phylogenetically diverse or distantly related to the invaders. this is thought to indicate reduced biotic resistance, but recent theory predicts that phylogenetic relationships have more influence on competitive outcomes when interactions are more pair-wise than diffuse. therefore, phylogenetic relationships should change when the invader becomes dominant and interactions are more pairwise, rather than alter biotic resistance, which is the outcome of diffuse interactions with the resident community; however both processes can produce similar phylogenetic structures within communities. we ask whether phylogenetic structure is more associated with biotic resistance or invasion impacts following bromus inermis (brome) invasion and identify the mechanisms behind changes to phylogenetic structure. location: native grassland in alberta, canada. methods: we tested whether phylogenetic structure affected biotic resistance by transplanting brome seedlings into intact vegetation and quantified invasion impacts on community structure by surveying across multiple invasion edges. additionally, we tested whether relatedness, rarity, average patch size, evolutionary distinctiveness or environmental tolerances determined species\u2019 response to brome invasion. results: neither phylogenetic diversity, nor relatedness to brome, influenced the strength of biotic resistance; resource availability was the strongest determinant of resistance. however, communities did become less diverse and phylogenetically over-dispersed following brome invasion, but not because of the loss of related species. brome invasion was associated with declines in common species from common lineages and increases in shade-tolerant species and rare species from species-poor lineages. conclusions: ourresults suggest that invasion is morelikelytoaffectthe phylogenetic structure of the community than the phylogenetic structure of the community will affect invasion. however, they also suggest that the degree of relatedness between the invader and the resident community is unlikely todrive these effects on phylogenetic community structure. consistent with previous studies, invasion effects were stronger for common species as they have reduced shade tolerance and cannot persist in a subordinate role. this suggests that invasion effects on phylogenetic community structure will depend on which species exhibit traits that enable persistence with the invader and how these traits are distributed across the phylogeny.",
            "contribution_ids": [
                "R53259"
            ]
        },
        {
            "instance_id": "R53407xR53261",
            "comparison_id": "R53407",
            "paper_id": "R53261",
            "text": "A phylogenetic approach towards understanding the drivers of plant invasiveness on Robben Island- South Africa \"invasive plant species are a considerable threat to ecosystems globally and on islands in particular where species diversity can be relatively low. in this study, we examined the phylogenetic basis of invasion success on robben island in south africa. the flora of the island was sampled extensively and the phylogeny of the local community was reconstructed using the two core dna barcode regions, rbcla and matk. by analysing the phylogenetic patterns of native and invasive floras at two different scales, we found that invasive alien species are more distantly related to native species, a confirmation of darwin's naturalization hypothesis. however, this pattern also holds even for randomly generated communities, therefore discounting the explanatory power of darwin's naturalization hypothesis as the unique driver of invasion success on the island. these findings suggest that the drivers of invasion success on the island may be linked to species traits rather than their evolutionary history alone, or to the combination thereof. this result also has implications for the invasion management programmes currently being implemented to rehabilitate the native diversity on robben island.\\xa0\u00a9 2013 the linnean society of london, botanical journal of the linnean society, 2013, 172, 142\u2013152.\"",
            "contribution_ids": [
                "R53262",
                "R53264"
            ]
        },
        {
            "instance_id": "R53407xR53266",
            "comparison_id": "R53407",
            "paper_id": "R53266",
            "text": "Darwin's naturalization hypothesis: scale matters in coastal plant communities \"darwin proposed two seemingly contradictory hypotheses for a better understanding of biological invasions. strong relatedness of invaders to native communities as an indication of niche overlap could promote naturalization because of appropriate niche adaptation, but could also hamper naturalization because of negative interactions with native species ('darwin's naturalization hypothesis'). although these hypotheses provide clear and opposing predictions for expected patterns of species relatedness in invaded communities, so far no study has been able to clearly disentangle the underlying mechanisms. we hypothesize that conflicting past results are mainly due to the neglected role of spatial resolution of the community sampling. in this study, we corroborate both of darwin's expectations by using phylogenetic relatedness as a measure of niche overlap and by testing the effects of sampling resolution in highly invaded coastal plant communities. at spatial resolutions fine enough to detect signatures of biotic interactions, we find that most invaders are less related to their nearest relative in invaded plant communities than expected by chance (phylogenetic overdispersion). yet at coarser spatial resolutions, native assemblages become more invasible for closely-related species as a consequence of habitat filtering (phylogenetic clustering). recognition of the importance of the spatial resolution at which communities are studied allows apparently contrasting theoretical and empirical results to be reconciled. our study opens new perspectives on how to better detect, differentiate and understand the impact of negative biotic interactions and habitat filtering on the ability of invaders to establish in native communities.\"",
            "contribution_ids": [
                "R53267",
                "R53269"
            ]
        },
        {
            "instance_id": "R53407xR53314",
            "comparison_id": "R53407",
            "paper_id": "R53314",
            "text": "An experimental test of Darwin's naturalization hypothesis one of the oldest ideas in invasion biology, known as darwin\u2019s naturalization hypothesis, suggests that introduced species are more successful in communities in which their close relatives are absent. we conducted the first experimental test of this hypothesis in laboratory bacterial communities varying in phylogenetic relatedness between resident and invading species with and without a protist bacterivore. as predicted, invasion success increased with phylogenetic distance between the invading and the resident bacterial species in both the presence and the absence of protistan bacterivory. the frequency of successful invader establishment was best explained by average phylogenetic distance between the invader and all resident species, possibly indicating limitation by the availability of the unexploited niche (i.e., organic substances in the medium capable of supporting the invader growth); invader abundance was best explained by phylogenetic distance between the invader and its nearest resident relative, possibly indicating limitation by the availability of the unexploited optimal niche (i.e., the subset of organic substances supporting the best invader growth). these results were largely driven by one resident bacterium (a subspecies of serratia marcescens) posting the strongest resistance to the alien bacterium (another subspecies of s. marcescens). overall, our findings support phylogenetic relatedness as a useful predictor of species invasion success.",
            "contribution_ids": [
                "R53315",
                "R53317"
            ]
        },
        {
            "instance_id": "R53407xR53319",
            "comparison_id": "R53407",
            "paper_id": "R53319",
            "text": "Colonization plasticity of the boring bivalve Lithophaga aristata (Dillwyn- 1817) on the Southeastern Brazilian coast: considerations on its invasiveness potential lithophaga aristata is a boring bivalve native to the caribbean sea, first recorded in 2005 as an introduced species on the southeastern brazilian coast. the geographic distribution and density of l. aristata and of its native congeneric l. bisulcata were assessed in four areas of brazil (24 sites), additionally considering their relationship with types of substrate, depth and wave exposure. this study records the first occurrence of l. aristata in the sepetiba bay and also reports the species at five new localities in the arraial do cabo bay. lithophaga aristata is established in the four surveyed regions. at intertidal habitats, the exotic species only colonizes the infralittoral fringe but its density was not related to wave action. at subtidal habitats, the species colonizes natural and artificial substrates, from shallow (0.5m) to deep (5.0-7.0m) zones but no relationship between density and these evaluated factors was detected. broad geographical and ecological distributions and higher densities of this introduced species in relation to its native congeneric are suggested as contrary to darwin\u2019s naturalization hypothesis and instead indicate a high invasiveness potential.",
            "contribution_ids": [
                "R53320"
            ]
        },
        {
            "instance_id": "R53407xR53340",
            "comparison_id": "R53407",
            "paper_id": "R53340",
            "text": "Patterns of bird invasion are consistent with environmental filtering predicting invasion potential has global significance for managing ecosystems as well as important theoretical implications for understanding community assembly. phylogenetic relationships of introduced species to the extant community may be predictive of establishment success because of the opposing forces of competition/shared enemies (which should limit invasions by close relatives) versus environmental filtering (which should allow invasions by close relatives). we examine here the association between establishment success of introduced birds and their phylogenetic relatedness to the extant avifauna within three highly invaded regions (florida, new zealand, and hawaii). published information on both successful and failed introductions, as well as native species, was compiled for all three regions. we created a phylogeny for each avifauna including all native and introduced bird species. from the estimated branch lengths on these phylogenies, we calculated multiple measurements of relatedness between each introduced species and the extant avifauna. we used generalized linear models to test for an association between relatedness and establishment success. we found that close relatedness to the extant avifauna was significantly associated with increased establishment success for exotic birds both at the regional (florida, hawaii, new zealand) and sub-regional (islands within hawaii) levels. our results suggest that habitat filtering may be more important than interspecific competition in avian communities assembled under high rates of anthropogenic species introductions. this work also supports the utility of community phylogenetic methods in the study of vertebrate invasions.",
            "contribution_ids": [
                "R53341",
                "R53343"
            ]
        },
        {
            "instance_id": "R53407xR53382",
            "comparison_id": "R53407",
            "paper_id": "R53382",
            "text": "Exotic taxa less related to native species are more invasive some species introduced into new geographical areas from their native ranges wreak ecological and economic havoc in their new environment. although many studies have searched for either species or habitat characteristics that predict invasiveness of exotic species, the match between characteristics of the invader and those of members of the existing native community may be essential to understanding invasiveness. here, we find that one metric, the phylogenetic relatedness of an invader to the native community, provides a predictive tool for invasiveness. using a phylogenetic supertree of all grass species in california, we show that highly invasive grass species are, on average, significantly less related to native grasses than are introduced but noninvasive grasses. the match between the invader and the existing native community may explain why exotic pest species are not uniformly noxious in all novel habitats. relatedness of invaders to the native biota may be one useful criterion for prioritizing management efforts of exotic species.",
            "contribution_ids": [
                "R53383",
                "R53385"
            ]
        },
        {
            "instance_id": "R53407xR53393",
            "comparison_id": "R53407",
            "paper_id": "R53393",
            "text": "Establishment success of introduced amphibians increases in the presence of congeneric species darwin\u2019s naturalization hypothesis predicts that the success of alien invaders will decrease with increasing taxonomic similarity to the native community. alternatively, shared traits between aliens and the native assemblage may preadapt aliens to their novel surroundings, thereby facilitating establishment (the preadaptation hypothesis). here we examine successful and failed introductions of amphibian species across the globe and find that the probability of successful establishment is higher when congeneric species are present at introduction locations and increases with increasing congener species richness. after accounting for positive effects of congeners, residence time, and propagule pressure, we also find that invader establishment success is higher on islands than on mainland areas and is higher in areas with abiotic conditions similar to the native range. these findings represent the first example in which the preadaptation hypothesis is supported in organisms other than plants and suggest that preadaptation has played a critical role in enabling introduced species to succeed in novel environments.",
            "contribution_ids": [
                "R53394"
            ]
        },
        {
            "instance_id": "R54244xR54032",
            "comparison_id": "R54244",
            "paper_id": "R54032",
            "text": "Morphological variation between non-native lake- and stream-dwelling pumpkinseed Lepomis gibbosusin the Iberian Peninsula the objective of this study was to test if morphological differences in pumpkinseed lepomis gibbosus found in their native range (eastern north america) that are linked to feeding regime, competition with other species, hydrodynamic forces and habitat were also found among stream- and lake- or reservoir-dwelling fish in iberian systems. the species has been introduced into these systems, expanding its range, and is presumably well adapted to freshwater iberian peninsula ecosystems. the results show a consistent pattern for size of lateral fins, with l. gibbosus that inhabit streams in the iberian peninsula having longer lateral fins than those inhabiting reservoirs or lakes. differences in fin placement, body depth and caudal peduncle dimensions do not differentiate populations of l. gibbosus from lentic and lotic water bodies and, therefore, are not consistent with functional expectations. lepomis gibbosus from lotic and lentic habitats also do not show a consistent pattern of internal morphological differentiation, probably due to the lack of lotic-lentic differences in prey type. overall, the univariate and multivariate analyses show that most of the external and internal morphological characters that vary among populations do not differentiate lotic from lentic iberian populations. the lack of expected differences may be a consequence of the high seasonal flow variation in mediterranean streams, and the resultant low- or no-flow conditions during periods of summer drought.",
            "contribution_ids": [
                "R54033"
            ]
        },
        {
            "instance_id": "R54244xR54034",
            "comparison_id": "R54244",
            "paper_id": "R54034",
            "text": "Norway maple displays greater seasonal growth and phenotypic plasticity to light than native sugar maple norway maple (acer platanoides l), which is among the most invasive tree species in forests of eastern north america, is associated with reduced regeneration of the related native species, sugar maple (acer saccharum marsh) and other native flora. to identify traits conferring an advantage to norway maple, we grew both species through an entire growing season under simulated light regimes mimicking a closed forest understorey vs. a canopy disturbance (gap). dynamic shade-houses providing a succession of high-intensity direct-light events between longer periods of low, diffuse light were used to simulate the light regimes. we assessed seedling height growth three times in the season, as well as stem diameter, maximum photosynthetic capacity, biomass allocation above- and below-ground, seasonal phenology and phenotypic plasticity. given the north european provenance of norway maple, we also investigated the possibility that its growth in north america might be increased by delayed fall senescence. we found that norway maple had significantly greater photosynthetic capacity in both light regimes and grew larger in stem diameter than sugar maple. the differences in below- and above-ground biomass, stem diameter, height and maximum photosynthesis were especially important in the simulated gap where norway maple continued extension growth during the late fall. in the gap regime sugar maple had a significantly higher root : shoot ratio that could confer an advantage in the deepest shade of closed understorey and under water stress or browsing pressure. norway maple is especially invasive following canopy disturbance where the opposite (low root : shoot ratio) could confer a competitive advantage. considering the effects of global change in extending the potential growing season, we anticipate that the invasiveness of norway maple will increase in the future.",
            "contribution_ids": [
                "R54035"
            ]
        },
        {
            "instance_id": "R54244xR54046",
            "comparison_id": "R54244",
            "paper_id": "R54046",
            "text": "Phenotypic Plasticity and Population Differentiation in an Ongoing Species Invasion the ability to succeed in diverse conditions is a key factor allowing introduced species to successfully invade and spread across new areas. two non-exclusive factors have been suggested to promote this ability: adaptive phenotypic plasticity of individuals, and the evolution of locally adapted populations in the new range. we investigated these individual and population-level factors in polygonum cespitosum, an asian annual that has recently become invasive in northeastern north america. we characterized individual fitness, life-history, and functional plasticity in response to two contrasting glasshouse habitat treatments (full sun/dry soil and understory shade/moist soil) in 165 genotypes sampled from nine geographically separate populations representing the range of light and soil moisture conditions the species inhabits in this region. polygonum cespitosum genotypes from these introduced-range populations expressed broadly similar plasticity patterns. in response to full sun, dry conditions, genotypes from all populations increased photosynthetic rate, water use efficiency, and allocation to root tissues, dramatically increasing reproductive fitness compared to phenotypes expressed in simulated understory shade. although there were subtle among-population differences in mean trait values as well as in the slope of plastic responses, these population differences did not reflect local adaptation to environmental conditions measured at the population sites of origin. instead, certain populations expressed higher fitness in both glasshouse habitat treatments. we also compared the introduced-range populations to a single population from the native asian range, and found that the native population had delayed phenology, limited functional plasticity, and lower fitness in both experimental environments compared with the introduced-range populations. our results indicate that the future spread of p. cespitosum in its introduced range will likely be fueled by populations consisting of individuals able to express high fitness across diverse light and moisture conditions, rather than by the evolution of locally specialized populations.",
            "contribution_ids": [
                "R54047"
            ]
        },
        {
            "instance_id": "R54244xR54054",
            "comparison_id": "R54244",
            "paper_id": "R54054",
            "text": "Phenotypic Plasticity in the Invasion of Crofton Weed (Eupatorium adenophorum) in China phenotypic plasticity and rapid evolution are two important strategies by which invasive species adapt to a wide range of environments and consequently are closely associated with plant invasion. to test their importance in invasion success of crofton weed, we examined the phenotypic response and genetic variation of the weed by conducting a field investigation, common garden experiments, and intersimple sequence repeat (issr) marker analysis on 16 populations in china. molecular markers revealed low genetic variation among and within the sampled populations. there were significant differences in leaf area (la), specific leaf area (sla), and seed number (sn) among field populations, and plasticity index (pi v ) for la, sla, and sn were 0.62, 0.46 and 0.85, respectively. regression analyses revealed a significant quadratic effect of latitude of population origin on la, sla, and sn based on field data but not on traits in the common garden experiments (greenhouse and open air). plants from different populations showed similar reaction norms across the two common gardens for functional traits. la, sla, aboveground biomass, plant height at harvest, first flowering day, and life span were higher in the greenhouse than in the open-air garden, whereas sn was lower. growth conditions (greenhouse vs. open air) and the interactions between growth condition and population origin significantly affect plant traits. the combined evidence suggests high phenotypic plasticity but low genetically based variation for functional traits of crofton weed in the invaded range. therefore, we suggest that phenotypic plasticity is the primary strategy for crofton weed as an aggressive invader that can adapt to diverse environments in china.",
            "contribution_ids": [
                "R54055"
            ]
        },
        {
            "instance_id": "R54244xR54062",
            "comparison_id": "R54244",
            "paper_id": "R54062",
            "text": "Shell morphology and relative growth variability of the invasive pearl oyster Pinctada radiata in coastal Tunisia \" the variability of shell morphology and relative growth of the invasive pearl oyster pinctada radiata was studied within and among ten populations from coastal tunisia using discriminant tests. therefore, 12 morphological characters were examined and 34 metric and weight ratios were defined. in addition to the classic morphological characters, populations were compared by the thickness of the nacreous layer. results of duncan's multiple comparison test showed that the most discriminative ratios were the width of nacreous layer of right valve to the inflation of shell, the hinge line length to the maximum width of shell and the nacre thickness to the maximum width of shell. the analysis of variance revealed an important inter-population morphological variability. both multidimensional scaling analysis and the squared mahalanobis distances ( d 2 ) of metric ratios divided tunisian p. radiata populations into four biogeographical groupings: the north coast (la marsa); harbours (hammamet, monastir and zarzis); the gulf of gab\u00e8s (sfax, kerkennah island, mahar\u00e8s, skhira and djerba) and the intertidal area (ajim). however, the kerkennah island population was discriminated by the squared mahalanobis distances ( d 2 ) of weight ratios in an isolated group suggesting particular trophic conditions in this area. the allometric study revealed high linear correlation between shell morphological characters and differences in allometric growth among p. radiata populations. unlike the morphological discrimination, allometric differentiation shows no clear geographical distinction. this study revealed that the pearl oyster p. radiata exhibited considerable phenotypic plasticity related to differences of environmental and/or ecological conditions along tunisian coasts and highlighted the discriminative character of the nacreous layer thickness parameter. \"",
            "contribution_ids": [
                "R54063"
            ]
        },
        {
            "instance_id": "R54244xR54066",
            "comparison_id": "R54244",
            "paper_id": "R54066",
            "text": "Germination patterns and implications for invasiveness in three Taraxacum (Asteraceae) species luo j & cardina j (2012). germination patterns and implications for invasiveness in three taraxacum (asteraceae) species. weed research\\xa052, 112\u2013121. \\n \\n \\n \\nsummary \\n \\nthe ability to germinate across different environments has been considered an important trait of invasive plant species that allows for establishment success in new habitats. using two alien congener species of asteraceae \u2013taraxacum officinale (invasive) and taraxacum laevigatum laevigatum (non-invasive) \u2013 we tested the hypothesis that invasive species germinate better than non-invasives under various conditions. the germination patterns of taraxacum brevicorniculatum, a contaminant found in seeds of the crop taraxacum kok-saghyz, were also investigated to evaluate its invasive potential. in four experiments, we germinated seeds along gradients of alternating temperature, constant temperature (with or without light), water potential and following accelerated ageing. neither higher nor lower germination per se explained invasion success for the taraxacum species tested here. at alternating temperature, the invasive t. officinale had higher germination than or similar to the non-invasive t.\\xa0laevigatum. contrary to predictions, t.\\xa0laevigatum exhibited higher germination than t.\\xa0officinale in environments of darkness, low water potential or after the seeds were exposed to an ageing process. these results suggested a complicated role of germination in the success of t.\\xa0officinale. taraxacum brevicorniculatum showed the highest germination among the three species in all environments. the invasive potential of this species is thus unclear and will probably depend on its performance at other life stages along environmental gradients.",
            "contribution_ids": [
                "R54067"
            ]
        },
        {
            "instance_id": "R54244xR54072",
            "comparison_id": "R54244",
            "paper_id": "R54072",
            "text": "Phenotypic Plasticity Influences the Size, Shape and Dynamics of the Geographic Distribution of an Invasive Plant phenotypic plasticity has long been suspected to allow invasive species to expand their geographic range across large-scale environmental gradients. we tested this possibility in australia using a continental scale survey of the invasive tree parkinsonia aculeata (fabaceae) in twenty-three sites distributed across four climate regions and three habitat types. using tree-level responses, we detected a trade-off between seed mass and seed number across the moisture gradient. individual trees plastically and reversibly produced many small seeds at dry sites or years, and few big seeds at wet sites and years. bigger seeds were positively correlated with higher seed and seedling survival rates. the trade-off, the relation between seed mass, seed and seedling survival, and other fitness components of the plant life-cycle were integrated within a matrix population model. the model confirms that the plastic response resulted in average fitness benefits across the life-cycle. plasticity resulted in average fitness being positively maintained at the wet and dry range margins where extinction risks would otherwise have been high (\u201cjack-of-all-trades\u201d strategy jt), and fitness being maximized at the species range centre where extinction risks were already low (\u201cmaster-of-some\u201d strategy ms). the resulting hybrid \u201cjack-and-master\u201d strategy (jm) broadened the geographic range and amplified average fitness in the range centre. our study provides the first empirical evidence for a jm species. it also confirms mechanistically the importance of phenotypic plasticity in determining the size, the shape and the dynamic of a species distribution. the jm allows rapid and reversible phenotypic responses to new or changing moisture conditions at different scales, providing the species with definite advantages over genetic adaptation when invading diverse and variable environments. furthermore, natural selection pressure acting on phenotypic plasticity is predicted to result in maintenance of the jt and strengthening of the ms, further enhancing the species invasiveness in its range centre.",
            "contribution_ids": [
                "R54073"
            ]
        },
        {
            "instance_id": "R54244xR54090",
            "comparison_id": "R54244",
            "paper_id": "R54090",
            "text": "Multiple common garden experiments suggest lack of local adaptation in an invasive ornamental plant aims adaptive evolution along geographic gradients of climatic conditions is suggested to facilitate the spread of invasive plant species, leading to clinal variation among populations in the introduced range. we investigated whether adaptation to climate is also involved in the invasive spread of an ornamental shrub, buddleja davidii, across western and central europe. methods we combined a common garden experiment, replicated in three climatically different central european regions, with reciprocal transplantation to quantify genetic differentiation in growth and reproductive traits of 20 invasive b. davidii populations. additionally, we compared compensatory regrowth among populations after clipping of stems to simulate mechanical damage.",
            "contribution_ids": [
                "R54091"
            ]
        },
        {
            "instance_id": "R54244xR54112",
            "comparison_id": "R54244",
            "paper_id": "R54112",
            "text": "VARIATION IN PHENOTYPIC PLASTICITY AMONG NATIVE AND INVASIVE POPULATIONS OF ALLIARIA PETIOLATA alliaria petiolata is a eurasian biennial herb that is invasive in north america and for which phenotypic plasticity has been noted as a potentially important invasive trait. using four european and four north american populations, we explored variation among populations in the response of a suite of antioxidant, antiherbivore, and morphological traits to the availability of water and nutrients and to jasmonic acid treatment. multivariate analyses revealed substantial variation among populations in mean levels of these traits and in the response of this suite of traits to environmental variation, especially water availability. univariate analyses revealed variation in plasticity among populations in the expression of all of the traits measured to at least one of these environmental factors, with the exception of leaf length. there was no evidence for continentally distinct plasticity patterns, but there was ample evidence for variation in phenotypic plasticity among the populations within continents. this implies that a. petiolata has the potential to evolve distinct phenotypic plasticity patterns within populations but that invasive populations are no more plastic than native populations.",
            "contribution_ids": [
                "R54113"
            ]
        },
        {
            "instance_id": "R54244xR54120",
            "comparison_id": "R54244",
            "paper_id": "R54120",
            "text": "Variation in morphological characters of two invasive leafminers, Liriomyza huidobrensis and L. sativae, across a tropical elevation gradient abstract changes in morphological traits along elevation and latitudinal gradients in ectotherms are often interpreted in terms of the temperature-size rule, which states that the body size of organisms increases under low temperatures, and is therefore expected to increase with elevation and latitude. however other factors like host plant might contribute to spatial patterns in size as well, particularly for polyphagous insects. here elevation patterns for trait size and shape in two leafminer species are examined, liriomyza huidobrensis (blanchard) (diptera: agromyzidae) and l. sativae blanchard, along a tropical elevation gradient in java, indonesia. adult leafminers were trapped from different locations in the mountainous area of dieng in the province of central java. to separate environmental versus genetic effects, l. huidobrensis originating from 1378 m and 2129 m asl were reared in the laboratory for five generations. size variation along the elevation gradient was only found in l. huidobrensis and this followed expectations based on the temperature-size rule. there were also complex changes in wing shape along the gradient. morphological differences were influenced by genetic and environmental effects. findings are discussed within the context of adaptation to different elevations in the two species.",
            "contribution_ids": [
                "R54121"
            ]
        },
        {
            "instance_id": "R54244xR54142",
            "comparison_id": "R54244",
            "paper_id": "R54142",
            "text": "Microhabitat analysis of the invasive exotic liana Lonicera japonica Thunb. abstract we documented microhabitat occurrence and growth of lonicera japonica to identify factors related to its invasion into a southern illinois shale barren. the barren was surveyed for l. japonica in june 2003, and the microhabitats of established l. japonica plants were compared to random points that sampled the range of available microhabitats in the barren. vine and leaf characters were used as measurements of plant growth. lonicera japonica occurred preferentially in areas of high litter cover and species richness, comparatively small trees, low par, low soil moisture and temperature, steep slopes, and shallow soils. plant growth varied among these microhabitats. among plots where l. japonica occurred, growth was related to soil and light conditions, and aspects of surrounding cover. overhead canopy cover was a common variable associated with nearly all measured growth traits. plasticity of traits to improve invader success can only affect the likelihood of invasion once constraints to establishment and persistence have been surmounted. therefore, understanding where l. japonica invasion occurs, and microhabitat interactions with plant growth are important for estimating invasion success.",
            "contribution_ids": [
                "R54143"
            ]
        },
        {
            "instance_id": "R54244xR54190",
            "comparison_id": "R54244",
            "paper_id": "R54190",
            "text": "Phenotypic variability in Holcus lanatus L. in southern Chile: a strategy that enhances plant survival and pasture stability \\n\\nholcus lanatus l. can colonise a wide range of sites within the naturalised grassland of the humid dominion of chile. the objectives were to determine plant growth mechanisms and strategies that have allowed h. lanatus to colonise contrasting pastures and to determine the existence of ecotypes of h. lanatus in southern chile. plants of h. lanatus were collected from four geographic zones of southern chile and established in a randomised complete block design with four replicates. five newly emerging tillers were marked per plant and evaluated at the vegetative, pre-ear emergence, complete emerged inflorescence, end of flowering period, and mature seed stages. at each evaluation, one marked tiller was harvested per plant. the variables measured included lamina length and width, tiller height, length of the inflorescence, total number of leaves, and leaf, stem, and inflorescence mass. at each phenological stage, groups of accessions were statistically formed using cluster analysis. the grouping of accessions (cluster analysis) into statistically different groups (anova and canonical variate analysis) indicated the existence of different ecotypes. the phenotypic variation within each group of the accessions suggested that each group has its own phenotypic plasticity. it is concluded that the successful colonisation by h. lanatus has resulted from diversity within the species.\\n",
            "contribution_ids": [
                "R54191"
            ]
        },
        {
            "instance_id": "R54244xR54196",
            "comparison_id": "R54244",
            "paper_id": "R54196",
            "text": "Increased fitness and plasticity of an invasive species in its introduced range: a study using Senecio pterophorus 1 when a plant species is introduced into a new range, it may differentiate genetically from the original populations in the home range. this genetic differentiation may influence the extent to which the invasion of the new range is successful. we tested this hypothesis by examining senecio pterophorus, a south african shrub that was introduced into ne spain about 40 years ago. we predicted that in the introduced range invasive populations would perform better and show greater plasticity than native populations. 2 individuals of s. pterophorus from four spanish (invasive) and four south african (native) populations were grown in catalonia, spain, in a common garden in which disturbance and water availability were manipulated. fitness traits and several ecophysiological parameters were measured. 3 the invasive populations of s. pterophorus survived better throughout the summer drought in a disturbed (unvegetated) environment than native south african populations. this success may be attributable to the lower specific leaf area (sla) and better water content regulation of the invasive populations in this treatment. 4 invasive populations displayed up to three times higher relative growth rate than native populations under conditions of disturbance and non\u2010limiting water availability. 5 the reproductive performance of the invasive populations was higher in all treatments except under the most stressful conditions (i.e. in non\u2010watered undisturbed plots), where no plant from either population flowered. 6 the results for leaf parameters and chlorophyll fluorescence measurements suggested that the greater fitness of the invasive populations could be attributed to more favourable ecophysiological responses. 7 synthesis. spanish invasive populations of s. pterophorus performed better in the presence of high levels of disturbance, and displayed higher plasticity of fitness traits in response to resource availability than native south african populations. our results suggest that genetic differentiation from source populations associated with founding may play a role in invasion success.",
            "contribution_ids": [
                "R54197"
            ]
        },
        {
            "instance_id": "R54244xR54198",
            "comparison_id": "R54244",
            "paper_id": "R54198",
            "text": "Predicting invasiveness in exotic species: do subtropical native and invasive exotic aquatic plants differ in their growth responses to macronutrients? we investigated whether plasticity in growth responses to nutrients could predict invasive potential in aquatic plants by measuring the effects of nutrients on growth of eight non\u2010invasive native and six invasive exotic aquatic plant species. nutrients were applied at two levels, approximating those found in urbanized and relatively undisturbed catchments, respectively. to identify systematic differences between invasive and non\u2010invasive species, we compared the growth responses (total biomass, root:shoot allocation, and photosynthetic surface area) of native species with those of related invasive species after 13 weeks growth. the results were used to seek evidence of invasive potential among four recently naturalized species. there was evidence that invasive species tend to accumulate more biomass than native species (p = 0.0788). root:shoot allocation did not differ between native and invasive plant species, nor was allocation affected by nutrient addition. however, the photosynthetic surface area of invasive species tended to increase with nutrients, whereas it did not among native species (p = 0.0658). of the four recently naturalized species, hydrocleys nymphoides showed the same nutrient\u2010related plasticity in photosynthetic area displayed by known invasive species. cyperus papyrus showed a strong reduction in photosynthetic area with increased nutrients. h. nymphoides and c. papyrus also accumulated more biomass than their native relatives. h. nymphoides possesses both of the traits we found to be associated with invasiveness, and should thus be regarded as likely to be invasive.",
            "contribution_ids": [
                "R54199"
            ]
        },
        {
            "instance_id": "R54244xR54200",
            "comparison_id": "R54244",
            "paper_id": "R54200",
            "text": "Spreading of the invasive Carpobrotus aff. acinaciformis in Mediterranean ecosystems: The advantage of performing in different light environments abstract question: do specific environmental conditions affect the performance and growth dynamics of one of the most invasive taxa (carpobrotus aff. acinaciformis) on mediterranean islands? location: four populations located on mallorca, spain. methods: we monitored growth rates of main and lateral shoots of this stoloniferous plant for over two years (2002\u20132003), comparing two habitats (rocky coast vs. coastal dune) and two different light conditions (sun vs. shade). in one population of each habitat type, we estimated electron transport rate and the level of plant stress (maximal photochemical efficiency fv/fm) by means of chlorophyll fluorescence. results: main shoots of carpobrotus grew at similar rates at all sites, regardless habitat type. however, growth rate of lateral shoots was greater in shaded plants than in those exposed to sunlight. its high phenotypic plasticity, expressed in different allocation patterns in sun and shade individuals, and its clonal growth which promotes the continuous search of available resources, contributed to a good growth and photochemical efficiency of carpobrotus in the relatively moderate shade of the understories of mediterranean shrublands and woodlands. each main shoot of a carpobrotus clone (which can have several dozens main shoots) grows ca. 40 cm per year, which explains its vigorous habitat colonization capacity. conclusion: the highly plastic morphological response to different light regimes of this taxon contributes to a rapid colonization of heterogeneous coastal mediterranean environments spreading well beyond the open sand dune systems where it has been often reported. nomenclature: tutin et al. (1964\u20131980).",
            "contribution_ids": [
                "R54201"
            ]
        },
        {
            "instance_id": "R54244xR54202",
            "comparison_id": "R54244",
            "paper_id": "R54202",
            "text": "Photosynthesis and water-use efficiency: A comparison between invasive (exotic) and non-invasive (native) species invasive species have been hypothesized to out-compete natives though either a jack-of-all-trades strategy, where they are able to utilize resources effectively in unfavourable environments, a master-of-some, where resource utilization is greater than its competitors in favourable environments, or a combination of the two (jack-and-master). we examined the invasive strategy of berberis darwinii in new zealand compared with four co-occurring native species by examining germination, seedling survival, photosynthetic characteristics and water-use efficiency of adult plants, in sun and shade environments. berberis darwinii seeds germinated more in shady sites than the other natives, but survival was low. in contrast, while germination of b.\\xa0darwinii was the same as the native species in sunny sites, seedling survival after 18\\xa0months was nearly twice that of the all native species. the maximum photosynthetic rate of b.\\xa0darwinii was nearly double that of all native species in the sun, but was similar among all species in the shade. other photosynthetic traits (quantum yield and stomatal conductance) did not generally differ between b.\\xa0darwinii and the native species, regardless of light environment. berberis darwinii had more positive values of \u03b413c than the four native species, suggesting that it gains more carbon per unit water transpired than the competing native species. these results suggest that the invasion success of b.\\xa0darwinii may be partially explained by combination of a jack-of-all-trades scenario of widespread germination with a master-of-some scenario through its ability to photosynthesize at higher rates in the sun and, hence, gain a rapid height and biomass advantage over native species in favourable environments.",
            "contribution_ids": [
                "R54203"
            ]
        },
        {
            "instance_id": "R54244xR54218",
            "comparison_id": "R54244",
            "paper_id": "R54218",
            "text": "Rapid evolution in response to introduced predators I: rates and patterns of morphological and life-history trait divergence abstract \\n \\n background \\n introduced species can have profound effects on native species, communities, and ecosystems, and have caused extinctions or declines in native species globally. we examined the evolutionary response of native zooplankton populations to the introduction of non-native salmonids in alpine lakes in the sierra nevada of california, usa. we compared morphological and life-history traits in populations of daphnia with a known history of introduced salmonids and populations that have no history of salmonid introductions. \\n \\n \\n results \\n our results show that daphnia populations co-existing with fish have undergone rapid adaptive reductions in body size and in the timing of reproduction. size-related traits decreased by up to 13 percent in response to introduced fish. rates of evolutionary change are as high as 4,238 darwins (0.036 haldanes). \\n \\n \\n conclusion \\n species introductions into aquatic habitats can dramatically alter the selective environment of native species leading to a rapid evolutionary response. knowledge of the rates and limits of adaptation is an important component of understanding the long-term effects of alterations in the species composition of communities. we discuss the evolutionary consequences of species introductions and compare the rate of evolution observed in the sierra nevada daphnia to published estimates of evolutionary change in ecological timescales. \\n",
            "contribution_ids": [
                "R54219"
            ]
        },
        {
            "instance_id": "R54244xR54222",
            "comparison_id": "R54244",
            "paper_id": "R54222",
            "text": "Adaptation vs. phenotypic plasticity in the success of a clonal invader the relative importance of plasticity vs. adaptation for the spread of invasive species has rarely been studied. we examined this question in a clonal population of invasive freshwater snails (potamopyrgus antipodarum) from the western united states by testing whether observed plasticity in life history traits conferred higher fitness across a range of temperatures. we raised isofemale lines from three populations from different climate regimes (high- and low-elevation rivers and an estuary) in a split-brood, common-garden design in three temperatures. we measured life history and growth traits and calculated population growth rate (as a measure of fitness) using an age-structured projection matrix model. we found a strong effect of temperature on all traits, but no evidence for divergence in the average level of traits among populations. levels of genetic variation and significant reaction norm divergence for life history traits suggested some role for adaptation. plasticity varied among traits and was lowest for size and reproductive traits compared to age-related traits and fitness. plasticity in fitness was intermediate, suggesting that invasive populations are not general-purpose genotypes with respect to the range of temperatures studied. thus, by considering plasticity in fitness and its component traits, we have shown that trait plasticity alone does not yield the same fitness across a relevant set of temperature conditions.",
            "contribution_ids": [
                "R54223"
            ]
        },
        {
            "instance_id": "R54244xR54230",
            "comparison_id": "R54244",
            "paper_id": "R54230",
            "text": "Leaf-level phenotypic variability and plasticity of invasive Rhododendron ponticum and non-invasive Ilex aquifolium co-occurring at two contrasting European sites to understand the role of leaf-level plasticity and variability in species invasiveness, foliar characteristics were studied in relation to seasonal average integrated quantum flux density (qint) in the understorey evergreen species rhododendron ponticum and ilex aquifolium at two sites. a native relict population of r. ponticum was sampled in southern spain (mediterranean climate), while an invasive alien population was investigated in belgium (temperate maritime climate). ilex aquifolium was native at both sites. both species exhibited a significant plastic response to qint in leaf dry mass per unit area, thickness, photosynthetic potentials, and chlorophyll contents at the two sites. however, r. ponticum exhibited a higher photosynthetic nitrogen use efficiency and larger investment of nitrogen in chlorophyll than i. aquifolium. since leaf nitrogen (n) contents per unit dry mass were lower in r. ponticum, this species formed a larger foliar area with equal photosynthetic potential and light-harvesting efficiency compared with i. aquifolium. the foliage of r. ponticum was mechanically more resistant with larger density in the belgian site than in the spanish site. mean leaf-level phenotypic plasticity was larger in the belgian population of r. ponticum than in the spanish population of this species and the two populations of i. aquifolium. we suggest that large fractional investments of foliar n in photosynthetic function coupled with a relatively large mean, leaf-level phenotypic plasticity may provide the primary explanation for the invasive nature and superior performance of r. ponticum at the belgian site. with alleviation of water limitations from mediterranean to temperate maritime climates, the invasiveness of r. ponticum may also be enhanced by the increased foliage mechanical resistance observed in the alien populations.",
            "contribution_ids": [
                "R54231"
            ]
        },
        {
            "instance_id": "R54244xR54236",
            "comparison_id": "R54244",
            "paper_id": "R54236",
            "text": "Induced defenses in response to an invading crab predator: An explanation of historical and geographic phenotypic change \\n the expression of defensive morphologies in prey often is correlated with predator abundance or diversity over a range of temporal and spatial scales. these patterns are assumed to reflect natural selection via differential predation on genetically determined, fixed phenotypes. phenotypic variation, however, also can reflect within-generation developmental responses to environmental cues (phenotypic plasticity). for example, water-borne effluents from predators can induce the production of defensive morphologies in many prey taxa. this phenomenon, however, has been examined only on narrow scales. here, we demonstrate adaptive phenotypic plasticity in prey from geographically separated populations that were reared in the presence of an introduced predator. marine snails exposed to predatory crab effluent in the field increased shell thickness rapidly compared with controls. induced changes were comparable to (\\n i \\n ) historical transitions in thickness previously attributed to selection by the invading predator and (\\n ii \\n ) present-day clinal variation predicted from water temperature differences. thus, predator-induced phenotypic plasticity may explain broad-scale geographic and temporal phenotypic variation. if inducible defenses are heritable, then selection on the reaction norm may influence coevolution between predator and prey. trade-offs may explain why inducible rather than constitutive defenses have evolved in several gastropod species.\\n",
            "contribution_ids": [
                "R54237"
            ]
        },
        {
            "instance_id": "R54867xR54585",
            "comparison_id": "R54867",
            "paper_id": "R54585",
            "text": "The incidence of exotic species following clearfelling of Eucalyptus regnans forest in the Central Highlands, Victoria invasion by exotic species following clearfelling of eucalyptus regnans f. muell. (mountain ash) forest was examined in the toolangi state forest in the central highlands of victoria. coupes ranging in age from < 1- to 10-years-old and the spar-stage forests (1939 bushfire regrowth) adjacent to each of these coupes and a mature, 250-year-old forest were surveyed. the dispersal and establishment of weeds was facilitated by clearfelling. an influx of seeds of exotic species was detected in recently felled coupes but not in the adjacent, unlogged forests. vehicles and frequently disturbed areas, such as roadside verges, are likely sources of the seeds of exotic species. the soil seed bank of younger coupes had a greater number and percentage of seeds of exotics than the 10-year-old coupes and the spar-stage and mature forests. exotic species were a minor component (< 1% vegetation cover) in the more recently logged coupes and were not present in 10-year-old coupes and the spar-stage and mature forests. these particular exotic species did not persist in the dense regeneration nor exist in the older forests because the weeds were ruderal species (light-demanding, short-lived and short-statured plants). the degree of influence that these particular exotic species have on the regeneration and survival of native species in e. regnans forests is almost negligible. however, the current management practices may need to be addressed to prevent a more threatening exotic species from establishing in these coupes and forests.",
            "contribution_ids": [
                "R54586",
                "R54587"
            ]
        },
        {
            "instance_id": "R54867xR54622",
            "comparison_id": "R54867",
            "paper_id": "R54622",
            "text": "Responses of exotic plant species to fires in Pinus ponderosa forests in northern Arizona . changes in disturbance due to fire regime in southwestern pinus ponderosa forests over the last century have led to dense forests that are threatened by widespread fire. it has been shown in other studies that a pulse of native, early-seral opportunistic species typically follow such disturbance events. with the growing importance of exotic plants in local flora, however, these exotics often fill this opportunistic role in recovery. we report the effects of fire severity on exotic plant species following three widespread fires of 1996 in northern arizona p. ponderosa forests. species richness and abundance of all vascular plant species, including exotics, were higher in burned than nearby unburned areas. exotic species were far more important, in terms of cover, where fire severity was highest. species present after wildfires include those of the pre-disturbed forest and new species that could not be predicted from above-ground flora of nearby unburned forests.",
            "contribution_ids": [
                "R54623",
                "R54624"
            ]
        },
        {
            "instance_id": "R54867xR54638",
            "comparison_id": "R54867",
            "paper_id": "R54638",
            "text": "Exotic invasive species in urban wetlands: environmental correlates and implications for wetland management summary 1. wetlands in urban regions are subjected to a wide variety of anthropogenic disturbances, many of which may promote invasions of exotic plant species. in order to devise management strategies, the influence of different aspects of the urban and natural environments on invasion and community structure must be understood. 2. the roles of soil variables, anthropogenic effects adjacent to and within the wetlands, and vegetation structure on exotic species occurrence within 21 forested wetlands in north-eastern new jersey, usa, were compared. the hypotheses were tested that different vegetation strata and different invasive species respond similarly to environmental factors, and that invasion increases with increasing direct human impact, hydrologic disturbance, adjacent residential land use and decreasing wetland area. canonical correspondence analyses, correlation and logistic regression analyses were used to examine invasion by individual species and overall site invasion, as measured by the absolute and relative number of exotic species in the site flora. 3. within each stratum, different sets of environmental factors separated exotic and native species. nutrients, soil clay content and ph, adjacent land use and canopy composition were the most frequently identified factors affecting species, but individual species showed highly individualistic responses to the sets of environmental variables, often responding in opposite ways to the same factor. 4. overall invasion increased with decreasing area but only when sites > 100 ha were included. unexpectedly, invasion decreased with increasing proportions of industrial/commercial adjacent land use. 5. the hypotheses were only partially supported; invasion does not increase in a simple way with increasing human presence and disturbance. 6. synthesis and applications . the results suggest that a suite of environmental conditions can be identified that are associated with invasion into urban wetlands, which can be widely used for assessment and management. however, a comprehensive ecosystem approach is needed that places the remediation of physical alterations from urbanization within a landscape context. specifically, sediment, inputs and hydrologic changes need to be related to adjoining urban land use and to the overlapping requirements of individual native and exotic species.",
            "contribution_ids": [
                "R54639"
            ]
        },
        {
            "instance_id": "R54867xR54642",
            "comparison_id": "R54867",
            "paper_id": "R54642",
            "text": "Re-colonisation rate differs between co-existing indigenous and invasive intertidal mussels following major disturbance the potential of introduced species to become invasive is often linked to their ability to colonise disturbed habitats rapidly. we studied the effects of major disturbance by severe storms on the indigenous mussel perna perna and the invasive mussel mytilus galloprovincialis in sympatric intertidal populations on the south coast of south africa. at the study sites, these species dominate different shore levels and co-exist in the mid mussel zone. we tested the hypotheses that in the mid- zone p. perna would suffer less dislodgment than m. galloprovincialis, because of its greater tenacity, while m. galloprovincialis would respond with a higher re-colonisation rate. we estimated the per- cent cover of the 2 mussels in the mid-zone from photographs, once before severe storms and 3 times afterwards. m. galloprovincialis showed faster re-colonisation and 3 times more cover than p. perna 1 and 1.5 yr after the storms (when populations had recovered). storm-driven dislodgment in the mid- zone was highest for the species that initially dominated at each site, conforming to the concept of compensatory mortality. this resulted in similar cover of the 2 species immediately after the storms. thus, the storm wave forces exceeded the tenacity even of p. perna, while the higher recruitment rate of m. galloprovincialis can explain its greater colonisation ability. we predict that, because of its weaker attachment strength, m. galloprovincialis will be largely excluded from open coast sites where wave action is generally stronger, but that its greater capacity for exploitation competition through re-colonisation will allow it to outcompete p. perna in more sheltered areas (especially in bays) that are periodically disturbed by storms.",
            "contribution_ids": [
                "R54643"
            ]
        },
        {
            "instance_id": "R54867xR54663",
            "comparison_id": "R54867",
            "paper_id": "R54663",
            "text": "Fire and competition in a southern California grassland: impacts on the rare forb Erodium macrophyllum summary 1. the use of off-season burns to control exotic vegetation shows promise for land managers. in california, wildfires tend to occur in the summer and autumn, when most grassland vegetation is dormant. the effects of spring fires on native bunchgrasses have been examined but their impacts on native forbs have received less attention. 2. we introduced erodium macrophyllum, a rare native annual forb, by seeding plots in 10 different areas in a california grassland. we tested the hypotheses that e. macrophyllum would perform better (increased fecundity and germination) when competing with native grasses than with a mixture of exotic and native grasses, and fire would alter subsequent demography of e. macrophyllum and other species\u2019 abundances. we monitored the demography of e. macrophyllum for two seasons in plots manually weeded so that they were free from exotics, and in areas that were burned or not burned the spring after seeding. 3. weeding increased e. macrophyllum seedling emergence, survival and fecundity during both seasons. when vegetation was burned in june 2001 (at the end of the first growing season) to kill exotic grass seeds before they dispersed, all e. macrophyllum plants had finished their life cycle and dispersed seeds, suggesting that burns at this time of year would not directly impact on fecundity. in the growing season after burning (2002), burned plots had less recruitment of e. macrophyllum but more establishment of native grass seedlings, suggesting burning may differentially affect seedling recruitment. 4. at the end of the second growing season (june 2002), burned plots had less cover of exotic and native grasses but more cover of exotic forbs. nevertheless, e. macrophyllum plants in burned plots had greater fecundity than in non-burned plots, suggesting that exotic grasses are more competitive than exotic forbs. 5. a glasshouse study showed that exotic grasses competitively suppress e. macrophyllum to a greater extent than native grasses, indicating that the poor performance of e. macrophyllum in the non-burned plots was due to exotic grass competition. 6. synthesis and applications. this study illustrates that fire can alter the competitive environment in grasslands with differential effects on rare forbs, and that exotic grasses strongly interfere with e. macrophyllum. for land managers, the benefits of prescribed spring burns will probably outweigh the costs of decreased e. macrophyllum establishment. land managers can use spring burns to cause a flush of native grass recruitment and to create an environment that is, although abundant with exotic forbs, ultimately less competitive compared with non-burned areas dominated by exotic grasses.",
            "contribution_ids": [
                "R54664"
            ]
        },
        {
            "instance_id": "R54867xR54675",
            "comparison_id": "R54867",
            "paper_id": "R54675",
            "text": "Land use intensification differentially benefits alien over native predators in agricultural landscape mosaics both anthropogenic habitat disturbance and the breadth of habitat use by alien species have been found to facilitate invasion into novel environments, and these factors have been hypothesized to be important within coccinellid communities specifically. in this study, we address two questions: (1) do alien species benefit more than native species from human\u2010disturbed habitats? (2) are alien species more generalized in their habitat use than natives within the invaded range or can their abundance patterns be explained by specialization on the most common habitats?",
            "contribution_ids": [
                "R54676"
            ]
        },
        {
            "instance_id": "R54867xR54686",
            "comparison_id": "R54867",
            "paper_id": "R54686",
            "text": "Disturbance Facilitates Invasion: The Effects Are Stronger Abroad than at Home disturbance is one of the most important factors promoting exotic invasion. however, if disturbance per se is sufficient to explain exotic success, then \u201cinvasion\u201d abroad should not differ from \u201ccolonization\u201d at home. comparisons of the effects of disturbance on organisms in their native and introduced ranges are crucial to elucidate whether this is the case; however, such comparisons have not been conducted. we investigated the effects of disturbance on the success of eurasian native centaurea solstitialis in two invaded regions, california and argentina, and one native region, turkey, by conducting field experiments consisting of simulating different disturbances and adding locally collected c. solstitialis seeds. we also tested differences among c. solstitialis genotypes in these three regions and the effects of local soil microbes on c. solstitialis performance in greenhouse experiments. disturbance increased c. solstitialis abundance and performance far more in nonnative ranges than in the native range, but c. solstitialis biomass and fecundity were similar among populations from all regions grown under common conditions. eurasian soil microbes suppressed growth of c. solstitialis plants, while californian and argentinean soil biota did not. we suggest that escape from soil pathogens may contribute to the disproportionately powerful effect of disturbance in introduced regions.",
            "contribution_ids": [
                "R54687",
                "R54688"
            ]
        },
        {
            "instance_id": "R54867xR54709",
            "comparison_id": "R54867",
            "paper_id": "R54709",
            "text": "Epifaunal disturbance by periodic low levels of dissolved oxygen: native vs. invasive species response hypoxia is increasing in marine and estuarine systems worldwide, primarily due to anthropogenic causes. periodic hypoxia represents a pulse disturbance, with the potential to restruc- ture estuarine biotic communities. we chose the shallow, epifaunal community in the lower chesa- peake bay, virginia, usa, to test the hypothesis that low dissolved oxygen (do) (<4 mg l -1 ) affects community dynamics by reducing the cover of spatial dominants, creating space both for less domi- nant native species and for invasive species. settling panels were deployed at shallow depths in spring 2000 and 2001 at gloucester point, virginia, and were manipulated every 2 wk from late june to mid-august. manipulation involved exposing epifaunal communities to varying levels of do for up to 24 h followed by redeployment in the york river. exposure to low do affected both species com- position (presence or absence) and the abundance of the organisms present. community dominance shifted away from barnacles as level of hypoxia increased. barnacles were important spatial domi- nants which reduced species diversity when locally abundant. the cover of hydroides dianthus, a native serpulid polychaete, doubled when exposed to periodic hypoxia. increased h. dianthus cover may indicate whether a local region has experienced periodic, local do depletion and thus provide an indicator of poor water-quality conditions. in 2001, the combined cover of the invasive and crypto- genic species in this community, botryllus schlosseri (tunicate), molgula manhattensis (tunicate), ficopomatus enigmaticus (polychaete) and diadumene lineata (anemone), was highest on the plates exposed to moderately low do (2 mg l -1 < do < 4 mg l -1 ). all 4 of these species are now found world- wide and exhibit life histories well adapted for establishment in foreign habitats. low do events may enhance success of invasive species, which further stress marine and estuarine ecosystems.",
            "contribution_ids": [
                "R54710"
            ]
        },
        {
            "instance_id": "R54867xR54711",
            "comparison_id": "R54867",
            "paper_id": "R54711",
            "text": "Dam invaders: impoundments facilitate biological invasions into freshwaters freshwater ecosystems are at the forefront of the global biodiversity crisis, with more declining and extinct species than in terrestrial or marine environments. hydrologic alterations and biological invasions represent two of the greatest threats to freshwater biota, yet the importance of linkages between these drivers of environmental change remains uncertain. here, we quantitatively test the hypothesis that impoundments facilitate the introduction and establishment of aquatic invasive species in lake ecosystems. by combining data on boating activity, water body physicochemistry, and geographical distribution of five nuisance invaders in the laurentian great lakes region, we show that non-indigenous species are 2.4 to 300 times more likely to occur in impoundments than in natural lakes, and that impoundments frequently support multiple invaders. furthermore, comparisons of the contemporary and historical landscapes revealed that impoundments enhance the invasion risk of natural lakes by increasing their...",
            "contribution_ids": [
                "R54712"
            ]
        },
        {
            "instance_id": "R54867xR54725",
            "comparison_id": "R54867",
            "paper_id": "R54725",
            "text": "Fire and grazing impacts on plant diversity and alien plant invasions in the southern Sierra Nevada patterns of native and alien plant diversity in response to disturbance were examined along an elevational gradient in blue oak savanna, chaparral, and coniferous forests. total species richness, alien species richness, and alien cover declined with elevation, at scales from 1 to 1000 m2. we found no support for the hypothesis that community diversity inhibits alien invasion. at the 1-m2 point scale, where we would expect competitive interactions between the largely herbaceous flora to be most intense, alien species richness as well as alien cover increased with increasing native species richness in all communities. this suggests that aliens are limited not by the number of native competitors, but by resources that affect establishment of both natives and aliens. blue oak savannas were heavily dominated by alien species and consistently had more alien than native species at the 1-m2 scale. all of these aliens are annuals, and it is widely thought that they have displaced native bunchgrasses. if true, this...",
            "contribution_ids": [
                "R54726",
                "R54727",
                "R54728"
            ]
        },
        {
            "instance_id": "R54867xR54781",
            "comparison_id": "R54867",
            "paper_id": "R54781",
            "text": "Are invaders disturbance-limited? Conservation of mountain grasslands in Central Argentina abstract extensive areas in the mountain grasslands of central argentina are heavily invaded by alien species from europe. a decrease in biodiversity and a loss of palatable species is also observed. the invasibility of the tall-grass mountain grassland community was investigated in an experiment of factorial design. six alien species which are widely distributed in the region were sown in plots where soil disturbance, above-ground biomass removal by cutting and burning were used as treatments. alien species did not establish in undisturbed plots. all three types of disturbances increased the number and cover of alien species; the effects of soil disturbance and biomass removal was cumulative. cirsium vulgare and oenothera erythrosepala were the most efficient alien colonizers. in conditions where disturbances did not continue the cover of aliens started to decrease in the second year, by the end of the third season, only a few adults were established. consequently, disturbances are needed to maintain alien populations in tall-grass mountain grasslands. burning also increased the species richness of native species. we conclude that an efficient way to control the distribution of alien species is to decrease grazing pressure while burning as a traditional management tool may be continued. nomenclature: cantero & bianco (1986).",
            "contribution_ids": [
                "R54782",
                "R54783"
            ]
        },
        {
            "instance_id": "R54867xR54797",
            "comparison_id": "R54867",
            "paper_id": "R54797",
            "text": "Mammals of the northern Philippines: tolerance for habitat disturbance and resistance to invasive species in an endemic insular fauna aim\\u2002 island faunas, particularly those with high levels of endemism, usually are considered especially susceptible to disruption from habitat disturbance and invasive alien species. we tested this general hypothesis by examining the distribution of small mammals along gradients of anthropogenic habitat disturbance in northern luzon island, an area with a very high level of mammalian endemism.",
            "contribution_ids": [
                "R54798"
            ]
        },
        {
            "instance_id": "R54867xR54799",
            "comparison_id": "R54867",
            "paper_id": "R54799",
            "text": "Relationship between fragmentation, degradation and native and exotic species richness in an Andean temperate forest of Chile impactos humanos tales como la fragmentacion y degradacion de bosques pueden tener fuertes efectos en las comunidades de especies vegetales nativas y exoticas. ademas, perturbaciones antropicas ocurren principalmente en menores altitudes produciendo mayores grados de fragmentacion y degradacion que en mayores altitudes. la invasion de plantas exoticas deberia ser mayor en bosques mas fragmentados o degradados y, por lo tanto, en menores altitudes dentro de un tipo de bosque o piso altitudinal. en cambio, la riqueza de especies nativas deberia ser negativamente afectada por la fragmentacion y degradacion, encontrandose mayor riqueza en mayores altitudes dentro de un tipo de bosque determinado. en este trabajo evaluamos estas hipotesis en un bosque templado andino de la region de la araucania, chile. registramos la composicion de plantas vasculares en doce fragmentos de diferente tamano, razon perimetro/area, altitud y degradacion antropica (cortas, incendios, fecas de ganado). en base a estas variables construimos un indice de fragmentacion y uno de degradacion para estos fragmentos. se analizaron las relaciones entre estas variables a traves de correlaciones de pearson. nuestros resultados sugieren que la fragmentacion y degradacion estan positivamente relacionadas y que ambos tipos de perturbacion ocurren en altitudes mas bajas del tipo de bosque estudiado. ademas, la fragmentacion y degradacion estan afectando en diferente forma a la riqueza de especies nativas y exoticas. la invasion se incremento como consecuencia tanto de fragmentacion como de degradacion, y como consecuencia del patron de distribucion altitudinal de estas perturbaciones, la invasion aparentemente ocurre principalmente en zonas bajas. en cambio, la riqueza de especies nativas fue negativamente afectada solo por la fragmentacion, y no se relaciono con la degradacion interna de los bosques ni con la altitud.",
            "contribution_ids": [
                "R54800"
            ]
        },
        {
            "instance_id": "R54867xR54803",
            "comparison_id": "R54867",
            "paper_id": "R54803",
            "text": "Relationship between productivity, and species and functional group diversity in grazed and non-grazed Pampas grassland most hypotheses addressing the effect of diversity on ecosystem function indicate the occurrence of higher process rates with increasing diversity, and only diverge in the shape of the function depending on their assumptions about the role of individual species and functional groups. contrarily to these predictions, we show that grazing of the flooding pampas grasslands increased species richness, but drastically reduced above ground net primary production, even when communities with similar initial biomass were compared. grazing increased species richness through the addition of a number of exotic forbs, without reducing the richness and cover of the native flora. since these forbs were essentially cool-season species, and also because their introduction has led to the displacement of warm-season grasses from dominant to subordinate positions in the community, grazing not only decreased productivity, but also shifted its seasonality towards the cool season. these results suggest that species diversity and/or richness alone are poor predictors of above-ground primary production. therefore, models that relate productivity to diversity should take into account the relative abundance and identity of species that are added or deleted by the specific disturbances that modify diversity.",
            "contribution_ids": [
                "R54804",
                "R54805"
            ]
        },
        {
            "instance_id": "R54867xR54806",
            "comparison_id": "R54867",
            "paper_id": "R54806",
            "text": "Fire effects on plant diversity in serpentine vs. sandstone chaparral fire contributes to the maintenance of species diversity in many plant com- munities, but few studies have compared its impacts in similar communities that vary in such attributes as soils and productivity. we compared how a wildfire affected plant diversity in chaparral vegetation on serpentine and sandstone soils. we hypothesized that because biomass and cover are lower in serpentine chaparral, space and light are less limiting, and therefore postfire increases in plant species diversity would be lower than in sandstone chaparral. in 40 pairs of burned and unburned 250-m 2 plots, we measured changes in the plant community after a fire for three years. the diversity of native and exotic species increased more in response to fire in sandstone than serpentine chaparral, at both the local (plot) and regional (whole study) scales. in serpentine compared with sandstone chaparral, specialized fire-dependent species were less prevalent, mean fire severity was lower, mean time since last fire was longer, postfire shrub recruitment was lower, and regrowth of biomass was slower. within each chaparral type, the responses of diversity to fire were positively correlated with prefire shrub cover and with a number of measures of soil fertility. fire severity was negatively related to the postfire change in diversity in sandstone chaparral, and unimodally related to the postfire change in diversity in serpentine chaparral. our results suggest that the effects of fire on less productive plant communities like serpentine chaparral may be less pronounced, although longer lasting, than the effects of fire on similar but more productive communities.",
            "contribution_ids": [
                "R54807"
            ]
        },
        {
            "instance_id": "R54867xR54808",
            "comparison_id": "R54867",
            "paper_id": "R54808",
            "text": "Resource availability and invasibility in an intertidal macroalgal assemblage \"the invasibility of a low intertidal macroalgal assemblage was experimentally tested from march 2003 to april 2004 at 1 locality in northern spain. it was hypothesised that a community becomes more susceptible to invasion when there is an increase in the amount of key resources. a bifactorial ('nutrient supply' and 'macroalgal biomass removed') orthogonal experiment was designed with 3 levels in each factor (high, medium and control). fertile plants of sargassum muticum (yendo) fensholt were transplanted to each plot to simulate the arrival of an invader. the invasibility of the assemblage was quantified in the pre- (density of recruits) and post-settlement (percentage cover, size and density of s. muticum at the end of the experiment) phases of s. muticum's life cycle. results supported the initial hypothesis. both space availability and nutrient enrichment facilitated the establishment and spread of s. muticum in the experimental plots. established s. muticum plants grew faster in enriched plots than in controls. furthermore, different successional assemblages played different roles in resisting invasion as s. muticum's life cycle pro- gressed. in the initial stage of the invasion, the bifurcaria bifurcata canopy inhibited recruitment by s. muticum, whereas understory species did not have a significant effect on invasion success. in contrast, an increased survivorship of s. muticum beneath the canopy of b. bifurcata was observed in those plots where s. muticum had successfully recruited. this study shows that the invasibility of this low intertidal assemblage is mediated by a complex interaction of several resources acting at different stages during s. muticum's invasion.\"",
            "contribution_ids": [
                "R54809",
                "R54810",
                "R54811"
            ]
        },
        {
            "instance_id": "R54867xR54817",
            "comparison_id": "R54867",
            "paper_id": "R54817",
            "text": "Recent Invasion of the Symbiont-Bearing Foraminifera Pararotalia into the Eastern Mediterranean Facilitated by the Ongoing Warming Trend the eastern mediterranean is a hotspot of biological invasions. numerous species of indo-pacific origin have colonized the mediterranean in recent times, including tropical symbiont-bearing foraminifera. among these is the species pararotalia calcariformata. unlike other invasive foraminifera, this species was discovered only two decades ago and is restricted to the eastern mediterranean coast. combining ecological, genetic and physiological observations, we attempt to explain the recent invasion of this species in the mediterranean sea. using morphological and genetic data, we confirm the species attribution to p. calcariformata mcculloch 1977 and identify its symbionts as a consortium of diatom species dominated by minutocellus polymorphus. we document photosynthetic activity of its endosymbionts using pulse amplitude modulated fluorometry and test the effects of elevated temperatures on growth rates of asexual offspring. the culturing of asexual offspring for 120 days shows a 30-day period of rapid growth followed by a period of slower growth. a subsequent 48-day temperature sensitivity experiment indicates a similar developmental pathway and high growth rate at 28\u00b0c, whereas an almost complete inhibition of growth was observed at 20\u00b0c and 35\u00b0c. this indicates that the offspring of this species may have lower tolerance to cold temperatures than what would be expected for species native to the mediterranean. we expand this hypothesis by applying a species distribution model (sdm) based on modern occurrences in the mediterranean using three environmental variables: irradiance, turbidity and yearly minimum temperature. the model reproduces the observed restricted distribution and indicates that the range of the species will drastically expand westwards under future global change scenarios. we conclude that p. calcariformata established a population in the levant because of the recent warming in the region. in line with observations from other groups of organisms, our results indicate that continued warming of the eastern mediterranean will facilitate the invasion of more tropical marine taxa into the mediterranean, disturbing local biodiversity and ecosystem structure.",
            "contribution_ids": [
                "R54818"
            ]
        },
        {
            "instance_id": "R54867xR54824",
            "comparison_id": "R54867",
            "paper_id": "R54824",
            "text": "Pre-fire fuel reduction treatments influence plant communities and exotic species 9 years after a large wildfire questions: how did post-wildfire understorey plant community response, including exotic species response, differ between pre-fire treated areas that were less severely burned, and pre-fire untreated areas that were more severely burned? were these differences consistent through time? location: east-central arizona, southwestern us. methods: we used a multi-year data set from the 2002 rodeo\u2013chediski fire to detect post-fire trends in plant community response in burned ponderosa pine forests. within the burn perimeter, we examined the effects of pre-fire fuels treatments on post-fire vegetation by comparing paired treated and untreated sites on the apache-sitgreaves national forest. we sampled these paired sites in 2004, 2005 and 2011. results: there were significant differences in pre-fire treated and untreated plant communities by species composition and abundance in 2004 and 2005, but these communities were beginning to converge in 2011. total understorey plant cover was significantly higher in untreated areas for all 3 yr. plant cover generally increased between 2004 and 2005 and markedly decreased in 2011, with the exception of shrub cover, which steadily increased through time. the sharp decrease in forb and graminoid cover in 2011 is likely related to drought conditions since the fire. annual/biennial forb and graminoid cover decreased relative to perennial cover through time, consistent with the initial floristics hypothesis. exotic plant response was highly variable and not limited to the immediate post-fire, annual/biennial community. despite low overall exotic forb and graminoid cover for all years (<2.5%), several exotic species increased in frequency, and the relative proportion of exotic to native cover increased through time. conclusions: pre-treatment fuel reduction treatments helped maintain foundation overstorey species and associated native plant communities following this large wildfire. the overall low cover of exotic species on these sites supports other findings that the disturbance associated with high-severity fire does not always result in exotic species invasions. the increase in relative cover and frequency though time indicates that some species are proliferating, and continued monitoring is recommended. patterns of exotic species invasions after severe burning are not easily predicted, and are likely more dependent on site-specific factors such as propagules, weather patterns and management.",
            "contribution_ids": [
                "R54825"
            ]
        },
        {
            "instance_id": "R54867xR54839",
            "comparison_id": "R54867",
            "paper_id": "R54839",
            "text": "Altered stream-flow regimes and invasive plant species: the Tamarix case aim to test the hypothesis that anthropogenic alteration of stream-flow regimes is a key driver of compositional shifts from native to introduced riparian plant species. location the arid south-western united states; 24 river reaches in the gila and lower colorado drainage basins of arizona. methods we compared the abundance of three dominant woody riparian taxa (native populus fremontii and salix gooddingii , and introduced tamarix ) between river reaches that varied in stream-flow permanence (perennial vs. intermittent), presence or absence of an upstream flow-regulating dam, and presence or absence of municipal effluent as a stream water source. results populus and salix were the dominant pioneer trees along the reaches with perennial flow and a natural flood regime. in contrast, tamarix had high abundance (patch area and basal area) along reaches with intermittent stream flows (caused by natural and cultural factors), as well as those with dam-regulated flows. main conclusions stream-flow regimes are strong determinants of riparian vegetation structure, and hydrological alterations can drive dominance shifts to introduced species that have an adaptive suite of traits. deep alluvial groundwater on intermittent rivers favours the deep-rooted, stress-adapted tamarix over the shallower-rooted and more competitive populus and salix . on flow-regulated rivers, shifts in flood timing favour the reproductively opportunistic tamarix over populus and salix , both of which have narrow germination windows . the prevailing hydrological conditions thus favour a new dominant pioneer species in the riparian corridors of the american southwest. these results reaffirm the importance of reinstating stream-flow regimes (inclusive of groundwater flows) for re-establishing the native pioneer trees as the dominant forest type.",
            "contribution_ids": [
                "R54840"
            ]
        },
        {
            "instance_id": "R54867xR54841",
            "comparison_id": "R54867",
            "paper_id": "R54841",
            "text": "Lack of native species recovery following severe exotic disturbance in southern Californian shrublands summary \\n \\n1.\\u2002urban and agricultural activities are not part of natural disturbance regimes and may bear little resemblance to them. such disturbances are common in densely populated semi-arid shrub communities of the south-western us, yet successional studies in these regions have been limited primarily to natural successional change and the impact of human-induced changes on natural disturbance regimes. although these communities are resilient to recurrent and large-scale disturbance by fire, they are not necessarily well-adapted to recover from exotic disturbances. \\n \\n \\n \\n2.\\u2002this study investigated the effects of severe exotic disturbance (construction, heavy-vehicle activity, landfill operations, soil excavation and tillage) on shrub communities in southern california. these disturbances led to the conversion of indigenous shrublands to exotic annual communities with low native species richness. \\n \\n \\n \\n3.\\u2002nearly 60% of the cover on disturbed sites consisted of exotic annual species, while undisturbed sites were primarily covered by native shrub species (68%). annual species dominant on disturbed sites included erodium botrys, hypochaeris glabra, bromus spp., vulpia myuros and avena spp. \\n \\n \\n \\n4.\\u2002the cover of native species remained low on disturbed sites even 71\\xa0years after initial exotic disturbance ceased. native shrub seedlings were also very infrequent on disturbed sites, despite the presence of nearby seed sources. only two native shrubs, eriogonum fasciculatum and baccharis sarothroides, colonized some disturbed sites in large numbers. \\n \\n \\n \\n5.\\u2002although some disturbed sites had lower total soil nitrogen and percentage organic matter and higher ph than undisturbed sites, soil variables measured in this study were not sufficient to explain variations in species abundances on these sites. \\n \\n \\n \\n6.\\u2002non-native annual communities observed in this study did not recover to a predisturbed state within typical successional time (<\\xa025\\xa0years), supporting the hypothesis that altered stable states can occur if a community is pushed beyond its threshold of resilience.",
            "contribution_ids": [
                "R54842",
                "R54843"
            ]
        },
        {
            "instance_id": "R54867xR54859",
            "comparison_id": "R54867",
            "paper_id": "R54859",
            "text": "Feral sheep on Socorro Island: facilitators of alien plant colonization and ecosystem decay the paper examines the role of feral sheep (ovis aries) in facilitating the naturalization of alien plants and degrading a formerly robust and stable ecosystem of socorro, an isolated oceanic island in the mexican pacific ocean. approximately half of the island is still sheep\u2010free. the other half has been widely overgrazed and transformed into savannah and prairie\u2010like open habitats that exhibit sheet and gully erosion and are covered by a mix of native and alien invasive vegetation today. vegetation transects in this moderately sheep\u2010impacted sector show that a significant number of native and endemic herb and shrub species exhibit sympatric distribution patterns with introduced plants. only one alien plant species has been recorded from any undisturbed and sheep\u2010free island sector so far.",
            "contribution_ids": [
                "R54860"
            ]
        },
        {
            "instance_id": "R55219xR54958",
            "comparison_id": "R55219",
            "paper_id": "R54958",
            "text": "Quarantine arthropod invasions in Europe: the role of climate, hosts and propagule pressure to quantify the relative importance of propagule pressure, climate\u2010matching and host availability for the invasion of agricultural pest arthropods in europe and to forecast newly emerging pest species and european areas with the highest risk of arthropod invasion under current climate and a future climate scenario (a1f1).",
            "contribution_ids": [
                "R54959"
            ]
        },
        {
            "instance_id": "R55219xR54977",
            "comparison_id": "R55219",
            "paper_id": "R54977",
            "text": "Introduction history and species characteristics partly explain naturalization success of North American woody species in Europe 1 the search for general characteristics of invasive species has not been very successful yet. a reason for this could be that current invasion patterns are mainly reflecting the introduction history (i.e. time since introduction and propagule pressure) of the species. accurate data on the introduction history are, however, rare, particularly for introduced alien species that have not established. as a consequence, few studies that tested for the effects of species characteristics on invasiveness corrected for introduction history. 2 we tested whether the naturalization success of 582 north american woody species in europe, measured as the proportion of european geographic regions in which each species is established, can be explained by their introduction history. for 278 of these species we had data on characteristics related to growth form, life cycle, growth, fecundity and environmental tolerance. we tested whether naturalization success can be further explained by these characteristics. in addition, we tested whether the effects of species characteristics differ between growth forms. 3 both planting frequency in european gardens and time since introduction significantly increased naturalization success, but the effect of the latter was relatively weak. after correction for introduction history and taxonomy, six of the 26 species characteristics had significant effects on naturalization success. leaf retention and precipitation tolerance increased naturalization success. tree species were only 56% as likely to naturalize as non\u2010tree species (vines, shrubs and subshrubs), and the effect of planting frequency on naturalization success was much stronger for non\u2010trees than for trees. on the other hand, the naturalization success of trees, but not for non\u2010trees, increased with native range size, maximum plant height and seed spread rate. 4 synthesis. our results suggest that introduction history, particularly planting frequency, is an important determinant of current naturalization success of north american woody species (particularly of non\u2010trees) in europe. therefore, studies comparing naturalization success among species should correct for introduction history. species characteristics are also significant determinants of naturalization success, but their effects may differ between growth forms.",
            "contribution_ids": [
                "R54978"
            ]
        },
        {
            "instance_id": "R55219xR54981",
            "comparison_id": "R55219",
            "paper_id": "R54981",
            "text": "Dealing with scarce data to understand how environmental gradients and propagule pressure shape fine-scale alien distribution patterns on coastal dunes questions: on sandy coastal habitats, factors related to substrate and to wind action vary along the sea\u2013inland ecotone, forming a marked directional disturbance and stress gradient. further, input of propagules of alien plant species associated to touristic exploitation and development is intense. this has contributed to establishment and spread of aliens in coastal systems. records of alien species in databases of such heterogeneous landscapes remain scarce, posing a challenge for statistical modelling. we address this issue and attempt to shed light on the role of environmental stress/disturbance gradients and propagule pressure on invasibility of plant communities in these typical model systems. \\n \\nlocation: sandy coasts of lazio (central italy). \\n \\nmethods: we proposed an innovative methodology to deal with low prevalence of alien occurrence in a data set and high cost of field-based sampling by taking advantage, through predictive modelling, of the strong interrelation between vegetation and abiotic features in coastal dunes. we fitted generalized additive models to analyse (1) overall patterns of alien occurrence and spread and (2) specific patterns of the most common alien species recorded. \\n \\nconclusion: even in the presence of strong propagule pressure, variation in local abiotic conditions can explain differences in invasibility within a local environment, and intermediate levels of natural disturbance and stress offer the best conditions for spread of alien species. however, in our model system, propagule pressure is actually the main determinant of alien species occurrence and spread. we demonstrated that extending the information of environmental features measured in a subsample of vegetation plots through predictive modelling allows complex questions in invasion biology to be addressed without requiring disproportionate funding and sampling effort.",
            "contribution_ids": [
                "R54982",
                "R54983"
            ]
        },
        {
            "instance_id": "R55219xR55000",
            "comparison_id": "R55219",
            "paper_id": "R55000",
            "text": "Movement, colonization, and establishment success of a planthopper of prairie potholes, Delphacodes scolochloa (Hemiptera: Delphacidae) abstract 1.\\u2002movement, and particularly the colonisation of new habitat patches, remains one of the least known aspects of the life history and ecology of the vast majority of species. here, a series of experiments was conducted to rectify this problem with delphacodes scolochloa cronin & wilson, a wing\u2010dimorphic planthopper of the north american great plains.",
            "contribution_ids": [
                "R55001"
            ]
        },
        {
            "instance_id": "R55219xR55046",
            "comparison_id": "R55219",
            "paper_id": "R55046",
            "text": "Role of Propagule Size in the Success of Incipient Colonies of the Invasive Argentine Ant abstract: factors that contribute to the successful establishment of invasive species are often poorly understood. propagule size is considered a key determinant of establishment success, but experimental tests of its importance are rare. we used experimental colonies of the invasive argentine ant (\\u2003\\u2003linepithema humile) that differed both in worker and queen number to test how these attributes influence the survivorship and growth of incipient colonies. all propagules without workers experienced queen mortality, in contrast to only 6% of propagules with workers. in small propagules (10\u20131,000 workers), brood production increased with worker number but not queen number. in contrast, per capita measures of colony growth decreased with worker number over these colony sizes. in larger propagules (\\u20031,000\u201311,000 workers), brood production also increased with increasing worker number, but per capita brood production appeared independent of colony size. our results suggest that queens need workers to establish successfully but that propagules with as few as 10 workers can grow quickly. given the requirements for propagule success in argentine ants, it is not surprising how easily they spread via human commerce.",
            "contribution_ids": [
                "R55047"
            ]
        },
        {
            "instance_id": "R55219xR55057",
            "comparison_id": "R55219",
            "paper_id": "R55057",
            "text": "Role of propagule pressure in colonization success: disentangling the relative importance of demographic, genetic and habitat effects high propagule pressure is arguably the only consistent predictor of colonization success. more individuals enhance colonization success because they aid in overcoming demographic consequences of small population size (e.g. stochasticity and allee effects). the number of founders can also have direct genetic effects: with fewer individuals, more inbreeding and thus inbreeding depression will occur, whereas more individuals typically harbour greater genetic variation. thus, the demographic and genetic components of propagule pressure are interrelated, making it difficult to understand which mechanisms are most important in determining colonization success. we experimentally disentangled the demographic and genetic components of propagule pressure by manipulating the number of founders (fewer or more), and genetic background (inbred or outbred) of individuals released in a series of three complementary experiments. we used bemisia whiteflies and released them onto either their natal host (benign) or a novel host (challenging). our experiments revealed that having more founding individuals and those individuals being outbred both increased the number of adults produced, but that only genetic background consistently shaped net reproductive rate of experimental populations. environment was also important and interacted with propagule size to determine the number of adults produced. quality of the environment interacted also with genetic background to determine establishment success, with a more pronounced effect of inbreeding depression in harsh environments. this interaction did not hold for the net reproductive rate. these data show that the positive effect of propagule pressure on founding success can be driven as much by underlying genetic processes as by demographics. genetic effects can be immediate and have sizable effects on fitness.",
            "contribution_ids": [
                "R55058"
            ]
        },
        {
            "instance_id": "R55219xR55083",
            "comparison_id": "R55219",
            "paper_id": "R55083",
            "text": "ALIEN FISHES IN CALIFORNIA WATERSHEDS: CHARACTERISTICS OF SUCCESSFUL AND FAILED INVADERS the literature on alien animal invaders focuses largely on successful invasions over broad geographic scales and rarely examines failed invasions. as a result, it is difficult to make predictions about which species are likely to become successful invaders or which environments are likely to be most susceptible to invasion. to address these issues, we developed a data set on fish invasions in watersheds throughout california (usa) that includes failed introductions. our data set includes information from three stages of the invasion process (establishment, spread, and integration). we define seven categorical predictor variables (trophic status, size of native range, parental care, maximum adult size, physiological tolerance, distance from nearest native source, and propagule pressure) and one continuous predictor variable (prior invasion success) for all introduced species. using an information-theoretic approach we evaluate 45 separate hypotheses derived from the invasion literature over these three sta...",
            "contribution_ids": [
                "R55084"
            ]
        },
        {
            "instance_id": "R55219xR55088",
            "comparison_id": "R55219",
            "paper_id": "R55088",
            "text": "Effects of soil fungi, disturbance and propagule pressure on exotic plant recruitment and establishment at home and abroad \"biogeographic experiments that test how multiple interacting factors influence exotic plant abundance in their home and recipient communities are remarkably rare. we examined the effects of soil fungi, disturbance and propagule pressure on seed germination, seedling recruitment and adult plant establishment of the invasive centaurea stoebe in its native european and non\u2010native north american ranges. centaurea stoebe can establish virtual monocultures in parts of its non\u2010native range, but occurs at far lower abundances where it is native. we conducted parallel experiments at four european and four montana (usa) grassland sites with all factorial combinations of \u00b1 suppression of soil fungi, \u00b1disturbance and low versus high knapweed propagule pressure [100 or 300 knapweed seeds per 0.3 m \u00d7 0.3 m plot (1000 or 3000 per m2)]. we also measured germination in buried bags containing locally collected knapweed seeds that were either treated or not with fungicide. disturbance and propagule pressure increased knapweed recruitment and establishment, but did so similarly in both ranges. treating plots with fungicides had no effect on recruitment or establishment in either range. however, we found: (i) greater seedling recruitment and plant establishment in undisturbed plots in montana compared to undisturbed plots in europe and (ii) substantially greater germination of seeds in bags buried in montana compared to europe. also, across all treatments, total plant establishment was greater in montana than in europe. synthesis. our results highlight the importance of simultaneously examining processes that could influence invasion in both ranges. they indicate that under \u2018background\u2019 undisturbed conditions, knapweed recruits and establishes at greater abundance in montana than in europe. however, our results do not support the importance of soil fungi or local disturbances as mechanisms for knapweed's differential success in north america versus europe.\"",
            "contribution_ids": [
                "R55089"
            ]
        },
        {
            "instance_id": "R55219xR55095",
            "comparison_id": "R55219",
            "paper_id": "R55095",
            "text": "The effect of propagule size on the invasion of an alien insect \"1. the movement of species from their native ranges to alien environments is a serious threat to biological diversity. the number of individuals involved in an invasion provides a strong theoretical basis for determining the likelihood of establishment of an alien species. 2. here a field experiment was used to manipulate the critical first stages of the invasion of an alien insect, a psyllid weed biocontrol agent, arytainilla spartiophila forster, in new zealand and to observe the progress of the invasion over the following 6 years. 3. fifty-five releases were made along a linear transect 135 km long: 10 releases of two, four, 10, 30 and 90 psyllids and five releases of 270 psyllids. six years after their original release, psyllids were present in 22 of the 55 release sites. analysis by logistic regression showed that the probability of establishment was significantly and positively related to initial release size, but that this effect was important only during the psyllids' first year in the field. 4. although less likely to establish, some of the releases of two and four psyllids did survive 5 years in the field. overall, releases that survived their first year had a 96% chance of surviving thereafter, providing the release site remained secure. the probability of colony loss due to site destruction remained the same throughout the experiment, whereas the probability of natural extinction reduced steeply over time. 5. during the first year colonies were undergoing a process of establishment and, in most cases, population size decreased. after this first year, a period of exponential growth ensued. 6. a lag period was observed before the populations increased dramatically in size. this was thought to be due to inherent lags caused by the nature of population growth, which causes the smaller releases to appear to have a longer lag period.\"",
            "contribution_ids": [
                "R55096"
            ]
        },
        {
            "instance_id": "R55219xR55097",
            "comparison_id": "R55219",
            "paper_id": "R55097",
            "text": "Effect of propagule pressure on the establishment and spread of the little fire ant Wasmannia auropunctata in a Gabonese oilfield we studied the effect of propagule pressure on the establishment and subsequent spread of the invasive little fire ant wasmannia auropunctata in a gabonese oilfield in lowland rain forest. oil well drilling, the major anthropogenic disturbance over the past 21 years in the area, was used as an indirect measure of propagule pressure. an analysis of 82 potential introductions at oil production platforms revealed that the probability of successful establishment significantly increased with the number of drilling events. specifically, the shape of the dose\u2013response establishment curve could be closely approximated by a poisson process with a 34% chance of infestation per well drilled. consistent with our knowledge of largely clonal reproduction by w. auropunctata, the shape of the establishment curve suggested that the ants were not substantially affected by allee effects, probably greatly contributing to this species\u2019 success as an invader. by contrast, the extent to which w. auropunctata spread beyond the point of initial introduction, and thus the extent of its damage to diversity of other ant species, was independent of propagule pressure. these results suggest that while establishment success depends on propagule pressure, other ecological or genetic factors may limit the extent of further spread. knowledge of the shape of the dose\u2013response establishment curve should prove useful in modelling the future spread of w. auropunctata and perhaps the spread of other clonal organisms.",
            "contribution_ids": [
                "R55098"
            ]
        },
        {
            "instance_id": "R55219xR55127",
            "comparison_id": "R55219",
            "paper_id": "R55127",
            "text": "Propagule pressure and climate contribute to the displacement of Linepithema humile by Pachycondyla chinensis identifying mechanisms governing the establishment and spread of invasive species is a fundamental challenge in invasion biology. because species invasions are frequently observed only after the species presents an environmental threat, research identifying the contributing agents to dispersal and subsequent spread are confined to retrograde observations. here, we use a combination of seasonal surveys and experimental approaches to test the relative importance of behavioral and abiotic factors in determining the local co-occurrence of two invasive ant species, the established argentine ant (linepithema humile mayr) and the newly invasive asian needle ant (pachycondyla chinensis emery). we show that the broader climatic envelope of p. chinensis enables it to establish earlier in the year than l. humile. we also demonstrate that increased p. chinensis propagule pressure during periods of l. humile scarcity contributes to successful p. chinensis early season establishment. furthermore, we show that, although l. humile is the numerically superior and behaviorally dominant species at baits, p. chinensis is currently displacing l. humile across the invaded landscape. by identifying the features promoting the displacement of one invasive ant by another we can better understand both early determinants in the invasion process and factors limiting colony expansion and survival.",
            "contribution_ids": [
                "R55128",
                "R56365",
                "R56780"
            ]
        },
        {
            "instance_id": "R55219xR55139",
            "comparison_id": "R55219",
            "paper_id": "R55139",
            "text": "Habitat, dispersal and propagule pressure control exotic plant infilling within an invaded range \"deep in the heart of a longstanding invasion, an exotic grass is still invading. range infilling potentially has the greatest impact on native communities and ecosystem processes, but receives much less attention than range expansion. \u2018snapshot' studies of invasive plant dispersal, habitat and propagule limitations cannot determine whether a landscape is saturated or whether a species is actively infilling empty patches. we investigate the mechanisms underlying invasive plant infilling by tracking the localized movement and expansion of microstegium vimineum populations from 2009 to 2011 at sites along a 100-km regional gradient in eastern u.s. deciduous forests. we find that infilling proceeds most rapidly where the invasive plants occur in warm, moist habitats adjacent to roads: under these conditions they produce copious seed, the dispersal distances of which increase exponentially with proximity to roadway. invasion then appears limited where conditions are generally dry and cool as propagule pressure tapers off. invasion also is limited in habitats >1 m from road corridors, where dispersal distances decline precipitously. in contrast to propagule and dispersal limitations, we find little evidence that infilling is habitat limited, meaning that as long as m. vimineum seeds are available and transported, the plant generally invades quite vigorously. our results suggest an invasive species continues to spread, in a stratified manner, within the invaded landscape long after first arriving. these dynamics conflict with traditional invasion models that emphasize an invasive edge with distinct boundaries. we find that propagule pressure and dispersal regulate infilling, providing the basis for projecting spread and landscape coverage, ecological effects and the efficacy of containment strategies.\"",
            "contribution_ids": [
                "R55140"
            ]
        },
        {
            "instance_id": "R55219xR55146",
            "comparison_id": "R55219",
            "paper_id": "R55146",
            "text": "Propagule pressure drives establishment of introduced freshwater fish: quantitative evidence from an irrigation network propagule pressure is recognized as a fundamental driver of freshwater fish invasions, though few studies have quantified its role. natural experiments can be used to quantify the role of this factor relative to others in driving establishment success. an irrigation network in south africa takes water from an inter-basin water transfer (ibwt) scheme to supply multiple small irrigation ponds. we compared fish community composition upstream, within, and downstream of the irrigation network, to show that this system is a unidirectional dispersal network with a single immigration source. we then assessed the effect of propagule pressure and biological adaptation on the colonization success of nine fish species across 30 recipient ponds of varying age. establishing species received significantly more propagules at the source than did incidental species, while rates of establishment across the ponds displayed a saturation response to propagule pressure. this shows that propagule pressure is a significant driver of establishment overall. those species that did not establish were either extremely rare at the immigration source or lacked the reproductive adaptations to breed in the ponds. the ability of all nine species to arrive at some of the ponds illustrates how long-term continuous propagule pressure from ibwt infrastructure enables range expansion of fishes. the quantitative link between propagule pressure and success and rate of population establishment confirms the driving role of this factor in fish invasion ecology.",
            "contribution_ids": [
                "R55147"
            ]
        },
        {
            "instance_id": "R55219xR55150",
            "comparison_id": "R55219",
            "paper_id": "R55150",
            "text": "Propagule pressure and colony social organization are associated with the successful invasion and rapid range expansion of fire ants in China we characterized patterns of genetic variation in populations of the fire ant solenopsis invicta in china using mitochondrial dna sequences and nuclear microsatellite loci to test predictions as to how propagule pressure and subsequent dispersal following establishment jointly shape the invasion success of this ant in this recently invaded area. fire ants in wuchuan (guangdong province) are genetically differentiated from those found in other large infested areas of china. the immediate source of ants in wuchuan appears to be somewhere near texas, which ranks first among the southern usa infested states in the exportation of goods to china. most colonies from spatially distant, outlying areas in china are genetically similar to one another and appear to share a common source (wuchuan, guangdong province), suggesting that long\u2010distance jump dispersal has been a prevalent means of recent spread of fire ants in china. furthermore, most colonies at outlier sites are of the polygyne social form (featuring multiple egg\u2010laying queens per nest), reinforcing the important role of this social form in the successful invasion of new areas and subsequent range expansion following invasion. several analyses consistently revealed characteristic signatures of genetic bottlenecks for s. invicta populations in china. the results of this study highlight the invasive potential of this pest ant, suggest that the magnitude of international trade may serve as a predictor of propagule pressure and indicate that rates and patterns of subsequent range expansion are partly determined by the interplay between species traits and the trade and transportation networks.",
            "contribution_ids": [
                "R55151"
            ]
        },
        {
            "instance_id": "R56945xR56541",
            "comparison_id": "R56945",
            "paper_id": "R56541",
            "text": "Seed and seedling demography of invasive and native trees of subtropical Pacific islands abstract bischofia javanica is an invasive tree of the bonin islands in the western pacific, japan. this species has aggressive growth, competitively replacing native trees in the natural forest of the islands. the aim of this study was to examine seed and seedling factors which might confer an advantage to the establishment of bischofia over native trees. during a 5-yr period we compared the demographic parameters of early life history of bischofia and elaeocarpus photiniaefolius, a native canopy dominant, in actively invaded forests. predation of elaeocarpus seeds by in troduced rodents was much higher before (27.9\u201332.9%) and after (41.3\u2013100%) dispersal of seeds than that of b. javanica. most elaeocarpus seeds lost viability ca. 6 mo after burial in forest soil while some seeds of bischofia remained viable for more than 2 yr. seedling survival in the first 2 yr was much higher in bischofia (16%) than in elaeocarpus (1.3%). the high persistence of bischofia in the shade, coupled to its rapid acclimation to high light levels, is an unusual combination because in forest tree species there is generally a trade-off between seedling survival in the shade and response to canopy opening. compared with a native canopy dominant, greater seed longevity, lower seed predation by introduced rodents, longer fruiting periods and the ability to form seedling banks under closed canopy appear to have contributed to the invasive success of bischofia on the bonin islands. nomenclature: satake et al. (1989).",
            "contribution_ids": [
                "R56542"
            ]
        },
        {
            "instance_id": "R56945xR56547",
            "comparison_id": "R56945",
            "paper_id": "R56547",
            "text": "Invasional 'meltdown' on an oceanic island islands can serve as model systems for understanding how biological invasions affect community structure and ecosystem function. here we show invasion by the alien crazy ant anoplolepis gracilipes causes a rapid, catastrophic shift in the rain forest ecosystem of a tropical oceanic island, affecting at least three trophic levels. in invaded areas, crazy ants extirpate the red land crab, the dominant endemic consumer on the forest floor. in doing so, crazy ants indirectly release seedling recruitment, enhance species richness of seedlings, and slow litter breakdown. in the forest canopy, new associations between this invasive ant and honeydew-secreting scale insects accelerate and diversify impacts. sustained high densities of foraging ants on canopy trees result in high population densities of hostgeneralist scale insects and growth of sooty moulds, leading to canopy dieback and even deaths of canopy trees. the indirect fallout from the displacement of a native keystone species by an ant invader, itself abetted by introduced/cryptogenic mutualists, produces synergism in impacts to precipitate invasional meltdown in this system.",
            "contribution_ids": [
                "R56548"
            ]
        },
        {
            "instance_id": "R56945xR56567",
            "comparison_id": "R56945",
            "paper_id": "R56567",
            "text": "Positive effects of a dominant invader on introduced and native mudflat species \"many introduced species have negative impacts on native species, but some develop positive interactions with both native species and other invaders. facilitation between invaders may lead to an overall acceleration in invasion success and impacts. mechanisms of facilitation include habitat alteration, or ecosystem engineering, and trophic interactions. in marine systems, only a handful of positive effects have been reported for invading species. in an unusual ne pacific marine assemblage dominated by 5 conspicuous invaders and 2 native species, we identified positive effects of the most abundant invader, the asian hornsnail batillaria attramentaria, on all other species. b. attramentaria reached densities >1400 m -2 , providing an average of 600 cm of hard substrate per m 2 on this mudflat. its shells were used as habitat almost exclusively by the introduced atlantic slipper shell crepidula convexa, the introduced asian anemone diadumene lineata, and 2 native hermit crabs pagurus hirsutiusculus and p. granosimanus. in addition, manipulative experiments showed that the abundance of the mudsnail nassarius fraterculus and percentage cover of the eelgrass zostera japonica, both introduced from the nw pacific, increased significantly in the presence of b. attramentaria. the most likely mechanisms for these facilitations are indirect grazing effects and bioturbation, respectively. since the precise arrival dates of all these invaders are unknown, the role of b. attramentaria's positive interactions in their initial invasion success is unknown. nevertheless, by providing habitat for 2 non-native epibionts and 2 native species, and by facilitating 2 other invaders, the non-native b. attramentaria enhances the level of invasion by all 6 species.\"",
            "contribution_ids": [
                "R56568"
            ]
        },
        {
            "instance_id": "R56945xR56573",
            "comparison_id": "R56945",
            "paper_id": "R56573",
            "text": "Effects of Acer platanoides invasion on understory plant communities and tree regeneration in the northern Rocky Mountains quantitative studies are necessary to determine whether invasive plant species displace natives and reduce local biodiversity, or if they increase local biodiversity. here we describe the effects of invasion by norway maple acer platanoides on riparian plant communities and tree regeneration at two different scales (individual tree vs stand scales) in western montana, usa, using both descriptive and experimental approaches. the three stands differed in community composition with the stand most dominated by a. platanoides invasion being more compositionally homogenous, and less species rich (-67%), species even (-40%), and diverse ( -75%) than the two other stands. this sharp decrease in community richness and diversity of the highly invaded stand, relative to the other stands, corresponded with a 28-fold increase in a. platanoides seedlings and saplings. the dramatic difference between stand 1 vs 2 and 3 suggests that a. platanoides invasion is associated with a dramatic change in community composition and local loss of species diversity; however, other unaccounted for differences between stands may be the cause. these whole-stand correlations were corroborated by community patterns under individual a. platanoides trees in a stand with intermediate levels of patchy invasion. at the scale of individual a. platanoides canopies within a matrix of native trees, diversity and richness of species beneath solitary a. platanoides trees declined as the size of the trees increased. these decreases in native community properties corresponded with an increase in the density of a. platanoides seedlings. the effect of a. platanoides at the stand scale was more dramatic than at the individual canopy scale; however, at this smaller scale we only collected data from the stand with intermediate levels of invasion and not from the stand with high levels of invasion. transplant experiments with tree seedlings demonstrated that a. platanoides seedlings performed better when grown beneath conspecific canopies than under natives, but populus and pinus seedlings performed better when grown beneath populus canopies, the dominant native. our results indicate that a. platanoides trees suppress most native species, including the regeneration of the natural canopy dominants, but facilitate conspecifics in their understories.",
            "contribution_ids": [
                "R56574"
            ]
        },
        {
            "instance_id": "R56945xR56616",
            "comparison_id": "R56945",
            "paper_id": "R56616",
            "text": "Non-native habitat as home for non-native species: comparison of communities associated with invasive tubeworm and native oyster reefs \"introduction vectors for marine non-native species, such as oyster culture and boat foul- ing, often select for organisms dependent on hard substrates during some or all life stages. in soft- sediment estuaries, hard substrate is a limited resource, which can increase with the introduction of hard habitat-creating non-native species. positive interactions between non-native, habitat-creating species and non-native species utilizing such habitats could be a mechanism for enhanced invasion success. most previous studies on aquatic invasive habitat-creating species have demonstrated posi- tive responses in associated communities, but few have directly addressed responses of other non- native species. we explored the association of native and non-native species with invasive habitat- creating species by comparing communities associated with non-native, reef-building tubeworms ficopomatus enigmaticus and native oysters ostrea conchaphila in elkhorn slough, a central califor- nia estuary. non-native habitat supported greater densities of associated organisms\u2014primarily highly abundant non-native amphipods (e.g. monocorophium insidiosum, melita nitida), tanaid (sinelebus sp.), and tube-dwelling polychaetes (polydora spp.). detritivores were the most common trophic group, making up disproportionately more of the community associated with f. enigmaticus than was the case in the o. conchaphila community. analysis of similarity (anosim) showed that native species' community structure varied significantly among sites, but not between biogenic habi- tats. in contrast, non-natives varied with biogenic habitat type, but not with site. thus, reefs of the invasive tubeworm f. enigmaticus interact positively with other non-native species.\"",
            "contribution_ids": [
                "R56617"
            ]
        },
        {
            "instance_id": "R56945xR56626",
            "comparison_id": "R56945",
            "paper_id": "R56626",
            "text": "Enemy release or invasional meltdown? Deer preference for exotic and native trees on Isla Victoria, Argentina \"how interactions between exotic species affect invasion impact is a fundamental issue on both theoretical and applied grounds. exotics can facilitate establishment and invasion of other exotics (invasional meltdown) or they can restrict them by re-establishing natural population control (as predicted by the enemy- release hypothesis). we studied forest invasion on an argentinean island where 43 species of pinaceae, including 60% of the world's recorded invasive pinaceae, were introduced c. 1920 but where few species are colonizing pristine areas. in this area two species of palearctic deer, natural enemies of most pinaceae, were introduced 80 years ago. expecting deer to help to control the exotics, we conducted a cafeteria experiment to assess deer preferences among the two dominant native species (a conifer, austrocedrus chilensis, and a broadleaf, nothofagus dombeyi) and two widely introduced exotic tree species (pseudotsuga menziesii and pinus ponderosa). deer browsed much more intensively on native species than on exotic conifers, in terms of number of individuals attacked and degree of browsing. deer preference for natives could potentially facilitate invasion by exotic pines. however, we hypothesize that the low rates of invasion currently observed can result at least partly from high densities of exotic deer, which, despite their preference for natives, can prevent establishment of both native and exotic trees. other factors, not mutually exclusive, could produce the observed pattern. our results underscore the difficulty of predicting how one introduced species will effect impact of another one.\"",
            "contribution_ids": [
                "R56627"
            ]
        },
        {
            "instance_id": "R56945xR56678",
            "comparison_id": "R56945",
            "paper_id": "R56678",
            "text": "Effects of introduced Canada geese (Branta canadensis) on native plant communities of the southern gulf islands, British Columbia abstract: \\n recent experiments suggest that introduced, non-migratory canada geese (branta canadensis) may be facilitating the spread of exotic grasses and decline of native plant species abundance on small islets in the georgia basin, british columbia, which otherwise harbour outstanding examples of threatened maritime meadow ecosystems. we examined this idea by testing if the presence of geese predicted the abundance of exotic grasses and native competitors at 2 spatial scales on 39 islands distributed throughout the southern gulf and san juan islands of canada and the united states, respectively. at the plot level, we found significant positive relationships between the percent cover of goose feces and exotic annual grasses. however, this trend was absent at the scale of whole islands. because rapid population expansion of introduced geese in the region only began in the 1980s, our results are consistent with the hypothesis that the deleterious effects of geese on the cover of exotic annual grasses have yet to proceed beyond the local scale, and that a window of opportunity now exists in which to implement management strategies to curtail this emerging threat to native ecosystems. research is now needed to test if the removal of geese results in the decline of exotic annual grasses.",
            "contribution_ids": [
                "R56679"
            ]
        },
        {
            "instance_id": "R56945xR56680",
            "comparison_id": "R56945",
            "paper_id": "R56680",
            "text": "Intra-regional transportation of a tugboat fouling community between the ports of Recife and Natal, northeast Brazil \" this study aimed to identify the incrusting and sedentary animals associated with the hull of a tugboat active in the ports of pernambuco and later loaned to the port of natal, rio grande do norte. thus, areas with dense biofouling were scraped and the species then classified in terms of their bioinvasive status for the brazilian coast. six were native to brazil, two were cryptogenic and 16 nonindigenous; nine of the latter were classified as established (musculus lateralis, sphenia fragilis, balanus trigonus, biflustra savartii, botrylloides nigrum, didemnum psammatodes, herdmania pallida, microscosmus exasperatus, and symplegma rubra) and three as invasive (mytilopsis leucophaeta, amphibalanus reticulatus, and striatobalanus amaryllis). the presence of m. leucophaeata, amphibalanus eburneus and a. reticulatus on the boat's hull propitiated their introduction onto the natal coast. the occurrence of a great number of tunicate species in natal reflected the port area's benthic diversity and facilitated the inclusion of two bivalves - musculus lateralis and sphenia fragilis - found in their siphons and in the interstices between colonies or individuals, respectively. the results show the role of biofouling on boat hulls in the introduction of nonindigenous species and that the port of recife acts as a source of some species. \"",
            "contribution_ids": [
                "R56681"
            ]
        },
        {
            "instance_id": "R56945xR56762",
            "comparison_id": "R56945",
            "paper_id": "R56762",
            "text": "An invasive tree alters the structure of seed dispersal networks between birds and plants in French Polynesia aim\\u2002 we studied how the abundance of the highly invasive fruit\u2010bearing tree miconia calvescens dc. influences seed dispersal networks and the foraging patterns of three avian frugivores.",
            "contribution_ids": [
                "R56763"
            ]
        },
        {
            "instance_id": "R56945xR56847",
            "comparison_id": "R56945",
            "paper_id": "R56847",
            "text": "Cascading ecological effects caused by the establishment of the emerald ash borer Agrilus planipennis (Coleoptera: Buprestidae) in European Russia emerald ash borer, agrilus planipennis, is a destructive invasive forest pest in north america and european russia. this pest species is rapidly spreading in european russia and is likely to arrive in other countries soon. the aim is to analyze the ecological consequences of the establishment of this pest in european russia and investigate (1) what other xylophagous beetles develop on trees affected by a. planipennis, (2) how common is the parasitoid of the emerald ash borer spathius polonicus (hymenoptera: braconidae: doryctinae) and what is the level of parasitism by this species, and (3) how susceptible is the native european ash species fraxinus excelsior to a. planipennis. a survey of approximately 1000 fraxinus pennsylvanica trees damaged by a. planipennis in 13 localities has shown that hylesinus varius (coleoptera: curculionidae: scolytinae), tetrops starkii (coleoptera: cerambycidae) and agrilus convexicollis (coleoptera: buprestidae) were common on these trees. spathius polonicus is frequently recorded. about 50 percent of late instar larvae of a. planipennis sampled were parasitized by s. polonicus. maps of the distributions of t. starkii, a. convexicollis and s. polonicus before and after the establishment of a. planipennis in european russia were compiled. it is hypothesized that these species, which are native to the west palaearctic, spread into central european russia after a. planipennis became established there. current observations confirm those of previous authors that native european ash fraxinus excelsior is susceptible to a. planipennis, increasing the threat posed by this pest. the establishment of a. planipennis has resulted in a cascade of ecological effects, such as outbreaks of other xylophagous beetles in a. planipennis-infested trees. it is likely that the propagation of s. polonicus will reduce the incidence of outbreaks of a. planipennis.",
            "contribution_ids": [
                "R56848"
            ]
        },
        {
            "instance_id": "R56945xR56907",
            "comparison_id": "R56945",
            "paper_id": "R56907",
            "text": "Novel species interactions in a highly modified estuary: association of largemouth bass with Brazilian waterweed Egeria densa abstractfrequent invasions in coastal ecosystems result in novel species interactions that have unknown ecological consequences. largemouth bass micropterus salmoides and brazilian waterweed egeria densa are introduced species in the sacramento\u2013san joaquin river delta (the delta) of california, a highly modified estuary. in this system, brazilian waterweed and largemouth bass have seen marked increases in distribution and abundance in recent decades, but their association has not been specifically studied until now. we conducted a 2-year, bimonthly electrofishing survey with simultaneous sampling of water quality and submerged aquatic vegetation (sav) biomass at 33 locations throughout the delta. we used generalized linear mixed models to assess the relative influences of water temperature, conductivity, secchi depth, and sav biomass density on the abundance of both juvenile-sized and larger largemouth bass. water temperature had a positive relationship with the abundance of both size-classes, but only ju...",
            "contribution_ids": [
                "R56908"
            ]
        },
        {
            "instance_id": "R56945xR56915",
            "comparison_id": "R56945",
            "paper_id": "R56915",
            "text": "Positive plant and bird diversity response to experimental deer population reduction after decades of uncontrolled browsing during the 20th century, deer (family cervidae), both native and introduced populations, dramatically increased in abundance in many parts of the world and became seen as major threats to biodiversity in forest ecosystems. here, we evaluated the consequences that restoring top\u2010down herbivore population control has on plants and birds.",
            "contribution_ids": [
                "R56916"
            ]
        },
        {
            "instance_id": "R56945xR56923",
            "comparison_id": "R56945",
            "paper_id": "R56923",
            "text": "Early life stages of exotic gobiids as new hosts for unionid glochidia summary \\nintroduction of an exotic species has the potential to alter interactions between fish and bivalves; yet our knowledge in this field is limited, not least by lack of studies involving fish early life stages (els). \\nhere, for the first time, we examine glochidial infection of fish els by native and exotic bivalves in a system recently colonised by two exotic gobiid species (round goby neogobius melanostomus, tubenose goby proterorhinus semilunaris) and the exotic chinese pond mussel anodonta woodiana. \\nthe els of native fish were only rarely infected by native glochidia. by contrast, exotic fish displayed significantly higher native glochidia prevalence and mean intensity of infection than native fish (17 versus 2% and 3.3 versus 1.4 respectively), inferring potential for a parasite spillback/dilution effect. exotic fish also displayed a higher parasitic load for exotic glochidia, inferring potential for invasional meltdown. compared to native fish, presence of gobiids increased the total number of glochidia transported downstream on drifting fish by approximately 900%. \\nwe show that gobiid els are a novel, numerous and \u2018attractive\u2019 resource for unionid glochidia. as such, unionids could negatively affect gobiid recruitment through infection-related mortality of gobiid els and/or reinforce downstream unionid populations through transport on drifting gobiid els. these implications go beyond what is suggested in studies of older life stages, thereby stressing the importance of an holistic ontogenetic approach in ecological studies.",
            "contribution_ids": [
                "R56924"
            ]
        },
        {
            "instance_id": "R57101xR56951",
            "comparison_id": "R57101",
            "paper_id": "R56951",
            "text": "The potential impact of the New Zealand flatworm, a predator of earthworms, in western Europe \"the new zealand flatworm arthurdendyus triangulatus (=artioposthia triangulata) is an example of an invasive organism that, by reducing lumbricid earthworm populations, could have a major impact on soil ecosystems in britain and the faroe islands. how it was introduced into the british isles is not known, but like many invasive species, it is suspected that it was introduced by humans and was associated with the trade between new zealand and britain. once established in britain it found in the large, readily available earthworm population a niche that it could exploit. the microclimate of the forests in the center and south of the south island of new zealand from whence the flatworm came is similar to that in parts of the british isles and consequently conducive to its survival. although when compared with many other invertebrate introductions (e.g., insects) the flatworm's rate of increase has been slow, a retrospective study strongly suggested that, in scotland, they spread from botanic gardens to horti...\"",
            "contribution_ids": [
                "R56952"
            ]
        },
        {
            "instance_id": "R57101xR56959",
            "comparison_id": "R57101",
            "paper_id": "R56959",
            "text": "Interception frequency of exotic bark and ambrosia beetles (Coleoptera: Scolytinae) and relationship with establishment in New Zealand and worldwide \" scolytinae species are among the most damaging forest pests, and many of them are invasive. over 1500 scolytinae interceptions were recorded at new zealand's borders between 1950 and 2000. among the 103 species were dendroctonus ponderosae, ips typographus, and other high-risk species, but actual arrivals probably included many more species. interceptions were primarily associated with dunnage, casewood (crating), and sawn timber, and originated from 59 countries, mainly from europe, australasia, northern asia, and north america. new zealand and united states interception data were highly correlated, and 7 of the 10 most intercepted species were shared. interception frequency and establishment in new zealand were not clearly related. by combining new zealand and united states interceptions of true bark beetles we obtained data on species found in shipments from around the world. logistic regression analysis showed that frequently intercepted species were about four times as likely as rarely intercepted species to be established somewhere. interception records of wood and bark borers are valuable for the prediction of invaders and for our general understanding of invasions. the use of alternatives to solid wood packaging, such as processed wood, should be encouraged to reduce the spread of invasive wood and bark borers. \"",
            "contribution_ids": [
                "R56960"
            ]
        },
        {
            "instance_id": "R57101xR56984",
            "comparison_id": "R57101",
            "paper_id": "R56984",
            "text": "Introduction pathways and establishment rates of invasive aquatic species in Europe species invasion is one of the leading mechanisms of global environmental change, particularly in freshwater ecosystems. we used the food and agriculture organization\\'s database of invasive aquatic species to study invasion rates and to analyze invasion pathways within europe. of the 123 aquatic species introduced into six contrasting european countries, the average percentage established is 63%, well above the 5%\\x9620% suggested by williamson\\'s \"tens\" rule. the introduction and establishment transitions are independent of each other, and species that became widely established did so because their introduction was attempted in many countries, not because of a better establishment capability. the most frequently introduced aquatic species in europe are freshwater fishes. we describe clear introduction pathways of aquatic species into europe and three types of country are observed: \"recipient and donor\" (large, midlatitude european countries, such as france, the united kingdom, and germany, that give and receive the most introductions), \"recipient\" (most countries, but particularly southern countries, which give few species but receive many), and \"neither recipient nor donor\" (only two countries). a path analysis showed that the numbers of species given and received are mediated by the size (area) of the country and population density, but not gross domestic product per capita.",
            "contribution_ids": [
                "R56985"
            ]
        },
        {
            "instance_id": "R57101xR56990",
            "comparison_id": "R57101",
            "paper_id": "R56990",
            "text": "Alien aquatic plant species in European countries hussner a (2012). alien aquatic plant species in european countries. weed research52, 297\u2013306. \\n \\nsummary \\nalien aquatic plant species cause serious ecological and economic impacts to european freshwater ecosystems. this study presents a comprehensive overview of all alien aquatic plants in europe, their places of origin and their distribution within the 46 european countries. in total, 96 aquatic species from 30 families have been reported as aliens from at least one european country. most alien aquatic plants are native to northern america, followed by asia and southern america. elodea canadensis is the most widespread alien aquatic plant in europe, reported from 41 european countries. azolla filiculoides ranks second (25), followed by vallisneria spiralis (22) and elodea nuttallii (20). the highest number of alien aquatic plant species has been found in italy and france (34 species), followed by germany (27), belgium and hungary (both 26) and the netherlands (24). even though the number of alien aquatic plants seems relatively small, the european and mediterranean plant protection organization (eppo, http://www.eppo.org) has listed 18 of these species as invasive or potentially invasive within the eppo region. as ornamental trade has been regarded as the major pathway for the introduction of alien aquatic plants, trading bans seem to be the most effective option to reduce the risk of further unintended entry of alien aquatic plants into europe.",
            "contribution_ids": [
                "R56991"
            ]
        },
        {
            "instance_id": "R57101xR57020",
            "comparison_id": "R57101",
            "paper_id": "R57020",
            "text": "Differentiating successful and failed molluscan invaders in estuarine ecosystems abstract: despite mounting evidence of invasive species\u2019 impacts on the environment and society,our ability to predict invasion establishment, spread, and impact are inadequate. efforts to explainand predict invasion outcomes have been limited primarily to terrestrial and freshwater ecosystems.invasions are also common in coastal marine ecosystems, yet to date predictive marine invasion mod-els are absent. here we present a model based on biological attributes associated with invasion suc-cess (establishment) of marine molluscs that compares successful and failed invasions from a groupof 93 species introduced to san francisco bay (sfb) in association with commercial oyster transfersfrom eastern north america (ca. 1869 to 1940). a multiple logistic regression model correctly classi-fied 83% of successful and 80% of failed invaders according to their source region abundance at thetime of oyster transfers, tolerance of low salinity, and developmental mode. we tested the generalityof the sfb invasion model by applying it to 3 coastal locations (2 in north america and 1 in europe)that received oyster transfers from the same source and during the same time as sfb. the model cor-rectly predicted 100, 75, and 86% of successful invaders in these locations, indicating that abun-dance, environmental tolerance (ability to withstand low salinity), and developmental mode not onlyexplain patterns of invasion success in sfb, but more importantly, predict invasion success in geo-graphically disparate marine ecosystems. finally, we demonstrate that the proportion of marine mol-luscs that succeeded in the latter stages of invasion (i.e. that establish self-sustaining populations,spread and become pests) is much greater than has been previously predicted or shown for otheranimals and plants.key words: invasion \u00b7 bivalve \u00b7 gastropod \u00b7 mollusc \u00b7 marine \u00b7 oyster \u00b7 vector \u00b7 risk assessment",
            "contribution_ids": [
                "R57021",
                "R57022",
                "R57023"
            ]
        },
        {
            "instance_id": "R57101xR57028",
            "comparison_id": "R57101",
            "paper_id": "R57028",
            "text": "Accounting for differential success in the biological control of homopteran and lepidopteran pests one of the strongest patterns in the historical record of biological control is that programmes targeted against lepidopteran pests have been far less successful than those targeted against homopteran pests. despite fueling considerable interest in the theory of host-parasitoid interactions, biological control has few unifying principles and no theoretical basis for understanding the differential pattern of success against these two pest groups. potential explanations considered here include competitive limitation of natural enemy establishment, the influence of antagonistic parasitoid interactions, generation time ratio, and gregarious parasitoid development. an analysis of the biological control record showed that on average six natural enemies have been introduced per pest for both pest groups, providing no evidence of a differential intensity of competition. similarly, use of a discrete time host-parasitoid model showed that antagonistic interactions that are common among parasitoids of lepidoptera should not limit the success of biological control as such interactions can readily be counteracted by host refuge breaking. a similar model showed that a small generation time ratio (coupled with a broad window of host attack) and gregarious development can facilitate the suppression of pest abundance by parasitoids, and both were found to be positively associated with success in the biological control record. of the four explanations considered here, generation time ratio coupled with a broad window of host attack appears to provide the best explanation for the differential pattern of success.",
            "contribution_ids": [
                "R57029"
            ]
        },
        {
            "instance_id": "R57101xR57048",
            "comparison_id": "R57101",
            "paper_id": "R57048",
            "text": "Predicting the number of ecologically harmful exotic species in an aquatic system most introduced species apparently have little impact on native biodiversity, but the proliferation of human vectors that transport species worldwide increases the probability of a region being affected by high\u2010impact invaders \u2013 i.e. those that cause severe declines in native species populations. our study determined whether the number of high\u2010impact invaders can be predicted from the total number of invaders in an area, after controlling for species\u2013area effects. these two variables are positively correlated in a set of 16 invaded freshwater and marine systems from around the world. the relationship is a simple linear function; there is no evidence of synergistic or antagonistic effects of invaders across systems. a similar relationship is found for introduced freshwater fishes across 149 regions. in both data sets, high\u2010impact invaders comprise approximately 10% of the total number of invaders. although the mechanism driving this correlation is likely a sampling effect, it is not simply the proportional sampling of a constant number of repeat\u2010offenders; in most cases, an invader is not reported to have strong impacts on native species in the majority of regions it invades. these findings link vector activity and the negative impacts of introduced species on biodiversity, and thus justify management efforts to reduce invasion rates even where numerous invasions have already occurred.",
            "contribution_ids": [
                "R57049",
                "R57050"
            ]
        },
        {
            "instance_id": "R57101xR57057",
            "comparison_id": "R57101",
            "paper_id": "R57057",
            "text": "Predicting the Australian weed status of southern African plants a method of predicting weed status was developed for southern african plants naturalized in australia, based upon information on extra-australian weed status, distribution and taxonomy. weed status in australia was associated with being geographically widespread in southern africa, being found in a wide range of climates in southern africa, being described as a weed or targeted by herbicides in southern africa, with early introduction and establishment in australia, and with weediness in regions other than southern africa. multiple logistic regressions were used to identify the variables that best predicted weed status. the best fitting regressions were for weeds present for a long time in australia (more than 140 years). they utilized three variables, namely weed status, climatic range in southern africa and the existence of congeneric weeds in southern africa. the highest level of variation explained (43%) was obtained for agricultural weeds using a single variable, weed status in southern africa. being recorded as a weed in australia was related to climatic range and the existence of congeneric weeds in southern africa (40% of variation explained). no variables were suitable predictors of non-agricultural (environmental) weeds. the regressions were used to predict future weed status of plants either not introduced or recently arrived in australia. recently-arrived species which were predicted to become weeds are acacia karroo hayne (mimosaceae), arctotis venustra t. norl. (asteraceae), sisymbrium thellungii o.e. schulz (brassicaceae) and solanum retroflexum dun. (solanaceae). twenty species not yet arrived in australia were predicted to have a high likelihood of becoming weeds. analysis of the residuals of the regressions indicated two long-established species which might prove to be good targets for biological control: mesembryanthemum crystallinum l. (aizoaceae) and watsonia meriana (l.) mill. (iridaceae).",
            "contribution_ids": [
                "R57058"
            ]
        },
        {
            "instance_id": "R57101xR57061",
            "comparison_id": "R57101",
            "paper_id": "R57061",
            "text": "Patterns of extinction in the introduced Hawaiian avifauna: a reexamination of the role of competition among introduced passeriform and columbiform birds of the six major hawaiian islands, some species (including most of those introduced early) may have an intrinsically high probability of successful invasion, whereas others (including many of those introduced from 1900 through 1936) may be intrinsically less likely to succeed. this hypothesis accords well with the observation that, of the 41 species introduced on more than one of the hawaiian islands, all but four either succeeded everywhere they were introduced or failed everywhere they were introduced, no matter what other species or how many other species were present. other hypotheses, including competitive ones, are possible. however, most other patterns that have been claimed to support the hypothesis that competitive interactions have been key to which species survived are ambiguous. we propose that the following patterns are true: (1) extinction rate as a function of number of species present (s) is not better fit by addition of an s2 term. (2) bill-length differences between pairs of species that invaded together may tend to be less for pairs in which at least one species became extinct, but the result is easily changed by use of one reasonable set of conventions rather than another. in any event, the relationship of bill-length differences to resource overlap has not been established for these species. (3) surviving forest passeriforms on oahu may be overdispersed in morphological space, although the species pool used to construct the space may not have been the correct one. (4) densities of surviving species on species-poor islands have not been shown to exceed those on species-rich islands.",
            "contribution_ids": [
                "R57062"
            ]
        },
        {
            "instance_id": "R57101xR57067",
            "comparison_id": "R57101",
            "paper_id": "R57067",
            "text": "The role of opportunity in the unintentional introduction of nonnative ants a longstanding goal in the study of biological invasions is to predict why some species are successful invaders, whereas others are not. to understand this process, detailed information is required concerning the pool of species that have the opportunity to become established. here we develop an extensive database of ant species unintentionally transported to the continental united states and use these data to test how opportunity and species-level ecological attributes affect the probability of establishment. this database includes an amount of information on failed introductions that may be unparalleled for any group of unintentionally introduced insects. we found a high diversity of species (232 species from 394 records), 12% of which have become established in the continental united states. the probability of establishment increased with the number of times a species was transported (propagule pressure) but was also influenced by nesting habit. ground nesting species were more likely to become established compared with arboreal species. these results highlight the value of developing similar databases for additional groups of organisms transported by humans to obtain quantitative data on the first stages of the invasion process: opportunity and transport.",
            "contribution_ids": [
                "R57068",
                "R57069"
            ]
        },
        {
            "instance_id": "R57501xR57137",
            "comparison_id": "R57501",
            "paper_id": "R57137",
            "text": "Control of plant species diversity and community invasibility by species immigration: seed richness versus seed density brown, r. l. and fridley, j. d. 2003. control of plant species diversity andcommunity invasibility by species immigration: seed richness versus seed density. \u2013oikos 102: 15\u201324.immigration rates of species into communities are widely understood to in\ufb02uencecommunity diversity, which in turn is widely expected to in\ufb02uence the susceptibilityof ecosystems to species invasion. for a given community, however, immigrationprocesses may impact diversity by means of two separable components: the numberof species represented in seed inputs and the density of seed per species. theindependent effects of these components on plant species diversity and consequentrates of invasion are poorly understood. we constructed experimental plant commu-nities through repeated seed additions to independently measure the effects of seedrichness and seed density on the trajectory of species diversity during the develop-ment of annual plant communities. because we sowed species not found in theimmediate study area, we were able to assess the invasibility of the resultingcommunities by recording the rate of establishment of species from adjacent vegeta-tion. early in community development when species only weakly interacted, seedrichness had a strong effect on community diversity whereas seed density had littleeffect. after the plants became established, the effect of seed richness on measureddiversity strongly depended on seed density, and disappeared at the highest level ofseed density. the ability of surrounding vegetation to invade the experimentalcommunities was decreased by seed density but not by seed richness, primarilybecause the individual effects of a few sown species could explain the observedinvasion rates. these results suggest that seed density is just as important as seedrichness in the control of species diversity, and perhaps a more important determi-nant of community invasibility than seed richness in dynamic plant assemblages.",
            "contribution_ids": [
                "R57138"
            ]
        },
        {
            "instance_id": "R57501xR57157",
            "comparison_id": "R57501",
            "paper_id": "R57157",
            "text": "Human-related processes drive the richness of exotic birds in Europe \\n both human-related and natural factors can affect the establishment and distribution of exotic species. understanding the relative role of the different factors has important scientific and applied implications. here, we examined the relative effect of human-related and natural factors in determining the richness of exotic bird species established across europe. using hierarchical partitioning, which controls for covariation among factors, we show that the most important factor is the human-related community-level propagule pressure (the number of exotic species introduced), which is often not included in invasion studies due to the lack of information for this early stage in the invasion process. another, though less important, factor was the human footprint (an index that includes human population size, land use and infrastructure). biotic and abiotic factors of the environment were of minor importance in shaping the number of established birds when tested at a european extent using 50\u00d750\\u200akm\\n 2 \\n grid squares. we provide, to our knowledge, the first map of the distribution of exotic bird richness in europe. the richest hotspot of established exotic birds is located in southeastern england, followed by areas in belgium and the netherlands. community-level propagule pressure remains the major factor shaping the distribution of exotic birds also when tested for the uk separately. thus, studies examining the patterns of establishment should aim at collecting the crucial and hard-to-find information on community-level propagule pressure or develop reliable surrogates for estimating this factor. allowing future introductions of exotic birds into europe should be reconsidered carefully, as the number of introduced species is basically the main factor that determines the number established.\\n",
            "contribution_ids": [
                "R57158"
            ]
        },
        {
            "instance_id": "R57501xR57175",
            "comparison_id": "R57501",
            "paper_id": "R57175",
            "text": "Native communities determine the identity of exotic invaders even at scales at which communities are unsaturated aim\\u2002 to determine why some communities are more invasible than others and how this depends on spatial scale. our previous work in serpentine ecosystems showed that native and exotic diversity are negatively correlated at small scales, but became positively correlated at larger scales. we hypothesized that this pattern was the result of classic niche partitioning at small scales where the environment is homogeneous, and a shift to the dominance of coexistence mechanisms that depend on spatial heterogeneity in the environment at large scales.",
            "contribution_ids": [
                "R57176"
            ]
        },
        {
            "instance_id": "R57501xR57179",
            "comparison_id": "R57501",
            "paper_id": "R57179",
            "text": "Spatial heterogeneity explains the scale dependence of the native-exotic diversity relationship while small-scale studies show that more diverse native communities are less invasible by exotics, studies at large spatial scales often find positive correlations between native and exotic diversity. this large-scale pattern is thought to arise because landscapes with favorable conditions for native species also have favorable conditions for exotic species. from theory, we proposed an alternative hypothesis: the positive relationship at large scales is driven by spatial heterogeneity in species composition, which is driven by spatial heterogeneity in the environment. landscapes with more spatial heterogeneity in the environment can sustain more native and more exotic species, leading to a positive correlation of native and exotic diversity at large scales. in a nested data set for grassland plants, we detected negative relationships between native and exotic diversity at small spatial scales and positive relationships at large spatial scales. supporting our hypothesis, the positive relationships between native and exotic diversity at large scales were driven by positive relationships between native and exotic beta diversity. further, both native and exotic diversity were positively correlated with spatial heterogeneity in abiotic conditions (variance of soil depth, soil nitrogen, and aspect) but were uncorrelated with average abiotic conditions, supporting the spatial-heterogeneity hypothesis but not the favorable-conditions",
            "contribution_ids": [
                "R57180"
            ]
        },
        {
            "instance_id": "R57501xR57209",
            "comparison_id": "R57501",
            "paper_id": "R57209",
            "text": "Invasibility and compositional stability in a grassland community: relationships to diversity and extrinsic factors we present results from an ongoing field study conducted in kansas grassland to examine correlates of invasibility and community stability along a natural gradient of plant diversity. invasibility was evaluated by sowing seeds of 34 plant species into 40 experimental plots and then measuring colonization success after two growing seasons. compositional stability, defined as resistance to change in species relative abundances over two growing seasons and in response to experimental disturbance, was measured in a separate set of 40 plots. we found that community susceptibility to invasion was greatest in high diversity microsites within this grassland. multiple regression analyses suggested that the positive correlation between invasibility and plant diversity was due to the direct influences of the extrinsic factors that contribute to spatial variation in diversity (soil disturbances; light availability), not to any direct impact of diversity. in addition, we found that compositional stability in response to disturbance was greatest within low diversity microsites and was strongly related to the dominance (evenness) component of diversity.",
            "contribution_ids": [
                "R57210"
            ]
        },
        {
            "instance_id": "R57501xR57214",
            "comparison_id": "R57501",
            "paper_id": "R57214",
            "text": "Plant community diversity and composition provide little resistance to Juniperus encroachment widespread encroachment of the fire-intolerant species juniperus virginiana l. into north american grasslands and savannahs where fire has largely been removed has prompted the need to identify mechanisms driving j. virginiana encroachment. we tested whether encroachment success of j. virginiana is related to plant species diversity and composi- tion across three plant communities. we predicted j. virginiana encroachment success would (i) decrease with increasing diversity, and (ii)j.virginiana encroachment success would be unrelated to species composition. we simulated encroachment by planting j. virginiana seedlings in tallgrass prairie, old-field grassland, and upland oak forest. we used j. virginiana survival and growth as an index of encroachment success and evaluated success as a function of plant community traits (i.e., species richness, species diversity, and species composition). our results indicated that j. virginiana encroachment suc- cess increased with increasing plant richness and diversity. moreover, growth and survival of j. virginiana seedlings was associated with plant species composition only in the old-field grassland and upland oak forest. these results suggest that greater plant species richness and diversity provide little resistance to j. virginiana encroachment, and the results suggest resource availability and other biotic or abiotic factors are determinants of j. virginiana encroachment success.",
            "contribution_ids": [
                "R57215"
            ]
        },
        {
            "instance_id": "R57501xR57219",
            "comparison_id": "R57501",
            "paper_id": "R57219",
            "text": "Ecological filtering of exotic plants in an Australian sub-alpine environment abstract we investigated some of the factors influencing exotic invasion of native sub-alpine plant communities at a site in southeast australia. structure, floristic composition and invasibility of the plant communities and attributes of the invasive species were studied. to determine the plant characteristics correlated with invasiveness, we distinguished between roadside invaders, native community invaders and non-invasive exotic species, and compared these groups across a range of traits including functional group, taxonomic affinity, life history, mating system and morphology. poa grasslands and eucalyptus-poa woodlands contained the largest number of exotic species, although all communities studied appeared resilient to invasion by most species. most community invaders were broad-leaved herbs while roadside invaders contained both herbs and a range of grass species. over the entire study area the richness and cover of native and exotic herbaceous species were positively related, but exotic herbs were more negatively related to cover of specific functional groups (e.g. trees) than native herbs. compared with the overall pool of exotic species, those capable of invading native plant communities were disproportionately polycarpic, asteracean and cross-pollinating. our data support the hypothesis that strong ecological filtering of exotic species generates an exotic assemblage containing few dominant species and which functionally converges on the native assemblage. these findings contrast with those observed in the majority of invaded natural systems. we conclude that the invasion of closed sub-alpine communities must be viewed in terms of the unique attributes of the invading species, the structure and composition of the invaded communities and the strong extrinsic physical and climatic factors typical of the sub-alpine environment. nomenclature: australian plant name index (apni); http://www.anbg.gov.au/cgi-bin/apni abbreviations: knp = kosciuszko national park; mrpp = multi response permutation procedure; ve = variance explained.",
            "contribution_ids": [
                "R57220"
            ]
        },
        {
            "instance_id": "R57501xR57245",
            "comparison_id": "R57501",
            "paper_id": "R57245",
            "text": "Filling in the gaps: modelling native species richness and invasions using spatially incomplete data detailed knowledge of patterns of native species richness, an important component of biodiversity, and non\u2010native species invasions is often lacking even though this knowledge is essential to conservation efforts. however, we cannot afford to wait for complete information on the distribution and abundance of native and harmful invasive species. using information from counties well surveyed for plants across the usa, we developed models to fill data gaps in poorly surveyed areas by estimating the density (number of species km\u22122) of native and non\u2010native plant species. here, we show that native plant species density is non\u2010random, predictable, and is the best predictor of non\u2010native plant species density. we found that eastern agricultural sites and coastal areas are among the most invaded in terms of non\u2010native plant species densities, and that the central usa appears to have the greatest ratio of non\u2010native to native species. these large\u2010scale models could also be applied to smaller spatial scales or other taxa to set priorities for conservation and invasion mitigation, prevention, and control efforts.",
            "contribution_ids": [
                "R57246"
            ]
        },
        {
            "instance_id": "R57501xR57263",
            "comparison_id": "R57501",
            "paper_id": "R57263",
            "text": "Fish invasions in the world's river systems: When natural processes are blurred by human activities \"because species invasions are a principal driver of the human-induced biodiversity crisis, the identification of the major determinants of global invasions is a prerequisite for adopting sound conservation policies. three major hypotheses, which are not necessarily mutually exclusive, have been proposed to explain the establishment of non-native species: the \u201chuman activity\u201d hypothesis, which argues that human activities facilitate the establishment of non-native species by disturbing natural landscapes and by increasing propagule pressure; the \u201cbiotic resistance\u201d hypothesis, predicting that species-rich communities will readily impede the establishment of non-native species; and the \u201cbiotic acceptance\u201d hypothesis, predicting that environmentally suitable habitats for native species are also suitable for non-native species. we tested these hypotheses and report here a global map of fish invasions (i.e., the number of non-native fish species established per river basin) using an original worldwide dataset of freshwater fish occurrences, environmental variables, and human activity indicators for 1,055 river basins covering more than 80% of earth's surface. first, we identified six major invasion hotspots where non-native species represent more than a quarter of the total number of species. according to the world conservation union, these areas are also characterised by the highest proportion of threatened fish species. second, we show that the human activity indicators account for most of the global variation in non-native species richness, which is highly consistent with the \u201chuman activity\u201d hypothesis. in contrast, our results do not provide support for either the \u201cbiotic acceptance\u201d or the \u201cbiotic resistance\u201d hypothesis. we show that the biogeography of fish invasions matches the geography of human impact at the global scale, which means that natural processes are blurred by human activities in driving fish invasions in the world's river systems. in view of our findings, we fear massive invasions in developing countries with a growing economy as already experienced in developed countries. anticipating such potential biodiversity threats should therefore be a priority.\"",
            "contribution_ids": [
                "R57264"
            ]
        },
        {
            "instance_id": "R57501xR57273",
            "comparison_id": "R57501",
            "paper_id": "R57273",
            "text": "Phalaris arundinacea seedling establishment: effects of canopy complexity in fen, mesocosm, and restoration experiments phalaris arundinacea l. (reed canary grass) is a major invader of wetlands in temperate north america; it creates monotypic stands and displaces native vegetation. in this study, the effect of plant canopies on the establishment of p. arundinacea from seed in a fen, fen-like mesocosms, and a fen restoration site was assessed. in wingra fen, canopies that were more resistant to p. arundinacea establishment had more species (eight or nine versus four to six species) and higher cover of aster firmus. in mesocosms planted with glyceria striata plus 1, 6, or 15 native species, all canopies closed rapidly and prevented p. arundinacea establishment from seed, regardless of the density of the matrix species or the number of added species. only after gaps were created in the canopy was p. arundinacea able to establish seedlings; then, the 15-species treatment reduced establishment to 48% of that for single-species canopies. a similar experiment in the restoration site produced less cover of native plants, and p. a...",
            "contribution_ids": [
                "R57274"
            ]
        },
        {
            "instance_id": "R57501xR57309",
            "comparison_id": "R57501",
            "paper_id": "R57309",
            "text": "Weak vs. strong invaders of natural plant communities: Assessing invasibility and impact in response to the profound threat of exotic species to natural systems, much attention has been focused on the biotic resistance hypothesis, which predicts that diverse communities should better resist invasions. while studies of natural communities generally refute this hypothesis, reporting positive relationships between native species diversity and invasibility, some local-scale studies have instead obtained negative relationships. most treatments of the topic have failed to recognize that all exotic invaders do not behave alike: while \u201cweak\u201d invaders become minor components of communities, \u201cstrong\u201d invaders become community dominants at the expense of native species. at the same time, the specific impacts of strong invaders on communities are poorly documented yet critical to understanding implications of diversity loss. with these shortfalls in mind, we examined local-scale relationships between native and exotic plant taxa in bunchgrass communities of western montana, usa. we found that measures of...",
            "contribution_ids": [
                "R57310"
            ]
        },
        {
            "instance_id": "R57501xR57311",
            "comparison_id": "R57501",
            "paper_id": "R57311",
            "text": "Native plant diversity increases herbivory to non-natives there is often an inverse relationship between the diversity of a plant community and the invasibility of that community by non-native plants. native herbivores that colonize novel plants may contribute to diversity\u2013invasibility relationships by limiting the relative success of non-native plants. here, we show that, in large collections of non-native oak trees at sites across the usa, non-native oaks introduced to regions with greater oak species richness accumulated greater leaf damage than in regions with low oak richness. underlying this trend was the ability of herbivores to exploit non-native plants that were close relatives to their native host. in diverse oak communities, non-native trees were on average more closely related to native trees and received greater leaf damage than those in depauperate oak communities. because insect herbivores colonize non-native plants that are similar to their native hosts, in communities with greater native plant diversity, non-natives experience greater herbivory.",
            "contribution_ids": [
                "R57312"
            ]
        },
        {
            "instance_id": "R57501xR57341",
            "comparison_id": "R57501",
            "paper_id": "R57341",
            "text": "Ecological resistance to Acer negundo invasion in a European riparian forest: relative importance of environmental and biotic drivers question \\n \\nthe relative importance of environmental vs. biotic resistance of recipient ecological communities remains poorly understood in invasion ecology. acer negundo, a north american tree, has widely invaded riparian forests throughout europe at the ecotone between early- (salix spp. and populus spp.) and late-successional (fraxinus spp.) species. however, it is not present in the upper part of the rhone river, where native alnus incana occurs at an intermediate position along the successional riparian gradient. is this absence of the invasive tree due to environmental or biotic resistance of the recipient communities, and in particular due to the presence of alnus? \\n \\n \\n \\nlocation \\n \\nupper rhone river, france. \\n \\n \\n \\nmethods \\n \\nwe undertook a transplant experiment in an alnus-dominated community along the upper rhone river, where we compared acer negundo survival and growth, with and without biotic interactions (tree and herb layer effects), to those of four native tree species from differing successional positions in the upper rhone communities (p. alba, s. alba, f. excelsior and alnus incana). \\n \\n \\n \\nresults \\n \\nwithout biotic interactions acer negundo performed similarly to native species, suggesting that the upper rhone floodplain is not protected from acer invasion by a simple abiotic barrier. in contrast, this species performed less well than f. excelsior and alnus incana in environments with intact tree and/or herb layers. alnus showed the best growth rate in these conditions, indicating biotic resistance of the native plant community. \\n \\n \\n \\nconclusions \\n \\nwe did not find evidence for an abiotic barrier to acer negundo invasion of the upper rhone river floodplain communities, but our results suggest a biotic resistance. in particular, we demonstrated that (i) additive competitive effects of the tree and herb layer led to acer negundo suppression and (ii) alnus incana grew more rapidly than acer negundo in this intermediate successional niche.",
            "contribution_ids": [
                "R57342"
            ]
        },
        {
            "instance_id": "R57501xR57367",
            "comparison_id": "R57501",
            "paper_id": "R57367",
            "text": "Exotic plant species invade hot spots of native plant diversity some theories and experimental studies suggest that areas of low plant spe- cies richness may be invaded more easily than areas of high plant species richness. we gathered nested-scale vegetation data on plant species richness, foliar cover, and frequency from 200 1-m 2 subplots (20 1000-m 2 modified-whittaker plots) in the colorado rockies (usa), and 160 1-m 2 subplots (16 1000-m 2 plots) in the central grasslands in colorado, wyoming, south dakota, and minnesota (usa) to test the generality of this paradigm. at the 1-m 2 scale, the paradigm was supported in four prairie types in the central grasslands, where exotic species richness declined with increasing plant species richness and cover. at the 1-m 2 scale, five forest and meadow vegetation types in the colorado rockies contradicted the paradigm; exotic species richness increased with native-plant species richness and foliar cover. at the 1000-m 2 plot scale (among vegetation types), 83% of the variance in exotic species richness in the central grasslands was explained by the total percentage of nitrogen in the soil and the cover of native plant species. in the colorado rockies, 69% of the variance in exotic species richness in 1000-m 2 plots was explained by the number of native plant species and the total percentage of soil carbon. at landscape and biome scales, exotic species primarily invaded areas of high species richness in the four central grasslands sites and in the five colorado rockies vegetation types. for the nine vegetation types in both biomes, exotic species cover was positively correlated with mean foliar cover, mean soil percentage n, and the total number of exotic species. these patterns of invasibility depend on spatial scale, biome and vegetation type, spatial autocorrelation effects, availability of resources, and species-specific responses to grazing and other disturbances. we conclude that: (1) sites high in herbaceous foliar cover and soil fertility, and hot spots of plant diversity (and biodiversity), are invasible in many landscapes; and (2) this pattern may be more closely related to the degree resources are available in native plant communities, independent of species richness. exotic plant in- vasions in rare habitats and distinctive plant communities pose a significant challenge to land managers and conservation biologists.",
            "contribution_ids": [
                "R57368"
            ]
        },
        {
            "instance_id": "R57501xR57369",
            "comparison_id": "R57501",
            "paper_id": "R57369",
            "text": "Scale and plant invasions: a theory of biotic acceptance we examined the relationship between native and alien plant species richness, cover, and estimated biomass at multiple spatial scales. the large dataset included 7051 1-m subplots, 1443 10-m subplots, and 727 100-m subplots, nested in 727 1000-m plots in 37 natural vegetation types in seven states in the central united states. we found that native and alien species richness (averaged across the vegetation types) increased significantly with plot area. furthermore, the relationship between native and alien species richness became increasingly positive and significant from the plant neighbourhood scale (1-m) to the 10-m, 100-m, and the 1000-m scale where over 80% of the vegetation types had positive slopes between native and alien species richness. both native and alien plant species may be responding to increased resource availability and/or habitat heterogeneity with increased area. we found significant positive relationships between the coefficient of variation of native cover in 1-m subplots in a vegetation type (i.e. a measure of habitat heterogeneity), and both the relative cover and relative biomass of alien plant species. at the 1000-m scale, we did find weak negative relationships between native species richness and the cover, biomass, and relative cover of alien plant species. however, we found very strong positive relationships between alien species richness and the cover, relative cover, and relative biomass of alien species at regional scales. these results, along with many other field studies in natural ecosystems, show that the dominant general pattern in invasion ecology at multiple spatial scales is one of \u201cbiotic acceptance\u201d where natural ecosystems tend to accommodate the establishment and coexistence of introduced species despite the presence and abundance of native species.",
            "contribution_ids": [
                "R57370"
            ]
        },
        {
            "instance_id": "R57501xR57382",
            "comparison_id": "R57501",
            "paper_id": "R57382",
            "text": "Weed numbers in New Zealand's forest and scrub reserves \"new zealand's protected natural areas are being increasingly threatened by weeds as the natural landscape is fragmented and surrounding land use intensifies. to assist in designing management to reduce the threat, we attempted to determine the most important reserve characteristics influencing the presence of problem weeds in forest and scrub reserves. data on 15 reserve characteristics were derived from surveys of 234 reserves. from correlation analysis, analysis of variance and consideration of several multivariate models, it appears that the most important characteristics influencing the number of problem weeds in reserves are proximity to towns, distance from roads and railway lines, human use, reserve shape, and habitat diversity. these factors reflect principally increased proximity to source of propagules associated with intensifying land use, including urbanisation. reserves with the most weeds are narrow remnants on fertile soils with clearings and a history of modification, and those close to towns or sites of high human activity. if these reserves are to continue to protect natural values, they will require regular attention to prevent the establishment of further weeds. accidental spread of weeds and disturbance in reserves should be minimised.\"",
            "contribution_ids": [
                "R57383"
            ]
        },
        {
            "instance_id": "R57501xR57384",
            "comparison_id": "R57501",
            "paper_id": "R57384",
            "text": "Biotic resistance to invader establishment of a southern Appalachian plant community is determined by environmental conditions summary 1 tests of the relationship between resident plant species richness and habitat invasibility have yielded variable results. i investigated the roles of experimental manipulation of understorey species richness and overstorey characteristics in resistance to invader establishment in a floodplain forest in south-western virginia, usa. 2 i manipulated resident species richness in experimental plots along a flooding gradient, keeping plot densities at their original levels, and quantified the overstorey characteristics of each plot. 3 after manipulating the communities, i transplanted 10 randomly chosen invaders from widespread native and non-native forest species into the experimental plots. success of an invasion was measured by survival and growth of the invader. 4 native and non-native invader establishment trends were influenced by different aspects of the biotic community and these relationships depended on the site of invasion. the most significant influence on non-native invader survival in this system of streamside and upper terrace plots was the overstorey composition. non-native species survival in the flooded plots after 2 years was significantly positively related to proximity to larger trees. however, light levels did not fully explain the overstorey effect and were unrelated to native survivorship. the effects of understorey richness on survivorship depended on the origin of the invaders and the sites they were transplanted into. additionally, native species growth was significantly affected by understorey plot richness. 5 the direction and strength of interactions with both the overstorey (for non-native invaders) and understorey richness (for natives and non-natives) changed with the site of invasion and associated environmental conditions. rather than supporting the hypothesis of biotic resistance to non-native invasion, my results suggest that native invaders experienced increased competition with the native understorey plants in the more benign upland habitat and facilitation in the stressful riparian zone.",
            "contribution_ids": [
                "R57385"
            ]
        },
        {
            "instance_id": "R57501xR57393",
            "comparison_id": "R57501",
            "paper_id": "R57393",
            "text": "Diversity effects on invasion vary with life history stage in marine macroalgae most experimental studies of diversity effects on invasibility have reported negative relationships while observational studies have often found positive correlations between the numbers of exotic and native taxa. nearly all of these studies have been done with terrestrial plants or aquatic invertebrates. we investigated effects of native macroalgal diversity on invasion success of the introduced macroalga sargassum muticum (yendo) fensholt (phaeophyceae: fucales) on the west coast of vancouver island. we conducted both observational field surveys of the correlation between native diversity and exotic cover, and experimental manipulations of native diversity in constructed 25 \ufffd 25 cm communities. field surveys found higher cover of s. muticum in plots with low native diversity, suggesting a negative relationship between diversity and invasibility at the neighbourhood scale. the experiment found initial cover of s. muticum germlings was highest in plots with greater diversity. over the duration of the experiment cover of settled germlings increased fastest in the low diversity plots, so that there was a weak negative effect of diversity on final cover of the invader after 77 days. the slope of the relationship reversed over time, with field patterns and experimental results converging at the end of the experiment. our results suggest native diversity has contrasting effects on different stages of invasion. diversity facilitates invader recruitment of s. muticum but decreases growth and or survivorship.",
            "contribution_ids": [
                "R57394",
                "R57395"
            ]
        },
        {
            "instance_id": "R57501xR57401",
            "comparison_id": "R57501",
            "paper_id": "R57401",
            "text": "Realistic species losses disproportionately reduce grassland resistance to biological invaders consequences of progressive biodiversity declines depend on the functional roles of individual species and the order in which species are lost. most studies of the biodiversity\u2013ecosystem functioning relation tackle only the first of these factors. we used observed variation in grassland diversity to design an experimental test of how realistic species losses affect invasion resistance. because entire plant functional groups disappeared faster than expected by chance, resistance declined dramatically with progressive species losses. realistic biodiversity losses, even of rare species, can thus affect ecosystem processes far more than indicated by randomized-loss experiments.",
            "contribution_ids": [
                "R57402"
            ]
        },
        {
            "instance_id": "R58002xR57598",
            "comparison_id": "R58002",
            "paper_id": "R57598",
            "text": "Lack of pre-dispersal seed predators in introduced Asteraceae in New Zealand the idea that naturalised invading plants have fewer phytophagous insects associated with them in their new environment relative to their native range is often assumed, but quantitative data are few and mostly refer to pests on crop species. in this study, the incidence of seed-eating insect larvae in flowerheads of naturalised asteraceae in new zealand is compared with that in britain where the species are native. similar surveys were carried out in both countries by sampling 200 flowerheads of three populations of the same thirteen species. in the new zealand populations only one seed-eating insect larva was found in 7800 flowerheads (0.013% infected flowerheads, all species combined) in contrast with the british populations which had 487 (6.24%) flowerheads infested. possible reasons for the low colonization level of the introduced asteraceae by native insects in new zealand are 1) the relatively recent introduction of the plants (100-200 years), 2) their phylogenetic distance from the native flora, and 3) the specialised nature of the bud-infesting habit of the insects.",
            "contribution_ids": [
                "R57599"
            ]
        },
        {
            "instance_id": "R58002xR57614",
            "comparison_id": "R58002",
            "paper_id": "R57614",
            "text": "Herbivorous arthropod community of an alien weed Solanum carolinense L. herbivorous arthropod fauna of the horse nettle solanum carolinense l., an alien solanaceous herb of north american origin, was characterized by surveying arthropod communities in the fields and comparing them with the original community compiled from published data to infer the impact of herbivores on the weed in the introduced region. field surveys were carried out in the central part of mainland japan for five years including an intensive regular survey in 1992. thirty-nine arthropod species were found feeding on the weed. the leaf, stem, flower and fruit of the weed were infested by the herbivores. the comparison of characteristics of the arthropod community with those of the community in the usa indicated that more sapsuckers and less chewers were on the weed in japan than in the usa. the community in japan was composed of high proportions of polyphages and exophages compared to that in the usa. eighty-seven percent of the species are known to be pests of agricultural crops. low species diversity of the community was also suggested. the depauperated herbivore community, in terms of feeding habit and niche on s. carolinense, suggested that the weed partly escaped from herbivory in its reproductive parts. the regular population census, however, indicated that a dominant coccinellid beetle, epilachna vigintioctopunctata, caused a noticeable damage on the leaves of the weed.",
            "contribution_ids": [
                "R57615"
            ]
        },
        {
            "instance_id": "R58002xR57618",
            "comparison_id": "R58002",
            "paper_id": "R57618",
            "text": "Plant-soil biota interactions and spatial distribution of black cherry in its native and invasive ranges one explanation for the higher abundance of invasive species in their non-native than native ranges is the escape from natural enemies. but there are few experimental studies comparing the parallel impact of enemies (or competitors and mutualists) on a plant species in its native and invaded ranges, and release from soil pathogens has been rarely investigated. here we present evidence showing that the invasion of black cherry (prunus serotina) into north-western europe is facilitated by the soil community. in the native range in the usa, the soil community that develops near black cherry inhibits the establishment of neighbouring conspecifics and reduces seedling performance in the greenhouse. in contrast, in the non-native range, black cherry readily establishes in close proximity to conspecifics, and the soil community enhances the growth of its seedlings. understanding the effects of soil organisms on plant abundance will improve our ability to predict and counteract plant invasions.",
            "contribution_ids": [
                "R57619"
            ]
        },
        {
            "instance_id": "R58002xR57652",
            "comparison_id": "R58002",
            "paper_id": "R57652",
            "text": "Limited grazing pressure by native herbivores on the invasive seaweed Caulerpa taxifolia in a temperate Australian estuary \\n\\ncaulerpa taxifolia is an invasive alga threatening biodiversity in invaded regions. its proliferation in recipient communities will be due to several factors including limited grazing effects by native herbivores. however, little is known about grazing pressure exerted by native herbivores on c. taxifolia relative to native macrophytes or its attractiveness to them as habitat. the present study determined which herbivores co-occurred with invasive c. taxifolia in a temperate australian estuary and documented their abundance, relative grazing effects, habitat preference and survivorship on c. taxifolia compared with native macrophytes. four herbivores co-occurred with c. taxifolia and their densities were often low or zero at the sites studied. feeding experiments showed that compared with c. taxifolia: the fish, girella tricuspidata, preferred ulva sp.; the sea-hare, aplysia dactylomela, preferred laurencia sp.; whereas the mesograzers, cymadusa setosa and platynereis dumerilii antipoda, both consumed cystoseira trinodus and sargassum sp. at higher rates. the two mesograzers also showed strong habitat preference for c. trinodus and sargassum sp. cymadusa setosa had poor survivorship on caulerpa taxifolia whereas p. dumerilii antipoda had 100% survivorship on c. taxifolia after 41 days. we consider that the low diversity and abundance of native herbivores, their weak grazing pressure on c. taxifolia and its low attractiveness as habitat may facilitate further local spread in this estuary, and potentially in other invaded locations.\\n",
            "contribution_ids": [
                "R57653"
            ]
        },
        {
            "instance_id": "R58002xR57717",
            "comparison_id": "R58002",
            "paper_id": "R57717",
            "text": "Use of the introduced bivalve, Musculista senhousia, by generalist parasites of native New Zealand bivalves abstract introduced species are often thought to do well because of an escape from natural enemies. however, once established, they can acquire a modest assemblage of enemies, including parasites, in their new range. here we quantified prevalence and effects of infection with copepods (family myicolidae) and pea crabs (pinnotheres novaezelandiae), in three mussel species, the non\u2010native musculista senhousia, and two native mussels, perna canaliculus and xenostrobus pulex, at bucklands beach, auckland, new zealand. copepod prevalence was highest in x. pulex (17.9%), whereas pea crab prevalence was highest in p. canaliculus (33.6%). both parasites infected m. senhousia, but at a much lower prevalence. dry tissue weight was significantly lower in p. canaliculus infected with pea crabs. in addition, we experimentally investigated host species selection by pea crabs. in an experimental apparatus, pea crabs showed a significant attraction to p. canaliculus, but not so for x. pulex or m. senhousia. when the mussels were presented in combination, pea crabs showed a weak attraction for x. pulex. pea crab attraction to m. senhousia was not significant. it appears that the introduced m. senhousia largely escapes the detrimental effects of infection with either parasite species compared with native mussels occurring in sympatry.",
            "contribution_ids": [
                "R57718",
                "R57719"
            ]
        },
        {
            "instance_id": "R58002xR57720",
            "comparison_id": "R58002",
            "paper_id": "R57720",
            "text": "Herbivores, but not other insects, are scarce on alien plants \"abstract\\xa0 understanding how the landscape-scale replacement of indigenous plants with alien plants influences ecosystem structure and functioning is critical in a world characterized by increasing biotic homogenization. an important step in this process is to assess the impact on invertebrate communities. here we analyse insect species richness and abundance in sweep collections from indigenous and alien (australasian) woody plant species in south africa's western cape. we use phylogenetically relevant comparisons and compare one indigenous with three australasian alien trees within each of fabaceae: mimosoideae, myrtaceae, and proteaceae: grevilleoideae. although some of the alien species analysed had remarkably high abundances of herbivores, even when intentionally introduced biological control agents are discounted, overall, herbivorous insect assemblages from alien plants were slightly less abundant and less diverse compared with those from indigenous plants \u2013 in accordance with predictions from the enemy release hypothesis. however, there were no clear differences in other insect feeding guilds. we conclude that insect assemblages from alien plants are generally quite diverse, and significant differences between these and assemblages from indigenous plants are only evident for herbivorous insects.\"",
            "contribution_ids": [
                "R57721"
            ]
        },
        {
            "instance_id": "R58002xR57722",
            "comparison_id": "R58002",
            "paper_id": "R57722",
            "text": "Novel host associations and habitats for Senecio-specialist herbivorous insects in Auckland we studied the genusand species-specialist monophagous herbivorous insects of senecio (asteraceae) in auckland, new zealand. with the exception of the widespread s. hispidulus, the eight native senecio species in mainland auckland (two endemic) are typically uncommon and restricted to less modified conservation land. however, 11 naturalised senecio have established and are often widespread in urban and rural habitats. three endemic senecio-specialist herbivores \u2013 nyctemera annulata, patagoniodes farnaria, and tephritis fascigera \u2013 formed novel host associations with naturalised senecio species and spread into modified landscapes. host associations for these species were not related to whether senecio species are naturalised or native. however, the abundances of patagonoides farnaria and tephritis fascigera were significantly higher in wildland habitats than rural or urban habitats, and wildland senecio were on average 1.4 times more likely to experience >5% folivory than urban conspecifics. ___________________________________________________________________________________________________________________________________",
            "contribution_ids": [
                "R57723",
                "R57724"
            ]
        },
        {
            "instance_id": "R58002xR57740",
            "comparison_id": "R58002",
            "paper_id": "R57740",
            "text": "Acceleration of Exotic Plant Invasion in a Forested Ecosystem by a Generalist Herbivore abstract:\\u2002 the successful invasion of exotic plants is often attributed to the absence of coevolved enemies in the introduced range (i.e., the enemy release hypothesis). nevertheless, several components of this hypothesis, including the role of generalist herbivores, remain relatively unexplored. we used repeated censuses of exclosures and paired controls to investigate the role of a generalist herbivore, white\u2010tailed deer (odocoileus virginianus), in the invasion of 3 exotic plant species (microstegium vimineum, alliaria petiolata, and berberis thunbergii) in eastern hemlock (tsuga canadensis) forests in new jersey and pennsylvania (u.s.a.). this work was conducted in 10 eastern hemlock (t. canadensis) forests that spanned gradients in deer density and in the severity of canopy disturbance caused by an introduced insect pest, the hemlock woolly adelgid (adelges tsugae). we used maximum likelihood estimation and information theoretics to quantify the strength of evidence for alternative models of the influence of deer density and its interaction with the severity of canopy disturbance on exotic plant abundance. our results were consistent with the enemy release hypothesis in that exotic plants gained a competitive advantage in the presence of generalist herbivores in the introduced range. the abundance of all 3 exotic plants increased significantly more in the control plots than in the paired exclosures. for all species, the inclusion of canopy disturbance parameters resulted in models with substantially greater support than the deer density only models. our results suggest that white\u2010tailed deer herbivory can accelerate the invasion of exotic plants and that canopy disturbance can interact with herbivory to magnify the impact. in addition, our results provide compelling evidence of nonlinear relationships between deer density and the impact of herbivory on exotic species abundance. these findings highlight the important role of herbivore density in determining impacts on plant abundance and provide evidence of the operation of multiple mechanisms in exotic plant invasion.",
            "contribution_ids": [
                "R57741"
            ]
        },
        {
            "instance_id": "R58002xR57755",
            "comparison_id": "R58002",
            "paper_id": "R57755",
            "text": "Release from foliar and floral fungal pathogen species does not explain the geographic spread of naturalized North American plants in Europe 1 during the last centuries many alien species have established and spread in new regions, where some of them cause large ecological and economic problems. as one of the main explanations of the spread of alien species, the enemy\u2010release hypothesis is widely accepted and frequently serves as justification for biological control. 2 we used a global fungus\u2013plant host distribution data set for 140 north american plant species naturalized in europe to test whether alien plants are generally released from foliar and floral pathogens, whether they are mainly released from pathogens that are rare in the native range, and whether geographic spread of the north american plant species in europe is associated with release from fungal pathogens. 3 we show that the 140 north american plant species naturalized in europe were released from 58% of their foliar and floral fungal pathogen species. however, when we also consider fungal pathogens of the native north american host range that in europe so far have only been reported on other plant species, the estimated release is reduced to 10.3%. moreover, in europe north american plants have mainly escaped their rare, pathogens, of which the impact is restricted to few populations. most importantly and directly opposing the enemy\u2010release hypothesis, geographic spread of the alien plants in europe was negatively associated with their release from fungal pathogens. 4 synthesis. north american plants may have escaped particular fungal species that control them in their native range, but based on total loads of fungal species, release from foliar and floral fungal pathogens does not explain the geographic spread of north american plant species in europe. to test whether enemy release is the major driver of plant invasiveness, we urgently require more studies comparing release of invasive and non\u2010invasive alien species from enemies of different guilds, and studies that assess the actual impact of the enemies.",
            "contribution_ids": [
                "R57756"
            ]
        },
        {
            "instance_id": "R58002xR57761",
            "comparison_id": "R58002",
            "paper_id": "R57761",
            "text": "Community structure of insect herbivores on introduced and native Solidago plants in Japan we compared community composition, density, and species richness of herbivorous insects on the introduced plant solidago altissima l. (asteraceae) and the related native species solidago virgaurea l. in japan. we found large differences in community composition on the two solidago species. five hemipteran sap feeders were found only on s. altissima. two of them, the aphid uroleucon nigrotuberculatum olive (hemiptera: aphididae) and the scale insect parasaissetia nigra nietner (hemiptera: coccidae), were exotic species, accounting for 62% of the total individuals on s. altissima. these exotic sap feeders mostly determined the difference of community composition on the two plant species. in contrast, the herbivore community on s. virgaurea consisted predominately of five native insects: two lepidopteran leaf chewers and three dipteran leaf miners. overall species richness did not differ between the plants because the increased species richness of sap feeders was offset by the decreased richness of leaf chewers and leaf miners on s. altissima. the overall density of herbivorous insects was higher on s. altissima than on s. virgaurea, because of the high density of the two exotic sap feeding species on s. altissima. we discuss the importance of analyzing community composition in terms of feeding guilds of insect herbivores for understanding how communities of insect herbivores are organized on introduced plants in novel habitats.",
            "contribution_ids": [
                "R57762"
            ]
        },
        {
            "instance_id": "R58002xR57799",
            "comparison_id": "R58002",
            "paper_id": "R57799",
            "text": "Associations of leaf miners and leaf gallers with island plants of different residency histories aim\\u2002 introduced plant species are less likely to be attacked by herbivores than are native plant species. isolated oceanic islands provide an excellent model system for comparing the associations between herbivore species and plant species of different residency histories, namely endemic, indigenous (non\u2010endemic) or introduced (naturalized or cultivated) species. my aim was to test the prediction that, on isolated oceanic islands, introduced plant species have a lower tendency to have an association with insect herbivores than do endemic and indigenous plant species.",
            "contribution_ids": [
                "R57800"
            ]
        },
        {
            "instance_id": "R58002xR57889",
            "comparison_id": "R58002",
            "paper_id": "R57889",
            "text": "Biogeographic comparisons of herbivore attack, growth and impact of Japanese knotweed between Japan and France to shed light on the process of how exotic species become invasive, it is necessary to study them both in their native and non\u2010native ranges. our intent was to measure differences in herbivory, plant growth and the impact on other species in fallopia japonica in its native and non\u2010native ranges. we performed a cross\u2010range full descriptive, field study in japan (native range) and france (non\u2010native range). we assessed dna ploidy levels, the presence of phytophagous enemies, the amount of leaf damage, several growth parameters and the co\u2010occurrence of fallopia japonica with other plant species of herbaceous communities. invasive fallopia japonica plants were all octoploid, a ploidy level we did not encounter in the native range, where plants were all tetraploid. octoploids in france harboured far less phytophagous enemies, suffered much lower levels of herbivory, grew larger and had a much stronger impact on plant communities than tetraploid conspecifics in the native range in japan. our data confirm that fallopia japonica performs better \u2013 plant vigour and dominance in the herbaceous community \u2013 in its non\u2010native than its native range. because we could not find octoploids in the native range, we cannot separate the effects of differences in ploidy from other biogeographic factors. to go further, common garden experiments would now be needed to disentangle the proper role of each factor, taking into account the ploidy levels of plants in their native and non\u2010native ranges. synthesis. as the process by which invasive plants successfully invade ecosystems in their non\u2010native range is probably multifactorial in most cases, examining several components \u2013 plant growth, herbivory load, impact on recipient systems \u2013 of plant invasions through biogeographic comparisons is important. our study contributes towards filling this gap in the research, and it is hoped that this method will spread in invasion ecology, making such an approach more common.",
            "contribution_ids": [
                "R57890",
                "R57891"
            ]
        },
        {
            "instance_id": "R58002xR57902",
            "comparison_id": "R58002",
            "paper_id": "R57902",
            "text": "Herbivores on native and exotic Senecio plants: is host switching related to plant novelty and insect diet breadth under field conditions? native herbivores can establish novel interactions with alien plants after invasion. nevertheless, it is unclear whether these new associations are quantitatively significant compared to the assemblages with native flora under natural conditions. herbivores associated with two exotic plants, namely senecio inaequidens and s. pterophorus, and two coexisting natives, namely s. vulgaris and s. lividus, were surveyed in a replicated long\u2010term field study to ascertain whether the plant\u2013herbivore assemblages in mixed communities are related to plant novelty and insect diet breadth. native herbivores used exotic senecio as their host plants. of the 19 species of lepidoptera, diptera, and hemiptera found in this survey, 14 were associated with the exotic senecio plants. most of these species were polyphagous, yet we found a higher number of individuals with a narrow diet breadth, which is contrary to the assumption that host switching mainly occurs in generalist herbivores. the senecio specialist sphenella marginata (diptera: tephritidae) was the most abundant and widely distributed insect species (ca. 80% of the identified specimens). sphenella was associated with s. lividus, s. vulgaris and s. inaequidens and was not found on s. pterophorus. the presence of native plant congeners in the invaded community did not ensure an instantaneous ecological fitting between insects and alien plants. we conclude that novel associations between native herbivores and introduced senecio plants are common under natural conditions. plant novelty is, however, not the only predictor of herbivore abundance due to the complexity of natural conditions.",
            "contribution_ids": [
                "R57903"
            ]
        },
        {
            "instance_id": "R58002xR57907",
            "comparison_id": "R58002",
            "paper_id": "R57907",
            "text": "Little evidence for release from herbivores as a driver of plant invasiveness from a multi-species herbivore-removal experiment enemy release is frequently posed as a main driver of invasiveness of alien species. however, an experimental multi-species test examining performance and herbivory of invasive alien, non-invasive alien and native plant species in the presence and absence of natural enemies is lacking. in a common garden experiment in switzerland, we manipulated exposure of seven alien invasive, eight alien non-invasive and fourteen native species from six taxonomic groups to natural enemies (invertebrate herbivores), by applying a pesticide treatment under two different nutrient levels. we assessed biomass production, herbivore damage and the major herbivore taxa on plants. across all species, plants gained significantly greater biomass under pesticide treatment. however, invasive, non-invasive and native species did not differ in their biomass response to pesticide treatment at either nutrient level. the proportion of leaves damaged on invasive species was significantly lower compared to native species, but not when compared to non-invasive species. however, the difference was lost when plant size was accounted for. there were no differences between invasive, non-invasive and native species in herbivore abundance. our study offers little support for invertebrate herbivore release as a driver of plant invasiveness, but suggests that future enemy release studies should account for differences in plant size among species.",
            "contribution_ids": [
                "R57908",
                "R57909",
                "R57910",
                "R57911"
            ]
        },
        {
            "instance_id": "R58002xR57912",
            "comparison_id": "R58002",
            "paper_id": "R57912",
            "text": "Parasites and genetic diversity in an invasive bumblebee biological invasions are facilitated by the global transportation of species and climate change. given that invasions may cause ecological and economic damage and pose a major threat to biodiversity, understanding the mechanisms behind invasion success is essential. both the release of non-native populations from natural enemies, such as parasites, and the genetic diversity of these populations may play key roles in their invasion success. we investigated the roles of parasite communities, through enemy release and parasite acquisition, and genetic diversity in the invasion success of the non-native bumblebee, bombus hypnorum, in the united kingdom. the invasive b. hypnorum had higher parasite prevalence than most, or all native congeners for two high-impact parasites, probably due to higher susceptibility and parasite acquisition. consequently parasites had a higher impact on b. hypnorum queens\u2019 survival and colony-founding success than on native species. bombus hypnorum also had lower functional genetic diversity at the sex-determining locus than native species. higher parasite prevalence and lower genetic diversity have not prevented the rapid invasion of the united kingdom by b. hypnorum. these data may inform our understanding of similar invasions by commercial bumblebees around the world. this study suggests that concerns about parasite impacts on the small founding populations common to re-introduction and translocation programs may be less important than currently believed.",
            "contribution_ids": [
                "R57913"
            ]
        },
        {
            "instance_id": "R58002xR57920",
            "comparison_id": "R58002",
            "paper_id": "R57920",
            "text": "Invasive plants escape from suppressive soil biota at regional scales a prominent hypothesis for plant invasions is escape from the inhibitory effects of soil biota. although the strength of these inhibitory effects, measured as soil feedbacks, has been assessed between natives and exotics in non\u2010native ranges, few studies have compared the strength of plant\u2013soil feedbacks for exotic species in soils from non\u2010native versus native ranges. we examined whether 6 perennial european forb species that are widespread invaders in north american grasslands (centaurea stoebe, euphorbia esula, hypericum perforatum, linaria vulgaris, potentilla recta and leucanthemum vulgare) experienced different suppressive effects of soil biota collected from 21 sites across both ranges. four of the six species tested exhibited substantially reduced shoot biomass in \u2018live\u2019 versus sterile soil from europe. in contrast, north american soils produced no significant feedbacks on any of the invasive species tested indicating a broad scale escape from the inhibitory effects of soil biota. negative feedbacks generated by european soil varied idiosyncratically among sites and species. since this variation did not correspond with the presence of the target species at field sites, it suggests that negative feedbacks can be generated from soil biota that are widely distributed in native ranges in the absence of density\u2010dependent effects. synthesis. our results show that for some invasives, native soils have strong suppressive potential, whereas this is not the case in soils from across the introduced range. differences in regional\u2010scale evolutionary history among plants and soil biota could ultimately help explain why some exotics are able to occur at higher abundance in the introduced versus native range.",
            "contribution_ids": [
                "R57921"
            ]
        },
        {
            "instance_id": "R58002xR57948",
            "comparison_id": "R58002",
            "paper_id": "R57948",
            "text": "The parasite community of gobiid fishes (Actinopterygii: Gobiidae) from the Lower Volga River region abstract the parasitic fauna in the lower volga river basin was investigated for four gobiid species: the nonindigenous monkey goby neogobius fluviatilis (pallas, 1814), the round goby n. melanostomus (pallas, 1814), the caspian bighead goby ponticola gorlap (iljin, 1949), and the tubenose goby proterorhinus cf. semipellucidus (kessler, 1877). in total, 19 species of goby parasites were identified, of which two - bothriocephalus opsariichthydis yamaguti, 1934 and nicolla skrjabini (iwanitzki, 1928) - appeared to have been introduced from other geographic regions. the monkey goby had significantly fewer parasitic species (6), but relatively high levels of infection, in comparison to the native species. parasitism of the caspian bighead goby, which is the only predatory fish among the studied gobies, differed from the others according to the results of discriminant analysis. the parasitic fauna of the tubenose goby more closely resembled those of caspian sea gobiids, rather than the black sea monkey goby.",
            "contribution_ids": [
                "R57949"
            ]
        },
        {
            "instance_id": "R58002xR57959",
            "comparison_id": "R58002",
            "paper_id": "R57959",
            "text": "No release for the wicked: enemy release is dynamic and not associated with invasiveness the enemy release hypothesis predicts that invasive species will receive less damage from enemies, compared to co-occurring native and noninvasive exotic species in their introduced range. however, release operating early in invasion could be lost over time and with increased range size as introduced species acquire new enemies. we used three years of data, from 61 plant species planted into common gardens, to determine whether (1) invasive, noninvasive exotic, and native species experience differential damage from insect herbivores. and mammalian browsers, and (2) enemy release is lost with increased residence time and geographic spread in the introduced range. we find no evidence suggesting enemy release is a general mechanism contributing to invasiveness in this region. invasive species received the most insect herbivory, and damage increased with longer residence times and larger range sizes at three spatial scales. our results show that invasive and exotic species fail to escape enemies, particularly over longer temporal and larger spatial scales.",
            "contribution_ids": [
                "R57960",
                "R57961"
            ]
        },
        {
            "instance_id": "R58002xR57971",
            "comparison_id": "R58002",
            "paper_id": "R57971",
            "text": "Insect assemblages associated with the exotic riparian shrub Russian olive (Elaeagnaceae), and co-occurring native shrubs in British Columbia, Canada abstract russian olive ( elaeagnus angustifolia linnaeus; elaeagnaceae) is an exotic shrub/tree that has become invasive in many riparian ecosystems throughout semi-arid, western north america, including southern british columbia, canada. despite its prevalence and the potentially dramatic impacts it can have on riparian and aquatic ecosystems, little is known about the insect communities associated with russian olive within its invaded range. at six sites throughout the okanagan valley of southern british columbia, canada, we compared the diversity of insects associated with russian olive plants to that of insects associated with two commonly co-occurring native plant species: woods\u2019 rose ( rosa woodsii lindley; rosaceae) and saskatoon ( amelanchier alnifolia (nuttall) nuttall ex roemer; rosaceae). total abundance did not differ significantly among plant types. family richness and shannon diversity differed significantly between woods\u2019 rose and saskatoon, but not between either of these plant types and russian olive. an abundance of thripidae (thysanoptera) on russian olive and tingidae (hemiptera) on saskatoon contributed to significant compositional differences among plant types. the families chloropidae (diptera), heleomyzidae (diptera), and gryllidae (orthoptera) were uniquely associated with russian olive, albeit in low abundances. our study provides valuable and novel information about the diversity of insects associated with an emerging plant invader of western canada.",
            "contribution_ids": [
                "R57972"
            ]
        },
        {
            "instance_id": "R6755xR6523",
            "comparison_id": "R6755",
            "paper_id": "R6523",
            "text": "Towards a Linked-Data based Visualization Wizard datasets published in the lod cloud are recommended to follow some best practice in order to be 4-5 stars linked data compliant. they can often be consumed and accessed by different means such as api access, bulk download or as linked data fragments, but most of the time, a sparql endpoint is also provided. while the lod cloud keeps growing, having a quick glimpse of those datasets is getting harder and there is a need to develop new methods enabling to detect automatically what an arbitrary dataset is about and to recommend visualizations for data samples. we consider that \"a visualization is worth a million triples\", and in this paper, we propose a novel approach that mines the content of datasets and automatically generates visualizations. our approach is directly based on the usage of sparql queries that will detect the important categories of a dataset and that will specifically consider the properties used by the objects which have been interlinked via owl:sameas links. we then propose to associate type of visualization for those categories. we have implemented this approach into a so-called linked data vizualization wizard (ldvizwiz).",
            "contribution_ids": [
                "R6524"
            ]
        },
        {
            "instance_id": "R6757xR6316",
            "comparison_id": "R6757",
            "paper_id": "R6316",
            "text": "A HMM-based approach to question answering against linked data in this paper, we present a qa system enabling nl questions against linked data, designed and adopted by the tor vergata university ai group in the qald-3 evaluation. the system integrates lexical semantic modeling and statistical inference within a complex architecture that decomposes the nl interpretation task into a cascade of three different stages: (1) the selection of key ontological information from the question (i.e. predicate, arguments and properties), (2) the location of such salient information in the ontology through the joint disambiguation of the different candidates and (3) the compilation of the final sparql query. this architecture characterizes a novel approach for the task and exploits a graphical model (i.e. an hidden markov model) to select the proper ontological triples according to the graph nature of rdf. in particular, for each query an hmm model is produced whose viterbi solution is the comprehensive joint disambiguation across the sentence elements. the combination of these approaches achieved interesting results in the qald competition. the rtv is in fact within the group of participants performing slightly below the best system, but with smaller requirements and on significantly poorer input information.",
            "contribution_ids": [
                "R6317"
            ]
        },
        {
            "instance_id": "R6757xR6268",
            "comparison_id": "R6757",
            "paper_id": "R6268",
            "text": "Intui2: a prototype system for question answering over linked data an ever increasing amount of linked data is made available every day. public triple stores offer the possibility of querying hundreds of millions of triples. but this information can only be retrieved using specialized query languages like sparql, so for the majority of internet users, it is still unavailable. this paper presents a prototype system aimed at streamlining the access to the information stored as rdf. the system takes as input a natural language question formulated in english and generates an equivalent sparql query. the mapping is based on the analysis of the syntactic patterns present in the input question. in the initial evaluation results, against the 99 questions in the qald-3 dbpedia test set, the system provides a correct answer to 30 questions and a partial answer for another 3 questions, achieving an f-measure of 0.32.",
            "contribution_ids": [
                "R6269"
            ]
        },
        {
            "instance_id": "R6757xR6401",
            "comparison_id": "R6757",
            "paper_id": "R6401",
            "text": "Natural language questions for the web of data the linked data initiative comprises structured databases in the semantic-web data model rdf. exploring this heterogeneous data by structured query languages is tedious and error-prone even for skilled users. to ease the task, this paper presents a methodology for translating natural language questions into structured sparql queries over linked-data sources. \\n \\nour method is based on an integer linear program to solve several disambiguation tasks jointly: the segmentation of questions into phrases; the mapping of phrases to semantic entities, classes, and relations; and the construction of sparql triple patterns. our solution harnesses the rich type system provided by knowledge bases in the web of linked data, to constrain our semantic-coherence objective function. we present experiments on both the question translation and the resulting query answering.",
            "contribution_ids": [
                "R6402"
            ]
        },
        {
            "instance_id": "R68535xR54884",
            "comparison_id": "R68535",
            "paper_id": "R54884",
            "text": "Past warming trend constrains future warming in CMIP6 models strong future warming in some new climate models is less likely as their recent warming is inconsistent with observed trends.",
            "contribution_ids": [
                "R54890",
                "R54893",
                "R54896",
                "R54899",
                "R54901",
                "R54902",
                "R54903",
                "R54904",
                "R54905",
                "R54906",
                "R54907",
                "R54908",
                "R54909",
                "R54910",
                "R54911",
                "R54912",
                "R54913",
                "R54914",
                "R54915",
                "R54916",
                "R54917",
                "R54918",
                "R54919",
                "R54920",
                "R54921",
                "R54922",
                "R54923",
                "R54924",
                "R54925",
                "R54951"
            ]
        },
        {
            "instance_id": "R68871xR23368",
            "comparison_id": "R68871",
            "paper_id": "R23368",
            "text": "Present-Day Atmospheric Simulations Using GISS ModelE: Comparison to In Situ, Satellite, and Reanalysis Data abstract \\n a full description of the modele version of the goddard institute for space studies (giss) atmospheric general circulation model (gcm) and results are presented for present-day climate simulations (ca. 1979). this version is a complete rewrite of previous models incorporating numerous improvements in basic physics, the stratospheric circulation, and forcing fields. notable changes include the following: the model top is now above the stratopause, the number of vertical layers has increased, a new cloud microphysical scheme is used, vegetation biophysics now incorporates a sensitivity to humidity, atmospheric turbulence is calculated over the whole column, and new land snow and lake schemes are introduced. the performance of the model using three configurations with different horizontal and vertical resolutions is compared to quality-controlled in situ data, remotely sensed and reanalysis products. overall, significant improvements over previous models are seen, particularly in upper-atmosphere temperatures and winds, cloud heights, precipitation, and sea level pressure. data\u2013model comparisons continue, however, to highlight persistent problems in the marine stratocumulus regions.",
            "contribution_ids": [
                "R23369"
            ]
        },
        {
            "instance_id": "R6947xR6701",
            "comparison_id": "R6947",
            "paper_id": "R6701",
            "text": "Multi-document summarisation using generic relation extraction experiments are reported that investigate the effect of various source document representations on the accuracy of the sentence extraction phase of a multi-document summarisation task. a novel representation is introduced based on generic relation extraction (gre), which aims to build systems for relation identification and characterisation that can be transferred across domains and tasks without modification of model parameters. results demonstrate performance that is significantly higher than a non-trivial baseline that uses tf*idf-weighted words and at least as good as a comparable but less general approach from the literature. analysis shows that the representations compared are complementary, suggesting that extraction performance could be further improved through system combination.",
            "contribution_ids": [
                "R6702"
            ]
        },
        {
            "instance_id": "R6947xR6712",
            "comparison_id": "R6947",
            "paper_id": "R6712",
            "text": "Understanding Text Corpora with Multiple Facets text visualization becomes an increasingly more important research topic as the need to understand massive-scale textual information is proven to be imperative for many people and businesses. however, it is still very challenging to design effective visual metaphors to represent large corpora of text due to the unstructured and high-dimensional nature of text. in this paper, we propose a data model that can be used to represent most of the text corpora. such a data model contains four basic types of facets: time, category, content (unstructured), and structured facet. to understand the corpus with such a data model, we develop a hybrid visualization by combining the trend graph with tag-clouds. we encode the four types of data facets with four separate visual dimensions. to help people discover evolutionary and correlation patterns, we also develop several visual interaction methods that allow people to interactively analyze text by one or more facets. finally, we present two case studies to demonstrate the effectiveness of our solution in support of multi-faceted visual analysis of text corpora.",
            "contribution_ids": [
                "R6713"
            ]
        },
        {
            "instance_id": "R6947xR6719",
            "comparison_id": "R6947",
            "paper_id": "R6719",
            "text": "ThemeCrowds: multiresolution summaries of twitter usage users of social media sites, such as twitter, rapidly generate large volumes of text content on a daily basis. visual summaries are needed to understand what groups of people are saying collectively in this unstructured text data. users will typically discuss a wide variety of topics, where the number of authors talking about a specific topic can quickly grow or diminish over time, and what the collective is saying about the subject can shift as a situation develops. in this paper, we present a technique that summarises what collections of twitter users are saying about certain topics over time. as the correct resolution for inspecting the data is unknown in advance, the users are clustered hierarchically over a fixed time interval based on the similarity of their posts. the visualisation technique takes this data structure as its input. given a topic, it finds the correct resolution of users at each time interval and provides tags to summarise what the collective is discussing. the technique is tested on a large microblogging corpus, consisting of millions of tweets and over a million users.",
            "contribution_ids": [
                "R6720"
            ]
        },
        {
            "instance_id": "R6947xR6736",
            "comparison_id": "R6947",
            "paper_id": "R6736",
            "text": "Towards Unsupervised Learning of Temporal Relations between Events automatic extraction of temporal relations between event pairs is an important task for several natural language processing applications such as question answering, information extraction, and summarization. since most existing methods are supervised and require large corpora, which for many languages do not exist, we have concentrated our efforts to reduce the need for annotated data as much as possible. this paper presents two different algorithms towards this goal. the first algorithm is a weakly supervised machine learning approach for classification of temporal relations between events. in the first stage, the algorithm learns a general classifier from an annotated corpus. then, inspired by the hypothesis of \"one type of temporal relation per discourse\\'\\', it extracts useful information from a cluster of topically related documents. we show that by combining the global information of such a cluster with local decisions of a general classifier, a bootstrapping cross-document classifier can be built to extract temporal relations between events. our experiments show that without any additional annotated data, the accuracy of the proposed algorithm is higher than that of several previous successful systems. the second proposed method for temporal relation extraction is based on the expectation maximization (em) algorithm. within em, we used different techniques such as a greedy best-first search and integer linear programming for temporal inconsistency removal. we think that the experimental results of our em based algorithm, as a first step toward a fully unsupervised temporal relation extraction method, is encouraging.",
            "contribution_ids": [
                "R6737"
            ]
        },
        {
            "instance_id": "R6947xR6743",
            "comparison_id": "R6947",
            "paper_id": "R6743",
            "text": "UWN: A Large Multilingual Lexical Knowledge Base we present uwn, a large multilingual lexical knowledge base that describes the meanings and relationships of words in over 200 languages. this paper explains how link prediction, information integration and taxonomy induction methods have been used to build uwn based on wordnet and extend it with millions of named entities from wikipedia. we additionally introduce extensions to cover lexical relationships, frame-semantic knowledge, and language data. an online interface provides human access to the data, while a software api enables applications to look up over 16 million words and names.",
            "contribution_ids": [
                "R6744"
            ]
        },
        {
            "instance_id": "R6948xR6571",
            "comparison_id": "R6948",
            "paper_id": "R6571",
            "text": "Trainable, scalable summarization using robust NLP and machine learning we describe a trainable and scalable summarization system which utilizes features derived from information retrieval, information extraction, and nlp techniques and on-line resources. the system combines these features using a trainable feature combiner learned from summary examples through a machine learning algorithm. we demonstrate system scalability by reporting results on the best combination of summarization features for different document sources. we also present preliminary results from a task-based evaluation on summarization output usability.",
            "contribution_ids": [
                "R6572"
            ]
        },
        {
            "instance_id": "R6948xR6593",
            "comparison_id": "R6948",
            "paper_id": "R6593",
            "text": "NewsInEssence: A System For Domain-Independent, Real-Time News Clustering and Multi-Document Summarization newsinessence is a system for finding, visualizing and summarizing a topic-based cluster of news stories. in the generic scenario for newsinessence, a user selects a single news story from a news web site. our system then searches other live sources of news for other stories related to the same event and produces summaries of a subset of the stories that it finds, according to parameters specified by the user.",
            "contribution_ids": [
                "R6594"
            ]
        },
        {
            "instance_id": "R6948xR6599",
            "comparison_id": "R6948",
            "paper_id": "R6599",
            "text": "Automated multi-document summarization in NeATS this paper describes the multi-document text summarization system neats. using a simple algorithm, neats was among the top two performers of the duc-01 evaluation.",
            "contribution_ids": [
                "R6600"
            ]
        },
        {
            "instance_id": "R69680xR69558",
            "comparison_id": "R69680",
            "paper_id": "R69558",
            "text": "A framework for explainable deep neural models using external knowledge graphs deep neural networks (dnns) have become the gold standard for solving challenging classification problems, especially given complex sensor inputs (e.g., images and video). while dnns are powerful, they are also brittle, and their inner workings are not fully understood by humans, leading to their use as \u201cblack-box\u201d models. dnns often generalize poorly when provided new data sampled from slightly shifted distributions; dnns are easily manipulated by adversarial examples; and the decision-making process of dnns can be difficult for humans to interpret. to address these challenges, we propose integrating dnns with external sources of semantic knowledge. large quantities of meaningful, formalized knowledge are available in knowledge graphs and other databases, many of which are publicly obtainable. but at present, these sources are inaccessible to deep neural methods, which can only exploit patterns in the signals they are given to classify. in this work, we conduct experiments on the ade20k dataset, using scene classification as an example task where combining dnns with external knowledge graphs can result in more robust and explainable models. we align the atomic concepts present in ade20k (i.e., objects) to wordnet, a hierarchically-organized lexical database. using this knowledge graph, we expand the concept categories which can be identified in ade20k and relate these concepts in a hierarchical manner. the neural architecture we present performs scene classification using these concepts, illuminating a path toward dnns which can efficiently exploit high-level knowledge in place of excessive quantities of direct sensory input. we hypothesize and experimentally validate that incorporating background knowledge via an external knowledge graph into a deep learning-based model should improve the explainability and robustness of the model.",
            "contribution_ids": [
                "R69559"
            ]
        },
        {
            "instance_id": "R69680xR69572",
            "comparison_id": "R69680",
            "paper_id": "R69572",
            "text": "Linking imagenet-wordnet synsets with wikidata the linkage of imagenet wordnet synsets to wikidata items will leverage deep learning algorithm with access to a rich multilingual knowledge graph. here i will describe our on-going efforts in linking the two resources and issues faced in matching the wikidata and wordnet knowledge graphs. i show an example on how the linkage can be used in a deep learning setting with real-time image classification and labeling in a non-english language and discuss what opportunities lies ahead.",
            "contribution_ids": [
                "R69573"
            ]
        },
        {
            "instance_id": "R69680xR69577",
            "comparison_id": "R69680",
            "paper_id": "R69577",
            "text": "Knowledgeable reader: Enhancing cloze-style read- ing comprehension with external commonsense knowledge we introduce a neural reading comprehension model that integrates external commonsense knowledge, encoded as a key-value memory, in a cloze-style setting. instead of relying only on document-to-question interaction or discrete features as in prior work, our model attends to relevant external knowledge and combines this knowledge with the context representation before inferring the answer. this allows the model to attract and imply knowledge from an external knowledge source that is not explicitly stated in the text, but that is relevant for inferring the answer. our model improves results over a very strong baseline on a hard common nouns dataset, making it a strong competitor of much more complex models. by including knowledge explicitly, our model can also provide evidence about the background knowledge used in the rc process.",
            "contribution_ids": [
                "R69578"
            ]
        },
        {
            "instance_id": "R69680xR69597",
            "comparison_id": "R69680",
            "paper_id": "R69597",
            "text": "Fvqa: Fact-based visual question answering visual question answering (vqa) has attracted much attention in both computer vision and natural language processing communities, not least because it offers insight into the relationships between two important sources of information. current datasets, and the models built upon them, have focused on questions which are answerable by direct analysis of the question and image alone. the set of such questions that require no external information to answer is interesting, but very limited. it excludes questions which require common sense, or basic factual knowledge to answer, for example. here we introduce fvqa (fact-based vqa), a vqa dataset which requires, and supports, much deeper reasoning. fvqa primarily contains questions that require external information to answer. we thus extend a conventional visual question answering dataset, which contains image-question-answer triplets, through additional image-question-answer-supporting fact tuples. each supporting-fact is represented as a structural triplet, such as . we evaluate several baseline models on the fvqa dataset, and describe a novel model which is capable of reasoning about an image on the basis of supporting-facts.",
            "contribution_ids": [
                "R69598"
            ]
        },
        {
            "instance_id": "R69680xR69601",
            "comparison_id": "R69680",
            "paper_id": "R69601",
            "text": "Out of the box: Reasoning with graph convolution nets for factual visual question answering \"accurately answering a question about a given image requires combining observations with general knowledge. while this is effortless for humans, reasoning with general knowledge remains an algorithmic challenge. to advance research in this direction a novel `fact-based' visual question answering (fvqa) task has been introduced recently along with a large set of curated facts which link two entities, i.e., two possible answers, via a relation. given a question-image pair, deep network techniques have been employed to successively reduce the large set of facts until one of the two entities of the final remaining fact is predicted as the answer. we observe that a successive process which considers one fact at a time to form a local decision is sub-optimal. instead, we develop an entity graph and use a graph convolutional network to `reason' about the correct answer by jointly considering all entities. we show on the challenging fvqa dataset that this leads to an improvement in accuracy of around 7% compared to the state of the art.\"",
            "contribution_ids": [
                "R69602"
            ]
        },
        {
            "instance_id": "R69680xR69611",
            "comparison_id": "R69680",
            "paper_id": "R69611",
            "text": "Algorithmic transparency of conversational agents a lack of algorithmic transparency is a major barrier to the adoption of artificial intelligence technologies within contexts which require high risk and high consequence decision making. in this paper we present a framework for providing transparency of algorithmic processes. we include important considerations not identified in research to date for the high risk and high consequence context of defence intelligence analysis. to demonstrate the core concepts of our framework we explore an example application (a conversational agent for knowledge exploration) which demonstrates shared human-machine reasoning in a critical decision making scenario. we include new findings from interviews with a small number of analysts and recommendations for future \\nresearch.",
            "contribution_ids": [
                "R69612"
            ]
        },
        {
            "instance_id": "R69680xR69619",
            "comparison_id": "R69680",
            "paper_id": "R69619",
            "text": "Knowledge-driven stock trend prediction and explanation via temporal convolutional network deep neural networks have achieved promising results in stock trend prediction. however, most of these models have two common drawbacks, including (i) current methods are not sensitive enough to abrupt changes of stock trend, and (ii) forecasting results are not interpretable for humans. to address these two problems, we propose a novel knowledge-driven temporal convolutional network (kdtcn) for stock trend prediction and explanation. firstly, we extract structured events from financial news, and utilize external knowledge from knowledge graph to obtain event embeddings. then, we combine event embeddings and price values together to forecast stock trend. we evaluate the prediction accuracy to show how knowledge-driven events work on abrupt changes. we also visualize the effect of events and linkage among events based on knowledge graph, to explain why knowledge-driven events are common sources of abrupt changes. experiments demonstrate that kdtcn can (i) react to abrupt changes much faster and outperform state-of-the-art methods on stock datasets, as well as (ii) facilitate the explanation of prediction particularly with abrupt changes.",
            "contribution_ids": [
                "R69620"
            ]
        },
        {
            "instance_id": "R69680xR69626",
            "comparison_id": "R69680",
            "paper_id": "R69626",
            "text": "Semantic explanations of predictions the main objective of explanations is to transmit knowledge to humans. this work proposes to construct informative explanations for predictions made from machine learning models. motivated by the observations from social sciences, our approach selects data points from the training sample that exhibit special characteristics crucial for explanation, for instance, ones contrastive to the classification prediction and ones representative of the models. subsequently, semantic concepts are derived from the selected data points through the use of domain ontologies. these concepts are filtered and ranked to produce informative explanations that improves human understanding. the main features of our approach are that (1) knowledge about explanations is captured in the form of ontological concepts, (2) explanations include contrastive evidences in addition to normal evidences, and (3) explanations are user relevant.",
            "contribution_ids": [
                "R69627"
            ]
        },
        {
            "instance_id": "R69680xR69641",
            "comparison_id": "R69680",
            "paper_id": "R69641",
            "text": "Explod: a framework for explaining recommendations based on the linked open data cloud in this paper we present explod, a framework which exploits the information available in the linked open data (lod) cloud to generate a natural language explanation of the suggestions produced by a recommendation algorithm. the methodology is based on building a graph in which the items liked by a user are connected to the items recommended through the properties available in the lod cloud. next, given this graph, we implemented some techniques to rank those properties and we used the most relevant ones to feed a module for generating explanations in natural language. in the experimental evaluation we performed a user study with 308 subjects aiming to investigate to what extent our explanation framework can lead to more transparent, trustful and engaging recommendations. the preliminary results provided us with encouraging findings, since our algorithm performed better than both a non-personalized explanation baseline and a popularity-based one.",
            "contribution_ids": [
                "R69642"
            ]
        },
        {
            "instance_id": "R69680xR69653",
            "comparison_id": "R69680",
            "paper_id": "R69653",
            "text": "Using taxonomies to facilitate the analysis of the association rules the data mining process enables the end users to analyze, understand and use the extracted knowledge in an intelligent system or to support in the decision-making processes. however, many algorithms used in the process encounter large quantities of patterns, complicating the analysis of the patterns. this fact occurs with association rules, a data mining technique that tries to identify intrinsic patterns in large data sets. a method that can help the analysis of the association rules is the use of taxonomies in the step of post-processing knowledge. in this paper, the gart algorithm is proposed, which uses taxonomies to generalize association rules, and the rulee-gar computational module, that enables the analysis of the generalized rules.",
            "contribution_ids": [
                "R69654"
            ]
        },
        {
            "instance_id": "R69680xR69663",
            "comparison_id": "R69680",
            "paper_id": "R69663",
            "text": "Semantic text mining with linked data linked data is an open data space that emerges from the publication and interlinking of structured data on the web using the semantic web technologies. how to utilize this wealth of data is currently a focused research theme of the semantic web community. in this paper, we aim to utilize linked data to generate semantic annotations for frequent patterns extracted from textual documents. first, we extract semantic relations from textual documents and merge them into a set of semantic graphs. then, we apply a frequent subgraph discovery algorithm on the set of graphs to generate frequent patterns. finally, we annotate the discovered patterns using linked data. our approach can be applied in such domains as terrorist network analysis and biological network analysis. the efficacy of our approach is demonstrated through an empirical experiment that discovers and validates relationships between political figures from large number of news on the web.",
            "contribution_ids": [
                "R69664"
            ]
        },
        {
            "instance_id": "R70287xR51252",
            "comparison_id": "R70287",
            "paper_id": "R51252",
            "text": "Identification of inhibitors of SARS-CoV-2 in-vitro cellular toxicity in human (Caco-2) cells using a large scale drug repurposing collection abstract \\n to identify possible candidates for progression towards clinical studies against sars-cov-2, we screened a well-defined collection of 5632 compounds including 3488 compounds which have undergone clinical investigations (marketed drugs, phases 1 -3, and withdrawn) across 600 indications. compounds were screened for their inhibition of viral induced cytotoxicity using the human epithelial colorectal adenocarcinoma cell line caco-2 and a sars-cov-2 isolate. the primary screen of 5632 compounds gave 271 hits. a total of 64 compounds with ic50 &lt;20 \u00b5m were identified, including 19 compounds with ic50 &lt; 1 \u00b5m. of this confirmed hit population, 90% have not yet been previously reported as active against sars-cov-2 in-vitro cell assays. some 37 of the actives are launched drugs, 19 are in phases 1-3 and 10 pre-clinical. several inhibitors were associated with modulation of host pathways including kinase signaling p53 activation, ubiquitin pathways and pde activity modulation, with long chain acyl transferases were effective viral inhibitors.",
            "contribution_ids": [
                "R51254"
            ]
        },
        {
            "instance_id": "R70287xR51386",
            "comparison_id": "R70287",
            "paper_id": "R51386",
            "text": "In vitro screening of a FDA approved chemical library reveals potential inhibitors of SARS-CoV-2 replication abstract a novel coronavirus, named sars-cov-2, emerged in 2019 in china and rapidly spread worldwide. as no approved therapeutics exists to treat covid-19, the disease associated to sars-cov-2, there is an urgent need to propose molecules that could quickly enter into clinics. repurposing of approved drugs is a strategy that can bypass the time-consuming stages of drug development. in this study, we screened the prestwick chemical library composed of 1,520 approved drugs in an infected cell-based assay. the robustness of the screen was assessed by the identification of drugs that already demonstrated in vitro antiviral effect against sars-cov-2. thereby, 90 compounds were identified as positive hits from the screen and were grouped according to their chemical composition and their known therapeutic effect. then ec50 and cc50 were determined for a subset of 15 compounds from a panel of 23 selected drugs covering the different groups. eleven compounds such as macrolides antibiotics, proton pump inhibitors, antiarrhythmic agents or cns drugs emerged showing antiviral potency with 2\\u2009&lt;\\u2009ec50\\u2009\u2264\\u200920\\xa0\u00b5m. by providing new information on molecules inhibiting sars-cov-2 replication in vitro, this study provides information for the selection of drugs to be further validated in vivo. disclaimer: this study corresponds to the early stages of antiviral development and the results do not support by themselves the use of the selected drugs to treat sars-cov-2 infection.",
            "contribution_ids": [
                "R51388",
                "R51404"
            ]
        },
        {
            "instance_id": "R70287xR70068",
            "comparison_id": "R70287",
            "paper_id": "R70068",
            "text": "Identification of potential treatments for COVID-19 through artificial intelligence-enabled phenomic analysis of human cells infected with SARS-CoV-2 abstract to identify potential therapeutic stop-gaps for sars-cov-2, we evaluated a library of 1,670 approved and reference compounds in an unbiased, cellular image-based screen for their ability to suppress the broad impacts of the sars-cov-2 virus on phenomic profiles of human renal cortical epithelial cells using deep learning. in our assay, remdesivir is the only antiviral tested with strong efficacy, neither chloroquine nor hydroxychloroquine have any beneficial effect in this human cell model, and a small number of compounds not currently being pursued clinically for sars-cov-2 have efficacy. we observed weak but beneficial class effects of \u03b2-blockers, mtor/pi3k inhibitors and vitamin d analogues and a mild amplification of the viral phenotype with \u03b2-agonists.",
            "contribution_ids": [
                "R70069"
            ]
        },
        {
            "instance_id": "R70584xR70566",
            "comparison_id": "R70584",
            "paper_id": "R70566",
            "text": "From vital signs to clinical outcomes for patients with sepsis: a machine learning basis for a clinical decision support system \"objective\\nto develop a decision support system to identify patients at high risk for hyperlactatemia based upon routinely measured vital signs and laboratory studies.\\n\\n\\nmaterials and methods\\nelectronic health records of 741 adult patients at the university of california davis health system who met at least two systemic inflammatory response syndrome criteria were used to associate patients' vital signs, white blood cell count (wbc), with sepsis occurrence and mortality. generative and discriminative classification (na\u00efve bayes, support vector machines, gaussian mixture models, hidden markov models) were used to integrate heterogeneous patient data and form a predictive tool for the inference of lactate level and mortality risk.\\n\\n\\nresults\\nan accuracy of 0.99 and discriminability of 1.00 area under the receiver operating characteristic curve (auc) for lactate level prediction was obtained when the vital signs and wbc measurements were analysed in a 24 h time bin. an accuracy of 0.73 and discriminability of 0.73 auc for mortality prediction in patients with sepsis was achieved with only three features: median of lactate levels, mean arterial pressure, and median absolute deviation of the respiratory rate.\\n\\n\\ndiscussion\\nthis study introduces a new scheme for the prediction of lactate levels and mortality risk from patient vital signs and wbc. accurate prediction of both these variables can drive the appropriate response by clinical staff and thus may have important implications for patient health and treatment outcome.\\n\\n\\nconclusions\\neffective predictions of lactate levels and mortality risk can be provided with a few clinical variables when the temporal aspect and variability of patient data are considered.\"",
            "contribution_ids": [
                "R70567",
                "R70583"
            ]
        },
        {
            "instance_id": "R70605xR70585",
            "comparison_id": "R70605",
            "paper_id": "R70585",
            "text": "Development and validation of a Clostridium difficile infection risk prediction model \"objective. to develop and validate a risk prediction model that could identify patients at high risk for clostridium difficile infection (cdi) before they develop disease. design and setting. retrospective cohort study in a tertiary care medical center. patients. patients admitted to the hospital for at least 48 hours during the calendar year 2003. methods. data were collected electronically from the hospital's medical informatics database and analyzed with logistic regression to determine variables that best predicted patients' risk for development of cdi. model discrimination and calibration were calculated. the model was bootstrapped 500 times to validate the predictive accuracy. a receiver operating characteristic curve was calculated to evaluate potential risk cutoffs. results. a total of 35,350 admitted patients, including 329 with cdi, were studied. variables in the risk prediction model were age, cdi pressure, times admitted to hospital in the previous 60 days, modified acute physiology score, days of treatment with high-risk antibiotics, whether albumin level was low, admission to an intensive care unit, and receipt of laxatives, gastric acid suppressors, or antimotility drugs. the calibration and discrimination of the model were very good to excellent (c index, 0.88; brier score, 0.009). conclusions. the cdi risk prediction model performed well. further study is needed to determine whether it could be used in a clinical setting to prevent cdi-associated outcomes and reduce costs.\"",
            "contribution_ids": [
                "R70586"
            ]
        },
        {
            "instance_id": "R70630xR70626",
            "comparison_id": "R70630",
            "paper_id": "R70626",
            "text": "Data-driven Temporal Prediction of Surgical Site Infection analysis of data from electronic health records (ehr) presents unique challenges, in particular regarding nonuniform temporal resolution of longitudinal variables. a considerable amount of patient information is available in the ehr - including blood tests that are performed routinely during inpatient follow-up. these data are useful for the design of advanced machine learning-based methods and prediction models. using a matched cohort of patients undergoing gastrointestinal surgery (101 cases and 904 controls), we built a prediction model for post-operative surgical site infections (ssis) using gaussian process (gp) regression, time warping and imputation methods to manage the sparsity of the data source, and support vector machines for classification. for most blood tests, wider confidence intervals after imputation were obtained in patients with ssi. predictive performance with individual blood tests was maintained or improved by joint model prediction, and non-linear classifiers performed consistently better than linear models.",
            "contribution_ids": [
                "R70627"
            ]
        },
        {
            "instance_id": "R8342xR8301",
            "comparison_id": "R8342",
            "paper_id": "R8301",
            "text": "The Document Components Ontology (DoCO) the availability in machine-readable form of descriptions of the structure of documents, as well as of the document\\ndiscourse (e.g. the scientific discourse within scholarly articles), is crucial for facilitating semantic publishing and the overall\\ncomprehension of documents by both users and machines. in this paper we introduce doco, the document components ontology,\\nan owl 2 dl ontology that provides a general-purpose structured vocabulary of document elements to describe both structural and\\nrhetorical document components in rdf. in addition to describing the formal description of the ontology, this paper showcases its\\nutility in practice in a variety of our own applications and other activities of the semantic publishing community that rely on doco\\nto annotate and retrieve document components of scholarly articles.",
            "contribution_ids": [
                "R8302"
            ]
        },
        {
            "instance_id": "EMPTYxR8245",
            "comparison_id": "EMPTY",
            "paper_id": "R8245",
            "text": "Knowledge base shipping to the linked open data cloud popular knowledge bases that provide sparql endpoints for the web are usually experiencing a high number of requests, which often results in low availability of their interfaces. a common approach to counter the availability issue is to run a local mirror of the knowledge base. running a sparql endpoint is currently a complex task which requires a lot of effort and technical support for domain experts who just want to use the sparql interface. with our approach of containerised knowledge base shipping we are introducing a simple to setup methodology for running a local mirror of an rdf knowledge base and sparql endpoint with interchangeable exploration components. the flexibility of the presented approach further helps maintaining the publication infrastructure for dataset projects. we are demonstrating and evaluating the presented methodology at the example of the dataset projects dbpedia, catalogus professorum lipsiensium and s\u00e4chsisches pfarrerbuch.",
            "contribution_ids": [
                "R8246",
                "R8249"
            ]
        },
        {
            "instance_id": "EMPTYxR108224",
            "comparison_id": "EMPTY",
            "paper_id": "R108224",
            "text": "Linking Business Goals to Process Models in Semantic Business Process Modeling broad knowledge is required when a business process is modeled by a business analyst. we argue that existing business process management methodologies do not consider business goals at the appropriate level. in this paper we present an approach to integrate business goals and business process models. we design a business goal ontology for modeling business goals. furthermore, we devise a modeling pattern for linking the goals to process models and show how the ontology can be used in query answering. in this way, we integrate the intentional perspective into our business process ontology framework, enriching the process description and enabling new types of business process analysis.",
            "contribution_ids": [
                "R108226"
            ]
        },
        {
            "instance_id": "EMPTYxR110487",
            "comparison_id": "EMPTY",
            "paper_id": "R110487",
            "text": "An analysis of Service Level Agreement parameters and scheduling in Multi-Tenant Cloud Systems in cloud systems it usually the case that there exists a multi-tenancy of cloud service customers meaning that some cloud service customers applications share the same cloud infrastructure. in this situation there must exist a service level agreement (sla) contract between the multi-tenant cloud service provider (mtcsp) and the cloud service customers (cscs). in this article we discuss about the parameters of an sla in the cloud and we particularize it in the case of multi-tenancy. we analyze and implement two algorithms with the purpose of optimizing the scheduling of tasks from the tenants of the multi-tenant cloud service. the results show that the algorithms can be used in different situations with good results.",
            "contribution_ids": [
                "R110489"
            ]
        },
        {
            "instance_id": "EMPTYxR78214",
            "comparison_id": "EMPTY",
            "paper_id": "R78214",
            "text": "Textural and Heavy Minerals Characterization of Coastal Sediments in Ibeno and Eastern Obolo Local Government Areas of Akwa Ibom State \u2013 Nigeria textural characterization and heavy mineral studies of beach sediments in ibeno and eastern obolo local government areas of akwa ibom state were carried out in the present study. the main aim was to infer their provenance, transport history and environment of deposition. sediment samples were collected at the water\u2013sediment contact along the shoreline at an interval of about 3m. ten samples were collected from study location 1 (ibeno beach) and twelve samples were collected from study location 2 (eastern obolo beach). a total of twenty\u2013two samples were collected from the field and brought to the laboratory for textural and compositional analyses. the results showed that the value of graphic mean size ranged from 1.70\u0444 to 2.83\u0444, sorting values ranged from 0.39\u0444 \u2013 0.60\u0444, skewness values ranged from -0.02 to 0.10 while kurtosis values ranged from 1.02 to 2.46, indicating medium to fine grained and well sorted sediments. this suggested that the sediments have been transported far from their source. longshore current and onshore\u2013offshore movements of sediment are primarily responsible in sorting of the heavy minerals. the histogram charts for the different samples and standard deviation versus skewness indicated a beach environment of deposition. this implies that the sediments are dominated by one class of grain size; a phenomenon characteristic of beach environments. the heavy mineral assemblages identified in this research work were rutile, zircon, tourmaline, hornblende, apatite, diopside, glauconite, pumpellyite, cassiterite, epidote, garnet, augite, enstatite, andalusite and opaque minerals. the zircon-tourmaline-rutile (ztr) index ranged from 47.30% to 87.00% with most of the samples showing a ztr index greater than 50%. these indicated that the sediments were mineralogically sub-mature and have been transported far from their source. the heavy minerals identified are indicative of being products of reworked sediments of both metamorphic (high rank) and igneous (both mafic and sialic) origin probably derived from the basement rocks of the oban massif as well as reworked sediments of the benue trough. therefore, findings from the present study indicated that erosion, accretion, and stability of beaches are controlled by strong hydrodynamic and hydraulic processes.",
            "contribution_ids": [
                "R78216",
                "R78222"
            ]
        },
        {
            "instance_id": "EMPTYxR141328",
            "comparison_id": "EMPTY",
            "paper_id": "R141328",
            "text": "High new production in the Bay of Bengal: Possible causes and implications we report the first measurements of new production (15n tracer technique), the component of primary production that sustains on extraneous nutrient inputs to the euphotic zone, in the bay of bengal. experiments done in two different seasons consistently show high new production (averaging around 4 mmol n m\u22122 d\u22121 during post monsoon and 5.4 mmol n m\u22122 d\u22121 during pre monsoon), validating the earlier conjecture of high new production, based on pco2 measurements, in the bay. averaged over annual time scales, higher new production could cause higher rate of removal of organic carbon. this could also be one of the reasons for comparable organic carbon fluxes observed in the sediment traps of the bay of bengal and the eastern arabian sea. thus, oceanic regions like bay of bengal may play a more significant role in removing the excess co2 from the atmosphere than hitherto believed.",
            "contribution_ids": [
                "R141329"
            ]
        },
        {
            "instance_id": "EMPTYxR3000",
            "comparison_id": "EMPTY",
            "paper_id": "R3000",
            "text": "A model for contextual data sharing in smartphone applications \\n purpose \\n the purpose of this paper is to introduce a model for identifying, storing and sharing contextual information across smartphone apps that uses the native device services. the authors present the idea of using user input and interaction within an app as contextual information, and how each app can identify and store contextual information. \\n \\n \\n design/methodology/approach \\n contexts are modeled as hierarchical objects that can be stored and shared by applications using native mechanisms. a proof-of-concept implementation of the model for the android platform demonstrates contexts modelled as hierarchical objects stored and shared by applications using native mechanisms. \\n \\n \\n findings \\n the model was found to be practically viable by implemented sample apps that share context and through a performance analysis of the system. \\n \\n \\n practical implications \\n the contextual data-sharing model enables the creation of smart apps and services without being tied to any vendor\u2019s cloud services. \\n \\n \\n originality/value \\n this paper introduces a new approach for sharing context in smartphone applications that does not require cloud services. \\n",
            "contribution_ids": [
                "R3005"
            ]
        },
        {
            "instance_id": "EMPTYxR38066",
            "comparison_id": "EMPTY",
            "paper_id": "R38066",
            "text": "Ontology-based exchange of product data semantics an increasing trend toward product development in a collaborative environment has resulted in the use of various software tools to enhance the product design. this requires a meaningful representation and exchange of product data semantics across different application domains. this paper proposes an ontology-based framework to enable such semantic interoperability. a standards-based approach is used to develop a product semantic representation language (psrl). formal description logic (daml+oil) is used to encode the psrl. mathematical logic and corresponding reasoning is used to determine semantic equivalences between an application ontology and the psrl. the semantic equivalence matrix enables resolution of ambiguities created due to differences in syntaxes and meanings associated with terminologies in different application domains. successful semantic interoperability will form the basis of seamless communication and thereby enable better integration of product development systems. note to practitioners-semantic interoperability of product information refers to automating the exchange of meaning associated with the data, among information resources throughout the product development. this research is motivated by the problems in enabling such semantic interoperability. first, product information is formalized into an explicit, extensible, and comprehensive product semantics representation language (psrl). the psrl is open and based on standard w3c constructs. next, in order to enable semantic translation, the paper describes a procedure to semi-automatically determine mappings between exactly equivalent concepts across representations of the interacting applications. the paper demonstrates that this approach to translation is feasible, but it has not yet been implemented commercially. current limitations and the directions for further research are discussed. future research addresses the determination of semantic similarities (not exact equivalences) between the interacting information resources.",
            "contribution_ids": [
                "R38068"
            ]
        },
        {
            "instance_id": "EMPTYxR38074",
            "comparison_id": "EMPTY",
            "paper_id": "R38074",
            "text": "OntoIMM: An Ontology for Product Intelligent Master Model information organizing principle is one of the key issues of intelligent master model (imm), which is an enhancement of the master model (mm) based on kbe (knowledge-based engineering). despite the fact that the core product model (cpm) has been confirmed to be an organizing mechanism for product master model, the key issue of supporting the information organizing for imm is not yet well addressed, mainly due to the following two reasons; (1) lack of representation of complete information and knowledge with regard to product and process, including the know-why, know-how, and know-what information and knowledge, and (2) lack of semantic richness. therefore, a multiaspect extension to cpm was first defined, and then an ontology was constructed to represent the information and design knowledge. the extension refers to adding a design process model, context model, product control structure model, and design rationale model to cpm concerning the enhancement of master model, which is to comprehensively represent the reason, process, and result information and knowledge of theproduct. the ontology construction refers to representing the concepts, relationships among these concepts and consistency rules of imm information structure. finally, an example of barrel design and analysis process is illustrated to verify the effectiveness of proposed method.",
            "contribution_ids": [
                "R38076"
            ]
        },
        {
            "instance_id": "EMPTYxR159789",
            "comparison_id": "EMPTY",
            "paper_id": "R159789",
            "text": "The Potential of Using Vision Videos for CrowdRE: Video Comments as a Source of Feedback vision videos are established for soliciting feedback and stimulating discussions in requirements engineering (re) practices such as focus groups. different researchers motivated the transfer of these benefits into crowd-based re (crowdre) by using vision videos on social media platforms. so far, however, little research explored the potential of using vision videos for crowdre in detail. in this paper, we analyze and assess this potential, in particular, focusing on video comments as a source of feedback. in a case study, we analyzed 4505 comments on a vision video from youtube. we found that the video solicited 2770 comments from 2660 viewers in four days. this is more than 50% of all comments the video received in four years. even though only a certain fraction of these comments are relevant to re, the relevant comments address typical intentions and topics of user feedback, such as feature request or problem report. besides the typical user feedback categories, we found more than 300 comments that address the topic safety which has not appeared in previous analyses of user feedback. in an automated analysis, we compared the performance of three machine learning algorithms on classifying the video comments. despite certain differences, the algorithms classified the video comments well. based on these findings, we conclude that the use of vision videos for crowdre has a large potential. despite the preliminary nature of the case study, we are optimistic that vision videos can motivate stakeholders to actively participate in a crowd and solicit numerous of video comments as a valuable source of feedback.",
            "contribution_ids": [
                "R175000"
            ]
        },
        {
            "instance_id": "EMPTYxR74547",
            "comparison_id": "EMPTY",
            "paper_id": "R74547",
            "text": "Supporting Requirements Elicitation by Tool-Supported Video Analysis \"workshops are an established technique for requirements elicitation. a lot of information is revealed during a workshop, which is generally captured via textual minutes. the scribe suffers from a cognitive overload due to the difficulty of gathering all information, listening and writing at the same time. video recording is used as additional option to capture more information, including non-verbal gestures. since a workshop can take several hours, the recorded video will be long and may be disconnected from the scribe's notes. therefore, the weak and unclear structure of the video complicates the access to the recorded information, for example in subsequent requirements engineering activities. we propose the combination of textual minutes and video with a software tool. our objective is connecting textual notes with the corresponding part of the video. by highlighting relevant sections of a video and attaching notes that summarize those sections, a more useful structure can be achieved. this structure allows an easy and fast access to the relevant information and their corresponding video context. thus, a scribe's overload can be mitigated and further use of a video can be simplified. tool-supported analysis of such an enriched video can facilitate the access to all communicated information of a workshop. this allows an easier elicitation of high-quality requirements. we performed a preliminary evaluation of our approach in an experimental set-up with 12 participants. they were able to elicit higher-quality requirements with our software tool.\"",
            "contribution_ids": [
                "R74549",
                "R74593",
                "R172612",
                "R198908"
            ]
        },
        {
            "instance_id": "EMPTYxR75435",
            "comparison_id": "EMPTY",
            "paper_id": "R75435",
            "text": "MapReduce: simplified data processing on large clusters \" \\n mapreduce is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. users specify the computation in terms of a\\n map \\n and a\\n reduce \\n function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. programmers find the system easy to use: more than ten thousand distinct mapreduce programs have been implemented internally at google over the past four years, and an average of one hundred thousand mapreduce jobs are executed on google's clusters every day, processing a total of more than twenty petabytes of data per day.\\n \"",
            "contribution_ids": [
                "R75437"
            ]
        },
        {
            "instance_id": "EMPTYxR76341",
            "comparison_id": "EMPTY",
            "paper_id": "R76341",
            "text": "The Crowd in Requirements Engineering: The Landscape and Challenges crowd-based requirements engineering (crowdre) could significantly change re. performing re activities such as elicitation with the crowd of stakeholders turns re into a participatory effort, leads to more accurate requirements, and ultimately boosts software quality. although any stakeholder in the crowd can contribute, crowdre emphasizes one stakeholder group whose role is often trivialized: users. crowdre empowers the management of requirements, such as their prioritization and segmentation, in a dynamic, evolved style through collecting and harnessing a continuous flow of user feedback and monitoring data on the usage context. to analyze the large amount of data obtained from the crowd, automated approaches are key. this article presents current research topics in crowdre; discusses the benefits, challenges, and lessons learned from projects and experiments; and assesses how to apply the methods and tools in industrial contexts. this article is part of a special issue on crowdsourcing for software engineering.",
            "contribution_ids": [
                "R76343"
            ]
        },
        {
            "instance_id": "EMPTYxR108344",
            "comparison_id": "EMPTY",
            "paper_id": "R108344",
            "text": "How We Refactor, and How We Know It much of what we know about how programmers refactor in the wild is based on studies that examine just a few software projects. researchers have rarely taken the time to replicate these studies in other contexts or to examine the assumptions on which they are based. to help put refactoring research on a sound scientific basis, we draw conclusions using four data sets spanning more than 13 000 developers, 240 000 tool-assisted refactorings, 2500 developer hours, and 3400 version control commits. using these data, we cast doubt on several previously stated assumptions about how programmers refactor, while validating others. for example, we find that programmers frequently do not indicate refactoring activity in commit logs, which contradicts assumptions made by several previous researchers. in contrast, we were able to confirm the assumption that programmers do frequently intersperse refactoring with other program changes. by confirming assumptions and replicating studies made by other researchers, we can have greater confidence that those researchers' conclusions are generalizable.",
            "contribution_ids": [
                "R108346"
            ]
        },
        {
            "instance_id": "EMPTYxR108347",
            "comparison_id": "EMPTY",
            "paper_id": "R108347",
            "text": "The Usability (or Not) of Refactoring Tools although software developers typically have access to numerous refactoring tools, most developers avoid using these tools despite their benefits. researchers have identified many reasons for the disuse of refactoring tools, including a lack of awareness by the developers, a lack of predictability of the tools, and a lack of need for the tools. in this paper, we build on this earlier work and employ the iso 9241-11 definition of usability to develop a theory of usability for refactoring tools. we investigate existing refactoring tools using this theory by analyzing how 17 developers experience refactoring tools in three software change tasks we asked them to perform. we analyze qualitatively the resulting interview transcripts based on our theory and report on a number of observations that can inform tool designers interested in improving the usability of refactoring tools. for instance, we found a desire for developers to guide how a refactoring tool changes the code and a need for refactoring tools to describe changes made to developers. refactoring tools are currently expected to preserve program behavior. these observations indicate that it may be necessary to give developers more control over this property, including the ability to relax it, for the tools to be usable; that is, for the tools to be effective, efficient and satisfying for the developer to employ.",
            "contribution_ids": [
                "R108349"
            ]
        },
        {
            "instance_id": "EMPTYxR108350",
            "comparison_id": "EMPTY",
            "paper_id": "R108350",
            "text": "Improving Usability of Software Refactoring Tools \"post-deployment maintenance and evolution can account for up to 75% of the cost of developing a software system. software refactoring can reduce the costs associated with evolution by improving system quality. although refactoring can yield benefits, the process includes potentially complex, error-prone, tedious and time-consuming tasks. it is these tasks that automated refactoring tools seek to address. however, although the refactoring process is well-defined, current refactoring tools do not support the full process. to develop better automated refactoring support, we have completed a usability study of software refactoring tools. in the study, we analysed the task of software refactoring using the iso 9241-11 usability standard and fitts' list of task allocation. expanding on this analysis, we reviewed 11 collections of usability guidelines and combined these into a single list of 38 guidelines. from this list, we developed 81 usability requirements for refactoring tools. using these requirements, the software refactoring tools eclipse 3.2, condenser 1.05, refactorit 2.5.1, and eclipse 3.2 with the simian ui 2.2.12 plugin were studied. based on the analysis, we have selected a subset of the requirements that can be incorporated into a prototype refactoring tool intended to address the full refactoring process.\"",
            "contribution_ids": [
                "R108352"
            ]
        },
        {
            "instance_id": "EMPTYxR175392",
            "comparison_id": "EMPTY",
            "paper_id": "R175392",
            "text": "Automatically improve software architecture models for performance, reliability, and cost using evolutionary algorithms quantitative prediction of quality properties (i.e. extra-functional properties such as performance, reliability, and cost) of software architectures during design supports a systematic software engineering approach. designing architectures that exhibit a good trade-off between multiple quality criteria is hard, because even after a functional design has been created, many remaining degrees of freedom in the software architecture span a large, discontinuous design space. in current practice, software architects try to find solutions manually, which is time-consuming, can be error-prone and can lead to suboptimal designs. we propose an automated approach to search the design space for good solutions. starting with a given initial architectural model, the approach iteratively modifies and evaluates architectural models. our approach applies a multi-criteria genetic algorithm to software architectures modelled with the palladio component model. it supports quantitative performance, reliability, and cost prediction and can be extended to other quantitative quality criteria of software architectures. we validate the applicability of our approach by applying it to an architecture model of a component-based business information system and analyse its quality criteria trade-offs by automatically investigating more than 1200 alternative design candidates.",
            "contribution_ids": [
                "R175394"
            ]
        },
        {
            "instance_id": "EMPTYxR193418",
            "comparison_id": "EMPTY",
            "paper_id": "R193418",
            "text": "Voice of the users: A demographic study of software feedback behaviour user feedback on mobile app stores, product forums, and on social media can contain product development insights. there has been a lot of recent research studying this feedback and developing methods to automatically extract requirement-related information. this feedback is generally considered to be the \u201cvoice of the users\u201d; however, only a subset of software users provide online feedback. if the demographics of the online feedback givers are not representative of the user base, this introduces the possibility of developing software that does not meet the needs of all users. it is, therefore, important to understand who provides online feedback to ensure the needs of underrepresented groups are not being missed.in this work, we directly survey 1040 software users about their feedback habits, software use, and demographic information. their responses indicate that there are statistically significant differences in who gives feedback on each online channel, with respect to traditional demographics (gender, age, etc). we also identify key differences in what motivates software users to engage with each of the three channels. our findings provide valuable context for requirements elicited from online feedback and show that considering information from all channels will provide a more comprehensive view of user needs.",
            "contribution_ids": [
                "R193420"
            ]
        },
        {
            "instance_id": "EMPTYxR193467",
            "comparison_id": "EMPTY",
            "paper_id": "R193467",
            "text": "Cutting through the jungle: Disambiguating model-based traceability terminology traceability, a classic requirements engineering topic, is increasingly used in the context of model-based engineering. however, researchers and practitioners lack a concise terminology to discuss aspects of requirements traceability in situations in which engineers heavily rely on models and model-based engineering. while others have previously surveyed the domain, no one has so far provided a clear, unambiguous set of terms that can be used to discuss traceability in such a context. we therefore set out to cut a path through the jungle of terminology for model-based traceability, ground it in established terminology from requirements engineering, and derive an unambiguous set of relevant terms. we also map the terminology used in existing primary and secondary studies to our taxonomy to show differences and commonalities. the contribution of this paper is thus a terminology for model-based traceability that allows requirements engineers and engineers working with models to unambiguously discuss their joint traceability efforts.",
            "contribution_ids": [
                "R193469"
            ]
        },
        {
            "instance_id": "EMPTYxR193490",
            "comparison_id": "EMPTY",
            "paper_id": "R193490",
            "text": "Which app features are being used? Learning app feature usages from interaction data in the dynamic and fast-growing app market, monitoring and understanding how past releases are actually being used is indispensable for successful app maintenance and evolution. current app usage analytics tools either log execution events, e.g., in stack traces, or general usage information such as the app activation time, location, and device. in this paper, we focus on analyzing the usages of the single app features as described in release notes and app pages. we suggest monitoring nine app-independent, privacy-friendly interaction events for training a machine learning model to learn app feature usages. we conducted a crowdsourcing study with 55 participants who labeled 5,815 feature usages of 170 unique apps for 18 days. our within-apps evaluation shows that we could achieve encouraging precision and recall values already with ten labeled feature usages. for certain popular features such as browse newsfeed or send an email, we achieved f1 values above 88%. betweenapps feature learning seems feasible with f1 values of up to 86%.",
            "contribution_ids": [
                "R193492"
            ]
        },
        {
            "instance_id": "EMPTYxR193920",
            "comparison_id": "EMPTY",
            "paper_id": "R193920",
            "text": "Same same but different: Finding similar user feedback across multiple platforms and languages users submit feedback about the software they use through application distributions platforms, i.e., app stores, and social media. previous research has found that this type of feedback contains valuable information for software evolution, such as bug reports, or feature requests. however, popular applications receive thousands of feedback entities per day, making their manual analysis unrealistic. in this work, we present an approach to automatically identify similar user feedback across different languages and platforms. at the core of the approach is a word aligner that aligns words based on their semantic similarity and the similarity of their local semantic contexts. additionally, we make use of machine translation, sentiment analysis, and text classification, to extract the sentiment polarity and content nature of user feedback written in different languages. we use the results of these components to compute a similarity score between user feedback pairs. we evaluated our approach on user feedback entities written in four different languages, and retrieved from five different mobile applications obtained from four different app stores and social networking sites. the obtained results are encouraging. compared to human assessment, the overall performance for monolingual user feedback pairs yielded a strong correlation of 0.79. for the crosslingual feedback pairs the correlation was also strong, with a value of 0.78.",
            "contribution_ids": [
                "R193922"
            ]
        },
        {
            "instance_id": "EMPTYxR39020",
            "comparison_id": "EMPTY",
            "paper_id": "R39020",
            "text": "A data-driven assessment of early travel restrictions related to the spreading of the novel COVID-19 within mainland China two months after it was firstly reported, the novel coronavirus disease covid-19 has already spread worldwide. however, the vast majority of reported infections have occurred in china. to assess the effect of early travel restrictions adopted by the health authorities in china, we have implemented an epidemic metapopulation model that is fed with mobility data corresponding to 2019 and 2020. this allows to compare two radically different scenarios, one with no travel restrictions and another in which mobility is reduced by a travel ban. our findings indicate that i) travel restrictions are an effective measure in the short term, however, ii) they are ineffective when it comes to completely eliminate the disease. the latter is due to the impossibility of removing the risk of seeding the disease to other regions. our study also highlights the importance of developing more realistic models of behavioral changes when a disease outbreak is unfolding.",
            "contribution_ids": [
                "R39021",
                "R39022",
                "R39023",
                "R39024",
                "R39025",
                "R39027",
                "R39029",
                "R39031",
                "R39033",
                "R39035",
                "R39037",
                "R39039",
                "R39041",
                "R39043",
                "R39045",
                "R39047",
                "R39049",
                "R39051",
                "R39053",
                "R39055",
                "R39057",
                "R39059",
                "R39061",
                "R39062",
                "R39064",
                "R39066",
                "R39068",
                "R39070",
                "R39072",
                "R39074",
                "R39076"
            ]
        },
        {
            "instance_id": "EMPTYxR42003",
            "comparison_id": "EMPTY",
            "paper_id": "R42003",
            "text": "Virus Isolation from the First Patient with SARS-CoV-2 in Korea novel coronavirus (sars-cov-2) is found to cause a large outbreak started from wuhan since december 2019 in china and sars-cov-2 infections have been reported with epidemiological linkage to china in 25 countries until now. we isolated sars-cov-2 from the oropharyngeal sample obtained from the patient with the first laboratory-confirmed sars-cov-2 infection in korea. cytopathic effects of sars-cov-2 in the vero cell cultures were confluent 3 days after the first blind passage of the sample. coronavirus was confirmed with spherical particle having a fringe reminiscent of crown on transmission electron microscopy. phylogenetic analyses of whole genome sequences showed that it clustered with other sars-cov-2 reported from wuhan.",
            "contribution_ids": [
                "R42017"
            ]
        },
        {
            "instance_id": "EMPTYxR200003",
            "comparison_id": "EMPTY",
            "paper_id": "R200003",
            "text": "Detection of Antibodies against Norovirus Genogroup GIV in Carnivores abstract \\n noroviruses (novs) resembling human nov genotype giv (alphatron-like) have recently been detected in carnivores. by using an enzyme-linked immunosorbent assay based on baculovirus-expressed capsid protein vp1 of lion strain ggiv.2/pistoia/387/06/ita, nov-specific antibodies were detected in cats (16.11%) and dogs (4.8%), demonstrating that these animals are exposed to infections caused by novs.",
            "contribution_ids": [
                "R200005"
            ]
        },
        {
            "instance_id": "EMPTYxR214011",
            "comparison_id": "EMPTY",
            "paper_id": "R214011",
            "text": "Transmission of SARS-CoV-2 from Human to Domestic Ferret we report a case of natural infection with severe acute respiratory syndrome coronavirus 2 transmitted from an owner to a pet ferret in the same household in slovenia. the ferret had onset of gastroenteritis with severe dehydration. whole-genome sequencing of the viruses isolated from the owner and ferret revealed a 2-nt difference.",
            "contribution_ids": [
                "R214013"
            ]
        },
        {
            "instance_id": "EMPTYxR138607",
            "comparison_id": "EMPTY",
            "paper_id": "R138607",
            "text": "A Novel Nanoparticle Formulation for Sustained Paclitaxel Delivery purposeto develop a novel nanoparticle drug delivery system consisting of chitosan and glyceryl monooleate (gmo) for the delivery of a wide variety of therapeutics including paclitaxel.methodschitosan/gmo nanoparticles were prepared by multiple emulsion (o/w/o) solvent evaporation methods. particle size and surface charge were determined. the morphological characteristics and cellular adhesion were evaluated with surface or transmission electron microscopy methods. the drug loading, encapsulation efficiency, in vitro release and cellular uptake were determined using hplc methods. the safety and efficacy were evaluated by mtt cytotoxicity assay in human breast cancer cells (mda-mb-231).resultsthese studies provide conceptual proof that chitosan/gmo can form polycationic nano-sized particles (400 to 700\\xa0nm). the formulation demonstrates high yields (98 to 100%) and similar entrapment efficiencies. the lyophilized powder can be stored and easily be resuspended in an aqueous matrix. the nanoparticles have a hydrophobic inner-core with a hydrophilic coating that exhibits a significant positive charge and sustained release characteristics. this novel nanoparticle formulation shows evidence of mucoadhesive properties; a fourfold increased cellular uptake and a 1000-fold reduction in the ic50 of ptx.conclusionthese advantages allow lower doses of ptx to achieve a therapeutic effect, thus presumably minimizing the adverse side effects.",
            "contribution_ids": [
                "R138609"
            ]
        },
        {
            "instance_id": "EMPTYxR138909",
            "comparison_id": "EMPTY",
            "paper_id": "R138909",
            "text": "Targeted Paclitaxel by Conjugation to Iron Oxide and Gold Nanoparticles \"the fe(3)o(4) nanoparticles, tailored with maleimidyl 3-succinimidopropionate ligands, were conjugated with paclitaxel molecules that were attached with a poly(ethylene glycol) (peg) spacer through a phosphodiester moiety at the (c-2')-oh position. the average number of paclitaxel molecules/nanoparticles was determined as 83. these nanoparticles liberated paclitaxel molecules upon exposure to phosphodiesterase.\"",
            "contribution_ids": [
                "R138911"
            ]
        },
        {
            "instance_id": "EMPTYxR140238",
            "comparison_id": "EMPTY",
            "paper_id": "R140238",
            "text": "Oral Drug Delivery Systems for Ulcerative Colitis Therapy: A Comparative Study with Microparticles and Nanoparticles \\n background: \\n oral administrations of microparticles (mps) and nanoparticles (nps) have\\nbeen widely employed as therapeutic approaches for the treatment of ulcerative colitis (uc). however,\\nno previous study has comparatively investigated the therapeutic efficacies of mps and nps.\\n \\n \\n methods: \\n in this study, curcumin (cur)-loaded mps (cur-mps) and cur-loaded nps (cur-nps)\\nwere prepared using a single water-in-oil emulsion solvent evaporation technique. their therapeutic\\noutcomes against uc were further comparatively studied.\\n \\n \\n results: \\n the resultant spherical mps and nps exhibited slightly negative zeta-potential with average\\nparticle diameters of approximately 1.7 &amp;#181;m and 270 nm, respectively. it was found that nps exhibited\\na much higher cur release rate than mps within the same period of investigation. in vivo experiments\\ndemonstrated that oral administration of cur-mps and cur-nps reduced the symptoms\\nof inflammation in a uc mouse model induced by dextran sulfate sodium. importantly, cur-nps\\nshowed much better therapeutic outcomes in alleviating uc compared with cur-mps.\\n \\n \\n conclusion: \\n nps can improve the anti-inflammatory activity of cur by enhancing the drug release\\nand cellular uptake efficiency, in comparison with mps. thus, they could be exploited as a promising\\noral drug delivery system for effective uc treatment. \\n",
            "contribution_ids": [
                "R140240"
            ]
        },
        {
            "instance_id": "EMPTYxR144336",
            "comparison_id": "EMPTY",
            "paper_id": "R144336",
            "text": "Solid Lipid Nanoparticles: Emerging Colloidal Nano Drug Delivery Systems solid lipid nanoparticles (slns) are nanocarriers developed as substitute colloidal drug delivery systems parallel to liposomes, lipid emulsions, polymeric nanoparticles, and so forth. owing to their unique size dependent properties and ability to incorporate drugs, slns present an opportunity to build up new therapeutic prototypes for drug delivery and targeting. slns hold great potential for attaining the goal of targeted and controlled drug delivery, which currently draws the interest of researchers worldwide. the present review sheds light on different aspects of slns including fabrication and characterization techniques, formulation variables, routes of administration, surface modifications, toxicity, and biomedical applications.",
            "contribution_ids": [
                "R144338"
            ]
        },
        {
            "instance_id": "EMPTYxR147006",
            "comparison_id": "EMPTY",
            "paper_id": "R147006",
            "text": "Exendin-4-Loaded PLGA Microspheres Relieve Cerebral Ischemia/Reperfusion Injury and Neurologic Deficits through Long-Lasting Bioactivity-Mediated Phosphorylated Akt/eNOS Signaling in Rats glucagon-like peptide-1 (glp-1) receptor activation in the brain provides neuroprotection. exendin-4 (ex-4), a glp-1 analog, has seen limited clinical usage because of its short half-life. we developed long-lasting ex-4-loaded poly(d,l-lactide-co-glycolide) microspheres (pex-4) and explored its neuroprotective potential against cerebral ischemia in diabetic rats. compared with ex-4, pex-4 in the gradually degraded microspheres sustained higher ex-4 levels in the plasma and cerebrospinal fluid for at least 2 weeks and improved diabetes-induced glycemia after a single subcutaneous administration (20 \u03bcg/day). ten minutes of bilateral carotid artery occlusion (cao) combined with hemorrhage-induced hypotension (around 30 mm hg) significantly decreased cerebral blood flow and microcirculation in male wistar rats subjected to streptozotocin-induced diabetes. cao increased cortical o 2 \u2013 levels by chemiluminescence amplification and prefrontal cortex edema by t2-weighted magnetic resonance imaging analysis. cao significantly increased aquaporin 4 and glial fibrillary acidic protein expression and led to cognition deficits. cao downregulated phosphorylated akt/endothelial nitric oxide synthase (p-akt/p-enos) signaling and enhanced nuclear factor (nf)-\u03babp65/ intercellular adhesion molecule-1 (icam-1) expression, endoplasmic reticulum (er) stress, and apoptosis in the cerebral cortex. pex-4 was more effective than ex-4 to improve cao-induced oxidative injury and cognitive deficits. the neuroprotection provided by pex-4 was through p-akt/p-enos pathways, which suppressed cao-enhanced nf- \u03bab/icam-1 signaling, er stress, and apoptosis.",
            "contribution_ids": [
                "R147008"
            ]
        },
        {
            "instance_id": "EMPTYxR138698",
            "comparison_id": "EMPTY",
            "paper_id": "R138698",
            "text": "Application of Autoencoder in Depression Diagnosis major depressive disorder (mdd) is a mental disorder characterized by at least two weeks of low mood which is present across most situations. diagnosis of mdd using rest-state functional magnetic resonance imaging (fmri) data faces many challenges due to the high dimensionality, small samples, noisy and individual variability. no method can automatically extract discriminative features from the origin time series in fmri images for mdd diagnosis. in this study, we proposed a new method for feature extraction and a workflow which can make an automatic feature extraction and classification without a prior knowledge. an autoencoder was used to learn pre-training parameters of a dimensionality reduction process using 3-d convolution network. through comparison with the other three feature extraction methods, our method achieved the best classification performance. this method can be used not only in mdd diagnosis, but also other similar disorders.",
            "contribution_ids": [
                "R138700"
            ]
        },
        {
            "instance_id": "EMPTYxR164009",
            "comparison_id": "EMPTY",
            "paper_id": "R164009",
            "text": "A Survey of Bioinformatics Database and Software Usage through Mining the Literature computer-based resources are central to much, if not most, biological and medical research. however, while there is an ever expanding choice of bioinformatics resources to use, described within the biomedical literature, little work to date has provided an evaluation of the full range of availability or levels of usage of database and software resources. here we use text mining to process the pubmed central full-text corpus, identifying mentions of databases or software within the scientific literature. we provide an audit of the resources contained within the biomedical literature, and a comparison of their relative usage, both over time and between the sub-disciplines of bioinformatics, biology and medicine. we find that trends in resource usage differs between these domains. the bioinformatics literature emphasises novel resource development, while database and software usage within biology and medicine is more stable and conservative. many resources are only mentioned in the bioinformatics literature, with a relatively small number making it out into general biology, and fewer still into the medical literature. in addition, many resources are seeing a steady decline in their usage (e.g., blast, swiss-prot), though some are instead seeing rapid growth (e.g., the go, r). we find a striking imbalance in resource usage with the top 5% of resource names (133 names) accounting for 47% of total usage, and over 70% of resources extracted being only mentioned once each. while these results highlight the dynamic and creative nature of bioinformatics research they raise questions about software reuse, choice and the sharing of bioinformatics practice. is it acceptable that so many resources are apparently never reused? finally, our work is a step towards automated extraction of scientific method from text. we make the dataset generated by our study available under the cc0 license here: http://dx.doi.org/10.6084/m9.figshare.1281371.",
            "contribution_ids": [
                "R164011"
            ]
        },
        {
            "instance_id": "EMPTYxR168483",
            "comparison_id": "EMPTY",
            "paper_id": "R168483",
            "text": "PhyloGibbs-MP: Module Prediction and Discriminative Motif-Finding by Gibbs Sampling \"phylogibbs, our recent gibbs-sampling motif-finder, takes phylogeny into account in detecting binding sites for transcription factors in dna and assigns posterior probabilities to its predictions obtained by sampling the entire configuration space. here, in an extension called phylogibbs-mp, we widen the scope of the program, addressing two major problems in computational regulatory genomics. first, phylogibbs-mp can localise predictions to small, undetermined regions of a large input sequence, thus effectively predicting cis-regulatory modules (crms) ab initio while simultaneously predicting binding sites in those modules\u2014tasks that are usually done by two separate programs. phylogibbs-mp's performance at such ab initio crm prediction is comparable with or superior to dedicated module-prediction software that use prior knowledge of previously characterised transcription factors. second, phylogibbs-mp can predict motifs that differentiate between two (or more) different groups of regulatory regions, that is, motifs that occur preferentially in one group over the others. while other \u201cdiscriminative motif-finders\u201d have been published in the literature, phylogibbs-mp's implementation has some unique features and flexibility. benchmarks on synthetic and actual genomic data show that this algorithm is successful at enhancing predictions of differentiating sites and suppressing predictions of common sites and compares with or outperforms other discriminative motif-finders on actual genomic data. additional enhancements include significant performance and speed improvements, the ability to use \u201cinformative priors\u201d on known transcription factors, and the ability to output annotations in a format that can be visualised with the generic genome browser. in stand-alone motif-finding, phylogibbs-mp remains competitive, outperforming phylogibbs-1.0 and other programs on benchmark data.\"",
            "contribution_ids": [
                "R168485",
                "R168486"
            ]
        },
        {
            "instance_id": "EMPTYxR168521",
            "comparison_id": "EMPTY",
            "paper_id": "R168521",
            "text": "Chaste: An Open Source C++ Library for Computational Physiology and Biology chaste \u2014 cancer, heart and soft tissue environment \u2014 is an open source c++ library for the computational simulation of mathematical models developed for physiology and biology. code development has been driven by two initial applications: cardiac electrophysiology and cancer development. a large number of cardiac electrophysiology studies have been enabled and performed, including high-performance computational investigations of defibrillation on realistic human cardiac geometries. new models for the initiation and growth of tumours have been developed. in particular, cell-based simulations have provided novel insight into the role of stem cells in the colorectal crypt. chaste is constantly evolving and is now being applied to a far wider range of problems. the code provides modules for handling common scientific computing components, such as meshes and solvers for ordinary and partial differential equations (odes/pdes). re-use of these components avoids the need for researchers to \u2018re-invent the wheel\u2019 with each new project, accelerating the rate of progress in new applications. chaste is developed using industrially-derived techniques, in particular test-driven development, to ensure code quality, re-use and reliability. in this article we provide examples that illustrate the types of problems chaste can be used to solve, which can be run on a desktop computer. we highlight some scientific studies that have used or are using chaste, and the insights they have provided. the source code, both for specific releases and the development version, is available to download under an open source berkeley software distribution (bsd) licence at http://www.cs.ox.ac.uk/chaste, together with details of a mailing list and links to documentation and tutorials.",
            "contribution_ids": [
                "R168523",
                "R168524",
                "R168525",
                "R168526"
            ]
        },
        {
            "instance_id": "EMPTYxR168532",
            "comparison_id": "EMPTY",
            "paper_id": "R168532",
            "text": "GINI: From ISH Images to Gene Interaction Networks accurate inference of molecular and functional interactions among genes, especially in multicellular organisms such as drosophila, often requires statistical analysis of correlations not only between the magnitudes of gene expressions, but also between their temporal-spatial patterns. the ish (in-situ-hybridization)-based gene expression micro-imaging technology offers an effective approach to perform large-scale spatial-temporal profiling of whole-body mrna abundance. however, analytical tools for discovering gene interactions from such data remain an open challenge due to various reasons, including difficulties in extracting canonical representations of gene activities from images, and in inference of statistically meaningful networks from such representations. in this paper, we present gini, a machine learning system for inferring gene interaction networks from drosophila embryonic ish images. gini builds on a computer-vision-inspired vector-space representation of the spatial pattern of gene expression in ish images, enabled by our recently developed system; and a new multi-instance-kernel algorithm that learns a sparse markov network model, in which, every gene (i.e., node) in the network is represented by a vector-valued spatial pattern rather than a scalar-valued gene intensity as in conventional approaches such as a gaussian graphical model. by capturing the notion of spatial similarity of gene expression, and at the same time properly taking into account the presence of multiple images per gene via multi-instance kernels, gini is well-positioned to infer statistically sound, and biologically meaningful gene interaction networks from image data. using both synthetic data and a small manually curated data set, we demonstrate the effectiveness of our approach in network building. furthermore, we report results on a large publicly available collection of drosophila embryonic ish images from the berkeley drosophila genome project, where gini makes novel and interesting predictions of gene interactions. software for gini is available at http://sailing.cs.cmu.edu/drosophila_ish_images/",
            "contribution_ids": [
                "R168533",
                "R168534"
            ]
        },
        {
            "instance_id": "EMPTYxR151763",
            "comparison_id": "EMPTY",
            "paper_id": "R151763",
            "text": "Demonstration of a High Average Power Tabletop Soft X-Ray Laser we report the first demonstration of a high average power tabletop soft x-ray laser. an average laser output power of o1 mw s.2 3 1014 photonsysd was generated at 46.9 nm in ne-like ar using a very compact tabletop discharge. the spatially coherent average power emitted by this 26.5 ev laser is comparable to that generated at this photon energy in a similar bandwidth sdlyl \\xad 1024d by a thirdgeneration synchrotron beam line. lasing was obtained at a repetition rate of 7 hz with an average output energy of 135 mjypulse by exciting a plasma column in a ceramic capillary with a fast current pulse. this very compact high-repetition-rate laser source makes intense short-wavelength coherent radiation accessible to a wide variety of new applications. [s0031-9007(98)08022-3]",
            "contribution_ids": [
                "R151765"
            ]
        },
        {
            "instance_id": "EMPTYxR153258",
            "comparison_id": "EMPTY",
            "paper_id": "R153258",
            "text": "Demonstration of X-Ray Amplification in Transient Gain Nickel-like Palladium Scheme we report experimental results of x-ray amplification of spontaneous emission in a ni-like transient collisional excitation scheme. the ni-like plasma formation, ionization, and collisional excitation requires irradiation of a slab target by two laser pulses: a formation beam with 5j energy of 800ps duration and a pump beam of 5j energy in 1.1ps. a gain of 35 cm{sup {minus}1} and a gl product of 12.5 are measured on the 4d{r_arrow}4p j=0{r_arrow}1 transition for ni-like pd at 147{angstrom} with an 8mm line focus. the high efficiency of this scheme at {open_quotes}table-top{close_quotes} laser energies is a direct consequence of the nonstationary population inversion produced by the high intensity picosecond pulse. {copyright} {ital 1998} {ital the american physical society}",
            "contribution_ids": [
                "R153260"
            ]
        },
        {
            "instance_id": "EMPTYxR153969",
            "comparison_id": "EMPTY",
            "paper_id": "R153969",
            "text": "Demonstration of transient gain x-ray lasers near 20??nm for nickellike yttrium, zirconium, niobium, and molybdenum we demonstrate strong lasing on the ni-like 4d(1)s(0)?4p(1)p(1) transition at 18.9, 20.3, 22.0, and 24.0 nm for mo, nb, zr, and y ions, respectively, using the transient collisional excitation scheme. approximately 5 j of laser energy in a combination of a 600-ps pulse and a 1-ps pulse from the compact multipulse terawatt (comet) tabletop laser system is used to irradiate slab targets of these materials. small-signal gains of 17-26cm (-1) are determined on the 4d?4p transition, with overall gain-length products gl of 11-12. lasing is observed and gain is measured on the 4f(1)p(1)?4d(1)p(1) transition, which is pumped by collisional excitation combined with self-photopumping, for what is to our knowledge the first time.",
            "contribution_ids": [
                "R153971"
            ]
        },
        {
            "instance_id": "EMPTYxR41079",
            "comparison_id": "EMPTY",
            "paper_id": "R41079",
            "text": "Speech Recognition Using Deep Neural Networks: A Systematic Review over the past decades, a tremendous amount of research has been done on the use of machine learning for speech processing applications, especially speech recognition. however, in the past few years, research has focused on utilizing deep learning for speech-related applications. this new area of machine learning has yielded far better results when compared to others in a variety of applications including speech, and thus became a very attractive area of research. this paper provides a thorough examination of the different studies that have been conducted since 2006, when deep learning first arose as a new area of machine learning, for speech applications. a thorough statistical analysis is provided in this review which was conducted by extracting specific information from 174 papers published between the years 2006 and 2018. the results provided in this paper shed light on the trends of research in this area as well as bring focus to new research topics.",
            "contribution_ids": [
                "R41082"
            ]
        },
        {
            "instance_id": "EMPTYxR5289",
            "comparison_id": "EMPTY",
            "paper_id": "R5289",
            "text": "Controlling an autonomous agent using internal value based action selection in this paper we describe an approach of controlling an autonomous robot by means of a hierarchical control structure, with a learning action selection. since damasio\\'s \"descartes\\' error\" in 1994 the number of approaches to action selection that use internal values, derived from psychological models of emotions or drives has increased significantly. the approach realises a learning action selection mechanism in a hierarchy of sensory and actuatory layers. the sensory values yield the internal states, as a basis for action selection. in addition they are used to calculate the reinforcement signal that trains the action selection.",
            "contribution_ids": [
                "R5293"
            ]
        },
        {
            "instance_id": "EMPTYxR6286",
            "comparison_id": "EMPTY",
            "paper_id": "R6286",
            "text": "Template-based question answering as an increasing amount of rdf data is published as linked data, intuitive ways of accessing this data become more and more important. question answering approaches have been proposed as a good compromise between intuitiveness and expressivity. most question answering systems translate questions into triples which are matched against the rdf data to retrieve an answer, typically relying on some similarity metric. however, in many cases, triples do not represent a faithful representation of the semantic structure of the natural language question, with the result that more expressive queries can not be answered. to circumvent this problem, we present a novel approach that relies on a parse of the question to produce a sparql template that directly mirrors the internal structure of the question. this template is then instantiated using statistical entity identification and predicate detection. we show that this approach is competitive and discuss cases of questions that can be answered with our approach but not with competing approaches.",
            "contribution_ids": [
                "R6287"
            ]
        },
        {
            "instance_id": "EMPTYxR6685",
            "comparison_id": "EMPTY",
            "paper_id": "R6685",
            "text": "Personalized PageRank Based Multi-document Summarization this paper presents a novel multi-document summarization approach based on personalized pagerank (pprsum). in this algorithm, we uniformly integrate various kinds of information in the corpus. at first, we train a salience model of sentence global features based on naive bayes model. secondly, we generate a relevance model for each corpus utilizing the query of it. then, we compute the personalized prior probability for each sentence in the corpus utilizing the salience model and the relevance model both. with the help of personalized prior probability, a personalized pagerank ranking process is performed depending on the relationships among all sentences in the corpus. additionally, the redundancy penalty is imposed on each sentence. the summary is produced by choosing the sentences with both high query-focused information richness and high information novelty. experiments on duc2007 are performed and the rouge evaluation results show that pprsum ranks between the 1st and the 2nd systems on duc2007 main task.",
            "contribution_ids": [
                "R6686"
            ]
        },
        {
            "instance_id": "EMPTYxR139451",
            "comparison_id": "EMPTY",
            "paper_id": "R139451",
            "text": "Mapping XML to OWL Ontologies by now, xml has reached a wide acceptance as data exchange format in e-business. an efficient collaboration between different participants in e-business thus, is only possible, when business partners agree on a common syntax and have a common understanding of the basic concepts in the domain. xml covers the syntactic level, but lacks support for efficient sharing of conceptualizations. the web ontology language (owl [bec04]) in turn supports the representation of domain knowledge using classes, properties and instances for the use in a distributed environment as the worldwideweb. we present in this paper a mapping between the data model elements of xml and owl. we give account about its implementation within a ready-to-use xslt framework, as well as its evaluation for common use cases.",
            "contribution_ids": [
                "R139453"
            ]
        },
        {
            "instance_id": "EMPTYxR139897",
            "comparison_id": "EMPTY",
            "paper_id": "R139897",
            "text": "Ontology enrichment and automatic population from XML data this paper presents a flexible method to enrich and populate an existing owl ontology from xml data. basic mapping rules are defined in order to specify the conversion rules on properties. advanced mapping rules are defined on xml schemas a nd owl xml schema elements in order to define rules for th e population process. in addition, this flexible method allows u sers to reuse rules for other conversions and populations.",
            "contribution_ids": [
                "R139898"
            ]
        },
        {
            "instance_id": "EMPTYxR139899",
            "comparison_id": "EMPTY",
            "paper_id": "R139899",
            "text": "Building ontologies from XML data sources in this paper, we present a tool called x2owl that aims at building an owl ontology from an xml datasource. this method is based on xml schema to automatically generate the ontology structure, as well as, a set of mapping bridges. the presented method also includes a refinement step that allows to clean the mapping bridges and possibly to restructure the generated ontology.",
            "contribution_ids": [
                "R139900"
            ]
        },
        {
            "instance_id": "EMPTYxR139901",
            "comparison_id": "EMPTY",
            "paper_id": "R139901",
            "text": "Transforming XML schema to OWL using patterns one of the promises of the semantic web is to support applications that easily and seamlessly deal with heterogeneous data. most data on the web, however, is in the extensible markup language (xml) format, but using xml requires applications to understand the format of each data source that they access. to achieve the benefits of the semantic web involves transforming xml into the semantic web language, owl (ontology web language), a process that generally has manual or only semi-automatic components. in this paper we present a set of patterns that enable the direct, automatic transformation from xml schema into owl allowing the integration of much xml data in the semantic web. we focus on an advanced logical representation of xml schema components and present an implementation, including a comparison with related work.",
            "contribution_ids": [
                "R139902"
            ]
        },
        {
            "instance_id": "EMPTYxR139905",
            "comparison_id": "EMPTY",
            "paper_id": "R139905",
            "text": "Automatic generation of OWL ontology from XML data source the extensible markup language (xml) can be used as data exchange format in different domains. it allows different parties to exchange data by providing common understanding of the basic concepts in the domain. xml covers the syntactic level, but lacks support for reasoning. ontology can provide a semantic representation of domain knowledge which supports efficient reasoning and expressive power. one of the most popular ontology languages is the web ontology language (owl). it can represent domain knowledge using classes, properties, axioms and instances for the use in a distributed environment such as the world wide web. this paper presents a new method for automatic generation of owl ontology from xml data sources.",
            "contribution_ids": [
                "R139906"
            ]
        },
        {
            "instance_id": "EMPTYxR140383",
            "comparison_id": "EMPTY",
            "paper_id": "R140383",
            "text": "Automatic Constructing OWL Ontology from Relational Database Schema:  in this paper we present a new tool, called db_doowl, for creating domain ontology from relational database schema (rdbs). in contrast with existing transformation approaches, we propose a generic solution based on automatic instantiation of a specified meta-ontology. this later is an owl ontology which describes any database structure. a prototype of our proposed tool is implemented based on jena in java in order to demonstrate its feasibility.",
            "contribution_ids": [
                "R140385"
            ]
        },
        {
            "instance_id": "EMPTYxR140841",
            "comparison_id": "EMPTY",
            "paper_id": "R140841",
            "text": "SemEval-2015 Task 5: QA TempEval - Evaluating Temporal Information Understanding with Question Answering qa tempeval shifts the goal of previous tempevals away from an intrinsic evaluation methodology toward a more extrinsic goal of question answering. this evaluation requires systems to capture temporal information relevant to perform an end-user task, as opposed to corpus-based evaluation where all temporal information is equally important. evaluation results show that the best automated timeml annotations reach over 30% recall on questions with \u2018yes\u2019 answer and about 50% on easier questions with \u2018no\u2019 answers. features that helped achieve better results are event coreference and a time expression reasoner.",
            "contribution_ids": [
                "R140843"
            ]
        },
        {
            "instance_id": "EMPTYxR140846",
            "comparison_id": "EMPTY",
            "paper_id": "R140846",
            "text": "SemEval-2015 Task 9: CLIPEval Implicit Polarity of Events sentiment analysis tends to focus on the polarity of words, combining their values to detect which portion of a text is opinionated. clipeval wants to promote a more holistic approach, looking at psychological researches that frame the connotations of words as the emotional values activated by them. the implicit polarity of events is just one aspect of connotative meaning and we address it with a task that is based on a dataset of sentences annotated as instantiations of pleasant and unpleasant events previously collected in psychological research as the ones on which human judgments converge.",
            "contribution_ids": [
                "R140848"
            ]
        },
        {
            "instance_id": "EMPTYxR143687",
            "comparison_id": "EMPTY",
            "paper_id": "R143687",
            "text": "Design and Development of a Flexible Strain Sensor for Textile Structures Based on a Conductive Polymer Composite \"the aim of this work is to develop a smart flexible sensor adapted to textile structures, able to measure their strain deformations. the sensors are \u201csmart\u201d because of their capacity to adapt to the specific mechanical properties of textile structures that are lightweight, highly flexible, stretchable, elastic, etc. because of these properties, textile structures are continuously in movement and easily deformed, even under very low stresses. it is therefore important that the integration of a sensor does not modify their general behavior. the material used for the sensor is based on a thermoplastic elastomer (evoprene)/carbon black nanoparticle composite, and presents general mechanical properties strongly compatible with the textile substrate. two preparation techniques are investigated: the conventional melt-mixing process, and the solvent process which is found to be more adapted for this particular application. the preparation procedure is fully described, namely the optimization of the process in terms of filler concentration in which the percolation theory aspects have to be considered. the sensor is then integrated on a thin, lightweight nylon fabric, and the electromechanical characterization is performed to demonstrate the adaptability and the correct functioning of the sensor as a strain gauge on the fabric. a normalized relative resistance is defined in order to characterize the electrical response of the sensor. finally, the influence of environmental factors, such as temperature and atmospheric humidity, on the sensor performance is investigated. the results show that the sensor's electrical resistance is particularly affected by humidity. this behavior is discussed in terms of the sensitivity of the carbon black filler particles to the presence of water.\"",
            "contribution_ids": [
                "R143689"
            ]
        },
        {
            "instance_id": "EMPTYxR139736",
            "comparison_id": "EMPTY",
            "paper_id": "R139736",
            "text": "Public History and Contested Heritage: Archival Memories of the Bombing of Italy this article presents a case study of a collaborative public history project between participants in two countries, the united kingdom and italy. its subject matter is the bombing war in europe, 1939-1945, which is remembered and commemorated in very different ways in these two countries: the sensitivities involved thus constitute not only a case of public history conducted at the national level but also one involving contested heritage. an account of the ways in which public history has developed in the uk and italy is presented. this is followed by an explanation of how the bombing war has been remembered in each country. in the uk, veterans of raf bomber command have long felt a sense of neglect, largely because the deliberate targeting of civilians has not fitted comfortably into the dominant victor narrative. in italy, recollections of being bombed have remained profoundly dissonant within the received liberation discourse. the international bomber command centre digital archive (or archive) is then described as a case study that employs a public history approach, focusing on various aspects of its inclusive ethos, intended to preserve multiple perspectives. the italian component of the project is highlighted, problematising the digitisation of contested heritage within the broader context of twentieth-century history. reflections on the use of digital archiving practices and working in partnership are offered, as well as a brief account of user analytics of the archive through its first eighteen months online.",
            "contribution_ids": [
                "R139743"
            ]
        },
        {
            "instance_id": "EMPTYxR139761",
            "comparison_id": "EMPTY",
            "paper_id": "R139761",
            "text": "The Story of the Markham Car Collection: A Cross-Platform Panoramic Tour of Contested Heritage in this article, we share our experiences of using digital technologies and various media to present historical narratives of a museum object collection aiming to provide an engaging experience on multiple platforms. based on p. joseph\u2019s article, dawson presented multiple interpretations and historical views of the markham car collection across various platforms using multimedia resources. through her creative production, she explored how to use cylindrical panoramas and rich media to offer new ways of telling the controversial story of the contested heritage of a museum\u2019s veteran and vintage car collection. the production\u2019s usability was investigated involving five experts before it was published online and the general users\u2019 experience was investigated. in this article, we present an important component of findings which indicates that virtual panorama tours featuring multimedia elements could be successful in attracting new audiences and that using this type of storytelling technique can be effective in the museum sector. the storyteller panorama tour presented here may stimulate glam (galleries, libraries, archives, and museums) professionals to think of new approaches, implement new strategies or services to engage their audiences more effectively. the research may ameliorate the education of future professionals as well.",
            "contribution_ids": [
                "R139763"
            ]
        },
        {
            "instance_id": "EMPTYxR139784",
            "comparison_id": "EMPTY",
            "paper_id": "R139784",
            "text": "The Management Of Heritage In Contested Cross-Border Contexts: Emerging Research On The Island Of Ireland this paper introduces the recently begun reinvent research project focused on the management of heritage in the cross-border cultural landscape of derry/londonderry. the importance of facilitating dialogue over cultural heritage to the maintenance of \u2018thin\u2019 borders in contested cross-border contexts is underlined in the paper, as is the relatively favourable strategic policy context for progressing \u2018heritage diplomacy\u2019 on the island of ireland. however, it is argued that more inclusive and participatory approaches to the management \\nof heritage are required to assist in the mediation of contestation, particularly accommodating a greater diversity of \u2018non-expert\u2019 opinion, in addition to \\nhelping identify value conflicts and dissonance. the application of digital technologies in the form of public participation geographic information systems (ppgis) is proposed, and this is briefly discussed in relation to some of \\nthe expected benefits and methodological challenges that must be addressed \\nin the reinvent project. the paper concludes by emphasising the importance \\nof dialogue and knowledge exchange between academia and heritage \\npolicymakers/practitioners.",
            "contribution_ids": [
                "R139785"
            ]
        },
        {
            "instance_id": "EMPTYxR140059",
            "comparison_id": "EMPTY",
            "paper_id": "R140059",
            "text": "Open data hackathons: an innovative strategy to enhance entrepreneurial intention \\n purpose \\n in terms of entrepreneurship, open data benefits include economic growth, innovation, empowerment and new or improved products and services. hackathons encourage the development of new applications using open data and the creation of startups based on these applications. researchers focus on factors that affect nascent entrepreneurs\u2019 decision to create a startup but researches in the field of open data hackathons have not been fully investigated yet. this paper aims to suggest a model that incorporates factors that affect the decision of establishing a startup by developers who have participated in open data hackathons. \\n \\n \\n design/methodology/approach \\n in total, 70 papers were examined and analyzed using a three-phased literature review methodology, which was suggested by webster and watson (2002). these surveys investigated several factors that affect a nascent entrepreneur to create a startup. \\n \\n \\n findings \\n eventually, by identifying the motivations for developers to participate in a hackathon, and understanding the benefits of the use of open data, researchers will be able to elaborate the proposed model and evaluate if the contest has contributed to the decision of establish a startup and what factors affect the decision to establish a startup apply to open data developers, and if the participants of the contest agree with these factors. \\n \\n \\n originality/value \\n the paper expands the scope of open data research on entrepreneurship field, stating the need for more research to be conducted regarding the open data in entrepreneurship through hackathons. \\n",
            "contribution_ids": [
                "R140061"
            ]
        },
        {
            "instance_id": "EMPTYxR140070",
            "comparison_id": "EMPTY",
            "paper_id": "R140070",
            "text": "Hackathons as Co-optation Ritual: Socializing Workers and Institutionalizing Innovation in the \u201cNew\u201d Economy abstract \\nhackathons, time-bounded events where participants write computer code and build apps, have become a popular means of socializing tech students and workers to produce \u201cinnovation\u201d despite little promise of material reward. although they offer participants opportunities for learning new skills and face-to-face networking and set up interaction rituals that create an emotional \u201chigh,\u201d potential advantage is even greater for the events\u2019 corporate sponsors, who use them to outsource work, crowdsource innovation, and enhance their reputation. ethnographic observations and informal interviews at seven hackathons held in new york during the course of a single school year show how the format of the event and sponsors\u2019 discursive tropes, within a dominant cultural frame reflecting the appeal of silicon valley, reshape unpaid and precarious work as an extraordinary opportunity, a ritual of ecstatic labor, and a collective imaginary for fictional expectations of innovation that benefits all, a powerful strategy for manufacturing workers\u2019 consent in the \u201cnew\u201d economy.",
            "contribution_ids": [
                "R140072"
            ]
        },
        {
            "instance_id": "EMPTYxR148013",
            "comparison_id": "EMPTY",
            "paper_id": "R148013",
            "text": "Google Dataset Search: Building a search engine for datasets in an open Web ecosystem \"there are thousands of data repositories on the web, providing access to millions of datasets. national and regional governments, scientific publishers and consortia, commercial data providers, and others publish data for fields ranging from social science to life science to high-energy physics to climate science and more. access to this data is critical to facilitating reproducibility of research results, enabling scientists to build on others' work, and providing data journalists easier access to information and its provenance. in this paper, we discuss google dataset search, a dataset-discovery tool that provides search capabilities over potentially all datasets published on the web. the approach relies on an open ecosystem, where dataset owners and providers publish semantically enhanced metadata on their own sites. we then aggregate, normalize, and reconcile this metadata, providing a search engine that lets users find datasets in the \u201clong tail\u201d of the web. in this paper, we discuss both social and technical challenges in building this type of tool, and the lessons that we learned from this experience.\"",
            "contribution_ids": [
                "R148015"
            ]
        },
        {
            "instance_id": "EMPTYxR163875",
            "comparison_id": "EMPTY",
            "paper_id": "R163875",
            "text": "The role of software in science: a knowledge graph-based analysis of software mentions in PubMed Central science across all disciplines has become increasingly data-driven, leading to additional needs with respect to software for collecting, processing and analysing data. thus, transparency about software used as part of the scientific process is crucial to understand provenance of individual research data and insights, is a prerequisite for reproducibility and can enable macro-analysis of the evolution of scientific methods over time. however, missing rigor in software citation practices renders the automated detection and disambiguation of software mentions a challenging problem. in this work, we provide a large-scale analysis of software usage and citation practices facilitated through an unprecedented knowledge graph of software mentions and affiliated metadata generated through supervised information extraction models trained on a unique gold standard corpus and applied to more than 3 million scientific articles. our information extraction approach distinguishes different types of software and mentions, disambiguates mentions and outperforms the state-of-the-art significantly, leading to the most comprehensive corpus of 11.8 m software mentions that are described through a knowledge graph consisting of more than 300 m triples. our analysis provides insights into the evolution of software usage and citation patterns across various fields, ranks of journals, and impact of publications. whereas, to the best of our knowledge, this is the most comprehensive analysis of software use and citation at the time, all data and models are shared publicly to facilitate further research into scientific use and citation of software.",
            "contribution_ids": [
                "R163878",
                "R166530"
            ]
        },
        {
            "instance_id": "EMPTYxR164003",
            "comparison_id": "EMPTY",
            "paper_id": "R164003",
            "text": "SoMeSci- A 5 Star Open Data Gold Standard Knowledge Graph of Software Mentions in Scientific Articles knowledge about software used in scientific investigations is important for several reasons, for instance, to enable an understanding of provenance and methods involved in data handling. however, software is usually not formally cited, but rather mentioned informally within the scholarly description of the investigation, raising the need for automatic information extraction and disambiguation. given the lack of reliable ground truth data, we present somesci-software mentions in science-a gold standard knowledge graph of software mentions in scientific articles. it contains high quality annotations (irr: k=.82) of 3756 software mentions in 1367 pubmed central articles. besides the plain mention of the software, we also provide relation labels for additional information, such as the version, the developer, a url or citations. moreover, we distinguish between different types, such as application, plugin or programming environment, as well as different types of mentions, such as usage or creation. to the best of our knowledge, somesci is the most comprehensive corpus about software mentions in scientific articles, providing training samples for named entity recognition, relation extraction, entity disambiguation, and entity linking. finally, we sketch potential use cases and provide baseline results.",
            "contribution_ids": [
                "R164005",
                "R166456"
            ]
        },
        {
            "instance_id": "EMPTYxR178155",
            "comparison_id": "EMPTY",
            "paper_id": "R178155",
            "text": "A link prediction approach for item recommendation with complex number recommendation can be reduced to a sub-problem of link prediction, with specific nodes (users and items) and links (similar relations among users/items, and interactions between users and items). however, the previous link prediction algorithms need to be modified to suit the recommendation cases since they do not consider the separation of these two fundamental relations: similar or dissimilar and like or dislike. in this paper, we propose a novel and unified way to solve this problem, which models the relation duality using complex number. under this representation, the previous works can directly reuse. in experiments with the movie lens dataset and the android software website appchina.com, the presented approach achieves significant performance improvement comparing with other popular recommendation algorithms both in accuracy and coverage. besides, our results revealed some new findings. first, it is observed that the performance is improved when the user and item popularities are taken into account. second, the item popularity plays a more important role than the user popularity does in final recommendation. since its notable performance, we are working to apply it in a commercial setting, appchina.com website, for application recommendation.",
            "contribution_ids": [
                "R178157"
            ]
        },
        {
            "instance_id": "EMPTYxR139596",
            "comparison_id": "EMPTY",
            "paper_id": "R139596",
            "text": "An Integrated Approach for Improving Brand Consistency of Web Content: Modeling, Analysis, and Recommendation \\n a consumer-dependent (business-to-consumer) organization tends to present itself as possessing a set of human qualities, which is termed the\\n brand personality \\n of the company. the perception is impressed upon the consumer through the content, be it in the form of advertisement, blogs, or magazines, produced by the organization. a consistent brand will generate trust and retain customers over time as they develop an affinity toward regularity and common patterns. however, maintaining a consistent messaging tone for a brand has become more challenging with the virtual explosion in the amount of content that needs to be authored and pushed to the internet to maintain an edge in the era of digital marketing. to understand the depth of the problem, we collect around 300k web page content from around 650 companies. we develop trait-specific classification models by considering the linguistic features of the content. the classifier automatically identifies the web articles that are not consistent with the mission and vision of a company and further helps us to discover the conditions under which the consistency cannot be maintained. to address the brand inconsistency issue, we then develop a sentence ranking system that outputs the top three sentences that need to be changed for making a web article more consistent with the company\u2019s brand personality.\\n",
            "contribution_ids": [
                "R139598"
            ]
        },
        {
            "instance_id": "EMPTYxR144816",
            "comparison_id": "EMPTY",
            "paper_id": "R144816",
            "text": "NLTK: The Natural Language Toolkit nltk, the natural language toolkit, is a suite of open source program modules, tutorials and problem sets, providing ready-to-use computational linguistics courseware. nltk covers symbolic and statistical natural language processing, and is interfaced to annotated corpora. students augment and replace existing components, learn structured programming by example, and manipulate sophisticated models from the outset.",
            "contribution_ids": [
                "R144818"
            ]
        },
        {
            "instance_id": "EMPTYxR145794",
            "comparison_id": "EMPTY",
            "paper_id": "R145794",
            "text": "Neural Architectures for Named Entity Recognition comunicacio presentada a la 2016 conference of the north american chapter of the association for computational linguistics, celebrada a san diego (ca, eua) els dies 12 a 17 de juny 2016.",
            "contribution_ids": [
                "R145796"
            ]
        },
        {
            "instance_id": "EMPTYxR147894",
            "comparison_id": "EMPTY",
            "paper_id": "R147894",
            "text": "Active Learning Yields Better Training Data for Scientific Named Entity Recognition despite significant progress in natural language processing, machine learning models require substantial expertannotated training data to perform well in tasks such as named entity recognition (ner) and entity relations extraction. furthermore, ner is often more complicated when working with scientific text. for example, in polymer science, chemical structure may be encoded using nonstandard naming conventions, the same concept can be expressed using many different terms (synonymy), and authors may refer to polymers with ad-hoc labels. these challenges, which are not unique to polymer science, make it difficult to generate training data, as specialized skills are needed to label text correctly. we have previously designed polyner, a semi-automated system for efficient identification of scientific entities in text. polyner applies word embedding models to generate entity-rich corpora for productive expert labeling, and then uses the resulting labeled data to bootstrap a context-based classifier. polyner facilitates a labeling process that is otherwise tedious and expensive. here, we use active learning to efficiently obtain more annotations from experts and improve performance. our approach requires just five hours of expert time to achieve discrimination capacity comparable to that of a state-of-the-art chemical ner toolkit.",
            "contribution_ids": [
                "R147896"
            ]
        },
        {
            "instance_id": "EMPTYxR161808",
            "comparison_id": "EMPTY",
            "paper_id": "R161808",
            "text": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (nlp). the effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. in this paper, we explore the landscape of transfer learning techniques for nlp by introducing a unified framework that converts every language problem into a text-to-text format. our systematic study compares pre-training objectives, architectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks. by combining the insights from our exploration with scale and our new \"colossal clean crawled corpus\", we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. to facilitate future work on transfer learning for nlp, we release our dataset, pre-trained models, and code.",
            "contribution_ids": [
                "R161810"
            ]
        },
        {
            "instance_id": "EMPTYxR176039",
            "comparison_id": "EMPTY",
            "paper_id": "R176039",
            "text": "Attention is All you Need the dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. the best performing models also connect the encoder and decoder through an attention mechanism. we propose a new simple network architecture, the transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. our model achieves 28.4 bleu on the wmt 2014 english-to-german translation task, improving over the existing best results, including ensembles by over 2 bleu. on the wmt 2014 english-to-french translation task, our model establishes a new single-model state-of-the-art bleu score of 41.8 after training for 3.5 days on eight gpus, a small fraction of the training costs of the best models from the literature. we show that the transformer generalizes well to other tasks by applying it successfully to english constituency parsing both with large and limited training data.",
            "contribution_ids": [
                "R176041"
            ]
        },
        {
            "instance_id": "EMPTYxR139328",
            "comparison_id": "EMPTY",
            "paper_id": "R139328",
            "text": "High-Performance Sensors Based on Molybdenum Disulfide Thin Films high-performance sensors based on molybdenum disulfide (mos2 ) grown by sulfurization of sputtered molybdenum layers are presented. using a simple integration scheme, it is found that the electrical conductivity of mos2 films is highly sensitive to nh3 adsorption, consistent with n-type semiconducting behavior. a sensitivity of 300 ppb at room temperature is achieved, showing the high potential of 2d transition metal-dichalcogenides for sensing.",
            "contribution_ids": [
                "R139330"
            ]
        },
        {
            "instance_id": "EMPTYxR139340",
            "comparison_id": "EMPTY",
            "paper_id": "R139340",
            "text": "Cu2O nanorods modified by reduced graphene oxide for NH3 sensing at room temperature in this work, cu 2 o nanorods modified by reduced graphene oxide (rgo) were produced via a two-step synthesis method.",
            "contribution_ids": [
                "R139342"
            ]
        },
        {
            "instance_id": "EMPTYxR141435",
            "comparison_id": "EMPTY",
            "paper_id": "R141435",
            "text": "Multifold study of volume plasma chemistry in Ar/CF_4and Ar/CHF_3  CCP discharges low-pressure rf plasma in fluorohydrocarbon gas mixtures is widely used in modern microelectronics, e.g. in the etching of materials with a low dielectric constant (low-k) materials). the multifold experimental and theoretical study of a radio frequency capacitively coupled plasma at 81 mhz in ar/cf4/chf3 has been carried out at 50 mtorr and 150 mtorr gas pressures. a wide set of experimental diagnostics together with hybrid pic mc model calculations were applied to a detailed study of the plasmas. measurements of the f atoms, hf molecules and cfx radicals, electron density, electronegativity and positive ion composition were performed. absolutely calibrated vuv spectrometry was carried out to measure the vuv photon fluence towards the electrode. this combined experimental and model approach allowed us to establish the fundamental mechanisms of the charged and neutral species elementary reactions. dissociative charge transfer reactions and fluoride transfer reactions influence the main ion (cf 3 + , chf 2 + ) composition in ar/cf4/chf3 plasma a lot. the mechanisms of heavy ion formation in ar/chf3 are also discussed. the important role of additional attachment mechanisms (besides dissociative attachment to the feedstock gases, cf4, chf3) was analyzed. the catalytic chain mechanism, including the hf molecules, which defines the cfx kinetics in ar/chf3 plasma, was validated. this multifold approach enabled us to determine the complicated plasma chemical composition of the active species as well as the fluxes of vuv photons at the surface of the processed material, and is a result that is important for understanding low-k damage.",
            "contribution_ids": [
                "R141436"
            ]
        },
        {
            "instance_id": "EMPTYxR145572",
            "comparison_id": "EMPTY",
            "paper_id": "R145572",
            "text": "Stark broadening of C iv and N v lines in the vacuum-uv spectral range spectral line shapes of 3p-4d, 3d-4f, 4d-5f, and 4f-5g transitions in the lithiumlike ions c iv and n v have been measured in a gas-liner pinch discharge at a density of 7.7\\\\ifmmode\\\\times\\\\else\\\\texttimes\\\\fi{}${10}^{23}$ ${\\\\mathrm{m}}^{\\\\mathrm{\\\\ensuremath{-}}3}$. the full widths at half maximum are larger than theoretical values obtained by the impact approximation by factors between 3 and 4 and smaller than theoretical full widths at half maximum calculated in the quasistatic, linear stark effect approximation by factors between 1.2 and 3.",
            "contribution_ids": [
                "R145573"
            ]
        },
        {
            "instance_id": "EMPTYxR139878",
            "comparison_id": "EMPTY",
            "paper_id": "R139878",
            "text": "A Conceptual Enterprise Architecture Framework for Smart Cities - A Survey Based Approach:  \"enterprise architecture for smart cities is the focus of the research project \u201ceadic - (developing an enterprise architecture for digital cities)\u201d which is the context of the reported results in this work. we report in detail the results of a survey we contacted. using these results we identify important quality and functional requirements for smart cities. important quality properties include interoperability, usability, security, availability, recoverability and maintainability. we also observe business-related issues such as an apparent uncertainty on who is selling services, the lack of business plan in most cases and uncertainty in commercialization of services. at the software architecture domain we present a conceptual architectural framework based on architectural patterns which address the identified quality requirements. the conceptual framework can be used as a starting point for actual smart cities' projects.\"",
            "contribution_ids": [
                "R139880"
            ]
        },
        {
            "instance_id": "EMPTYxR141943",
            "comparison_id": "EMPTY",
            "paper_id": "R141943",
            "text": "Smart city intellectual capital: an emerging view of territorial systems innovation management purpose \u2013 the purpose of this paper is to explore whether and how the intellectual capital (ic) approach and concepts could be fruitfully adapted to study the smart city phenomenon from a managerial point of view. design/methodology/approach \u2013 this study is based on a long-term, in-depth ethnographic exploration of the vast global community, which is created around the smart city movement. findings \u2013 the analysis suggests that, in order to effectively analyse a smart city context through the ic lens, the traditional ic framework needs to be extended for: expected outcomes, which should also include sustainability, resilience and quality of life; categories of key resources, which should also include institutional capital and environmental capital; units of analysis, which should also include territorial systems, such as transportation or waste; and key managerial challenges implied. as a final result, a smart city intellectual capital (sc-ic) framework is proposed. research limitations/implications \u2013 most of the cases analysed in this study are european; further studies are advisable to better investigate non-european smart city contexts. practical implications \u2013 the paper suggests that the knowledge management, project portfolio management and network management approaches are crucial to better support managerial practices in smart city organizations. originality/value \u2013 the sc-ic framework allows for a clear definition of the smart city organization, as a new knowledge-based, project-oriented, network-shaped type of organization. therefore, the sc-ic framework provides smart city research with a consistent rooting in management studies. further, this paper contributes to the fourth stage of ic research.",
            "contribution_ids": [
                "R141945"
            ]
        },
        {
            "instance_id": "EMPTYxR141958",
            "comparison_id": "EMPTY",
            "paper_id": "R141958",
            "text": "The \u2018actually existing smart city\u2019 this paper grounds the critique of the \u2018smart city\u2019 in its historical and geographical context. adapting brenner and theodore\u2019s notion of \u2018actually existing neoliberalism\u2019, we suggest a greater attention be paid to the \u2018actually existing smart city\u2019, rather than the exceptional or paradigmatic smart cities of songdo, masdar and living planit valley. through a closer analysis of cases in louisville and philadelphia, we demonstrate the utility of understanding the material effects of these policies in actual cities around the world, with a particular focus on how and from where these policies have arisen, and how they have unevenly impacted the places that have adopted them.",
            "contribution_ids": [
                "R141960"
            ]
        },
        {
            "instance_id": "EMPTYxR141961",
            "comparison_id": "EMPTY",
            "paper_id": "R141961",
            "text": "Smart Cities at the Crossroads: New Tensions in City Transformation the smart cities movement has produced a large number of projects and experiments around the world. to understand the primary ones, as well as their underlying tensions and the insights emerging from them, the editors of this special issue of the california management review enlisted a panel of experts, academics, and practitioners from different nationalities, backgrounds, experiences, and perspectives. the panel focused its discussion on three main areas: new governance models for smart cities, how to spur growth and renewal, and the sharing economy\u2014both commons and market based.",
            "contribution_ids": [
                "R141963"
            ]
        },
        {
            "instance_id": "EMPTYxR141967",
            "comparison_id": "EMPTY",
            "paper_id": "R141967",
            "text": "Unveiling smart city implementation challenges: The case of Ghent \"the 'smart city' label is internationally used by cities, researchers and technology providers with different meanings. as a popular concept it is widely used by city administrators and politicians to promote their efforts to prepare their cities for the future. there are decent definitions for what a smart city is, but it is much harder to find a trustworthy description of what it takes to become a smart city and how a city administration is impacted by that effort. this paper sets out to investigate how a city, aspiring to become a 'smart city', can manage its internal organization to realize that ambition. specifically, it describes the case of the city of ghent, belgium, and the key challenges it has been facing in its ongoing efforts to be a smart city. based on in depth interviews with city representatives six key challenges for smart city realization were identified and tested with a panel of representatives from five european cities that are in the process of becoming a smart city. the study contributes to a more professional pursuit of the smart city concept and elaborates the academic body of knowledge on smart city development, as an instance of it-enabled transformation in public services.\"",
            "contribution_ids": [
                "R141969"
            ]
        },
        {
            "instance_id": "EMPTYxR141983",
            "comparison_id": "EMPTY",
            "paper_id": "R141983",
            "text": "Smart City Implementation Through Shared Vision of Social Innovation for Environmental Sustainability: A Case Study of Kitakyushu, Japan environmental sustainability is a critical global issue that requires comprehensive intervention policies. viewed as localized intervention policy implementations, smart cities leverage information infrastructures and distributed renewable energy smart micro-grids, smart meters, and home/building energy management systems to reduce city-wide carbon emissions. however, theory-driven smart city implementation research is critically lacking. this theory-building case study identifies antecedent conditions necessary for implementing smart cities. we integrated resource dependence, social embeddedness, and citizen-centric e-governance theories to develop a citizen-centric social governance framework. we apply the framework to a field-based case study of japan\u2019s kitakyushu smart community project to examine the validity and utility of the framework\u2019s antecedent conditions: resource-dependent leadership network, cross-sector collaboration based on social ties, and citizen-centric e-governance. we conclude that complex smart community implementation processes require shared vision of social innovation owned by diverse stakeholders with conflicting values and adaptive use of informal social governance mechanisms for effective smart city implementation.",
            "contribution_ids": [
                "R141985"
            ]
        },
        {
            "instance_id": "EMPTYxR141986",
            "comparison_id": "EMPTY",
            "paper_id": "R141986",
            "text": "How smart is smart? Theoretical and empirical considerations on implementing smart city objectives \u2013 a case study of Dutch railway station areas the current widespread attention on the concept of smart city in both policy and practice has stimulated academic discussion regarding the scope and applicability of this concept. an important question is whether cities and regions are truly advanced in implementing the concept in their policies and practices relative to its conceptual elaborations in academia. the aim of this paper is to analyse this congruence between theory and practice in the context of the ongoing transformations of railway station areas in european urban regions. based on in-depth interviewing using aspects of q-methodology, this paper investigates whether and how smart city concepts are implemented by stakeholders in three station redevelopment projects in the netherlands. the results show that the current implementation of smart city concepts in practice is varied but modest and not (yet) very advanced. knowledge exchange and innovations are currently hampered by a lack of acceptance and know-how among stakeholders, as well as by institutional and competitive constraints. for instance, stakeholders stress that data privacy regulations should be well organized before further implementation can occur. transparency about how and what data are used may create more willingness among users to assist in developing and accepting new data technologies. however, the technologies are not yet completely developed, and concerns about the \u201closs\u201d of personal privacy are holding back the widespread and advanced use of data supplied technologies. although stakeholders seem to be aware of the opportunities the smart city concept offers, for now, the widespread implementation of innovative and advanced smart city concepts remains in the future.",
            "contribution_ids": [
                "R141988"
            ]
        },
        {
            "instance_id": "EMPTYxR142005",
            "comparison_id": "EMPTY",
            "paper_id": "R142005",
            "text": "Human limitations to introduction of smart cities: Comparative analysis from two CEE cities abstract smart cities are a modern administrative/ developmental concept that tries to combine the development of urban areas with a higher level of citizens\u2019 participation. however, there is a lack of understanding of the concept\u2019s potential, due possibly to an unwillingness to accept a new form of relationship with the citizens. in this article, the willingness to introduce the elements of smart cities into two central and eastern european cities is tested. the results show that people are reluctant to use technology above the level of their needs and show little interest in participating in matters of governance, which prevents smart cities from developing in reality.",
            "contribution_ids": [
                "R142007"
            ]
        },
        {
            "instance_id": "EMPTYxR142050",
            "comparison_id": "EMPTY",
            "paper_id": "R142050",
            "text": "Competitive urbanism and the limits to smart city innovation: The UK Future Cities initiative the technological vision of smart urbanism has been promoted as a silver bullet for urban problems and a major market opportunity. the search is on for firms and governments to find effective and transferable demonstrations of advanced urban technology. this paper examines initiatives by the uk national government to facilitate urban technological innovation through a range of strategies, particularly the tsb future cities demonstrator competition. this case study is used to explore opportunities and tensions in the practical realisation of the smart city imaginary. tensions are shown to be partly about the conjectural nature of the smart city debate. attention is also drawn to weakened capacity of urban governments to control their infrastructural destiny and also constraints on the ability of the public and private sectors to innovate. the paper contributes to smart city debates by providing further evidence of the difficulties in substantiating the smart city imaginary.",
            "contribution_ids": [
                "R142052"
            ]
        },
        {
            "instance_id": "EMPTYxR142153",
            "comparison_id": "EMPTY",
            "paper_id": "R142153",
            "text": "CdSe Quantum Dots for Two-Photon Fluorescence Thermal Imaging the technological development of quantum dots has ushered in a new era in fluorescence bioimaging, which was propelled with the advent of novel multiphoton fluorescence microscopes. here, the potential use of cdse quantum dots has been evaluated as fluorescent nanothermometers for two-photon fluorescence microscopy. in addition to the enhancement in spatial resolution inherent to any multiphoton excitation processes, two-photon (near-infrared) excitation leads to a temperature sensitivity of the emission intensity much higher than that achieved under one-photon (visible) excitation. the peak emission wavelength is also temperature sensitive, providing an additional approach for thermal imaging, which is particularly interesting for systems where nanoparticles are not homogeneously dispersed. on the basis of these superior thermal sensitivity properties of the two-photon excited fluorescence, we have demonstrated the ability of cdse quantum dots to image a temperature gradient artificially created in a biocompatible fluid (phosphate-buffered saline) and also their ability to measure an intracellular temperature increase externally induced in a single living cell.",
            "contribution_ids": [
                "R142155"
            ]
        },
        {
            "instance_id": "EMPTYxR142305",
            "comparison_id": "EMPTY",
            "paper_id": "R142305",
            "text": "Mapping ER Schemas to OWL Ontologies as the semantic web initiative gains momentum, a fundamental problem of integrating existing data-intensive www applications into the semantic web emerges. in order for today\u2019s relational database supported web applications to transparently participate in the semantic web, their associated database schemas need to be converted into semantically equivalent ontologies. in this paper we present a solution to an important special case of the automatic mapping problem with wide applicability: mapping well-formed entity-relationship (er) schemas to semantically equivalent owl lite ontologies. we present a set of mapping rules that fully capture the er schema semantics, along with an overview of an implementation of the complete mapping algorithm integrated into the current sfsu er design tools software.",
            "contribution_ids": [
                "R142307"
            ]
        },
        {
            "instance_id": "EMPTYxR141070",
            "comparison_id": "EMPTY",
            "paper_id": "R141070",
            "text": "Named Entity Recognition on Code-Switched Data: Overview of the CALCS 2018 Shared Task in the third shared task of the computational approaches to linguistic code-switching (calcs) workshop, we focus on named entity recognition (ner) on code-switched social-media data. we divide the shared task into two competitions based on the english-spanish (eng-spa) and modern standard arabic-egyptian (msa-egy) language pairs. we use twitter data and 9 entity types to establish a new dataset for code-switched ner benchmarks. in addition to the cs phenomenon, the diversity of the entities and the social media challenges make the task considerably hard to process. as a result, the best scores of the competitions are 63.76% and 71.61% for eng-spa and msa-egy, respectively. we present the scores of 9 participants and discuss the most common challenges among submissions.",
            "contribution_ids": [
                "R141072"
            ]
        },
        {
            "instance_id": "EMPTYxR142108",
            "comparison_id": "EMPTY",
            "paper_id": "R142108",
            "text": "SemEval-2013 Task 7: The Joint Student Response Analysis and 8th Recognizing Textual Entailment Challenge we present the results of the joint student response analysis and 8th recognizing textual entailment challenge, aiming to bring together researchers in educational nlp technology and textual entailment. the task of giving feedback on student answers requires semantic inference and therefore is related to recognizing textual entailment. thus, we offered to the community a 5-way student response labeling task, as well as 3-way and 2way rte-style tasks on educational data. in addition, a partial entailment task was piloted. we present and compare results from 9 participating teams, and discuss future directions.",
            "contribution_ids": [
                "R142110",
                "R142112"
            ]
        },
        {
            "instance_id": "EMPTYxR146741",
            "comparison_id": "EMPTY",
            "paper_id": "R146741",
            "text": "The Stanford CoreNLP Natural Language Processing Toolkit we describe the design and use of the stanford corenlp toolkit, an extensible pipeline that provides core natural language analysis. this toolkit is quite widely used, both in the research nlp community and also among commercial and government users of open source nlp technology. we suggest that this follows from a simple, approachable design, straightforward interfaces, the inclusion of robust and good quality analysis components, and not requiring use of a large amount of associated baggage.",
            "contribution_ids": [
                "R146743",
                "R162883",
                "R187503"
            ]
        },
        {
            "instance_id": "EMPTYxR146915",
            "comparison_id": "EMPTY",
            "paper_id": "R146915",
            "text": "DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs reading comprehension has recently seen rapid progress, with systems matching humans on the most popular datasets for the task. however, a large body of work has highlighted the brittleness of these systems, showing that there is much work left to be done. we introduce a new reading comprehension benchmark, drop, which requires discrete reasoning over the content of paragraphs. in this crowdsourced, adversarially-created, 55k-question benchmark, a system must resolve references in a question, perhaps to multiple input positions, and perform discrete operations over them (such as addition, counting, or sorting). these operations require a much more comprehensive understanding of the content of paragraphs, as they remove the paraphrase-and-entity-typing shortcuts available in prior datasets. we apply state-of-the-art methods from both the reading comprehension and semantic parsing literatures on this dataset and show that the best systems only achieve 38.4% f1 on our generalized accuracy metric, while expert human performance is 96%. we additionally present a new model that combines reading comprehension methods with simple numerical reasoning to achieve 51% f1.",
            "contribution_ids": [
                "R146917"
            ]
        },
        {
            "instance_id": "EMPTYxR147989",
            "comparison_id": "EMPTY",
            "paper_id": "R147989",
            "text": "Semantic Parsing Freebase: Towards Open-domain Semantic Parsing existing semantic parsing research has steadily improved accuracy on a few domains and their corresponding databases. this paper introduces freeparser, a system that trains on one domain and one set of predicate and constant symbols, and then can parse sentences for any new domain, including sentences that refer to symbols never seen during training. freeparser uses a domain-independent architecture to automatically identify sentences relevant to each new database symbol, which it uses to supplement its manually-annotated training data from the training domain. in cross-domain experiments involving 23 domains, freeparser can parse sentences for which it has seen comparable unannotated sentences with an f1 of 0.71.",
            "contribution_ids": [
                "R147991"
            ]
        },
        {
            "instance_id": "EMPTYxR162920",
            "comparison_id": "EMPTY",
            "paper_id": "R162920",
            "text": "GATE: an architecture for development of robust HLT applications in this paper we present gate, a framework and graphical development environment which enables users to develop and deploy language engineering components and resources in a robust fashion. the gate architecture has enabled us not only to develop a number of successful applications for various language processing tasks (such as information extraction), but also to build and annotate corpora and carry out evaluations on the applications generated. the framework can be used to develop applications and resources in multiple languages, based on its thorough unicode support.",
            "contribution_ids": [
                "R162922"
            ]
        },
        {
            "instance_id": "EMPTYxR162973",
            "comparison_id": "EMPTY",
            "paper_id": "R162973",
            "text": "Shared Tasks of the 2015 Workshop on Noisy User-generated Text: Twitter Lexical Normalization and Named Entity Recognition this paper presents the results of the two shared tasks associated with w-nut 2015: (1) a text normalization task with 10 participants; and (2) a named entity tagging task with 8 participants. we outline the task, annotation process and dataset statistics, and provide a high-level overview of the participating systems for each shared task.",
            "contribution_ids": [
                "R162975"
            ]
        },
        {
            "instance_id": "EMPTYxR163043",
            "comparison_id": "EMPTY",
            "paper_id": "R163043",
            "text": "NLTK: the natural language toolkit nltk, the natural language toolkit, is a suite of open source program modules, tutorials and problem sets, providing ready-to-use computational linguistics courseware. nltk covers symbolic and statistical natural language processing, and is interfaced to annotated corpora. students augment and replace existing components, learn structured programming by example, and manipulate sophisticated models from the outset.",
            "contribution_ids": [
                "R163045"
            ]
        },
        {
            "instance_id": "EMPTYxR163747",
            "comparison_id": "EMPTY",
            "paper_id": "R163747",
            "text": "CrossNER: Evaluating Cross-Domain Named Entity Recognition cross-domain named entity recognition (ner) models are able to cope with the scarcity issue of ner samples in target domains. however, most of the existing ner benchmarks lack domain-specialized entity types or do not focus on a certain domain, leading to a less effective cross-domain evaluation. to address these obstacles, we introduce a cross-domain ner dataset (crossner), a fully-labeled collection of ner data spanning over five diverse domains with specialized entity categories for different domains. additionally, we also provide a domain-related corpus since using it to continue pre-training language models (domain-adaptive pre-training) is effective for the domain adaptation. we then conduct comprehensive experiments to explore the effectiveness of leveraging different levels of the domain corpus and pre-training strategies to do domain-adaptive pre-training for the cross-domain task. results show that focusing on the fractional corpus containing domain-specialized entities and utilizing a more challenging pre-training strategy in domain-adaptive pre-training are beneficial for the ner domain adaptation, and our proposed method can consistently outperform existing cross-domain ner baselines. nevertheless, experiments also illustrate the challenge of this cross-domain ner task. we hope that our dataset and baselines will catalyze research in the ner domain adaptation area. the code and data are available at this https url.",
            "contribution_ids": [
                "R163785",
                "R163749",
                "R163784",
                "R163786",
                "R163787",
                "R163788",
                "R163789"
            ]
        },
        {
            "instance_id": "EMPTYxR164240",
            "comparison_id": "EMPTY",
            "paper_id": "R164240",
            "text": "Towards Exhaustive Protein Modification Event Extraction protein modifications, in particular post-translational modifications, have a central role in bringing about the full repertoire of protein functions, and the identification of specific protein modifications is important for understanding biological systems. this task presents a number of opportunities for the automatic support of manual curation efforts. however, the sheer number of different types of protein modifications is a daunting challenge for automatic extraction that has so far not been met in full, with most studies focusing on single modifications or a few prominent ones. in this work, aim to meet this challenge: we analyse protein modification types through ontologies, databases, and literature and introduce a corpus of 360 abstracts manually annotated in the bionlp shared task event representation for over 4500 mentions of proteins and 1000 statements of modification events of nearly 40 different types. we argue that together with existing resources, this corpus provides sufficient coverage of modification types to make effectively exhaustive extraction of protein modifications from text feasible.",
            "contribution_ids": [
                "R164242"
            ]
        },
        {
            "instance_id": "EMPTYxR164289",
            "comparison_id": "EMPTY",
            "paper_id": "R164289",
            "text": "Towards Event Extraction from Full Texts on Infectious Diseases event extraction approaches based on expressive structured representations of extracted information have been a significant focus of research in recent biomedical natural language processing studies. however, event extraction efforts have so far been limited to publication abstracts, with most studies further considering only the specific transcription factor-related subdo-main of molecular biology of the genia corpus. to establish the broader relevance of the event extraction approach and proposed methods, it is necessary to expand on these constraints. in this study, we propose an adaptation of the event extraction approach to a subdomain related to infectious diseases and present analysis and initial experiments on the feasibility of event extraction from domain full text publications.",
            "contribution_ids": [
                "R164291"
            ]
        },
        {
            "instance_id": "EMPTYxR150967",
            "comparison_id": "EMPTY",
            "paper_id": "R150967",
            "text": "Annotation of Chemical Named Entities we describe the annotation of chemical named entities in scientific text. a set of annotation guidelines defines 5 types of named entities, and provides instructions for the resolution of special cases. a corpus of fulltext chemistry papers was annotated, with an inter-annotator agreement f score of 93%. an investigation of named entity recognition using lingpipe suggests that f scores of 63% are possible without customisation, and scores of 74% are possible with the addition of custom tokenisation and the use of dictionaries.",
            "contribution_ids": [
                "R150969"
            ]
        },
        {
            "instance_id": "EMPTYxR171931",
            "comparison_id": "EMPTY",
            "paper_id": "R171931",
            "text": "COMET: Commonsense Transformers for Automatic Knowledge Graph Construction we present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: atomic (sap et al., 2019) and conceptnet (speer et al., 2017). contrary to many conventional kbs that store knowledge with canonical templates, commonsense kbs only store loosely structured open-text descriptions of knowledge. we posit that an important step toward automatic commonsense completion is the development of generative models of commonsense knowledge, and propose commonsense transformers (comet) that learn to generate rich and diverse commonsense descriptions in natural language. despite the challenges of commonsense modeling, our investigation reveals promising results when implicit knowledge from deep pre-trained language models is transferred to generate explicit knowledge in commonsense knowledge graphs. empirical results demonstrate that comet is able to generate novel knowledge that humans rate as high quality, with up to 77.5% (atomic) and 91.7% (conceptnet) precision at top 1, which approaches human performance for these resources. our findings suggest that using generative commonsense models for automatic commonsense kb completion could soon be a plausible alternative to extractive methods.",
            "contribution_ids": [
                "R171933"
            ]
        },
        {
            "instance_id": "EMPTYxR187826",
            "comparison_id": "EMPTY",
            "paper_id": "R187826",
            "text": "Discovering Implicit Entity Relation with the Gene-Citation-Gene Network in this paper, we apply the entitymetrics model to our constructed gene-citation-gene (gcg) network. based on the premise there is a hidden, but plausible, relationship between an entity in one article and an entity in its citing article, we constructed a gcg network of gene pairs implicitly connected through citation. we compare the performance of this gcg network to a gene-gene (gg) network constructed over the same corpus but which uses gene pairs explicitly connected through traditional co-occurrence. using 331,411 medline abstracts collected from 18,323 seed articles and their references, we identify 25 gene pairs. a comparison of these pairs with interactions found in biogrid reveal that 96% of the gene pairs in the gcg network have known interactions. we measure network performance using degree, weighted degree, closeness, betweenness centrality and pagerank. combining all measures, we find the gcg network has more gene pairs, but a lower matching rate than the gg network. however, combining top ranked genes in both networks produces a matching rate of 35.53%. by visualizing both the gg and gcg networks, we find that cancer is the most dominant disease associated with the genes in both networks. overall, the study indicates that the gcg network can be useful for detecting gene interaction in an implicit manner.",
            "contribution_ids": [
                "R187827"
            ]
        },
        {
            "instance_id": "EMPTYxR143705",
            "comparison_id": "EMPTY",
            "paper_id": "R143705",
            "text": "A highly stretchable and sensitive strain sensor based on graphene\u2013elastomer composites with a novel double-interconnected network a facile assembly approach was firstly reported to fabricate a highly stretchable and sensitive strain sensor based on graphene\u2013rubber composites with a novel double-interconnected network.",
            "contribution_ids": [
                "R143707"
            ]
        },
        {
            "instance_id": "EMPTYxR108772",
            "comparison_id": "EMPTY",
            "paper_id": "R108772",
            "text": "Dietary Reference Intakes for Water, Potassium, Sodium, Chloride, and Sulfate dietary reference intakes for water, potassium, sodium, chloride, and sulfate the dietary reference intakes (dris) are quantitative estimates of nutrient intakes to be used for planning and assessing diets for healthy people. this new report, the sixth in a series of reports presenting dietary reference values for the intakes of nutrients by americans and canadians, establishes nutrient recommendations on water, potassium, and salt for health maintenance and the reduction of chronic disease risk. dietary reference intakes for water, potassium, sodium, chloride, and sulfate discusses in detail the role of water, potassium, salt, chloride, and sulfate in human physiology and health. the major findings in this book include the establishment of adequate intakes for total water (drinking water, beverages, and food), potassium, sodium, and chloride and the establishment of tolerable upper intake levels for sodium and chloride. the book makes research recommendations for information needed to advance the understanding of human requirements for water and electrolytes, as well as adverse effects associated with the intake of excessive amounts of water, sodium, chloride, potassium, and sulfate. this book will be an invaluable reference for nutritionists, nutrition researchers, and food manufacturers.",
            "contribution_ids": [
                "R108773"
            ]
        },
        {
            "instance_id": "EMPTYxR142089",
            "comparison_id": "EMPTY",
            "paper_id": "R142089",
            "text": "Iranian Registry of Crohn\u2019s and Colitis: study profile of first nation-wide inflammatory bowel disease registry in Middle East background/aims a recent study revealed increasing incidence and prevalence of inflammatory bowel disease (ibd) in iran. the iranian registry of crohn\u2019s and colitis (ircc) was designed recently to answer the needs. we reported the design, methods of data collection, and aims of ircc in this paper. methods ircc is a multicenter prospective registry, which is established with collaboration of more than 100 gastroenterologists from different provinces of iran. minimum data set for ircc was defined according to an international consensus on standard set of outcomes for ibd. a pilot feasibility study was performed on 553 ibd patients with a web-based questionnaire. the reliability of questionnaire evaluated by cronbach\u2019s \u03b1. results all sections of questionnaire had cronbach\u2019s \u03b1 of more than 0.6. in pilot study, 312 of participants (56.4%) were male and mean age was 38 years (standard deviation=12.8) and 378 patients (68.35%) had ulcerative colitis, 303 subjects (54,7%) had college education and 358 patients (64.74%) were of fars ethnicity. we found that 68 (12.3%), 44 (7.9%), and 13 (2.3%) of participants were smokers, hookah and opium users, respectively. history of appendectomy was reported in 58 of patients (10.48%). the most common medication was 5-aminosalicylate (94.39%). conclusions to the best of our knowledge, ircc is the first national ibd registry in the middle east and could become a reliable infrastructure for national and international research on ibd. ircc will improve the quality of care of ibd patients and provide national information for policy makers to better plan for controlling ibd in iran.",
            "contribution_ids": [
                "R142093"
            ]
        },
        {
            "instance_id": "EMPTYxR211059",
            "comparison_id": "EMPTY",
            "paper_id": "R211059",
            "text": "Scalable One-Step Wet-Spinning of Graphene Fibers and Yarns from Liquid Crystalline Dispersions of Graphene Oxide: Towards Multifunctional Textiles key points in the formation of liquid crystalline (lc) dispersions of graphene oxide (go) and their processability via wet\u2010spinning to produce long lengths of micrometer\u2010dimensional fibers and yarns are addressed. based on rheological and polarized optical microscopy investigations, a rational relation between go sheet size and polydispersity, concentration, liquid crystallinity, and spinnability is proposed, leading to an understanding of lyotropic lc behavior and fiber spinnability. the knowledge gained from the straightforward formulation of lc go \u201cinks\u201d in a range of processable concentrations enables the spinning of continuous conducting, strong, and robust fibers at concentrations as low as 0.075 wt%, eliminating the need for relatively concentrated spinning dope dispersions. the dilute lc go dispersion is proven to be suitable for fiber spinning using a number of coagulation strategies, including non\u2010solvent precipitation, dispersion destabilization, ionic cross\u2010linking, and polyelectrolyte complexation. one\u2010step continuous spinning of graphene fibers and yarns is introduced for the first time by in situ spinning of lc go in basic coagulation baths (i.e., naoh or koh), eliminating the need for post\u2010treatment processes. the thermal conductivity of these graphene fibers is found to be much higher than polycrystalline graphite and other types of 3d carbon based materials.",
            "contribution_ids": [
                "R211061",
                "R211063",
                "R213379",
                "R213397"
            ]
        },
        {
            "instance_id": "EMPTYxR188861",
            "comparison_id": "EMPTY",
            "paper_id": "R188861",
            "text": "in-vehicle network intrusion controller area network (can) is a bus communication protocol which defines a standard for reliable and efficient transmission between in-vehicle nodes in real-time. since can message is broadcast from a transmitter to the other nodes on a bus, it does not contain information about the source and destination address for validation. therefore, an attacker can easily inject any message to lead system malfunctions. in this paper, we propose an intrusion detection method based on the analysis of the offset ratio and time interval between request and response messages in can. if a remote frame having a particular identifier is transmitted, a receiver node should respond to the remote frame immediately. in attack-free state, each node has a fixed response offset ratio and time interval while these values vary in attack state. using this property, we can measure the response performance of the existing nodes based on the offset ratio and time interval between request and response messages. as a result, our methodology can detect intrusions by monitoring offset ratio and time interval, and it allows quick intrusion detection with high accuracy.",
            "contribution_ids": [
                "R188863"
            ]
        },
        {
            "instance_id": "EMPTYxR194155",
            "comparison_id": "EMPTY",
            "paper_id": "R194155",
            "text": "Car2X Communication: Securing the Last Meter - A Cost-Effective Approach for Ensuring Trust in Car2X Applications Using In-Vehicle Symmetric Cryptography the effectiveness of car2x communication strongly relies on trust in received data. securing in-vehicle communication is an essential yet so far overlooked step to achieve this objective. we present an approach based on the use of symmetric key material protected with inexpensive hardware. we modeled the involved cryptographic and network protocols, showed their applicability to automotive bus systems and conclude about their soundness with analytical and simulation methods. a prototype realization in real vehicles is envisaged as part of an ongoing project.",
            "contribution_ids": [
                "R194157"
            ]
        },
        {
            "instance_id": "EMPTYxR204210",
            "comparison_id": "EMPTY",
            "paper_id": "R204210",
            "text": "Accelerating PUF-based UAV Authentication Protocols Using Programmable Switch many uav technology use cases (e.g., traffic management) has ultra-low latency and strong security requirements. but achieving both simultaneously is challenging. in this work, we consider uav device authentication as a use case and develop a fast and secure uav device authentication system. our key idea is to leverage highly secure physically unclonable functions (pufs) and high-speed programmable packet-processing data planes, and develop a practically deployable puf-based authentication protocol for uavs that is (a) robust to various security attacks, and (b) enables uav authentication at network speed. in this work, we demonstrate the feasibility of our idea by offloading the authentication protocol to a tofino-based highspeed programmable switch. our preliminary experiments show that protocol offloading would reduce authentication latency significantly (approx. 100 %).",
            "contribution_ids": [
                "R204212"
            ]
        },
        {
            "instance_id": "EMPTYxR25003",
            "comparison_id": "EMPTY",
            "paper_id": "R25003",
            "text": "Predatory Open-Access Journals in India: A Study this paper analyses the list of predatory journals published by jeffrey beall. the study found that india is publishing the highest number of predatory journals. the state-wise analysis shows that the contribution of madhya pradesh is the highest in india. a trend reveals that majority of these journals are published after the year 2010.",
            "contribution_ids": [
                "R25004"
            ]
        },
        {
            "instance_id": "EMPTYxR191648",
            "comparison_id": "EMPTY",
            "paper_id": "R191648",
            "text": "Fake Accounts Detection on Twitter Using Blacklist social networking sites such as twitter, facebook, weibo etc. are extremely mainstream today. also, the greater part of the malicious users utilize these sites to persuade legitimate users for different purposes, for example, to promote their products item, to enter their spam links, to stigmatize other persons and so forth. an ever increasing number of users are utilized these social networking sites and fake accounts on these destinations are turned into a major issue. in this paper, fake accounts are detected using blacklist instead of traditional spam words list. blacklist is created by using topic modeling approach and keyword extraction approach. we conduct an evaluation experiment with not only 1ks - 10kn dataset but also social honeypot dataset. the accuracy of the traditional spam words list based approach and our blacklist based approach are compared. decorate, a meta-learner classifier is applied for classifying fake accounts on twitter from legitimate accounts. our approach achieves 95.4% accuracy and true positive rate is 0.95.",
            "contribution_ids": [
                "R191650"
            ]
        },
        {
            "instance_id": "EMPTYxR209105",
            "comparison_id": "EMPTY",
            "paper_id": "R209105",
            "text": "Bidirectional LSTM Based on POS tags and CNN Architecture for Fake News Detection fake news generally on social media spreads very quickly and this brings many serious consequences. traditional lexico-syntactic based features have limited success to detect fake news. majority of fake news detection techniques are tested on small dataset containing limited training examples. in this work, we evaluate our architecture on liar-liar dataset which contain 12836 short news from different sources including social media. the proposed architecture incorporates pos (part of speech) tags information of news article through bidirectional lstm and speaker profile information through convolutional neural network. the results show that the resulting hybrid architecture significantly improves detection performance of fake news on liar dataset.",
            "contribution_ids": [
                "R209107"
            ]
        },
        {
            "instance_id": "EMPTYxR209121",
            "comparison_id": "EMPTY",
            "paper_id": "R209121",
            "text": "Fake News Identification on Twitter with Hybrid CNN and RNN Models the problem associated with the propagation of fake news continues to grow at an alarming scale. this trend has generated much interest from politics to academia and industry alike. we propose a framework that detects and classifies fake news messages from twitter posts using hybrid of convolutional neural networks and long-short term recurrent neural network models. the proposed work using this deep learning approach achieves 82% accuracy. our approach intuitively identifies relevant features associated with fake news stories without previous knowledge of the domain.",
            "contribution_ids": [
                "R209123"
            ]
        },
        {
            "instance_id": "EMPTYxR209138",
            "comparison_id": "EMPTY",
            "paper_id": "R209138",
            "text": "TI-CNN: Convolutional Neural Networks for Fake News Detection with the development of social networks, fake news for various commercial and political purposes has been appearing in large numbers and gotten widespread in the online world. with deceptive words, people can get infected by the fake news very easily and will share them without any fact-checking. for instance, during the 2016 us president election, various kinds of fake news about the candidates widely spread through both official news media and the online social networks. these fake news is usually released to either smear the opponents or support the candidate on their side. the erroneous information in the fake news is usually written to motivate the voters' irrational emotion and enthusiasm. such kinds of fake news sometimes can bring about devastating effects, and an important goal in improving the credibility of online social networks is to identify the fake news timely. in this paper, we propose to study the fake news detection problem. automatic fake news identification is extremely hard, since pure model based fact-checking for news is still an open problem, and few existing models can be applied to solve the problem. with a thorough investigation of a fake news data, lots of useful explicit features are identified from both the text words and images used in the fake news. besides the explicit features, there also exist some hidden patterns in the words and images used in fake news, which can be captured with a set of latent features extracted via the multiple convolutional layers in our model. a model named as ti-cnn (text and image information based convolutinal neural network) is proposed in this paper. by projecting the explicit and latent features into a unified feature space, ti-cnn is trained with both the text and image information simultaneously. extensive experiments carried on the real-world fake news datasets have demonstrate the effectiveness of ti-cnn.",
            "contribution_ids": [
                "R209140"
            ]
        },
        {
            "instance_id": "EMPTYxR186224",
            "comparison_id": "EMPTY",
            "paper_id": "R186224",
            "text": "Building an AS-topology model that captures route diversity an understanding of the topological structure of the internet is needed for quite a number of networking tasks, e. g., making decisions about peering relationships, choice of upstream providers, inter-domain traffic engineering. one essential component of these tasks is the ability to predict routes in the internet. however, the internet is composed of a large number of independent autonomous systems (ases) resulting in complex interactions, and until now no model of the internet has succeeded in producing predictions of acceptable accuracy.we demonstrate that there are two limitations of prior models: (i) they have all assumed that an autonomous system (as) is an atomic structure - it is not, and (ii) models have tended to oversimplify the relationships between ases. our approach uses multiple quasi-routers to capture route diversity within the ases, and is deliberately agnostic regarding the types of relationships between ases. the resulting model ensures that its routing is consistent with the observed routes. exploiting a large number of observation points, we show that our model provides accurate predictions for unobserved routes, a first step towards developing structural mod-els of the internet that enable real applications.",
            "contribution_ids": [
                "R186226"
            ]
        },
        {
            "instance_id": "EMPTYxR186240",
            "comparison_id": "EMPTY",
            "paper_id": "R186240",
            "text": "Sibyl: A Practical Internet Route Oracle network operators measure internet routes to troubleshoot problems, and researchers measure routes to characterize the internet. however, they still rely on decades-old tools like traceroute, bgp route collectors, and looking glasses, all of which permit only a single query about internet routes--what is the path from here to there? this limited interface complicates answering queries about routes such as \"find routes traversing the level3/at&t peering in atlanta,\" to understand the scope of a reported problem there. \\n \\nthis paper presents sibyl, a system that takes rich queries that researchers and operators express as regular expressions, then issues and returns traceroutes that match even if it has never measured a matching path in the past. sibyl achieves this goal in three steps. first, to maximize its coverage of internet routing, sibyl integrates together diverse sets of traceroute vantage points that provide complementary views, measuring from thousands of networks in total. second, because users may not knowwhich measurements will traverse paths of interest, and because vantage point resource constraints keep sibyl from tracing to all destinations from all sources, sibyl uses historical measurements to predict which new ones are likely to match a query. finally, based on these predictions, sibyl optimizes across concurrent queries to decide which measurements to issue given resource constraints. we show that sibyl provides researchers and operators with the routing information they need--in fact, it matches 76% of the queries that it could match if an oracle told it which measurements to issue.",
            "contribution_ids": [
                "R186242"
            ]
        },
        {
            "instance_id": "EMPTYxR4796",
            "comparison_id": "EMPTY",
            "paper_id": "R4796",
            "text": "The hierarchy-of-hypotheses approach: A synthesis method for enhancing theory development in ecology and evolution in the current era of big data, existing synthesis tools (e.g. formal meta-analysis) are useful for handling the deluge of data and information. however, there is a need for complementary tools that help to (i) structure data and information, (ii) closely connect evidence to theory and (iii) further develop theory. we present the hierarchy-of-hypotheses (hoh) approach to address these issues. in an hoh, hypotheses are conceptually and visually structured in a hierarchically nested way, where the lower branches can be directly connected to empirical results. used as an evidence-driven, bottom-up approach, it can (i) show connections between empirical results, even when derived through diverse approaches; and (ii) indicate under which circumstances hypotheses are applicable. used as a theory-driven, top-down method, it helps uncover mechanistic components of hypotheses. we offer guidance on how to build an hoh, provide examples from population and evolutionary biology and propose terminological clarifications.",
            "contribution_ids": [
                "R4816"
            ]
        },
        {
            "instance_id": "EMPTYxR52092",
            "comparison_id": "EMPTY",
            "paper_id": "R52092",
            "text": "Species composition and diversity affect grassland susceptibility and response to invasion in a microcosm experiment, i tested how species composition, species rich- ness, and community age affect the susceptibility of grassland communities to invasion by a noxious weed (centaurea solstitialis l.). i also examined how these factors influenced centaurea\\'s impact on the rest of the plant community. when grown in monoculture, eight species found in california\\'s grasslands differed widely in their ability to suppress centaurea growth. the most effective competitor in monoculture was hemizonia congesta ssp. iuzulifolia, which, like centaurea, is a summer- active annual forb. on average, centaurea growth decreased as the species richness of communities increased. however, no polyculture suppressed centaurea growth more than the monoculture of hemizonia. centaurea generally made up a smaller proportion of com- munity biomass in newly created (\"new\") microcosms than in older (\"established\") mi- crocosms, largely because centaurea\\'s competitors were more productive in the new treat- ment. measures of complementarity suggest that centaurea partitioned resources with an- nual grasses in the new microcosms. this resource partitioning may help to explain cen- taurea\\'s great success in western north american grasslands. centaurea strongly suppressed growth of some species but hardly affected others. an- nual grasses were the least affected species in the new monocultures, and perennial grasses were among the least affected species in the established monocultures. in the new micro- cosms, centaurea\\'s suppression of competing species marginally abated with increasing species richness. this trend was a consequence of the declining success of centaurea in species-rich communities, rather than a change in the vulnerability of these communities to suppression by a given amount of the invader. the impact of the invader was not related to species richness in the-established microcosms. the results of this study suggest that, at the neighborhood level, diversity can limit invasibility and may reduce the impact of an invader.",
            "contribution_ids": [
                "R52093"
            ]
        },
        {
            "instance_id": "EMPTYxR52094",
            "comparison_id": "EMPTY",
            "paper_id": "R52094",
            "text": "Limiting similarity between invaders and dominant species in herbaceous plant communities? 1 limiting similarity theory predicts that successful invaders should differ functionally from species already present in the community. this theory has been tested by manipulating the functional richness of communities, but not other aspects of functional diversity such as the identity of dominant species. because dominant species are known to have strong effects on ecosystem functioning, i hypothesized that successful invaders should be functionally dissimilar from community dominants. 2 to test this hypothesis, i added seeds of 17 different species to two different experiments: one in a natural oldfield community that had patches dominated by different plant species, and one in grassland mesocosms that varied in the identity of the dominant species but not in species richness or evenness. i used indicator species analyses to test whether invaders had higher establishment success in plots with functionally different dominant species. 3 a large percentage of invader species (47\u201371%) in both experiments showed no difference in affinity across the different dominant treatments, although one\u2010third of species did show some evidence for limiting similarity. exotic invaders had much higher invasion success than native invaders, and seemed to be inhibited by dominant species that were functionally similar. however, even these invasion patterns were not consistent across the two experiments. 4 the results from this study show that there is some evidence that dominant species suppress invasion by functionally similar species, beyond the effect of simple presence or absence of species in communities, although it is not the sole factor affecting invasion success. patterns of invasion success were inconsistent across species and experiments, indicating that other studies using only a single species of invader to make conclusions about community invasibility should be interpreted with caution.",
            "contribution_ids": [
                "R52095"
            ]
        },
        {
            "instance_id": "EMPTYxR144046",
            "comparison_id": "EMPTY",
            "paper_id": "R144046",
            "text": "Land Use and Avian Species Diversity Along an Urban Gradient i examined the distribution and abundance of bird species across an urban gradient, and concomitant changes in community structure, by censusing summer resident bird populations at six sites in santa clara county, california (all former oak woodlands). these sites represented a gradient of urban land use that ranged from relatively undisturbed to highly developed, and included a biological preserve, recreational area, golf course, residential neighborhood, office park, and business district. the composition of the bird community shifted from predominantly native species in the undisturbed area to invasive and exotic species in the business district. species richness, shannon diversity, and bird biomass peaked at moderately disturbed sites. one or more species reached maximal densities in each of the sites, and some species were restricted to a given site. the predevelopment bird species (assumed to be those found at the most undisturbed site) dropped out gradually as the sites became more urban. these patterns were significantly related to shifts in habitat structure that occurred along the gradient, as determined by canonical correspondence analysis (cca) using the environmental variables of percent land covered by pavement, buildings, lawn, grasslands, and trees or shrubs. i compared each formal site to four additional sites with similar levels of development within a two-county area to verify that the bird communities at the formal study sites were rep- resentative of their land use category.",
            "contribution_ids": [
                "R144048"
            ]
        },
        {
            "instance_id": "EMPTYxR76020",
            "comparison_id": "EMPTY",
            "paper_id": "R76020",
            "text": "HealthIoT Ontology for Data Semantic Representation and Interpretation Obtained from Medical Connected Objects internet of things (iot) covers a variety of applications including the healthcare field. consequently, medical objects become connected to each other with the purpose to share and exchange health data. these medical connected objects raise issues on how to ensure the analysis, interpretation and semantic interoperability of the extensive obtained health data with the purpose to make an appropriate decision. this paper proposes a healthiot ontology for representing the semantic interoperability of the medical connected objects and their data; while an algorithm alleviates the analysis of the detected vital signs and the decision-making of the doctor. the execution of this algorithm needs the definition of several swrl rules (semantic web rule language).",
            "contribution_ids": [
                "R76022"
            ]
        },
        {
            "instance_id": "EMPTYxR76026",
            "comparison_id": "EMPTY",
            "paper_id": "R76026",
            "text": "Design and Implementation of e-Health System Based on Semantic Sensor Network Using IETF YANG recently, healthcare services can be delivered effectively to patients anytime and anywhere using e-health systems. e-health systems are developed through information and communication technologies (ict) that involve sensors, mobiles, and web-based applications for the delivery of healthcare services and information. remote healthcare is an important purpose of the e-health system. usually, the ehealth system includes heterogeneous sensors from diverse manufacturers producing data in different formats. device interoperability and data normalization is a challenging task that needs research attention. several solutions are proposed in the literature based on manual interpretation through explicit programming. however, programmatically implementing the interpretation of the data sender and data receiver in the e-health system for the data transmission is counterproductive as modification will be required for each new device added into the system. in this paper, an e-health system with the semantic sensor network (ssn) is proposed to address the device interoperability issue. in the proposed system, we have used ietf yang for modeling the semantic e-health data to represent the information of e-health sensors. this modeling scheme helps in provisioning semantic interoperability between devices and expressing the sensing data in a user-friendly manner. for this purpose, we have developed an ontology for e-health data that supports different styles of data formats. the ontology is defined in yang for provisioning semantic interpretation of sensing data in the system by constructing meta-models of e-health sensors. the proposed approach assists in the auto-configuration of ehealth sensors and querying the sensor network with semantic interoperability support for the e-health system.",
            "contribution_ids": [
                "R76028"
            ]
        },
        {
            "instance_id": "EMPTYxR76029",
            "comparison_id": "EMPTY",
            "paper_id": "R76029",
            "text": "Towards Consistent Data Representation in the IoT Healthcare Landscape nowadays, the enormous volume of health and fitness data gathered from iot wearable devices offers favourable opportunities to the research community. for instance, it can be exploited using sophisticated data analysis techniques, such as automatic reasoning, to find patterns and, extract information and new knowledge in order to enhance decision-making and deliver better healthcare. however, due to the high heterogeneity of data representation formats, the iot healthcare landscape is characterised by an ubiquitous presence of data silos which prevents users and clinicians from obtaining a consistent representation of the whole knowledge. semantic web technologies, such as ontologies and inference rules, have been shown as a promising way for the integration and exploitation of data from heterogeneous sources. in this paper, we present a semantic data model useful to: (1) consistently represent health and fitness data from heterogeneous iot sources; (2) integrate and exchange them; and (3) enable automatic reasoning by inference engines.",
            "contribution_ids": [
                "R76031"
            ]
        },
        {
            "instance_id": "EMPTYxR109317",
            "comparison_id": "EMPTY",
            "paper_id": "R109317",
            "text": "Groundwater Arsenic Contamination in the Ganga-Padma-Meghna-Brahmaputra Plain of India and Bangladesh magnitude of arsenic groundwater contamination, and its related health effects, in the ganga-meghnabrahmaputra (gmb) plain\u2014an area of 569,749 km2, with a population of over 500 million, which largely comprises the flood plains of 3 major river systems that flow through india and bangladesh. design: on the basis of our 17-yr\u2013long study thus far, we report herein the magnitude of groundwater arsenic contamination, its health effects, results of our analyses of biological and food samples, and our investigation into sources of arsenic in the gmb plain setting: the gmb plain includes the following states in india: uttar pradesh in the upper and middle ganga plain, bihar and jharkhand in the middle ganga plain, west bengal in the lower ganga plain, and assam in the upper brahmaputra plain. the country of bangladesh is located in the padma-meghna-brahmaputra plain. in a preliminary study,1 we identified arsenic in water samples from hand-operated tubewells in the gmb plain. levels in excess of 50 ppb (the permissible limit for arsenic in drinking water in india and bangladesh) were found in samples from 51 villages in 3 arsenic-affected districts of uttar pradesh, 202 villages in 6 districts in bihar, 11 villages in 1 district in jharkhand, 3,500 villages in 9 (of a total of 18) districts in west bengal, 2,000 villages in 50 (of a total of 64) districts in bangladesh, and 17 villages in 2 districts in assam. study populations: because, over time, new regions of arsenic contamination have been found, affecting additional populations, the characteristics of our study subjects have varied widely. we feel that, even after working for 17 yr in the gmb plain, we have had only a glimpse of the full extent of the problem. protocol: thus far, on the gmb plain, we have analyzed 145,000 tubewell water samples from india and 52,000 from bangladesh for arsenic contamination. in india, 3,781 villages had arsenic levels above 50 ppb and 5,380 villages had levels exceeding 10 ppb; in bangladesh, the numbers were 2,000 and 2,450, respectively. we also analyzed 12,954 urine samples, 13,560 hair samples, 13,758 nail samples, and 1,300 skin scale samples from inhabitants of the arsenic-affected villages. groundwater arsenic contamination in the ganga-padma-",
            "contribution_ids": [
                "R109319"
            ]
        },
        {
            "instance_id": "EMPTYxR175444",
            "comparison_id": "EMPTY",
            "paper_id": "R175444",
            "text": "Efficient synthesis of physically valid human motion \\n optimization is a promising way to generate new animations from a minimal amount of input data. physically based optimization techniques, however, are difficult to scale to complex animated characters, in part because evaluating and differentiating physical quantities becomes prohibitively slow. traditional approaches often require optimizing or constraining parameters involving joint torques; obtaining first derivatives for these parameters is generally an\\n o \\n (\\n d \\n 2 \\n ) process, where\\n d \\n is the number of degrees of freedom of the character. in this paper, we describe a set of objective functions and constraints that lead to linear time analytical first derivatives. the surprising finding is that this set includes constraints on physical validity, such as ground contact constraints. considering only constraints and objective functions that lead to linear time first derivatives results in fast per-iteration computation times and an optimization problem that appears to scale well to more complex characters. we show that qualities such as squash-and-stretch that are expected from physically based optimization result from our approach. our animation system is particularly useful for synthesizing highly dynamic motions, and we show examples of swinging and leaping motions for characters having from 7 to 22 degrees of freedom.\\n",
            "contribution_ids": [
                "R175446"
            ]
        },
        {
            "instance_id": "EMPTYxR175450",
            "comparison_id": "EMPTY",
            "paper_id": "R175450",
            "text": "Comparing Constraint-Based Motion Editing Methods tools for assisting with editing human motion have become one of the most active research areas in the field of computer animation. not surprisingly, the area has demonstrated some stunning successes in both research and practice. this paper explores the range of constraint-based techniques used to alter motions while preserving specific spatial features. we examine a variety of methods, defining a taxonomy of these methods that is categorized by the mechanism employed to enforce temporal constraints. we pay particular attention to a less explored category of techniques that we term per-frame inverse kinematics plus filtering, and we show how these methods may provide an easier to implement while retaining the benefits of other approaches.",
            "contribution_ids": [
                "R175452"
            ]
        },
        {
            "instance_id": "EMPTYxR175453",
            "comparison_id": "EMPTY",
            "paper_id": "R175453",
            "text": "A hierarchical approach to interactive motion editing for human-like figures this paper presents a technique for adapting existing motion of a human-like character to have the desired features that are specified by a set of constraints. this problem can be typically formulated as a spacetime constraint problem. our approach combines a hierarchical curve fitting technique with a new inverse kinematics solver. using the kinematics solver, we can adjust the configuration of an articulated figure to meet the constraints in each frame. through the fitting technique, the motion displacement of every joint at each constrained frame is interpolated and thus smoothly propagated to frames. we are able to adaptively add motion details to satisfy the constraints within a specified tolerance by adopting a multilevel bspline representation which also provides a speedup for the interpolation. the performance of our system is further enhanced by the new inverse kinematics solver. we present a closed-form solution to compute the joint angles of a limb linkage. this analytical method greatly reduces the burden of a numerical optimization to find the solutions for full degrees of freedom of a human-like articulated figure. we demonstrate that the technique can be used for retargetting a motion to compensate for geometric variations caused by both characters and environments. furthermore, we can also use this technique for directly manipulating a motion clip through a graphical interface. cr categories: i.3.7 [computer graphics]: threedimensional graphics\u2014animation; g.1.2 [numerical analysis]: approximation\u2014spline and piecewise polynomial approximation",
            "contribution_ids": [
                "R175455"
            ]
        },
        {
            "instance_id": "EMPTYxR178308",
            "comparison_id": "EMPTY",
            "paper_id": "R178308",
            "text": "The KIT whole-body human motion database we present a large-scale whole-body human motion database consisting of captured raw motion data as well as the corresponding post-processed motions. this database serves as a key element for a wide variety of research questions related e.g. to human motion analysis, imitation learning, action recognition and motion generation in robotics. in contrast to previous approaches, the motion data in our database considers the motions of the observed human subject as well as the objects with which the subject is interacting. the information about human-object relations is crucial for the proper understanding of human actions and their goal-directed reproduction on a robot. to facilitate the creation and processing of human motion data, we propose procedures and techniques for capturing of motion, labeling and organization of the motion capture data based on a motion description tree, as well as for the normalization of human motion to an unified representation based on a reference model of the human body. we provide software tools and interfaces to the database allowing access and efficient search with the proposed motion representation.",
            "contribution_ids": [
                "R178310"
            ]
        },
        {
            "instance_id": "EMPTYxR178323",
            "comparison_id": "EMPTY",
            "paper_id": "R178323",
            "text": "Interactive control of avatars animated with human motion data real-time control of three-dimensional avatars is an important problem in the context of computer games and virtual environments. avatar animation and control is difficult, however, because a large repertoire of avatar behaviors must be made available, and the user must be able to select from this set of behaviors, possibly with a low-dimensional input device. one appealing approach to obtaining a rich set of avatar behaviors is to collect an extended, unlabeled sequence of motion data appropriate to the application. in this paper, we show that such a motion database can be preprocessed for flexibility in behavior and efficient search and exploited for real-time avatar control. flexibility is created by identifying plausible transitions between motion segments, and efficient search through the resulting graph structure is obtained through clustering. three interface techniques are demonstrated for controlling avatar motion using this data structure: the user selects from a set of available choices, sketches a path through an environment, or acts out a desired motion in front of a video camera. we demonstrate the flexibility of the approach through four different applications and compare the avatar motion to directly recorded human motion.",
            "contribution_ids": [
                "R178325"
            ]
        },
        {
            "instance_id": "EMPTYxR189621",
            "comparison_id": "EMPTY",
            "paper_id": "R189621",
            "text": "Inverse Kinematics Techniques in Computer Graphics: A Survey: Inverse Kinematics Techniques in Computer Graphics inverse kinematics (ik) is the use of kinematic equations to determine the joint parameters of a manipulator so that the end effector moves to a desired position; ik can be applied in many areas, including robotics, engineering, computer graphics and video games. in this survey, we present a comprehensive review of the ik problem and the solutions developed over the years from the computer graphics point of view. the paper starts with the definition of forward and ik, their mathematical formulations and explains how to distinguish the unsolvable cases, indicating when a solution is available. the ik literature in this report is divided into four main categories: the analytical, the numerical, the data\u2010driven and the hybrid methods. a timeline illustrating key methods is presented, explaining how the ik approaches have progressed over the years. the most popular ik methods are discussed with regard to their performance, computational cost and the smoothness of their resulting postures, while we suggest which ik family of solvers is best suited for particular problems. finally, we indicate the limitations of the current ik methodologies and propose future research directions.",
            "contribution_ids": [
                "R189623"
            ]
        },
        {
            "instance_id": "EMPTYxR189637",
            "comparison_id": "EMPTY",
            "paper_id": "R189637",
            "text": "Human upper-body inverse kinematics for increased embodiment in consumer-grade virtual reality having a virtual body can increase embodiment in virtual reality (vr) applications. however, comsumer-grade vr falls short of delivering sufficient sensory information for full-body motion capture. consequently, most current vr applications do not even show arms, although they are often in the field of view. we address this shortcoming with a novel human upper-body inverse kinematics algorithm specifically targeted at tracking from head and hand sensors only. we present heuristics for elbow positioning depending on the shoulder-to-hand distance and for avoiding reaching unnatural joint limits. our results show that our method increases the accuracy compared to general inverse kinematics applied to human arms with the same tracking input. in a user study, participants preferred our method over displaying disembodied hands without arms, but also over a more expensive motion capture system. in particular, our study shows that virtual arms animated with our inverse kinematics system can be used for applications involving heavy arm movement. we demonstrate that our method can not only be used to increase embodiment, but can also support interaction involving arms or shoulders, such as holding up a shield.",
            "contribution_ids": [
                "R189639"
            ]
        },
        {
            "instance_id": "EMPTYxR189640",
            "comparison_id": "EMPTY",
            "paper_id": "R189640",
            "text": "Real-Time Inverse Kinematics Techniques for Anthropomorphic Limbs in this paper we develop a set of inverse kinematics algorithms suitable for an anthropomorphic arm or leg. we use a combination of analytical and numerical methods to solve generalized inverse kinematics problems including position, orientation, and aiming constraints. our combination of analytical and numerical methods results in faster and more reliable algorithms than conventional inverse jacobian and optimization-based techniques. additionally, unlike conventional numerical algorithms, our methods allow the user to interactively explore all possible solutions using an intuitive set of parameters that define the redundancy of the system.",
            "contribution_ids": [
                "R189642"
            ]
        },
        {
            "instance_id": "EMPTYxR191635",
            "comparison_id": "EMPTY",
            "paper_id": "R191635",
            "text": "A Full-Body Gesture Database for Automatic Gesture Recognition this paper presents a full-body gesture database which contains 2d video data and 3d motion data of 14 normal gestures, 10 abnormal gestures and 30 command gestures for 20 subjects. we call this database the korea university gesture (kug) database. using 3d motion cameras and 3 sets of stereo cameras, we captured 3d motion data and 3 pairs of stereo-video data at 3 different directions for normal and abnormal gestures. in case of command gestures, 2 pairs of stereo-video data is obtained by 2 sets of stereo cameras with different focal length in order to effectively capture views of whole body and upper body, simultaneously. in addition to these, the 2d silhouette data is synthesized by separating a subject and background in 2d stereo-video data and saved as binary mask images. in this paper, we describe the gesture capture system, the organization of database, the potential usages of the database and the way of obtaining the kug database",
            "contribution_ids": [
                "R191637"
            ]
        },
        {
            "instance_id": "EMPTYxR191641",
            "comparison_id": "EMPTY",
            "paper_id": "R191641",
            "text": "The CMU Motion of Body (MoBo) Database in march 2001 we started to collect the cmu motion of body (mobo) database. to date the database contains 25 individuals walking on a treadmill in the cmu 3d room. the subjects perform four different walk patterns: slow walk, fast walk, incline walk and walking with a ball. all subjects are captured using six high resolution color cameras distributed evenly around the treadmill. in this technical report we describe the capture setup, the collection procedure and the organization of the database.",
            "contribution_ids": [
                "R191642"
            ]
        },
        {
            "instance_id": "EMPTYxR8061",
            "comparison_id": "EMPTY",
            "paper_id": "R8061",
            "text": "Wind extremes in the North Sea Basin under climate change: An ensemble study of 12 CMIP5 GCMs: WIND EXTREMES IN THE NORTH SEA IN CMIP5 coastal safety may be influenced by climate change, as changes in extreme surge levels and wave extremes may increase the vulnerability of dunes and other coastal defenses. in the north sea, an area already prone to severe flooding, these high surge levels and waves are generated by low atmospheric pressure and severe wind speeds during storm events. as a result of the geometry of the north sea, not only the maximum wind speed is relevant, but also wind direction. climate change could change maximum wind conditions, with potentially negative effects for coastal safety. here, we use an ensemble of 12 coupled model intercomparison project phase 5 (cmip5) general circulation models (gcms) and diagnose the effect of two climate scenarios (rcp4.5 and rcp8.5) on annual maximum wind speed, wind speeds with lower return frequencies, and the direction of these annual maximum wind speeds. the 12 selected cmip5 models do not project changes in annual maximum wind speed and in wind speeds with lower return frequencies; however, we do find an indication that the annual extreme wind events are coming more often from western directions. our results are in line with the studies based on cmip3 models and do not confirm the statement based on some reanalysis studies that there is a climate\u2010change\u2010related upward trend in storminess in the north sea area.",
            "contribution_ids": [
                "R8062",
                "R8237"
            ]
        },
        {
            "instance_id": "EMPTYxR152812",
            "comparison_id": "EMPTY",
            "paper_id": "R152812",
            "text": "LNN-EL: A Neuro-Symbolic Approach to Short-text Entity Linking entity linking (el) is the task of disambiguating mentions appearing in text by linking them to entities in a knowledge graph, a crucial task for text understanding, question answering or conversational systems. in the special case of short-text el, which poses additional challenges due to limited context, prior approaches have reached good performance by employing heuristics-based methods or purely neural approaches. here, we take a different, neuro-symbolic approach that combines the advantages of using interpretable rules based on first-order logic with the performance of neural learning. even though constrained to use rules, we show that we reach competitive or better performance with sota black-box neural approaches. furthermore, our framework has the benefits of extensibility and transferability. we show that we can easily blend existing rule templates given by a human expert, with multiple types of features (priors, bert encodings, box embeddings, etc), and even with scores resulting from previous el methods, thus improving on such methods. as an example of improvement, on the lc-quad-1.0 dataset, we show more than 3% increase in f1 score relative to previous sota. finally, we show that the inductive bias offered by using logic results in a set of learned rules that transfers from one dataset to another, sometimes without finetuning, while still having high accuracy.",
            "contribution_ids": [
                "R152814",
                "R157525",
                "R157526",
                "R157530",
                "R161854"
            ]
        },
        {
            "instance_id": "EMPTYxR25908",
            "comparison_id": "EMPTY",
            "paper_id": "R25908",
            "text": "Development, Characterization, and Diagnostic Applications of Monoclonal Antibodies against Bovine Rotavirus abstract \\n hybridomas secreting monoclonal antibodies (mabs) against the nebraska calf diarrhea strain of bovine rotavirus (brv) were characterized. indirect fluorescent-antibody assay, immunodot assay, and immunoprecipitation were used to select hybridomas that produced anti-brv mabs. seven of the mabs were shown by sodium dodecyl sulfate-polyacrylamide gel electrophoresis and western blot assay to be reactive with the brv outer capsid protein, vp7, which has a molecular mass of 37.5 kda. none of the seven mabs were reactive with canine rotavirus, bovine coronavirus, or uninfected madin-darby bovine kidney cells. two clones, 8b4 (immunoglobulin g2a [igg2a]) and 2b11 (igg1), were found suitable for use in an antigen capture enzyme-linked immunosorbent assay for detecting brv in bovine fecal samples. both were subtype a specific (g6 subtype) but did not react with all isolates of brv group a.",
            "contribution_ids": [
                "R25909"
            ]
        },
        {
            "instance_id": "EMPTYxR25925",
            "comparison_id": "EMPTY",
            "paper_id": "R25925",
            "text": "One-step competitive immunochromatographic assay for semiquantitative determination of lipoprotein(a) in plasma \" abstract \\n numerous studies have associated high concentrations of lipoprotein(a) [lp(a)] with atherosclerosis. we developed a rapid, one-step competitive immunochromatographic assay to measure lp(a) in plasma. the assay is performed on a nitrocellulose membrane strip and the result is determined by a visual readout of rust-colored colloidal selenium. the assay is based on the principle that lp(a) in the sample will compete with lp(a)-coated colloidal selenium for binding to the anti-lp(a) monoclonal antibody immobilized on the assay strip in the format of four ladder bars. the number of capture bars that appear as a result of the formation of colloidal selenium color is proportional to the concentration of the lp(a) protein in the samples. the strip assay semiquantitatively measures lp(a) concentrations ranging from 0 to 180 mg/l of lp(a) protein in serum, plasma, or fingerstick whole-blood samples. this assay appears very useful for quick identification of individuals with above-normal concentrations of plasma lp(a) protein (&amp;gt; 70 mg/l), and has potential for monitoring a patient's response to treatment with lp(a)-lowering drugs. \"",
            "contribution_ids": [
                "R25926"
            ]
        },
        {
            "instance_id": "EMPTYxR25946",
            "comparison_id": "EMPTY",
            "paper_id": "R25946",
            "text": "Principles of some novel rapid dipstick methods for detection and characterization of verotoxigenic Escherichia coli aims: the verotoxigenic escherichia coli (vtec) serotype most commonly associated with verotoxin (vt) production is o157:h7, but other serotypes have also been implicated in food\u2010borne illness. these serotypes exhibit much greater genetic and biochemical diversity than e. coli o157:h7, making screening for all vtec difficult. here we describe development and testing of novel multi\u2010analyte antibody\u2010based dipstick methods for presumptive detection of vtec cells and vts, including non\u2010o157 serotypes.",
            "contribution_ids": [
                "R25947"
            ]
        },
        {
            "instance_id": "EMPTYxR25949",
            "comparison_id": "EMPTY",
            "paper_id": "R25949",
            "text": "Rapid, Sensitive, and Specific Lateral-Flow Immunochromatographic Device To Measure Anti-Anthrax Protective Antigen Immunoglobulin G in Serum and Whole Blood abstract \\n \\n evidence from animals suggests that anti-anthrax protective antigen (pa) immunoglobulin g (igg) from vaccination with anthrax vaccine adsorbed (ava) is protective against\\n bacillus anthracis \\n infection. measurement of anti-pa igg in human sera can be performed using either enzyme-linked immunosorbent assay or fluorescent covalent microsphere immunoassay (elisa) (r. e. biagini, d. l. sammons, j. p. smith, b. a. mackenzie, c. a. striley, v. semenova, e. steward-clark, k. stamey, a. e. freeman, c. p. quinn, and j. e. snawder, clin. diagn. lab. immunol. 11:50-55, 2004). both these methods are laboratory based. we describe the development of a rapid lateral-flow immunochromatographic assay (lfia) test kit for the measurement of anti-pa igg in serum or whole-blood samples (30-\u03bcl samples) using colloidal gold nanoparticles as the detection reagent and an internal control. using sera from 19 anthrax ava vaccinees (anti-pa igg range, 2.4 to 340 \u03bcg/ml) and 10 controls and pa-supplemented whole-blood samples, we demonstrated that the lfia had a sensitivity of approximately 3 \u03bcg/ml anti-pa igg in serum and \u223c14 \u03bcg/ml anti-pa igg in whole blood. preabsorption of sera with pa yielded negative anti-pa lfias. the diagnostic sensitivity and specificity of the assay were 100% using elisa-measured anti-pa igg as the standard. this kit has utility in determining anti-pa antibody reactivity in the sera of individuals vaccinated with ava or individuals with clinical anthrax.\\n",
            "contribution_ids": [
                "R25950"
            ]
        },
        {
            "instance_id": "EMPTYxR26071",
            "comparison_id": "EMPTY",
            "paper_id": "R26071",
            "text": "A Comparative Study Of Discomfort Caused By Indoor Air Pollution, Thermal Load And Noisec the relative importance of sensory air pollution, thermal load and noise was studied under controlled conditions in two identical environmental chambers. in one chamber subjects were exposed to various levels of either thermal load or poor indoor air quality. for each condition tested in this chamber, the subjects were exposed to a number of noise levels in an adjacent chamber with neutral thermal conditions and good indoor air quality in order to determine a noise level causing the same degree of discomfort. a total of 68 comparisons of the conditions in the two chambers were made by the same group of 16 subjects after one-minute exposure in each chamber. in the operative temperature range of 23\u201329\u00b0c, a 1\u00b0c change in operative temperature was found to have the same effect on human comfort as a change in perceived air quality of 2.4 decipol or a change in noise level of 3.9 db. for levels of perceived air quality up to 10 decipol, a 1 -decipol change in perceived air quality had the same effect on human comfort as a change in noise level of 1.2 db. a relationship between traffic noise level and percentage dissatisfied was established",
            "contribution_ids": [
                "R26072"
            ]
        },
        {
            "instance_id": "EMPTYxR26077",
            "comparison_id": "EMPTY",
            "paper_id": "R26077",
            "text": "Perceived Importance of the Quality of the Indoor Environment in Commercial Buildings recognition of the importance of the quality of the indoor environment (ieq) to health, comfort and productivity of building end users has produced increasing numbers of voluntary schemes whose assessment embraces a wide spectrum of environmental attributes. studies which aim to derive appropriate weighting factors for these attributes through soliciting the perceived importance from experts are abundant. this article reports the findings of a study which, based on face-to-face interviews with 548 end users and 66 building professionals, processed their perceived importance of ieq using the analytical hierarchy process (ahp). attributes included were thermal comfort, air cleanliness, odor and noise associated with the air conditioning system of typical commercial buildings. correlation analysis of the ranking results of the ahp weights revealed the difference in perceived importance of the attributes according to gender of the respondents. other factors also found to have influence on the perceived importance of the ieq were whether the respondents were professionals or other end users and the reason for them working or visiting the buildings and the duration of their stay. these all varied with psychophysical factors such as personal experiences, needs and expectations. further work is needed to study whether the weighting factors should be derived from the perceptions of experts, end users, or a balance between the two.",
            "contribution_ids": [
                "R26078"
            ]
        },
        {
            "instance_id": "EMPTYxR27113",
            "comparison_id": "EMPTY",
            "paper_id": "R27113",
            "text": "Kinetics of acetylcholinesterase immobilized on polyethylene tubing acetylcholinesterase was covalently attached to the inner surface of polyethylene tubing. initial oxidation generated surface carboxylic groups which, on reaction with thionyl chloride, produced acid chloride groups; these were caused to react with excess ethylenediamine. the amine groups on the surface were linked to glutaraldehyde, and acetylcholinesterase was then attached to the surface. various kinetic tests showed the catalysis of the hydrolysis of acetylthiocholine iodide to be diffusion controlled. the apparent michaelis constants were strongly dependent on flow rate and were much larger than the value for the free enzyme. rate measurements over the temperature range 6\u201342 \u00b0c showed changes in activation energies consistent with diffusion control.",
            "contribution_ids": [
                "R27114"
            ]
        },
        {
            "instance_id": "EMPTYxR27272",
            "comparison_id": "EMPTY",
            "paper_id": "R27272",
            "text": "The evolution of the entrepreneurial university a second academic revolution, integrating a mission for economic and social development is transforming the traditional teaching and research university into an entrepreneurial university. the triple helix thesis postulates that the interaction among university-industry-government is the key to improving the conditions for innovation in a knowledge-based society. more than the development of new products in firms, innovation is the creation of new arrangements among the institutional spheres that foster the conditions for innovation. invention of organisational innovations, new social arrangements and new channels for interaction becomes as important as the creation of physical devices in speeding the pace of innovation. this paper draws for data on interviews conducted by the author in the usa, sweden, brazil, italy, portugal and denmark.",
            "contribution_ids": [
                "R27273"
            ]
        },
        {
            "instance_id": "EMPTYxR27389",
            "comparison_id": "EMPTY",
            "paper_id": "R27389",
            "text": "Robust load frequency control using genetic algorithms and linear matrix inequalities in this paper, two robust decentralized control design methodologies for load frequency control (lfc) are proposed. the first one is based on h/sub /spl infin// control design using linear matrix inequalities (lmi) technique in order to obtain robustness against uncertainties. the second controller has a simpler structure, which is more appealing from an implementation point of view, and it is tuned by a proposed novel robust control design algorithm to achieve the same robust performance as the first one. more specifically, genetic algorithms (gas) optimization is used to tune the control parameters of the proportional-integral (pi) controller subject to the h/sub /spl infin// constraints in terms of lmi. hence, the second control design is called galmi. both proposed controllers are tested on a three-area power system with three scenarios of load disturbances to demonstrate their robust performances.",
            "contribution_ids": [
                "R27390"
            ]
        },
        {
            "instance_id": "EMPTYxR27708",
            "comparison_id": "EMPTY",
            "paper_id": "R27708",
            "text": "Nuclear energy consumption and economic growth in the US: an empirical note abstract this empirical note examines the relationship between nuclear energy consumption growth and real gross domestic product (gdp) growth within a neoclassical production function framework for the us using annual data from 1957 to 2006. the toda-yamamoto (1995) test for long-run granger-causality reveals the absence of granger-causality between nuclear energy consumption growth and real gdp growth which supports the neutrality hypothesis within the energy consumption-economic growth literature.",
            "contribution_ids": [
                "R27709"
            ]
        },
        {
            "instance_id": "EMPTYxR28510",
            "comparison_id": "EMPTY",
            "paper_id": "R28510",
            "text": "Accelerated testing of IGBT power modules to determine time to failure reliability of igbt power modules is crucial to their use in failure critical systems and with the advent of all electric and hybrid vehicles the need for good reliability data for igbt modules is essential. igbt power modules are constructed of layers and power dies, all of which are interconnected with solder or bond wires. these materials have dissimilar coefficients of thermal expansion and during its life, the igbt module experiences temperature changes which cause stresses to build up in the various materials eventually resulting in the failure of the module. because of the high robustness of these modules, testing in service for time to failure can be a very lengthy process. this paper describes a procedure and test rig which can automatically temperature cycle igbt power modules in a very short time and determine their life expectancy. the paper also shows test results from a number of modules and correlates this data to provide a time to failure for the modules.",
            "contribution_ids": [
                "R28511"
            ]
        },
        {
            "instance_id": "EMPTYxR28919",
            "comparison_id": "EMPTY",
            "paper_id": "R28919",
            "text": "Simulation analysis of dispatching rules for an automated interbay material handling system in wafer fab here, the performance evaluation of a double-loop interbay automated material handling system (amhs) in wafer fab was analysed by considering the effects of the dispatching rules. discrete event simulation models based on simple++ were developed to implement the heuristic dispatching rules in such an amhs system with a zone control scheme to avoid vehicle collision. the layout of an interbay system is a combination configuration in which the hallway contains double loops and the vehicles have double capacity. the results show that the dispatching rule has a significant impact on average transport time, waiting time, throughput and vehicle utilization. the combination of the shortest distance with nearest vehicle and the first encounter first served rule outperformed the other rules. furthermore, the relationship between vehicle number and material flow rate by experimenting with a simulation model was investigated. the optimum combination of these two factors can be obtained by response surface methodology.",
            "contribution_ids": [
                "R28920"
            ]
        },
        {
            "instance_id": "EMPTYxR29248",
            "comparison_id": "EMPTY",
            "paper_id": "R29248",
            "text": "ERP systems and open source: an initial review and some implications for SMEs purpose the purpose of this paper is to further build up the knowledge about reasons for small and mid\u2010sized enterprises (smes) to adopt open source enterprise resource planning (erp) systems. design/methodology/approach the paper presents and analyses findings in articles about proprietary erps and open source erps. in addition, a limited investigation of the distribution channel sourceforge for open source is made. findings the cost perspective seems to receive a high attention regarding adoption of open source erps. this can be questioned and the main conclusion is that costs seem to have a secondary role in adoption or non adoption of open source erps. research limitations/implications the paper is mainly a conceptual paper written from a literature review. the ambition is to search support for the findings by doing more research in the area. practical implications the findings presented are of interest both for developers of proprietary erps as well as smes since it is shown that there are definitely reasons other than costs involved when deciding on proprietary erps or open source erps. originality/value it can be argued that there is a lack of research conducted and published about why smes choose open source erps instead of proprietary erps. this paper identifies the gap and suggests future research directions about this subject.",
            "contribution_ids": [
                "R29249"
            ]
        },
        {
            "instance_id": "EMPTYxR29279",
            "comparison_id": "EMPTY",
            "paper_id": "R29279",
            "text": "Re-conceptualizing Information Systems Models: An Experience from ERP Systems Environment \"information systems have transformed organizations, performance and work. hence, the linkage between information systems and individual performance has been an ongoing concern in information systems (is) research. in the last decades, is researchers have concentrated their efforts in developing and testing models that help with the investigation of is and user performance in different environments. as a result, a number of models for studying end users' systems utilization and other related issues including system usefulness, system success and user aspects in business organizations have appeared. a synthesized model consolidating three well known and widely used models in is research is proposed. the model was empirically tested in a sophisticated is environment investigating the impacts of the enterprise recourse planning (erp) systems on user perceived performance. statistical analysis was performed including factors analysis and regression to test the model and prove its validity. the findings demonstrated that the proposed model performed well as most factors had direct and or indirect significant influences on user perceived performance suggesting therefore that the model possesses the ability to explain the main impacts of these factors on user performance.\"",
            "contribution_ids": [
                "R29280"
            ]
        },
        {
            "instance_id": "EMPTYxR29282",
            "comparison_id": "EMPTY",
            "paper_id": "R29282",
            "text": "ERP Systems' Usage in the German IT Service Industry: An Exploratory Multi-case Study \"in order to achieve efficiency and effectiveness gains, concepts such as standardization and automation originating in the manufacturing industry are adopted by it service providers. erp systems are tools to implement such concepts in manufacturing companies. this research examines if and how erp systems are used by it service providers. to answer this question, an interview-based exploratory multiple-case study is conducted because only very limited findings on the topic exist. representatives of 24 it service providers and erp vendors were interviewed. we found that erp systems are used by the studied companies: 21 out of 24 use erp systems. seven selected companies are presented in greater detail: one that doesn't use an erp system and six that do. we describe which functional areas are covered by their erp systems and which ones are covered by other application systems. for instance, all of the six companies use the material management module of their erp system, but four out of five cases used a non-erp standard application system for ticketing. finally, we found no case that used traditional production and planning capabilities of erp systems as suggested by previous design science work.\"",
            "contribution_ids": [
                "R29283"
            ]
        },
        {
            "instance_id": "EMPTYxR30542",
            "comparison_id": "EMPTY",
            "paper_id": "R30542",
            "text": "An SSL-based client-oriented anti-spoofing email application spoofing is a very common security threat to email applications. several powerful techniques have been developed to counteract spoofing, but most of them are server-oriented and transparent to the user. in this paper a client-oriented secure socket layer (ssl)-based anti-spoofing application is proposed. this application allows a client to send trusted emails and authenticate received emails using the ssl protocol. the application has been developed in java and it provides users with a table populated with details of all devices on a subnet. it uses cryptographic self-signed certificates to exchange a secure authentication message alongside the email with a view to prevent spoofing. the application has been tested on devices within the same subnet and it successfully authenticated valid email messages and detected spoofed ones. the main advantages of this application are the incorporation of ssl, its user-friendliness and its ability to allow users to use anti-spoofing measures independently of an email server.",
            "contribution_ids": [
                "R30543"
            ]
        },
        {
            "instance_id": "EMPTYxR31287",
            "comparison_id": "EMPTY",
            "paper_id": "R31287",
            "text": "Face and expression recognition based on bag of words method considering holistic and local image features this paper proposes a new framework for extracting facial features based on the bag of words method, and applies it to face and facial expression recognition. recently, the bag of words method has been successfully used in object recognition. however, for recognition problems of facial images, the orderless collection of local patches in bag of words method cannot provide strongly distinctive information since the object category (face image) is the same. in our work, a new framework based on bag of words is presented to extract discriminative local facial features while maintaining holistic spatial information at the same time. the new method is applied to both face and facial expression recognition. experimental results show that only using one neutral expression frame per person for training, our method can obtain the best face recognition performance ever on face images of ar database with extreme expressions, variant illuminations, and partial occlusions. for facial expression recognition, the average rate on the cohn-kanade database is 96.33%, which also outperforms the state of the arts.",
            "contribution_ids": [
                "R31288"
            ]
        },
        {
            "instance_id": "EMPTYxR31289",
            "comparison_id": "EMPTY",
            "paper_id": "R31289",
            "text": "Local Directional Number Pattern for Face Analysis: Face and Expression Recognition this paper proposes a novel local feature descriptor, local directional number pattern (ldn), for face analysis, i.e., face and expression recognition. ldn encodes the directional information of the face's textures (i.e., the texture's structure) in a compact way, producing a more discriminative code than current methods. we compute the structure of each micro-pattern with the aid of a compass mask that extracts directional information, and we encode such information using the prominent direction indices (directional numbers) and sign-which allows us to distinguish among similar structural patterns that have different intensity transitions. we divide the face into several regions, and extract the distribution of the ldn features from them. then, we concatenate these features into a feature vector, and we use it as a face descriptor. we perform several experiments in which our descriptor performs consistently under illumination, noise, expression, and time lapse variations. moreover, we test our descriptor with different masks to analyze its performance in different face analysis tasks.",
            "contribution_ids": [
                "R31290"
            ]
        },
        {
            "instance_id": "EMPTYxR29359",
            "comparison_id": "EMPTY",
            "paper_id": "R29359",
            "text": "Cloud ERP system customization challenges customization is one of the known challenges in traditional erp systems. with the advent of cloud erp systems, a question of determining the state of such systems regarding customization and configuration ability arises. as there are only a few literature sources partially covering this topic, a more comprehensive and systematic literature review is needed. thus, this paper presents a literature review performed in order to give an overview of reported research on \"cloud erp customization\" topic performed in the last 5 years. in two search iterations, a total of 32 relevant papers are identified and analyzed. the results show that several dominant research trends are identified along with 12 challenges and issues. additionally, based on the results, the possible future researches are proposed.",
            "contribution_ids": [
                "R29360"
            ]
        },
        {
            "instance_id": "EMPTYxR32957",
            "comparison_id": "EMPTY",
            "paper_id": "R32957",
            "text": "Zinc and Skin Health: Overview of Physiology and Pharmacology background\\nzinc is known to have a critical role in overall human physiology, which likely explains many of its therapeutic uses for the last several thousand years. the specific roles zinc plays in skin health and function are less widely known yet are likely just as critical based on the manifestations of dietary zinc deprivation, which include moderate to severe dermatitis.\\n\\n\\nobjective\\nto provide a critical review of the scientific literature as to the physiologic importance of zinc to skin, the biochemical basis for these effects, and pharmacologic aspects of zinc therapeutics.\\n\\n\\nresults and conclusions\\nskin is in a continual state of renewal, placing a high demand on zinc-based enzymes and proteins that direct this process. the importance of zinc physiologically is especially evident in studies of wound healing and inflammation reduction. during these processes, the high needs for zinc can be supplemented externally, generally increasing the rates of the natural processes. topical zinc delivery involves the pharmacologic optimization of zinc delivery, often mediated by the solubility of the zinc material and interactions within the product matrix.",
            "contribution_ids": [
                "R32958"
            ]
        },
        {
            "instance_id": "EMPTYxR33583",
            "comparison_id": "EMPTY",
            "paper_id": "R33583",
            "text": "Early Intensive Behavioral Treatment \"abstract. although previous studies have shown favorable results with early intensive behavioral treatment (eibt) for children with autism, it remains important to replicate these findings, particularly in community settings. the authors conducted a 3-year prospective outcome study that compared 2 groups: (1) 21 children who received 35 to 40 hours per week of eibt from a community agency that replicated lovaas' model of eibt and (2) 21 age- and iq-matched children in special education classes at local public schools. a quasi-experimental design was used, with assignment to groups based on parental preference. assessments were conducted by independent examiners for iq (bayley scales of infant development or wechsler preschool and primary scales of intelligence), language (reynell developmental language scales), nonverbal skill (merrill-palmer scale of mental tests), and adaptive behavior (vineland adaptive behavior scales). analyses of covariance, with baseline scores as covariates and year 1-3 assessments as repeated measures, revealed that, with treatment, the eibt group obtained significantly higher iq (f = 5.21, p = .03) and adaptive behavior scores (f = 7.84, p = .01) than did the comparison group. no difference between groups was found in either language comprehension (f = 3.82, p = .06) or nonverbal skill. six of the 21 eibt children were fully included into regular education without assistance at year 3, and 11 others were included with support; in contrast, only 1 comparison child was placed primarily in regular education. although the study was limited by the nonrandom assignment to groups, it does provide evidence that eibt can be successfully implemented in a community setting.\"",
            "contribution_ids": [
                "R33584"
            ]
        },
        {
            "instance_id": "EMPTYxR33591",
            "comparison_id": "EMPTY",
            "paper_id": "R33591",
            "text": "A two-year prospective follow-up study of community-based early intensive behavioural intervention and specialist nursery provision for children with autism spectrum disorders background\\nthis prospective study compared outcome for pre-school children with autism spectrum disorders (asd) receiving autism-specific nursery provision or home-based early intensive behavioural interventions (eibi) in a community setting.\\n\\n\\nmethods\\nforty-four 23- to 53-month-old children with asd participated (28 in eibi home-based programmes; 16 in autism-specific nurseries). cognitive, language, play, adaptive behaviour skills and severity of autism were assessed at intake and 2 years later.\\n\\n\\nresults\\nboth groups showed improvements in age equivalent scores but standard scores changed little over time. at follow-up, there were no significant group differences in cognitive ability, language, play or severity of autism. the only difference approaching significance (p = .06), in favour of the eibi group, was for vineland daily living skills standard scores. however, there were large individual differences in progress, with intake iq and language level best predicting overall progress.\\n\\n\\nconclusions\\nhome-based eibi, as implemented in the community, and autism-specific nursery provision produced comparable outcomes after two years of intervention.",
            "contribution_ids": [
                "R33592"
            ]
        },
        {
            "instance_id": "EMPTYxR33629",
            "comparison_id": "EMPTY",
            "paper_id": "R33629",
            "text": "Adult outcome for children with autism \"background\\ninformation on long-term prognosis in autism is limited. outcome is known to be poor for those with an iq below 50, but there have been few systematic studies of individuals with an iq above this.\\n\\n\\nmethod\\nsixty-eight individuals meeting criteria for autism and with a performance iq of 50 or above in childhood were followed up as adults. their mean age when first seen was 7 years (range 3-15 years); at follow-up the average age was 29 years (range 21-48 years). outcome measures included standardised cognitive, language and attainment tests. information on social, communication and behavioural problems was obtained from the autism diagnostic interview (adi).\\n\\n\\nresults\\nalthough a minority of adults had achieved relatively high levels of independence, most remained very dependent on their families or other support services. few lived alone, had close friends, or permanent employment. communication generally was impaired, and reading and spelling abilities were poor. stereotyped behaviours or interests frequently persisted into adulthood. ten individuals had developed epilepsy. overall, only 12% were rated as having a 'very good' outcome; 10% were rated as 'good' and 19% as 'fair'. the majority was rated as having a 'poor' (46%) or 'very poor' (12%) outcome. individuals with a childhood performance iq of at least 70 had a significantly better outcome than those with an iq below this. however, within the normal iq range outcome was very variable and, on an individual level, neither verbal nor performance iq proved to be consistent prognostic indicators.\\n\\n\\nconclusions\\nalthough outcome for adults with autism has improved over recent years, many remain highly dependent on others for support. this study provides some information on prognostic indicators, but more fine-grained research is needed into the childhood variables that are associated with good or poor outcome.\"",
            "contribution_ids": [
                "R33630"
            ]
        },
        {
            "instance_id": "EMPTYxR33957",
            "comparison_id": "EMPTY",
            "paper_id": "R33957",
            "text": "Reversible data embedding using a difference expansion reversible data embedding has drawn lots of interest recently. being reversible, the original digital content can be completely restored. we present a novel reversible data-embedding method for digital images. we explore the redundancy in digital images to achieve very high embedding capacity, and keep the distortion low.",
            "contribution_ids": [
                "R33958"
            ]
        },
        {
            "instance_id": "EMPTYxR33967",
            "comparison_id": "EMPTY",
            "paper_id": "R33967",
            "text": "Reversible image watermarking using interpolation technique watermarking embeds information into a digital signal like audio, image, or video. reversible image watermarking can restore the original image without any distortion after the hidden data is extracted. in this paper, we present a novel reversible watermarking scheme using an interpolation technique, which can embed a large amount of covert data into images with imperceptible modification. different from previous watermarking schemes, we utilize the interpolation-error, the difference between interpolation value and corresponding pixel value, to embed bit \u00bf1\u00bf or \u00bf0\u00bf by expanding it additively or leaving it unchanged. due to the slight modification of pixels, high image quality is preserved. experimental results also demonstrate that the proposed scheme can provide greater payload capacity and higher image fidelity compared with other state-of-the-art schemes.",
            "contribution_ids": [
                "R33968"
            ]
        },
        {
            "instance_id": "EMPTYxR34462",
            "comparison_id": "EMPTY",
            "paper_id": "R34462",
            "text": "Production function, productivities, and capacity utilization of the Port of Mobile in this study, the author considers the problems related to the expansion of port facilities using economic theory as a basis for discussion and the port of mobile as an example.",
            "contribution_ids": [
                "R34463"
            ]
        },
        {
            "instance_id": "EMPTYxR44575",
            "comparison_id": "EMPTY",
            "paper_id": "R44575",
            "text": "The reciprocity of data integration in disaster risk analysis humanitarian organizations are increasingly challenged by the amount of data available to drive their decisions. useful data can come from many sources, exists in different formats, and merging it into a basis for analysis and planning often exceeds organizations\u2019 capacities and resources. at the same time, affected communities\u2019 participation in decision making processes is often hindered by a lack of information and data literacy capacities within the communities. we describe a participatory disaster risk analysis project in the central philippines where the community and a humanitarian ngo worked towards a joint understanding of disaster risks and coping capacities through data integration and it-supported analysis. we present findings from workshops, focus group discussions and semi-structured interviews, showing the reciprocal effects of the collaborative work. while the community valued the systematically gathered and structured evidence that supported their own risk perceptions and advocacy efforts, the humanitarian ngo revisited established work practices for data collection for analysis and planning.",
            "contribution_ids": [
                "R44577"
            ]
        },
        {
            "instance_id": "EMPTYxR50173",
            "comparison_id": "EMPTY",
            "paper_id": "R50173",
            "text": "Personal Knowledge Graphs: A Research Agenda knowledge graphs, organizing structured information about entities, and their attributes and relationships, are ubiquitous today. entities, in this context, are usually taken to be anyone or anything considered to be globally important. this, however, rules out many entities people interact with on a daily basis. in this position paper, we present the concept of personal knowledge graphs: resources of structured information about entities personally related to its user, including the ones that might not be globally important. we discuss key aspects that separate them for general knowledge graphs, identify the main challenges involved in constructing and using them, and define a research agenda.",
            "contribution_ids": [
                "R50175"
            ]
        },
        {
            "instance_id": "EMPTYxR50390",
            "comparison_id": "EMPTY",
            "paper_id": "R50390",
            "text": "A Technology-enhanced Smart Learning Environment based on the Combination of Knowledge Graphs and Learning Paths:  in our position paper on a technology-enhanced smart learning environment, we propose the innovative combination of a knowledge graph representing what one has to learn and a learning path defining in which order things are going to be learned. in this way, we aim to identify students\u2019 weak spots or knowledge gaps in order to individually assist them in reaching their goals. based on the performance of different learning paths, one might further identify the characteristics of a learning system that leads to successful students. in addition, by studying assessments and the different ways a particular problem can be solved, new methods for a multi-dimensional classification of assessments can be developed. the theoretical findings on learning paths in combination with the classification of assessments will inform the design and development of a smart learning environment. by combining a knowledge graph with different learning paths and the corresponding practical assessments we enable the creation of a smart learning tool. while the proposed approach can be applied to different educational domains and should lead to more effective learning environments fostering deep learning in schools as well as in professional settings, in this paper we focus on the domain of mathematics in primary and high schools as the main use case.",
            "contribution_ids": [
                "R50391"
            ]
        },
        {
            "instance_id": "EMPTYxR70539",
            "comparison_id": "EMPTY",
            "paper_id": "R70539",
            "text": "Development of an infection screening system for entry inspection at airport quarantine stations using ear temperature, heart and respiration rates after the outbreak of severe acute respiratory syndrome (sars) in 2003, many international airport quarantine stations conducted fever-based screening to identify infected passengers using infrared thermography for preventing global pandemics. due to environmental factors affecting measurement of facial skin temperature with thermography, some previous studies revealed the limits of authenticity in detecting infectious symptoms. in order to implement more strict entry screening in the epidemic seasons of emerging infectious diseases, we developed an infection screening system for airport quarantines using multi-parameter vital signs. this system can automatically detect infected individuals within several tens of seconds by a neural-network-based discriminant function using measured vital signs, i.e., heart rate obtained by a reflective photo sensor, respiration rate determined by a 10-ghz non-contact respiration radar, and the ear temperature monitored by a thermography. in this paper, to reduce the environmental effects on thermography measurement, we adopted the ear temperature as a new screening indicator instead of facial skin. we tested the system on 13 influenza patients and 33 normal subjects. the sensitivity of the infection screening system in detecting influenza were 92.3%, which was higher than the sensitivity reported in our previous paper (88.0%) with average facial skin temperature.",
            "contribution_ids": [
                "R70540",
                "R70570"
            ]
        },
        {
            "instance_id": "EMPTYxR70541",
            "comparison_id": "EMPTY",
            "paper_id": "R70541",
            "text": "A Pediatric Infection Screening System with a Radar Respiration Monitor for Rapid Detection of Seasonal Influenza among Outpatient Children background: seasonal influenza virus outbreaks cause annual epidemics, mostly during winter in temperate zone countries, especially resulting in increased morbidity and higher mortality in children. in order to conduct rapid screening for influenza in pediatric outpatient units, we developed a pediatric infection screening system with a radar respiration monitor. \\nmethods: the system conducts influenza screening within 10 seconds based on vital signs (i.e., respiration rate monitored using a 24 ghz microwave radar; facial temperature, using a thermopile array; and heart rate, using a pulse photosensor). a support vector machine (svm) classification method was used to discriminate influenza children from healthy children based on vital signs. to assess the classification performance of the screening system that uses the svm, we conducted influenza screening for 70 children (i.e., 27 seasonal influenza patients (11 \u00b1 2 years) at a pediatric clinic and 43 healthy control subjects (9 \u00b1 4 years) at a pediatric dental clinic) in the winter of 2013-2014. \\nresults: the screening system using the svm identified 26 subjects with influenza (22 of the 27 influenza patients and 4 of the 43 healthy subjects). the system discriminated 44 subjects as healthy (5 of the 27 influenza patients and 39 of the 43 healthy subjects), with sensitivity, specificity, positive predictive value (ppv), and negative predictive value (npv) of 81.5%, 90.7%, 84.6%, and 88.6%, respectively. \\nconclusion: the svm-based screening system achieved classification results for the outpatient children based on vital signs with comparatively high npv within 10 seconds. at pediatric clinics and hospitals, our system seems potentially useful in the first screening step for infections in the future.",
            "contribution_ids": [
                "R70542",
                "R70571"
            ]
        },
        {
            "instance_id": "EMPTYxR140147",
            "comparison_id": "EMPTY",
            "paper_id": "R140147",
            "text": "The Role of Advanced Sensing in Smart Cities in a world where resources are scarce and urban areas consume the vast majority of these resources, it is vital to make cities greener and more sustainable. advanced systems to improve and automate processes within a city will play a leading role in smart cities. from smart design of buildings, which capture rain water for later use, to intelligent control systems, which can monitor infrastructures autonomously, the possible improvements enabled by sensing technologies are immense. ubiquitous sensing poses numerous challenges, which are of a technological or social nature. this paper presents an overview of the state of the art with regards to sensing in smart cities. topics include sensing applications in smart cities, sensing platforms and technical challenges associated with these technologies. in an effort to provide a holistic view of how sensing technologies play a role in smart cities, a range of applications and technical challenges associated with these applications are discussed. as some of these applications and technologies belong to different disciplines, the material presented in this paper attempts to bridge these to provide a broad overview, which can be of help to researchers and developers in understanding how advanced sensing can play a role in smart cities.",
            "contribution_ids": [
                "R140148"
            ]
        },
        {
            "instance_id": "EMPTYxR151147",
            "comparison_id": "EMPTY",
            "paper_id": "R151147",
            "text": "Open source software for disaster management evaluating how the sahana disaster information system coordinates disparate institutional and technical resources in the wake of the indian ocean tsunami.",
            "contribution_ids": [
                "R151148",
                "R152894",
                "R153017",
                "R153410",
                "R153514",
                "R153629",
                "R153830",
                "R155916",
                "R156022"
            ]
        },
        {
            "instance_id": "EMPTYxR151149",
            "comparison_id": "EMPTY",
            "paper_id": "R151149",
            "text": "Recovering IT in a disaster: Lessons from Hurricane Katrina on august 29, 2005, hurricane katrina destroyed a data center and much of the communications infrastructure at the pascagoula and gulfport, mississippi, operations of the ship systems sector of northrop grumman corporation. simultaneously, the hurricane put a second data center out of commission in a shipyard near new orleans. the storm disrupted the lives of the sector\u2019s 20,000 employees and their dependents located in the gulf coast, caused over us$1 billion in damage for the company, and, for two weeks, brought two of the nation\u2019s largest shipyards to a standstill.2",
            "contribution_ids": [
                "R151150"
            ]
        },
        {
            "instance_id": "EMPTYxR151268",
            "comparison_id": "EMPTY",
            "paper_id": "R151268",
            "text": "Social Media in Crisis: When Professional Responders Meet Digital Volunteers abstract in this paper, we examine the socio-technical impact that social media has had on coordination between professional emergency responders and digital volunteers. drawing from the research literature, we outline the problem space and explore ways to improve coordination and collaboration between these two groups. possible improvements include mediators, revisiting trust, emergency policy and process changes, a bounded social environment, digital volunteer data as context, and computational solutions. as the space matures and collaboration improves, we predict that professional responders will begin to rely on the data and products produced by digital volunteers. volunteer groups will be challenged to mature as well, to develop volunteer management systems, permanent staff, data management practices, and training for new volunteers to ensure consistent response to professional responders as needed.",
            "contribution_ids": [
                "R151269",
                "R152963",
                "R153078",
                "R153471",
                "R153582",
                "R153692",
                "R153891",
                "R155978",
                "R156083"
            ]
        },
        {
            "instance_id": "EMPTYxR151308",
            "comparison_id": "EMPTY",
            "paper_id": "R151308",
            "text": "Twitter for Crisis Communication: Lessons Learned from Japan's Tsunami Disaster two weeks after the great tohoku earthquake followed by the devastating tsunami, we have sent open-ended questionnaires to a randomly selected sample of twitter users and also analysed the tweets sent from the disaster-hit areas. we found that people in directly affected areas tend to tweet about their unsafe and uncertain situation while people in remote areas post messages to let their followers know that they are safe. our analysis of the open-ended answers has revealed that unreliable retweets (rts) on twitter was the biggest problem the users have faced during the disaster. some of the solutions offered by the respondents included introducing official hash tags, limiting the number of rts for each hash tag and adding features that allow users to trace information by maintaining anonymity.",
            "contribution_ids": [
                "R151309"
            ]
        },
        {
            "instance_id": "EMPTYxR152991",
            "comparison_id": "EMPTY",
            "paper_id": "R152991",
            "text": "Assessing Risk Following a Wireless Emergency Alert: Are 90 Characters Enough? abstract in a relatively new initiative, homeland security and other emergency management officials use wireless cell technology to communicate wireless emergency alert (wea) messages to an increasingly mobile public. severe weather warnings represent one type of wea message that the public can receive on their cell phone. so far, officials have limited wea messages to 90 characters of text and therefore have excluded information-rich weather graphics like warning polygons and radar images. the question remains if this lean messaging strategy effectively communicates the risk and severity of the storm. in the current study, the researchers created prototype wea tornado warning messages equivalent to both popular mobile weather apps on the market and the national weather service\u2019s inws service to compare to typical wea text-only warnings. the study therefore investigates wea weather warning message effectiveness across one of four conditions: (1) wea (text-only) alert; (2) wea text+nws warning polygon; (3) wea text+radar image; and (4) wea text+warning polygon+radar image. participants were told they were driving through an unknown region of the us. the researchers asked participants to assess the perceived risk, perceived severity, and likelihood to contact a loved one for each message. the results indicate the decisions did not differ as a function of warning type. also, the participants\u2019 times to make the three decisions were equivalent across all four types of messages.",
            "contribution_ids": [
                "R152992",
                "R153099",
                "R153492",
                "R153609",
                "R153714",
                "R153912",
                "R156001",
                "R156102"
            ]
        },
        {
            "instance_id": "EMPTYxR152995",
            "comparison_id": "EMPTY",
            "paper_id": "R152995",
            "text": "Communicating with the Workforce during Emergencies: Developing an Employee Text Messaging Program in a Local Public Health Setting short message service (sms) text messaging can be useful for communicating information to public health employees and improving workforce situational awareness during emergencies. we sought to understand how the 1,500 employees at public health \u2013 seattle &amp; king county, washington, perceived barriers to and benefits of participation in a voluntary, employer-based sms program. based on employee feedback, we developed the system, marketed it, and invited employees to opt in. the system was tested during an ice storm in january 2012. employee concerns about opting into an sms program included possible work encroachment during non-work time and receiving excessive irrelevant messages. employees who received messages during the weather event reported high levels of satisfaction and perceived utility from the program. we conclude that text messaging is a feasible form of communication with employees during emergencies. care should be taken to design and deploy a program that maximizes employee satisfaction.",
            "contribution_ids": [
                "R152996",
                "R153101",
                "R153494",
                "R153611",
                "R153716",
                "R153914",
                "R156004",
                "R156104"
            ]
        },
        {
            "instance_id": "EMPTYxR158044",
            "comparison_id": "EMPTY",
            "paper_id": "R158044",
            "text": "Software Cinema-Video-based Requirements Engineering the dialogue between end-user and developer presents several challenges in requirements development. one issue is the gap between the conceptual models of end-users and formal specification/analysis models of developers. this paper presents a novel technique for the video analysis of scenarios, relating the use of video-based requirements to process models of software development. it uses a knowledge model-an rdf graph-based on a semiotic interpretation of film language, which allows mapping conceptual into formal models. it can be queried with rdql, a query language for rdf. the technique has been implemented with a tool which lets the analyst annotate objects as well as spatial or temporal relationships in the video, to represent the conceptual model. the video can be arranged in a scenario graph effectively representing a multi-path video. it can be viewed in linear time order to facilitate the review of individual scenarios by end-users. each multi-path scene from the conceptual model is mapped to a uml use case in the formal model. a uml sequence diagram can also be generated from the annotations, which shows the direct mapping of film language to uml. this sequence diagram can be edited by the analyst, refining the conceptual model to reflect deeper understanding of the application domain. the use of the software cinema technique is demonstrated with several prototypical applications. one example is a loan application scenario for a financial services consulting firm which acted as an end-user",
            "contribution_ids": [
                "R172935"
            ]
        },
        {
            "instance_id": "EMPTYxR159596",
            "comparison_id": "EMPTY",
            "paper_id": "R159596",
            "text": "At home with agents: exploring attitudes towards future smart energy infrastructures energy systems researchers are proposing a broad range of future \"smart\" energy infrastructures to promote more efficient management of energy resources. this paper considers how consumers might relate to these future smart grids within the uk. to address this challenge we exploited a combination of demonstration and animated sketches to convey the nature of a future smart energy infrastructure based on software agents. users\\' reactions suggested that although they felt an obligation to engage with energy issues, they were principally disinterested. users showed a considerable lack of trust in energy companies raising a dilemma of design. while users might welcome agents to help in engaging with complex energy infrastructures, they had little faith in those that might provide them. this suggests the need to consider how to design software agents to enhance trust in these socio-economic settings.",
            "contribution_ids": [
                "R159598"
            ]
        },
        {
            "instance_id": "EMPTYxR159604",
            "comparison_id": "EMPTY",
            "paper_id": "R159604",
            "text": "Speculative Requirements: Design Fiction and RE \"many innovative software products are conceived, developed and deployed without any conventional attempt to elicit stakeholder requirements. rather, they are the result of the vision and intuition of a small number of creative individuals, facilitated by the emergence of a new technology. in this paper we consider how the conditions that enable new products' emergence might be better anticipated, making innovations a little less reliant on individual vision and a little more informed by stakeholder need. this is particularly important where a new technology would have the potential for social impact, good or bad. speculative design seeks to explore this landscape. we describe a case study using a variant called design fiction to explore how plausible new technologies might impact on dementia care.\"",
            "contribution_ids": [
                "R159606"
            ]
        },
        {
            "instance_id": "EMPTYxR159623",
            "comparison_id": "EMPTY",
            "paper_id": "R159623",
            "text": "User model and system model: the yin and yang in user-centered software development software systems can be viewed from both external and internal perspectives. they are called user model and system model respectively in the human-computer interaction community. in this paper, we employ the yin-yang principle as an analytical tool for reviewing the relationship between the user model and the system model. in the traditional system-centered approach, the engineer is more concerned with the system model and does not pay much attention to the user model. however, as the user-centered approach has gained increasing acceptance in a number of projects, we claim that the user model and system model are the yin and yang in user-centered software development and, following the yin-yang principle, call for equal emphasis on both models. particularly, we propose using video-based scenarios as the representation of user models and reveal the benefits of the use of video in software development. as a case study, we describe how we have employed scenario videos in a project course and share best practices that we have identified for the creation of demo scenario videos.",
            "contribution_ids": [
                "R159625"
            ]
        },
        {
            "instance_id": "EMPTYxR159637",
            "comparison_id": "EMPTY",
            "paper_id": "R159637",
            "text": "Using video to re-present the user advocates of user-centered design and participatory design, also referred to as \u201cwork practice practitioners\u201d include computer scientists, systems designers, software engineers, social scientists, industrial and graphic designers, marketing, sales, and service personnel. working singly or in teams, we have been identifying and combining effective techniques and methods of: gathering data, interacting with user participants, representing activities and observations, and integrating findings with the design and construction of new technologies.",
            "contribution_ids": [
                "R159639"
            ]
        },
        {
            "instance_id": "EMPTYxR159657",
            "comparison_id": "EMPTY",
            "paper_id": "R159657",
            "text": "Supporting requirements with video-based analysis the dealing-room study is one of many studies that have used video to support requirements elicitation and the general design process. a growing body of experience with video-based ethnographies supports technology development in various domains, including air traffic and other control rooms, healthcare, public settings such as museums, and more experimental technologies, including media spaces and ubiquitous computing",
            "contribution_ids": [
                "R159659"
            ]
        },
        {
            "instance_id": "EMPTYxR159735",
            "comparison_id": "EMPTY",
            "paper_id": "R159735",
            "text": "Software Professionals are Not Directors: What Constitutes a Good Video? videos are one of the best documentation options for a rich and effective communication. they allow experiencing the overall context of a situation by representing concrete realizations of certain requirements. despite 35 years of research on integrating videos in requirements engineering (re), videos are not an established documentation option in terms of re best practices. several approaches use videos but omit the details about how to produce them. software professionals lack knowledge on how to communicate visually with videos since they are not directors. therefore, they do not necessarily have the required skills neither to produce good videos in general nor to deduce what constitutes a good video for an existing approach. the discipline of video production provides numerous generic guidelines that represent best practices on how to produce a good video with specific characteristics. we propose to analyze this existing know-how to learn what constitutes a good video for visual communication. as a plan of action, we suggest a literature study of video production guidelines. we expect to identify quality characteristics of good videos in order to derive a quality model. software professionals may use such a quality model for videos as an orientation for planning, shooting, post-processing, and viewing a video. thus, we want to encourage and enable software professionals to produce good videos at moderate costs, yet sufficient quality.",
            "contribution_ids": [
                "R159737"
            ]
        },
        {
            "instance_id": "EMPTYxR159798",
            "comparison_id": "EMPTY",
            "paper_id": "R159798",
            "text": "Keep Your Stakeholders Engaged: Interactive Vision Videos in Requirements Engineering one of the most important issues in requirements engineering (re) is the alignment of stakeholders\u2019 mental models. making sure that all stakeholders share the same vision of a changing system is crucial to the success of any project. misaligned mental models of stakeholders can lead to conflicting requirements. a promising approach to this problem is the use of video showing a system vision, so-called vision videos, which help stakeholders to disclose, discuss, and align their mental models of the future system. however, videos have the drawback of allowing viewers to adopt a passive role, as has been shown in research on e-learning. in this role, viewers tend to be inactive, unfocused and bored while watching a video. in this paper, we learn and adopt findings from scientific literature in the field of e-learning on how to mitigate this passive role while watching vision videos in requirements engineering. in this way, we developed concepts that incorporate interactive elements into vision videos to help viewers stay focused. these elements include questions that are asked during the video and ways for viewers to decide what happens next in the video. in a preliminary evaluation with twelve participants, we found statistically significant differences when comparing the interactive vision videos with their traditional form. using an interactive vision videos, viewers are noticeably more engaged and gather more information on the shown system.",
            "contribution_ids": [
                "R159800"
            ]
        },
        {
            "instance_id": "EMPTYxR160000",
            "comparison_id": "EMPTY",
            "paper_id": "R160000",
            "text": "Piezoresistive n-type 4H-SiC pressure sensor with membrane formed by mechanical milling a 4h-sic pressure sensor with piezoresistive transducers, for harsh environment applications, e.g., high temperature (\u223c650\u00b0c) and/or in corrosive chemicals is presented. the sensing membrane, 1 mm in diameter and 50 \u00b5m in thickness, was formed by milling (drilling) a bulk single crystal sic wafer. both transverse and longitudinal piezoresistors were formed on the membrane out of an n-type sic epitaxial layer. ohmic contacts were obtained with ta/ni/pt metallization followed by annealing at 1000\u00b0c for 20 min. the sensor was assembled on a small board and characterized under hydrostatic pressures up to 60 bar at room temperature. the obtained pressure sensitivity was 268 \u00b5v/v/bar. the sensor chip was exposed in air at 600\u00b0c for 165 hours and changes in bridge resistance were measured.",
            "contribution_ids": [
                "R160002"
            ]
        },
        {
            "instance_id": "EMPTYxR160015",
            "comparison_id": "EMPTY",
            "paper_id": "R160015",
            "text": "Demonstration of SiC Pressure Sensors at 750 \u00c2\u00b0C we report the first demonstration of mems-based 4h-sic piezoresistive pressure sensors tested at 750 \u00b0c and in the process confirmed the existence of strain sensitivity recovery with increasing temperature above 400 \u00b0c, eventually achieving near or up to 100 % of the room temperature values at 750 \u00b0c. this strain sensitivity recovery phenomenon in 4h-sic is uncharacteristic of the well-known monotonic decrease in strain sensitivity with increasing temperature in silicon piezoresistors. for the three sensors tested, the room temperature full-scale output (fso) at 200 psig ranged between 29 and 36 mv. although the fso at 400 \u00b0c dropped by about 60 %, full recovery was achieved at 750 \u00b0c. this result will allow the operation of sic pressure sensors at higher temperatures, thereby permitting deeper insertion into the engine combustion chamber to improve the accurate quantification of combustor dynamics.",
            "contribution_ids": [
                "R160017"
            ]
        },
        {
            "instance_id": "EMPTYxR160032",
            "comparison_id": "EMPTY",
            "paper_id": "R160032",
            "text": "Fabrication of SiC Sealing Cavity Structure for All-SiC Piezoresistive Pressure Sensor Applications high hardness and corrosion resistance of sic (silicon carbide) bulk materials have always been a difficult problem in the processing of an all-sic piezoresistive pressure sensor. in this work, we demonstrated a sic sealing cavity structure utilizing sic shallow plasma-etched process (\u226420 \u03bcm) and sic\u2013sic room temperature bonding technology. the sic bonding interface was closely connected, and its average tensile strength could reach 6.71 mpa. in addition, through a rapid thermal annealing (rta) experiment of 1 min and 10 mins in n2 atmosphere of 1000 \u00b0c, it was found that si, c and o elements at the bonding interface were diffused, while the width of the intermediate interface layer was narrowed, and the tensile strength could remain stable. this sic sealing cavity structure has important application value in the realization of an all-sic piezoresistive pressure sensor.",
            "contribution_ids": [
                "R160035"
            ]
        },
        {
            "instance_id": "EMPTYxR160037",
            "comparison_id": "EMPTY",
            "paper_id": "R160037",
            "text": "Design and Fabrication of Bulk Micromachined 4H-SiC Piezoresistive Pressure Chips Based on Femtosecond Laser Technology silicon carbide (sic) has promising potential for pressure sensing in a high temperature and harsh environment due to its outstanding material properties. in this work, a 4h-sic piezoresistive pressure chip fabricated based on femtosecond laser technology was proposed. a 1030 nm, 200 fs yb: kgw laser with laser average powers of 1.5, 3 and 5 w was used to drill blind micro holes for achieving circular sensor diaphragms. an accurate per lap feed of 16.2 \u03bcm was obtained under laser average power of 1.5 w. after serialized laser processing, the machining depth error of no more than 2% and the surface roughness as low as 153 nm of the blind hole were measured. the homoepitaxial piezoresistors with a doping concentration of 1019 cm\u22123 were connected by a closed-loop wheatstone bridge after a rapid thermal annealing process, with a specific contact resistivity of 9.7 \u00d7 10\u22125 \u03c9 cm2. our research paved the way for the integration of femtosecond laser micromachining and sic pressure sensor chips manufacturing.",
            "contribution_ids": [
                "R160041"
            ]
        },
        {
            "instance_id": "EMPTYxR160097",
            "comparison_id": "EMPTY",
            "paper_id": "R160097",
            "text": "\u00ce\u00b1(6H)-SiC pressure sensors at 350\u00c2\u00b0C 6h-sic piezoresistive pressure sensors operational at 350/spl deg/c, with potential to operate up to 600/spl deg/c, were batch fabricated and tested. the full scale output (fso) was 87.89 mv and 38.21 mv at 23/spl deg/c and 350/spl deg/c, respectively, at full scale pressure of 1000 psi. no serious degradation was observed when operated for ten hours at 308/spl deg/c. the temperature coefficient of resistance (tcr) was 1.52%/100/spl deg/c and 16%/100/spl deg/c at 140/spl deg/c and 350/spl deg/c, respectively. the temperature coefficient of gauge factor (tcgf) exhibited negative values of -26.1%/100/spl deg/c and -17.55%/100/spl deg/c at 140/spl deg/c and 350/spl deg/c, respectively. this work demonstrated batch manufacturing and operation of pressure sensors for temperatures beyond silicon technology.",
            "contribution_ids": [
                "R160099"
            ]
        },
        {
            "instance_id": "EMPTYxR161423",
            "comparison_id": "EMPTY",
            "paper_id": "R161423",
            "text": "Atomic Layer Deposition of Nanostructured TiO2 Photocatalysts via Template Approach two kinds of tio2 nanostructures, i.e., tio2-coated alumina membranes and tio2-coated ni nanowires, were prepared by combining different kinds of porous alumina, template-directed electrodeposition...",
            "contribution_ids": [
                "R161425"
            ]
        },
        {
            "instance_id": "EMPTYxR161439",
            "comparison_id": "EMPTY",
            "paper_id": "R161439",
            "text": "Atomic Layer Deposition of Ta-doped TiO2 Electrodes for Dye-Sensitized Solar Cells ta-doped tio 2 inverse opals were obtained by selective etching of a silica template after atomic layer deposition (ald) of ta-doped tio 2 films and were applied as an electrode for dye-sensitized solar cells (dsscs). ta content in the ta-doped tio 2 film was controlled by the ta/(ta+ti) unitcycle ratios in the ta\u2015tio 2 supercycle of ald. also, excellent step coverage of nearly 100% in the inverse opal structure was confirmed by field-emission scanning electron microscopy (fe-sem). maximum photo-conversion efficiency of 1.56% was achieved with the ta (3.4 atom %)-doped tio 2 inverse opal electrode due to increased photocurrent density. however, further ta doping (> 4.9 atom %) decreased the j sc and photoconversion efficiency.",
            "contribution_ids": [
                "R161441"
            ]
        },
        {
            "instance_id": "EMPTYxR161443",
            "comparison_id": "EMPTY",
            "paper_id": "R161443",
            "text": "Development of Inverted Organic Solar Cells with TiO2 Interface Layer by Using Low-Temperature Atomic Layer Deposition organic solar cells (oscs) with inverted structure have attracted much attention in recent years because of their improved device air stability due to the use of stable materials for electrodes and interface layers. in this work, tio(2) films, fabricated using low temperature (e.g., 130-170 \u00b0c) atomic layer deposition (ald) on ito substrates, are used as electron selective interface layers to investigate inverted oscs. it is found that though the as-deposited tio(2) films are high resistive due to the presence of oxygen defects, the defects can be significantly reduced by light soaking. pv cells with 15-nm-thick amorphous-tio(2) layers fabricated at low temperature show better performance than those with poly crystal tio(2) with same thickness deposited at 250 \u00b0c. the low temperature ald-grown tio(2) films are dense, stable and robust with capability of conformal coating on nanostructural surfaces, showing a promising interface layer for achieving air-stable plastic oscs with roll-to-roll mass production potential.",
            "contribution_ids": [
                "R161444"
            ]
        },
        {
            "instance_id": "EMPTYxR161450",
            "comparison_id": "EMPTY",
            "paper_id": "R161450",
            "text": "Low-Temperature Crystalline Titanium Dioxide by Atomic Layer Deposition for Dye-Sensitized Solar Cells low-temperature processing of dye-sensitized solar cells (dscs) is crucial to enable commercialization with low-cost, plastic substrates. prior studies have focused on mechanical compression of premade particles on plastic or glass substrates; however, this did not yield sufficient interconnections for good carrier transport. furthermore, such compression can lead to more heterogeneous porosity. to circumvent these problems, we have developed a low-temperature processing route for photoanodes where crystalline tio2 is deposited onto well-defined, mesoporous templates. the tio2 is grown by atomic layer deposition (ald), and the crystalline films are achieved at a growth temperature of 200 \u00b0c. the ald tio2 thickness was systematically studied in terms of charge transport and performance to lead to optimized photovoltaic performance. we found that a 15 nm tio2 overlayer on an 8 \u03bcm thick sio2 film leads to a high power conversion efficiency of 7.1% with the state-of-the-art zinc porphyrin sensitizer and cobalt bipyridine redox mediator.",
            "contribution_ids": [
                "R161451"
            ]
        },
        {
            "instance_id": "EMPTYxR161457",
            "comparison_id": "EMPTY",
            "paper_id": "R161457",
            "text": "High-speed atmospheric atomic layer deposition of ultra thin amorphous TiO2\n blocking layers at 100\u00e2\u0080\u0089\u00c2\u00b0C for inverted bulk heterojunction solar cells: AALD for inverted bulk heterojunction solar cells ultrafast, spatial atmospheric atomic layer deposition, which does not involve vacuum steps and is compatible with roll\u2010to\u2010roll processing, is used to grow high quality tio2 blocking layers for organic solar cells. dense, uniform thin tio2 films are grown at temperatures as low as 100\\u2009\u00b0c in only 37\\u2009s (~20\\u2009nm/min growth rate). incorporation of these films in p3ht\u2010pcbm\u2010based solar cells shows performances comparable with cells made using tio2 films deposited with much longer processing times and/or higher temperatures. copyright \u00a9 2013 john wiley & sons, ltd.",
            "contribution_ids": [
                "R161459"
            ]
        },
        {
            "instance_id": "EMPTYxR161474",
            "comparison_id": "EMPTY",
            "paper_id": "R161474",
            "text": "Atomic Layer Deposition of TiO2 for a High-Efficiency Hole-Blocking Layer in Hole-Conductor-Free Perovskite Solar Cells Processed in Ambient Air in this study we design and construct high-efficiency, low-cost, highly stable, hole-conductor-free, solid-state perovskite solar cells, with tio2 as the electron transport layer (etl) and carbon as the hole collection layer, in ambient air. first, uniform, pinhole-free tio2 films of various thicknesses were deposited on fluorine-doped tin oxide (fto) electrodes by atomic layer deposition (ald) technology. based on these tio2 films, a series of hole-conductor-free perovskite solar cells (pscs) with carbon as the counter electrode were fabricated in ambient air, and the effect of thickness of tio2 compact film on the device performance was investigated in detail. it was found that the performance of pscs depends on the thickness of the compact layer due to the difference in surface roughness, transmittance, charge transport resistance, electron-hole recombination rate, and the charge lifetime. the best-performance devices based on optimized tio2 compact film (by 2000 cycles ald) can achieve power conversion efficiencies (pces) of as high as 7.82%. furthermore, they can maintain over 96% of their initial pce after 651 h (about 1 month) storage in ambient air, thus exhibiting excellent long-term stability.",
            "contribution_ids": [
                "R161475"
            ]
        },
        {
            "instance_id": "EMPTYxR161477",
            "comparison_id": "EMPTY",
            "paper_id": "R161477",
            "text": "Optimization of TiO2 compact layer formed by atomic layer deposition for efficient perovskite solar cells the microstructure of the compact tio2 (c-tio2) layer formed by atomic layer deposition (ald) was investigated for optimization of organometal halide perovskite solar cells (pscs). the ald c-tio2 layer has an amorphous structure alleviating performance deterioration of the pscs caused by defects. to apply the optimized ald c-tio2 layer to the pscs, an efficiency of 18.36% was achieved. it is the top record among the pscs using a compact tio2 layer formed by ald.the microstructure of the compact tio2 (c-tio2) layer formed by atomic layer deposition (ald) was investigated for optimization of organometal halide perovskite solar cells (pscs). the ald c-tio2 layer has an amorphous structure alleviating performance deterioration of the pscs caused by defects. to apply the optimized ald c-tio2 layer to the pscs, an efficiency of 18.36% was achieved. it is the top record among the pscs using a compact tio2 layer formed by ald.",
            "contribution_ids": [
                "R161480"
            ]
        },
        {
            "instance_id": "EMPTYxR164396",
            "comparison_id": "EMPTY",
            "paper_id": "R164396",
            "text": "Engaging older people using participatory design the use of digital technologies is increasingly proposed in health and social care to address the aging population phenomenon but, in practice, the designers of these technologies are ill equipped to design for older people. we suggest participatory design as an approach to improving the quality of design for older people but, based on previous work and our own experiences, identify four central issues that participatory design approaches need to address. we describe an approach to early engagement in design with older people that address each of these issues and some of our experiences applying the approach in a variety of different design projects. we conclude by discussing some of the issues that have been highlighted when attempting apply this approach in different design contexts and the issues that have been raised when working with partners who are less committed to the idea of engaging with older adults in participatory design.",
            "contribution_ids": [
                "R164398"
            ]
        },
        {
            "instance_id": "EMPTYxR108400",
            "comparison_id": "EMPTY",
            "paper_id": "R108400",
            "text": "Comparison of Brain Network Models using Cross-Frequency Coupling and Attack Strategies \"several neuroimaging studies have suggested that functional brain connectivity networks exhibit \u201csmall-world\u201d characteristics, whereas recent studies based on structural data have proposed a \u201crich-club\u201d organization of brain networks, whereby hubs of high connection density tend to connect among themselves compared to nodes of lower density. in this study, we adopted an \u201cattack strategy\u201d to compare the rich-club and small-world organizations and identify the model that describes best the topology of brain connectivity. we hypothesized that the highest reduction in global efficiency caused by a targeted attack on each model's hubs would reveal the organization that better describes the topology of the underlying brain networks. we applied this approach to magnetoencephalographic data obtained at rest from neurologically intact controls and mild traumatic brain injury patients. functional connectivity networks were computed using phase-to-amplitude cross-frequency coupling between the \u03b4 and \u03b2 frequency bands. our results suggest that resting state meg connectivity networks follow a rich-club organization.\"",
            "contribution_ids": [
                "R108401",
                "R108410"
            ]
        },
        {
            "instance_id": "EMPTYxR108422",
            "comparison_id": "EMPTY",
            "paper_id": "R108422",
            "text": "Constrained maximum intensity optimized multi-electrode tDCS targeting of human somatosensory network transcranial direct current stimulation (tdcs) is a noninvasive method that delivers current through the scalp to enhance or suppress brain activity. the standard way of applying tdcs is by the use of two large rectangular sponge electrodes on the scalp. the resulting currents often stimulate a broad region of the brain distributed over brain networks. in order to address this issue, recently, multi-electrode transcranial direct current stimulation with optimized montages has been used to stimulate brain regions of interest (roi) with improved trade-off between focality and intensity of the electrical current at the target brain region. however, in many cases only the location of target region is considered and not the orientation. here we emphasize the importance of calculating the individualized target location and orientation by combined electroencephalography and magnetoencephalography (emeg) source analysis in individualized skull-conductivity calibrated finite element method (fem) head models and stimulate the target region by four different tdcs montages. we have chosen the generator of the p20/n20 component, located at brodmann area 3b and oriented mainly from posterior to anterior directions as our target for stimulation because it can be modeled as a single dipole source with a fixed position and orientation. the simulations will deliver optimized excitatory and inhibitory electrode montages that are in future investigations compared to standard and sham tdcs in a somatosensory experiment. we also present a new constrained maximum intensity (cmi) optimization approach that better distributes the currents over multiple electrodes, therefore should lead to less tingling and burning sensations at the skin, and thus allows an easier realization of the sham condition significantly reducing the current intensity parallel to the target.",
            "contribution_ids": [
                "R108423"
            ]
        },
        {
            "instance_id": "EMPTYxR108428",
            "comparison_id": "EMPTY",
            "paper_id": "R108428",
            "text": "Combined EEG/MEG Source Reconstruction of Epileptic Activity using a Two-Phase Spike Clustering Approach in recent years, several approaches have been introduced for estimating the spike onset zone within the irritative zone in epilepsy diagnosis for presurgical planning. one important direction utilizes source analysis from combined electroencephalography (eeg) and magnetoencephalography (meg), emeg, leveraging the benefits from the complementary properties of the two modalities. for emeg source reconstruction, an average across the annotated epileptic spikes is often used to improve the signal-to-noise-ratio (snr). in this contribution, we propose a two-phase clustering of interictal spikes with unsupervised learning methods, namely self organizing maps (som) and k-means. in addition, we investigate the accuracy of combined emeg source analysis on the sorted activity, using an individualized (with regard to both geometry and conductivity) six-compartment finite element head model with calibrated skull conductivity and white matter conductivity anisotropy. the results indicate that som eliminates the random variations of k-means and stabilizes the clustering efficiency. in terms of source reconstruction accuracy, this study demonstrates that the combined use of modalities reveals activity around two focal cortical dysplasias (fcds), of one epilepsy patient, one in the right frontal area and one smaller in the left premotor cortex. it is worth mentioning that only emeg could localize the left premotor fcd, which was then also found in surgery to be the responsible for triggering the epilepsy.",
            "contribution_ids": [
                "R108429"
            ]
        },
        {
            "instance_id": "EMPTYxR34470",
            "comparison_id": "EMPTY",
            "paper_id": "R34470",
            "text": "The development of a production function for a container terminal in the port of Melbourne dconned transport openuions and reuarch manager port of melbourne authority d i ross port statistician port of melbourne authority it is generally accepted that for australia to be competitive on world markets it must become more productive. as a trading nation it is dependent on a reliable transportation system in which container terminals are a vitalhnk for the shipment of goods and commodities. the waterfront in particular\u00b7 has been criticised for disadvantaging local exporters because of inefficiencies, an accusation that is all the more significant because of the large percentage of cargo that is carried by sea in order to find ways of increasing port productivity it is essential that it can be suitably measured. this paper is the study of an attempt to develop a production function for a container terminal in the port of melbourne as an alternative performance indicator to partial factor productivity measurement contact author: rudy reker port of melbourne authority world trade centre melbourne vie 3005 telephone: (03) 611 1895 fax: (03) 629 8121",
            "contribution_ids": [
                "R34471"
            ]
        },
        {
            "instance_id": "EMPTYxR50289",
            "comparison_id": "EMPTY",
            "paper_id": "R50289",
            "text": "Message Passing for Hyper-Relational Knowledge Graphs hyper-relational knowledge graphs (kgs) (e.g., wikidata) enable associating additional key-value pairs along with the main triple to disambiguate, or restrict the validity of a fact. in this work, we propose a message passing based graph encoder - stare capable of modeling such hyper-relational kgs. unlike existing approaches, stare can encode an arbitrary number of additional information (qualifiers) along with the main triple while keeping the semantic roles of qualifiers and triples intact. we also demonstrate that existing benchmarks for evaluating link prediction (lp) performance on hyper-relational kgs suffer from fundamental flaws and thus develop a new wikidata-based dataset - wd50k. our experiments demonstrate that stare based lp model outperforms existing approaches across multiple benchmarks. we also confirm that leveraging qualifiers is vital for link prediction with gains up to 25 mrr points compared to triple-based representations.",
            "contribution_ids": [
                "R50290"
            ]
        },
        {
            "instance_id": "EMPTYxR50671",
            "comparison_id": "EMPTY",
            "paper_id": "R50671",
            "text": "Querying the Semantic Web for Concept Identifiers to Annotate Research Datasets researchers are encouraged to describe and publish research datasets so that others can find and reuse it. following a semantic approach, well-known concept identifiers are necessary that can be used as values for meta-data properties to describe relevant characteristics of such a research artifact. multiple research disciplines, communities or initiatives have already created and published standardized terms as taxonomies or ontologies for that. however, these developments are distributed on the web. as a consequence, it can be difficult for researchers to become aware of already recommended structured terminologies. thus, they will further rely on ambiguous, literal annotations. in this paper, we investigate existing data sources in the semantic web that contain relevant terms to describe a research dataset in a structured, content-oriented and fine-grained way and how to integrate it in corresponding applications. we therefore analyze both linked data services and traditional terminology services on how to retrieve and filter terms for particular research-relevant characteristics. it is shown that a variety of well-structured communityspecific terminologies with relevant concepts already exist, but that community-overspanning building blocks are nevertheless missing. furthermore, filtering and mapping particular concepts is still a challenge to improve interdisciplinary publishing. keywords\u2013linked data; research data management; data publishing; fair; nfdi.",
            "contribution_ids": [
                "R50672"
            ]
        },
        {
            "instance_id": "EMPTYxR159803",
            "comparison_id": "EMPTY",
            "paper_id": "R159803",
            "text": "Using Vision Videos in a Virtual Focus Group: Experiences and Recommendations facilitated meetings are an established practice for the requirements engineering activities elicitation and validation. focus groups are one well-known technique to implement this practice. several researchers already reported the successful use of vision videos to stimulate active discussions among the participants of on-site focus groups, e.g., for validating scenarios and eliciting feedback. these vision videos show scenarios of a system vision. in this way, the videos serve all parties involved as a visual reference point to actively disclose, discuss, and align their mental models of the future system to achieve shared understanding. in the joint project trusd, we had planned to conduct such an on-site focus group using a vision video to validate a scenario of a future software tool, the so-called privacy dashboard. however, the covid-19 pandemic and its associated measures led to an increase in home and remote working, which also affected us. therefore, we had to replan and conduct the focus group virtually. in this paper, we report about our experiences and recommendations for the use of vision videos in virtual focus groups.",
            "contribution_ids": [
                "R159807"
            ]
        },
        {
            "instance_id": "EMPTYxR166677",
            "comparison_id": "EMPTY",
            "paper_id": "R166677",
            "text": "Conference Indexing in Digital Libraries: A Ranking Model and Case Study on dblp digital library curators make relevance decisions in their daily work to prioritize the most urgent metadata updates. in this work, we propose a complex relevance and ranking model to support the decision and prioritization process of digital library curators. our approach incorporates different aspects of relevance decisions into a framework for feasible data quality management in digital libraries. a case study demonstrates the effects of the factors we use to model these aspects.",
            "contribution_ids": [
                "R166679"
            ]
        },
        {
            "instance_id": "EMPTYxR108484",
            "comparison_id": "EMPTY",
            "paper_id": "R108484",
            "text": "IPOR: An Efficient IDA-Based Proof of Retrievability Scheme for Cloud Storage Systems with the arrival of big data era, cloud storage has become more ubiquitous. a growing number of consumers remote their data into cloud, as cloud can provide them with ample storage space and powerful computational capacity. however, storing data in cloud means that data is out of their control. how to verify the integrity of stored data and retrieve the corrupted data has become an urgent security problem. in this paper, we propose a new efficient proof of retrievability scheme, named as ipor, for cloud storage systems. the ipor not only can verify the integrity of remote data, but also can retrieve the original data of corrupted blocks from the healthy servers with probability 100%. moreover, ipor obviously decreases the complexity of data integrity tags and it requires performing a few multiplication and addition operations to retrieve the corrupted data. therefore, our scheme is much more efficient than the state-of-the-art schemes. in addition, the security analysis indicates that our scheme is provably secure.",
            "contribution_ids": [
                "R108485"
            ]
        },
        {
            "instance_id": "EMPTYxR108500",
            "comparison_id": "EMPTY",
            "paper_id": "R108500",
            "text": "Efficient Proofs of Retrievability with Public Verifiability for Dynamic Cloud Storage cloud service providers offer various facilities to their clients. the clients with limited resources opt for some of these facilities. they can outsource their bulk data to the cloud server. the cloud server maintains these data in lieu of monetary benefits. however, a malicious cloud server might delete some of these data to save some space and offer this extra amount of storage to another client. therefore, the client might not retrieve her file (or some portions of it) as often as needed. proofs of retrievability (por) provide an assurance to the client that the server is actually storing all of her data appropriately and they can be retrieved at any point of time. in a dynamic por scheme, the client can update her data after she uploads them to the cloud server. moreover, in publicly verifiable por schemes, the client can delegate her auditing task to some third party specialized for this purpose. in this work, we exploit the homomorphic hashing technique to design a publicly verifiable dynamic por scheme that is more efficient (in terms of bandwidth required between the client and the server) than the \u201cstate-of-the-art\u201d publicly verifiable dynamic por scheme. we also analyze security and performance of our scheme.",
            "contribution_ids": [
                "R108501",
                "R108502"
            ]
        },
        {
            "instance_id": "EMPTYxR108509",
            "comparison_id": "EMPTY",
            "paper_id": "R108509",
            "text": "SW-POR: A Novel POR Scheme Using Slepian-Wolf Coding for Cloud Storage cloud computing is a service by which the clients can outsource their data to the cloud storage server to deal with the local storage limitation. however, the cloud storage providers are untrustworthy, which can lead to several security challenges, such as data availability, data integrity, and data confidentiality. to mitigate the issues of data availability and data integrity, a novel slepian-wolf-based proof of retrievability (sw-por) scheme is proposed to enable the client to check whether the distributed data stored in the cloud servers is intact or not. the proposed sw-por scheme not only can obtain an optimal coded block size, but also it can provide the exact-repair feature and low complexity. in this paper, the security analysis and efficiency analysis are provided. simulation results show that the sw-por scheme can accomplish a significant improvement in computation time.",
            "contribution_ids": [
                "R108510"
            ]
        },
        {
            "instance_id": "EMPTYxR108513",
            "comparison_id": "EMPTY",
            "paper_id": "R108513",
            "text": "Towards Efficient Provable Data Possession in Cloud Storage provable data possession (pdp) allows data owner to periodically and remotely audit integrity of their data stored in a cloud storage, without retrieving the file and without keeping a local copy. ateniese et al. (ccs 07, acm tiss \u201911) proposed the first pdp scheme, which is very efficient in communication and storage. however their scheme requires a lot of group exponentiation operations: in the setup, one group exponentiation is required to generate a tag per each data block. in each verification, (equivalently) (m+ `) group exponentiations are required to generate a proof, where m is the size of a data block and ` is the number of blocks accessed during a verification. this paper proposed an efficient pdp scheme. compared to ateniese et al. (ccs 07, acm tiss \u201911), the proposed scheme has the same complexities in communication and storage, but is much more efficient in computation: in the setup, no expensive group exponentiations are required. in each verification, only m group exponentiations are required to generate a proof. our experiment shows that our scheme is about 400 times faster than ateniese et al. (ccs 07, acm tiss \u201911) in the setup phase. the security of the proposed scheme is proved under knowledge of exponent assumption and factorization assumption.",
            "contribution_ids": [
                "R108514"
            ]
        },
        {
            "instance_id": "EMPTYxR108515",
            "comparison_id": "EMPTY",
            "paper_id": "R108515",
            "text": "A Novel Zero Knowledge Proof of Retrievability proof of retrievability is a cryptographic tool which interacts between the data user and the server, and the server proves to the data user the integrity of data which he will download. it is a crucial problem in outsourcing storage such as cloud computing. in this paper, a novel scheme called the zero knowledge proof of retrievability is proposed, which combines proof of retrievability and zero knowledge proof. it has lower computation and communication complexity and higher security than the previous schemes.",
            "contribution_ids": [
                "R108516"
            ]
        },
        {
            "instance_id": "EMPTYxR137023",
            "comparison_id": "EMPTY",
            "paper_id": "R137023",
            "text": "Increased attention for computer-tailored health communications: an event-related potential study the authors tested whether individually tailored health communications receive more attention from the reader than nontailored health communications in a randomized, controlled trial among student volunteers (n = 24). they used objective measures of attention allocation during the message exposure. in a between-subjects design, participants had to read tailored or nontailored nutrition education messages and at the same time had to pay attention to specific odd auditory stimuli in a sequence of frequent auditory stimuli (odd ball paradigm). the amount of attention allocation was measured by recording event-related potentials (erps; i.e., n100 and p300 erps) and reaction times. for the tailored as opposed to the nontailored group, results revealed larger amplitudes for the n100 effect, smaller amplitudes for the p300 effect, and slower reaction times. resource allocation theory and these results suggest that those in the tailored group allocated more attention resources to the nutrition message than those in the nontailored group.",
            "contribution_ids": [
                "R137024"
            ]
        },
        {
            "instance_id": "EMPTYxR186589",
            "comparison_id": "EMPTY",
            "paper_id": "R186589",
            "text": "Low-Dimensional Model for Bike-Sharing Demand Forecasting that Explicitly Accounts for Weather Data with the increasing availability of big, transport-related datasets, detailed data-driven mobility analysis is becoming possible. trips with their origins, destinations, and travel times are now collected in publicly available databases, allowing for detailed demand forecasting with methods exploiting big and accurate data. in this paper, we predict the demand pattern of new york city bikes with a low-dimensional approach utilizing three-level data clustering. we use historical demand data along with temperature and precipitation to first aggregate and then decompose data to obtain meaningful clusters. the core of this approach lies in the proposed clustering technique, which reduces the dimension of the problem and, differently from other machine learning techniques, requires limited assumptions on the model or its parameters. the proposed method allows, for the given temperature and precipitation method, to obtain expected vector of movement (mean number and direction of trips) for each zone. in this paper, we synthesize more than 17 million trips into daily and zonal vectors of movement, which combined with weather data allow forecasting of the trip demand. the method allows us to predict the demand with over 75% accuracy, as shown in series of experiments in which various settings and parameterizations are validated against 25% holdout data.",
            "contribution_ids": [
                "R186591"
            ]
        },
        {
            "instance_id": "EMPTYxR210141",
            "comparison_id": "EMPTY",
            "paper_id": "R210141",
            "text": "Constructing citations: reviewing chat transcripts to improve citation assistance as a service purpose using chat transcripts from indiana university libraries, the authors examined a subset of transcripts involving citations. from this analysis, they propose improvements for citation assistance as a holistic service. design/methodology/approach two years of chat transcripts were examined and questions containing citation-related keywords were segregated for further examination. the authors used a test data set to create a coding scheme for the questions and responses. this scheme was then applied to all the citation-related transcripts. findings 390 of 11,553 transcripts included interactions about citations. in 42% of the transcripts, no specific citation style was mentioned. american psychological association and modern language association were the most frequently mentioned citation styles by chat users. business reports (company data and market research), periodicals (journal, newspaper or magazine articles), websites and government documents were the most often asked about formats, but there was a wide variety of other unusual formats. questions about endnote were more common than other types of citation management software. chat staff utilized a variety of responses including guiding the student by example, directing to an online resource for more information (85% of the responses) or referring to a citation management expert. an unexpected amount of hedging words in the responses indicates the presence of anxiety on the part of chat staff in responding to these types of questions. originality/value this paper goes beyond most existing studies of chat transcripts by using chat transcripts as data to guide service improvements for a commonly asked but not typically discussed set of questions.",
            "contribution_ids": [
                "R210143"
            ]
        },
        {
            "instance_id": "EMPTYxR210151",
            "comparison_id": "EMPTY",
            "paper_id": "R210151",
            "text": "AN OPTIMIZED PAGE RANK ALGORITHM WITH WEB MINING, WEB CONTENT MINING AND WEB STRUCTURE MINING with the rapid increase in internet technology, users get easily confused in large hypertext structure. the primary goal of the web site owner is to provide the relevant information to the users to fulfill their needs. in order to achieve this goal, they use the concept of web mining. web mining is used to categorize users and pages by analyzing the users\u201f behaviour, the content of the pages, and the order of the urls that tend to be accessed in order. most of the search engines are ranking their search results in response to users' queries to make their search navigation easier. with a web browser, one can view web pages that may contain text, images, videos, and other multimedia, and navigate between them via hyperlinks. it is very difficult for a user to find the high quality information which he wants. page ranking algorithm is needed which provide the higher ranking to the important pages. in this paper, we discuss the improvement of page ranking algorithm to provide the higher ranking to important pages. most of the search engines are ranking their search results in response to user\u2019s queries to make their search navigations easier.",
            "contribution_ids": [
                "R210153"
            ]
        },
        {
            "instance_id": "EMPTYxR210158",
            "comparison_id": "EMPTY",
            "paper_id": "R210158",
            "text": "3B G\u00c3\u00b6rselle\u00c5\u009ftirme Ortam\u00c4\u00b1 Olarak Web Taray\u00c4\u00b1c\u00c4\u00b1lar\u00c4\u00b1 y\u00fcksek kaliteli 3b imajlar\u0131n elde edilebildi\u011fi modelleme ve bilgisayar programlar\u0131nda kar\u015f\u0131la\u015f\u0131lan i\u015flem zorlu\u011fu, yeni platformlar\u0131n geli\u015ftirilmesini gerekli k\u0131lan \u00f6nemli bir etkendir. web taray\u0131c\u0131lar\u0131 ile \u00e7al\u0131\u015fan ve ger\u00e7ek zamanl\u0131 etkile\u015fime izin veren 3b grafik kitapl\u0131klar\u0131, tasar\u0131m ve yaz\u0131l\u0131m\u0131n birlikte y\u00fcr\u00fct\u00fclebildi\u011fi platformlar haline gelmektedir. bu \u00e7al\u0131\u015fman\u0131n amac\u0131, web ortam\u0131n\u0131n kullan\u0131m \u015fekillerini ve 3b g\u00f6rselle\u015ftirmedeki potansiyellerini ke\u015ffetmektir. 3b grafiklerde bildirimsel ve zorunlu s\u0131n\u0131fland\u0131rman\u0131n incelenmesinden sonra, web uygulamas\u0131 ve i\u00e7erik \u00fcretiminde zorunlu olan ve son zamanlarda \u00f6n plana \u00e7\u0131kan webgl standard\u0131na odaklan\u0131lmaktad\u0131r. bu ba\u011flamda, tasar\u0131mlar\u0131n temsil s\u00fcrecinde etkile\u015fimli 3b web grafiklerinin kullan\u0131m\u0131na y\u00f6nelik tart\u0131\u015f\u0131lan yakla\u015f\u0131mlar \u015funlard\u0131r: 1. ger\u00e7ek zamanl\u0131 etkile\u015fime ve komut dosyas\u0131 arac\u0131l\u0131\u011f\u0131yla 3b modellemeye izin veren web grafi\u011fi kitapl\u0131klar\u0131. 2. web taray\u0131c\u0131lar\u0131ndan yararlanman\u0131n ikinci yolu olarak, masa\u00fcst\u00fc bilgisayarlarda 3d modelleme programlar\u0131na eklenti olarak geli\u015ftirilen ve web entegrasyonu sa\u011flayan ara\u00e7lar. 3. hem bir web taray\u0131c\u0131s\u0131nda modeller sunan hem de e\u015f zamanl\u0131 kodlamaya izin veren k\u00fct\u00fcphane tabanl\u0131 edit\u00f6rler incelenmi\u015ftir. \u00e7al\u0131\u015fmada haz\u0131rlanan genel \u00e7er\u00e7eve, bu yakla\u015f\u0131mlar\u0131n modelleme ve g\u00f6rselle\u015ftirme odakl\u0131 kullan\u0131m\u0131n\u0131 web grafik k\u00fct\u00fcphaneleri ba\u011flam\u0131nda sunarak; avantaj ve dezavantajlar\u0131n\u0131 ele almaktad\u0131r.",
            "contribution_ids": [
                "R210160"
            ]
        },
        {
            "instance_id": "EMPTYxR210164",
            "comparison_id": "EMPTY",
            "paper_id": "R210164",
            "text": "Ontological methods and tools for semantic extension of the media WIKI technology practical aspects of ontological approach to organization of intelligent wiki-based information resources (ir) are considered. we analyze the main features, capabilities and limitations of mediawiki as a technological platform for development of the web-based information resource and suggest main directions of its refinement. we propose an abstract model of mediawiki architecture that formalizes relations between the main components of this software environment and analyze the ways of its semantic extensions based on ontological representation of domain knowledge. an original algorithm of semantic wiki pages matching with domain ontology is developed. we propose an ontological model of ir that formalizes its knowledge base structure and explicitly performs main features of typical information objects (tio) of this ir. such tios depend on domain specifics and purposes of ir, therefore their development has to involve domain experts and knowledge engineers. use of ontology corresponding to the set of wiki pages (either with semantic markup or without it) provides new ir functions associated with semantic search and navigation. other important aspect of intelligent wiki resource development deals with adaptation of user interface to the specifics of ir: enabling various tools of navigation, visualization and content analysis by processing of tio features enriches ir functionality, reduces access time to information and makes usage of ir more efficient. developing additional mediawiki functionality with new requests to the mediawiki api using tio templates, extends data analysis and integration capabilities, and offers different, user-focused, ir content views expands the possibilities of data integration and proposes various user-oriented representations of ir content. wiki resource semantization allows the use knowledge acquired from such ir by external application, or example, by search engines for intelligent web retrieval. domain ontologies based on various subsets of the wiki pages and generated by them thesauri can be used by various semantic web applications, both independently or in general technological chain for personified retrieval focused on individual users and their tasks. approbation of this approach is demonstrated by maips retrieval system. we consider the use semantic similarity of concepts represented by wiki-pages of ir as an additional way of intelligent navigation between these pages. such approach allows to group wiki pages according to user interests by different aspects of their content and structure. wiki ontologies are considered as the basis for estimation of semantic similarity between domain concepts pertinent to user task. such elements of wiki ontology as classes, property values of class instances and relations between them are used as parameters for the quantitative assessment of semantic similarity of wiki pages. we propose to use local similarity and generate the sets of semantically similar concepts (ssc) that takes into account some subset of page properties and categories defined by user needs. such sets of sscs can be considered as user task thesauri for other applications. in addition, we propose to enrich the basic tools of mediawiki used for access management to the ir content with specialized software code that performs content classification that take into consideration separate namespaces, categories, templates and semantic properties of tio acquired from wiki markup. we demonstrate the software implementation of proposed solutions by developing of portal version of the great ukrainian encyclopedia (e-vue) that contains heterogeneous multimedia content with complex structure. we analyze the specifics of e-vue knowledge system and develop its formalized tio representation based on semantic web technologies and ontological analysis. ontological model of e-vue and original methods of its processing used for this project extend the functionality of the portal in the area of search, navigation, integration and protection of content based on background domain knowledge. in addition, original user interface of e-vue is developed with an allowance for encyclopedia knowledge specifics, substantially differs from the standard wiki, meets the requirements, goals and objectives of this ir and provides a lot of additional features.",
            "contribution_ids": [
                "R210166"
            ]
        },
        {
            "instance_id": "EMPTYxR210176",
            "comparison_id": "EMPTY",
            "paper_id": "R210176",
            "text": "Educating PhD students for knowledge-driven society universities educate students for working in knowledge-driven societies. whereas subject-related knowledge is part of every curriculum, institutions of higher education fail to teach systematically how to utilize and benefit from today\u2019s variety of digital tools. students and researchers are mostly unaware of what they lack to work more effectively and efficiently and to benefit from existing knowledge. since this lack of awareness is not obvious to students and researchers (unknown unknowns; you cannot miss something that you do not know), it is difficult to convince them that there is a gap that needs to be filled. &#x0d; in 2014, we decided to tackle this problem by creating and developing the course \u201cscientific information retrieval &amp; management in life sciences and chemistry\u201d. the unique 2 ects course features a multi-level approach to obtain and employ scientific information and to get students information savvy. on one hand, the course demonstrates the bigger picture: we discuss the aspects of scientific writing and publishing, critical choice of data sources, patents, visualisation and design, text mining and data pipelining, knowledge generation, outreach and impact of publications. on the other hand, we highlight an extensive list of field-proven tools that can assist researchers in their daily activities. &#x0d; we also wanted to foster a lasting impact on how students utilize databases, tools, software, and web services. thus, at the end of the course students have to write an essay describing their current information workflow or their (un)met information needs. these essays confirm and explain how the students changed their information use, and which parts of the course they may have not understood. moreover, essays that describe unmet information needs allow us to explore possible solutions and to work with our vendors. in our talk, we will share the concept for the course and report on our experiences.",
            "contribution_ids": [
                "R210178"
            ]
        },
        {
            "instance_id": "EMPTYxR210179",
            "comparison_id": "EMPTY",
            "paper_id": "R210179",
            "text": "Dual-Component Ontograph Visualization abstract today there are several generally accepted methods of storing data in an information network. one of the most modern is the presentation of data in the form of a semi-structured (with the possibility of fuzzy formalization) set \u2013 a knowledge base. compared to databases, this view has several advantages: the ability to store complex heterogeneous information; the ability to expand and supplement the description of the subject area without reprogramming; visibility and accessibility of knowledge presentation to the user. but this advantage of them turns into a problem, which currently has been only partially solved. the data in the knowledge base can be in such a form that their presentation according to formalized rules and algorithms is impossible or ineffective. currently, the most promising in terms of representing data structures is considered to be an ontological representation that copes well with displaying an arbitrary structure. most of the visual representations of ontologies (prot\u00e9g\u00e9 in integration with owlviz, ontograf, 3d hyperbolyc, tree, etc.) are images of nodes as a set of conditional points (small geometric shapes) connected by lines \u2013ontographs. this approach to visualization is less informative and inconvenient to apply to the educational process. the need to create new approaches to the presentation of information, implement its accessibility and efficiency of usage is becoming increasingly important. along with traditional information support in the form of databases, knowledge bases have begun to develop at a tremendous pace, which, when used effectively, provide significant competitive advantages. an important feature of knowledge bases is the ability to work with approximate sets. the authors developed ontograph visualization technology, partially implemented on the ontos.xyz web resource. this resource allows you to visualize the vertices of the ontograph, the connections between them and assign each set of contexts that are related to it. each of the nodes of the ontograph contains a specific descriptive context. the main feature of the ontos editor is the ability to assign each node a context of all types supported by the browser. including html pages, web 2.0 resources, etc. also, the proposed system implements the visualization of knowledge bases, consisting of two components: a navigator that determines the path to some node of the ontograph that has children and a visualization slider for this node that displays these elements. the knowledge base viewer is a slider that resembles a photo gallery slider with advanced navigation. the ontological approach to servicing knowledge bases can be not only a means of organizing knowledge. the knowledge bases developed on the basis of the ontological approach make it possible to work actively with knowledge, to solve problems associated with education, the development of artificial intelligence, decision-making systems, and many other areas where approximate sets can be used.",
            "contribution_ids": [
                "R210181"
            ]
        },
        {
            "instance_id": "EMPTYxR210192",
            "comparison_id": "EMPTY",
            "paper_id": "R210192",
            "text": "PYTHON FOR WEB DEVELOPMENT with evolution of web, several competitive languages such as java, php, python, ruby are catching the attention of the developers. recently python has emerged as a popular and the preferred web programming language, because of its simplicity to code and ease of learning. being a flexible language, it offers fast development of web-based applications. it offers development using cgi and wsgi. web development in python is aided by the powerful frameworks such as django, web2py, pyramid, and flask that python supports. thus, python promises to emerge as one of the preferred choice language for web applications. web is a rapidly growing repository of resources. internet is used as a medium for accessing these resources. web architecture mainly comprises of two entities, namely client and server. web client is an application (browser) on host machine that urges these resources, and web server is a machine on web that is responsible for fulfilling the request issued by client. hypertext transfer protocol (http) is the most popular protocol used by client and server for web communication. in a static web, browser issues http request to the http server, which searches for the requisite resource in its database and returns it as an http response. to avoid any compatibility issues, every request issued by browser is in form of a url (uniform resource locator). the url protocol defines the rules for communication between client and server. it comprise of host name (ip address) which helps in identifying the server system on the web, port number which determines the service (for example, ftp, email service) on the server that should respond to request, and the access path of the resource (web page) on server. the web where responses are already stored in server database in form of static web pages is termed static web. however, response returned by server to the client may be generated on the fly depending upon the request of the client. web applications offer several benefits over traditional applications that are required to be installed at each host computer that wishes to use them. web applications do not incur publishing and distribution costs as opposed to traditional applications where the software (applications) were published using cd\u2019s and distributed. they need not be installed at each client host; rather they are placed at a central server and accessed by large number of clients. since a web application is managed centrally, application updates and data backups can be performed easily. the web applications are easily accessible irrespective of the boundaries of space and time. since, they are accessed through browser, the platform accessing them is not an issue, and thus they provide cross-platform compatibility. inspite of above- mentioned advantages, web applications have a few limitations. internet connectivity and server availability is required for accessing web application through browser. however, accessing them through internet my take more time as compared to applications installed on host systems. also, web applications require compatible web browsers. since they are deployed on web, they are vulnerable to several internet attacks. web programming using cgi and wsgi requires building web applications from the scratch by using python standard libraries. python provides with web frameworks in the form of packages/ modules that simplify the task of writing application programs. these frameworks lighten tedious job of developers. they support server and client side programming by providing support for several activities such as request interpretation (getting form parameters, handling cookies and sessions), response generation (generating data in html or other format such as pdf, excel), and storing data. the web frameworks are further categorized as full- stack and non-full-stack frameworks. full-stack frameworks provide components for every phase of programming in contrast to non-full-stack frameworks. all the frameworks include templates and data persistence as key ingredients for constructing web. templates are used to avoid complex code that results when html and python code is mixed in a single file. templates are html files with placeholder for the data depending upon user input. data persistence deals with storing and retrieving data and maintaining consistency. the data can be stored and maintained using plain text files, relational database engines such as mysql, oracle, or some object-oriented databases. the web framework providing support for wsgi should be preferred. this makes deploying an application easier.",
            "contribution_ids": [
                "R210194"
            ]
        },
        {
            "instance_id": "EMPTYxR210216",
            "comparison_id": "EMPTY",
            "paper_id": "R210216",
            "text": "Web Crawler: Design And Implementation For Extracting Article-Like Contents the world wide web is a large, wealthy, and accessible information system whose users are increasing rapidly nowadays. to retrieve information from the web as per users\u2019 requests, search engines are built to access web pages. as search engine systems play a significant role in cybernetics, telecommunication, and physics, many efforts were made to enhance their capacity.however, most of the data contained on the web are unmanaged, making it impossible to access the entire network at once by current search engine system mechanisms. web crawler, therefore, is a critical part of search engines to navigate and download full texts of the web pages. web crawlers may also be applied to detect missing links and for community detection in complex networks and cybernetic systems. however, template-based crawling techniques could not handle the layout diversity of objects from web pages. in this paper, a web crawler module was designed and implemented, attempted to extract article-like contents from 495 websites. it uses a machine learning approach with visual cues, trivial html, and text-based features to filter out clutters. the outcomes are promising for extracting article-like contents from websites, contributing to the search engine systems development and future research gears towards proposing higher performance systems.",
            "contribution_ids": [
                "R210218"
            ]
        },
        {
            "instance_id": "EMPTYxR210222",
            "comparison_id": "EMPTY",
            "paper_id": "R210222",
            "text": "PLeveraging Django and Redis using Web Scraping web scraping is also known as data scraping and it is used for extracting data from sites. the software used for this may directly access the world wide web by using the hypertext transfer protocol or by using a web browser. over the years, due to advancements in web development and its technology, various frameworks have come in use and almost all of websites are dynamic with their content being served from cms. this makes it tough to extract data since there is no common template for extracting data. hence, we use rss. rich site summary is a kind of timeline allowing users and also applications to gain access to the updates on websites in a standardized, computer-readable format. this project combines the use of rss to extract data from websites and serve users in a robust and easy way. the differentiation is that this project uses server side caching to serve users almost instantaneously without the need to perform data extraction from the requested site all over again. this is done using redis and django.",
            "contribution_ids": [
                "R210224"
            ]
        },
        {
            "instance_id": "EMPTYxR210235",
            "comparison_id": "EMPTY",
            "paper_id": "R210235",
            "text": "Evolution of the Web: from Web 1.0 to 4.0 the internet has become a vital component of the twenty-first century as technology has advanced. the number of new technologies emerging in tandem with the qualities supplied by the internet is rapidly increasing. the world wide web (www), which is commonly referred to as the world's largest information environment, is a vital virtual environment in which internet users may trade, read, and publish information using a web browser. web 1.0, web 2.0, and web 3.0 technologies have all been seen and are still being observed in this review paper. however, there is no clear definition for web 4.0, which is a 4th generation web technology, in the literature. web 4.0 has multiple dimensions, as seen by the first examples that have appeared. big data, augmented reality, machine-to-machine communication (m2m), cloud computing, and artificial intelligence (ai) technologies, as well as smart agents, will be able to integrate in the future years. web 4.0 is a web technology revolution that includes a new internet of things (iot) that interacts with a variety of models. the goal of this study is to clarify the notion of web 4.0, which is viewed as an intelligent and symbiotic (human-machine interaction) network with massive interfaces and linkages, as well as to contribute to the literature by studying its many dimensions and investigating its links with new generation technologies.",
            "contribution_ids": [
                "R210237"
            ]
        },
        {
            "instance_id": "EMPTYxR210261",
            "comparison_id": "EMPTY",
            "paper_id": "R210261",
            "text": "STML (Sketch to Markup Language) \u201cweb development encompasses many stages, which involve designing the website done by making a wireframe first, after which the code for the frontend and backend is appropriately written over many iterations until the developers arrive at a fully functional and satisfying website for their need. we see how every website starts with the basic idea and structure of the website that can be described using a wireframe. it shows the basic elements and gives developers an idea about the structure of the website. it is given to the developers to create the boilerplate code that places all the elements into place accordingly. the task of converting the wireframe to html code is tedious and time-consuming. at present, the boilerplate code is mostly written manually. currently, the users have to write the html code for structuring the elements on the webpage, which leads to a lot of redundant work and users investing their precious time into it. generally, where the structure of web pages is the same, users would tend to maintain a copy of the pre-existing boilerplate code for reusability. in most cases, the boilerplate code differs for web pages despite the code for the html elements being the same. in such situations, the work becomes redundant. however, this process can be automated to ease the world of the web developer community. to make this process effortless, we propose a machine learning model. it will be trained to identify specific symbols and shapes as elements, recognize texts from the wireframe. the model will take in wireframe images as input through the web application. the idea is to process input, recognize each element in the wireframe using the open source computer vision library (opencv). identified elements will each have a corresponding code in the backend. once the elements on the wireframe are identified, the corresponding code is written into an html file. the user gets the html file as an output. the creation of the boilerplate code for a website becomes much less time-consuming, which gives developers the freedom to test out many different designs and layouts before opting for the one that best suits their needs.\u201d",
            "contribution_ids": [
                "R210263"
            ]
        },
        {
            "instance_id": "EMPTYxR210279",
            "comparison_id": "EMPTY",
            "paper_id": "R210279",
            "text": "When Push Comes to Ads: Measuring the Rise of (Malicious) Push Advertising the rapid growth of online advertising has fueled the growth of ad-blocking software, such as new ad-blocking and privacy-oriented browsers or browser extensions. in response, both ad publishers and ad networks are constantly trying to pursue new strategies to keep up their revenues. to this end, ad networks have started to leverage the web push technology enabled by modern web browsers. as web push notifications (wpns) are relatively new, their role in ad delivery has not yet been studied in depth. furthermore, it is unclear to what extent wpn ads are being abused for malvertising (i.e., to deliver malicious ads). in this paper, we aim to fill this gap. specifically, we propose a system called pushadminer that is dedicated to (1) automatically registering for and collecting a large number of web-based push notifications from publisher websites, (2) finding wpn-based ads among these notifications, and (3) discovering malicious wpn-based ad campaigns. using pushadminer, we collected and analyzed 21,541 wpn messages by visiting thousands of different websites. among these, our system identified 572 wpn ad campaigns, for a total of 5,143 wpn-based ads that were pushed by a variety of ad networks. furthermore, we found that 51% of all wpn ads we collected are malicious, and that traditional ad-blockers and url filters were mostly unable to block them, thus leaving a significant abuse vector unchecked.",
            "contribution_ids": [
                "R210281"
            ]
        },
        {
            "instance_id": "EMPTYxR214233",
            "comparison_id": "EMPTY",
            "paper_id": "R214233",
            "text": "Reinforced Spatiotemporal Attentive Graph Neural Networks for Traffic Forecasting the advances in the internet of things (iot) and increased availability of the road sensors allow for fine-grained traffic forecasting, which is of particular importance toward building an intelligent transportation system. in the literature, recent efforts have applied various deep learning methods for traffic forecasting, e.g., leveraging graph convolutional networks (gcns) for spatial dependency modeling, and utilizing recurrent neural networks (rnns) for capturing temporal dynamics. however, most of the existing approaches assume that spatial correlations are static and temporal correlations have only sequential dependencies and do not consider temporal periodicity of traffic across multiple time steps. the real challenge lies in using the dynamic spatiotemporal correlations while also considering the influence of the nontraffic-related factors, such as time-of-day and weekday-or-weekend in the learning architectures. we propose a novel framework titled \u201creinforced spatial\u2013temporal attention graph (rstag) neural networks\u201d for traffic prediction. our method captures dynamic spatial correlations through diffusion network graphs, while temporal dependencies are represented through the sequence-to-sequence model with an attention mechanism. in addition, we utilize the policy gradient to update the model parameters while largely alleviating the exposure bias issue that exists in previous traffic prediction models. we conduct extensive experiments on two large-scale traffic data sets collected from the road sensor networks in los angles and bay area of california. the results demonstrate that our method significantly outperforms the state-of-the-art baselines.",
            "contribution_ids": [
                "R214239",
                "R214241"
            ]
        },
        {
            "instance_id": "EMPTYxR35052",
            "comparison_id": "EMPTY",
            "paper_id": "R35052",
            "text": "Investigating Correlations of Automatically Extracted Multimodal Features and Lecture Video Quality \"ranking and recommendation of multimedia content such as videos is usually realized with respect to the relevance to a user query. however, for lecture videos and moocs (massive open online courses) it is not only required to retrieve relevant videos, but particularly to find lecture videos of high quality that facilitate learning, for instance, independent of the video's or speaker's popularity. thus, metadata about a lecture video's quality are crucial features for learning contexts, e.g., lecture video recommendation in search as learning scenarios. in this paper, we investigate whether automatically extracted features are correlated to quality aspects of a video. a set of scholarly videos from a mass open online course (mooc) is analyzed regarding audio, linguistic, and visual features. furthermore, a set of cross-modal features is proposed which are derived by combining transcripts, audio, video, and slide content. a user study is conducted to investigate the correlations between the automatically collected features and human ratings of quality aspects of a lecture video. finally, the impact of our features on the knowledge gain of the participants is discussed.\"",
            "contribution_ids": [
                "R35054"
            ]
        },
        {
            "instance_id": "EMPTYxR38461",
            "comparison_id": "EMPTY",
            "paper_id": "R38461",
            "text": "Rich Representations of Visual Content for Screen Reader Users alt text (short for \"alternative text\") is descriptive text associated with an image in html and other document formats. screen reader technologies speak the alt text aloud to people who are visually impaired. introduced with html 2.0 in 1995, the alt attribute has not evolved despite significant changes in technology over the past two decades. in light of the expanding volume, purpose, and importance of digital imagery, we reflect on how alt text could be supplemented to offer a richer experience of visual content to screen reader users. our contributions include articulating the design space of representations of visual content for screen reader users, prototypes illustrating several points within this design space, and evaluations of several of these new image representations with people who are blind. we close by discussing the implications of our taxonomy, prototypes, and user study findings.",
            "contribution_ids": [
                "R38463"
            ]
        },
        {
            "instance_id": "EMPTYxR8348",
            "comparison_id": "EMPTY",
            "paper_id": "R8348",
            "text": "Research Articles in Simplified HTML: a Web-first format for HTML-based scholarly articles purpose this paper introduces the research articles in simplified html (or rash), which is a web-first format for writing html-based scholarly papers; it is accompanied by the rash framework, a set of tools for interacting with rash-based articles. the paper also presents an evaluation that involved authors and reviewers of rash articles submitted to the save-sd 2015 and save-sd 2016 workshops. design rash has been developed aiming to: be easy to learn and use; share scholarly documents (and embedded semantic annotations) through the web; support its adoption within the existing publishing workflow. findings the evaluation study confirmed that rash is ready to be adopted in workshops, conferences, and journals and can be quickly learnt by researchers who are familiar with html. research limitations the evaluation study also highlighted some issues in the adoption of rash, and in general of html formats, especially by less technically savvy users. moreover, additional tools are needed, e.g., for enabling additional conversions from/to existing formats such as openxml. practical implications rash (and its framework) is another step towards enabling the definition of formal representations of the meaning of the content of an article, facilitating its automatic discovery, enabling its linking to semantically related articles, providing access to data within the article in actionable form, and allowing integration of data between papers. social implications rash addresses the intrinsic needs related to the various users of a scholarly article: researchers (focussing on its content), readers (experiencing new ways for browsing it), citizen scientists (reusing available data formally defined within it through semantic annotations), publishers (using the advantages of new technologies as envisioned by the semantic publishing movement). value rash helps authors to focus on the organisation of their texts, supports them in the task of semantically enriching the content of articles, and leaves all the issues about validation, visualisation, conversion, and semantic data extraction to the various tools developed within its framework.",
            "contribution_ids": [
                "R8349"
            ]
        },
        {
            "instance_id": "EMPTYxR8356",
            "comparison_id": "EMPTY",
            "paper_id": "R8356",
            "text": "The anatomy of a nanopublication as the amount of scholarly communication increases, it is increasingly difficult for specific core scientific statements to be found, connected and curated. additionally, the redundancy of these statements in multiple fora makes it difficult to determine attribution, quality and provenance. to tackle these challenges, the concept web alliance has promoted the notion of nanopublications (core scientific statements with associated context). in this document, we present a model of nanopublications along with a named graph/rdf serialization of the model. importantly, the serialization is defined completely using already existing community-developed technologies. finally, we discuss the importance of aggregating nanopublications and the role that the concept wiki plays in facilitating it.",
            "contribution_ids": [
                "R8357"
            ]
        },
        {
            "instance_id": "EMPTYxR46146",
            "comparison_id": "EMPTY",
            "paper_id": "R46146",
            "text": "A hybrid of CdS/HCa2Nb3O10 ultrathin nanosheets for promoting photocatalytic hydrogen eVolution a hybrid of cds/hca 2 nb 3 o 10 ultrathin nanosheets with a tough heterointerface was successfully fabricated. efficient interfacial charge transfer from cds to hca 2 nb 3 o 10 nanosheets was achieved to realize the enhanced photocatalytic h 2 evolution activity.",
            "contribution_ids": [
                "R46147"
            ]
        },
        {
            "instance_id": "EMPTYxR75084",
            "comparison_id": "EMPTY",
            "paper_id": "R75084",
            "text": "A Survey on Knowledge Graph Embedding: Approaches, Applications and Benchmarks a knowledge graph (kg), also known as a knowledge base, is a particular kind of network structure in which the node indicates entity and the edge represent relation. however, with the explosion of network volume, the problem of data sparsity that causes large-scale kg systems to calculate and manage difficultly has become more significant. for alleviating the issue, knowledge graph embedding is proposed to embed entities and relations in a kg to a low-, dense and continuous feature space, and endow the yield model with abilities of knowledge inference and fusion. in recent years, many researchers have poured much attention in this approach, and we will systematically introduce the existing state-of-the-art approaches and a variety of applications that benefit from these methods in this paper. in addition, we discuss future prospects for the development of techniques and application trends. specifically, we first introduce the embedding models that only leverage the information of observed triplets in the kg. we illustrate the overall framework and specific idea and compare the advantages and disadvantages of such approaches. next, we introduce the advanced models that utilize additional semantic information to improve the performance of the original methods. we divide the additional information into two categories, including textual descriptions and relation paths. the extension approaches in each category are described, following the same classification criteria as those defined for the triplet fact-based models. we then describe two experiments for comparing the performance of listed methods and mention some broader domain tasks such as question answering, recommender systems, and so forth. finally, we collect several hurdles that need to be overcome and provide a few future research directions for knowledge graph embedding.",
            "contribution_ids": [
                "R75086"
            ]
        },
        {
            "instance_id": "EMPTYxR69721",
            "comparison_id": "EMPTY",
            "paper_id": "R69721",
            "text": "Measuring completeness as metadata quality metric in Europeana europeana, the european digital platform for cultural heritage, has a heterogeneous collection of metadata records ingested from more than 3200 data providers. the original nature and context of these records were different. in order to create effective services upon them we should know the strength and weakness or in other words the quality of these data. this paper proposes a method and an open source implementation to measure some structural features of these data, such as completeness, multilinguality, uniqueness, record patterns, to reveal quality issues.",
            "contribution_ids": [
                "R69723"
            ]
        },
        {
            "instance_id": "EMPTYxR146842",
            "comparison_id": "EMPTY",
            "paper_id": "R146842",
            "text": "Push\u00e2\u0080\u0093Pull Type Non-Fullerene Acceptors for Polymer Solar Cells: Effect of the Donor Core there has been a growing interest in the design and synthesis of non-fullerene acceptors for organic solar cells that may overcome the drawbacks of the traditional fullerene-based acceptors. herein, two novel push-pull (acceptor-donor-acceptor) type small-molecule acceptors, that is, itdi and cdtdi, with indenothiophene and cyclopentadithiophene as the core units and 2-(3-oxo-2,3-dihydroinden-1-ylidene)malononitrile (incn) as the end-capping units, are designed and synthesized for non-fullerene polymer solar cells (pscs). after device optimization, pscs based on itdi exhibit good device performance with a power conversion efficiency (pce) as high as 8.00%, outperforming the cdtdi-based counterparts fabricated under identical condition (2.75% pce). we further discuss the performance of these non-fullerene pscs by correlating the energy level and carrier mobility with the core of non-fullerene acceptors. these results demonstrate that indenothiophene is a promising electron-donating core for high-performance non-fullerene small-molecule acceptors.",
            "contribution_ids": [
                "R146845"
            ]
        },
        {
            "instance_id": "EMPTYxR4693",
            "comparison_id": "EMPTY",
            "paper_id": "R4693",
            "text": "A Graph Based Tool for Modelling Planning Processes in Building Engineering the planning process of a building is very complex. many participants with different technical disciplines are involved and work on certain tasks. to manage the planning process the project leader has to organize participants, tasks and building data. for this purpose modern information and communication technologies can be used very effi ciently. but these technologies require a formal description of the planning process. within the research project \u201crelation based process modelling of co-operative building planning\u201d we have defined a consistent mathematical process model for planning processes and have developed a prototype implementation of an application for modelling these processes. our project is embedded in the priori ty program 1103 \u201cnetwork-based co-operative planning processes in structural engineering\u201d promoted by the german research foundation (dfg). in this paper we present the mathematical concept of our relational process model and the tool for building up the m odel and checking the structural consistency and correctness.",
            "contribution_ids": [
                "R4699"
            ]
        },
        {
            "instance_id": "EMPTYxR144081",
            "comparison_id": "EMPTY",
            "paper_id": "R144081",
            "text": "A soluble cryogenic thermometer with high sensitivity based on excited-state configuration transformations cryogenic temperature detection plays an irreplaceable role in exploring nature. developing high sensitivity, accurate, observable and convenient measurements of cryogenic temperature is not only a challenge but also an opportunity for the thermometer field. the small molecule 9-(9,9-dimethyl-9h-fluoren-3yl)-14-phenyl-9,14-dihydrodibenzo[a,c]phenazine (fipac) in 2-methyl-tetrahydrofuran (methf) solution is utilized for the detection of cryogenic temperature with a wide range from 138 k to 343 k. this system possesses significantly high sensitivity at low temperature, which reaches as high as 19.4% k(-1) at 138 k. the temperature-dependent ratio of the dual emission intensity can be fitted as a single-exponential curve as a function of temperature. this single-exponential curve can be explained by the mechanism that the dual emission feature of fipac results from the excited-state configuration transformations upon heating or cooling, which is very different from the previously reported mechanisms. here, our work gives an overall interpretation for this mechanism. therefore, application of fipac as a cryogenic thermometer is experimentally and theoretically feasible.",
            "contribution_ids": [
                "R144083"
            ]
        },
        {
            "instance_id": "EMPTYxR170704",
            "comparison_id": "EMPTY",
            "paper_id": "R170704",
            "text": "Singing-Related Activity in Anterior Forebrain of Male Zebra Finches Reflects Courtship Motivation for Target Females \"a critical function of singing by male songbirds is to attract a female mate. previous studies have suggested that the anterior forebrain system is involved in this courtship behavior. neural activity in this system, including the striatal area x, is strikingly dependent on the function of male singing. when males sing to attract a female bird rather than while alone, less variable neural activity results in less variable song spectral features, which may be attractive to the female. these characteristics of neural activity and singing thus may reflect a male's motivation for courtship. here, we compared the variability of neural activity and song features between courtship singing directed to a female with whom a male had previously formed a pair-bond or to other females. surprisingly, across all units, there was no clear tendency for a difference in variability of neural activity or song features between courtship of paired females, nonpaired females, or dummy females. however, across the population of recordings, there was a significant relationship between the relative variability of syllable frequency and neural activity: when syllable frequency was less variable to paired than nonpaired females, neural activity was also less variable (and vice-versa). these results show that the lower variability of neural activity and syllable frequency during directed singing is not a binary distinction from undirected singing, but can vary in intensity, possibly related to the relative preference of a male for his singing target.\"",
            "contribution_ids": [
                "R170705"
            ]
        },
        {
            "instance_id": "EMPTYxR4432",
            "comparison_id": "EMPTY",
            "paper_id": "R4432",
            "text": "Evaluating the Demand for Soft Skills in Software Development \"an analysis of 500 advertisements for it positions focuses on the soft skills mentioned in the ads, revealing which soft skills are in high demand for software development and which ones are neglected despite their importance. our survey indicates that soft skills are in demand in the software industry, but only to a limited extent. this highlights the lack of understanding of the role that soft skills play in an employee's professional ability and performance.\"",
            "contribution_ids": [
                "R4438"
            ]
        },
        {
            "instance_id": "EMPTYxR4208",
            "comparison_id": "EMPTY",
            "paper_id": "R4208",
            "text": "You will be\u00e2\u0080\u00a6: a study of job advertisements to determine employers' requirements for LIS professionals in the UK in 2007 purpose the purpose of this paper is to investigate what employers seek when recruiting library and information professionals in the uk and whether professional skills, generic skills or personal qualities are most in demand. design/methodology/approach a content analysis of a sample of 180 advertisements requiring a professional library or information qualification from chartered institute of library and information professional\\'s library\\u2009+\\u2009information gazette over the period may 2006\u20102007. findings the findings reveal that a multitude of skills and qualities are required in the profession. when the results were compared with information national training organisation and library and information management employability skills research, customer service, interpersonal and communication skills, and general computing skills emerged as the requirements most frequently sought by employers. overall, requirements from the generic skills area were most important to employers, but the research also demonstrates that professional skills are still valued. an unanticipated demand for profession related experience was found: this was the single most frequently sought requirement in the advertisements analysed. research limitations/implications although the gazette is the largest source of library and information jobs, it does not provide a complete picture of the employment market. originality/value the paper contributes to debates about the skillsbase of the profession, and raises awareness of the abilities professionals need to cultivate in order to progress through their careers.",
            "contribution_ids": [
                "R4212"
            ]
        },
        {
            "instance_id": "EMPTYxR138439",
            "comparison_id": "EMPTY",
            "paper_id": "R138439",
            "text": "Lignin Conversion to Low-Molecular-Weight Aromatics via an Aerobic Oxidation-Hydrolysis Sequence: Comparison of Different Lignin Sources diverse lignin samples have been subjected to a catalytic aerobic oxidation process, followed by formic-acid-induced hydrolytic depolymerization. the yield of monomeric aromatic compounds varies depending on the lignin plant source and pretreatment method. the best results are obtained from poplar lignin isolated via a acidolysis pretreatment method, which gives 42 wt% yield of low-molecular-weight aromatics. use of other pretreatment methods and/or use of maple and maize lignins afford yields of aromatics ranging from 3 to 31 wt%. these results establish useful references for the development of improved oxidation/depolymerization protocols.",
            "contribution_ids": [
                "R138448"
            ]
        },
        {
            "instance_id": "EMPTYxR38841",
            "comparison_id": "EMPTY",
            "paper_id": "R38841",
            "text": "A Survey of Scholarly Data Visualization scholarly information usually contains millions of raw data, such as authors, papers, citations, as well as scholarly networks. with the rapid growth of the digital publishing and harvesting, how to visually present the data efficiently becomes challenging. nowadays, various visualization techniques can be easily applied on scholarly data visualization and visual analysis, which enables scientists to have a better way to represent the structure of scholarly data sets and reveal hidden patterns in the data. in this paper, we first introduce the basic concepts and the collection of scholarly data. then, we provide a comprehensive overview of related data visualization tools, existing techniques, as well as systems for the analyzing volumes of diverse scholarly data. finally, open issues are discussed to pursue new solutions for abundant and complicated scholarly data visualization, as well as techniques, that support a multitude of facets.",
            "contribution_ids": [
                "R69808"
            ]
        },
        {
            "instance_id": "EMPTYxR213086",
            "comparison_id": "EMPTY",
            "paper_id": "R213086",
            "text": "NorNE: Annotating Named Entities for Norwegian this paper presents norne, a manually annotated corpus of named entities which extends the annotation of the existing norwegian dependency treebank. comprising both of the official standards of written norwegian (bokm\u00e5l and nynorsk), the corpus contains around 600,000 tokens and annotates a rich set of entity types including persons, organizations, locations, geo-political entities, products, and events, in addition to a class corresponding to nominals derived from names. we here present details on the annotation effort, guidelines, inter-annotator agreement and an experimental analysis of the corpus using a neural sequence labeling architecture.",
            "contribution_ids": [
                "R213088",
                "R213091"
            ]
        },
        {
            "instance_id": "EMPTYxR169119",
            "comparison_id": "EMPTY",
            "paper_id": "R169119",
            "text": "Copy Number Variation in Subjects with Major Depressive Disorder Who Attempted Suicide background suicide is one of the top ten leading causes of death in north america and represents a major public health burden, partcularly for people with major depressive disorder (md). many studies have suggested that suicidal behavior runs in families, however, identification of genomic loci that drive this efffect remain to be identified. methodology/principal findings using subjects collected as part of star*d, we genotyped 189 subjects with md with history of a suicide attempt and 1073 subjects with major depressive disorder that had never attempted suicide. copy number variants (cnvs) were called in birdsuite and analyzed in plink. we found a set of cnvs present in the suicide attempter group that were not present in in the non-attempter group including in sntg2 and macrod2 \u2013 two brain expressed genes previously linked to psychopathology; however, these results failed to reach genome-wide signifigance. conclusions these data suggest potential cnvs to be investigated further in relation to suicide attempts in md using large sample sizes.",
            "contribution_ids": [
                "R169120",
                "R169121",
                "R169122"
            ]
        },
        {
            "instance_id": "EMPTYxR169904",
            "comparison_id": "EMPTY",
            "paper_id": "R169904",
            "text": "Stress Marker Signatures in Lesion Mimic Single and Double Mutants Identify a Crucial Leaf Age-Dependent Salicylic Acid Related Defense Signal plants are exposed to abiotic and biotic stress conditions throughout their lifespans that activates various defense programs. programmed cell death (pcd) is an extreme defense strategy the plant uses to manage unfavorable environments as well as during developmentally induced senescence. here we investigated the role of leaf age on the regulation of defense gene expression in arabidopsis thaliana. two lesion mimic mutants with misregulated cell death, catalase2 (cat2) and defense no death1 (dnd1) were used together with several double mutants to dissect signaling pathways regulating defense gene expression associated with cell death and leaf age. pcd marker genes showed leaf age dependent expression, with the highest expression in old leaves. the salicylic acid (sa) biosynthesis mutant salicylic acid induction deficient2 (sid2) had reduced expression of pcd marker genes in the cat2 sid2 double mutant demonstrating the importance of sa biosynthesis in regulation of defense gene expression. while the auxin- and jasmonic acid (ja)- insensitive auxin resistant1 (axr1) double mutant cat2 axr1 also led to decreased expression of pcd markers; the expression of several marker genes for sa signaling (isochorismate synthase 1, pr1 and pr2) were additionally decreased in cat2 axr1 compared to cat2. the reduced expression of these sa markers genes in cat2 axr1 implicates axr1 as a regulator of sa signaling in addition to its known role in auxin and ja signaling. overall, the current study reinforces the important role of sa signaling in regulation of leaf age-related transcript signatures.",
            "contribution_ids": [
                "R169905",
                "R169906",
                "R169907"
            ]
        },
        {
            "instance_id": "EMPTYxR137470",
            "comparison_id": "EMPTY",
            "paper_id": "R137470",
            "text": "Fabrication and characterization of Ga-doped ZnO / Si heterojunction nanodiodes in this study, temperature-dependent electrical properties of n-type ga-doped zno thin film / p-type si nanowire heterojunction diodes were reported. metal-assisted chemical etching (mace) process was performed to fabricate si nanowires. ga-doped zno films were then deposited onto nanowires through chemical bath deposition (cbd) technique to build three-dimensional nanowire-based heterojunction diodes. fabricated devices revealed significant diode characteristics in the temperature range of 220 - 360\\u2005k. electrical measurements shown that diodes had a well-defined rectifying behavior with a good rectification ratio of 103 \u00b13\\u2005v at room temperature. ideality factor (n) were changed from 2.2 to 1.2 with increasing temperature.in this study, temperature-dependent electrical properties of n-type ga-doped zno thin film / p-type si nanowire heterojunction diodes were reported. metal-assisted chemical etching (mace) process was performed to fabricate si nanowires. ga-doped zno films were then deposited onto nanowires through chemical bath deposition (cbd) technique to build three-dimensional nanowire-based heterojunction diodes. fabricated devices revealed significant diode characteristics in the temperature range of 220 - 360\\u2005k. electrical measurements shown that diodes had a well-defined rectifying behavior with a good rectification ratio of 103 \u00b13\\u2005v at room temperature. ideality factor (n) were changed from 2.2 to 1.2 with increasing temperature.",
            "contribution_ids": [
                "R137471"
            ]
        },
        {
            "instance_id": "EMPTYxR169660",
            "comparison_id": "EMPTY",
            "paper_id": "R169660",
            "text": "Learning to Produce Syllabic Speech Sounds via Reward-Modulated Neural Plasticity at around 7 months of age, human infants begin to reliably produce well-formed syllables containing both consonants and vowels, a behavior called canonical babbling. over subsequent months, the frequency of canonical babbling continues to increase. how the infant\u2019s nervous system supports the acquisition of this ability is unknown. here we present a computational model that combines a spiking neural network, reinforcement-modulated spike-timing-dependent plasticity, and a human-like vocal tract to simulate the acquisition of canonical babbling. like human infants, the model\u2019s frequency of canonical babbling gradually increases. the model is rewarded when it produces a sound that is more auditorily salient than sounds it has previously produced. this is consistent with data from human infants indicating that contingent adult responses shape infant behavior and with data from deaf and tracheostomized infants indicating that hearing, including hearing one\u2019s own vocalizations, is critical for canonical babbling development. reward receipt increases the level of dopamine in the neural network. the neural network contains a reservoir with recurrent connections and two motor neuron groups, one agonist and one antagonist, which control the masseter and orbicularis oris muscles, promoting or inhibiting mouth closure. the model learns to increase the number of salient, syllabic sounds it produces by adjusting the base level of muscle activation and increasing their range of activity. our results support the possibility that through dopamine-modulated spike-timing-dependent plasticity, the motor cortex learns to harness its natural oscillations in activity in order to produce syllabic sounds. it thus suggests that learning to produce rhythmic mouth movements for speech production may be supported by general cortical learning mechanisms. the model makes several testable predictions and has implications for our understanding not only of how syllabic vocalizations develop in infancy but also for our understanding of how they may have evolved.",
            "contribution_ids": [
                "R169661",
                "R169662",
                "R169663",
                "R169664",
                "R169665"
            ]
        },
        {
            "instance_id": "EMPTYxR135842",
            "comparison_id": "EMPTY",
            "paper_id": "R135842",
            "text": "Considerations for the Conduction and Interpretation of FAIRness Evaluations the fair principles were received with broad acceptance in several scientific communities. however, there is still some degree of uncertainty on how they should be implemented. several self-report questionnaires have been proposed to assess the implementation of the fair principles. moreover, the fairmetrics group released 14, general-purpose maturity for representing fairness. initially, these metrics were conducted as open-answer questionnaires. recently, these metrics have been implemented into a software that can automatically harvest metadata from metadata providers and generate a principle-specific fairness evaluation. with so many different approaches for fairness evaluations, we believe that further clarification on their limitations and advantages, as well as on their interpretation and interplay should be considered.",
            "contribution_ids": [
                "R135851"
            ]
        },
        {
            "instance_id": "EMPTYxR170318",
            "comparison_id": "EMPTY",
            "paper_id": "R170318",
            "text": "Recognition Profile of Emotions in Natural and Virtual Faces background computer-generated virtual faces become increasingly realistic including the simulation of emotional expressions. these faces can be used as well-controlled, realistic and dynamic stimuli in emotion research. however, the validity of virtual facial expressions in comparison to natural emotion displays still needs to be shown for the different emotions and different age groups. methodology/principal findings thirty-two healthy volunteers between the age of 20 and 60 rated pictures of natural human faces and faces of virtual characters (avatars) with respect to the expressed emotions: happiness, sadness, anger, fear, disgust, and neutral. results indicate that virtual emotions were recognized comparable to natural ones. recognition differences in virtual and natural faces depended on specific emotions: whereas disgust was difficult to convey with the current avatar technology, virtual sadness and fear achieved better recognition results than natural faces. furthermore, emotion recognition rates decreased for virtual but not natural faces in participants over the age of 40. this specific age effect suggests that media exposure has an influence on emotion recognition. conclusions/significance virtual and natural facial displays of emotion may be equally effective. improved technology (e.g. better modelling of the naso-labial area) may lead to even better results as compared to trained actors. due to the ease with which virtual human faces can be animated and manipulated, validated artificial emotional expressions will be of major relevance in future research and therapeutic applications.",
            "contribution_ids": [
                "R170319"
            ]
        },
        {
            "instance_id": "EMPTYxR171019",
            "comparison_id": "EMPTY",
            "paper_id": "R171019",
            "text": "The Prevalence and Characteristics of Fibromyalgia in the 2012 National Health Interview Survey background most knowledge of fibromyalgia comes from the clinical setting, where healthcare-seeking behavior and selection issues influence study results. the characteristics of fibromyalgia in the general population have not been studied in detail. methods we developed and tested surrogate study specific criteria for fibromyalgia in rheumatology practices using variables from the us national health interview survey (nhis) and the modification (for surveys) of the 2010 american college of rheumatology (acr) preliminary fibromyalgia criteria. the surrogate criteria were applied to the 2012 nhis and identified persons who satisfied criteria from symptom data. the nhis weighted sample of 8446 persons represents 225.7 million us adults. results fibromyalgia was identified in 1.75% (95% ci 1.42, 2.07), or 3.94 million persons. however, 73% of identified cases self-reported a physician\u2019s diagnosis other than fibromyalgia. identified cases had high levels of self-reported pain, non-pain symptoms, comorbidity, psychological distress, medical costs, social security and work disability. caseness was associated with gender, education, ethnicity, citizenship and unhealthy behaviors. demographics, behaviors, and comorbidity were predictive of case status. examination of the surrogate polysymptomatic distress scale (psd) of the 2010 acr criteria found fibromyalgia symptoms extending through the full length of the scale. conclusions persons identified with criteria-based fibromyalgia have severe symptoms, but most (73%) have not received a clinical diagnosis of fibromyalgia. the association of fibromyalgia-like symptoms over the full length of the psd scale with physiological as well as mental stressors suggests psd may be a universal response variable rather than one restricted to fibromyalgia.",
            "contribution_ids": [
                "R171020"
            ]
        },
        {
            "instance_id": "EMPTYxR169633",
            "comparison_id": "EMPTY",
            "paper_id": "R169633",
            "text": "Individual Effect Modifiers of Dust Exposure Effect on Cardiovascular Morbidity \"background high concentrations of particulate matter (pm) air pollution have been associated with death and hospital admissions due to cardiovascular morbidity. however, it is not clear a) whether high levels of non-anthropogenic pm from dust storms constitute a health risk; and b) whether these health risks are exacerbated in a particular demographic. methods this study comprised all patients above 18 years old admitted to soroka university medical center (1000 bed tertiary hospital, be\u2019er- sheva, israel, 2001\u20132010) with a primary diagnosis of acute coronary syndrome (acs). data on meteorological parameters and pm10 (particulate matter <10 \u03bcm in aerodiameter) were obtained from monitoring stations in the city of be'er-sheva. data were analyzed using a case crossover analysis to examine the effect of dust exposure on hospitalization due to acs and the interaction with co-morbidities and demographic factors. results there were 16,734 hospitalizations due to acs during the study period. the estimated odds of hospitalization due to acs was significantly associated with pm10 during non dust storm days at the same day of the exposure (lag0); or = 1.014 (95%ci 1.001\u20131.027) for a 10 \u03bcg/m3 increase, while a delayed response (lag1) was found during the dust storm days; or = 1.007 (95%ci 1.002\u20131.012). the effect size for the dust exposure association was larger for older (above the age of 65), female or bedouin patients. conclusions exposure to non-anthropogenic pm is associated with cardiovascular morbidity. health risk associated dust exposure is gender and age specific with older women and bedouin patients being the most vulnerable groups.\"",
            "contribution_ids": [
                "R169634"
            ]
        },
        {
            "instance_id": "EMPTYxR131136",
            "comparison_id": "EMPTY",
            "paper_id": "R131136",
            "text": "Look, Listen and Learn we consider the question: what can be learnt by looking at and listening to a large number of unlabelled videos? there is a valuable, but so far untapped, source of information contained in the video itself \u2013 the correspondence between the visual and the audio streams, and we introduce a novel \u201caudio-visual correspondence\u201d learning task that makes use of this. training visual and audio networks from scratch, without any additional supervision other than the raw unconstrained videos themselves, is shown to successfully solve this task, and, more interestingly, result in good visual and audio representations. these features set the new state-of-the-art on two sound classification benchmarks, and perform on par with the state-of-the-art selfsupervised approaches on imagenet classification. we also demonstrate that the network is able to localize objects in both modalities, as well as perform fine-grained recognition tasks.",
            "contribution_ids": [
                "R131137"
            ]
        },
        {
            "instance_id": "EMPTYxR170780",
            "comparison_id": "EMPTY",
            "paper_id": "R170780",
            "text": "A Meta-Analysis of Self-Reported Achievement Goals and Nonself-Report Performance across Three Achievement Domains (Work, Sports, and Education) during the past three decades, the achievement goal approach to achievement motivation has emerged as an influential area of research, and is dedicated to understanding the reasons behind the individual\u2019s drive to achieve competence and performance. however, the current literature on achievement goals is segmented rather than integrated. that is, citations across the three major and distinct achievement domains (work, education, and sports) are more the exception than the rule and similarities and differences between findings for the different achievement domains have yet to be tested. the purpose of the present study was to examine the relationships between self-reported achievement goals and nonself-report performance through meta-analysis, and the moderating potential of achievement domain. identifying achievement domain as moderator improves our understanding to which contexts we can (not) generalize conclusions to, it helps to understand seemingly inconsistent findings, and opens avenues for future research on the underlying processes. because the achievement goal (ag) measure used in a study is partially confounded with achievement domain, we examined the moderating role of this variable as well. our findings suggest that \u2013 overall \u2013 approach goals (either mastery or performance) were associated positively with performance attainment, whereas avoidance goals (either mastery or performance) were associated negatively with performance attainment. these relationships were moderated by achievement domain. for example, relative to the education or work domain, in the sports domain, we did not observe negative correlations between avoidance goals and performance. the absence of statistical moderation due to ag measure suggests that the observed moderation of achievement domain cannot be explained by the ag measure utilized. we suggest further steps to integrate the achievement goal literature, and accordingly, to broaden and deepen understanding of performance attainment in competence-relevant settings, including the workplace, the sports field, and the classroom.",
            "contribution_ids": [
                "R170781"
            ]
        },
        {
            "instance_id": "EMPTYxR171684",
            "comparison_id": "EMPTY",
            "paper_id": "R171684",
            "text": "The impact of self-esteem on the preferential processing of self-related information: Electrophysiological correlates of explicit self vs. other evaluation preferential processing of self-related information is a well-documented phenomenon on both the behavioral and neural levels. however, the impact of self-esteem on this self-preference has not been studied in a systematic way. here, the electrophysiological correlates of explicit self-reflection were investigated in individuals with low (lse) and high self-esteem (hse). participants evaluated trait adjectives in reference to the self or to an \u201cother\u201d person (close-other, famous) while eeg was recorded. the analysis of event-related potentials focused on the late positive component (lpc), which exhibits a fronto-central distribution and latency over 500 ms. in both lse and hse groups, the amplitudes of lpc were enhanced in the self condition when compared to control conditions (both close-other and famous). crucially, lpc amplitudes in the hse group were significantly higher than in the lse group. moreover, the self-preference effect, defined as the difference between amplitudes of lpc associated with the evaluation of words in relation to oneself vs. other people, was significantly higher in the hse group than in the lse group. overall, our findings indicate that people with high self-esteem tend to engage in self-referential processing to a higher extent.",
            "contribution_ids": [
                "R171685"
            ]
        },
        {
            "instance_id": "EMPTYxR169355",
            "comparison_id": "EMPTY",
            "paper_id": "R169355",
            "text": "Windowed Correlation: A Suitable Tool for Providing Dynamic fMRI-Based Functional Connectivity Neurofeedback on Task Difficulty the goal of neurofeedback training is to provide participants with relevant information on their ongoing brain processes in order to enable them to change these processes in a meaningful way. under the assumption of an intrinsic brain-behavior link, neurofeedback can be a tool to guide a participant towards a desired behavioral state, such as a healthier state in the case of patients. current research in clinical neuroscience regarding the most robust indicators of pathological brain processes in psychiatric and neurological disorders indicates that fmri-based functional connectivity measures may be among the most important biomarkers of disease. the present study therefore investigated the general potential of providing fmri neurofeedback based on functional correlations, computed from short-window time course data at the level of single task periods. the ability to detect subtle changes in task performance with block-wise functional connectivity measures was evaluated based on imaging data from healthy participants performing a simple motor task, which was systematically varied along two task dimensions representing two different aspects of task difficulty. the results demonstrate that fmri-based functional connectivity measures may provide a better indicator for an increase in overall (motor) task difficulty than activation level-based measures. windowed functional correlations thus seem to provide relevant and unique information regarding ongoing brain processes, which is not captured equally well by standard activation level-based neurofeedback measures. functional connectivity markers, therefore, may indeed provide a valuable tool to enhance and monitor learning within an fmri neurofeedback setup.",
            "contribution_ids": [
                "R169356",
                "R169357",
                "R169358",
                "R169359"
            ]
        },
        {
            "instance_id": "EMPTYxR134345",
            "comparison_id": "EMPTY",
            "paper_id": "R134345",
            "text": "Unifying Count-Based Exploration and Intrinsic Motivation \"we consider an agent's uncertainty about its environment and the problem of generalizing this uncertainty across observations. specifically, we focus on the problem of exploration in non-tabular reinforcement learning. drawing inspiration from the intrinsic motivation literature, we use density models to measure uncertainty, and propose a novel algorithm for deriving a pseudo-count from an arbitrary density model. this technique enables us to generalize count-based exploration algorithms to the non-tabular case. we apply our ideas to atari 2600 games, providing sensible pseudo-counts from raw pixels. we transform these pseudo-counts into intrinsic rewards and obtain significantly improved exploration in a number of hard games, including the infamously difficult montezuma's revenge.\"",
            "contribution_ids": [
                "R134346",
                "R134357"
            ]
        },
        {
            "instance_id": "EMPTYxR142214",
            "comparison_id": "EMPTY",
            "paper_id": "R142214",
            "text": "Nanoscale thermometry via the fluorescence of YAG:Ce phosphor particles: measurements from 7 to 77\u00c2\u00a0C the laser-induced fluorescence lifetime of 30 nm particles of yag:ce was measured as a function of temperature from 7 to 77\u00b0c. the fluorescence decay lifetimes for the nanoparticles of this phosphor varied from \u224818 to 27 ns, i.e. \u224833% relative to the longest lifetime measured. this large variation in lifetime, coupled with the high signal strength that was observed, suggest that yag:ce nanoparticles will be useful thermographic phosphors. we describe the material and the apparatus used to characterize its fluorescence, present the results of measurements made over the range of temperatures tested and comment on some possible applications for this novel material.",
            "contribution_ids": [
                "R142216"
            ]
        },
        {
            "instance_id": "EMPTYxR75832",
            "comparison_id": "EMPTY",
            "paper_id": "R75832",
            "text": "The Coordination\u00e2\u0080\u0090Information Bubble in Humanitarian Response: Theoretical Foundations and Empirical Investigations humanitarian disasters are highly dynamic and uncertain. the shifting situation, volatility of information, and the emergence of decision processes and coordination structures require humanitarian organizations to continuously adapt their operations. in this study, we aim to make headway in understanding adaptive decision-making in a dynamic interplay between changing situation, volatile information, and emerging coordination structures. starting from theories of sensemaking, coordination, and decision-making, we present two case studies that represent the response to two different humanitarian disasters: typhoon haiyan in the philippines, and the syria crisis, one of the most prominent ongoing conflicts. for both, we highlight how volatile information and the urge to respond via sensemaking lead to fragmentation and misalignment of emergent coordination structures and decisions, which, in turn, slow down adaptation. based on the case studies, we derive propositions and the need to continuously align laterally between different regions and hierarchically between operational and strategic levels to avoid persistence of coordination-information bubbles. we discuss the implications of our findings for the development of methods and theory to ensure that humanitarian operations management captures the critical role of information as a driver of emergent coordination and adaptive decisions.",
            "contribution_ids": [
                "R75837"
            ]
        },
        {
            "instance_id": "EMPTYxR191750",
            "comparison_id": "EMPTY",
            "paper_id": "R191750",
            "text": "Effect of Data Scaling Methods on Machine Learning Algorithms and Model Performance heart disease, one of the main reasons behind the high mortality rate around the world, requires a sophisticated and expensive diagnosis process. in the recent past, much literature has demonstrated machine learning approaches as an opportunity to efficiently diagnose heart disease patients. however, challenges associated with datasets such as missing data, inconsistent data, and mixed data (containing inconsistent missing data both as numerical and categorical) are often obstacles in medical diagnosis. this inconsistency led to a higher probability of misprediction and a misled result. data preprocessing steps like feature reduction, data conversion, and data scaling are employed to form a standard dataset\u2014such measures play a crucial role in reducing inaccuracy in final prediction. this paper aims to evaluate eleven machine learning (ml) algorithms\u2014logistic regression (lr), linear discriminant analysis (lda), k-nearest neighbors (knn), classification and regression trees (cart), naive bayes (nb), support vector machine (svm), xgboost (xgb), random forest classifier (rf), gradient boost (gb), adaboost (ab), extra tree classifier (et)\u2014and six different data scaling methods\u2014normalization (nr), standscale (ss), minmax (mm), maxabs (ma), robust scaler (rs), and quantile transformer (qt) on a dataset comprising of information of patients with heart disease. the result shows that cart, along with rs or qt, outperforms all other ml algorithms with 100% accuracy, 100% precision, 99% recall, and 100% f1 score. the study outcomes demonstrate that the model\u2019s performance varies depending on the data scaling method.",
            "contribution_ids": [
                "R191755"
            ]
        },
        {
            "instance_id": "EMPTYxR149052",
            "comparison_id": "EMPTY",
            "paper_id": "R149052",
            "text": "Local ontologies for semantic interoperability in supply chain networks \"most of the issues of current supply chain management practices are related to the challenges of interoperability of relevant enterprise information systems (eis). in this paper, we present the ontological framework for semantic interoperability of eiss in supply chain networks, based on supply chain operations reference (scor) model, its semantic enrichment and mappings with relevant enterprise conceptualizations. in order to introduce the realities of the enterprises into this framework, namely their models, we define and implement the approach to generation of local ontologies, based on the databases of their eiss. also, we discuss on the translation between semantic and sql queries, a process in which implicit semantics of the eis's databases and explicit semantics of the local ontologies become inter-related.\"",
            "contribution_ids": [
                "R149054"
            ]
        },
        {
            "instance_id": "EMPTYxR171468",
            "comparison_id": "EMPTY",
            "paper_id": "R171468",
            "text": "National substance use patterns on Twitter purpose we examined openly shared substance-related tweets to estimate prevalent sentiment around substance use and identify popular substance use activities. additionally, we investigated associations between substance-related tweets and business characteristics and demographics at the zip code level. methods a total of 79,848,992 tweets were collected from 48 states in the continental united states from april 2015-march 2016 through the twitter api, of which 688,757 were identified as being related to substance use. we implemented a machine learning algorithm (maximum entropy text classifier) to estimate sentiment score for each tweet. zip code level summaries of substance use tweets were created and merged with the 2013 zip code business patterns and 2010 us census data. results quality control analyses with a random subset of tweets yielded excellent agreement rates between computer generated and manually generated labels: 97%, 88%, 86%, 75% for underage engagement in substance use, alcohol, drug, and smoking tweets, respectively. overall, 34.1% of all substance-related tweets were classified as happy. alcohol was the most frequently tweeted substance, followed by marijuana. regression results suggested more convenience stores in a zip code were associated with higher percentages of tweets about alcohol. larger zip code population size and higher percentages of african americans and hispanics were associated with fewer tweets about substance use and underage engagement. zip code economic disadvantage was associated with fewer alcohol tweets but more drug tweets. conclusions the patterns in substance use mentions on twitter differ by zip code economic and demographic characteristics. online discussions have great potential to glorify and normalize risky behaviors. health promotion and underage substance prevention efforts may include interactive social media campaigns to counter the social modeling of risky behaviors.",
            "contribution_ids": [
                "R171469"
            ]
        },
        {
            "instance_id": "EMPTYxR194895",
            "comparison_id": "EMPTY",
            "paper_id": "R194895",
            "text": "Scalable Analysis of Real-Time Requirements detecting issues in real-time requirements is usually a trade-off between flexibility and cost: the effort expended depends on how expensive it is to fix a defect introduced by faulty, ambiguous or incomplete requirements. the most rigorous techniques for real-time requirement analysis depend on the formalisation of these requirements. completely formalised real-time requirements allow the detection of issues that are hard to find through other means, like real-time inconsistency (i.e., \"do the requirements lead to deadlocks and starvation of the system?\") or vacuity (i.e., \"are some requirements trivially satisfied\"). current analysis techniques for real-time requirements suffer from scalability issues \u2013 larger sets of such requirements are usually intractable. we present a new technique to analyse formalised real-time requirements for various properties. our technique leverages recent advances in software model checking and automatic theorem proving by converting the analysis problem for real-time requirements to a program analysis task. we also report preliminary results from an ongoing, large scale application of our technique in the automotive domain at bosch.",
            "contribution_ids": [
                "R194897"
            ]
        },
        {
            "instance_id": "EMPTYxR171344",
            "comparison_id": "EMPTY",
            "paper_id": "R171344",
            "text": "Socio-environmental exposures and health outcomes among persons with sickle cell disease there is much variability in the expression of sickle cell disease (scd) and recent works suggest that environmental and social factors may also influence this variability. this paper aims to use geographic information systems technology to examine the association between socio-environmental exposures and health outcomes in all persons who have attended or currently attend the sickle cell unit in jamaica. rural patients presented for clinical care at older ages and had less annual visits to clinic. persons travelled relatively long distances to seek scd care and those travelling longer had less health maintenance visits. urban patients had a higher prevalence of significant pain crises (69.4% vs. 55.8%, p value<0.001) and respiratory events (21.2% vs. 14%, p value<0.001). prevalence of leg ulcers did not vary between rural and urban patients but was higher in males than in females. females also had lower odds of having respiratory events but there was no sex difference in history of painful crises. persons with more severe genotypes lived in higher poverty and travelled longer for healthcare services. persons in areas with higher annual rainfall, higher mean temperatures and living farther from factories had less painful crises and respiratory events. the paper highlights a need for better access to healthcare services for jamaicans with scd especially in rural areas of the island. it also reports interesting associations between environmental climatic exposures and health outcomes.",
            "contribution_ids": [
                "R171345",
                "R171346",
                "R171347"
            ]
        },
        {
            "instance_id": "EMPTYxR155287",
            "comparison_id": "EMPTY",
            "paper_id": "R155287",
            "text": "Ultra-Sensitive Strain Sensor Based on Femtosecond Laser Inscribed In-Fiber Reflection Mirrors and Vernier Effect \"one of the efficient techniques to enhance the sensitivity of optical fiber sensor is to utilize vernier effect. however, the complex system structure, precisely controlled device fabrication, or expensive materials required for implementing the technique creates the difficulties for practical applications. here, we propose a highly sensitive optical fiber strain sensor based on two cascaded fabry\u2013perot interferometers and vernier effect. of the two interferometers, one is for sensing and the other for referencing, and they are formed by two pairs of in-fiber reflection mirrors fabricated by femtosecond laser pulse illumination to induce refractive-index-modified area in the fiber core. a relatively large distance between the two fabry\u2013perot interferometers needs to be used to ensure the independent operation of the two interferometers. the fabrication of the device is simple, and the cavity's length can be precisely controlled by a computer-controlled three-dimensional micromachining platform. moreover, as the device is based on the inner structure inside the optical fiber, good robustness of the device can be guaranteed. the experimental results obtained show that the strain sensitivity of the device is \u223c28.11\\xa0pm/\u03bc\u03f5, while the temperature sensitivity achieved is \u223c278.48\\xa0pm/\u00b0c.\"",
            "contribution_ids": [
                "R155290"
            ]
        },
        {
            "instance_id": "EMPTYxR46427",
            "comparison_id": "EMPTY",
            "paper_id": "R46427",
            "text": "Machine comprehension using match-lstm and answer pointer machine comprehension of text is an important problem in natural language processing. a recently released dataset, the stanford question answering dataset (squad), offers a large number of real questions and their answers created by humans through crowdsourcing. squad provides a challenging testbed for evaluating machine comprehension algorithms, partly because compared with previous datasets, in squad the answers do not come from a small set of candidate answers and they have variable lengths. we propose an end-to-end neural architecture for the task. the architecture is based on match-lstm, a model we proposed previously for textual entailment, and pointer net, a sequence-to-sequence model proposed by vinyals et al.(2015) to constrain the output tokens to be from the input sequences. we propose two ways of using pointer net for our task. our experiments show that both of our two models substantially outperform the best results obtained by rajpurkar et al.(2016) using logistic regression and manually crafted features.",
            "contribution_ids": [
                "R46429"
            ]
        },
        {
            "instance_id": "EMPTYxR151319",
            "comparison_id": "EMPTY",
            "paper_id": "R151319",
            "text": "S2ORC: The Semantic Scholar Open Research Corpus we introduce s2orc, a large corpus of 81.1m english-language academic papers spanning many academic disciplines. the corpus consists of rich metadata, paper abstracts, resolved bibliographic references, as well as structured full text for 8.1m open access papers. full text is annotated with automatically-detected inline mentions of citations, figures, and tables, each linked to their corresponding paper objects. in s2orc, we aggregate papers from hundreds of academic publishers and digital archives into a unified source, and create the largest publicly-available collection of machine-readable academic text to date. we hope this resource will facilitate research and development of tools and tasks for text mining over academic text.",
            "contribution_ids": [
                "R151321"
            ]
        },
        {
            "instance_id": "EMPTYxR198917",
            "comparison_id": "EMPTY",
            "paper_id": "R198917",
            "text": "Mining Requirements Knowledge from Collections of Domain Documents \"when organizations enter domains that are entirely new to them, they need to invest significant time and effort to acquire domain knowledge. this typically involves searching through a broad set of domain documents, retrieving relevant ones, and analyzing the textual content in order to discover and specify pertinent requirements. depending on the nature of the domain and the availability of documentation, this task can be extremely time-consuming and may require non-trivial human effort. furthermore, the task must often be performed repeatedly throughout early phases of the project. in this paper we first explore the effort needed to manually build a high-level domain model capturing the functional components. we then present mark (mining requirements knowledge), which identifies and retrieves the documents containing descriptions of functional components in the domain model. domain analysts can use this information to to specify requirements. we introduce and evaluate an algorithm which ranks domain documents according to their relevance to a component and then highlights sections of text which are likely to contain requirements-related information. we describe our process within the context of the positive train control (ptc) domain with a repository of of 523 documents, representing 852mb of data. we empirically evaluate the mark relevance algorithm and its ability to retrieve relevant requirements knowledge for requirements related to ptc's on-board unit.\"",
            "contribution_ids": [
                "R198918"
            ]
        },
        {
            "instance_id": "EMPTYxR46391",
            "comparison_id": "EMPTY",
            "paper_id": "R46391",
            "text": "A parallel-hierarchical model for machine comprehension on sparse data understanding unstructured text is a major goal within natural language processing. comprehension tests pose questions based on short text passages to evaluate such understanding. in this work, we investigate machine comprehension on the challenging {\\\\it mctest} benchmark. partly because of its limited size, prior work on {\\\\it mctest} has focused mainly on engineering better features. we tackle the dataset with a neural approach, harnessing simple neural networks arranged in a parallel hierarchy. the parallel hierarchy enables our model to compare the passage, question, and answer from a variety of trainable perspectives, as opposed to using a manually designed, rigid feature set. perspectives range from the word level to sentence fragments to sequences of sentences; the networks operate only on word-embedding representations of text. when trained with a methodology designed to help cope with limited training data, our parallel-hierarchical model sets a new state of the art for {\\\\it mctest}, outperforming previous feature-engineered approaches slightly and previous neural approaches by a significant margin (over 15\\\\% absolute).",
            "contribution_ids": [
                "R46393"
            ]
        },
        {
            "instance_id": "EMPTYxR194884",
            "comparison_id": "EMPTY",
            "paper_id": "R194884",
            "text": "Extraction of System States from Natural Language Requirements in recent years, simulations have proven to be an important means to verify the behavior of complex software systems. the different states of a system are monitored in the simulations and are compared against the requirements specification. so far, system states in natural language requirements cannot be automatically linked to signals from the simulation. however, the manual mapping between requirements and simulation is a time-consuming task. named-entity recognition is a sub-task from the field of automated information retrieval and is used to classify parts of natural language texts into categories. in this paper, we use a self-trained named-entity recognition model with bidirectional lstms and cnns to extract states from requirements specifications. we present an almost entirely automated approach and an iterative semi-automated approach to train our model. the automated and iterative approach are compared and discussed with respect to the usual manual extraction. we show that the manual extraction of states in 2,000 requirements takes nine hours. our automated approach achieves an f1-score of 0.51 with 15 minutes of manual work and the iterative approach achieves an f1-score of 0.62 with 100 minutes of work.",
            "contribution_ids": [
                "R194885"
            ]
        },
        {
            "instance_id": "EMPTYxR196436",
            "comparison_id": "EMPTY",
            "paper_id": "R196436",
            "text": "The Interplay of Cross-Situational Word Learning and Sentence-Level Constraints \"a variety of mechanisms contribute to word learning. learners can track co-occurring words and referents across situations in a bottom-up manner (cross-situational word learning, cswl). equally, they can exploit sentential contexts, relying on top-down information such as verb-argument relations and world knowledge, offering immediate constraints on meaning (word learning based on sentence-level constraints, slcl). when combined, cswl and slcl potentially modulate each other's influence, revealing how word learners deal with multiple mechanisms simultaneously: do they use all mechanisms? prefer one? is their strategy context dependent? three experiments conducted with adult learners reveal that learners prioritize slcl over cswl. cswl is applied in addition to slcl only if slcl is not perfectly disambiguating, thereby complementing or competing with it. these studies demonstrate the importance of investigating word-learning mechanisms simultaneously, revealing important characteristics of their interaction in more naturalistic learning environments.\"",
            "contribution_ids": [
                "R196438"
            ]
        },
        {
            "instance_id": "EMPTYxR175051",
            "comparison_id": "EMPTY",
            "paper_id": "R175051",
            "text": "The transition of\n            ARVO\n            journals to open access in january 2016, the three journals of the association for research in vision and ophthalmology (arvo) transitioned to gold open access. increased author charges were introduced to partially offset the loss of subscription revenue. submissions to the two established journals initially dropped by almost 15% but have now stabilized. the transition has not impacted acceptance rates and impact factors, and article pageviews and downloads may have increased as a result of open access.",
            "contribution_ids": [
                "R175063",
                "R175053"
            ]
        },
        {
            "instance_id": "EMPTYxR169943",
            "comparison_id": "EMPTY",
            "paper_id": "R169943",
            "text": "Personality in the cockroach Diploptera punctata: Evidence for stability across developmental stages despite age effects on boldness despite a recent surge in the popularity of animal personality studies and their wide-ranging associations with various aspects of behavioural ecology, our understanding of the development of personality over ontogeny remains poorly understood. stability over time is a central tenet of personality; ecological pressures experienced by an individual at different life stages may, however, vary considerably, which may have a significant effect on behavioural traits. invertebrates often go through numerous discrete developmental stages and therefore provide a useful model for such research. here we test for both differential consistency and age effects upon behavioural traits in the gregarious cockroach diploptera punctata by testing the same behavioural traits in both juveniles and adults. in our sample, we find consistency in boldness, exploration and sociality within adults whilst only boldness was consistent in juveniles. both boldness and exploration measures, representative of risk-taking behaviour, show significant consistency across discrete juvenile and adult stages. age effects are, however, apparent in our data; juveniles are significantly bolder than adults, most likely due to differences in the ecological requirements of these life stages. size also affects risk-taking behaviour since smaller adults are both bolder and more highly explorative. whilst a behavioural syndrome linking boldness and exploration is evident in nymphs, this disappears by the adult stage, where links between other behavioural traits become apparent. our results therefore indicate that differential consistency in personality can be maintained across life stages despite age effects on its magnitude, with links between some personality traits changing over ontogeny, demonstrating plasticity in behavioural syndromes.",
            "contribution_ids": [
                "R169944",
                "R169945",
                "R169946",
                "R169947"
            ]
        },
        {
            "instance_id": "EMPTYxR209304",
            "comparison_id": "EMPTY",
            "paper_id": "R209304",
            "text": "Regional Climate Sensitivity of Climate Extremes in CMIP6 Versus CMIP5 Multimodel Ensembles we analyze projected changes in climate extremes (extreme temperatures and heavy precipitation) in the multimodel ensembles of the fifth and sixth coupled model intercomparison projects (cmip5 and cmip6). the results reveal close similarity between both ensembles in the regional climate sensitivity of the projected multimodel mean changes in climate extremes, that is, their projected changes as a function of global warming. this stands in contrast to widely reported divergences in global (transient and equilibrium) climate sensitivity in the two multimodel ensembles. some exceptions include higher warming in the south america monsoon region, lower warming in southern asia and central africa, and higher increases in heavy precipitation in western africa and the sahel region in the cmip6 ensemble. the multimodel spread in regional climate sensitivity is found to be large in both ensembles. in particular, it contributes more to intermodel spread in projected regional climate extremes compared with the intermodel spread in global climate sensitivity in cmip6. our results highlight the need to consider regional climate sensitivity as a distinct feature of earth system models and a key determinant of projected regional impacts, which is largely independent of the models' response in global climate sensitivity.",
            "contribution_ids": [
                "R213843",
                "R213904",
                "R209308",
                "R213369",
                "R213637",
                "R213640",
                "R213647",
                "R213648",
                "R213649",
                "R213650",
                "R213652",
                "R213653",
                "R213655",
                "R213656",
                "R213658",
                "R213659",
                "R213661",
                "R213668",
                "R213672",
                "R213673",
                "R213682",
                "R213691",
                "R213694",
                "R213700",
                "R213701",
                "R213702",
                "R213717",
                "R213721",
                "R213728",
                "R213730",
                "R213741",
                "R213751",
                "R213783",
                "R213789",
                "R213792",
                "R213794",
                "R213801",
                "R213805",
                "R213811",
                "R213828",
                "R213851",
                "R213852",
                "R213876",
                "R213918",
                "R213936",
                "R213938",
                "R213942",
                "R213944",
                "R215002",
                "R215015"
            ]
        },
        {
            "instance_id": "EMPTYxR161635",
            "comparison_id": "EMPTY",
            "paper_id": "R161635",
            "text": "Extremely Stretchable Strain Sensors Based on Conductive Self-Healing Dynamic Cross-Links Hydrogels for Human-Motion Detection extremely stretchable self\u2010healing strain sensors based on conductive hydrogels are successfully fabricated. the strain sensor can achieve autonomic self\u2010heal electrically and mechanically under ambient conditions, and can sustain extreme elastic strain (1000%) with high gauge factor of 1.51. furthermore, the strain sensors have good response, signal stability, and repeatability under various human motion detections.",
            "contribution_ids": [
                "R161637"
            ]
        },
        {
            "instance_id": "EMPTYxR145355",
            "comparison_id": "EMPTY",
            "paper_id": "R145355",
            "text": "Monitoring Out-of-State Patients during a 2017 Hurricane Response using ESSENCE objective to demonstrate the use of essence in the biosense platform to monitor out-of-state patients seeking emergency healthcare in tennessee during hurricanes harvey and irma. introduction syndromic surveillance is the monitoring of symptom combinations (i.e., syndromes) or other indicators within a population to inform public health actions. the tennessee department of health (tdh) collects emergency department (ed) data from more than 70 hospitals across tennessee to support statewide syndromic surveillance activities. hospitals in tennessee typically provide data within 48 hours of a patient encounter. while syndromic surveillance often supplements disease- or condition-specific surveillance, it can also provide general situational awareness about emergency department patients during an event or response. during hurricanes harvey (continental us landfall on august 25, 2017) and irma (continental us landfall on september 10, 2017), tdh supported all hazards situational awareness using the electronic surveillance system for the early notification of community-based epidemics (essence) in the biosense platform supported by the national syndromic surveillance program (nssp). the volume of out-of-state patients in tennessee was monitored to assess the impact on the healthcare system and any geographic- or hospital-specific clustering of out-of-state patients within tennessee. results were included in daily state health operations center (shoc) situation reports and shared with agency response partners such as the tennessee emergency management agency (tema). methods data were monitored from august 18, 2017 through september 24, 2017. a simple query was established in essence using the patient location (full details) dataset. data were limited to hospital ed visits reported by tennessee (site = \u201ctennessee\u201d). to monitor ed visits among residents of texas before, during, and after major hurricane harvey, data were queried for a patient zip code within texas (state = \u201ctexas\u201d). ed visits among florida residents were monitored similarly (state = \u201cflorida\u201d) before, during, and after major hurricane irma. additionally, a free text chief complaint search was implemented for the terms \u201charvey\u201d, \u201cirma, \u201churricane\u201d, \u201cevacuee\u201d, \u201cevacuate\u201d, \u201cflorida\u201d, and \u201ctexas\u201d. chief complaint search results were then filtered to remove encounters with patient zip codes within tennessee. results from august 18, 2017 through september 24, 2017, tennessee hospital eds reported 277 patient encounters among texas residents and 1,041 patient encounters among florida residents. the number of encounters among patients from texas remained stable throughout the monitoring period. in contrast, the number of encounters among patients from florida exceeded the expected value on september 7, peaked september 10 at 116 patient encounters, and returned to expected levels on september 16 (figure 1). the increase in patients from florida was evenly distributed across most of tennessee, with some clustering around a popular tourism area in east tennessee. no concerning trends in reported syndromes or chief complaints were identified among texas or florida patients. the free text chief complaint query first exceeded the expected value on september 9, peaked on september 11 with 5 patient encounters, and returned to expected levels on september 14. from august 18 through september 24, 21 of 30 visits captured by the query were among florida residents. one tennessee hospital appeared to be intentionally using the term \u201cirma\u201d in their chief complaint field to indicate patients from florida impacted by the hurricane. conclusions the essence instance in the biosense platform provided tdh the opportunity to easily locate and monitor out-of-state patients seen in tennessee hospital eds. while tdh was unable to validate whether all patients identified as residents of florida were displaced because of major hurricane irma, the timing of the rise and fall of patient encounters was highly suggestive. likewise, seeing no substantial increase ed patients with residence in texas reassured tdh that the effects of hurricane harvey were not impacting hospital emergency departments in tennessee. tdh used information and charts from essence to support situational awareness in our shoc and at tema. use of patient zip code to identify out-of-state residents was more sensitive than chief complaint searches by keyword during this event. essence allowed tdh to see where out-of-state patients appeared to be concentrating in tennessee and monitor the need for targeting messaging and resources to heavily affected areas. additionally, close surveillance of chief complaints among out-of-state patients provided assurance that no unusual patterns in illness or injury were occurring. essence is the only tdh information source capable of rapidly collecting health information on out-of-state patients. essence allowed tdh to quickly identify a change within the patient population seen at tennessee emergency departments and monitor the situation until the patient population returned to baseline levels.",
            "contribution_ids": [
                "R145357"
            ]
        },
        {
            "instance_id": "EMPTYxR170060",
            "comparison_id": "EMPTY",
            "paper_id": "R170060",
            "text": "Nurses\u00e2\u0080\u0099 professional competency and organizational commitment: Is it important for human resource management? \"background professional competency is a fundamental concept in nursing, which has a direct relationship with quality improvement of patient care and public health. organizational commitment as a kind of affective attachment or sense of loyalty to the organization is an effective factor for professional competency. objective this study was conducted to evaluate the nurses\u00b4 professional competency and their organizational commitment as well as the relationship between these two concepts. methods and materials this descriptive-analytic study was conducted at the hospitals affiliated with a university of medical sciences, in the southeast of iran in 2016. the sample included 230 nurses who were selected using stratified random sampling. data were gathered by three questionnaires including socio-demographic information, competency inventory for registered nurse (cirn) and allen meyer's organizational commitment. results results showed that professional competency (mean\u00b1sd: 2.82\u00b10.53, range: 1.56\u20134.00) and organizational commitment (mean\u00b1sd: 72.80\u00b14.95, range: 58\u201381) of the nurses were at moderate levels. there was no statistically significant correlation between professional competency and organizational commitment (\u03c1 = 0.02; p = 0.74). there were significant differences in professional competency based on marital status (p = 0.03) and work experience (p<0.001). conclusion the results highlighted that the nurses needed to be more competent and committed to their organizations. developing professional competency and organizational commitment is vital, but not easy. this study suggests that human resource managers should pursue appropriate strategies to enhance the professional competency and organizational commitment of their nursing staff. it is necessary to conduct more comprehensive studies for exploring the status and gaps in the human resource management of healthcare in different cultures and contexts.\"",
            "contribution_ids": [
                "R170061"
            ]
        },
        {
            "instance_id": "EMPTYxR186148",
            "comparison_id": "EMPTY",
            "paper_id": "R186148",
            "text": "Learning Sequence Encoders for Temporal Knowledge Graph Completion research on link prediction in knowledge graphs has mainly focused on static multi-relational data. in this work we consider temporal knowledge graphs where relations between entities may only hold for a time interval or a specific point in time. in line with previous work on static knowledge graphs, we propose to address this problem by learning latent entity and relation type representations. to incorporate temporal information, we utilize recurrent neural networks to learn time-aware representations of relation types which can be used in conjunction with existing latent factorization methods. the proposed approach is shown to be robust to common challenges in real-world kgs: the sparsity and heterogeneity of temporal expressions. experiments show the benefits of our approach on four temporal kgs. the data sets are available under a permissive bsd-3 license.",
            "contribution_ids": [
                "R186150"
            ]
        },
        {
            "instance_id": "EMPTYxR130420",
            "comparison_id": "EMPTY",
            "paper_id": "R130420",
            "text": "Simple and Effective Multi-Paragraph Reading Comprehension we introduce a method of adapting neural paragraph-level question answering models to the case where entire documents are given as input. most current question answering models cannot scale to document or multi-document input, and naively applying these models to each paragraph independently often results in them being distracted by irrelevant text. we show that it is possible to significantly improve performance by using a modified training scheme that teaches the model to ignore non-answer containing paragraphs. our method involves sampling multiple paragraphs from each document, and using an objective function that requires the model to produce globally correct output. we additionally identify and improve upon a number of other design decisions that arise when working with document-level data. experiments on triviaqa and squad shows our method advances the state of the art, including a 10 point gain on triviaqa.",
            "contribution_ids": [
                "R130421",
                "R130425"
            ]
        },
        {
            "instance_id": "EMPTYxR78301",
            "comparison_id": "EMPTY",
            "paper_id": "R78301",
            "text": "Petroleum Hydrocarbons Contamination of Surface Water and Groundwater in the Niger Delta Region of Nigeria petroleum hydrocarbons contamination of the environment associated with exploration, development and production operations is a common feature in oil producing nations around the world, especially in a developing country like nigeria where the incidence of facilities sabotage, operational failures, accidental discharges, pipeline vandalization and leakages, bunkering and artisanal refining is very common. apart from poor governance systems, poor corporate social responsibility (csr) of multinational oil companies (mocs), poor environmental regulation of the petroleum industry, the inability of the political elite to effectively manage petroleum hydrocarbon-derived revenue, loss of petroleum hydrocarbons resource revenue to corruption and theft, petroleum hydrocarbons contamination of the total environment (air, soil, water and biota) have impacted negatively on the human health and wellbeing of oil producing communities in the nigeria\u2019s niger delta region. findings from several studies have revealed variable negative impacts of petroleum hydrocarbons toxicity on the human health (including exposed populations), the natural environment and other ecological receptors. over the past fifty\u2013five years, the oil producing host communities in the nigeria\u2019s niger delta region have experienced a wide range of environmental pollution, degradation, human health risks, deterioration of our cultural heritage items and socio\u2013economic problems as a result of various activities associated with petroleum exploration, development and production. petroleum hydrocarbons contamination of surface water and groundwater is a notable environmental and human health problem in the oil producing communities and there are several water quality issues in the nigeria\u2019s niger delta region. this review examines some of the water quality issues and human health implications of petroleum hydrocarbons contamination of controlled water sources (surface-water and groundwater) in the oil producing host communities in the nigeria\u2019s niger delta region. it will further highlight some of the problems of petroleum hydrocarbons contamination and/or pollution of marine environments associated with unsustainable practices of petroleum industry in the region.",
            "contribution_ids": [
                "R78303"
            ]
        },
        {
            "instance_id": "EMPTYxR74127",
            "comparison_id": "EMPTY",
            "paper_id": "R74127",
            "text": "ISO-Standardized Smart City Platform Architecture and Dashboard a concept guided by the iso 37120 standard for city services and quality of life is suggested as unified framework for smart city dashboards. the slow (annual, quarterly, or monthly) iso 37120 indicators are enhanced and complemented with more detailed and person-centric indicators that can further accelerate the transition toward smart cities. the architecture supports three tasks: acquire and manage data from heterogeneous sensors; process data originated from heterogeneous sources (sensors, opendata, social data, blogs, news, and so on); and implement such collection and processing on the cloud. a prototype application based on the proposed architecture concept is developed for the city of skopje, macedonia. this article is part of a special issue on smart cities.",
            "contribution_ids": [
                "R74129"
            ]
        },
        {
            "instance_id": "EMPTYxR110142",
            "comparison_id": "EMPTY",
            "paper_id": "R110142",
            "text": "Do Animals Engage Greater Social Attention in Autism? An Eye Tracking Analysis background visual atypicalities in autism spectrum disorder (asd) are a well documented phenomenon, beginning as early as 2\u20136 months of age and manifesting in a significantly decreased attention to the eyes, direct gaze and socially salient information. early emerging neurobiological deficits in perceiving social stimuli as rewarding or its active avoidance due to the anxiety it entails have been widely purported as potential reasons for this atypicality. parallel research evidence also points to the significant benefits of animal presence for reducing social anxiety and enhancing social interaction in children with autism. while atypicality in social attention in asd has been widely substantiated, whether this atypicality persists equally across species types or is confined to humans has not been a key focus of research insofar. methods we attempted a comprehensive examination of the differences in visual attention to static images of human and animal faces (40 images; 20 human faces and 20 animal faces) among children with asd using an eye tracking paradigm. 44 children (asd n = 21; td n = 23) participated in the study (10,362 valid observations) across five regions of interest (left eye, right eye, eye region, face and screen). results results obtained revealed significantly greater social attention across human and animal stimuli in typical controls when compared to children with asd. however in children with asd, a significantly greater attention allocation was seen to animal faces and eye region and lesser attention to the animal mouth when compared to human faces, indicative of a clear attentional preference to socially salient regions of animal stimuli. the positive attentional bias toward animals was also seen in terms of a significantly greater visual attention to direct gaze in animal images. conclusion our results suggest the possibility that atypicalities in social attention in asd may not be uniform across species. it adds to the current neural and biomarker evidence base of the potentially greater social reward processing and lesser social anxiety underlying animal stimuli as compared to human stimuli in children with asd.",
            "contribution_ids": [
                "R110144"
            ]
        },
        {
            "instance_id": "EMPTYxR170985",
            "comparison_id": "EMPTY",
            "paper_id": "R170985",
            "text": "The Majority of the Migrant Factory Workers of the Light Industry in Shenzhen, China May Be Physically Inactive physical inactivity is a strong risk factor of non-communicable diseases (ncd). in china, there are 250 million migrant factory workers, who are susceptible to physical inactivity and hence ncd because of work nature and setting. with random stratified sampling, 807 such workers of the light industry were recruited in shenzhen, china and completed a self-administered questionnaire with informed consent. the prevalence of inadequate physical activity (defined according to the world health organization\u2019s recommendation on level of moderate/vigorous physical activity) was 95.4%. of all participants, 69.1% showed \u201ca very low level of physical activity\u201d (vllpa), defined as \u226430 minutes of weekly moderate/vigorous physical activity, which was significantly associated with female sex (odds ratio [or]=1.65), lower education level (or=0.10 to 0.33, primary education as the reference group) and married status (or=0.63, single status as the reference group). adjusted for these factors, perceived social support (adjusted or=0.87) was negatively associated with vllpa, while job stress due to workload, which was significant in the univariate analysis (or=0.98), became non-significant (p=0.184). significant interaction between perceived social support and perceived job stress onto vllpa was found (p=0.044), implying that the negative association between job stress and vllpa, which might reflect a potential response to cope with stress by performing exercises, was stronger among those with weaker social support. the extremely low level of physical activity rings an alarm, as it implies high risk of ncd, and as there are no existing programs promoting physical activity in this group. interventions need to take into account social support, potential coping to job stress, and structural factors of the factory setting, while involving factories\u2019 management.",
            "contribution_ids": [
                "R170986",
                "R170987"
            ]
        },
        {
            "instance_id": "EMPTYxR193165",
            "comparison_id": "EMPTY",
            "paper_id": "R193165",
            "text": "Human motion synthesis from 3D video multiple view 3d video reconstruction of actor performance captures a level-of-detail for body and clothing movement which is time-consuming to produce using existing animation tools. in this paper we present a framework for concatenative synthesis from multiple 3d video sequences according to user constraints on movement, position and timing. multiple 3d video sequences of an actor performing different movements are automatically constructed into a surface motion graph which represents the possible transitions with similar shape and motion between sequences without unnatural movement artifacts. shape similarity over an adaptive temporal window is used to identify transitions between 3d video sequences. novel 3d video sequences are synthesized by finding the optimal path in the surface motion graph between user specified key-frames for control of movement, location and timing. the optimal path which satisfies the user constraints whilst minimizing the total transition cost between 3d video sequences is found using integer linear programming. results demonstrate that this framework allows flexible production of novel 3d video sequences which preserve the detailed dynamics of the captured movement for an actress with loose clothing and long hair without visible artifacts.",
            "contribution_ids": [
                "R193167"
            ]
        },
        {
            "instance_id": "EMPTYxR75825",
            "comparison_id": "EMPTY",
            "paper_id": "R75825",
            "text": "Evidence-Based Decision-Making (Part II): Applications in Disaster Relief Operations abstract recognized limitations to data in disaster management have led to dozens of initiatives to strengthen data gathering and decision-making during disasters. these initiatives are complicated by fundamental problems of definitions of terms, ambiguity of concepts, lack of standardization in methods of data collection, and inadequate attempts to strengthen the analytic capability of field organizations. cross-cutting issues in needs assessment, coordination, and evaluation illustrate additional recurring challenges in dealing with evidence in humanitarian assistance. these challenges include lack of agency expertise, dyscoordination at the field level, inappropriate reliance on indicators that measure process rather than outcome, flawed scientific inference, and erosion of the concept of minimum standards. decision-making in disaster management currently places a premium on expert or eminence-based decisions. by contrast, scientific advances in disaster medicine call for evidence-based decisions whose strength of evidence is established by the methods of data acquisition. at present, disaster relief operations may be data driven, but that does not mean that they are soundly evidence-based. options for strengthening evidence-based activities include rigorously adhering to evidenced-based interventions, using evidence-based tools to identify new approaches to problems of concern, studying model programs as well as failed ones to identify approaches that deserve replication, and improving standards for evidence of effectiveness in disaster science and services.",
            "contribution_ids": [
                "R75827"
            ]
        },
        {
            "instance_id": "EMPTYxR170269",
            "comparison_id": "EMPTY",
            "paper_id": "R170269",
            "text": "Crowd vocal learning induces vocal dialects in bats: Playback of conspecifics shapes fundamental frequency usage by pups \"vocal learning, the substrate of human language acquisition, has rarely been described in other mammals. often, group-specific vocal dialects in wild populations provide the main evidence for vocal learning. while social learning is often the most plausible explanation for these intergroup differences, it is usually impossible to exclude other driving factors, such as genetic or ecological backgrounds. here, we show the formation of dialects through social vocal learning in fruit bats under controlled conditions. we raised 3 groups of pups in conditions mimicking their natural roosts. namely, pups could hear their mothers' vocalizations but were also exposed to a manipulation playback. the vocalizations in the 3 playbacks mainly differed in their fundamental frequency. from the age of approximately 6 months and onwards, the pups demonstrated distinct dialects, where each group was biased towards its playback. we demonstrate the emergence of dialects through social learning in a mammalian model in a tightly controlled environment. unlike in the extensively studied case of songbirds where specific tutors are imitated, we demonstrate that bats do not only learn their vocalizations directly from their mothers, but that they are actually influenced by the sounds of the entire crowd. this process, which we term \u201ccrowd vocal learning,\u201d might be relevant to many other social animals such as cetaceans and pinnipeds.\"",
            "contribution_ids": [
                "R170271"
            ]
        },
        {
            "instance_id": "EMPTYxR137065",
            "comparison_id": "EMPTY",
            "paper_id": "R137065",
            "text": "Biaryl Construction via Ni-Catalyzed C\u00e2\u0088\u0092O Activation of Phenolic Carboxylates biaryl scaffolds were constructed via ni-catalyzed aryl c-o activation by avoiding cleavage of the more reactive acyl c-o bond of aryl carboxylates. now aryl esters, in general, can be successfully employed in cross-coupling reactions for the first time. the substrate scope and synthetic utility of the chemistry were demonstrated by the syntheses of more than 40 biaryls and by constructing complex organic molecules. water was observed to play an important role in facilitating this transformation.",
            "contribution_ids": [
                "R137067"
            ]
        },
        {
            "instance_id": "EMPTYxR170818",
            "comparison_id": "EMPTY",
            "paper_id": "R170818",
            "text": "How Psychological and Behavioral Team States Change during Positive and Negative Momentum in business and sports, teams often experience periods of positive and negative momentum while pursuing their goals. however, researchers have not yet been able to provide insights into how psychological and behavioral states actually change during positive and negative team momentum. in the current study we aimed to provide these insights by introducing an experimental dynamical research design. rowing pairs had to compete against a virtual opponent on rowing ergometers, while a screen in front of the team broadcasted the ongoing race. the race was manipulated so that the team\u2019s rowing avatar gradually progressed (positive momentum) or regressed (negative momentum) in relation to the victory. the participants responded verbally to collective efficacy and task cohesion items appearing on the screen each minute. in addition, effort exertion and interpersonal coordination were continuously measured. our results showed negative psychological changes (perceptions of collective efficacy and task cohesion) during negative team momentum, which were stronger than the positive changes during positive team momentum. moreover, teams\u2019 exerted efforts rapidly decreased during negative momentum, whereas positive momentum accompanied a more variable and adaptive sequence of effort exertion. finally, the interpersonal coordination was worse during negative momentum than during positive momentum. these results provide the first empirical insights into actual team momentum dynamics, and demonstrate how a dynamical research approach significantly contributes to current knowledge on psychological and behavioral processes.",
            "contribution_ids": [
                "R170819"
            ]
        },
        {
            "instance_id": "EMPTYxR160558",
            "comparison_id": "EMPTY",
            "paper_id": "R160558",
            "text": "Classification of Iowa wetlands using an airborne hyperspectral image: a comparison of the spectral angle mapper classifier and an object-oriented approach \"wetlands mapping using multispectral imagery from landsat multispectral scanner (mss) and thematic mapper (tm) and syst\u00e8me pour l'observation de la terre (spot) does not in general provide high classification accuracies because of poor spectral and spatial resolutions. this study tests the feasibility of using high-resolution hyperspectral imagery to map wetlands in iowa with two nontraditional classification techniques: the spectral angle mapper (sam) method and a new nonparametric object-oriented (oo) classification. the software programs used were envi and ecognition. accuracies of these classified images were assessed by using the information collected through a field survey with a global positioning system and high-resolution color infrared images. wetlands were identified more accurately with the oo method (overall accuracy 92.3%) than with sam (63.53%). this paper also discusses the limitations of these classification techniques for wetlands, as well as discussing future directions for study.\"",
            "contribution_ids": [
                "R160560"
            ]
        },
        {
            "instance_id": "EMPTYxR211914",
            "comparison_id": "EMPTY",
            "paper_id": "R211914",
            "text": "WiFiMon app measuring Wi-Fi performance as experienced by end-users the measurement of quality and efficiency of a wireless wi-fi network is particularly difficult, as there is not a single tool that can record measurements from all sides of the system, i.e. from both the access point and the end-user. existing tools are able to monitor the overall quality of the wireless network; although they cannot determine how end-users experience the quality of wi-fi in a particular part of the network at a given time. in this paper we present a novel tool, named wifimon, which enables measuring, recording and exporting statistics regarding the quality of a wi-fi network as experienced by the end-users. the measurements are triggered by the end-users when they visit wifimon-enabled websites and/or run wifimon-enabled mobile applications and are recorded without users' intervention. main goal of wifimon is to give network administrators a better overview on how the end-users experience the conditions of the wi-fi network.",
            "contribution_ids": [
                "R211916"
            ]
        },
        {
            "instance_id": "EMPTYxR4677",
            "comparison_id": "EMPTY",
            "paper_id": "R4677",
            "text": "Fragmentation as an aggregation process when severely impacted, a cohesive object deforms and eventually breaks into fragments. cohesion forces keeping the material together and momentum driving the fragmentation couple through a complicated process involving crack propagation on a deforming substrate, so that a comprehensive scenario for the build-up of the full fragment size distribution of broken objects is still lacking. we use necklaces of cohesive particles (magnetized spheres) as an experimental model of a one-dimensional material, which we expand radially in an impulsive way. exploring in real time the intermediate state where the particles are no longer in contact, but still in interaction as they separate, we demonstrate that the final fragments result from the self-assembly of individual particles and that their size distribution converges to a stable self-similar distribution whose parameters, interpreted from first principles, depend on the expansion and cohesion strengths.",
            "contribution_ids": [
                "R4678"
            ]
        },
        {
            "instance_id": "EMPTYxR53426",
            "comparison_id": "EMPTY",
            "paper_id": "R53426",
            "text": "Big Earth data analytics: a survey abstract big earth data are produced from satellite observations, internet-of-things, model simulations, and other sources. the data embed unprecedented insights and spatiotemporal stamps of relevant earth phenomena for improving our understanding, responding, and addressing challenges of earth sciences and applications. in the past years, new technologies (such as cloud computing, big data and artificial intelligence) have gained momentum in addressing the challenges of using big earth data for scientific studies and geospatial applications historically intractable. this paper reviews the big earth data analytics from several aspects to capture the latest advancements in this fast-growing domain. we first introduce the concepts of big earth data. the architecture, various functionalities, and supporting modules are then reviewed from a generic methodology aspect. analytical methods supporting the functionalities are surveyed and analyzed in the context of different tools. the driven questions are exemplified through cutting-edge earth science researches and applications. a list of challenges and opportunities are proposed for different stakeholders to collaboratively advance big earth data analytics in the near future.",
            "contribution_ids": [
                "R53449",
                "R53450",
                "R53451",
                "R53454"
            ]
        },
        {
            "instance_id": "EMPTYxR171497",
            "comparison_id": "EMPTY",
            "paper_id": "R171497",
            "text": "Engagement of vulnerable youths using internet platforms aim the aim of this study was to explore the online distress and help-seeking behavior of youths in hong kong. methods a cross-sectional telephone-based survey was conducted among 1,010 young people in hong kong. logistic regression analysis was then performed to identify the factors associated with those who reported expressing emotional distress online and the differences in help-seeking behavior among four groups of youths: (1) the non-distressed (reference) group; (2) \u201cdid not seek help\u201d group; (3) \u201cseek informal help\u201d group; and (4) \u201cseek formal help\u201d group. results the seeking of help and expression of distress online were found to be associated with a higher lifetime prevalence of suicidal ideation. the \u201cseek formal help\u201d and \u201cdid not seek help\u201d groups had a similar risk profile, including a higher prevalence of suicidal ideation, non-suicidal self-injury, unsafe sex, and being bullied. the \u201cseek informal help\u201d group was more likely to express distress online, which indicates that this population of youths may be accessible to professional identification. approximately 20% of the distressed youths surveyed had not sought help despite expressing their distress online. implication the study\u2019s results indicate that helping professionals have opportunities to develop strategic engagement methods that make use of social media to help distressed youths.",
            "contribution_ids": [
                "R171498"
            ]
        },
        {
            "instance_id": "EMPTYxR130733",
            "comparison_id": "EMPTY",
            "paper_id": "R130733",
            "text": "Multiplicative LSTM for sequence modelling we introduce multiplicative lstm (mlstm), a recurrent neural network architecture for sequence modelling that combines the long short-term memory (lstm) and multiplicative recurrent neural network architectures. mlstm is characterised by its ability to have different recurrent transition functions for each possible input, which we argue makes it more expressive for autoregressive density estimation. we demonstrate empirically that mlstm outperforms standard lstm and its deep variants for a range of character level language modelling tasks. in this version of the paper, we regularise mlstm to achieve 1.27 bits/char on text8 and 1.24 bits/char on hutter prize. we also apply a purely byte-level mlstm on the wikitext-2 dataset to achieve a character level entropy of 1.26 bits/char, corresponding to a word level perplexity of 88.8, which is comparable to word level lstms regularised in similar ways on the same task.",
            "contribution_ids": [
                "R130734",
                "R130738",
                "R130745"
            ]
        },
        {
            "instance_id": "EMPTYxR142560",
            "comparison_id": "EMPTY",
            "paper_id": "R142560",
            "text": "Products and Services Ontologies: A Methodology for Deriving OWL Ontologies from Industrial Categorization Standards using semantic web technologies for e-business tasks, like product search or content integration, requires ontologies for products and services. their manual creation is problematic due to (1) the high specificity, resulting in a large number of concepts, and (2) the need for timely ontology maintenance due to product innovation; and due to cost, since building such ontologies from scratch requires significant resources. at the same time, industrial categorization standards, like unspsc, ecl@ss, eotd, or the rosettanet technical dictionary, reflect some degree of consensus and contain a wealth of concept definitions plus a hierarchy. they can thus be valuable input for creating domain ontologies. however, the transformation of existing standards, originally developed for some purpose other than ontology engineering, into useful ontologies is not as straightforward as it appears. in this paper, (1) we argue that deriving products and services ontologies from industrial taxonomies is more feasible than manual ontology engineering; (2) show that the representation of the original semantics of the input standard, especially the taxonomic relationship, is an important modeling decision that determines the usefulness of the resulting ontology; (3) illustrate the problem by analyzing existing ontologies derived from unspcs and ecl@ss; (4) present a methodology for creating ontologies in owl based on the reuse of existing standards; and (5) demonstrate this approach by transforming ecl@ss 5.1 into a practically useful products and services ontology.",
            "contribution_ids": [
                "R142562"
            ]
        },
        {
            "instance_id": "EMPTYxR75719",
            "comparison_id": "EMPTY",
            "paper_id": "R75719",
            "text": "Cucurbit[n]uril-Immobilized Sensor Arrays for Indicator-Displacement Assays of Small Bioactive Metabolites the patterned immobilization of chemosensors into nano/microarrays has often boosted utilization in diagnostics and environmental sensing applications. while this is a standard approach for biosens...",
            "contribution_ids": [
                "R75723"
            ]
        },
        {
            "instance_id": "EMPTYxR44454",
            "comparison_id": "EMPTY",
            "paper_id": "R44454",
            "text": "Disposition and clinical use of bromide in cats objective\\nto establish a dosing regimen for potassium bromide and evaluate use of bromide to treat spontaneous seizures in cats.\\n\\n\\ndesign\\nprospective and retrospective studies.\\n\\n\\nanimals\\n7 healthy adult male cats and records of 17 cats with seizures.\\n\\n\\nprocedure\\nseven healthy cats were administered potassium bromide (15 mg/kg [6.8 mg/lb], p.o., q 12 h) until steady-state concentrations were reached. serum samples for pharmacokinetic analysis were obtained weekly until bromide concentrations were not detectable. clinical data were obtained from records of 17 treated cats.\\n\\n\\nresults\\nin the prospective study, maximum serum bromide concentration was 1.1 +/- 0.2 mg/ml at 8 weeks. mean disappearance half-life was 1.6 +/- 0.2 weeks. steady state was achieved at a mean of 5.3 +/-1.1 weeks. no adverse effects were detected and bromide was well tolerated. in the retrospective study, administration of bromide (n = 4) or bromide and phenobarbital (3) was associated with eradication of seizures in 7 of 15 cats (serum bromide concentration range, 1.0 to 1.6 mg/ml); however, bromide administration was associated with adverse effects in 8 of 16 cats. coughing developed in 6 of these cats, leading to euthanasia in 1 cat and discontinuation of bromide administration in 2 cats.\\n\\n\\nconclusions and clinical relevance\\ntherapeutic concentrations of bromide are attained within 2 weeks in cats that receive 30 mg/kg/d (13.6 mg/lb/d) orally. although somewhat effective in seizure control, the incidence of adverse effects may not warrant routine use of bromide for control of seizures in cats.",
            "contribution_ids": [
                "R44455",
                "R44472",
                "R44499",
                "R44500"
            ]
        },
        {
            "instance_id": "EMPTYxR170503",
            "comparison_id": "EMPTY",
            "paper_id": "R170503",
            "text": "Matter Over Mind: A Randomised-Controlled Trial of Single-Session Biofeedback Training on Performance Anxiety and Heart Rate Variability in Musicians background musical performance is a skilled activity performed under intense pressure, thus is often a profound source of anxiety. in other contexts, anxiety and its concomitant symptoms of sympathetic nervous system arousal have been successfully ameliorated with hrv biofeedback (hrv bf), a technique involving slow breathing which augments autonomic and emotional regulatory capacity. objective: this randomised-controlled study explored the impact of a single 30-minute session of hrv bf on anxiety in response to a highly stressful music performance. methods a total of 46 trained musicians participated in this study and were randomly allocated to a slow breathing with or without biofeedback or no-treatment control group. a 3 group\u00d72 time mixed experimental design was employed to compare the effect of group before and after intervention on performance anxiety (stai-s) and frequency domain measures of hrv. results slow breathing groups (n\\u200a=\\u200a30) showed significantly greater improvements in high frequency (hf) and lf/hf ratio measures of hrv relative to control (n\\u200a=\\u200a15) during 5 minute recordings of performance anticipation following the intervention (effect size: \u03b72\\u200a=\\u200a0.122 and \u03b72\\u200a=\\u200a0.116, respectively). the addition of biofeedback to a slow breathing protocol did not produce differential results. while intervention groups did not exhibit an overall reduction in self-reported anxiety, participants with high baseline anxiety who received the intervention (n\\u200a=\\u200a15) displayed greater reductions in self-reported state anxiety relative to those in the control condition (n\\u200a=\\u200a7) (r\\u200a=\\u200a0.379). conclusions these findings indicate that a single session of slow breathing, regardless of biofeedback, is sufficient for controlling physiological arousal in anticipation of psychosocial stress associated with music performance and that slow breathing is particularly helpful for musicians with high levels of anxiety. future research is needed to further examine the effects of hrv bf as a low-cost, non-pharmacological treatment for music performance anxiety.",
            "contribution_ids": [
                "R170504",
                "R170505"
            ]
        },
        {
            "instance_id": "EMPTYxR36093",
            "comparison_id": "EMPTY",
            "paper_id": "R36093",
            "text": "TableSeer: automatic table metadata extraction and searching in digital libraries tables are ubiquitous in digital libraries. in scientific documents, tables are widely used to present experimental results or statistical data in a condensed fashion. however, current search engines do not support table search. the difficulty of automatic extracting tables from un-tagged documents, the lack of a universal table metadata specification, and the limitation of the existing ranking schemes make table search problem challenging. in this paper, we describe tableseer, a search engine for tables. tableseer crawls digital libraries, detects tables from documents, extracts tables metadata, indexes and ranks tables, and provides a user-friendly search interface. we propose an extensive set of medium-independent metadata for tables that scientists and other users can adopt for representing table information. in addition, we devise a novel page box-cutting method to improve the performance of the table detection. given a query, tableseer ranks the matched tables using an innovative ranking algorithm - tablerank. tablerank rates each \u20edquery, table\u2102 pair with a tailored vector space model and a specific term weighting scheme. overall, tableseer eliminates the burden of manually extract table data from digital libraries and enables users to automatically examine tables. we demonstrate the value of tableseer with empirical studies on scientific documents.",
            "contribution_ids": [
                "R36094"
            ]
        },
        {
            "instance_id": "EMPTYxR140556",
            "comparison_id": "EMPTY",
            "paper_id": "R140556",
            "text": "An image processing approach for converging ASTER-derived spectral maps for mapping Kolhan limestone, Jharkhand, India in the present study, we have attempted the delineation of limestone using different spectral mapping algorithms in aster data. each spectral mapping algorithm derives limestone exposure map independently. although these spectral maps are broadly similar to each other, they are also different at places in terms of spatial disposition of limestone pixels. therefore, an attempt is made to integrate the results of these spectral maps to derive an integrated map using minimum noise fraction (mnf) method. the first mnf image is the result of two cascaded principal component methods suitable for preserving complementary information derived from each spectral map. while implementing mnf, noise or non-coherent pixels occurring within a homogeneous patch of limestone are removed first using shift difference method, before attempting principal component analysis on input spectral maps for deriving composite spectral map of limestone exposures. the limestone exposure map is further validated based on spectral data and ancillary geological data.",
            "contribution_ids": [
                "R140557"
            ]
        },
        {
            "instance_id": "EMPTYxR171247",
            "comparison_id": "EMPTY",
            "paper_id": "R171247",
            "text": "Open-Access Mega-Journals: A Bibliometric Profile in this paper we present the first comprehensive bibliometric analysis of eleven open-access mega-journals (oamjs). oamjs are a relatively recent phenomenon, and have been characterised as having four key characteristics: large size; broad disciplinary scope; a gold-oa business model; and a peer-review policy that seeks to determine only the scientific soundness of the research rather than evaluate the novelty or significance of the work. our investigation focuses on four key modes of analysis: journal outputs (the number of articles published and changes in output over time); oamj author characteristics (nationalities and institutional affiliations); subject areas (the disciplinary scope of oamjs, and variations in sub-disciplinary output); and citation profiles (the citation distributions of each oamj, and the impact of citing journals). we found that while the total output of the eleven mega-journals grew by 14.9% between 2014 and 2015, this growth is largely attributable to the increased output of scientific reports and medicine. we also found substantial variation in the geographical distribution of authors. several journals have a relatively high proportion of chinese authors, and we suggest this may be linked to these journals\u2019 high journal impact factors (jifs). the mega-journals were also found to vary in subject scope, with several journals publishing disproportionately high numbers of articles in certain sub-disciplines. our citation analsysis offers support for bj\u00f6rk & catani\u2019s suggestion that oamjs\u2019s citation distributions can be similar to those of traditional journals, while noting considerable variation in citation rates across the eleven titles. we conclude that while the oamj term is useful as a means of grouping journals which share a set of key characteristics, there is no such thing as a \u201ctypical\u201d mega-journal, and we suggest several areas for additional research that might help us better understand the current and future role of oamjs in scholarly communication.",
            "contribution_ids": [
                "R171248",
                "R171249"
            ]
        },
        {
            "instance_id": "EMPTYxR207042",
            "comparison_id": "EMPTY",
            "paper_id": "R207042",
            "text": "Summarizing Scientific Articles: Experiments with Relevance and Rhetorical Status in this article we propose a strategy for the summarization of scientific articles that concentrates on the rhetorical status of statements in an article: material for summaries is selected in such a way that summaries can highlight the new contribution of the source article and situate it with respect to earlier work. we provide a gold standard for summaries of this kind consisting of a substantial corpus of conference articles in computational linguistics annotated with human judgments of the rhetorical status and relevance of each sentence in the articles. we present several experiments measuring our judges' agreement on these annotations. we also present an algorithm that, on the basis of the annotated training material, selects content from unseen articles and classifies it into a fixed set of seven rhetorical categories. the output of this extraction and classification system can be viewed as a single-document summary in its own right; alternatively, it provides starting material for the generation of task-oriented and user-tailored summaries designed to give users an overview of a scientific field.",
            "contribution_ids": [
                "R207044"
            ]
        },
        {
            "instance_id": "EMPTYxR196832",
            "comparison_id": "EMPTY",
            "paper_id": "R196832",
            "text": "\u00ef\u00bb\u00bfFocus marking in Indian English this paper investigates the use of only and itself in indian english, drawing on data from the indian subcorpus of the international corpus of english (ice-india). in all varieties of english, only is used as an exclusive focus particle and itself as a reflexive pronoun and intensifier. indian english has developed an additional use for only and itself as presentational, i.e. non-contrastive focus markers. the paper investigates the syntactic and semantic contexts of itself and only in order to capture the two lexical items\u2019 functional extension in current indian english. one interesting finding concerns the distribution of the two forms within the corpus: itself is mainly found in written texts, while only is restricted to the spoken language. the paper further considers the origin and the likely future of this innovation in indian english: whereas it is quite clear that substrate influence is directly responsible for the innovative usage, the question whether this usage will also become accepted as part of an emerging indian english standard remains to be settled.",
            "contribution_ids": [
                "R196834"
            ]
        },
        {
            "instance_id": "EMPTYxR145104",
            "comparison_id": "EMPTY",
            "paper_id": "R145104",
            "text": "Syndromic Surveillance: Adapting Innovations to Developing Settings the tools and strategies of syndromic surveillance, say the authors, hold promise for improving public health security in developing countries.",
            "contribution_ids": [
                "R145106"
            ]
        },
        {
            "instance_id": "EMPTYxR142295",
            "comparison_id": "EMPTY",
            "paper_id": "R142295",
            "text": "Phase 1 Assessment of the Safety and Immunogenicity of an mRNA- Lipid Nanoparticle Vaccine Candidate Against SARS-CoV-2 in Human Volunteers abstract there is an urgent need for vaccines to counter the covid-19 pandemic due to infections with severe acute respiratory syndrome coronavirus (sars-cov-2). evidence from convalescent sera and preclinical studies has identified the viral spike (s) protein as a key antigenic target for protective immune responses. we have applied an mrna-based technology platform, rnactive \u00ae , to develop cvncov which contains sequence optimized mrna coding for a stabilized form of s protein encapsulated in lipid nanoparticles (lnp). following demonstration of protective immune responses against sars-cov-2 in animal models we performed a dose-escalation phase 1 study in healthy 18-60 year-old volunteers. this interim analysis shows that two doses of cvncov ranging from 2 \u03bcg to 12 \u03bcg per dose, administered 28 days apart were safe. no vaccine-related serious adverse events were reported. there were dose-dependent increases in frequency and severity of solicited systemic adverse events, and to a lesser extent of local reactions, but the majority were mild or moderate and transient in duration. immune responses when measured as igg antibodies against s protein or its receptor-binding domain (rbd) by elisa, and sars-cov-2-virus neutralizing antibodies measured by micro-neutralization, displayed dose-dependent increases. median titers measured in these assays two weeks after the second 12 \u03bcg dose were comparable to the median titers observed in convalescent sera from covid-19 patients. seroconversion (defined as a 4-fold increase over baseline titer) of virus neutralizing antibodies two weeks after the second vaccination occurred in all participants who received 12 \u03bcg doses. preliminary results in the subset of subjects who were enrolled with known sars-cov-2 seropositivity at baseline show that cvncov is also safe and well tolerated in this population, and is able to boost the pre-existing immune response even at low dose levels. based on these results, the 12 \u03bcg dose is selected for further clinical investigation, including a phase 2b/3 study that will investigate the efficacy, safety, and immunogenicity of the candidate vaccine cvncov.",
            "contribution_ids": [
                "R142296"
            ]
        },
        {
            "instance_id": "EMPTYxR171533",
            "comparison_id": "EMPTY",
            "paper_id": "R171533",
            "text": "Increase in suicides the months after the death of Robin Williams in the US investigating suicides following the death of robin williams, a beloved actor and comedian, on august 11th, 2014, we used time-series analysis to estimate the expected number of suicides during the months following williams\u2019 death. monthly suicide count data in the us (1999\u20132015) were from the centers for disease control and prevention wide-ranging online data for epidemiologic research (cdc wonder). expected suicides were calculated using a seasonal autoregressive integrated moving averages model to account for both the seasonal patterns and autoregression. time-series models indicated that we would expect 16,849 suicides from august to december 2014; however, we observed 18,690 suicides in that period, suggesting an excess of 1,841 cases (9.85% increase). although excess suicides were observed across gender and age groups, males and persons aged 30\u201344 had the greatest increase in excess suicide events. this study documents associations between robin williams\u2019 death and suicide deaths in the population thereafter.",
            "contribution_ids": [
                "R171534",
                "R171535"
            ]
        },
        {
            "instance_id": "EMPTYxR135836",
            "comparison_id": "EMPTY",
            "paper_id": "R135836",
            "text": "Making FAIR Easy with FAIR Tools: From Creolization to Convergence since their publication in 2016 we have seen a rapid adoption of the fair principles in many scientific disciplines where the inherent value of research data and, therefore, the importance of good data management and data stewardship, is recognized. this has led to many communities asking \u201cwhat is fair?\u201d and \u201chow fair are we currently?\u201d, questions which were addressed respectively by a publication revisiting the principles and the emergence of fair metrics. however, early adopters of the fair principles have already run into the next question: \u201chow can we become (more) fair?\u201d this question is more difficult to answer, as the principles do not prescribe any specific standard or implementation. moreover, there does not yet exist a mature ecosystem of tools, platforms and standards to support human and machine agents to manage, produce, publish and consume fair data in a user-friendly and efficient (i.e., \u201ceasy\u201d) way. in this paper we will show, however, that there are already many emerging examples of fair tools under development. this paper puts forward the position that we are likely already in a creolization phase where fair tools and technologies are merging and combining, before converging in a subsequent phase to solutions that make fair feasible in daily practice.",
            "contribution_ids": [
                "R135837"
            ]
        },
        {
            "instance_id": "EMPTYxR139698",
            "comparison_id": "EMPTY",
            "paper_id": "R139698",
            "text": "Accessibility, Natural User Interfaces and Interactions in Museums: The IntARSI Project in a museum context, people have specific needs in terms of physical, cognitive, and social accessibility that cannot be ignored. therefore, we need to find a way to make art and culture accessible to them through the aid of universal design principles, advanced technologies, and suitable interfaces and contents. integration of such factors is a priority of the museums general direction of the italian ministry of cultural heritage, within the wider strategy of museum exploitation. in accordance with this issue, the intarsi project, publicly funded, consists of a pre-evaluation and a report of technical specifications for a new concept of museology applied to the new museum of civilization in rome (muciv). it relates to planning of multimedia, virtual, and mixed reality applications based on the concept of \u201caugmented\u201d and multisensory experience, innovative tangible user interfaces, and storytelling techniques. an inclusive approach is applied, taking into account the needs and attitudes of a wide audience with different ages, cultural interests, skills, and expectations, as well as cognitive and physical abilities.",
            "contribution_ids": [
                "R139702"
            ]
        },
        {
            "instance_id": "EMPTYxR134920",
            "comparison_id": "EMPTY",
            "paper_id": "R134920",
            "text": "The Tsetlin Machine - A Game Theoretic Bandit Driven Approach to Optimal Pattern Recognition with Propositional Logic although simple individually, artificial neurons provide state-of-the-art performance when interconnected in deep networks. arguably, the tsetlin automaton is an even simpler and more versatile learning mechanism, capable of solving the multi-armed bandit problem. merely by means of a single integer as memory, it learns the optimal action in stochastic environments through increment and decrement operations. in this paper, we introduce the tsetlin machine, which solves complex pattern recognition problems with propositional formulas, composed by a collective of tsetlin automata. to eliminate the longstanding problem of vanishing signal-to-noise ratio, the tsetlin machine orchestrates the automata using a novel game. further, both inputs, patterns, and outputs are expressed as bits, while recognition and learning rely on bit manipulation, simplifying computation. our theoretical analysis establishes that the nash equilibria of the game align with the propositional formulas that provide optimal pattern recognition accuracy. this translates to learning without local optima, only global ones. in five benchmarks, the tsetlin machine provides competitive accuracy compared with svms, decision trees, random forests, naive bayes classifier, logistic regression, and neural networks. we further demonstrate how the propositional formulas facilitate interpretation. we believe the combination of high accuracy, interpretability, and computational simplicity makes the tsetlin machine a promising tool for a wide range of domains.",
            "contribution_ids": [
                "R134921"
            ]
        },
        {
            "instance_id": "EMPTYxR131069",
            "comparison_id": "EMPTY",
            "paper_id": "R131069",
            "text": "Improving Neural Language Models with a Continuous Cache we propose an extension to neural network language models to adapt their prediction to the recent history. our model is a simplified version of memory augmented networks, which stores past hidden activations as memory and accesses them through a dot product with the current hidden activation. this mechanism is very efficient and scales to very large memory sizes. we also draw a link between the use of external memory in neural network and cache models used with count based language models. we demonstrate on several language model datasets that our approach performs significantly better than recent memory augmented networks.",
            "contribution_ids": [
                "R131070",
                "R131073",
                "R131076",
                "R131079",
                "R131082"
            ]
        },
        {
            "instance_id": "EMPTYxR211091",
            "comparison_id": "EMPTY",
            "paper_id": "R211091",
            "text": "Generating Wikipedia by Summarizing Long Sequences we show that generating english wikipedia articles can be approached as a multi- document summarization of source documents. we use extractive summarization to coarsely identify salient information and a neural abstractive model to generate the article. for the abstractive model, we introduce a decoder-only architecture that can scalably attend to very long sequences, much longer than typical encoder- decoder architectures used in sequence transduction. we show that this model can generate fluent, coherent multi-sentence paragraphs and even whole wikipedia articles. when given reference documents, we show it can extract relevant factual information as reflected in perplexity, rouge scores and human evaluations.",
            "contribution_ids": [
                "R211093"
            ]
        },
        {
            "instance_id": "EMPTYxR209873",
            "comparison_id": "EMPTY",
            "paper_id": "R209873",
            "text": "Improved cell composition deconvolution method of bulk gene expression profiles to quantify subsets of immune cells abstract background to facilitate the investigation of the pathogenic roles played by various immune cells in complex tissues such as tumors, a few computational methods for deconvoluting bulk gene expression profiles to predict cell composition have been created. however, available methods were usually developed along with a set of reference gene expression profiles consisting of imbalanced replicates across different cell types. therefore, the objective of this study was to create a new deconvolution method equipped with a new set of reference gene expression profiles that incorporate more microarray replicates of the immune cells that have been frequently implicated in the poor prognosis of cancers, such as t helper cells, regulatory t cells and macrophage m1/m2 cells. methods our deconvolution method was developed by choosing \u03b5-support vector regression (\u03b5-svr) as the core algorithm assigned with a loss function subject to the l1 -norm penalty. to construct the reference gene expression signature matrix for regression, a subset of differentially expressed genes were chosen from 148 microarray-based gene expression profiles for 9 types of immune cells by using anova and minimizing condition number. agreement analyses including mean absolute percentage errors and bland-altman plots were carried out to compare the performances of our method and cibersort. results in silico cell mixtures, simulated bulk tissues, and real human samples with known immune-cell fractions were used as the test datasets for benchmarking. our method outperformed cibersort in the benchmarks using in silico breast tissue-immune cell mixtures in the proportions of 30:70 and 50:50, and in the benchmark using 164 human pbmc samples. our results suggest that the performance of our method was at least comparable to that of a state-of-the-art tool, cibersort. conclusions we developed a new cell composition deconvolution method and the implementation was entirely based on the publicly available r and python packages. in addition, we compiled a new set of reference gene expression profiles, which might allow for a more robust prediction of the immune cell fractions from the expression profiles of cell mixtures. the source code of our method could be downloaded from https://github.com/holiday01/deconvolution-to-estimate-immune-cell-subsets .",
            "contribution_ids": [
                "R209876"
            ]
        },
        {
            "instance_id": "EMPTYxR12048",
            "comparison_id": "EMPTY",
            "paper_id": "R12048",
            "text": "Adaptive context formation for linear prediction of image data images are typically non-stationary signals. if prediction is applied in a linear fashion, it must be combined with a technique which takes this characteristic into account. in general, images can be either regarded as piecewise two-dimensional autoregressive processes or they are handled in a block-wise manner. this paper presents a novel prediction technique, which treats the image data as an interleaved sequence generated by multiple sources. the challenge is to de-interleave the sequence and to compute prediction weights for each sub-source separately. the proposed approach adaptively determines the sub-sources based on the textures within the images. the prediction method is incorporated in a framework for lossless image compression. it is based on least-mean-square filtering and achieves prediction-error entropies, which are comparable to those of least-squares approaches. in combination with a dedicated coding algorithm, the proposed approach shows a competitive compression performance for a wide range of different natural images.",
            "contribution_ids": [
                "R12050",
                "R12051"
            ]
        },
        {
            "instance_id": "EMPTYxR134227",
            "comparison_id": "EMPTY",
            "paper_id": "R134227",
            "text": "Rainbow: Combining Improvements in Deep Reinforcement Learning \\n \\n the deep reinforcement learning community has made several independent improvements to the dqn algorithm. however, it is unclear which of these extensions are complementary and can be fruitfully combined. this paper examines six extensions to the dqn algorithm and empirically studies their combination. our experiments show that the combination provides state-of-the-art performance on the atari 2600 benchmark, both in terms of data efficiency and final performance. we also provide results from a detailed ablation study that shows the contribution of each component to overall performance.\\n \\n",
            "contribution_ids": [
                "R134228",
                "R134231"
            ]
        },
        {
            "instance_id": "EMPTYxR196692",
            "comparison_id": "EMPTY",
            "paper_id": "R196692",
            "text": "Modeling Soil Organic Carbon at Regional Scale by Combining Multi-Spectral Images with Laboratory Spectra there is a great challenge in combining soil proximal spectra and remote sensing spectra to improve the accuracy of soil organic carbon (soc) models. this is primarily because mixing of spectral data from different sources and technologies to improve soil models is still in its infancy. the first objective of this study was to integrate information of soc derived from visible near-infrared reflectance (vis-nir) spectra in the laboratory with remote sensing (rs) images to improve predictions of topsoil soc in the skjern river catchment, denmark. the second objective was to improve soc prediction results by separately modeling uplands and wetlands. a total of 328 topsoil samples were collected and analyzed for soc. satellite pour l\u2019observation de la terre (spot5), landsat data continuity mission (landsat 8) images, laboratory vis-nir and other ancillary environmental data including terrain parameters and soil maps were compiled to predict topsoil soc using cubist regression and bayesian kriging. the results showed that the model developed from rs data, ancillary environmental data and laboratory spectral data yielded a lower root mean square error (rmse) (2.8%) and higher r2 (0.59) than the model developed from only rs data and ancillary environmental data (rmse: 3.6%, r2: 0.46). plant-available water (paw) was the most important predictor for all the models because of its close relationship with soil organic matter content. moreover, vegetation indices, such as the normalized difference vegetation index (ndvi) and enhanced vegetation index (evi), were very important predictors in soc spatial models. furthermore, the \u2018upland model\u2019 was able to more accurately predict soc compared with the \u2018upland & wetland model\u2019. however, the separately calibrated \u2018upland and wetland model\u2019 did not improve the prediction accuracy for wetland sites, since it was not possible to adequately discriminate the vegetation in the rs summer images. we conclude that laboratory vis-nir spectroscopy adds critical information that significantly improves the prediction accuracy of soc compared to using rs data alone. we recommend the incorporation of laboratory spectra with rs data and other environmental data to improve soil spatial modeling and digital soil mapping (dsm).",
            "contribution_ids": [
                "R196693"
            ]
        },
        {
            "instance_id": "EMPTYxR169419",
            "comparison_id": "EMPTY",
            "paper_id": "R169419",
            "text": "The Association of 5-HT2A, 5-HTT, and LEPR Polymorphisms with Obstructive Sleep Apnea Syndrome: A Systematic Review and Meta-Analysis objective a consensus has not been reached regarding the association of several different gene polymorphisms and susceptibility to obstructive sleep apnea syndrome (osas). we performed a meta-analysis to better evaluate the associations between 5-ht2a, 5-htt, and lepr polymorphisms, and osas. method 5-ht2a, 5-htt, and lepr polymorphisms and osas were identified in pubmed and embase. the pooled odd rates (ors) with 95%cis were estimated using a fixed-effect or random-effect models. the associations between these polymorphisms and osas risk were assessed using dominant, recessive and additive models. results twelve publications were included in this study. the -1438 \u201ca\u201d allele of 5-ht2a was identified as a candidate genetic risk factor for osas (or: 2.33, 95%ci 1.49\u20133.66). individuals carrying the -1438 \u201cg\u201d allele had a nearly 70% reduced risk of osas when compared with aa homozygotes (or: 0.30, 95%ci 0.23\u20130.40). there was no significant association between 5-ht2a 102c/t and osas risk, using any model. the \u201cs\u201d allele of 5-httlpr conferred protection against osas (or: 0.80, 95%ci 0.67\u20130.95), while the \u201c10\u201d allele of 5-httvntr contributed to the risk of osas (or: 2.08, 95%ci: 1.58\u20132.73). the \u201cgg\u201d genotype of lepr was associated with a reduced risk of osas (or: 0.39, 95%ci 0.17\u20130.88). conclusion the meta-analysis demonstrated that 5-htr-1438 \u201ca\u201d and 5-httvntr \u201c10\u201d alleles were significantly associated with osas. the \u201cs\u201d allele of 5-httlpr and the \u201cgg\u201d genotype of lepr conferred protection against osas. further studies, such as genome-wide association study (gwas), should be conducted in a large cohort of osas patients to confirm our findings.",
            "contribution_ids": [
                "R169420"
            ]
        },
        {
            "instance_id": "EMPTYxR111355",
            "comparison_id": "EMPTY",
            "paper_id": "R111355",
            "text": "Distribution, phenology and demography of sympatric sexual and asexual dandelions (Taraxacum officinale s.l.): geographic parthenogenesis on a small scale: GEOGRAPHIC PARTHENOGENESIS IN DANDELIONS \"in many plant and animal species, sexual and asexual forms have different geographical distributions ('geographic parthenogenesis'). the common dandelion taraxacum officinale s.l. provides a particularly clear example of differing distributions: diploid sexuals are restricted to southern and central europe, while triploid asexuals occur across europe. to get a better understanding of the factors underlying this pattern, we studied the distribution and demography of sexuals and asexuals in a mixed population that was located at the northern distribution limit of the sexuals. in this population three adjacent, contrasting microhabitats were found: a foreland and south and north slopes of a river dike. comparative analyses of the distribution, phenology and demography indicated that sexuals had a stronger preference for the south slope than did asexuals. we therefore propose that the large-scale geographic parthenogenesis in t. officinale is shaped by an environmental gradient which acts upon the sexuals. [keywords: agamospermy; apomixis; flowering; microhabitat; polyploidy; triploidy]\"",
            "contribution_ids": [
                "R111357"
            ]
        },
        {
            "instance_id": "EMPTYxR169262",
            "comparison_id": "EMPTY",
            "paper_id": "R169262",
            "text": "Independent and Combined Effects of Physical Activity and Sedentary Behavior on Blood Pressure in Adolescents: Gender Differences in Two Cross-Sectional Studies objectives to examine the independent and combined association of physical activity (pa) and sedentary behavior (sb) on both systolic (sbp) and diastolic blood pressure (dbp) in adolescents from two observational studies. methods participants from two cross-sectional studies, one conducted in europe (n\\u200a=\\u200a3,308; helena study) and the other in brazil (n\\u200a=\\u200a991; bracah study), were selected by complex sampling. systolic and diastolic blood pressure (outcomes), pa and sb, both independently and combined, and potential confounders were analyzed. associations were examined by multilevel linear regression. results performing the recommended amount of pa (\u226560 min/d) attenuated the effect of sb on dbp in bracah study girls and in boys from both studies. in contrast, pa did not attenuate the effects of sb on the sbp of girls in the helena study. the combination of less than recommended levels of pa with 2\u20134 h/d of sedentary behavior was found to be associated with increased sbp in boys from both studies. conclusions meeting current pa recommendations could mediate the association between sb and dbp in both sexes. in boys, the joint effect of low levels of pa and excessive sedentary activity increases sbp levels. longitudinal studies are required to confirm these findings.",
            "contribution_ids": [
                "R169263"
            ]
        },
        {
            "instance_id": "EMPTYxR212197",
            "comparison_id": "EMPTY",
            "paper_id": "R212197",
            "text": "Designing a multi-echelon closed-loop supply chain with disruption in the distribution centers under uncertainty &lt;p style='text-indent:20px;'&gt;according to the need for further cost reduction and improving the process of the organization in the direction of customer demand, the concept of the supply chain has become increasingly significant and the organizations seek to expand this concept within their organizational framework. in this regard, efficient planning of distribution of products in the supply chain by considering disruption has received more attention recently. in this study a multi-objective mixed-integer linear programming model is developed for a green multi-echelon closed-loop supply chain network design under uncertainty. moreover, a partial disruption is considered for distribution centers where has not been studied enough in previous works. the fuzzy credibility constraint approach is applied to cover uncertainty. in the following, the \u03b5-constraint method is presented to solve and validate the model in small-sized instances. moreover, a non-dominated sorting genetic algorithm is developed for solving the large-sized problems. results show that uncertainty has a crucial impact on objective functions where the increase of objective functions by increasing the level of uncertainty, which was observed in all categories. furthermore, the proposed nsga-\u2171 is the best tool to deal with large-size problems where the ec method lacks the necessary efficiency.&lt;/p&gt;",
            "contribution_ids": [
                "R212199"
            ]
        },
        {
            "instance_id": "EMPTYxR169502",
            "comparison_id": "EMPTY",
            "paper_id": "R169502",
            "text": "Implementing Direct Access to Low-Dose Computed Tomography in General Practice\u00e2\u0080\u0094Method, Adaption and Outcome background early detection of lung cancer is crucial as the prognosis depends on the disease stage. chest radiographs has been the principal diagnostic tool for general practitioners (gps), but implies a potential risk of false negative results, while computed tomography (ct) has a higher sensitivity. the aim of this study was to describe the implementation of direct access to low-dose ct (ldct) from general practice. methods we conducted a cohort study nested in a randomised study. a total of 119 general practices with 266 gps were randomised into two groups. intervention gps were offered direct access to chest ldct combined with a continuing medical education (cme) meeting on lung cancer diagnosis. results during a 19-month period, 648 patients were referred to ldct (0.18/1000 adults on gp list/month). half of the patients needed further diagnostic work-up, and 15 (2.3%, 95% ci: 1.3\u20133.8%) of the patients had lung cancer; 60% (95% ci: 32.3\u201383.7%) in a localised stage. the gp referral rate was 61% higher for cme participants compared to non-participants. conclusion of all patients referred to ldct, 2.3% were diagnosed with lung cancer with a favourable stage distribution. half of the referred patients needed additional diagnostic work-up. there was an association between participation in cme and use of ct scan. the proportion of cancers diagnosed through the usual fast-track evaluation was 2.2 times higher in the group of cme-participating gps. the question remains if primary care case-finding with ldct is a better option for patients having signs and symptoms indicating lung cancer than a screening program. whether open access to ldct may provide earlier diagnosis of lung cancer is yet unknown and a randomised trial is required to assess any effect on outcome. trial registration clinicaltrials.gov nct01527214",
            "contribution_ids": [
                "R169503",
                "R169504"
            ]
        },
        {
            "instance_id": "EMPTYxR138423",
            "comparison_id": "EMPTY",
            "paper_id": "R138423",
            "text": "Oxidative Depolymerization of Lignin in Ionic Liquids beech lignin was oxidatively cleaved in ionic liquids to give phenols, unsaturated propylaromatics, and aromatic aldehydes. a multiparallel batch reactor system was used to screen different ionic liquids and metal catalysts. mn(no(3))(2) in 1-ethyl-3-methylimidazolium trifluoromethanesulfonate [emim][cf(3)so(3)] proved to be the most effective reaction system. a larger scale batch reaction with this system in a 300 ml autoclave (11 g lignin starting material) resulted in a maximum conversion of 66.3 % (24 h at 100 degrees c, 84x10(5) pa air). by adjusting the reaction conditions and catalyst loading, the selectivity of the process could be shifted from syringaldehyde as the predominant product to 2,6-dimethoxy-1,4-benzoquinone (dmbq). surprisingly, the latter could be isolated as a pure substance in 11.5 wt % overall yield by a simple extraction/crystallization process.",
            "contribution_ids": [
                "R138425"
            ]
        },
        {
            "instance_id": "EMPTYxR50150",
            "comparison_id": "EMPTY",
            "paper_id": "R50150",
            "text": "Global survey of star clusters in the Milky Way: I. The pipeline and fundamental parameters in the second quadrant\u00e2\u008b\u0086\u00e2\u008b\u0086\u00e2\u008b\u0086 aims. on the basis of the ppmxl star catalogue we performed a survey of star clusters in the second quadrant of the milky way. methods. from the ppmxl catalogue of positions and proper motions we took the subset of stars with near-infrared photometry from 2mass and added the remaining 2mass stars without proper motions (called 2mast, i.e. 2mass with astrometry). we developed a data-processing pipeline including interactive human control of a standardised set of multi-dimensional diagrams to determine kinematic and photometric membership probabilities for stars in a cluster region. the pipeline simultaneously produced the astrophysical parameters of a cluster. from literature we compiled a target list of presently known open and globular clusters, cluster candidates, associations, and moving groups. from established member stars we derived spatial parameters (coordinates of centres and radii of the main morphological parts of clusters) and cluster kinematics (average proper motions and sometimes radial velocities). for distance, reddening, and age determination we used specific sets of theoretical isochrones. tidal parameters were obtained by a fit of three-parameter king profiles to the observed density distributions of members. results. we investigated all 871 objects in the 2nd galactic quadrant, of which we successfully treated 642 open clusters, 2 globular clusters, and 8 stellar associations. the remaining 219 objects (24%) were recognised by us to be nonexistent clusters, duplicate entries, or clusters too faint for 2mast. we found that our sample is complete in the 2nd quadrant up to a distance of 2 kpc, where the average surface density is 94 clusters per kpc 2 . compared with literature values we found good agreement in spatial and kinematic data, as well as for optical distances and reddening. small, but systematic offsets were detected in the age determination.",
            "contribution_ids": [
                "R50152"
            ]
        },
        {
            "instance_id": "EMPTYxR170080",
            "comparison_id": "EMPTY",
            "paper_id": "R170080",
            "text": "Visualizing the intercity correlation of PM2.5 time series in the Beijing-Tianjin-Hebei region using ground-based air quality monitoring data the beijing-tianjin-hebei area faces a severe fine particulate matter (pm2.5) problem. to date, considerable progress has been made toward understanding the pm2.5 problem, including spatial-temporal characterization, driving factors, and health effects. however, little research has been done on the dynamic interactions and relationships between pm2.5 concentrations in different cities in this area. to address the research gap, this study discovered a phenomenon of time-lagged intercity correlations of pm2.5 time series and proposed a visualization framework based on this phenomenon to visualize the interaction in pm2.5 concentrations between cities. the visualizations produced using the framework show that there are significant time-lagged correlations between the pm2.5 time series in different cities in this area. the visualizations also show that the correlations are more significant in colder months and between cities that are closer, and that there are seasonal changes in the temporal order of the correlated pm2.5 time series. further analysis suggests that the time-lagged intercity correlations of pm2.5 time series are most likely due to synoptic meteorological variations. we argue that the visualizations demonstrate the interactions of air pollution between cities in the beijing-tianjin-hebei area and the significant effect of synoptic meteorological conditions on pm2.5 pollution. the visualization framework could help determine the pathway of regional transportation of air pollution and may also be useful in delineating the area of interaction of pm2.5 pollution for impact analysis.",
            "contribution_ids": [
                "R170081",
                "R170082",
                "R170083",
                "R170084"
            ]
        },
        {
            "instance_id": "EMPTYxR170244",
            "comparison_id": "EMPTY",
            "paper_id": "R170244",
            "text": "Socioeconomic status and 30-day mortality after minor and major trauma: A retrospective analysis of the Trauma Audit and Research Network (TARN) dataset for England introduction socioeconomic status (ses) is associated with rate and severity of trauma. however, it is unclear whether there is an independent association between ses and mortality after injury. our aim was to assess the relationship between ses and mortality from trauma. materials and methods we conducted a secondary analysis of the trauma audit and research network dataset. participants were patients admitted to nhs hospitals for trauma between january 2015 and december 2015, and resident in england. analyses used multivariate logistic regression with thirty-day mortality as the main outcome. co-variates include ses derived from area-level deprivation, age, injury severity and comorbidity. all analyses were stratified into minor and major trauma. results there were 48,652 admissions (68% for minor injury, iss<15) included, and 3,792 deaths. thirty-day mortality was 10% for patients over 85 with minor trauma, which was higher than major trauma for all age groups under 65. deprivation was not significantly associated with major trauma mortality. for minor trauma, patients older than 40 had significantly higher aors than the 0\u201315 age group. both the most and second most deprived had significantly higher aors (1.35 and 1.28 respectively). conclusions this study provides evidence of an independent relationship between ses and mortality after minor trauma, but not for major trauma. our results identify that, for less severe trauma, older patients and patients with low ses with have an increased risk of 30-day mortality. policy makers and service providers should consider extending the provision of \u2018major trauma\u2019 healthcare delivery to this at-risk population.",
            "contribution_ids": [
                "R170245"
            ]
        },
        {
            "instance_id": "EMPTYxR169123",
            "comparison_id": "EMPTY",
            "paper_id": "R169123",
            "text": "Central Projection of Pain Arising from Delayed Onset Muscle Soreness (DOMS) in Human Subjects delayed onset muscle soreness (doms) is a subacute pain state arising 24\u201348 hours after a bout of unaccustomed eccentric muscle contractions. functional magnetic resonance imaging (fmri) was used to examine the patterns of cortical activation arising during doms-related pain in the quadriceps muscle of healthy volunteers evoked by either voluntary contraction or physical stimulation. the painful movement or physical stimulation of the doms-affected thigh disclosed widespread activation in the primary somatosensory and motor (s1, m1) cortices, stretching far beyond the corresponding areas somatotopically related to contraction or physical stimulation of the thigh; activation also included a large area within the cingulate cortex encompassing posteroanterior regions and the cingulate motor area. pain-related activations were also found in premotor (m2) areas, bilateral in the insular cortex and the thalamic nuclei. in contrast, movement of a doms-affected limb led also to activation in the ipsilateral anterior cerebellum, while doms-related pain evoked by physical stimulation devoid of limb movement did not.",
            "contribution_ids": [
                "R169124",
                "R169125"
            ]
        },
        {
            "instance_id": "EMPTYxR170932",
            "comparison_id": "EMPTY",
            "paper_id": "R170932",
            "text": "Health-Related Quality of Life of Latin-American Immigrants and Spanish-Born Attended in Spanish Primary Health Care: Socio-Demographic and Psychosocial Factors background this study compares the health-related quality of life of spanish-born and latin american-born individuals settled in spain. socio-demographic and psychosocial factors associated with health-related quality of life are analyzed. methods a cross-sectional primary health care multi center-based study of latin american-born (n = 691) and spanish-born (n = 903) outpatients from 15 primary health care centers (madrid, spain). the medical outcomes study 36-item short form health survey (sf-36) was used to assess health-related quality of life. socio-demographic, psychosocial, and specific migration data were also collected. results compared to spanish-born participants, latin american-born participants reported higher health-related quality of life in the physical functioning and vitality dimensions. across the entire sample, latin american-born participants, younger participants, men and those with high social support reported significantly higher levels of physical health. men with higher social support and a higher income reported significantly higher mental health. when stratified by gender, data show that for men physical health was only positively associated with younger age. for women, in addition to age, social support and marital status were significantly related. both men and women with higher social support and income had significantly better mental health. finally, for immigrants, the physical and mental health components of health-related quality of life were not found to be significantly associated with any of the pre-migration factors or conditions of migration. only the variable \u201cexposure to political violence\u201d was significantly associated with the mental health component (p = 0.014). conclusions the key factors to understanding hrqol among latin american-born immigrants settled in spain are age, sex and social support. therefore, strategies to maintain optimal health outcomes in these immigrant communities should include public policies on social inclusion in the host society and focus on improving social support networks in order to foster and maintain the health and hrqol of this group.",
            "contribution_ids": [
                "R170933",
                "R170934"
            ]
        },
        {
            "instance_id": "EMPTYxR74422",
            "comparison_id": "EMPTY",
            "paper_id": "R74422",
            "text": "Integrating OER in the design of educational material: Blended learning and linked-open-educational-resources-data approach teaching and learning takes place in (or in a combination of) different educational environments: classroom, online, or mobile. blended learning, or hybrid learning, is a formal educational program that integrates face-to-face learning with technology-based, digital instruction. on the other hand, open educational resources (oer) provides a strategic opportunity to improve the quality of education as well as facilitate policy dialog, knowledge sharing, and capacity building. oers are actual resources/tools that can help enrich any classroom environment and push student thinking and comprehension. one of the fundamental concepts of oer is \"the ability to freely adapt and reuse existing pieces of knowledge\", and therefore be a way to create more economic and personalized learning. the oer movement has challenged the traditional value chain by employing new methods to deliver high-quality educational content. the purpose of this work is to show a way to enhance the face-to-face classrooms with integration of oers, and thus create blended learning instruction. reuse of oers by both individuals and organizations may have significant creative and economic benefit for learning environments. the approach is based on linked data for describe and publish oer. in this new paradigm for educational content consumption and integration, oer are expected to play a decisive and productive role for blended learning. the approach presented can be used to support different blended-learning models.",
            "contribution_ids": [
                "R74423",
                "R109079"
            ]
        },
        {
            "instance_id": "EMPTYxR170002",
            "comparison_id": "EMPTY",
            "paper_id": "R170002",
            "text": "The current status of syphilis prevention and control in Jiangsu province, China: A cross-sectional study objective to analyze the midterm evaluation data from the national syphilis prevention and control plan (2010\u20132020) and evaluate the current status of syphilis prevention and control in jiangsu province, china. methods we collected data via (1) field surveys conducted in 2015 and (2) data recorded in existing syphilis surveillance systems. we conducted descriptive statistical analysis to evaluate the current landscape of syphilis control initiatives and their potential effect in syphilis control. results the incidence of all cases of syphilis decreased from 2010 (32.3 per 100,000) to 2015 (30.1 per 100,000), with an annual growth of -1.17% (x2trend = -7.52, p<0.001) in jiangsu province. the incidence of primary and secondary syphilis and congenital syphilis both decreased significantly from 2010 to 2015. the average awareness rate of syphilis knowledge among professional personnel was 95.4% (3781/3963). rural residents had the lowest awareness rate (83.5%, 1875/2245) and commercial sex workers had the highest awareness rate (92.1%, 7804/8474) in 2015. only 47.8% (33908/70894) of patients received provider-initiated syphilis counseling and testing (pistc) services in sexually transmitted disease (std) clinics, but 94.5% (87927/93020) of all syphilis patients received free testing for syphilis. overall, 97.2% (9378/9648) of syphilis reported cases of syphilis at medical institutions were confirmed to be accurate, and 92.2% (5850/6345) of patients diagnosed with syphilis at medical institutions received treatment with penicillin. conclusion the syphilis incidence rate in jiangsu has decreased in recent years, but remains at a high level. it is essential to promote pistc services to improve knowledge of syphilis and rates of testing and treatment in jiangsu province.",
            "contribution_ids": [
                "R170003",
                "R170004"
            ]
        },
        {
            "instance_id": "EMPTYxR196520",
            "comparison_id": "EMPTY",
            "paper_id": "R196520",
            "text": "LIORI at SemEval-2021 Task 2: Span Prediction and Binary Classification approaches to Word-in-Context Disambiguation this paper presents our approaches to semeval-2021 task 2: multilingual and cross-lingual word-in-context disambiguation task. the first approach attempted to reformulate the task as a question answering problem, while the second one framed it as a binary classification problem. our best system, which is an ensemble of xlm-r based binary classifiers trained with data augmentation, is among the 3 best-performing systems for russian, french and arabic in the multilingual subtask. in the post-evaluation period, we experimented with batch normalization, subword pooling and target word occurrence aggregation methods, resulting in further performance improvements.",
            "contribution_ids": [
                "R196522"
            ]
        },
        {
            "instance_id": "EMPTYxR207059",
            "comparison_id": "EMPTY",
            "paper_id": "R207059",
            "text": "Identifying Sections in Scientific Abstracts using Conditional Random Fields objective: the prior knowledge about the rhetorical structure of scientific abstracts is useful for various text-mining tasks such as information extraction, information retrieval, and automatic summarization. this paper presents a novel approach to categorize sentences in scientific abstracts into four sections, objective, methods, results, and conclusions. method: formalizing the categorization task as a sequential labeling problem, we employ conditional random fields (crfs) to annotate section labels into abstract sentences. the training corpus is acquired automatically from medline abstracts. results: the proposed method outperformed the previous approaches, achieving 95.5% per-sentence accuracy and 68.8% per-abstract accuracy. conclusion: the experimental results showed that crfs could model the rhetorical structure of abstracts more suitably.",
            "contribution_ids": [
                "R207063"
            ]
        },
        {
            "instance_id": "EMPTYxR70291",
            "comparison_id": "EMPTY",
            "paper_id": "R70291",
            "text": "Development of a low-cost, user-customizable, high-speed camera high-speed imaging equipment can be an expensive investment, especially when certain applications require custom solutions. in this paper, we present a low-cost high-speed prototype camera built on a low-end zynq-7000 system-on-chip (soc) platform and off-the-shelf components with the aim of removing the entry barrier into various high-speed imaging applications. the camera is standalone (does not require a host computer) and can achieve 211 frames per second (fps) at its maximum resolution of 1280x1024, and up to 2329 fps at a 256x256 resolution. with a current cost of only several hundred dollars and resource utilization of ~5%, the open-source design\u2019s modularity and customizability allows users with sufficient hardware or programming experience to modify the camera to suit their needs, potentially driving the cost lower. this can be done by utilizing the large remaining programmable logic for custom image processing algorithms, creating user interface software on the cpu, attaching extensions through the peripheral module connections, or creating custom carrier or daughter boards. the development and design of the camera is described and a figure-of-merit is presented to provide a value assessment of some available commercial high-speed cameras against which our camera is competitive. finally, the camera was tested to record low frequency spatial vibration and was found to be useful in investigating phenotypes associated with aging in a leading animal model, the nematode (worm) caenorhabditis elegans.",
            "contribution_ids": [
                "R70295"
            ]
        },
        {
            "instance_id": "EMPTYxR133937",
            "comparison_id": "EMPTY",
            "paper_id": "R133937",
            "text": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning we explore the use of evolution strategies (es), a class of black box optimization algorithms, as an alternative to popular mdp-based rl techniques such as q-learning and policy gradients. experiments on mujoco and atari show that es is a viable solution strategy that scales extremely well with the number of cpus available: by using a novel communication strategy based on common random numbers, our es implementation only needs to communicate scalars, making it possible to scale to over a thousand parallel workers. this allows us to solve 3d humanoid walking in 10 minutes and obtain competitive results on most atari games after one hour of training. in addition, we highlight several advantages of es as a black box optimization technique: it is invariant to action frequency and delayed rewards, tolerant of extremely long horizons, and does not need temporal discounting or value function approximation.",
            "contribution_ids": [
                "R133938"
            ]
        },
        {
            "instance_id": "EMPTYxR205057",
            "comparison_id": "EMPTY",
            "paper_id": "R205057",
            "text": "A Human-in-the-Loop Approach for Personal Knowledge Graph Construction from File Names users\u2019 personal and work related concepts (e.g. persons, projects, topics) are usually not sufficiently covered by knowledge graphs. yet, already handmade classification schemes, prominently folder structures, naturally mention several of their concepts in file names. thus, such data could be a promising source for constructing personal knowledge graphs. however, this idea poses several challenges: file names are usually noisy non-grammatical text snippets, while folder structures do not clearly define how concepts relate to each other. to cope with this semantic gap, we include knowledge workers as humans-in-the-loop to guide the building process with their feedback. our semi-automatic personal knowledge graph construction approach consists of four major stages: domain term extraction, ontology population, taxonomic and non-taxonomic relation learning. we conduct a case study with four expert interviews from different domains in an industrial scenario. results indicate that file systems are promising sources and, combined with our approach, already yield useful personal knowledge graphs with moderate effort spent.",
            "contribution_ids": [
                "R205059"
            ]
        },
        {
            "instance_id": "EMPTYxR171513",
            "comparison_id": "EMPTY",
            "paper_id": "R171513",
            "text": "The effect of relaxation techniques on edema, anxiety and depression in post-mastectomy lymphedema patients undergoing comprehensive decongestive therapy: A clinical trial objectives lymphedema is sometimes accompanied by high degrees of anxiety and depression. this study aimed to assess the effects of relaxation techniques on the level of edema, anxiety and depression in women undergoing comprehensive decongestive therapy (cdt). design this clinical trial compared two treatment methods in 31 women with post-mastectomy lymphedema, including 15 cases who received cdt and 16 who received rcdt (relaxation plus cdt). the edema volume, anxiety and depression scores were compared at the first and last sessions of the first phase of the treatment and six weeks afterwards. results the edema, anxiety and depression scores were 63.6%, 54.1% and 65.5% in the rcdt group and 60.7%, 31.4% and 35.2% in the cdt group. there were significant differences between the two groups in terms of the reduction in depression (p = 0.024) and anxiety (p = 0.011) scores throughout the study. this significant relationship was due to the differences in the depression score in the 3rd and 9th weeks of the study between the two groups. similarly, anxiety levels differed significantly between the two groups at the 9th week of the study (p = 0.013). conclusion relaxation techniques reduced the anxiety and depression scores and the volume of edema in the patients with lymphedema. the addition of this intervention to the therapeutic package for lymphedema patients requires further studies in terms of cost-effectiveness.",
            "contribution_ids": [
                "R171514",
                "R171515"
            ]
        },
        {
            "instance_id": "EMPTYxR108304",
            "comparison_id": "EMPTY",
            "paper_id": "R108304",
            "text": "CATS: Characterizing automation of Twitter spammers twitter, with its rising popularity as a micro-blogging website, has inevitably attracted the attention of spammers. spammers use myriad of techniques to evade security mechanisms and post spam messages, which are either unwelcome advertisements for the victim or lure victims in to clicking malicious urls embedded in spam tweets. in this paper, we propose several novel features capable of distinguishing spam accounts from legitimate accounts. the features analyze the behavioral and content entropy, bait-techniques, and profile vectors characterizing spammers, which are then fed into supervised learning algorithms to generate models for our tool, cats. using our system on two real-world twitter data sets, we observe a 96% detection rate with about 0.8% false positive rate beating state of the art detection approach. our analysis reveals detection of more than 90% of spammers with less than five tweets and about half of the spammers detected with only a single tweet. our feature computation has low latency and resource requirement making fast detection feasible. additionally, we cluster the unknown spammers to identify and understand the prevalent spam campaigns on twitter.",
            "contribution_ids": [
                "R108306"
            ]
        },
        {
            "instance_id": "EMPTYxR194281",
            "comparison_id": "EMPTY",
            "paper_id": "R194281",
            "text": "Learning Requirements Elicitation Interviews with Role-Playing, Self-Assessment and Peer-Review interviews are largely used in the practice of requirements elicitation. nevertheless, performing an effective interview often depends on soft-skills, and on knowledge acquired through experience. when it comes to requirements engineering education and training (reet), limited resources and few well-founded pedagogical approaches are available to allow students to acquire and improve their skills as interviewers. this paper presents a novel pedagogical approach that combines role-playing, peer-review and self-assessment to enable students to reflect on their mistakes, and improve their interview skills. we evaluate the approach through a controlled quasi-experiment. the study shows that the approach significantly reduces the amount of mistakes made by the students. feedback from the participants confirms the usefulness and easiness of the proposed training. this work contributes to the body of knowledge of reet with an empirically evaluated method for teaching inter-views. furthermore, we share the pedagogical material used, to enable other educators to apply and possibly tailor the approach.",
            "contribution_ids": [
                "R194283"
            ]
        },
        {
            "instance_id": "EMPTYxR168667",
            "comparison_id": "EMPTY",
            "paper_id": "R168667",
            "text": "FIMTrack: An open source tracking and locomotion analysis software for small animals imaging and analyzing the locomotion behavior of small animals such as drosophila larvae or c. elegans worms has become an integral subject of biological research. in the past we have introduced fim, a novel imaging system feasible to extract high contrast images. this system in combination with the associated tracking software fimtrack is already used by many groups all over the world. however, so far there has not been an in-depth discussion of the technical aspects. here we elaborate on the implementation details of fimtrack and give an in-depth explanation of the used algorithms. among others, the software offers several tracking strategies to cover a wide range of different model organisms, locomotion types, and camera properties. furthermore, the software facilitates stimuli-based analysis in combination with built-in manual tracking and correction functionalities. all features are integrated in an easy-to-use graphical user interface. to demonstrate the potential of fimtrack we provide an evaluation of its accuracy using manually labeled data. the source code is available under the gnu gplv3 at https://github.com/i-git/fimtrack and pre-compiled binaries for windows and mac are available at http://fim.uni-muenster.de.",
            "contribution_ids": [
                "R168668",
                "R168669",
                "R168670",
                "R168671",
                "R168672"
            ]
        },
        {
            "instance_id": "EMPTYxR146812",
            "comparison_id": "EMPTY",
            "paper_id": "R146812",
            "text": "\u00cf\u0080-Bridge-Independent 2-(Benzo[c][1,2,5]thiadiazol-4-ylmethylene)malononitrile-Substituted Nonfullerene Acceptors for Efficient Bulk Heterojunction Solar Cells molecular acceptors are promising alternatives to fullerenes (e.g., pc61/71bm) in the fabrication of high-efficiency bulk-heterojunction (bhj) solar cells. while solution-processed polymer\u2013fullerene bhj devices have recently met the 10% efficiency threshold, molecular acceptors have yet to prove comparably efficient with polymer donors. at this point in time, it is important to forge a better understanding of the design parameters that directly impact small-molecule (sm) acceptor performance in bhj solar cells. in this report, we show that 2-(benzo[c][1,2,5]thiadiazol-4-ylmethylene)malononitrile (bm)-terminated sm acceptors can achieve efficiencies as high as 5.3% in bhj solar cells with the polymer donor pce10. through systematic device optimization and characterization studies, we find that the nonfullerene analogues (fbm, cbm, and cdtbm) all perform comparably well, independent of the molecular structure and electronics of the \u03c0-bridge that links the two electron-deficient bm end groups. with estimated...",
            "contribution_ids": [
                "R146814",
                "R146824",
                "R146826"
            ]
        },
        {
            "instance_id": "EMPTYxR136499",
            "comparison_id": "EMPTY",
            "paper_id": "R136499",
            "text": "Increased attention but more efficient disengagement: Neuroscientific evidence for defensive processing of threatening health information. \"objective\\nprevious studies indicate that people respond defensively to threatening health information, especially when the information challenges self-relevant goals. the authors investigated whether reduced acceptance of self-relevant health risk information is already visible in early attention processes, that is, attention disengagement processes.\\n\\n\\ndesign\\nin a randomized, controlled trial with 29 smoking and nonsmoking students, a variant of posner's cueing task was used in combination with the high-temporal resolution method of event-related brain potentials (erps).\\n\\n\\nmain outcome measures\\nreaction times and p300 erp.\\n\\n\\nresults\\nsmokers showed lower p300 amplitudes in response to high- as opposed to low-threat invalid trials when moving their attention to a target in the opposite visual field, indicating more efficient attention disengagement processes. furthermore, both smokers and nonsmokers showed increased p300 amplitudes in response to the presentation of high- as opposed to low-threat valid trials, indicating threat-induced attention-capturing processes. reaction time measures did not support the erp data, indicating that the erp measure can be extremely informative to measure low-level attention biases in health communication.\\n\\n\\nconclusion\\nthe findings provide the first neuroscientific support for the hypothesis that threatening health information causes more efficient disengagement among those for whom the health threat is self-relevant.\"",
            "contribution_ids": [
                "R136501"
            ]
        },
        {
            "instance_id": "EMPTYxR130803",
            "comparison_id": "EMPTY",
            "paper_id": "R130803",
            "text": "Language Models with Transformers the transformer architecture is superior to rnn-based models in computational efficiency. recently, gpt and bert demonstrate the efficacy of transformer models on various nlp tasks using pre-trained language models on large-scale corpora. surprisingly, these transformer architectures are suboptimal for language model itself. neither self-attention nor the positional encoding in the transformer is able to efficiently incorporate the word-level sequential context crucial to language modeling. \\nin this paper, we explore effective transformer architectures for language model, including adding additional lstm layers to better capture the sequential context while still keeping the computation efficient. we propose coordinate architecture search (cas) to find an effective architecture through iterative refinement of the model. experimental results on the ptb, wikitext-2, and wikitext-103 show that cas achieves perplexities between 20.42 and 34.11 on all problems, i.e. on average an improvement of 12.0 perplexity units compared to state-of-the-art lstms. the source code is publicly available.",
            "contribution_ids": [
                "R130804"
            ]
        },
        {
            "instance_id": "EMPTYxR209428",
            "comparison_id": "EMPTY",
            "paper_id": "R209428",
            "text": "Method for Recognition of the Physical Activity of Human Being Using a Wearable Accelerometer companies are interested in retaining workers healthy, productive, and satisfied while cutting health-care and insurance costs. using a computer at work can cause back, neck and shoulder pain, eyestrain, and overuse injuries of human hands and wrists. it is possible to reduce these risks with better posture and good habits, such as taking rest breaks. during these breaks computer users should be encouraged to stand, stretch, and move around. for people who forget about a break or truly are focused on their direct work need help from special equipment for evaluation of real physical activity of computer user. method for recording accelerometer data from moving human as he or she performs daily activities and for identification of type, duration and intensity of movements by using wearable wireless sensing system is presented in this paper. the extraction of orientation independent acceleration data has positive effect on recognition accuracy of k-nearest neighbour classification scheme used for classification task. the recognition accuracy of algorithm is 78.9% and these results are better than accuracy obtained from raw accelerometer data. the method presented is simple, exhibited good performance and does not require significant computational recourses. doi: http://dx.doi.org/10.5755/j01.eee.20.5.7113",
            "contribution_ids": [
                "R209429"
            ]
        },
        {
            "instance_id": "EMPTYxR194114",
            "comparison_id": "EMPTY",
            "paper_id": "R194114",
            "text": "How developers believe Invisibility impacts NFRs related to User Interaction the advance of ubiquitous computing (ubicomp) and internet of things (iot) brought a new set of non-functional requirements (nfrs), especially related to human-computer interaction (hci). invisibility is one of these nfrs, and it refers to either the merging of technology in the user environment or the decrease of the interaction workload. this new nfr may impact traditional nfrs (e.g., usability), revealing positive correlations, when one nfr helps another, and negative correlations, when a procedure favors an nfr but creates difficulty for another one. software engineers need to know about these correlations, so they can select appropriate strategies to satisfy invisibility and traditional nfrs. correlations between nfrs are usually stored in catalogs, which is a well-defined body of knowledge gathered from previous experience. although invisibility has been recently cataloged with development strategies, the literature still lacks catalogs with correlations for this nfr. therefore, this work aims at capturing and cataloging invisibility correlations for ubicomp and iot systems. to do that, we also propose to systematize the definition of correlations using the following well-defined research methods: interview, content analysis and questionnaire. as a result, we defined a catalog with 110 positive and negative correlations with 9 nfrs. this well-defined body of knowledge is useful for supporting software engineers to select strategies to satisfy invisibility and other nfrs related to user interaction.",
            "contribution_ids": [
                "R194115"
            ]
        },
        {
            "instance_id": "EMPTYxR194317",
            "comparison_id": "EMPTY",
            "paper_id": "R194317",
            "text": "Optimizing for Recall in Automatic Requirements Classification: An Empirical Study using machine learning to solve requirements engineering problems can be a tricky task. even though certain algorithms have exceptional performance, their recall is usually below 100%. one key aspect in the implementation of machine learning tools is the balance between recall and precision. tools that do not find all correct answers may be considered useless. however, some tasks are very complicated and even requirements engineers struggle to solve them perfectly. if a tool achieves performance comparable to a trained engineer while reducing her workload considerably, it is considered to be useful. one such task is the classification of specification content elements into requirements and non-requirements. in this paper, we analyze this specific requirements classification problem and assess the importance of recall by performing an empirical study. we compared two groups of students who performed this task with and without tool support, respectively. we use the results to compute an estimate of f for the ff score, allowing us to choose the optimal balance between precision and recall. furthermore, we use the results to assess the practical time savings realized by the approach. by using the tool, users may not be able to find all defects in a document, however, they will be able to find close to all of them in a fraction of the time necessary. this demonstrates the practical usefulness of our approach and machine learning tools in general.",
            "contribution_ids": [
                "R194319"
            ]
        },
        {
            "instance_id": "EMPTYxR171021",
            "comparison_id": "EMPTY",
            "paper_id": "R171021",
            "text": "Administration of Non-Absorbable Antibiotics to Pregnant Mice to Perturb the Maternal Gut Microbiota Is Associated with Alterations in Offspring Behavior there is increasing evidence that the gut microbiota plays a major role in host health and disease. in this study, we examined whether perturbation of the maternal gut microbiota during pregnancy, induced by administration of non-absorbable antibiotics to pregnant dams, influences the behavior of offspring. terminal restriction fragment length polymorphism analyses of fecal bacterial composition showed that the relative abundance of the bacterial order lactobacillales was lower in offspring born from antibiotic-treated dams (20.7\u00b13.4%) than in control offspring (42.1\u00b16.2%) at p24, while the relative abundance of the bacterial family clostridium subcluster xiva was higher in offspring born from antibiotic-treated dams (34.2\u00b15.0%) than in control offspring (16.4\u00b13.3%). offspring born from antibiotic-treated dams exhibited low locomotor activity in both familiar and novel environments, and preferred to explore in the peripheral area of an unfamiliar field at postnatal week 4. at postnatal weeks 7\u20138, no difference was observed in the level of locomotor activity between control offspring and offspring from antibiotic-treated dams, while the tendency for the offspring from antibiotic-treated dams to be less engaged in exploring the inside area was still observed. the behavioral phenotypes of the offspring from antibiotic-treated dams at postnatal week 4 could be rescued to a considerable extent through fostering of these offspring by normal dams from postnatal day 1. although the detailed underlying mechanisms are not fully elucidated, the present results suggest that administration of non-absorbable antibiotics to pregnant dams to perturb the maternal gut microbiota during pregnancy leads to alterations in the behavior of their offspring.",
            "contribution_ids": [
                "R171022"
            ]
        },
        {
            "instance_id": "EMPTYxR49006",
            "comparison_id": "EMPTY",
            "paper_id": "R49006",
            "text": "A conserved RNA seed\u00e2\u0080\u0090pairing domain directs small RNA\u00e2\u0080\u0090mediated stress resistance in enterobacteria small regulatory rnas (srnas) are crucial components of many stress response systems. the envelope stress response (esr) of gram\u2010negative bacteria is a paradigm for srna\u2010mediated stress management and involves, among other factors, the alternative sigma factor e (\u03c3e) and one or more srnas. in this study, we identified the micv srna as a new member of the \u03c3e regulon in vibrio cholerae. we show that micv acts redundantly with another srna, vrra, and that both srnas share a conserved seed\u2010pairing domain allowing them to regulate multiple target mrnas. v. cholerae lacking \u03c3e displayed increased sensitivity toward antimicrobials, and over\u2010expression of either of the srnas suppressed this phenotype. laboratory selection experiments using a library of synthetic srna regulators revealed that the seed\u2010pairing domain of \u03c3e\u2010dependent srnas is strongly enriched among srnas identified under membrane\u2010damaging conditions and that repression of ompa is crucial for srna\u2010mediated stress relief. together, our work shows that micv and vrra act as global regulators in the esr of v. cholerae and provides evidence that bacterial srnas can be functionally annotated by their seed\u2010pairing sequences.",
            "contribution_ids": [
                "R49010"
            ]
        },
        {
            "instance_id": "EMPTYxR193470",
            "comparison_id": "EMPTY",
            "paper_id": "R193470",
            "text": "An Empirical Evaluation of Convolutional Networks for Malaria Diagnosis malaria is a globally widespread disease caused by parasitic protozoa transmitted to humans by infected female mosquitoes of anopheles. it is caused in humans only by the parasite plasmodium, further classified into four different species. identifying malaria parasites is possible by analysing digital microscopic blood smears, which is tedious, time-consuming and error prone. so, automation of the process has assumed great importance as it helps the laborious manual process of review and diagnosis. this work focuses on deep learning-based models, by comparing off-the-shelf architectures for classifying healthy and parasite-affected cells, by investigating the four-class classification on the plasmodium falciparum stages of life and, finally, by evaluating the robustness of the models with cross-dataset experiments on two different datasets. the main contributions to the research in this field can be resumed as follows: (i) comparing off-the-shelf architectures in the task of classifying healthy and parasite-affected cells, (ii) investigating the four-class classification on the p. falciparum stages of life and (iii) evaluating the robustness of the models with cross-dataset experiments. eleven well-known convolutional neural networks on two public datasets have been exploited. the results show that the networks have great accuracy in binary classification, even though they lack few samples per class. moreover, the cross-dataset experiments exhibit the need for some further regulations. in particular, resnet-18 achieved up to 97.68% accuracy in the binary classification, while densenet-201 reached 99.40% accuracy on the multiclass classification. the cross-dataset experiments exhibit the limitations of deep learning approaches in such a scenario, even though combining the two datasets permitted densenet-201 to reach 97.45% accuracy. naturally, this needs further investigation to improve the robustness. in general, densenet-201 seems to offer the most stable and robust performance, offering as a crucial candidate to further developments and modifications. moreover, the mobile-oriented architectures showed promising and satisfactory performance in the classification of malaria parasites. the obtained results enable extensive improvements, specifically oriented to the application of object detectors for type and stage of life recognition, even in mobile environments.",
            "contribution_ids": [
                "R193472"
            ]
        },
        {
            "instance_id": "EMPTYxR170413",
            "comparison_id": "EMPTY",
            "paper_id": "R170413",
            "text": "Fluid Intelligence and Psychosocial Outcome: From Logical Problem Solving to Social Adaptation \"background while fluid intelligence has proved to be central to executive functioning, logical reasoning and other frontal functions, the role of this ability in psychosocial adaptation has not been well characterized. methodology/principal findings a random-probabilistic sample of 2370 secondary school students completed measures of fluid intelligence (raven's progressive matrices, rpm) and several measures of psychological adaptation: bullying (delaware bullying questionnaire), domestic abuse of adolescents (conflict tactic scale), drug intake (onudd), self-esteem (rosenberg's self esteem scale) and the perceived mental health scale (spanish adaptation). lower fluid intelligence scores were associated with physical violence, both in the role of victim and victimizer. drug intake, especially cannabis, cocaine and inhalants and lower self-esteem were also associated with lower fluid intelligence. finally, scores on the perceived mental health assessment were better when fluid intelligence scores were higher. conclusions/significance our results show evidence of a strong association between psychosocial adaptation and fluid intelligence, suggesting that the latter is not only central to executive functioning but also forms part of a more general capacity for adaptation to social contexts.\"",
            "contribution_ids": [
                "R170414"
            ]
        },
        {
            "instance_id": "EMPTYxR6649",
            "comparison_id": "EMPTY",
            "paper_id": "R6649",
            "text": "ERSS 2005: Coreference-Based Summarization Reloaded we present erss 2005, our entry to this year\u2019s duc competition. with only slight modifications from last year\u2019s version to accommodate the more complex context information present in duc 2005, we achieved a similar performance to last year\u2019s entry, ranking roughly in the upper third when examining the rouge-1 and basic element score. we also participated in the additional manual evaluation based on the new pyramid method and performed further evaluations based on the basic elements method and the automatic generation of pyramids. interestingly, the ranking of our system differs greatly between the different measures; we attempt to analyse this effect based on correlations between the different results using the spearman coefficient.",
            "contribution_ids": [
                "R6650"
            ]
        },
        {
            "instance_id": "EMPTYxR193422",
            "comparison_id": "EMPTY",
            "paper_id": "R193422",
            "text": "Badvertisements: Stealthy click-fraud with unwitting accessories abstract we describe a new type of threat to the internet infrastructure, in the shape of a highly efficient but very well camouflaged click-fraud attack on the advertising infrastructure. the attack, which we refer to as a \u201cbadvertisement,\u201d is described and experimentally verified on several prominent advertisement schemes. this stealthy attack can be thought of as a threatening mutation of spam and phishing attacks, with which it has many commonalities, except for the fact that it is not the targeted individual who is the victim in the attack, but the unwitting advertiser.",
            "contribution_ids": [
                "R193424"
            ]
        },
        {
            "instance_id": "EMPTYxR49152",
            "comparison_id": "EMPTY",
            "paper_id": "R49152",
            "text": "REDI: Towards knowledge graph-powered scholarly information management and research networking academic data management has become an increasingly challenging task as research evolves over time. essential tasks such as information retrieval and research networking have turned into extremely difficult operations due to an ever-growing number of researchers and scientific articles. numerous initiatives have emerged in the it environments to address this issue, especially focused on web technologies. although those approaches have individually provided solutions for diverse problems, they still can not offer integrated knowledge bases nor flexibility to exploit adequately this information. in this article, we present redi, a linked data-powered framework for academic knowledge management and research networking, which introduces a new perspective of integration. redi combines information from multiple sources into a consolidated knowledge base through state-of-the-art procedures and leverages semantic web standards to represent the information. moreover, redi takes advantage of such knowledge for data visualisation and analysis, which ultimately improves and simplifies many activities including research networking.",
            "contribution_ids": [
                "R49155"
            ]
        },
        {
            "instance_id": "EMPTYxR171283",
            "comparison_id": "EMPTY",
            "paper_id": "R171283",
            "text": "Highly Educated Men Establish Strong Emotional Links with Their Dogs: A Study with Monash Dog Owner Relationship Scale (MDORS) in Committed Spanish Dog Owners the characteristics of the human-animal bond may be influenced by both owner-related and dog-related factors. a study was designed to explore the existence of different dog ownership patterns and their related factors. we created an on line questionnaire that included demographic questions about the dog and the owner, a spanish version of the monash dog owner relationship scale (mdors) and a validated measure of satisfaction with life (cantril\u2019s ladder). we collected 1140 valid responses from adult dog owners, who were recruited using the client databases of spanish veterinary practices. we explored the presence of groups within the population using principal components analysis (pca) of the mdors variables combined with hierarchical cluster analysis (hca). two groups were found; group i having a higher level of emotional involvement with their dogs compared with group ii. binary logistic regression was used to explore demographic factors that influenced group membership. four variables were significantly associated with membership of group i (p<0.0001); male gender of the owner (or = 32.36), high school level of maximum educational attainment (or = 0.052), university level of maximum educational attainment (or = 8.652), and owner cantril\u2019s score (or = 0.807). the results obtained from this convenience sample demonstrate that different patterns of dog-ownership may be present within a population of owner-dog dyads, and that certain owner characteristics are associated with the type of owner-dog relationship. future research could apply a similar approach to different types of sample population in order to identify specific patterns of dog-ownership.",
            "contribution_ids": [
                "R171284"
            ]
        },
        {
            "instance_id": "EMPTYxR155514",
            "comparison_id": "EMPTY",
            "paper_id": "R155514",
            "text": "Biogeographic drivers of diazotrophs in the western Pacific Ocean the global budget of marine nitrogen (n) is not balanced, with n removal largely exceeding n fixation. one of the major causes of this imbalance is our inadequate understanding of the diversity and distribution of marine n2 fixers (diazotrophs) as well as their contribution to n2 fixation. here, we performed a large\u2010scale cross\u2010system study spanning the south china sea, luzon strait, philippine sea, and western tropical pacific ocean to compare the biogeography of seven major diazotrophic groups and n2 fixation rates in these ecosystems. distinct spatial niche differentiation was observed. trichodesmium was dominant in the south china sea and western equatorial pacific, whereas the unicellular cyanobacterium ucyn\u2010b dominated in the philippine sea. furthermore, contrasting diel patterns of trichodesmium nifh genes and ucyn\u2010b nifh gene transcript activity were observed. the heterotrophic diazotroph gamma a phylotype was widespread throughout the western pacific ocean and occupied an ecological niche that overlapped with that of ucyn\u2010b. moreover, gamma a (or other possible unknown/undetected diazotrophs) rather than trichodesmium and ucyn\u2010b may have been responsible for the high n2 fixation rates in some samples. regional biogeochemistry analyses revealed cross\u2010system variations in n2\u2010fixing community composition and activity constrained by sea surface temperature, aerosol optical thickness, current velocity, mixed\u2010layer depth, and chlorophyll a concentration. these factors except for temperature essentially control/reflected iron supply/bioavailability and thus drive diazotroph biogeography. this study highlights biogeographical controls on marine n2 fixers and increases our understanding of global diazotroph biogeography.",
            "contribution_ids": [
                "R155516"
            ]
        },
        {
            "instance_id": "EMPTYxR138490",
            "comparison_id": "EMPTY",
            "paper_id": "R138490",
            "text": "Heterotrophic bacteria as major nitrogen fixers in the euphotic zone of the Indian Ocean: NITROGEN FIXATION IN THE INDIAN OCEAN diazotrophy in the indian ocean is poorly understood compared to that in the atlantic and pacific oceans. we first examined the basin\u2010scale community structure of diazotrophs and their nitrogen fixation activity within the euphotic zone during the northeast monsoon period along about 69\u00b0e from 17\u00b0n to 20\u00b0s in the oligotrophic indian ocean, where a shallow nitracline (49\u201359\\u2009m) prevailed widely and the sea surface temperature (sst) was above 25\u00b0c. phosphate was detectable at the surface throughout the study area. the dissolved iron concentration and the ratio of iron to nitrate\\u2009+\\u2009nitrite at the surface were significantly higher in the arabian sea than in the equatorial and southern indian ocean. nitrogen fixation in the arabian sea (24.6\u201347.1 \u03bcmoln m\u22122 d\u22121) was also significantly greater than that in the equatorial and southern indian ocean (6.27\u201316.6 \u03bcmoln m\u22122 d\u22121), indicating that iron could control diazotrophy in the indian ocean. phylogenetic analysis of nifh showed that most diazotrophs belonged to the proteobacteria and that cyanobacterial diazotrophs were absent in the study area except in the arabian sea. furthermore, nitrogen fixation was not associated with light intensity throughout the study area. these results are consistent with nitrogen fixation in the indian ocean, being largely performed by heterotrophic bacteria and not by cyanobacteria. the low cyanobacterial diazotrophy was attributed to the shallow nitracline, which is rarely observed in the pacific and atlantic oligotrophic oceans. because the shallower nitracline favored enhanced upward nitrate flux, the competitive advantage of cyanobacterial diazotrophs over nondiazotrophic phytoplankton was not as significant as it is in other oligotrophic oceans.",
            "contribution_ids": [
                "R138492"
            ]
        },
        {
            "instance_id": "EMPTYxR109994",
            "comparison_id": "EMPTY",
            "paper_id": "R109994",
            "text": "Corn Cob Biochar Improves Aggregate Characteristics of a Tropical Sandy Loam most tropical soils are highly weathered and are vulnerable to soil erosion due to their poor aggregate characteristics. soil aggregate characteristics are critical indicators of soil structural stability, and they have the propensity to influence soil physical behavior and functioning. in this study, we investigated the effect of corn cob biochar on the aggregate characteristics of a highly weathered tropical sandy loam. biochar significantly increased soil organic carbon by 22-40% relative to the untreated soil with a surprising trend of increasing water dispersible clay as biochar rate increased. amount of water stable aggregates was significantly improved by 15 \u2013 34% in biochar treatments compared to control. incorporation of biochar decreased the tensile strength of the large aggregates (4\u20138 mm and 8\u201316 mm), but increased same in the smaller aggregates (1\u20132 mm). soil friability and workability were significantly improved in the bc-20 and bc-20+p treatments. conclusions increasing the rate of corn cob biochar improved the water stability of the aggregates compared to the ct, despite the absence of a significant effect on the dispersible clay content. for smaller aggregates (1\u20132mm), tensile strength for bc-20 and bc-20+p treatments was significantly higher than the ct and bc-10, with an opposite trend observed for larger aggregates (4\u20138 mm and 8\u201316 mm). corn cob biochar significantly improved soil friability and the ease of tillage quantified with a workability index. reference dexter, a.r., and b. kroesbergen. 1985. methodology for determination of tensile strength of soil aggregates. journal of agric. engineering research 31:139-147. corn cob biochar improves aggregate characteristics of a tropical sandy loam ohio state university south centers college of food, agricultural, and environmental sciences cfaes provides research and related educational programs to clientele on a nondiscriminatory basis. for more information: go.osu.edu/cfaesdiversity. the ohio state university field layout and experimental design randomized complete block design 4 treatments with 4 replications",
            "contribution_ids": [
                "R109996"
            ]
        },
        {
            "instance_id": "EMPTYxR171627",
            "comparison_id": "EMPTY",
            "paper_id": "R171627",
            "text": "A multi-level model of emerging technology: An empirical study of the evolution of biotechnology from 1976 to 2003 in this paper, we develop an ecological, multi-level model that can be used to study the evolution of emerging technology. more specifically, by defining technology as a system composed of a set of interacting components, we can build upon the argument of multi-level density dependence from organizational ecology to develop a distribution-independent model of technological evolution. this allows us to distinguish between different stages of component development, which provides more insight into the emergence of stable component configurations, or dominant designs. we validate our hypotheses in the biotechnology industry by using patent data from the uspto from 1976 to 2003.",
            "contribution_ids": [
                "R171628"
            ]
        },
        {
            "instance_id": "EMPTYxR169657",
            "comparison_id": "EMPTY",
            "paper_id": "R169657",
            "text": "Optogenetics in Mice Performing a Visual Discrimination Task: Measurement and Suppression of Retinal Activation and the Resulting Behavioral Artifact optogenetic techniques are used widely to perturb and interrogate neural circuits in behaving animals, but illumination can have additional effects, such as the activation of endogenous opsins in the retina. we found that illumination, delivered deep into the brain via an optical fiber, evoked a behavioral artifact in mice performing a visually guided discrimination task. compared with blue (473 nm) and yellow (589 nm) illumination, red (640 nm) illumination evoked a greater behavioral artifact and more activity in the retina, the latter measured with electrical recordings. in the mouse, the sensitivity of retinal opsins declines steeply with wavelength across the visible spectrum, but propagation of light through brain tissue increases with wavelength. our results suggest that poor retinal sensitivity to red light was overcome by relatively robust propagation of red light through brain tissue and stronger illumination of the retina by red than by blue or yellow light. light adaptation of the retina, via an external source of illumination, suppressed retinal activation and the behavioral artifact without otherwise impacting behavioral performance. in summary, long wavelength optogenetic stimuli are particularly prone to evoke behavioral artifacts via activation of retinal opsins in the mouse, but light adaptation of the retina can provide a simple and effective mitigation of the artifact.",
            "contribution_ids": [
                "R169658",
                "R169659"
            ]
        },
        {
            "instance_id": "EMPTYxR168924",
            "comparison_id": "EMPTY",
            "paper_id": "R168924",
            "text": "Report of a series of 82 cases of Buruli ulcer from Nigeria treated in Benin, from 2006 to 2016 background nigeria is one of the countries endemic for buruli ulcer (bu) in west africa but did not have a control programme until recently. as a result, bu patients often access treatment services in neighbouring benin where dedicated health facilities have been established to provide treatment free of charge for bu patients. this study aimed to describe the epidemiological, clinical, biological and therapeutic characteristics of cases from nigeria treated in three of the four treatment centers in benin. methodology/principal findings a series of 82 bu cases from nigeria were treated in three centres in benin during 2006\u20132016 and are retrospectively described. the majority of these patients came from ogun and lagos states which border benin. most of the cases were diagnosed with ulcerative lesions (80.5%) and who category iii lesions (82.9%); 97.5% were healed after a median hospital stay of 46 days (interquartile range [iqr]: 32\u2013176 days). conclusions/significance this report adds to the epidemiological understanding of bu in nigeria in the hope that the programme will intensify efforts aimed at early case detection and treatment.",
            "contribution_ids": [
                "R168926",
                "R168927",
                "R168928",
                "R168929",
                "R168930"
            ]
        },
        {
            "instance_id": "EMPTYxR70742",
            "comparison_id": "EMPTY",
            "paper_id": "R70742",
            "text": "A PISA-2015 Comparative Meta-Analysis between Singapore and Finland: Relations of Students\u00e2\u0080\u0099 Interest in Science, Perceived ICT Competence, and Environmental Awareness and Optimism the aim of the present study is twofold: (1) to identify a factor structure between variables-interest in broad science topics, perceived information and communications technology (ict) competence, environmental awareness and optimism; and (2) to explore the relations between these variables at the country level. the first part of the aim is addressed using exploratory factor analysis with data from the program for international student assessment (pisa) for 15-year-old students from singapore and finland. the results show that a comparable structure with four factors was verified in both countries. correlation analyses and linear regression were used to address the second part of the aim. the results show that adolescents\u2019 interest in broad science topics can predict perceived ict competence. their interest in broad science topics and perceived ict competence can predict environmental awareness in both countries. however, there is difference in predicting environmental optimism. singaporean students\u2019 interest in broad science topics and their perceived ict competences are positive predictors, whereas environmental awareness is a negative predictor. finnish students\u2019 environmental awareness negatively predicted environmental optimism.",
            "contribution_ids": [
                "R70745"
            ]
        },
        {
            "instance_id": "EMPTYxR171103",
            "comparison_id": "EMPTY",
            "paper_id": "R171103",
            "text": "Counterfactual Reasoning Deficits in Schizophrenia Patients background counterfactual thinking is a specific type of conditional reasoning that enables the generation of mental simulations of alternatives to past factual events. although it has been broadly studied in the general population, research on schizophrenia is still scarce. the aim of the current study was to further examine counterfactual reasoning in this illness. methods forty schizophrenia patients and 40 controls completed a series of tests that assessed the influence of the \u201ccausal order effect\u201d on counterfactual thinking, and the ability to generate counterfactual thoughts and counterfactually derive inferences from a hypothetical situation. socio-demographic and clinical characteristics, as well as neurocognitive variables, were also examined. results compared to controls, the schizophrenia patients generated fewer counterfactual thoughts when faced with a simulated scenario. the pattern of response when assessing the causality effect of the order was also different between the groups, with the patients being more frequently unable to attribute any ordering of events than the control subjects. additionally, the schizophrenia patients showed more difficulties when deriving normative counterfactual inferences from hypothetical social situations. none of the counterfactual reasoning measures was associated to any of the cognitive functions or clinical and socio-demographic variables assessed. conclusions a global impairment in counterfactual thinking characterizes schizophrenia patients. because of the potential impact of such deficits on psychosocial functioning, targeting counterfactual reasoning for improvement might be considered in future treatment approaches.",
            "contribution_ids": [
                "R171104",
                "R171105"
            ]
        },
        {
            "instance_id": "EMPTYxR170784",
            "comparison_id": "EMPTY",
            "paper_id": "R170784",
            "text": "Screening Primary-Care Patients Forgoing Health Care for Economic Reasons \"background growing social inequities have made it important for general practitioners to verify if patients can afford treatment and procedures. incorporating social conditions into clinical decision-making allows general practitioners to address mismatches between patients' health-care needs and financial resources. objectives identify a screening question to, indirectly, rule out patients' social risk of forgoing health care for economic reasons, and estimate prevalence of forgoing health care and the influence of physicians' attitudes toward deprivation. design multicenter cross-sectional survey. participants forty-seven general practitioners working in the french\u2013speaking part of switzerland enrolled a random sample of patients attending their private practices. main measures patients who had forgone health care were defined as those reporting a household member (including themselves) having forgone treatment for economic reasons during the previous 12 months, through a self-administered questionnaire. patients were also asked about education and income levels, self-perceived social position, and deprivation levels. key results overall, 2,026 patients were included in the analysis; 10.7% (ci95% 9.4\u201312.1) reported a member of their household to have forgone health care during the 12 previous months. the question \u201cdid you have difficulties paying your household bills during the last 12 months\u201d performed better in identifying patients at risk of forgoing health care than a combination of four objective measures of socio-economic status (gender, age, education level, and income) (r2\\u200a=\\u200a0.184 vs. 0.083). this question effectively ruled out that patients had forgone health care, with a negative predictive value of 96%. furthermore, for physicians who felt powerless in the face of deprivation, we observed an increase in the odds of patients forgoing health care of 1.5 times. conclusion general practitioners should systematically evaluate the socio-economic status of their patients. asking patients whether they experience any difficulties in paying their bills is an effective means of identifying patients who might forgo health care.\"",
            "contribution_ids": [
                "R170785"
            ]
        },
        {
            "instance_id": "EMPTYxR137466",
            "comparison_id": "EMPTY",
            "paper_id": "R137466",
            "text": "Comparison of heterojunction device parameters for pure and doped ZnO thin films with IIIA (Al or In) elements grown on silicon at room ambient in this work, pure and iiia element doped zno thin films were grown on p type silicon (si) with (100) orientated surface by sol-gel method, and were characterized for comparing their electrical characteristics. the heterojunction parameters were obtained from the current-voltage (i-v) and capacitance-voltage (c-v) characteristics at room temperature. the ideality factor (n), saturation current (io) and junction resistance of zno/p-si heterojunction for both pure and doped (with al or in) cases were determined by using different methods at room ambient. other electrical parameters such as fermi energy level (ef), barrier height (\u03c6b), acceptor concentration (na), built-in potential (\u03c6i) and voltage dependence of surface states (nss) profile were obtained from the c-v measurements. the results reveal that doping zno with iiia (al or in) elements to fabricate n-zno/p-si heterojunction can result in high performance diode characteristics.",
            "contribution_ids": [
                "R137468"
            ]
        },
        {
            "instance_id": "EMPTYxR146591",
            "comparison_id": "EMPTY",
            "paper_id": "R146591",
            "text": "Quality assurance applied to animal disease surveillance systems: -EN- -FR- -ES- monitoring and surveillance systems (moss) are essential activities for official veterinary services. in addition, the increased trade in animals and animal products over recent years has increased the importance of international disease reporting. a reliable surveillance system is the key to early warning of a change in the health status of any animal population. such a system is also essential for providing evidence about the absence of diseases or in determining the extent of a disease which is known to be present. the authors discuss a set of methods and approaches for evaluating the quality of surveillance and survey systems. certain steps are required when assessing the quality of a service or product. various approaches for quality assessment are available and the suitability of each method depends on the objective of the evaluation. an essential basic requirement is, however, to use an objective, transparent and systematic approach. the evidence collected and the analyses used to reach conclusions must be of such high quality that the results are acceptable to both the management of the moss and the assessor. repeated discussions and negotiations may be necessary to reach consensus, particularly if the judgement affects activities between trading partners. well-documented moss with specified objectives and integrated quality assurance mechanisms are likely to be easier to evaluate.",
            "contribution_ids": [
                "R146593"
            ]
        },
        {
            "instance_id": "EMPTYxR170834",
            "comparison_id": "EMPTY",
            "paper_id": "R170834",
            "text": "Cortical Thinning in Temporo-Parietal Junction (TPJ) in Non-Affective First-Episode of Psychosis Patients with Persistent Negative Symptoms background negative symptoms represent an unmet therapeutic need in many patients with schizophrenia. in an extension to our previous voxel-based morphometry findings, we employed a more specific, vertex-based approach to explore cortical thinning in relation to persistent negative symptoms (pns) in non-affective first-episode of psychosis (fep) patients to advance our understanding of the pathophysiology of primary negative symptoms. methods this study included 62 non-affective fep patients and 60 non-clinical controls; 16 patients were identified with pns (i.e., at least 1 primary negative symptom at moderate or greater severity sustained for at least 6 consecutive months). using cortical thickness analyses, we explored for differences between pns and non-pns patients as well as between each patient group and healthy controls; cut-off threshold was set at p<0.01, corrected for multiple comparisons. results a thinner cortex prominently in the right superior temporal gyrus extending into the temporo-parietal junction (tpj), right parahippocampal gyrus, and left orbital frontal gyrus was identified in pns patients vs. non-pns patients. compared with healthy controls, pns patients showed a thinner cortex prominently in the right superior temporal gyrus, right parahippocampal gyrus, and right cingulate; non-pns patients showed a thinner cortex prominently in the parahippocampal gyrus bi-laterally. conclusion cortical thinning in the early stages of non-affective psychosis is present in the frontal and temporo-parietal regions in patients with pns. with these brain regions strongly related to social cognitive functioning, our finding suggests a potential link between primary negative symptoms and social cognitive deficits through common brain etiologies.",
            "contribution_ids": [
                "R170835"
            ]
        },
        {
            "instance_id": "EMPTYxR131085",
            "comparison_id": "EMPTY",
            "paper_id": "R131085",
            "text": "Discrete Flows: Invertible Generative Models of Discrete Data while normalizing flows have led to significant advances in modeling high-dimensional continuous distributions, their applicability to discrete distributions remains unknown. in this paper, we show that flows can in fact be extended to discrete events---and under a simple change-of-variables formula not requiring log-determinant-jacobian computations. discrete flows have numerous applications. we consider two flow architectures: discrete autoregressive flows that enable bidirectionality, allowing, for example, tokens in text to depend on both left-to-right and right-to-left contexts in an exact language model; and discrete bipartite flows that enable efficient non-autoregressive generation as in realnvp. empirically, we find that discrete autoregressive flows outperform autoregressive baselines on synthetic discrete distributions, an addition task, and potts models; and bipartite flows can obtain competitive performance with autoregressive baselines on character-level language modeling for penn tree bank and text8.",
            "contribution_ids": [
                "R131086",
                "R131089"
            ]
        },
        {
            "instance_id": "EMPTYxR171005",
            "comparison_id": "EMPTY",
            "paper_id": "R171005",
            "text": "Coping with Self-Threat and the Evaluation of Self-Related Traits: An fMRI Study a positive view of oneself is important for a healthy lifestyle. self-protection mechanisms such as suppressing negative self-related information help us to maintain a positive view of ourselves. this is of special relevance when, for instance, a negative test result threatens our positive self-view. to date, it is not clear which brain areas support self-protective mechanisms under self-threat. in the present functional magnetic resonance imaging (fmri) study the participants (n = 46) received a (negative vs. positive) performance test feedback before entering the scanner. in the scanner, the participants were instructed to ascribe personality traits either to themselves or to a famous other. our results showed that participants responded slower to negative self-related traits compared to positive self-related traits. high self-esteem individuals responded slower to negative traits compared to low self-esteem individuals following a self-threat. this indicates that high self-esteem individuals engage more in self-enhancing strategies after a threat by inhibiting negative self-related information more successfully than low self-esteem individuals. this behavioral pattern was mirrored in the fmri data as dacc correlated positively with trait self-esteem. generally, acc activation was attenuated under threat when participants evaluated self-relevant traits and even more for negative self-related traits. we also found that activation in the acc was negatively correlated with response times, indicating that greater activation of the acc is linked to better access (faster response) to positive self-related traits and to impaired access (slower response) to negative self-related traits. these results confirm the acc function as important in managing threatened self-worth but indicate differences in trait self-esteem levels. the fmri analyses also revealed a decrease in activation within the left hippocampus and the right thalamus under threat. this indicates that a down-regulation of activation in these regions might also serve as coping mechanism in dealing with self-threat.",
            "contribution_ids": [
                "R171006",
                "R171007"
            ]
        },
        {
            "instance_id": "EMPTYxR170847",
            "comparison_id": "EMPTY",
            "paper_id": "R170847",
            "text": "Resilience amongst Australian Aboriginal Youth: An Ecological Analysis of Factors Associated with Psychosocial Functioning in High and Low Family Risk Contexts we investigate whether the profile of factors protecting psychosocial functioning of high risk exposed australian aboriginal youth are the same as those promoting psychosocial functioning in low risk exposed youth. data on 1,021 youth aged 12\u201317 years were drawn from the western australian aboriginal child health survey (waachs 2000\u20132002), a population representative survey of the health and well-being of aboriginal children, their families and community contexts. a person-centered approach was used to define four groups of youth cross-classified according to level of risk exposure (high/low) and psychosocial functioning (good/poor). multivariate logistic regression was used to model the influence of individual, family, cultural and community factors on psychosocial outcomes separately for youth in high and low family-risk contexts. results showed that in high family risk contexts, prosocial friendship and low area-level socioeconomic status uniquely protected psychosocial functioning. however, in low family risk contexts the perception of racism increased the likelihood of poor psychosocial functioning. for youth in both high and low risk contexts, higher self-esteem and self-regulation were associated with good psychosocial functioning although the relationship was non-linear. these findings demonstrate that an empirical resilience framework of analysis can identify potent protective processes operating uniquely in contexts of high risk and is the first to describe distinct profiles of risk, protective and promotive factors within high and low risk exposed australian aboriginal youth.",
            "contribution_ids": [
                "R170848"
            ]
        },
        {
            "instance_id": "EMPTYxR196677",
            "comparison_id": "EMPTY",
            "paper_id": "R196677",
            "text": "Using Sentinel-2 Images for Soil Organic Carbon Content Mapping in Croplands of Southwestern France. The Usefulness of Sentinel-1/2 Derived Moisture Maps and Mismatches between Sentinel Images and Sampling Dates in agronomy, soil organic carbon (soc) content is important for the development and growth of crops. from an environmental monitoring viewpoint, soc sequestration is essential for mitigating the emission of greenhouse gases into the atmosphere. soc dynamics in cropland soils should be further studied through various approaches including remote sensing. in order to predict soc content over croplands in southwestern france (area of 22,177 km\u00b2), this study addresses (i) the influence of the dates on which sentinel-2 (s2) images were acquired in the springs of 2017\u20132018 as well as the influence of the soil sampling period of a set of samples collected between 2005 and 2018, (ii) the use of soil moisture products (smps) derived from sentinel-1/2 satellites to analyze the influence of surface soil moisture on model performance when included as a covariate, and (iii) whether the spatial distribution of soc as mapped using s2 is related to terrain-derived attributes. the influences of s2 image dates and soil sampling periods were analyzed for bare topsoil. the dates of the s2 images with the best performance (rpd \u2265 1.7) were 6 april and 26 may 2017, using soil samples collected between 2016 and 2018. the soil sampling dates were also analyzed using smp values. soil moisture values were extracted for each sample and integrated into partial least squares regression (plsr) models. the use of soil moisture as a covariate had no effect on the prediction performance of the models; however, smp values were used to select the driest dates, effectively mapping topsoil organic carbon. s2 was able to predict high soc contents in the specific soil types located on the old terraces (mesas) shaped by rivers flowing from the southwestern pyr\u00e9n\u00e9es.",
            "contribution_ids": [
                "R196684"
            ]
        },
        {
            "instance_id": "EMPTYxR12016",
            "comparison_id": "EMPTY",
            "paper_id": "R12016",
            "text": "Solving Mixed Model Workplace Time-dependent Assembly Line Balancing Problem with FSS Algorithm balancing assembly lines, a family of optimization problems commonly known as assembly line balancing problem, is notoriously np-hard. they comprise a set of problems of enormous practical interest to manufacturing industry due to the relevant frequency of this type of production paradigm. for this reason, many researchers on computational intelligence and industrial engineering have been conceiving algorithms for tackling different versions of assembly line balancing problems utilizing different methodologies. in this article, it was proposed a problem version referred as mixed model workplace time-dependent assembly line balancing problem with the intention of including pressing issues of real assembly lines in the optimization problem, to which four versions were conceived. heuristic search procedures were used, namely two swarm intelligence algorithms from the fish school search family: the original version, named \"vanilla\", and a special variation including a stagnation avoidance routine. either approaches solved the newly posed problem achieving good results when compared to particle swarm optimization algorithm.",
            "contribution_ids": [
                "R12018"
            ]
        },
        {
            "instance_id": "EMPTYxR199162",
            "comparison_id": "EMPTY",
            "paper_id": "R199162",
            "text": "Handling knowledge uncertainty in risk-based requirements engineering \"requirements engineers are faced with multiple sources of uncertainty. in particular, the extent to which the identified software requirements and environment assumptions are adequate and sufficiently complete is uncertain; the extent to which they will be satisfied in the system-to-be is uncertain; and the extent to which obstacles to their satisfaction will occur is uncertain. the resolution of such domain-level uncertainty requires estimations of the likelihood that those different types of situations may or may not occur. however, the extent to which the resulting estimates are accurate is uncertain as well. this meta-level uncertainty limits current risk-based methods for requirements engineering. the paper introduces a quantitative approach for managing it. an earlier formal framework for probabilistic goals and obstacles is extended to explicitly cope with uncertainties about estimates of likelihoods of fine-grained obstacles to goal satisfaction. such estimates are elicited from multiple sources and combined in order to reduce their uncertainty margins. the combined estimates and their uncertainties are up-propagated through obstacle refinement trees and then through the system's goal model. two metrics are introduced for measuring problematic uncertainties. when applied to the probability distributions obtained by up-propagation to the top-level goals, the metrics allow critical leaf obstacles with most problematic uncertainty margins to be highlighted. the proposed approach is evaluated on excerpts from a real ambulance dispatching system.\"",
            "contribution_ids": [
                "R199163"
            ]
        },
        {
            "instance_id": "EMPTYxR170215",
            "comparison_id": "EMPTY",
            "paper_id": "R170215",
            "text": "Risk of adverse treatment outcomes among new pulmonary TB patients co-infected with diabetes in Pakistan: A prospective cohort study purpose the escalating burden of diabetes in countries tackling high burden of tuberculosis (tb) has adverse implications for co-infected individuals and national tb control efforts. we aimed to study whether there was a difference in treatment outcome among diabetic and non-diabetic pulmonary tb patients and identify the determinants of treatment outcome among the two groups. materials and methods this prospective cohort study recruited new patients of pulmonary tuberculosis (ptb) aged 15 years and above who were diagnosed at and registered with gulab devi chest hospital, lahore, pakistan for anti-tuberculosis treatment (att). ptb patients were screened for diabetes using random and fasting blood glucose tests. diabetic and non-diabetic ptb patients were followed up at second, fifth and sixth month of att and 6 months after att completion to determine treatment outcome. multivariate logistic regression analysis was conducted to assess association between various factors and treatment outcome. results of 614 ptb patients, (n = 113 [18%]) were diabetic and (n = 501 [82%]) non-diabetic. final model showed that diabetics were more likely to experience an unfavorable outcome as compared to non-diabetics (adjusted odds ratio [aor] = 2.70, 95% confidence interval [ci] = 1.30 to 5.59). other predictors of unfavorable outcome included rural residence (aor = 1.98, 95% ci = 1.14 to 3.47), body mass index less than 18.50 (aor = 1.89, 95% ci = 1.03 to 3.47) and being a smoker (aor = 2.03, 95%ci = 1.04 to 3.94). conclusion our study shows unfavorable treatment outcome among diabetic ptb patients. integrated models of care with screening/testing and management for diabetes and tb could improve tb treatment outcomes.",
            "contribution_ids": [
                "R170216"
            ]
        },
        {
            "instance_id": "EMPTYxR74395",
            "comparison_id": "EMPTY",
            "paper_id": "R74395",
            "text": "Framework for the integration of digital resources based-on a Semantic Web approach [Marco de Trabajo para la Integraci\u00c3\u00b3n de Recursos Digitales Basado en un Enfoque de Web Sem\u00c3\u00a1ntica] espanolen un entorno abierto como la web, no es posible estandarizar los procesos de descripcion y publicacion de metadatos, cada institucion puede manejar diferentes formatos o modelos de datos. para mejorar la interoperabilidad semantica entre repositorios heterogeneos, se estan adoptando enfoques basados en tecnologias de la web semantica; de esta manera, cada libreria digital puede conservar sus cualidades locales especificas y no requerira resignarlas para poder normalizar el intercambio, reuso o la cosecha de recursos digitales. en este trabajo, se presenta un ciclo que cubre los procesos de: extraccion de metadatos desde repositorios oai-pmh, y la generacion y publicacion de datos enlazados, con el proposito de mejorar la integracion e interoperabilidad de recursos almacenados en librerias digitales. la propuesta descrita facilita la existencia de diversidad de metodos y estandares en los procesos de cada proveedor de recursos digitales. englishfrom the point of view of access to metadata from distributed repositories, the open archives initiative (oai) proposed a protocol for the interchange and harvesting of metadata called oai-pmh. this protocol provide a low degree of interoperability, however, with an approach based on semantic technologies, the interoperability of data can reach a higher level; thus, each digital library can retain their specific local qualities and will not require reassign them in order to standardize the exchange, re-use or harvesting of digital resources. in this paper, the process for the extraction of metadata, generation and publishing linked data in order to improve integration and interoperability between resources stored on digital libraries is presented. the proposal facilitates the existence of diversity of methods and standards in the processes of each supplier of digital resources",
            "contribution_ids": [
                "R74396",
                "R109062"
            ]
        },
        {
            "instance_id": "EMPTYxR170849",
            "comparison_id": "EMPTY",
            "paper_id": "R170849",
            "text": "Invasive Cane Toads: Social Facilitation Depends upon an Individual\u00e2\u0080\u0099s Personality individual variation in behavioural traits (including responses to social cues) may influence the success of invasive populations. we studied the relationship between sociality and personality in invasive cane toads (rhinella marina) from a recently established population in tropical australia. in our field experiments, we manipulated social cues (the presence of a feeding conspecific) near a food source. we captured and compared toads that only approached feeding sites where another toad was already present, with conspecifics that approached unoccupied feeding sites. subsequent laboratory trials showed correlated personality differences (behavioural syndromes) between these two groups of toads. for example, toads that approached already-occupied rather than unoccupied feeding sites in the field, took longer to emerge from a shelter-site in standardized trials, suggesting these individuals are \u2018shy\u2019 (whereas toads that approached unoccupied feeding stations tended to be \u2018bold\u2019). manipulating hunger levels did not abolish this difference. in feeding trials, a bold toad typically outcompeted a shy toad under conditions of low prey availability, but the outcome was reversed when multiple prey items were present. thus, both personality types may be favored under different circumstances. this invasive population of toads contains individuals that exhibit a range of personalities, hinting at the existence of a wide range of social dynamics in taxa traditionally considered to be asocial.",
            "contribution_ids": [
                "R170850"
            ]
        },
        {
            "instance_id": "EMPTYxR171134",
            "comparison_id": "EMPTY",
            "paper_id": "R171134",
            "text": "Controversies Regarding the Psychometric Properties of the Brief COPE: The Case of the Brazilian-Portuguese Version \u00e2\u0080\u009cCOPE Breve\u00e2\u0080\u009d \"the brief coping orientation to problems experienced (cope) inventory investigates the different ways in which people respond to stressful situations. knowledge is lacking regarding the coping strategies and styles of people in developing countries, including brazil. this study aimed to adapt and validate the brief cope to brazilian portuguese (named cope breve) by focusing on dispositional coping. for the cross-cultural adaptation, the original brief cope in english (28 items grouped into 14 subscales) was adapted according to a universalistic approach, following these steps: translation, synthesis, back-translation, analysis by an expert panel, and pretest with 30 participants. then, 237 adults from the community health service responded to the cope breve. psychometric analyses included reliability and exploratory factor analysis. most of the 14 subscales from the original brief cope exhibited problems related to internal consistency. a velicer's minimum average partial test (map) was performed and pointed out 3 factors. exploratory factor analysis produced a revised 20-item version with a 3-factor solution: religion and positive reframing, distraction and external support. the psychometric properties of the cope breve with three factors were appropriate. limitations of this study as well as suggestions for future studies are presented. the cope breve should be used in brazilian clinics and investigations, but divergences in its psychometrics should be further explored in other contexts.\"",
            "contribution_ids": [
                "R171135"
            ]
        },
        {
            "instance_id": "EMPTYxR169405",
            "comparison_id": "EMPTY",
            "paper_id": "R169405",
            "text": "Treatment Default amongst Patients with Tuberculosis in Urban Morocco: Predicting and Explaining Default and Post-Default Sputum Smear and Drug Susceptibility Results setting public tuberculosis (tb) clinics in urban morocco. objective explore risk factors for tb treatment default and develop a prediction tool. assess consequences of default, specifically risk for transmission or development of drug resistance. design case-control study comparing patients who defaulted from tb treatment and patients who completed it using quantitative methods and open-ended questions. results were interpreted in light of health professionals\u2019 perspectives from a parallel study. a predictive model and simple tool to identify patients at high risk of default were developed. sputum from cases with pulmonary tb was collected for smear and drug susceptibility testing. results 91 cases and 186 controls enrolled. independent risk factors for default included current smoking, retreatment, work interference with adherence, daily directly observed therapy, side effects, quick symptom resolution, and not knowing one\u2019s treatment duration. age >50 years, never smoking, and having friends who knew one\u2019s diagnosis were protective. a simple scoring tool incorporating these factors was 82.4% sensitive and 87.6% specific for predicting default in this population. clinicians and patients described additional contributors to default and suggested locally-relevant intervention targets. among 89 cases with pulmonary tb, 71% had sputum that was smear positive for tb. drug resistance was rare. conclusion the causes of default from tb treatment were explored through synthesis of qualitative and quantitative data from patients and health professionals. a scoring tool with high sensitivity and specificity to predict default was developed. prospective evaluation of this tool coupled with targeted interventions based on our findings is warranted. of note, the risk of tb transmission from patients who default treatment to others is likely to be high. the commonly-feared risk of drug resistance, though, may be low; a larger study is required to confirm these findings.",
            "contribution_ids": [
                "R169406",
                "R169407",
                "R169408",
                "R169409",
                "R169410"
            ]
        },
        {
            "instance_id": "EMPTYxR170275",
            "comparison_id": "EMPTY",
            "paper_id": "R170275",
            "text": "Parental neural responsivity to infants\u00e2\u0080\u0099 visual attention: How mature brains influence immature brains during social interaction almost all attention and learning\u2014in particular, most early learning\u2014take place in social settings. but little is known of how our brains support dynamic social interactions. we recorded dual electroencephalography (eeg) from 12-month-old infants and parents during solo play and joint play. during solo play, fluctuations in infants\u2019 theta power significantly forward-predicted their subsequent attentional behaviours. however, this forward-predictiveness was lower during joint play than solo play, suggesting that infants\u2019 endogenous neural control over attention is greater during solo play. overall, however, infants were more attentive to the objects during joint play. to understand why, we examined how adult brain activity related to infant attention. we found that parents\u2019 theta power closely tracked and responded to changes in their infants\u2019 attention. further, instances in which parents showed greater neural responsivity were associated with longer sustained attention by infants. our results offer new insights into how one partner influences another during social interaction.",
            "contribution_ids": [
                "R170276"
            ]
        },
        {
            "instance_id": "EMPTYxR168827",
            "comparison_id": "EMPTY",
            "paper_id": "R168827",
            "text": "Genes regulated by SATB2 during neurodevelopment contribute to schizophrenia and educational attainment satb2 is associated with schizophrenia and is an important transcription factor regulating neocortical organization and circuitry. rare mutations in satb2 cause a syndrome that includes developmental delay, and mouse studies identify an important role for satb2 in learning and memory. interacting partners bcl11b and gatad2a are also schizophrenia risk genes indicating that other genes interacting with or are regulated by satb2 are making a contribution to schizophrenia and cognition. we used data from satb2 mouse models to generate three gene-sets that contain genes either functionally related to satb2 or targeted by satb2 at different stages of development. each was tested for enrichment using the largest available genome-wide association studies (gwas) datasets for schizophrenia and educational attainment (ea) and enrichment analysis was also performed for schizophrenia and other neurodevelopmental disorders using data from rare variant sequencing studies. these satb2 gene-sets were enriched for genes containing common variants associated with schizophrenia and ea, and were enriched for genes containing rare variants reported in studies of schizophrenia, autism and intellectual disability. in the developing cortex, genes targeted by satb2 based on chip-seq data, and functionally affected when satb2 is not expressed based on differential expression analysis using rna-seq data, show strong enrichment for genes associated with ea. for genes expressed in the hippocampus or at the synapse, those targeted by satb2 are more strongly enriched for genes associated ea than gene-sets not targeted by satb2. this study demonstrates that single gene findings from gwas can provide important insights to pathobiological processes. in this case we find evidence that genes influenced by satb2 and involved in synaptic transmission, axon guidance and formation of the corpus callosum are contributing to schizophrenia and cognition.",
            "contribution_ids": [
                "R168829",
                "R168830",
                "R168831",
                "R168832"
            ]
        },
        {
            "instance_id": "EMPTYxR147402",
            "comparison_id": "EMPTY",
            "paper_id": "R147402",
            "text": "Pegmatite spectral behavior considering ASTER and Landsat 8 OLI data in Naipa and Muiane mines (Alto Ligonha, Mozambique) the naipa and muiane mines are located on the nampula complex, a stratigraphic tectonic subdivision of the mozambique belt, in the alto ligonha region. the pegmatites are of the li-cs-ta type, intrude a chlorite phyllite and gneisses with amphibole and biotite. the mines are still active. the main objective of this work was to analyze the pegmatite\u2019s spectral behavior considering aster and landsat 8 oli data. an aster image from 27/05/2005, and an image landsat oli image from 02/02/2018 were considered. the data were radiometric calibrated and after atmospheric corrected considered the dark object subtraction algorithm available in the semi-automatic classification plugin accessible in qgis software. in the field, samples were collected from lepidolite waste pile in naipa and muaine mines. a spectroadiometer was used in order to analyze the spectral behavior of several pegmatite\u2019s samples collected in the field in alto ligonha (naipa and muiane mines). in addition, qgis software was also used for the spectral mapping of the hypothetical hydrothermal alterations associated with occurrences of basic metals, beryl gemstones, tourmalines, columbite-tantalites, and lithium minerals. a supervised classification algorithm was employed - spectral angle mapper for the data processing, and the overall accuracy achieved was 80%. the integration of aster and landsat 8 oli data have proved very useful for pegmatite\u2019s mapping. from the results obtained, we can conclude that: (i) the combination of aster and landsat 8 oli data allows us to obtain more information about mineral composition than just one sensor, i.e., these two sensors are complementary; (ii) the alteration spots identified in the mines area are composed of clay minerals. in the future, more data and others image processing algorithms can be applied in order to identify the different lithium minerals, as spodumene, petalite, amblygonite and lepidolite.",
            "contribution_ids": [
                "R147404"
            ]
        },
        {
            "instance_id": "EMPTYxR169492",
            "comparison_id": "EMPTY",
            "paper_id": "R169492",
            "text": "The Local Effects of Ovarian Diathermy in an Ovine Model of Polycystic Ovary Syndrome in order to develop a medical alternative to surgical ovarian diathermy (od) in polycystic ovary syndrome (pcos) more mechanistic information is required about od. we therefore studied the cellular, molecular and vascular effects of diathermy on the ovary using an established ovine model of pcos. pregnant sheep were treated twice weekly with testosterone propionate (100 mg) from day 30\u2013100 gestation. their female offspring (n\\u200a=\\u200a12) were studied during their second breeding season when the pcos-like phenotype, with anovulation, is fully manifest. in one group (n\\u200a=\\u200a4) one ovary underwent diathermy and it was collected and compared to the contralateral ovary after 24 hours. in another group a treatment pcos cohort underwent diathermy (n\\u200a=\\u200a4) and the ovaries were collected and compared to the control pcos cohort (n\\u200a=\\u200a4) after 5 weeks. ovarian vascular indices were measured using contrast-enhanced ultrasound and colour doppler before, immediately after, 24 hours and five weeks after diathermy. antral follicles were assessed by immunohistochemistry and ovarian stromal gene expression by quantitative rt-pcr 24 hours and 5 weeks after diathermy. diathermy increased follicular atresia (p<0.05) and reduced antral follicle numbers after 5 weeks (p<0.05). there was an increase in stromal ccl2 expression 24 hours after diathermy (p<0.01) but no alteration in inflammatory indices at 5 weeks. immediately after diathermy there was increased microbubble transit time in the ovarian microvasculature (p\\u200a=\\u200a0.05) but this was not seen at 24 hours. however 24 hours after diathermy there was a reduction in the stromal doppler blood flow signal (p<0.05) and an increased ovarian resistance index (p<0.05) both of which persisted at 5 weeks (p<0.01; p<0.05). in the ovine model of pcos, od causes a sustained reduction in ovarian stromal blood flow with an increased ovarian artery resistance index associated with atresia of antral follicles.",
            "contribution_ids": [
                "R169493",
                "R169494",
                "R169495",
                "R169496",
                "R169497"
            ]
        },
        {
            "instance_id": "EMPTYxR171028",
            "comparison_id": "EMPTY",
            "paper_id": "R171028",
            "text": "Expectant Mothers Maximizing Opportunities: Maternal Characteristics Moderate Multifactorial Prenatal Stress in the Prediction of Birth Weight in a Sample of Children Adopted at Birth background mothers\u2019 stress in pregnancy is considered an environmental risk factor in child development. multiple stressors may combine to increase risk, and maternal personal characteristics may offset the effects of stress. this study aimed to test the effect of 1) multifactorial prenatal stress, integrating objective \u201cstressors\u201d and subjective \u201cdistress\u201d and 2) the moderating effects of maternal characteristics (perceived social support, self-esteem and specific personality traits) on infant birthweight. method hierarchical regression modeling was used to examine cross-sectional data on 403 birth mothers and their newborns from an adoption study. results distress during pregnancy showed a statistically significant association with birthweight (r2 = 0.032, f (2, 398) = 6.782, p = .001). the hierarchical regression model revealed an almost two-fold increase in variance of birthweight predicted by stressors as compared with distress measures (r2 \u03b4 = 0.049, f (4, 394) = 5.339, p < .001). further, maternal characteristics moderated this association (r2 \u03b4 = 0.031, f (4, 389) = 3.413, p = .009). specifically, the expected benefit to birthweight as a function of higher ses was observed only for mothers with lower levels of harm-avoidance and higher levels of perceived social support. importantly, the results were not better explained by prematurity, pregnancy complications, exposure to drugs, alcohol or environmental toxins. conclusions the findings support multidimensional theoretical models of prenatal stress. although both objective stressors and subjectively measured distress predict birthweight, they should be considered distinct and cumulative components of stress. this study further highlights that jointly considering risk factors and protective factors in pregnancy improves the ability to predict birthweight.",
            "contribution_ids": [
                "R171029"
            ]
        },
        {
            "instance_id": "EMPTYxR139226",
            "comparison_id": "EMPTY",
            "paper_id": "R139226",
            "text": "Affiliation policy rhetoric and reality in the Ghanaian higher education context abstract the present affiliation policy regime of ghana\u2019s higher education system has existed for more than two decades. however, empirical studies to examine the policy rhetoric and reality with regard to building quality assurance capacity in mentored institutions appear non-existent. this paper is based on an illustrative qualitative case study undertaken to examine the achievements and challenges of implementing the policy to build internal quality assurance capacities in mentored institutions. the study was guided by institutional theory using 12 key informant in-depth interviews and document reviews as data collection sources. the findings indicate a minimal achievement of the policy intent on internal quality assurance capacity building due to key implementation challenges such as a tripartite relationship structure; increasing cost on mentored institutions and increasing workload on mentor institutions. the study concludes that the gap between the policy rhetoric and reality in the studied mentored institutions appears undesirable and requires stakeholders\u2019 attention.",
            "contribution_ids": [
                "R139228"
            ]
        },
        {
            "instance_id": "EMPTYxR170892",
            "comparison_id": "EMPTY",
            "paper_id": "R170892",
            "text": "The Effect of Personality on Daily Life Emotional Processes personality features are associated with individual differences in daily emotional life, such as negative and positive affectivity, affect variability and affect reactivity. the existing literature is somewhat mixed and inconclusive about the nature of these associations. the aim of this study was to shed light on what personality features represent in daily life by investigating the effect of the five factor traits on different daily emotional processes using an ecologically valid method. the experience sampling method was used to collect repeated reports of daily affect and experiences from 104 healthy university students during one week of their normal lives. personality traits of the five factor model were assessed using neo five factor inventory. hierarchical linear modeling was used to analyze the effect of the personality traits on daily emotional processes. neuroticism predicted higher negative and lower positive affect, higher affect variability, more negative subjective evaluations of daily incidents, and higher reactivity to stressors. conscientiousness, by contrast, predicted lower average level, variability, and reactivity of negative affect. agreeableness was associated with higher positive and lower negative affect, lower variability of sadness, and more positive subjective evaluations of daily incidents. extraversion predicted higher positive affect and more positive subjective evaluations of daily activities. openness had no effect on average level of affect, but predicted higher reactivity to daily stressors. the results show that the personality features independently predict different aspects of daily emotional processes. neuroticism was associated with all of the processes. identifying these processes can help us to better understand individual differences in daily emotional life.",
            "contribution_ids": [
                "R170893"
            ]
        },
        {
            "instance_id": "EMPTYxR74723",
            "comparison_id": "EMPTY",
            "paper_id": "R74723",
            "text": "Disability, Mobility and Transport in Low- and Middle-Income Countries: A Thematic Review this paper discusses issues affecting the transport and mobility needs of people with disabilities in middle- and low-income countries and how disability intersects with a range of other factors to impact on transport needs, use and engagement. the paper is intended to stimulate discussion and identify areas for further research, and identifies a number of key issues that are salient to discussions around equitable and inclusive transport provision, including patterns of transport use, behaviour and experiences, solutions and policy directions, measuring access and inclusion, policies and intersectionality. the paper also identifies gaps in knowledge and provision, barriers to addressing these gaps, and some possible solutions to overcoming these barriers. these include shifting the focus from access to inclusion, reconceptualising how \u2018special\u2019 transport might be provided, and most importantly listening to the voices and experiences of adults and children with disabilities. despite lack of transport often being cited as a reason for lack of inclusion of people with disabilities, there is surprisingly little evidence which either quantifies this or translates what this lack of access means to people with disabilities in their daily lives in low- and middle-income countries.",
            "contribution_ids": [
                "R74725"
            ]
        },
        {
            "instance_id": "EMPTYxR109012",
            "comparison_id": "EMPTY",
            "paper_id": "R109012",
            "text": "Drug-Drug Interaction Prediction Based on Knowledge Graph Embeddings and Convolutional-LSTM Network interference between pharmacological substances can cause serious medical injuries. correctly predicting so-called drug-drug interactions (ddi) does not only reduce these cases but can also result in a reduction of drug development cost. presently, most drug-related knowledge is the result of clinical evaluations and post-marketing surveillance; resulting in a limited amount of information. existing data-driven prediction approaches for ddis typically rely on a single source of information, while using information from multiple sources would help improve predictions. machine learning (ml) techniques are used, but the techniques are often unable to deal with skewness in the data. hence, we propose a new ml approach for predicting ddis based on multiple data sources. for this task, we use 12,000 drug features from drugbank, pharmgkb, and kegg drugs, which are integrated using knowledge graphs (kgs). to train our prediction model, we first embed the nodes in the graph using various embedding approaches. we found that the best performing combination was a complex embedding method creating using pytorch-biggraph (pbg) with a convolutional-lstm network and classic machine learning-based prediction models. the model averaging ensemble method of three best classifiers yields up to 0.94, 0.92, 0.80 for aupr, f1 f1-score, and mcc, respectively during 5-fold cross-validation tests.",
            "contribution_ids": [
                "R109014"
            ]
        },
        {
            "instance_id": "EMPTYxR171505",
            "comparison_id": "EMPTY",
            "paper_id": "R171505",
            "text": "Association of loneliness with all-cause mortality: A meta-analysis introduction loneliness has social and health implications. the aim of this article is to evaluate the association of loneliness with all-cause mortality. methods pubmed, psycinfo, cinahl and scopus databases were searched through june 2016 for published articles that measured loneliness and mortality. the main characteristics and the effect size values of each article were extracted. moreover, an evaluation of the quality of the articles included was also carried out. a meta-analysis was performed firstly with all the included articles and secondly separating by gender, using a random effects model. results a total of 35 articles involving 77220 participants were included in the systematic review. loneliness is a risk factor for all-cause mortality [pooled hr = 1.22, 95% ci = (1.10, 1.35), p < 0.001] for both genders together, and for women [pooled hr = 1.26, 95% ci = (1.07, 1.48); p = 0.005] and men [pooled hr = 1.44; 95% ci = (1.19, 1.76); p < 0.001] separately. conclusions loneliness shows a harmful effect for all-cause mortality and this effect is slightly stronger in men than in women. moreover, the impact of loneliness was independent from the quality evaluation of each article and the effect of depression.",
            "contribution_ids": [
                "R171506"
            ]
        },
        {
            "instance_id": "EMPTYxR134713",
            "comparison_id": "EMPTY",
            "paper_id": "R134713",
            "text": "Going deeper with Image Transformers transformers have been recently adapted for large scale image classification, achieving high scores shaking up the long supremacy of convolutional neural networks. however the optimization of vision transformers has been little studied so far. in this work, we build and optimize deeper transformer networks for image classification. in particular, we investigate the interplay of architecture and optimization of such dedicated transformers. we make two architecture changes that significantly improve the accuracy of deep transformers. this leads us to produce models whose performance does not saturate early with more depth, for in-stance we obtain 86.5% top-1 accuracy on imagenet when training with no external data, we thus attain the current sate of the art with less floating-point operations and parameters. our best model establishes the new state of the art on imagenet with reassessed labels and imagenet-v2 / match frequency, in the setting with no additional training data. we share our code and models1.",
            "contribution_ids": [
                "R134714",
                "R134727",
                "R134735",
                "R134739",
                "R134743",
                "R134747",
                "R134751",
                "R134755",
                "R134759",
                "R134763",
                "R134767",
                "R134771"
            ]
        },
        {
            "instance_id": "EMPTYxR74479",
            "comparison_id": "EMPTY",
            "paper_id": "R74479",
            "text": "Contribution of big data in E-learning. A methodology to process academic data from heterogeneous sources big data covers a wide spectrum of technologies, which tends to support the processing of big amounts of heterogeneous data. the paper identifies the powerful benefits and the application areas of big data in the on-line education context. considering the boom of academic services on-line, and the free access to the educative content, a great amount of data is being generated in the formal educational field as well as in less formal contexts. in this sense, big data can help stakeholders, involved in education decision making, to reach the objective of improving the quality of education and the learning outcomes. in this paper, a methodology is proposed to process big amounts of data coming from the educational field. the current study ends with a specific case study where the data of a well-known ecuadorian institution that has more than 80 branches is analyzed.",
            "contribution_ids": [
                "R74480",
                "R109110"
            ]
        },
        {
            "instance_id": "EMPTYxR170715",
            "comparison_id": "EMPTY",
            "paper_id": "R170715",
            "text": "Enrichment and Training Improve Cognition in Rats with Cortical Malformations children with malformations of cortical development (mcd) frequently have associated cognitive impairments which reduce quality of life. we hypothesized that cognitive deficits associated with mcd can be improved with environmental manipulation or additional training. the e17 methylazoxymethanol acetate (mam) exposure model bears many anatomical hallmarks seen in human mcds as well as similar behavioral and cognitive deficits. we divided control and mam exposed sprague-dawley rats into enriched and non-enriched groups and tested performance in the morris water maze. another group similarly divided underwent sociability testing and also underwent magnetic resonance imaging (mri) scans pre and post enrichment. a third group of control and mam rats without enrichment were trained until they reached criterion on the place avoidance task. mam rats had impaired performance on spatial tasks and enrichment improved performance of both control and mam animals. although mam rats did not have a deficit in sociability they showed similar improvement with enrichment as controls. mri revealed a whole brain volume decrease with mam exposure, and an increase in both mam and control enriched volumes in comparison to non-enriched animals. in the place avoidance task, mam rats required approximately 3 times as long to reach criterion as control animals, but with additional training were able to reach control performance. environmental manipulation and additional training can improve cognition in a rodent mcd model. we therefore suggest that patients with mcd may benefit from appropriate alterations in educational strategies, social interaction and environment. these factors should be considered in therapeutic strategies.",
            "contribution_ids": [
                "R170716"
            ]
        },
        {
            "instance_id": "EMPTYxR110242",
            "comparison_id": "EMPTY",
            "paper_id": "R110242",
            "text": "Comparison, synthesis and evaluation of anticancer drug-loaded polymeric nanoparticles on breast cancer cell lines breast cancer is a major form of cancer, with a high mortality rate in women. it is crucial to achieve more efficient and safe anticancer drugs. recent developments in medical nanotechnology have resulted in novel advances in cancer drug delivery. cisplatin, doxorubicin, and 5-fluorouracil are three important anti-cancer drugs which have poor water-solubility. in this study, we used cisplatin, doxorubicin, and 5-fluorouracil-loaded polycaprolactone-polyethylene glycol (pcl-peg) nanoparticles to improve the stability and solubility of molecules in drug delivery systems. the nanoparticles were prepared by a double emulsion method and characterized with fourier transform infrared (ftir) spectroscopy and hydrogen-1 nuclear magnetic resonance (1hnmr). cells were treated with equal concentrations of cisplatin, doxorubicin and 5-fluorouracil-loaded pcl-peg nanoparticles, and free cisplatin, doxorubicin and 5-fluorouracil. the 3-[4,5-dimethylthiazol-2yl]-2,5-diphenyl tetrazolium bromide (mtt) assay confirmed that cisplatin, doxorubicin, and 5-fluorouracil-loaded pcl-peg nanoparticles enhanced cytotoxicity and drug delivery in t47d and mcf7 breast cancer cells. however, the ic50 value of doxorubicin was lower than the ic50 values of both cisplatin and 5-fluorouracil, where the difference was statistically considered significant (p\u02c20.05). however, the ic50 value of all drugs on t47d were lower than those on mcf7.",
            "contribution_ids": [
                "R110244"
            ]
        },
        {
            "instance_id": "EMPTYxR148626",
            "comparison_id": "EMPTY",
            "paper_id": "R148626",
            "text": "Dynamics of localized dissipative structures in a generalized Lugiato\u00e2\u0080\u0093Lefever model with negative quartic group-velocity dispersion we study localized dissipative structures in a generalized lugiato-lefever equation, exhibiting normal group-velocity dispersion and anomalous quartic group-velocity dispersion. in the conservative system, this parameter-regime has proven to enable generalized dispersion kerr solitons. here, we demonstrate via numerical simulations that our dissipative system also exhibits equivalent localized states, including special molecule-like two-color bound states recently reported. we investigate their generation, characterize the observed steady-state solution, and analyze their propagation dynamics under perturbations.",
            "contribution_ids": [
                "R148629"
            ]
        },
        {
            "instance_id": "EMPTYxR198706",
            "comparison_id": "EMPTY",
            "paper_id": "R198706",
            "text": "Challenging Incompleteness of Performance Requirements by Sentence Patterns performance requirements play an important role in software development. they describe system behavior that directly impacts the user experience. specifying performance requirements in a way that all necessary content is contained, i.e., the completeness of the individual requirements, is challenging, yet project critical. furthermore, it is still an open question, what content is necessary to make a performance requirement complete. to address this problem, we introduce a framework for specifying performance requirements. this framework (i) consists of a unified model derived from existing performance classifications, (ii) denotes completeness through a content model, and (iii) is operationalized through sentence patterns. we evaluate both the applicability of the framework as well as its ability uncover incompleteness with performance requirements taken from 11 industrial specifications. in our study, we were able to specify 86% of the examined performance requirements by means of our framework. furthermore, we show that 68% of the specified performance requirements are incomplete with respect to our notion of completeness. we argue that our framework provides an actionable definition of completeness for performance requirements.",
            "contribution_ids": [
                "R198708"
            ]
        },
        {
            "instance_id": "EMPTYxR170750",
            "comparison_id": "EMPTY",
            "paper_id": "R170750",
            "text": "Association between Socioeconomic Factors and Cancer Risk: A Population Cohort Study in Scotland (1991-2006) background lung and upper aero-digestive tract (uadt) cancer risk are associated with low socioeconomic circumstances and routinely measured using area socioeconomic indices. we investigated effect of country of birth, marital status, one area deprivation measure and individual socioeconomic variables (economic activity, education, occupational social class, car ownership, household tenure) on risk associated with lung, uadt and all cancer combined (excluding non melanoma skin cancer). methods we linked scottish longitudinal study and scottish cancer registry to follow 203,658 cohort members aged 15+ years from 1991\u20132006. relative risks (rr) were calculated using poisson regression models by sex offset for person-years of follow-up. results 21,832 first primary tumours (including 3,505 lung, 1,206 uadt) were diagnosed. regardless of cancer, economically inactivity (versus activity) was associated with increased risk (male: rr 1.14, 95% ci 1.10\u20131.18; female: rr 1.06, 95% ci 1.02\u20131.11). for lung cancer, area deprivation remained significant after full adjustment suggesting the area deprivation cannot be fully explained by individual variables. no or non degree qualification (versus degree) was associated with increased lung risk; likewise for uadt risk (females only). occupational social class associations were most pronounced and elevated for uadt risk. no car access (versus ownership) was associated with increased risk (excluding all cancer risk, males). renting (versus home ownership) was associated with increased lung cancer risk, uadt cancer risk (males only) and all cancer risk (females only). regardless of cancer group, elevated risk was associated with no education and living in deprived areas. conclusions different and independent socioeconomic variables are inversely associated with different cancer risks in both sexes; no one socioeconomic variable captures all aspects of socioeconomic circumstances or life course. association of multiple socioeconomic variables is likely to reflect the complexity and multifaceted nature of deprivation as well as the various roles of these dimensions over the life course.",
            "contribution_ids": [
                "R170751"
            ]
        },
        {
            "instance_id": "EMPTYxR155854",
            "comparison_id": "EMPTY",
            "paper_id": "R155854",
            "text": "Visible Light Photoredox Catalysis with Transition Metal Complexes: Applications in Organic Synthesis a fundamental aim in the field of catalysis is the development of new modes of small molecule activation. one approach toward the catalytic activation of organic molecules that has received much attention recently is visible light photoredox catalysis. in a general sense, this approach relies on the ability of metal complexes and organic dyes to engage in single-electron-transfer (set) processes with organic substrates upon photoexcitation with visible light. \\n \\nmany of the most commonly employed visible light photocatalysts are polypyridyl complexes of ruthenium and iridium, and are typified by the complex tris(2,2\u2032-bipyridine) ruthenium(ii), or ru(bpy)32+ (figure 1). these complexes absorb light in the visible region of the electromagnetic spectrum to give stable, long-lived photoexcited states.1,2 the lifetime of the excited species is sufficiently long (1100 ns for ru(bpy)32+) that it may engage in bimolecular electron-transfer reactions in competition with deactivation pathways.3 although these species are poor single-electron oxidants and reductants in the ground state, excitation of an electron affords excited states that are very potent single-electron-transfer reagents. importantly, the conversion of these bench stable, benign catalysts to redox-active species upon irradiation with simple household lightbulbs represents a remarkably chemoselective trigger to induce unique and valuable catalytic processes. \\n \\n \\n \\nfigure 1 \\n \\nruthenium polypyridyl complexes: versatile visible light photocatalysts. \\n \\n \\n \\nthe ability of ru(bpy)32+ and related complexes to function as visible light photocatalysts has been recognized and extensively investigated for applications in inorganic and materials chemistry. in particular, photoredox catalysts have been utilized to accomplish the splitting of water into hydrogen and oxygen4 and the reduction of carbon dioxide to methane.5 ru(bpy)32+ and its analogues have been used (i) as components of dye-sensitized solar cells6 and organic light-emitting diodes,7 (ii) to initiate polymerization reactions,8 and (iii) in photo-dynamic therapy.9 \\n \\nuntil recently, however, these complexes had been only sporadically employed as photocatalysts in the area of organic synthesis. the limited exploration of this area is perhaps surprising, as single-electron, radical processes have long been employed in c\u2013c bond construction and often provide access to reactivity that is complementary to that of closed-shell, two-electron pathways.10 in 2008, concurrent reports from the yoon group and our own lab detailed the use of ru(bpy)32+ as a visible light photoredox catalyst to perform a [2 + 2] cycloaddition11 and an \u03b1-alkylation of aldehydes,12 respectively. shortly thereafter, stephenson and co-workers disclosed a photoredox reductive dehalogenation of activated alkyl halides mediated by the same catalyst.13 the combined efforts of these three research groups have helped to initiate a renewed interest in this field, prompting a diversity of studies into the utility of photoredox catalysis as a conceptually novel approach to synthetic organic reaction development. \\n \\nmuch of the promise of visible light photoredox catalysis hinges on its ability to achieve unique, if not exotic bond constructions that are not possible using established protocols. for instance, photoredox catalysis may be employed to perform overall redox neutral reactions. as both oxidants and reductants may be transiently generated in the same reaction vessel, photoredox approaches may be used to develop reactions requiring both the donation and the reception of electrons at disparate points in the reaction mechanism. this approach stands in contrast to methods requiring stoichiometric chemical oxidants and reductants, which are often incompatible with each other, as well as to electrochemical approaches, which are not amenable to redox neutral transformations. furthermore, single-electron-transfer events often provide access to radical ion intermediates having reactivity patterns fundamentally different from those of their ground electronic or excited states.14 access to these intermediates using other means of activation is often challenging or requires conditions under which their unique reactivity cannot be productively harnessed. \\n \\nat the same time, photoredox catalysts such as ru(bpy)32+ may also be employed to generate radicals for use in a diverse range of established radical chemistries. photoredox reactions occur under extremely mild conditions, with most reactions proceeding at room temperature without the need for highly reactive radical initiators. the irradiation source is typically a commercial household light bulb, a significant advantage over the specialized equipment required for processes employing high-energy ultraviolet (uv) light. additionally, because organic molecules generally do not absorb visible light, there is little potential for deleterious side reactions that might arise from photoexcitation of the substrate itself. finally, photoredox catalysts may be employed at very low loadings, with 1 mole % or less being typical. \\n \\nthis review will highlight the early work on the use of transition metal complexes as photoredox catalysts to promote reactions of organic compounds (prior to 2008), as well as cover the surge of work that has appeared since 2008. we have for the most part grouped reactions according to whether the organic substrate undergoes reduction, oxidation, or a redox neutral reaction and throughout have sought to highlight the variety of reactive intermediates that may be accessed via this general reaction manifold.15 \\n \\nstudies on the use of transition metal complexes as visible light photocatalysts for organic synthesis have benefited tremendously from advances in the related fields of organic and semiconductor photocatalysis. many organic molecules may function as visible light photocatalysts; analogous to metal complexes such as ru(bpy)32+, organic dyes such as eosin y, 9,10-dicyanoanthracene, and triphenylpyrylium salts absorb light in the visible region to give excited states capable of single-electron transfer. these catalysts have been employed to achieve a vast range of bond-forming reactions of broad utility in organic synthesis.16 visible light photocatalysis has also been carried out with heterogeneous semiconductors such as mesoporous carbon nitride17 and various metal oxides and sulfides.18 these approaches are often complementary to photoredox catalysis with transition metal-polypyridyl complexes, and we have referred to work in these areas when it is similar to the chemistry under discussion. however, an in-depth discussion of the extensive literature in these fields is outside the scope of this review, and readers are directed to existing reviews on these topics.16\u201318",
            "contribution_ids": [
                "R155856",
                "R155903"
            ]
        },
        {
            "instance_id": "EMPTYxR50589",
            "comparison_id": "EMPTY",
            "paper_id": "R50589",
            "text": "2,3-Pentandion [MAK Value Documentation in German language, 2017] 2,3-pentanedione [pentane-2,3-dione] \\n \\nthe german commission for the investigation of health hazards of chemical compounds in the work area has evaluated 2,3-pentanedione to derive a maximum concentration at the workplace (mak value), considering all toxicity endpoints. the critical effects of 2,3-pentanedione were inflammation, necrosis, ulceration and fibrosis in the lung and inflammation, exudates and metaplasia in the nasal cavity in rats and mice after inhalation for 14 days. in this study the noaec in rats was 49\\xa0ml/m3 and the loaec in mice was 49\\xa0ml/m3 for effects in the lung. the occurrence of fibrosis after only two weeks of inhalation is assessed as a severe effect. due to the structural similarity of 2,3-pentanedione to diacetyl (2,3-butanedione), which is responsible for bronchiolitis obliterans in popcorn workers, and the likeliness of lung effects in rodents, a mak value of 0.02\\xa0ml/m3 is set in analogy to diacetyl. as the critical effect is systemic, 2,3-pentanedione is assigned to peak limitation category ii. the excursion factor of 1 is set in analogy to diacetyl. skin contact may contribute significantly to systemic toxicity and 2,3-pentanedione is designated with an \u201ch\u201d. in analogy to diacetyl, skin sensitization (sh) is expected but not airway sensitization. because there are no studies on developmental toxicity, the substance is assigned to pregnancy risk group d. 2,3-pentanedione is neither genotoxic nor carcinogenic. \\n \\n \\nkeywords: \\n \\n2,3-pentandion; \\nacetylpropionyl; \\nwirkungsmechanismus; \\ntoxikokinetik; \\nmetabolismus; \\n(sub)akute toxizitat; \\n(sub)chronische toxizitat; \\nreizwirkung; \\nallergene wirkung; \\ngenotoxizitat; \\nspitzenbegrenzung; \\nfruchtschadigende wirkung; \\nkrebserzeugende wirkung; \\nkeimzellmutagene wirkung; \\nhautresorption; \\nsensibilisierende wirkung; \\narbeitsstoff; \\nmaximale arbeitsplatzkonzentration; \\nmak-wert; \\ntoxizitat; \\ngefahrstoff",
            "contribution_ids": [
                "R50591"
            ]
        },
        {
            "instance_id": "EMPTYxR110813",
            "comparison_id": "EMPTY",
            "paper_id": "R110813",
            "text": "Resveratrol loaded polymeric micelles for theranostic targeting of breast cancer cells treatment of breast cancer underwent extensive progress in recent years with molecularly targeted therapies. however, non-specific pharmaceutical approaches (chemotherapy) persist, inducing severe side-effects. phytochemicals provide a promising alternative for breast cancer prevention and treatment. specifically, resveratrol (res) is a plant-derived polyphenolic phytoalexin with potent biological activity but displays poor water solubility, limiting its clinical use. here we have developed a strategy for delivering res using a newly synthesized nano-carrier with the potential for both diagnosis and treatment. methods: res-loaded nanoparticles were synthesized by the emulsion method using pluronic f127 block copolymer and vitamin e-tpgs. nanoparticle characterization was performed by sem and tunable resistive pulse sensing. encapsulation efficiency (ee%) and drug loading (dl%) content were determined by analysis of the supernatant during synthesis. nanoparticle uptake kinetics in breast cancer cell lines mcf-7 and mda-mb-231 as well as in mcf-10a breast epithelial cells were evaluated by flow cytometry and the effects of res on cell viability via mtt assay. results: res-loaded nanoparticles with spherical shape and a dominant size of 179\u00b122 nm were produced. res was loaded with high ee of 73\u00b10.9% and dl content of 6.2\u00b10.1%. flow cytometry revealed higher uptake efficiency in breast cancer cells compared to the control. an mtt assay showed that res-loaded nanoparticles reduced the viability of breast cancer cells with no effect on the control cells. conclusions: these results demonstrate that the newly synthesized nanoparticle is a good model for the encapsulation of hydrophobic drugs. additionally, the nanoparticle delivers a natural compound and is highly effective and selective against breast cancer cells rendering this type of nanoparticle an excellent candidate for diagnosis and therapy of difficult to treat mammary malignancies.",
            "contribution_ids": [
                "R110815"
            ]
        },
        {
            "instance_id": "EMPTYxR194718",
            "comparison_id": "EMPTY",
            "paper_id": "R194718",
            "text": "MQALD: Evaluating the impact of modifiers in question answering over knowledge graphs question answering (qa) over knowledge graphs (kg) aims to develop a system that is capable of answering users\u2019 questions using the information coming from one or multiple knowledge graphs, like dbpedia, wikidata, and so on. question answering systems need to translate the user\u2019s question, written using natural language, into a query formulated through a specific data query language that is compliant with the underlying kg. this translation process is already non-trivial when trying to answer simple questions that involve a single triple pattern. it becomes even more troublesome when trying to cope with questions that require modifiers in the final query, i.e., aggregate functions, query forms, and so on. the attention over this last aspect is growing but has never been thoroughly addressed by the existing literature. starting from the latest advances in this field, we want to further step in this direction. this work aims to provide a publicly available dataset designed for evaluating the performance of a qa system in translating articulated questions into a specific data query language. this dataset has also been used to evaluate three qa systems available at the state of the art.",
            "contribution_ids": [
                "R194720"
            ]
        },
        {
            "instance_id": "EMPTYxR136019",
            "comparison_id": "EMPTY",
            "paper_id": "R136019",
            "text": "Ontology-based E-learning Content Recommender System for Addressing the Pure Cold-start Problem e-learning recommender systems are gaining significance nowadays due to its ability to enhance the learning experience by providing tailor-made services based on learner preferences. a personalized learning environment (ple) that automatically adapts to learner characteristics such as learning styles and knowledge level can recommend appropriate learning resources that would favor the learning process and improve learning outcomes. the pure cold-start problem is a relevant issue in ples, which arises due to the lack of prior information about the new learner in the ple to create appropriate recommendations. this article introduces a semantic framework based on ontology to address the pure cold-start problem in content recommenders. the ontology encapsulates the domain knowledge about the learners as well as learning objects (los). the semantic model that we built has been experimented with different combinations of the key learner parameters such as learning style, knowledge level, and background knowledge. the proposed framework utilizes these parameters to build natural learner groups from the learner ontology using sparql queries. the ontology holds 480 learners\u2019 data, 468 annotated learning objects with 5,600 learner ratings. a multivariate k-means clustering algorithm, an unsupervised machine learning technique for grouping similar data, is used to evaluate the learner similarity computation accuracy. the learner satisfaction achieved with the proposed model is measured based on the ratings given by the 40 participants of the experiments. from the evaluation perspective, it is evident that 79% of the learners are satisfied with the recommendations generated by the proposed model in pure cold-start condition.",
            "contribution_ids": [
                "R136021"
            ]
        },
        {
            "instance_id": "EMPTYxR185333",
            "comparison_id": "EMPTY",
            "paper_id": "R185333",
            "text": "Mechanisms Underlying Interferon-\u00ce\u00b3-Induced Priming of Microglial Reactive Oxygen Species Production microglial priming and enhanced reactivity to secondary insults cause substantial neuronal damage and are hallmarks of brain aging, traumatic brain injury and neurodegenerative diseases. it is, thus, of particular interest to identify mechanisms involved in microglial priming. here, we demonstrate that priming of microglia with interferon-\u03b3 (ifn \u03b3) substantially enhanced production of reactive oxygen species (ros) following stimulation of microglia with atp. priming of microglial ros production was substantially reduced by inhibition of p38 mapk activity with sb203580, by increases in intracellular glutathione levels with n-acetyl-l-cysteine, by blockade of nadph oxidase subunit nox2 activity with gp91ds-tat or by inhibition of nitric oxide production with l-name. together, our data indicate that priming of microglial ros production involves reduction of intracellular glutathione levels, upregulation of nadph oxidase subunit nox2 and increases in nitric oxide production, and suggest that these simultaneously occurring processes result in enhanced production of neurotoxic peroxynitrite. furthermore, ifn\u03b3-induced priming of microglial ros production was reduced upon blockade of kir2.1 inward rectifier k+ channels with ml133. inhibitory effects of ml133 on microglial priming were mediated via regulation of intracellular glutathione levels and nitric oxide production. these data suggest that microglial kir2.1 channels may represent novel therapeutic targets to inhibit excessive ros production by primed microglia in brain pathology.",
            "contribution_ids": [
                "R185334"
            ]
        },
        {
            "instance_id": "EMPTYxR170680",
            "comparison_id": "EMPTY",
            "paper_id": "R170680",
            "text": "Chimpanzees Show a Developmental Increase in Susceptibility to Contagious Yawning: A Test of the Effect of Ontogeny and Emotional Closeness on Yawn Contagion contagious yawning has been reported for humans, dogs and several non-human primate species, and associated with empathy in humans and other primates. still, the function, development and underlying mechanisms of contagious yawning remain unclear. humans and dogs show a developmental increase in susceptibility to yawn contagion, with children showing an increase around the age of four, when also empathy-related behaviours and accurate identification of others\u2019 emotions begin to clearly evince. explicit tests of yawn contagion in non-human apes have only involved adult individuals and examined the existence of conspecific yawn contagion. here we report the first study of heterospecific contagious yawning in primates, and the ontogeny of susceptibility thereto in chimpanzees, pan troglodytes verus. we examined whether emotional closeness, defined as attachment history with the yawning model, affected the strength of contagion, and compared the contagiousness of yawning to nose-wiping. thirty-three orphaned chimpanzees observed an unfamiliar and familiar human (their surrogate human mother) yawn, gape and nose-wipe. yawning, but not nose-wiping, was contagious for juvenile chimpanzees, while infants were immune to contagion. like humans and dogs, chimpanzees are subject to a developmental trend in susceptibility to contagious yawning, and respond to heterospecific yawn stimuli. emotional closeness with the model did not affect contagion. the familiarity-biased social modulatory effect on yawn contagion previously found among some adult primates, seem to only emerge later in development, or be limited to interactions with conspecifics. the influence of the \u2018chameleon effect\u2019, targeted vs. generalised empathy, perspective-taking and visual attention on contagious yawning is discussed.",
            "contribution_ids": [
                "R170681",
                "R170682"
            ]
        },
        {
            "instance_id": "EMPTYxR187780",
            "comparison_id": "EMPTY",
            "paper_id": "R187780",
            "text": "The Impact of Open-Access Status on Journal Indices: Respiratory and Pulmonology Journals \\n background: \\n open access (oa) publishing is rapidly emerging in almost all disciplines,\\nwith variable intensity and effect on the discipline itself. the move toward oa is also observed in the\\nfield of respiratory and pulmonology, where both oa data repositories and oa journals are rapidly\\nemerging. \\n \\n \\n objective: \\n we aim to study the open-access status of respiratory and pulmonology journals and the\\nimpact of the open-access status on journal indices. \\n \\n \\n methods: \\n we collected journal\u2019s data from scopus source list on 1st of november 2018. we filtered\\nthe list for respiratory and pulmonology journals. open access journals covered by scopus are\\nrecognized as open access if the journal is listed in the directory of open access journals (doaj)\\nand/or the directory of open access scholarly resources (road). for each journal, we used\\nseveral metrics to measure its strength, and then we compared these metrics between oa and non-\\noa journals. \\n \\n \\n results: \\n there were 125 respiratory and pulmonology journals, a number that has increased by\\n12.6% since 2011. moreover, the percentage of oa journals has increased from 21.6% to 26.4%\\nduring the same period. non-oa journals have significantly higher scholarly output (p= 0.033), but\\noa journals have significantly higher percentage of citation (p= 0.05). \\n \\n \\n conclusion: \\n publishing in oa journals will yield a higher citation percentage compared to non-oa\\njournals. although this should not be the only reason to publish in an oa journal, it is still an\\nimportant factor to decide where to publish. \\n",
            "contribution_ids": [
                "R187782"
            ]
        },
        {
            "instance_id": "EMPTYxR170752",
            "comparison_id": "EMPTY",
            "paper_id": "R170752",
            "text": "Is Financial Hardship Associated with Reduced Health in Disability? The Case of Spinal Cord Injury in Switzerland objective to investigate socioeconomic inequalities in a comprehensive set of health indicators among persons with spinal cord injury in a wealthy country, switzerland. methods observational cross-sectional data from 1549 participants of the swiss spinal cord injury cohort study (swisci), aged over 16 years, and living in switzerland were analyzed. socioeconomic circumstances were operationalized by years of formal education, net equivalent household income and financial hardship. health indicators including secondary conditions, comorbidities, pain, mental health, participation and quality of life were used as outcomes. associations between socioeconomic circumstances and health indicators were evaluated using ordinal regressions. results financial hardship was consistently associated with more secondary conditions (or 3.37, 95% ci 2.18\u20135.21), comorbidities (or 2.88, 95% ci 1.83\u20134.53) and pain (or 3.32, 95% ci 2.21\u20134.99), whereas mental health (or 0.23, 95% ci 0.15\u20130.36), participation (or 0.30, 95% ci 0.21\u20130.43) and quality of life (or 0.22, 95% ci 0.15\u20130.33) were reduced. persons with higher education reported better mental health (or 1.04, 95% ci 1.00\u20131.07) and higher quality of life (or 1.06, 95% ci 1.02\u20131.09); other health indicators were not associated with education. household income was not related to any of the studied health indicators when models were controlled for financial hardship. conclusions suffering from financial hardship goes along with significant reductions in physical health, functioning and quality of life, even in a wealthy country with comprehensive social and health policies.",
            "contribution_ids": [
                "R170753",
                "R170754",
                "R170755"
            ]
        },
        {
            "instance_id": "EMPTYxR150069",
            "comparison_id": "EMPTY",
            "paper_id": "R150069",
            "text": "Contemporary factors influencing association conference attendance abstract competition amongst conference tourism destinations has intensified. understanding the factors influencing delegate attendance thus becomes increasingly important. this paper aims to extend the current body of academic knowledge by examining motivators and inhibitors deriving from not only previous academic research but also contemporary industry reports. delegate expectations relating to new and established factors influencing conference attendance are explored, while motivating and inhibiting factors are ranked in order of importance. proactive management and organization responses to these factors are proposed. the research findings are important to destination managers in prioritizing the investment of their limited resources aiming to address the higher-importance factors. this allows such destinations to improve in their competitiveness in attracting conference tourism and conference delegates.",
            "contribution_ids": [
                "R150071"
            ]
        },
        {
            "instance_id": "EMPTYxR191297",
            "comparison_id": "EMPTY",
            "paper_id": "R191297",
            "text": "Publicly Available Clinical BERT Embeddings contextual word embedding models such as elmo and bert have dramatically improved performance for many natural language processing (nlp) tasks in recent months. however, these models have been minimally explored on specialty corpora, such as clinical text; moreover, in the clinical domain, no publicly-available pre-trained bert models yet exist. in this work, we address this need by exploring and releasing bert models for clinical text: one for generic clinical text and another for discharge summaries specifically. we demonstrate that using a domain-specific model yields performance improvements on 3/5 clinical nlp tasks, establishing a new state-of-the-art on the mednli dataset. we find that these domain-specific models are not as performant on 2 clinical de-identification tasks, and argue that this is a natural consequence of the differences between de-identified source text and synthetically non de-identified task text.",
            "contribution_ids": [
                "R191299",
                "R191331"
            ]
        },
        {
            "instance_id": "EMPTYxR12100",
            "comparison_id": "EMPTY",
            "paper_id": "R12100",
            "text": "Supervised models for multimodal image retrieval based on visual, semantic and geographic information nowadays, large-scale networked social media need better search technologies to achieve suitable performance. multimodal approaches are promising technologies to improve image ranking. this is particularly true when metadata are not completely reliable, which is a rather common case as far as user annotation, time and location are concerned. in this paper, we propose to properly combine visual information with additional multi-faceted information, to define a novel multimodal similarity measure. more specifically, we combine visual features, which strongly relate to the image content, with semantic information represented by manually annotated concepts, and geo tagging, very often available in the form of object/subject location. furthermore, we propose a supervised machine learning approach, based on support vector machines (svms), to automatically learn optimized weights to combine the above features. the resulting models is used as a ranking function to sort the results of a multimodal query.",
            "contribution_ids": [
                "R12102",
                "R12103",
                "R12104"
            ]
        },
        {
            "instance_id": "EMPTYxR194428",
            "comparison_id": "EMPTY",
            "paper_id": "R194428",
            "text": "Predicting How to Test Requirements: An Automated Approach an important task in requirements engineering is to identify and determine how to verify a requirement (e.g., by manual review, testing, or simulation; also called potential verification method). this information is required to effectively create test cases and verification plans for requirements. [objective] in this paper, we propose an automatic approach to classify natural language requirements with respect to their potential verification methods (pvm). [method] our approach uses a convolutional neural network architecture to implement a multiclass and multilabel classifier that assigns probabilities to a predefined set of six possible verification methods, which we derived from an industrial guideline. additionally, we implemented a backtracing approach to analyze and visualize the reasons for the network\u2019s decisions. [results] in a 10-fold cross validation on a set of about 27,000 industrial requirements, our approach achieved a macro averaged f1 score of 0.79 across all labels. for the classification into test or non-test, the approach achieves an even higher f1 score of 0.94. [conclusions] the results show that our approach might help to increase the quality of requirements specifications with respect to the pvm attribute and guide engineers in effectively deriving test cases and verification plans.",
            "contribution_ids": [
                "R194430"
            ]
        },
        {
            "instance_id": "EMPTYxR193718",
            "comparison_id": "EMPTY",
            "paper_id": "R193718",
            "text": "Modelling compression with discourse constraints sentence compression holds promise for many applications ranging from summarisation to subtitle generation and subtitle generation. the task is typically performed on isolated sentences without taking the surrounding context into account, even though most applications would operate over entire documents. in this paper we present a discourse informed model which is capable of producing document compressions that are coherent and informative. our model is inspired by theories of local coherence and formulated within the framework of integer linear programming. experimental results show significant improvements over a stateof-the-art discourse agnostic approach.",
            "contribution_ids": [
                "R193720"
            ]
        },
        {
            "instance_id": "EMPTYxR169642",
            "comparison_id": "EMPTY",
            "paper_id": "R169642",
            "text": "Profiling the Succession of Bacterial Communities throughout the Life Stages of a Higher Termite Nasutitermes arborum (Termitidae, Nasutitermitinae) Using 16S rRNA Gene Pyrosequencing previous surveys of the gut microbiota of termites have been limited to the worker caste. termite gut microbiota has been well documented over the last decades and consists mainly of lineages specific to the gut microbiome which are maintained across generations. despite this intimate relationship, little is known of how symbionts are transmitted to each generation of the host, especially in higher termites where proctodeal feeding has never been reported. the bacterial succession across life stages of the wood-feeding higher termite nasutitermes arborum was characterized by 16s rrna gene deep sequencing. the microbial community in the eggs, mainly affiliated to proteobacteria and actinobacteria, was markedly different from the communities in the following developmental stages. in the first instar and last instar larvae and worker caste termites, proteobacteria and actinobacteria were less abundant than firmicutes, bacteroidetes, spirochaetes, fibrobacteres and the candidate phylum tg3 from the last instar larvae. most of the representatives of these phyla (except firmicutes) were identified as termite-gut specific lineages, although their relative abundances differed. the most salient difference between last instar larvae and worker caste termites was the very high proportion of spirochaetes, most of which were affiliated to the treponema ic, ia and if subclusters, in workers. the results suggest that termite symbionts are not transmitted from mother to offspring but become established by a gradual process allowing the offspring to have access to the bulk of the microbiota prior to the emergence of workers, and, therefore, presumably through social exchanges with nursing workers.",
            "contribution_ids": [
                "R169643",
                "R169644",
                "R169645",
                "R169646"
            ]
        },
        {
            "instance_id": "EMPTYxR171459",
            "comparison_id": "EMPTY",
            "paper_id": "R171459",
            "text": "Recurrence analysis of ant activity patterns in this study, we used recurrence quantification analysis (rqa) and recurrence plots (rps) to compare the movement activity of individual workers of three ant species, as well as a gregarious beetle species. rqa and rps quantify the number and duration of recurrences of a dynamical system, including a detailed quantification of signals that could be stochastic, deterministic, or both. first, we found substantial differences between the activity dynamics of beetles and ants, with the results suggesting that the beetles have quasi-periodic dynamics and the ants do not. second, workers from different ant species varied with respect to their dynamics, presenting degrees of predictability as well as stochastic signals. finally, differences were found among minor and major caste of the same (dimorphic) ant species. our results underscore the potential of rqa and rps in the analysis of complex behavioral patterns, as well as in general inferences on animal behavior and other biological phenomena.",
            "contribution_ids": [
                "R171460",
                "R171461"
            ]
        },
        {
            "instance_id": "EMPTYxR196615",
            "comparison_id": "EMPTY",
            "paper_id": "R196615",
            "text": "Heterogeneous Social Linked Data Integration and Sharing for Public Transportation solid (social linked data) technology has made significant progress in social web applications developed, such as facebook, twitter, and wikipedia. solid is based on semantic web and rdf (resource description framework) technologies. solid platforms can provide decentralized authentication, data management, and developer support in the form of libraries and web applications. however, thus far, little research has been conducted on understanding the problems involved in sharing public transportation data through solid technology. it is challenging to provide personalized and adaptable public transportation services for citizens because the public transportation data originate from different devices and are heterogeneous in nature. a novel approach is proposed in this study, in order to provide personalized sharing of public transportation data between different users through integrating and sharing these heterogeneous data. this approach not only integrates diverse data types into a uniform data type using the semantic web but also stores these data in a personal online data store and retrieves data through sparql on the solid platform; these data are visualized on the web pages using google maps. to the best of our knowledge, we are the first to apply solid in public transportation. furthermore, we conduct performance tests of the new c2rmf (csv to rdf mapping file) algorithm and functional and non-functional tests to demonstrate the stability and effectiveness of the approach. our results indicate the feasibility of the proposed approach in facilitating public transportation data integration and sharing through solid and semantic web technologies.",
            "contribution_ids": [
                "R196618"
            ]
        },
        {
            "instance_id": "EMPTYxR110005",
            "comparison_id": "EMPTY",
            "paper_id": "R110005",
            "text": "New Technique to Determine the Total Organic Carbon Based on Well Logs Using Artificial Neural Network (White Box) abstract \\n total organic carbon (toc) is the amount of carbon present in an organic compound and is often used as an essential factor for unconventional shale resources evaluation. the previous models for toc determination were either based on density log data only and considered the presence of organic matter is proportional to the bulk density, or based on resistivity log, sonic or density logs as well as the formation level of maturity (lom), where these models assumed a linear relation between resistivity and porosity logs. the average absolute deviation (add) of the previous model was not less than 1.20wt% of toc with a coefficient of determination (r2) of less than 0.85. \\n the objective of this research is to develop new empirical correlation to determine the toc based on well logs using artificial neural network for barnett shale formation. core toc data (442 data point) and well logs (resistivity, gamma ray, sonic transit time, and bulk density) were used to develop the ann model. for the first time, the ann model will change to a white box by extracting the weights and biases of the model to form the empirical equation. \\n the results obtained showed that toc is strong function of bulk density, and moderate function of gamma ray, compressional sonic time, and week function of deep resistivity. the developed ann model is able to predict the toc based on conventional log data with high accuracy (the add is 0.91wt% of toc and r2 between estimated and actual toc is 0.93). the developed empirical equation for toc determination from the ann model outperformed the previous available models, which had an add of 1.20 wt% or more and r2 of less than 0.85. the developed toc model and equation can be applied using simple computer without the need for a specific software. \\n the novelty of this new research is the simplicity and high accuracy of the developed model for estimating the total organic carbon based on conventional log data. the developed empirical equation will help the geologists and reservoir engineers to predict the toc without the need for hard lab work or complicated softwares.",
            "contribution_ids": [
                "R110006"
            ]
        },
        {
            "instance_id": "EMPTYxR172170",
            "comparison_id": "EMPTY",
            "paper_id": "R172170",
            "text": "Are women more generous than men? A meta-analysis abstract we perform a meta analysis of gender differences in the standard windfall gains dictator game (dg) by collecting raw data from 53 studies with 117 conditions, giving us 15,016 unique individual observations. we find that women on average give 4 percentage points more than men (cohen\u2019s $$d=0.16$$ \\n \\n d \\n = \\n 0.16 \\n \\n ), and that this difference decreases to $$3.1\\\\%$$ \\n \\n 3.1 \\n % \\n \\n points (cohen\u2019s $$d=0.13$$ \\n \\n d \\n = \\n 0.13 \\n \\n ) if we exclude studies where dictators can only give all or nothing. the gender difference is larger if the recipient in the dg is a charity, compared to the standard dg with an anonymous individual as the recipient (a 10.9 versus a $$2.3\\\\%$$ \\n \\n 2.3 \\n % \\n \\n points gender difference). these effect sizes imply that many individual studies on gender differences are underpowered; the median power in our sample of standard dg studies is only $$9\\\\%$$ \\n \\n 9 \\n % \\n \\n to detect the meta-analytic gender difference at the $$5\\\\%$$ \\n \\n 5 \\n % \\n \\n significance level. moving forward on this topic, sample sizes should thus be substantially larger than what has been the norm in the past.",
            "contribution_ids": [
                "R172174"
            ]
        },
        {
            "instance_id": "EMPTYxR170874",
            "comparison_id": "EMPTY",
            "paper_id": "R170874",
            "text": "A \u00e2\u0080\u009cMigrant Friendly Hospital\u00e2\u0080\u009d Initiative in Geneva, Switzerland: Evaluation of the Effects on Staff Knowledge and Practices background international migration poses important challenges to european health care systems. the development of \u201cmigrant friendly hospitals\u201d has been identified as a priority in both europe and switzerland. methods a multi-pronged initiative was developed at geneva university hospitals (hug) to improve staff knowledge and use of existing \u201cmigrant friendly\u201d resources. a self-administered questionnaire was sent pre and post-intervention to random samples of 4 major professional groups with direct patient contact at the hug. the questionnaire assessed staff knowledge, attitudes and reported practices regarding the care of migrant patients. results overall response rate was 51% (n\\u200a=\\u200a1460) in 2010 but only 19% (n\\u200a=\\u200a761) in 2013 owing to an institutionally imposed change in survey method. despite these difficulties, and after adjusting for sample differences, we found that respondents in 2013 were significantly more likely to have received training in how to organize an appointment with an interpreter, how to work with an interpreter and about health and social services available for migrant patients. respondents were also significantly more likely to have used several migrant friendly structures at the hug. use of, preference for and perceived skill at working with professional interpreters all improved, and respondents were both more likely to be encouraged by their supervisors to use professional interpreters, and less likely to be encouraged to look for alternative solutions for communicating with non francophone patients. finally, 2013 respondents encountered fewer difficulties caring for migrant patients, although lack of time and language barriers continued to be the most important sources of difficulty. conclusion our results suggest that an institution-wide information campaign may contribute to increased awareness and use of migrant friendly resources by clinical staff. hospital commitment and financing, along with inter-departmental participation in all activities were important in creating and maintaining project visibility, and in contributing to a migrant friendly institutional culture.",
            "contribution_ids": [
                "R170875"
            ]
        },
        {
            "instance_id": "EMPTYxR195679",
            "comparison_id": "EMPTY",
            "paper_id": "R195679",
            "text": "Reinforcing Security Requirements with Multifactor Quality Measurement choosing how to write natural language scenarios is challenging, because stakeholders may over-generalize their descriptions or overlook or be unaware of alternate scenarios. in security, for example, this can result in weak security constraints that are too general, or missing constraints. another challenge is that analysts are unclear on where to stop generating new scenarios. in this paper, we introduce the multifactor quality method (mqm) to help requirements analysts to empirically collect system constraints in scenarios based on elicited expert preferences. the method combines quantitative statistical analysis to measure system quality with qualitative coding to extract new requirements. the method is bootstrapped with minimal analyst expertise in the domain affected by the quality area, and then guides an analyst toward selecting expert-recommended requirements to monotonically increase system quality. we report the results of applying the method to security. this include 550 requirements elicited from 69 security experts during a bootstrapping stage, and subsequent evaluation of these results in a verification stage with 45 security experts to measure the overall improvement of the new requirements. security experts in our studies have an average of 10 years of experience. our results show that using our method, we detect an increase in the security quality ratings collected in the verification stage. finally, we discuss how our proposed method helps to improve security requirements elicitation, analysis, and measurement.",
            "contribution_ids": [
                "R195680"
            ]
        },
        {
            "instance_id": "EMPTYxR149058",
            "comparison_id": "EMPTY",
            "paper_id": "R149058",
            "text": "SCORVoc: vocabulary-based information integration and exchange in supply networks \"advanced, highly specialized economies require instant, robust and efficient information flows within its value-added and supply chain networks. especially also in the context of the recent industry 4.0, smart manufacturing or cyber-physical systems initiatives more efficient and effective information exchange in supply networks is of paramount importance. the supply chain operation reference (scor) is a cross-industry approach to lay the groundwork for this goal by defining a conceptual model for supply chain related information. semantics-based approaches could facilitate information flows in supply networks, and enable to analyze, monitor and optimize supply chains (in particular for robustness). this paper first reviews existing formalizations of the supply chain council's scor standard. it then introduces the scorvoc rdfs vocabulary which fully formalizes the latest scor standard, while over-coming the identified limitations of existing work. scorvoc is operationalized by a set of sparql queries, that enable to evaluate metrics and key performance indicator (kpis) defined by scor, on-the-fly, in an information systems that adheres to the vocabulary. finally, we define concrete test scenarios and implement a synthetic benchmark to demonstrate the practicality of scorvoc.\"",
            "contribution_ids": [
                "R149060"
            ]
        },
        {
            "instance_id": "EMPTYxR185380",
            "comparison_id": "EMPTY",
            "paper_id": "R185380",
            "text": "Estimating Uncertainty and Interpretability in Deep Learning for Coronavirus (COVID-19) Detection deep learning has achieved state of the art performance in medical imaging. however, these methods for disease detection focus exclusively on improving the accuracy of classification or predictions without quantifying uncertainty in a decision. knowing how much confidence there is in a computer-based medical diagnosis is essential for gaining clinicians trust in the technology and therefore improve treatment. today, the 2019 coronavirus (sars-cov-2) infections are a major healthcare challenge around the world. detecting covid-19 in x-ray images is crucial for diagnosis, assessment and treatment. however, diagnostic uncertainty in the report is a challenging and yet inevitable task for radiologist. in this paper, we investigate how drop-weights based bayesian convolutional neural networks (bcnn) can estimate uncertainty in deep learning solution to improve the diagnostic performance of the human-machine team using publicly available covid-19 chest x-ray dataset and show that the uncertainty in prediction is highly correlates with accuracy of prediction. we believe that the availability of uncertainty-aware deep learning solution will enable a wider adoption of artificial intelligence (ai) in a clinical setting.",
            "contribution_ids": [
                "R185381"
            ]
        },
        {
            "instance_id": "EMPTYxR170729",
            "comparison_id": "EMPTY",
            "paper_id": "R170729",
            "text": "Untangling the Influences of Voluntary Running, Environmental Complexity, Social Housing and Stress on Adult Hippocampal Neurogenesis environmental enrichment (ee) exerts powerful effects on brain physiology, and is widely used as an experimental and therapeutic tool. typical ee paradigms are multifactorial, incorporating elements of physical exercise, environmental complexity, social interactions and stress, however the specific contributions of these variables have not been separable using conventional housing paradigms. here, we evaluated the impacts of these individual variables on adult hippocampal neurogenesis by using a novel \u201calternating ee\u201d paradigm. for 4 weeks, adult male cd1 mice were alternated daily between two enriched environments; by comparing groups that differed in one of their two environments, the individual and combinatorial effects of ee variables could be resolved. the alternating ee paradigm revealed that (1) voluntary running for 3 days/week was sufficient to increase both mitotic and post-mitotic stages of hippocampal neurogenesis, confirming the central importance of exercise; (2) a complex environment (comprised of both social interactions and rotated inanimate objects) had no effect on neurogenesis itself, but enhanced depolarization-induced c-fos expression (attributable to social interactions) and buffered stress-induced plasma corticosterone levels (attributable to inanimate objects); and (3) neither social isolation, group housing, nor chronically increased levels of plasma corticosterone had a prolonged impact on neurogenesis. mouse strain, handling and type of running apparatus were tested and excluded as potential confounding factors. these findings provide valuable insights into the relative effects of key ee variables on adult neurogenesis, and this \u201calternating ee\u201d paradigm represents a useful tool for exploring the contributions of individual ee variables to mechanisms of neural plasticity.",
            "contribution_ids": [
                "R170730"
            ]
        },
        {
            "instance_id": "EMPTYxR209610",
            "comparison_id": "EMPTY",
            "paper_id": "R209610",
            "text": "SWAG: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference given a partial description like \u201cshe opened the hood of the car,\u201d humans can reason about the situation and anticipate what might come next (\u201dthen, she examined the engine\u201d). in this paper, we introduce the task of grounded commonsense inference, unifying natural language inference and commonsense reasoning. we present swag, a new dataset with 113k multiple choice questions about a rich spectrum of grounded situations. to address the recurring challenges of the annotation artifacts and human biases found in many existing datasets, we propose adversarial filtering (af), a novel procedure that constructs a de-biased dataset by iteratively training an ensemble of stylistic classifiers, and using them to filter the data. to account for the aggressive adversarial filtering, we use state-of-the-art language models to massively oversample a diverse set of potential counterfactuals. empirical results demonstrate that while humans can solve the resulting inference problems with high accuracy (88%), various competitive models struggle on our task. we provide comprehensive analysis that indicates significant opportunities for future research.",
            "contribution_ids": [
                "R209612"
            ]
        },
        {
            "instance_id": "EMPTYxR74446",
            "comparison_id": "EMPTY",
            "paper_id": "R74446",
            "text": "A user profile definition in context of recommendation of open educational resources. An approach based on linked open vocabularies open educational resources include a diverse range of materials making it the most representative icon arisen within the open content movement. users who access and use oers could be classified into one of these three groups: instructor, student and self-learner. to provide personalized lists of oers according to the user profile and personal preferences, the user should be characterized by an open and scalable model. in this paper, an open linked vocabulary is proposed to describe user profiles of the open educational resources, which take into account the challenges and opportunities that an open and extensible platform as the web can provide to learn about the oer users, and from this knowledge, offer the most appropriate resources.",
            "contribution_ids": [
                "R74447",
                "R109092"
            ]
        },
        {
            "instance_id": "EMPTYxR144869",
            "comparison_id": "EMPTY",
            "paper_id": "R144869",
            "text": "Arrays of Solar-Blind Ultraviolet Photodetector Based on \u00ce\u00b2-Ga2O3 Epitaxial Thin Films recently, the $\\\\beta $ -ga 2 o 3 -based solar-blind ultraviolet photodetector has attracted intensive attention due to its wide application prospects. photodetector arrays can act as an imaging detector and also improve the detecting sensitivity by series or parallel of detector cells. in this letter, the highly integrated metal-semiconductor-metal structured photodetector arrays of $32\\\\times 32$ , $16\\\\times 16$ , $8\\\\times 8$ , and $4\\\\times 4$ have been designed and fabricated for the first time. herein, we present a 4-1 photodetector cell chosen from a $4\\\\times 4$ photodetector array as an example to demonstrate the performance. the photo responsivity is $8.926 \\\\times 10^{-1}$ a/w @ 250 nm at a 10-v bias voltage, corresponding to a quantum efficiency of 444%. all of the photodetector cells exhibit the solar-blind ultraviolet photoelectric characteristic and the consistent photo responsivity with a standard deviation of 12.1%. the outcome of the study offers an efficient route toward the development of high-performance and low-cost duv photodetector arrays.",
            "contribution_ids": [
                "R144872"
            ]
        },
        {
            "instance_id": "EMPTYxR146689",
            "comparison_id": "EMPTY",
            "paper_id": "R146689",
            "text": "A Novel Method for Measuring the Timing of Heart Sound Components through Digital Phonocardiography the auscultation of heart sounds has been for decades a fundamental diagnostic tool in clinical practice. higher effectiveness can be achieved by recording the corresponding biomedical signal, namely the phonocardiographic signal, and processing it by means of traditional signal processing techniques. an unavoidable processing step is the heart sound segmentation, which is still a challenging task from a technical viewpoint\u2014a limitation of state-of-the-art approaches is the unavailability of trustworthy techniques for the detection of heart sound components. the aim of this work is to design a reliable algorithm for the identification and the classification of heart sounds\u2019 main components. the proposed methodology was tested on a sample population of 24 healthy subjects over 10-min-long simultaneous electrocardiographic and phonocardiographic recordings and it was found capable of correctly detecting and classifying an average of 99.2% of the heart sounds along with their components. moreover, the delay of each component with respect to the corresponding r-wave peak and the delay among the components of the same heart sound were computed: the resulting experimental values are coherent with what is expected from the literature and what was obtained by other studies.",
            "contribution_ids": [
                "R146693"
            ]
        },
        {
            "instance_id": "EMPTYxR197050",
            "comparison_id": "EMPTY",
            "paper_id": "R197050",
            "text": "Automatic Speech Recognition Datasets in Cantonese: A Survey and New Dataset automatic speech recognition (asr) on low resource languages improves the access of linguistic minorities to technological advantages provided by artificial intelligence (ai). in this paper, we address the problem of data scarcity for the hong kong cantonese language by creating a new cantonese dataset. our dataset, multi-domain cantonese corpus (mdcc), consists of 73.6 hours of clean read speech paired with transcripts, collected from cantonese audiobooks from hong kong. it comprises philosophy, politics, education, culture, lifestyle and family domains, covering a wide range of topics. we also review all existing cantonese datasets and analyze them according to their speech type, data source, total size and availability. we further conduct experiments with fairseq s2t transformer, a state-of-the-art asr model, on the biggest existing dataset, common voice zh-hk, and our proposed mdcc, and the results show the effectiveness of our dataset. in addition, we create a powerful and robust cantonese asr model by applying multi-dataset learning on mdcc and common voice zh-hk.",
            "contribution_ids": [
                "R197052"
            ]
        },
        {
            "instance_id": "EMPTYxR170771",
            "comparison_id": "EMPTY",
            "paper_id": "R170771",
            "text": "Multiple White Matter Volume Reductions in Patients with Panic Disorder: Relationships between Orbitofrontal Gyrus Volume and Symptom Severity and Social Dysfunction \"numerous brain regions are believed to be involved in the neuropathology of panic disorder (pd) including fronto-limbic regions, thalamus, brain stem, and cerebellum. however, while several previous studies have demonstrated volumetric gray matter reductions in these brain regions, there have been no studies evaluating volumetric white matter changes in the fiber bundles connecting these regions. in addition, although patients with pd typically exhibit social, interpersonal and occupational dysfunction, the neuropathologies underlying these dysfunctions remain unclear. a voxel-based morphometry study was conducted to evaluate differences in regional white matter volume between 40 patients with pd and 40 healthy control subjects (hc). correlation analyses were performed between the regional white matter volumes and patients' scores on the panic disorder severity scale (pdss) and the global assessment of functioning (gaf). patients with pd demonstrated significant volumetric reductions in widespread white matter regions including fronto-limbic, thalamo-cortical and cerebellar pathways (p<0.05, fdr corrected). furthermore, there was a significant negative relationship between right orbitofrontal gyrus (ofg) white matter volume and the severity of patients' clinical symptoms, as assessed with the pdss. a significant positive relationship was also observed between patients' right ofg volumes and their scores on the gaf. our results suggest that volumetric reductions in widespread white matter regions may play an important role in the pathology of pd. in particular, our results suggest that structural white matter abnormalities in the right ofg may contribute to the social, personal and occupational dysfunction typically experienced by patients with pd.\"",
            "contribution_ids": [
                "R170772",
                "R170773"
            ]
        },
        {
            "instance_id": "EMPTYxR78277",
            "comparison_id": "EMPTY",
            "paper_id": "R78277",
            "text": "BitConduite: Exploratory Visual Analysis of Entity Activity on the Bitcoin Network we present bitconduite, a visual analytics approach for explorative analysis of financial activity within the bitcoin network, offering a view on transactions aggregated by entities, i.e., by individuals, companies, or other groups actively using bitcoin. bitconduite makes bitcoin data accessible to nontechnical experts through a guided workflow around entities analyzed according to several activity metrics. analyses can be conducted at different scales, from large groups of entities down to single entities. bitconduite also enables analysts to cluster entities to identify groups of similar activities as well as to explore characteristics and temporal patterns of transactions. to assess the value of our approach, we collected feedback from domain experts.",
            "contribution_ids": [
                "R78279",
                "R78281"
            ]
        },
        {
            "instance_id": "EMPTYxR187763",
            "comparison_id": "EMPTY",
            "paper_id": "R187763",
            "text": "The open access advantage for studies of human electrophysiology: Impact on citations and Altmetrics barriers to accessing scientific findings contribute to knowledge inequalities based on financial resources and decrease the transparency and rigor of scientific research. recent initiatives aim to improve access to research as well as methodological rigor via transparency and openness. we sought to determine the impact of such initiatives on open access publishing in the sub-area of human electrophysiology and the impact of open access on the attention articles received in the scholarly literature and other outlets. data for 35,144 articles across 967 journals from the last 20 years were examined. approximately 35% of articles were open access, and the rate of publication of open-access articles increased over time. open access articles showed 9 to 21% more pubmed and crossref citations and 39% more altmetric mentions than closed access articles. green open access articles (i.e., author archived) did not differ from non-green open access articles (i.e., publisher archived) with respect to citations and were related to higher altmetric mentions. these findings demonstrate that open-access publishing is increasing in popularity in the sub-area of human electrophysiology and that open-access articles enjoy the \u201copen access advantage\u201d in citations similar to the larger scientific literature. the benefit of the open access advantage may motivate researchers to make their publications open access and pursue publication outlets that support it. in consideration of the direct connection between citations and journal impact factor, journal editors may improve the accessibility and impact of published articles by encouraging authors to self-archive manuscripts on preprint servers.",
            "contribution_ids": [
                "R187765",
                "R188828"
            ]
        },
        {
            "instance_id": "EMPTYxR44970",
            "comparison_id": "EMPTY",
            "paper_id": "R44970",
            "text": "Evaluation of geese theatre's re-connect program: Addressing resettlement issues in prison this study examined the impact of geese theatre\u2019s re-connect program on a sample of offenders who attended it. this program used theatre performance, experiential exercises, skills practice role-plays, and metaphors such as the masks to invite a group of offenders to consider and explore issues connected with their release and reconnecting with a life outside prison. pre- and postprogram psychometric tests, behavior ratings, and interviews were completed to assess the effectiveness of the program. significant changes were observed from pre- to posttreatment in terms of self-efficacy, motivation to change, and improved confidence in skills (i.e., social and friendship, occupational, family and intimacy, dealing with authority, alternatives to aggression or offending, and self-management and self-control skills). improved behavior and engagement within the program was observed over the 3 days of the program. interviews also revealed the positive impact the program had on the participants. this provides evidence supporting the short-term effectiveness of the re-connect program.",
            "contribution_ids": [
                "R44971"
            ]
        },
        {
            "instance_id": "EMPTYxR209426",
            "comparison_id": "EMPTY",
            "paper_id": "R209426",
            "text": "Optimal Placement of Accelerometers for the Detection of Everyday Activities this article describes an investigation to determine the optimal placement of accelerometers for the purpose of detecting a range of everyday activities. the paper investigates the effect of combining data from accelerometers placed at various bodily locations on the accuracy of activity detection. eight healthy males participated within the study. data were collected from six wireless tri-axial accelerometers placed at the chest, wrist, lower back, hip, thigh and foot. activities included walking, running on a motorized treadmill, sitting, lying, standing and walking up and down stairs. the support vector machine provided the most accurate detection of activities of all the machine learning algorithms investigated. although data from all locations provided similar levels of accuracy, the hip was the best single location to record data for activity detection using a support vector machine, providing small but significantly better accuracy than the other investigated locations. increasing the number of sensing locations from one to two or more statistically increased the accuracy of classification. there was no significant difference in accuracy when using two or more sensors. it was noted, however, that the difference in activity detection using single or multiple accelerometers may be more pronounced when trying to detect finer grain activities. future work shall therefore investigate the effects of accelerometer placement on a larger range of these activities.",
            "contribution_ids": [
                "R209427"
            ]
        },
        {
            "instance_id": "EMPTYxR134043",
            "comparison_id": "EMPTY",
            "paper_id": "R134043",
            "text": "Improving Computational Efficiency in Visual Reinforcement Learning via Stored Embeddings recent advances in off-policy deep reinforcement learning (rl) have led to impressive success in complex tasks from visual observations. experience replay improves sample-ef\ufb01ciency by reusing experiences from the past, and convolutional neural networks (cnns) process high-dimensional inputs effectively. however, such techniques demand high memory and computational bandwidth. in this paper, we present stored embeddings for ef\ufb01cient reinforcement learning (seer), a simple modi\ufb01cation of existing off-policy rl methods, to address these computational and memory requirements. to reduce the computational overhead of gradient updates in cnns, we freeze the lower layers of cnn encoders early in training due to early convergence of their parameters. additionally, we reduce memory requirements by storing the low-dimensional latent vectors for experience replay instead of high-dimensional images, enabling an adaptive increase in the replay buffer capacity, a useful technique in constrained-memory settings. in our experiments, we show that seer does not degrade the performance of rl agents while signi\ufb01cantly saving computation and memory across a diverse set of deepmind control environments and atari games.",
            "contribution_ids": [
                "R134044",
                "R134059"
            ]
        },
        {
            "instance_id": "EMPTYxR187629",
            "comparison_id": "EMPTY",
            "paper_id": "R187629",
            "text": "Gender Disparity in the Authorship of Biomedical Research Publications During the COVID-19 Pandemic: Retrospective Observational Study \\n background \\n gender imbalances in academia have been evident historically and persist today. for the past 60 years, we have witnessed the increase of participation of women in biomedical disciplines, showing that the gender gap is shrinking. however, preliminary evidence suggests that women, including female researchers, are disproportionately affected by the covid-19 pandemic in terms of unequal distribution of childcare, elderly care, and other kinds of domestic and emotional labor. sudden lockdowns and abrupt shifts in daily routines have had disproportionate consequences on their productivity, which is reflected by a sudden drop in research output in biomedical research, consequently affecting the number of female authors of scientific publications. \\n \\n \\n objective \\n the objective of this study is to test the hypothesis that the covid-19 pandemic has had a disproportionate adverse effect on the productivity of female researchers in the biomedical field in terms of authorship of scientific publications. \\n \\n \\n methods \\n this is a retrospective observational bibliometric study. we investigated the proportion of male and female researchers who published scientific papers during the covid-19 pandemic, using bibliometric data from biomedical preprint servers and selected springer-nature journals. we used the ordinary least squares regression model to estimate the expected proportions over time by correcting for temporal trends. we also used a set of statistical methods, such as the kolmogorov-smirnov test and regression discontinuity design, to test the validity of the results. \\n \\n \\n results \\n a total of 78,950 papers from the biorxiv and medrxiv repositories and from 62 selected springer-nature journals by 346,354 unique authors were analyzed. the acquired data set consisted of papers that were published between january 1, 2019, and august 2, 2020. the proportion of female first authors publishing in the biomedical field during the pandemic dropped by 9.1%, on average, across disciplines (expected arithmetic mean yest=0.39; observed arithmetic mean y=0.35; standard error of the estimate, sest=0.007; standard error of the observation, \u03c3x=0.004). the impact was particularly pronounced for papers related to covid-19 research, where the proportion of female scientists in the first author position dropped by 28% (yest=0.39; y=0.28; sest=0.007; \u03c3x=0.007). when looking at the last authors, the proportion of women dropped by 7.9%, on average (yest=0.25; y=0.23; sest=0.005; \u03c3x=0.003), while the proportion of women writing about covid-19 as the last author decreased by 18.8% (yest=0.25; y=0.21; sest=0.005; \u03c3x=0.007). further, by geocoding authors\u2019 affiliations, we showed that the gender disparities became even more apparent when disaggregated by country, up to 35% in some cases. \\n \\n \\n conclusions \\n our findings document a decrease in the number of publications by female authors in the biomedical field during the global pandemic. this effect was particularly pronounced for papers related to covid-19, indicating that women are producing fewer publications related to covid-19 research. this sudden increase in the gender gap was persistent across the 10 countries with the highest number of researchers. these results should be used to inform the scientific community of this worrying trend in covid-19 research and the disproportionate effect that the pandemic has had on female academics. \\n",
            "contribution_ids": [
                "R187634",
                "R187642",
                "R187645",
                "R187647",
                "R187656",
                "R187661"
            ]
        },
        {
            "instance_id": "EMPTYxR169531",
            "comparison_id": "EMPTY",
            "paper_id": "R169531",
            "text": "Biological Motion Primes the Animate/Inanimate Distinction in Infancy given that biological motion is both detected and preferred early in life, we tested the hypothesis that biological motion might be instrumental to infants\u2019 differentiation of animate and inanimate categories. infants were primed with either point-light displays of realistic biological motion, random motion, or schematic biological motion of an unfamiliar shape. after being habituated to these displays, 12-month-old infants categorized animals and vehicles as well as furniture and vehicles with the sequential touching task. the findings indicated that infants primed with point-light displays of realistic biological motion showed better categorization of animates than those exposed to random or schematic biological motion. these results suggest that human biological motion might be one of the motion cues that provide the building blocks for infants\u2019 concept of animacy.",
            "contribution_ids": [
                "R169532",
                "R169533",
                "R169534"
            ]
        },
        {
            "instance_id": "EMPTYxR144199",
            "comparison_id": "EMPTY",
            "paper_id": "R144199",
            "text": "Machine learning in remote sensing data processing remote sensing data processing deals with real-life applications with great societal values. for instance urban monitoring, fire detection or flood prediction from remotely sensed multispectral or radar images have a great impact on economical and environmental issues. to treat efficiently the acquired data and provide accurate products, remote sensing has evolved into a multidisciplinary field, where machine learning and signal processing algorithms play an important role nowadays. this paper serves as a survey of methods and applications, and reviews the latest methodological advances in machine learning for remote sensing data analysis.",
            "contribution_ids": [
                "R144201"
            ]
        },
        {
            "instance_id": "EMPTYxR110739",
            "comparison_id": "EMPTY",
            "paper_id": "R110739",
            "text": "Evaluation of sleep\u00e2\u0080\u0090disordered breathing and its relationship with respiratory parameters in children with mucopolysaccharidosis Type\n            IVA\n            and\n            VI the aims of the study were to evaluate the prevalence of sleep\u2010disordered breathing (sdb) by using polysomnography (psg) in children with mps iva and mps vi who underwent enzyme replacement therapy (ert) and to analyze the effect on sdb of having upper airway surgery, pulmonary functions, and exercise capacity. a retrospective cross\u2010sectional study was conducted on patients with mps iva (n:17) and mps vi (n:11) aged under 19\\u2009years who underwent polysomnography. descriptive and nonparametric analyses were performed for demographic, psg, pulmonary function and exercise capacity variables. the frequency of sleep apnea in the study sample was 85.7% (24/28). four patients (14.3%) had no sleep apnea, 15 (53.6%) had mild, and nine (32.1%) had moderate\u2010to\u2010severe sleep apnea. two patients (7.1%) had central sleep apnea and 22 had obstructive sleep apnea (osa) (78.6%). forced expiratory volume in 1\\u2009s (fev1) and forced vital capacity (fvc) were negatively correlated to apnea\u2010hypopnea index (ahi) (r =\\u2009\u22120.594, p =\\u2009.009; r =\\u2009\u22120.636, p =\\u2009.005, respectively). despite ert and previous upper airway surgery, the prevalence of osa was high in patients with mps iva\u2013mps iv, emphasizing the importance of psg screening for sleep disorders. pulmonary function tests may be useful for predicting sleep apnea in patients with mps iva and mps vi.",
            "contribution_ids": [
                "R110742"
            ]
        },
        {
            "instance_id": "EMPTYxR201341",
            "comparison_id": "EMPTY",
            "paper_id": "R201341",
            "text": "PERSONAL KNOWLEDGE GRAPH POPULATION FROM USER UTTERANCES IN CONVERSATIONAL UNDERSTANDING knowledge graphs provide a powerful representation of entities and the relationships between them, but automatically constructing such graphs from spoken language utterances presents the novelty and numerous challenges. in this paper, we introduce a statistical language understanding approach to automatically construct personal (user-centric) knowledge graphs in conversational dialogs. such information has the potential to better understand the users' requests, fulfilling them, and enabling other technologies such as developing better inferences or proactive interactions. knowledge encoded in semantic graphs such as freebase has been shown to benefit semantic parsing and interpretation of natural language utterances. hence, as a first step, we exploit the personal factual relation triples from freebase to mine natural language snippets with a search engine, and the resulting snippets containing pairs of related entities to create the training data. this data is then used to build three key language understanding components: (1) personal assertion classification identifies the user utterances that are relevant with personal facts, e.g., \u201cmy mother's name is rosa\u201d; (2) relation detection classifies the personal assertion utterance into one of the predefined relation classes, e.g., \u201cparents\u201d; and (3) slot filling labels the attributes or arguments of relations, e.g., \u201cname(parents): rosa\u201d. our experiments using the microsoft conversational understanding system demonstrate the performance of this proposed approach on the population of personal knowledge graphs.",
            "contribution_ids": [
                "R201343"
            ]
        },
        {
            "instance_id": "EMPTYxR170968",
            "comparison_id": "EMPTY",
            "paper_id": "R170968",
            "text": "Wasted Food: U.S. Consumers' Reported Awareness, Attitudes, and Behaviors the u.s. wastes 31 to 40% of its post-harvest food supply, with a substantial portion of this waste occurring at the consumer level. globally, interventions to address wasted food have proliferated, but efforts are in their infancy in the u.s. to inform these efforts and provide baseline data to track change, we performed a survey of u.s. consumer awareness, attitudes and behaviors related to wasted food. the survey was administered online to members of a nationally representative panel (n=1010), and post-survey weights were applied. the survey found widespread (self-reported) awareness of wasted food as an issue, efforts to reduce it, and knowledge about how to do so, plus moderately frequent performance of waste-reducing behaviors. three-quarters of respondents said they discard less food than the average american. the leading motivations for waste reduction were saving money and setting an example for children, with environmental concerns ranked last. the most common reasons given for discarding food were concern about foodborne illness and a desire to eat only the freshest food. in some cases there were modest differences based on age, parental status, and income, but no differences were found by race, education, rural/urban residence or other demographic factors. respondents recommended ways retailers and restaurants could help reduce waste. this is the first nationally representative consumer survey focused on wasted food in the u.s. it provides insight into u.s. consumers\u2019 perceptions related to wasted food, and comparisons to existing literature. the findings suggest approaches including recognizing that many consumers perceive themselves as being already-knowledgeable and engaged, framing messages to focus on budgets, and modifying existing messages about food freshness and aesthetics. this research also suggests opportunities to shift retail and restaurant practice, and identifies critical research gaps.",
            "contribution_ids": [
                "R170969"
            ]
        },
        {
            "instance_id": "EMPTYxR75661",
            "comparison_id": "EMPTY",
            "paper_id": "R75661",
            "text": "Prevalence of epilepsy in Croatia: a population-based survey objectives\\u2002\u2013\\u2002 to investigate the prevalence of active epilepsy in croatia.",
            "contribution_ids": [
                "R75663"
            ]
        },
        {
            "instance_id": "EMPTYxR170794",
            "comparison_id": "EMPTY",
            "paper_id": "R170794",
            "text": "Reaction Time and Incident Cancer: 25 Years of Follow-Up of Study Members in the UK Health and Lifestyle Survey objectives to investigate the association of reaction time with cancer incidence. methods 6900 individuals aged 18 to 94 years who participated in the uk health and lifestyle survey in 1984/1985 and were followed for a cancer registration for 25 years. results disease surveillance gave rise to 1015 cancer events from all sites. in general, there was essentially no clear pattern of association for either simple or choice reaction time with cancer of all sites combined, nor specific malignancies. however, selected associations were found for lung cancer, colorectal cancer and skin cancer. conclusions in the present study, reaction time and its components were not generally related to cancer risk.",
            "contribution_ids": [
                "R170795"
            ]
        },
        {
            "instance_id": "EMPTYxR110941",
            "comparison_id": "EMPTY",
            "paper_id": "R110941",
            "text": "Microwave-Assisted Cobinamide Synthesis we present a new method for the preparation of cobinamide (cn)2cbi, a vitamin b12 precursor, that should allow its broader utility. treatment of vitamin b12 with only nacn and heating in a microwave reactor affords (cn)2cbi as the sole product. the purification procedure was greatly simplified, allowing for easy isolation of the product in 94% yield. the use of microwave heating proved beneficial also for (cn)2cbi(c-lactone) synthesis. treatment of (cn)2cbi with triethanolamine led to (cn)2cbi(c-lactam).",
            "contribution_ids": [
                "R110943"
            ]
        },
        {
            "instance_id": "EMPTYxR73135",
            "comparison_id": "EMPTY",
            "paper_id": "R73135",
            "text": "The data-literature interlinking service: Towards a common infrastructure for sharing data-article links \\n purpose \\n research data publishing is today widely regarded as crucial for reproducibility, proper assessment of scientific results, and as a way for researchers to get proper credit for sharing their data. however, several challenges need to be solved to fully realize its potential, one of them being the development of a global standard for links between research data and literature. current linking solutions are mostly based on bilateral, ad hoc agreements between publishers and data centers. these operate in silos so that content cannot be readily combined to deliver a network graph connecting research data and literature in a comprehensive and reliable way. the research data alliance (rda) publishing data services working group (pds-wg) aims to address this issue of fragmentation by bringing together different stakeholders to agree on a common infrastructure for sharing links between datasets and literature. the paper aims to discuss these issues. \\n \\n \\n design/methodology/approach \\n this paper presents the synergic effort of the rda pds-wg and the openaire infrastructure toward enabling a common infrastructure for exchanging data-literature links by realizing and operating the data-literature interlinking (dli) service. the dli service populates and provides access to a graph of data set-literature links (at the time of writing close to five million, and growing) collected from a variety of major data centers, publishers, and research organizations. \\n \\n \\n findings \\n to achieve its objectives, the service proposes an interoperable exchange data model and format, based on which it collects and publishes links, thereby offering the opportunity to validate such common approach on real-case scenarios, with real providers and consumers. feedback of these actors will drive continuous refinement of the both data model and exchange format, supporting the further development of the service to become an essential part of a universal, open, cross-platform, cross-discipline solution for collecting, and sharing data set-literature links. \\n \\n \\n originality/value \\n this realization of the dli service is the first technical, cross-community, and collaborative effort in the direction of establishing a common infrastructure for facilitating the exchange of data set-literature links. as a result of its operation and underlying community effort, a new activity, name scholix, has been initiated involving the technological level stakeholders such as datacite and crossref. \\n",
            "contribution_ids": [
                "R73138"
            ]
        },
        {
            "instance_id": "EMPTYxR170447",
            "comparison_id": "EMPTY",
            "paper_id": "R170447",
            "text": "Physiological State Influences the Social Interactions of Two Honeybee Nest Mates \"physiological state profoundly influences the expression of the behaviour of individuals and can affect social interactions between animals. how physiological state influences food sharing and social behaviour in social insects is poorly understood. here, we examined the social interactions and food sharing behaviour of honeybees with the aim of developing the honeybee as a model for understanding how an individual's state influences its social interactions. the state of individual honeybees was manipulated by either starving donor bees or feeding them sucrose or low doses of ethanol to examine how a change in hunger or inebriation state affected the social behaviours exhibited by two closely-related nestmates. using a lab-based assay for measuring individual motor behaviour and social behaviour, we found that behaviours such as antennation, willingness to engage in trophallaxis, and mandible opening were affected by both hunger and ethanol intoxication. inebriated bees were more likely to exhibit mandible opening, which may represent a form of aggression, than bees fed sucrose alone. however, intoxicated bees were as willing to engage in trophallaxis as the sucrose-fed bees. the effects of ethanol on social behaviors were dose-dependent, with higher doses of ethanol producing larger effects on behaviour. hungry donor bees, on the other hand, were more likely to engage in begging for food and less likely to antennate and to display mandible opening. we also found that when nestmates received food from donors previously fed ethanol, they began to display evidence of inebriation, indicating that ethanol can be retained in the crop for several hours and that it can be transferred between honeybee nestmates during trophallaxis.\"",
            "contribution_ids": [
                "R170448"
            ]
        },
        {
            "instance_id": "EMPTYxR172579",
            "comparison_id": "EMPTY",
            "paper_id": "R172579",
            "text": "WISARD\u00c2\u00b7a radical step forward in image recognition the wisard recognition system invented at brunei university has been developed into an industrialised product by computer recognition systems under licence from the british technology group. using statistical pattern classification it already shows great potential in rapid sorting, and research indicates that it will track objects with positional feedback, rather like the human eye.",
            "contribution_ids": [
                "R172581"
            ]
        },
        {
            "instance_id": "EMPTYxR198000",
            "comparison_id": "EMPTY",
            "paper_id": "R198000",
            "text": "Sentinel-2 Exposed Soil Composite for Soil Organic Carbon Prediction pilot studies have demonstrated the potential of remote sensing for soil organic carbon (soc) mapping in exposed croplands. however, the use of remote sensing for soc prediction is often hindered by disturbing factors at the soil surface, such as photosynthetic active and non-photosynthetic active vegetation, variation in soil moisture or surface roughness. with the increasing amount of freely available satellite data, recent studies have focused on stabilizing the soil reflectance by building image composites. these composites tend to minimize the disturbing effects by applying sets of criteria. here, we aim to develop a robust method that allows selecting sentinel-2 (s-2) pixels with minimal influence of the following disturbing factors: crop residues, surface roughness and soil moisture. we selected all s-2 cloud-free images covering the belgian loam belt from january 2019 to december 2020 (in total 36 images). we then built nine exposed soil composites based on four sets of criteria: (1) lowest normalized burn ratio (nbr2), (2) normalized difference vegetation index (ndvi) &lt; 0.25, (3\u20135) ndvi &lt; 0.25 and nbr2 &lt; threshold, (6) the \u2018greening-up\u2019 period of a crop and (7\u20139) the \u2018greening-up\u2019 period of a crop and nbr2 &lt; threshold. the \u2018greening-up\u2019 period was selected based on the ndvi timeline, where \u2018greening-up\u2019 is considered as the last date of acquisition where the soil is exposed (ndvi &lt; 0.25) before the crop develops (ndvi &gt; 0.25). we then built a partial least square regression (plsr) model with 10-fold cross-validation to estimate the soc content based on 137 georeferenced calibration samples on the nine composites. we obtained non-satisfactory results (r2 &lt; 0.30, rmse &gt; 2.50 g c kg\u20131, and rpd &lt; 1.4, n &gt; 68) for all composites except for the composite in the \u2018greening-up\u2019 stage with a nbr2 &lt; 0.07 (r2 = 0.54 \u00b1 0.12, rpd = 1.68 \u00b1 0.45 and rmse = 2.09 \u00b1 0.39 g c kg\u20131, n = 49). hence, the \u2018greening-up\u2019 method combined with a strict nbr2 threshold allows selecting the purest exposed soil pixels suitable for soc prediction. the limit of this method might be its coverage of the total cropland area, which in a two-year period reached 62%, compared to 95% coverage if only the ndvi threshold is applied.",
            "contribution_ids": [
                "R198004"
            ]
        },
        {
            "instance_id": "EMPTYxR146467",
            "comparison_id": "EMPTY",
            "paper_id": "R146467",
            "text": "Formulation of a model for automating infection surveillance: algorithmic detection of central-line associated bloodstream infection objective\\nto formulate a model for translating manual infection control surveillance methods to automated, algorithmic approaches.\\n\\n\\ndesign\\nwe propose a model for creating electronic surveillance algorithms by translating existing manual surveillance practices into automated electronic methods. our model suggests that three dimensions of expert knowledge be consulted: clinical, surveillance, and informatics. once collected, knowledge should be applied through a process of conceptualization, synthesis, programming, and testing.\\n\\n\\nresults\\nwe applied our framework to central vascular catheter associated bloodstream infection surveillance, a major healthcare performance outcome measure. we found that despite major barriers such as differences in availability of structured data, in types of databases used and in semantic representation of clinical terms, bloodstream infection detection algorithms could be deployed at four very diverse medical centers.\\n\\n\\nconclusions\\nwe present a framework that translates existing practice-manual infection detection-to an automated process for surveillance. our experience details barriers and solutions discovered during development of electronic surveillance for central vascular catheter associated bloodstream infections at four hospitals in a variety of data environments. moving electronic surveillance to the next level-availability at a majority of acute care hospitals nationwide-would be hastened by the incorporation of necessary data elements, vocabularies and standards into commercially available electronic health records.",
            "contribution_ids": [
                "R146469"
            ]
        },
        {
            "instance_id": "EMPTYxR149049",
            "comparison_id": "EMPTY",
            "paper_id": "R149049",
            "text": "Ontologies for supply chain simulation modeling simulation might be an effective decision support tool in supply chain management. the review of supply chain simulation modeling methodologies revealed some issues one of which is the practicability of simulation in the supply chain environment. the supply chain environment is dynamic, information intensive, geographically dispersed, and heterogeneous. in order to develop usable supply chain simulation models, the models should be feasibly applicable in the supply chain environment. distributed simulation models have been used by several researchers, however, their complexity and usability hindered their continuation. in this paper, a new approach is proposed. the approach is based on ontologies to integrate several supply chain views and models, which captures the required distributed knowledge to build simulation models. the ontology core is based on the scor model as the widely shared supply chain concepts. the ontology can define any supply chain and help the user to build the required simulation models",
            "contribution_ids": [
                "R149051"
            ]
        },
        {
            "instance_id": "EMPTYxR171299",
            "comparison_id": "EMPTY",
            "paper_id": "R171299",
            "text": "Exposure to digital marketing enhances young adults\u00e2\u0080\u0099 interest in energy drinks: An exploratory investigation young adults experience faster weight gain and consume more unhealthy food than any other age groups. the impact of online food marketing on \u201cdigital native\u201d young adults is unclear. this study examined the effects of online marketing on young adults\u2019 consumption behaviours, using energy drinks as a case example. the elaboration likelihood model of persuasion was used as the theoretical basis. a pre-test post-test experimental research design was adopted using mixed-methods. participants (aged 18\u201324) were randomly assigned to control or experimental groups (n = 30 each). experimental group participants\u2019 attitudes towards and intended purchase and consumption of energy drinks were examined via surveys and semi-structured interviews after their exposure to two popular energy drink brands\u2019 websites and social media sites (exposure time 8 minutes). exposure to digital marketing contents of energy drinks improved the experimental group participants\u2019 attitudes towards and purchase and consumption intention of energy drinks. this study indicates the influential power of unhealthy online marketing on cognitively mature young adults. this study draws public health attentions to young adults, who to date have been less of a focus of researchers but are influenced by online food advertising.",
            "contribution_ids": [
                "R171300",
                "R171301"
            ]
        },
        {
            "instance_id": "EMPTYxR191800",
            "comparison_id": "EMPTY",
            "paper_id": "R191800",
            "text": "Analysis of Land Use and Land Cover Using Machine Learning Algorithms on Google Earth Engine for Munneru River Basin, India the growing human population accelerates alterations in land use and land cover (lulc) over time, putting tremendous strain on natural resources. monitoring and assessing lulc change over large areas is critical in a variety of fields, including natural resource management and climate change research. lulc change has emerged as a critical concern for policymakers and environmentalists. as the need for the reliable estimation of lulc maps from remote sensing data grows, it is critical to comprehend how different machine learning classifiers perform. the primary goal of the present study was to classify lulc on the google earth engine platform using three different machine learning algorithms\u2014namely, support vector machine (svm), random forest (rf), and classification and regression trees (cart)\u2014and to compare their performance using accuracy assessments. the lulc of the study area was classified via supervised classification. for improved classification accuracy, ndvi (normalized difference vegetation index) and ndwi (normalized difference water index) indices were also derived and included. for the years 2016, 2018, and 2020, multitemporal sentinel-2 and landsat-8 data with spatial resolutions of 10 m and 30 m were used for the lulc classification. \u2018water bodies\u2019, \u2018forest\u2019, \u2018barren land\u2019, \u2018vegetation\u2019, and \u2018built-up\u2019 were the major land use classes. the average overall accuracy of svm, rf, and cart classifiers for landsat-8 images was 90.88%, 94.85%, and 82.88%, respectively, and 93.8%, 95.8%, and 86.4% for sentinel-2 images. these results indicate that rf classifiers outperform both svm and cart classifiers in terms of accuracy.",
            "contribution_ids": [
                "R191804"
            ]
        },
        {
            "instance_id": "EMPTYxR155276",
            "comparison_id": "EMPTY",
            "paper_id": "R155276",
            "text": "Experimental Characterization of a Vernier Strain Sensor Using Cascaded Fiber Rings a highly sensitive strain sensor consisting of two cascaded fiber ring resonators based on the vernier effect is proposed. each fiber ring resonator, composed of an input optical coupler, an output optical coupler, and a polarization controller, has a comb-like transmission spectrum with peaks at its resonance wavelengths. as a result, the vernier effect will be generated, due to the displacement of the two transmission spectra. using this technique, strain measurements can be achieved by measuring the free spectral range of the cascaded fiber ring resonators. the experimental results show that the sensing setup can operate in large strain range with a sensitivity of 0.0129 nm-1/\u03bc\u03b5. the new generation of vernier strain sensor can also be useful for micro-displacement measurement.",
            "contribution_ids": [
                "R155278"
            ]
        },
        {
            "instance_id": "EMPTYxR211075",
            "comparison_id": "EMPTY",
            "paper_id": "R211075",
            "text": "Efficient Transformers: A Survey transformer model architectures have garnered immense interest lately due to their effectiveness across a range of domains like language, vision and reinforcement learning. in the field of natural language processing for example, transformers have become an indispensable staple in the modern deep learning stack. recently, a dizzying number of \u201cx-former\u201d models have been proposed - reformer, linformer, performer, longformer, to name a few - which improve upon the original transformer architecture, many of which make improvements around computational and memory efficiency . with the aim of helping the avid researcher navigate this flurry, this paper characterizes a large and thoughtful selection of recent efficiency-flavored \u201cx-former\u201d models, providing an organized and comprehensive overview of existing work and models across multiple domains.",
            "contribution_ids": [
                "R211081",
                "R211128",
                "R211174",
                "R211237",
                "R211238",
                "R211254",
                "R211259",
                "R211264"
            ]
        },
        {
            "instance_id": "EMPTYxR188496",
            "comparison_id": "EMPTY",
            "paper_id": "R188496",
            "text": "Researchers Outside APC-Financed Open Access: Implications for Scholars Without a Paying Institution the article processing charge (apc) financed open access is a publication model that provides immediate and free access to scientific articles. more than half of the world\u2019s open access articles are published according to this concept. however, a side effect of the model is that research is not published if researchers cannot pay the publication charge. the study examines the nature of this phenomenon, its extent, and implications. the study places a special focus on authors who are not affiliated with a research institution. the proportion of these authors is identified among 2,184 danish authors in danish periodicals in 2010. the possibility for poor researchers to receive compensation from publishers is investigated as well. paying the apc is a problem for many researchers\u2014represented by around 30% of authors who have published in danish journals (unemployed scientists, students, as well as retired and private employees). grants from publishers exist, but they are small and too uncertain to ensure that research is published optimally. this study predicts that a large amount of valuable research risks not being published if this publishing model dominates without alternatives or countermeasures.",
            "contribution_ids": [
                "R188498"
            ]
        },
        {
            "instance_id": "EMPTYxR171405",
            "comparison_id": "EMPTY",
            "paper_id": "R171405",
            "text": "Experiences of operational costs of HPV vaccine delivery strategies in Gavi-supported demonstration projects from 2012 to 2016, gavi, the vaccine alliance, provided support for countries to conduct small-scale demonstration projects for the introduction of the human papillomavirus vaccine, with the aim of determining which human papillomavirus vaccine delivery strategies might be effective and sustainable upon national scale-up. this study reports on the operational costs and cost determinants of different vaccination delivery strategies within these projects across twelve countries using a standardized micro-costing tool. the world health organization cervical cancer prevention and control costing tool was used to collect costing data, which were then aggregated and analyzed to assess the costs and cost determinants of vaccination. across the one-year demonstration projects, the average economic and financial costs per dose amounted to us$19.98 (standard deviation \u00b112.5) and us$8.74 (standard deviation \u00b15.8), respectively. the greatest activities representing the greatest share of financial costs were social mobilization at approximately 30% (range, 6\u201367%) and service delivery at about 25% (range, 3\u201346%). districts implemented varying combinations of school-based, facility-based, or outreach delivery strategies and experienced wide variation in vaccine coverage, drop-out rates, and service delivery costs, including transportation costs and per diems. size of target population, number of students per school, and average length of time to reach an outreach post influenced cost per dose. although the operational costs from demonstration projects are much higher than those of other routine vaccine immunization programs, findings from our analysis suggest that hpv vaccination operational costs will decrease substantially for national introduction. vaccination costs may be decreased further by annual vaccination, high initial investment in social mobilization, or introducing/strengthening school health programs. our analysis shows that drivers of cost are dependent on country and district characteristics. we therefore recommend that countries carry out detailed planning at the national and district levels to define a sustainable strategy for national hpv vaccine roll-out, in order to achieve the optimal balance between coverage and cost.",
            "contribution_ids": [
                "R171406"
            ]
        },
        {
            "instance_id": "EMPTYxR195182",
            "comparison_id": "EMPTY",
            "paper_id": "R195182",
            "text": "On the Impact of Semantic Transparency on Understanding and Reviewing Social Goal Models \"context: i* is one of the most influential languages in the requirements engineering research community. perhaps due to its complexity and low adoption in industry, it became a natural candidate for studies aiming at improving its concrete syntax and the stakeholders' ability to correctly interpret i* models. objectives: we evaluate the impact of semantic transparency on understanding and reviewing i* models, in the presence of a language key. methods: we performed a quasi-experiment comparing the standard i* concrete syntax with an alternative that has an increased semantic transparency. we asked 57 novice participants to perform understanding and reviewing tasks on i* models, and measured their accuracy, speed and ease, using metrics of task success, time and effort, collected with eye-tracking and participants' feedback. results: we found no evidence of improved accuracy or speed attributable to the alternative concrete syntax. although participants' perceived ease was similar, they devoted significantly less visual effort to the model and the provided language key, when using the alternative concrete syntax. conclusions: the context provided by the model and language key may mitigate the i* symbol recognition deficit reported in previous works. however, the alternative concrete syntax required a significantly lower visual effort.\"",
            "contribution_ids": [
                "R195183"
            ]
        },
        {
            "instance_id": "EMPTYxR191289",
            "comparison_id": "EMPTY",
            "paper_id": "R191289",
            "text": "BioELECTRA:Pretrained Biomedical text Encoder using Discriminators recent advancements in pretraining strategies in nlp have shown a significant improvement in the performance of models on various text mining tasks. we apply \u2018replaced token detection\u2019 pretraining technique proposed by electra and pretrain a biomedical language model from scratch using biomedical text and vocabulary. we introduce bioelectra, a biomedical domain-specific language encoder model that adapts electra for the biomedical domain. we evaluate our model on the blurb and blue biomedical nlp benchmarks. bioelectra outperforms the previous models and achieves state of the art (sota) on all the 13 datasets in blurb benchmark and on all the 4 clinical datasets from blue benchmark across 7 different nlp tasks. bioelectra pretrained on pubmed and pmc full text articles performs very well on clinical datasets as well. bioelectra achieves new sota 86.34%(1.39% accuracy improvement) on mednli and 64% (2.98% accuracy improvement) on pubmedqa dataset.",
            "contribution_ids": [
                "R191291",
                "R191327"
            ]
        },
        {
            "instance_id": "EMPTYxR110083",
            "comparison_id": "EMPTY",
            "paper_id": "R110083",
            "text": "Optimal Sizing and Scheduling of Hybrid Energy Systems: The Cases of Morona Santiago and the Galapagos Islands hybrid energy systems (hess) generate electricity from multiple energy sources that complement each other. recently, due to the reduction in costs of photovoltaic (pv) modules and wind turbines, these types of systems have become economically competitive. in this study, a mathematical programming model is applied to evaluate the techno-economic feasibility of autonomous units located in two isolated areas of ecuador: first, the province of galapagos (subtropical island) and second, the province of morona santiago (amazonian tropical forest). the two case studies suggest that hess are potential solutions to reduce the dependence of rural villages on fossil fuels and viable mechanisms to bring electrical power to isolated communities in ecuador. our results reveal that not only from the economic but also from the environmental point of view, for the case of the galapagos province, a hybrid energy system with a pv\u2013wind\u2013battery configuration and a levelized cost of energy (lcoe) equal to 0.36 $/kwh is the optimal energy supply system. for the case of morona santiago, a hybrid energy system with a pv\u2013diesel\u2013battery configuration and an lcoe equal to 0.37 $/kwh is the most suitable configuration to meet the load of a typical isolated community in ecuador. the proposed optimization model can be used as a decision-support tool for evaluating the viability of autonomous hes projects at any other location.",
            "contribution_ids": [
                "R110088"
            ]
        },
        {
            "instance_id": "EMPTYxR6629",
            "comparison_id": "EMPTY",
            "paper_id": "R6629",
            "text": "The University of Michigan at DUC 2004 we present the results of michigan\u2019s participation in duc 2004. our system, mead, ranked as one of the top systems in four of the five tasks. we introduce our new feature, lexpagerank, a new measure of sentence centrality inspired by the prestige concept in social networks. lexpagerank gave promising results in multi-document summarization. our approach for task 5, biographical summarization, was simplistic, yet succesful. we used regular expression matching to boost up the scores of the sentences that are likely to contain biographical information patterns.",
            "contribution_ids": [
                "R6630"
            ]
        },
        {
            "instance_id": "EMPTYxR170706",
            "comparison_id": "EMPTY",
            "paper_id": "R170706",
            "text": "Stakeholder Perspectives and Values when Setting Waterbird Population Targets: Implications for Flyway Management Planning in a European Context managing and controlling wildlife species within europe is an acknowledged part of conservation management, yet deciding and setting a population target in order to control a population is perceived to be conceptually very challenging. we interviewed stakeholders, within a variety of governmental and non-governmental organizations, to evaluate their perspectives about setting population targets as part of waterbird management for controlling population sizes. we conclude that the setting of a quantifiable population target is beneficial as a measurable objective for monitoring and evaluating management actions. however, it must be recognised as just one possible measurable objective and there may well be multiple supporting objectives that encapsulate the management aims of different stakeholders. when considering wide-scale control of waterbirds species, where it is likely that population size matters, any population target should be coupled to the issues being addressed. we highlight that it is important to actively engage with stakeholders as part of the decision-making process, not only to gain consensus but to share knowledge. a clear understanding of the context and the rationale for controlling a waterbird species is needed to align the interests of diverse stakeholders. the provision of scientific data and the continuous monitoring of management actions is viewed as beneficial and demanded by stakeholders, as part of any decision-making process when setting population targets. this facilitates effective evaluation of management actions, helping managers make wise decisions as well as enabling the continued development of management plans.",
            "contribution_ids": [
                "R170707",
                "R170708"
            ]
        },
        {
            "instance_id": "EMPTYxR145430",
            "comparison_id": "EMPTY",
            "paper_id": "R145430",
            "text": "Pandemic response in low-resource settings requires effective syndromic surveillance to the editor: starbuck et al. have identified a significant gap in any future global response to a severe influenza pandemic. the threat of inadequate preparedness and limited public health responses in low-resource settings, leading to uncontrolled transmission is a real and unwelcome possibility during a pandemic. the authors recommend that detailed authoritative guidance should be developed for low-resource settings and that support should be given to governments in these settings to adapt and implement these guidelines. however, an appropriate public health response and effective management of cases depend primarily on early detection of suspected cases. this remains a major challenge in many developing countries, but syndromic surveillance offers a potential solution in these settings. a novel and visionary system, using a simple but standardised set of symptoms, was first developed by t. jacob john in the early 1980s in southern india. the system utilised a district-level disease surveillance system in a low-resource setting, to control and limit disease outbreaks through early detection. this approach was further adapted in a rural african setting with a focus on rural hospitals reporting presentations of nine core clinical syndromes, including cholera and meningitis-like disease to ensure early identification of infectious disease outbreaks. a similar syndromic surveillance system for outbreak detection and response has recently been implemented in pacific island countries and territories (picts). in 2010, picts agreed to develop a regional standardised, simple and sustainable event-based syndromic surveillance system to ensure compliance with ihr requirements (rapid outbreak detection, information sharing and response to outbreaks). health resources vary across the region that includes a number of countries that are categorised as least developed countries (ldc). the system is based on the early detection and reporting of four core syndromes (influenza-like illness, diarrhoea, prolonged fever and acute fever with rash) and the immediate reporting of unusual events. the system uses standardised case definitions and processes rather than focussing on a technology platform used to collect or analyse the data. a pacific outbreak manual has been developed as an integral component of the system; to ensure that health workers have rapid access to robust and practical guidelines on the clinical and public health management of infectious disease outbreaks, including influenza-like illness, and triggers for action. this provides picts with authoritative guidance on appropriate response measures during a severe influenza pandemic. a recent evaluation highlighted the need for standardised surveillance to help meet ihr obligations and to ensure early warning of infectious disease outbreaks across the pacific. while there is variation in system implementation, it is apparent that this is a strength in a region that includes lowresource communities. despite differences in personnel resources, medical informatics systems and processes, picts have productively participated in and contributed to a regional early warning system. the syndromic surveillance system expanded from six to twenty participating picts within 1 year, indicating a high level of acceptance of the system. while there are remaining challenges in ensuring uniform data quality, the system has proven effective in detecting outbreaks, its simplicity and the standardisation of both case definitions and responses are key elements in its usefulness. detection of future influenza pandemics or other emerging infectious disease outbreaks in the south pacific should be greatly assisted by this syndromic surveillance system. syndromic surveillance is particularly useful in settings where access to laboratory diagnosis is not timely, allowing containment measures to be implemented prior to having a definitive diagnosis. however, there are inherent limitations in a system based purely on syndromes due to the broad range of diseases that may cause certain syndromes, including influenza-like illness. to avoid exhausting public health doi:10.1111/irv.12098 www.influenzajournal.com letter to the editor",
            "contribution_ids": [
                "R145432"
            ]
        },
        {
            "instance_id": "EMPTYxR171396",
            "comparison_id": "EMPTY",
            "paper_id": "R171396",
            "text": "Seasonal variability shapes resilience of small-scale fisheries in Baja California Sur, Mexico small-scale fisheries are an important source of food and livelihoods to coastal communities around the world. understanding the seasonality of fisheries catch and composition is crucial to fisheries management, particularly in the context of changing environmental and socioeconomic conditions. while seasonal variability directly impacts the lives of fishers, most fisheries studies focus on longer-term change. here we examine seasonal variability in the small-scale fisheries of baja california sur, mexico based on 13 years of government fisheries data. we investigate how four fisheries indicators with direct relevance to ecological resilience\u2013magnitude and variance of landed fish biomass, taxon richness and the proportion of top-trophic-level taxa in total catch\u2013vary within and among years and at multiple spatial scales. we find that these resilience indicators vary both seasonally and spatially. these results highlight the value of finer-scale monitoring and management, particularly for data-poor fisheries.",
            "contribution_ids": [
                "R171397",
                "R171398"
            ]
        },
        {
            "instance_id": "EMPTYxR189444",
            "comparison_id": "EMPTY",
            "paper_id": "R189444",
            "text": "Triple Classification for Scholarly Knowledge Graph Completion structured information representing knowledge encoded in scientific publications. with the sheer volume of published scientific literature comprising a plethora of inhomogeneous entities and relations to describe scientific concepts, these kgs are inherently incomplete. we present exbert, a method for leveraging pre-trained transformer language models to perform scholarly knowledge graph completion. we model triples of a knowledge graph as text and perform triple classification (i.e., belongs to kg or not). the evaluation shows that exbert outperforms other baselines on three scholarly kg completion datasets in the tasks of triple classification, link prediction, and relation prediction. furthermore, we present two scholarly datasets as resources for the research community, collected from public kgs and online resources.",
            "contribution_ids": [
                "R189446"
            ]
        },
        {
            "instance_id": "EMPTYxR161108",
            "comparison_id": "EMPTY",
            "paper_id": "R161108",
            "text": "Polymers and the Environment the traditional polymer materials available today, especially the plastics, are the result of decades of evolution. their production is extremely efficient in terms of utilization of raw materials and energy, as well as of waste release. the products present a series of excellent properties such as impermeability to water and microorganisms, high mechanical strength, low density (useful for transporting goods), and low cost due to manufacturing scale and process optimization [1]. however, some of their most useful features, the chemical, physical and biological inertness, and durability resulted in their accumulation in the environment if not recycled. unfortunately, the accumulation of plastics, along with other materials, is becoming a serious problem for all countries in the world. these materials occupy significant volume in landfills and dumps today. recently, the presence of huge amounts of plastic fragments on the oceans has been observed, considerable part of them coming from the streets, going through the drains with the rain, and then going into the rivers and lakes, and then to the oceans [1]. as a result, there is a very strong and irreversible movement, in all countries of the world, to use materials that do not harm the planet, that is, low environmental impact materials.",
            "contribution_ids": [
                "R161169",
                "R161255",
                "R161258",
                "R161276",
                "R161282",
                "R161289"
            ]
        },
        {
            "instance_id": "EMPTYxR170876",
            "comparison_id": "EMPTY",
            "paper_id": "R170876",
            "text": "Factors that Influence Adherence to Antiretroviral Treatment in an Urban Population, Jakarta, Indonesia introduction although the number of people receiving antiretroviral therapy (art) in indonesia has increased in recent years, little is known about the specific characteristics affecting adherence in this population. indonesia is different from most of its neighbors given that it is a geographically and culturally diverse country, with a large muslim population. we aimed to identify the current rate of adherence and explore factors that influence art adherence. methods data were collected from art-prescribed outpatients on an hiv registry at a north jakarta hospital in 2012. socio-demographic and behavioral characteristics were explored as factors associated with adherence using logistics regression analyses. chi squared test was used to compare the difference between proportions. reasons for missing medication were analyzed descriptively. results two hundred and sixty-one patients participated, of whom 77% reported art adherence in the last 3 months. the level of social support experienced was independently associated with adherence where some social support (p\\u200a=\\u200a0.018) and good social support (p\\u200a=\\u200a0.039) improved adherence compared to poor social support. frequently cited reasons for not taking art medication included forgetting to take medication (67%), busy with something else (63%) and asleep at medication time (60%). discussion this study identified that an increase in the level of social support experienced by art-prescribed patients was positively associated with adherence. social support may minimize the impact of stigma among art prescribed patients. based on these findings, if social support is not available, alternative support through community-based organizations is recommended to maximize treatment success.",
            "contribution_ids": [
                "R170877"
            ]
        },
        {
            "instance_id": "EMPTYxR75924",
            "comparison_id": "EMPTY",
            "paper_id": "R75924",
            "text": "Understanding Visual Memes: An Empirical Analysis of Text Superimposed on Memes Shared on Twitter \"visual memes have become an important mechanism through which ideologically potent and hateful content spreads on today's social media platforms. at the same time, they are also a mechanism through which we convey much more mundane things, like pictures of cats with strange accents. little is known, however, about the relative percentage of visual memes shared by real people that fall into these, or other, thematic categories. the present work focuses on visual memes that contain superimposed text. we carry out the first large-scale study on the themes contained in the text of these memes, which we refer to as image-with-text memes. we find that 30% of the image-with-text memes in our sample which have identifiable themes are politically relevant, and that these politically relevant memes are shared more often by democrats than republicans. we also find disparities in who expresses themselves via image-with-text memes, and images in general, versus other forms of expression on twitter. the fact that some individuals use images with text to express themselves, instead of sending a plain text tweet, suggests potential consequences for the representativeness of analyses that ignore text contained in images.\"",
            "contribution_ids": [
                "R75926"
            ]
        },
        {
            "instance_id": "EMPTYxR110694",
            "comparison_id": "EMPTY",
            "paper_id": "R110694",
            "text": "Fast algorithm for successive computation of group betweenness centrality in this paper, we propose a method for rapid computation of group betweenness centrality whose running time (after preprocessing) does not depend on network size. the calculation of group betweenness centrality is computationally demanding and, therefore, it is not suitable for applications that compute the centrality of many groups in order to identify new properties. our method is based on the concept of path betweenness centrality defined in this paper. we demonstrate how the method can be used to find the most prominent group. then, we apply the method for epidemic control in communication networks. we also show how the method can be used to evaluate distributions of group betweenness centrality and its correlation with group degree. the method may assist in finding further properties of complex networks and may open a wide range of research opportunities.",
            "contribution_ids": [
                "R110696"
            ]
        },
        {
            "instance_id": "EMPTYxR46321",
            "comparison_id": "EMPTY",
            "paper_id": "R46321",
            "text": "Fast and accurate entity recognition with iterated dilated convolutions today when many practitioners run basic nlp on the entire web and large-volume traffic, faster methods are paramount to saving time and energy costs. recent advances in gpu hardware have led to the emergence of bi-directional lstms as a standard method for obtaining per-token vector representations serving as input to labeling tasks such as ner (often followed by prediction in a linear-chain crf). though expressive and accurate, these models fail to fully exploit gpu parallelism, limiting their computational efficiency. this paper proposes a faster alternative to bi-lstms for ner: iterated dilated convolutional neural networks (id-cnns), which have better capacity than traditional cnns for large context and structured prediction. unlike lstms whose sequential processing on sentences of length n requires o(n) time even in the face of parallelism, id-cnns permit fixed-depth convolutions to run in parallel across entire documents. we describe a distinct combination of network structure, parameter sharing and training procedures that enable dramatic 14-20x test-time speedups while retaining accuracy comparable to the bi-lstm-crf. moreover, id-cnns trained to aggregate context from the entire document are more accurate than bi-lstm-crfs while attaining 8x faster test time speeds.",
            "contribution_ids": [
                "R46323"
            ]
        },
        {
            "instance_id": "EMPTYxR169321",
            "comparison_id": "EMPTY",
            "paper_id": "R169321",
            "text": "Divergent Control of Two Type VI Secretion Systems by RpoN in Pseudomonas aeruginosa three type vi secretion system (t6ss) loci called h1- to h3-t6ss coexist in pseudomonas aeruginosa. h1-t6ss targets prokaryotic cells whereas h2-t6ss mediates interactions with both eukaryotic and prokaryotic host cells. little is known about the third system, except that it may be connected to h2-t6ss during the host infection. here we show that h3-t6ss is required for p. aeruginosa pao1 virulence in the worm model. we demonstrate that the two putative h3-t6ss operons, called \u201cleft\u201d and \u201cright\u201d, are coregulated with h2-t6ss by the las and rhl quorum sensing systems. interestingly, the rpon \u03c354 factor has divergent effects on the three operons. as for many t6sss, rpon activates the expression of h3-t6ss left. however, rpon unexpectedly represses the expression of h3-t6ss right and also h2-t6ss. sfa2 and sfa3 are putative enhancer binding proteins encoded on h2-t6ss and h3-t6ss left. in other t6sss ebps can act as \u03c354 activators to promote t6ss transcription. strikingly, we found that the rpon effects of h3-t6ss are sfa-independent while the rpon mediated repression of h2-t6ss is sfa2-dependent. this is the first example of rpon repression of a t6ss being mediated by a t6ss-encoded ebp.",
            "contribution_ids": [
                "R169322",
                "R169323"
            ]
        },
        {
            "instance_id": "EMPTYxR170581",
            "comparison_id": "EMPTY",
            "paper_id": "R170581",
            "text": "Exploring the Morphospace of Communication Efficiency in Complex Networks \"graph theoretical analysis has played a key role in characterizing global features of the topology of complex networks, describing diverse systems such as protein interactions, food webs, social relations and brain connectivity. how system elements communicate with each other depends not only on the structure of the network, but also on the nature of the system's dynamics which are constrained by the amount of knowledge and resources available for communication processes. complementing widely used measures that capture efficiency under the assumption that communication preferentially follows shortest paths across the network (\u201crouting\u201d), we define analytic measures directed at characterizing network communication when signals flow in a random walk process (\u201cdiffusion\u201d). the two dimensions of routing and diffusion efficiency define a morphospace for complex networks, with different network topologies characterized by different combinations of efficiency measures and thus occupying different regions of this space. we explore the relation of network topologies and efficiency measures by examining canonical network models, by evolving networks using a multi-objective optimization strategy, and by investigating real-world network data sets. within the efficiency morphospace, specific aspects of network topology that differentially favor efficient communication for routing and diffusion processes are identified. charting regions of the morphospace that are occupied by canonical, evolved or real networks allows inferences about the limits of communication efficiency imposed by connectivity and dynamics, as well as the underlying selection pressures that have shaped network topology.\"",
            "contribution_ids": [
                "R170582",
                "R170583"
            ]
        },
        {
            "instance_id": "EMPTYxR159811",
            "comparison_id": "EMPTY",
            "paper_id": "R159811",
            "text": "Automatic Diagnosis of Attention Deficit Hyperactivity Disorder Using Machine Learning abstract attention deficit hyperactivity disorder (adhd) is a neurodevelopmental disorder that includes symptoms such as inattentiveness, hyperactivity and impulsiveness. it is considered as an important public health issue, and prevalence of diagnosis has increased as awareness of the disease grew over the past years. supply of specialist medical experts has not kept pace with the increasing demand for assessment, both due to financial pressures on health systems and the difficulty to train new experts, resulting in growing waiting lists. patients are not being treated quickly enough causing problems in other areas of health systems (e.g. increased gp visits, increased risk of self-harm and accidents) and more broadly (e.g. time off work, relationship problems). advances in machine learning make it possible to attempt to diagnose adhd based on the analysis of relevant data, and this could inform clinical practice. this paper reports on findings related to the mental health services of a specialist trust within the uk\u2019s national health service (nhs). the analysis studied data of adult patients who underwent diagnosis over the past few years, and developed a diagnostic model for adhd in adults. the results demonstrate that it is indeed possible to correctly diagnose adhd patients with promising statistical accuracy.",
            "contribution_ids": [
                "R159813",
                "R159815",
                "R159816",
                "R159817",
                "R159818",
                "R159819"
            ]
        },
        {
            "instance_id": "EMPTYxR6172",
            "comparison_id": "EMPTY",
            "paper_id": "R6172",
            "text": "ADANA: Active Name Disambiguation \"name ambiguity has long been viewed as a challenging problem in many applications, such as scientific literature management, people search, and social network analysis. when we search a person name in these systems, many documents (e.g., papers, web pages) containing that person's name may be returned. it is hard to determine which documents are about the person we care about. although much research has been conducted, the problem remains largely unsolved, especially with the rapid growth of the people information available on the web. in this paper, we try to study this problem from a new perspective and propose an adana method for disambiguating person names via active user interactions. in adana, we first introduce a pairwise factor graph (pfg) model for person name disambiguation. the model is flexible and can be easily extended by incorporating various features. based on the pfg model, we propose an active name disambiguation algorithm, aiming to improve the disambiguation performance by maximizing the utility of the user's correction. experimental results on three different genres of data sets show that with only a few user corrections, the error rate of name disambiguation can be reduced to 3.1%. a real system has been developed based on the proposed method and is available online.\"",
            "contribution_ids": [
                "R6173"
            ]
        },
        {
            "instance_id": "EMPTYxR196629",
            "comparison_id": "EMPTY",
            "paper_id": "R196629",
            "text": "Measuring and Mitigating Unintended Bias in Text Classification we introduce and illustrate a new approach to measuring and mitigating unintended bias in machine learning models. our definition of unintended bias is parameterized by a test set and a subset of input features. we illustrate how this can be used to evaluate text classifiers using a synthetic test set and a public corpus of comments annotated for toxicity from wikipedia talk pages. we also demonstrate how imbalances in training data can lead to unintended bias in the resulting models, and therefore potentially unfair applications. we use a set of common demographic identity terms as the subset of input features on which we measure bias. this technique permits analysis in the common scenario where demographic information on authors and readers is unavailable, so that bias mitigation must focus on the content of the text itself. the mitigation method we introduce is an unsupervised approach based on balancing the training dataset. we demonstrate that this approach reduces the unintended bias without compromising overall model quality.",
            "contribution_ids": [
                "R196631"
            ]
        },
        {
            "instance_id": "EMPTYxR74378",
            "comparison_id": "EMPTY",
            "paper_id": "R74378",
            "text": "A Relational Learning Approach for Collective Entity Resolution in the Web of Data the integration of different datasets in the linked data cloud is a key aspect to the success of the web of data. to tackle this problem most of existent solutions have been supported by the task of entity resolution. however, many challenges still prevail specially when considering different types, structures and vocabularies used in the web. another common problem is that data usually are incomplete, inconsistent and contain outliers. to overcome these limitations, some works have applied machine learning algorithms since they are typically robust to both noise and data inconsistencies and are able to efficiently utilize nondeterministic dependencies in the data. in this paper we propose an approach based in a relational learning algorithm that addresses the problem by statistical approximation method. modeling the problem as a relational machine learning task allows exploit contextual information that might be too distant in the relational graph. the joint application of relationship patterns between entities and evidences of similarity between their descriptions can improve the effectiveness of results. furthermore, it is based on a sparse structure that scales well to large datasets. we present initial experiments based on btc2012 datasets.",
            "contribution_ids": [
                "R74380"
            ]
        },
        {
            "instance_id": "EMPTYxR110056",
            "comparison_id": "EMPTY",
            "paper_id": "R110056",
            "text": "Tensor gradient based discriminative region analysis for cognitive state classification extraction of relevant features from high-dimensional multi-way functional mri (fmri) data is essential for the classification of a cognitive task. in general, fmri records a combination of neural activation signals and several other noisy components. alternatively, fmri data is represented as a high dimensional array using a number of voxels, time instants, and snapshots. the organisation of fmri data includes a number of region of interests (roi), snapshots, and thousand of voxels. the crucial step in cognitive task classification is a reduction of feature size through feature selection. extraction of a specific pattern of interest within the noisy components is a challenging task. tensor decomposition techniques have found several applications in the scientific fields. in this paper, a novel tensor gradient-based feature extraction technique for cognitive task classification is proposed. the technique has efficiently been applied on starplus fmri data. also, the technique has been used to discriminate the rois in fmri data in terms of cognitive state classification. the method has been achieved a better average accuracy when compared to other existing feature extraction methods.",
            "contribution_ids": [
                "R110058"
            ]
        },
        {
            "instance_id": "EMPTYxR189386",
            "comparison_id": "EMPTY",
            "paper_id": "R189386",
            "text": "ClausIE: clause-based open information extraction \"we propose clausie, a novel, clause-based approach to open information extraction, which extracts relations and their arguments from natural language text. clausie fundamentally differs from previous approaches in that it separates the detection of ``useful'' pieces of information expressed in a sentence from their representation in terms of extractions. in more detail, clausie exploits linguistic knowledge about the grammar of the english language to first detect clauses in an input sentence and to subsequently identify the type of each clause according to the grammatical function of its constituents. based on this information, clausie is able to generate high-precision extractions; the representation of these extractions can be flexibly customized to the underlying application. clausie is based on dependency parsing and a small set of domain-independent lexica, operates sentence by sentence without any post-processing, and requires no training data (whether labeled or unlabeled). our experimental study on various real-world datasets suggests that clausie obtains higher recall and higher precision than existing approaches, both on high-quality text as well as on noisy text as found in the web.\"",
            "contribution_ids": [
                "R189388"
            ]
        }
    ]
}