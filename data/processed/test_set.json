{
    "instances": [
        {
            "instance_id": "R108358xR108135",
            "comparison_id": "R108358",
            "paper_id": "R108135",
            "text": "Mapping of hydrothermally altered rocks by the EO-1 Hyperion sensor, Northern Danakil Depression, Eritrea \"an eo\u20101 hyperion scene was used to identify and map hydrothermally altered rocks and a precambrian metamorphic sequence at and around the alid volcanic dome, at the northern danakil depression, eritrea. mapping was coupled with laboratory analyses, including reflectance measurements, x\u2010ray diffraction, and petrographic examination of selected rock samples. thematic maps were compiled from the dataset, which was carefully pre\u2010processed to evaluate and to correct interferences in the data. despite the difficulties, lithological mapping using narrow spectral bands proved possible. a spectral signature attributed to ammonium was detected in the laboratory measurements of hydrothermally altered rocks from alid. this was expressed as spectral absorption clues in the atmospherically corrected cube, at the known hydrothermally altered areas. the existence of ammonium in hydrothermally altered rocks within the alid dome has been confirmed by previous studies. spectral information of endmember's mineralogy found in the area (e.g. dolomite) enables a surface mineral map to be produced that stands in good agreement with the known geology along the overpass. these maps are the first hyperspectral overview of the surface mineralogy in this arid terrain and may be used as a base for future studies of remote areas such as the danakil.\"",
            "contribution_ids": [
                "R108136"
            ]
        },
        {
            "instance_id": "R108358xR108144",
            "comparison_id": "R108358",
            "paper_id": "R108144",
            "text": "Mapping of Alteration Zones in Mineral Rich Belt of South-East Rajasthan Using Remote Sensing Techniques remote sensing techniques have emerged as an asset for various geological studies. satellite images obtained by different sensors contain plenty of information related to the terrain. digital image processing further helps in customized ways for the prospecting of minerals. in this study, an attempt has been made to map the hydrothermally altered zones using multispectral and hyperspectral datasets of south east rajasthan. advanced spaceborne thermal emission and reflection radiometer (aster) and hyperion (level1r) dataset have been processed to generate different band ratio composites (brcs). for this study, aster derived brcs were generated to delineate the alteration zones, gossans, abundant clays and host rocks. aster and hyperion images were further processed to extract mineral end members and classified mineral maps have been produced using spectral angle mapper (sam) method. results were validated with the geological map of the area which shows positive agreement with the image processing outputs. thus, this study concludes that the band ratios and image processing in combination play significant role in demarcation of alteration zones which may provide pathfinders for mineral prospecting studies. keywords\u2014advanced space-borne thermal emission and reflection radiometer, aster, hyperion, band ratios, alteration zones, spectral angle mapper.",
            "contribution_ids": [
                "R108145"
            ]
        },
        {
            "instance_id": "R109612xR109396",
            "comparison_id": "R109612",
            "paper_id": "R109396",
            "text": "No nitrogen fixation in the Bay of Bengal? \" abstract. the bay of bengal (bob) has long stood as a biogeochemical enigma, with\\nsubsurface waters containing extremely low, but persistent, concentrations\\nof oxygen in the nanomolar range which \u2013 for some, yet unconstrained, reason \u2013\\nare prevented from becoming anoxic. one reason for this may be the low\\nproductivity of the bob waters due to nutrient limitation and the resulting\\nlack of respiration of organic material at intermediate waters. thus, the\\nparameters determining primary production are key in understanding what\\nprevents the bob from developing anoxia. primary productivity in the sunlit\\nsurface layers of tropical oceans is mostly limited by the supply of\\nreactive nitrogen through upwelling, riverine flux, atmospheric deposition,\\nand biological dinitrogen (n2) fixation. in the bob, a stable\\nstratification limits nutrient supply via upwelling in the open waters, and\\nriverine or atmospheric fluxes have been shown to support only less than one-quarter of the nitrogen for primary production. this leaves a large\\nuncertainty for most of the bob's nitrogen input, suggesting a potential\\nrole of n2 fixation in those waters. here, we present a survey of n2 fixation and carbon fixation in the bob\\nduring the winter monsoon season. we detected a community of n2 fixers\\ncomparable to other oxygen minimum zone (omz) regions, with only a few\\ncyanobacterial clades and a broad diversity of non-phototrophic n2\\nfixers present throughout the water column (samples collected between 10\\nand 560\\u2009m water depth). while similar communities of n2 fixers were\\nshown to actively fix n2 in other omzs, n2 fixation rates were\\nbelow the detection limit in our samples covering the water column between\\nthe deep chlorophyll maximum and the omz. consistent with this, no n2\\nfixation signal was visible in \u03b415n signatures. we suggest that\\nthe absence of n2 fixation may be a consequence of a micronutrient\\nlimitation or of an o2 sensitivity of the omz diazotrophs in the bob.\\nexploring how the onset of n2 fixation by cyanobacteria compared to\\nnon-phototrophic n2 fixers would impact on omz o2 concentrations,\\na simple model exercise was carried out. we observed that both photic-zone-based and omz-based n2 fixation are very sensitive to even\\nminimal changes in water column stratification, with stronger mixing\\nincreasing organic matter production and export, which can exhaust\\nremaining o2 traces in the bob.\\n \"",
            "contribution_ids": [
                "R109397",
                "R109581",
                "R109596",
                "R138402"
            ]
        },
        {
            "instance_id": "R109612xR109573",
            "comparison_id": "R109612",
            "paper_id": "R109573",
            "text": "N2 Fixation in the Eastern Arabian Sea: Probable Role of Heterotrophic Diazotrophs biogeochemical implications of global imbalance between the rates of marine dinitrogen (n2) fixation and denitrification have spurred us to understand the former process in the arabian sea, which contributes considerably to the global nitrogen budget. heterotrophic bacteria have gained recent appreciation for their major role in marine n budget by fixing a significant amount of n2. accordingly, we hypothesize a probable role of heterotrophic diazotrophs from the 15n2 enriched isotope labelling dark incubations that witnessed rates comparable to the light incubations in the eastern arabian sea during spring 2010. maximum areal rates (8 mmol n m-2 d-1) were the highest ever observed anywhere in world oceans. our results suggest that the eastern arabian sea gains ~92% of its new nitrogen through n2 fixation. our results are consistent with the observations made in the same region in preceding year, i.e., during the spring of 2009.",
            "contribution_ids": [
                "R109574",
                "R109591",
                "R138494"
            ]
        },
        {
            "instance_id": "R109904xR109860",
            "comparison_id": "R109904",
            "paper_id": "R109860",
            "text": "Applying weighted PageRank to author citation networks this article aims to identify whether different weighted pagerank algorithms can be applied to author citation networks to measure the popularity and prestige of a scholar from a citation perspective. information retrieval (ir) was selected as a test field and data from 1956\u20132008 were collected from web of science. weighted pagerank with citation and publication as weighted vectors were calculated on author citation networks. the results indicate that both popularity rank and prestige rank were highly correlated with the weighted pagerank. principal component analysis was conducted to detect relationships among these different measures. for capturing prize winners within the ir field, prestige rank outperformed all the other measures. \u00a9 2011 wiley periodicals, inc.",
            "contribution_ids": [
                "R109862"
            ]
        },
        {
            "instance_id": "R109904xR109894",
            "comparison_id": "R109904",
            "paper_id": "R109894",
            "text": "A Hybrid Approach Toward Research Paper Recommendation Using Centrality Measures and Author Ranking the volume of research articles in digital repositories is increasing. this spectacular growth of repositories makes it rather difficult for researchers to obtain related research papers in response to their queries. the problem becomes worse when a researcher with insufficient knowledge of searching research articles uses these repositories. in the traditional recommendation approaches, the results of the query miss many high-quality papers, in the related work section, which are either published recently or have low citation count. to overcome this problem, there needs to be a solution which considers not only structural relationships between the papers but also inspects the quality of authors publishing those articles. many research paper recommendation approaches have been implemented which includes collaborative filtering-based, content-based, and citation analysis-based techniques. the collaborative filtering-based approaches primarily use paper-citation matrix for recommendations, whereas the content-based approaches only consider the content of the paper. the citation analysis considers the structure of the network and focuses on papers citing or cited by the paper of interest. it is therefore very difficult for a recommender system to recommend high-quality papers without a hybrid approach that incorporates multiple features, such as citation information and author information. the proposed method creates a multilevel citation and relationship network of authors in which the citation network uses the structural relationship between the papers to extract significant papers, and authors\u2019 collaboration network finds key authors from those papers. the papers selected by this hybrid approach are then recommended to the user. the results have shown that our proposed method performs exceedingly well as compared with the state-of-the-art existing systems, such as google scholar and multilevel simultaneous citation network.",
            "contribution_ids": [
                "R109899"
            ]
        },
        {
            "instance_id": "R111045xR110913",
            "comparison_id": "R111045",
            "paper_id": "R110913",
            "text": "Multinuclear Lanthanide-Implanted Tetrameric Dawson-Type Phosphotungstates with Switchable Luminescence Behaviors Induced by Fast Photochromism a series of benzoate-decorated lanthanide (ln)-containing tetrameric dawson-type phosphotungstates [n(ch3)4]6h20[{(p2w17o61)ln(h2o)3ln(c6h5coo)(h2o)6]}{[(p2w17o61)ln(h2o)3}]2cl2\u00b798h2o [ln = sm (1), eu (2), and gd (3)] were made using a facile one-step assembly strategy and characterized by several techniques. notably, the ln-containing tetrameric dawson-type polyoxoanions [{(p2w17o61)ln(h2o)3ln(c6h5coo)(h2o)6]}{[(p2w17o61)ln(h2o)3}]224- are all established by four monolacunary dawson-type [p2w17o61]10- segments, encapsulating a ln3+ ion with two benzoates coordinating to the ln3+ ions. 1-3 exhibit reversible photochromism, which can change from intrinsic white to blue for 6 min upon uv irradiation, and their colors gradually recover for 30 h in the dark. the solid-state photoluminescence spectra of 1 and 2 display characteristic emissions of ln components based on 4f-4f transitions. time-resolved emission spectra of 1 and 2 were also measured to authenticate the energy transfer from the phosphotungstate and organic chromophores to eu3+. in particular, 1 shows an effectively switchable luminescence behavior induced by its fast photochromism.",
            "contribution_ids": [
                "R110916"
            ]
        },
        {
            "instance_id": "R111045xR110993",
            "comparison_id": "R111045",
            "paper_id": "R110993",
            "text": "Anilido-oxazoline-ligated rare-earth metal complexes: synthesis, characterization and highly cis-1,4-selective polymerization of isoprene anilido-oxazoline-ligated rare-earth metal complexes show strong fluorescence emissions and good catalytic performance on isoprene polymerization with high cis -1,4-selectivity.",
            "contribution_ids": [
                "R110998"
            ]
        },
        {
            "instance_id": "R112387xR78371",
            "comparison_id": "R112387",
            "paper_id": "R78371",
            "text": "Automatic Classification of Non-Functional Requirements from Augmented App User Reviews \"context: the leading app distribution platforms, apple app store, google play, and windows phone store, have over 4 million apps. research shows that user reviews contain abundant useful information which may help developers to improve their apps. extracting and considering non-functional requirements (nfrs), which describe a set of quality attributes wanted for an app and are hidden in user reviews, can help developers to deliver a product which meets users' expectations. objective: developers need to be aware of the nfrs from massive user reviews during software maintenance and evolution. automatic user reviews classification based on an nfr standard provides a feasible way to achieve this goal. method: in this paper, user reviews were automatically classified into four types of nfrs (reliability, usability, portability, and performance), functional requirements (frs), and others. we combined four classification techniques bow, tf-idf, chi2, and aur-bow (proposed in this work) with three machine learning algorithms naive bayes, j48, and bagging to classify user reviews. we conducted experiments to compare the f-measures of the classification results through all the combinations of the techniques and algorithms. results: we found that the combination of aur-bow with bagging achieves the best result (a precision of 71.4%, a recall of 72.3%, and an f-measure of 71.8%) among all the combinations. conclusion: our finding shows that augmented user reviews can lead to better classification results, and the machine learning algorithm bagging is more suitable for nfrs classification from user reviews than na\u00efve bayes and j48.\"",
            "contribution_ids": [
                "R78373"
            ]
        },
        {
            "instance_id": "R112387xR78432",
            "comparison_id": "R112387",
            "paper_id": "R78432",
            "text": "Software Feature Request Detection in Issue Tracking Systems communication about requirements is often handled in issue tracking systems, especially in a distributed setting. as issue tracking systems also contain bug reports or programming tasks, the software feature requests of the users are often difficult to identify. this paper investigates natural language processing and machine learning features to detect software feature requests in natural language data of issue tracking systems. it compares traditional linguistic machine learning features, such as \"bag of words\", with more advanced features, such as subject-action-object, and evaluates combinations of machine learning features derived from the natural language and features taken from the issue tracking system meta-data. our investigation shows that some combinations of machine learning features derived from natural language and the issue tracking system meta-data outperform traditional approaches. we show that issues or data fields (e.g. descriptions or comments), which contain software feature requests, can be identified reasonably well, but hardly the exact sentence. finally, we show that the choice of machine learning algorithms should depend on the goal, e.g. maximization of the detection rate or balance between detection rate and precision. in addition, the paper contributes a double coded gold standard and an open-source implementation to further pursue this topic.",
            "contribution_ids": [
                "R78434",
                "R198935"
            ]
        },
        {
            "instance_id": "R112387xR108208",
            "comparison_id": "R112387",
            "paper_id": "R108208",
            "text": "Facilitating developer-user interactions with mobile app review digests \"as users are interacting with a large of mobile apps under various usage contexts, user involvements in an app design process has become a critical issue. despite this fact, existing apps or app store platforms only provide a limited form of user involvements such as posting app reviews and sending email reports. while building a unified platform for facilitating user involvements with various apps is our ultimate goal, we present our preliminary work on handling developers' information overload attributed to a large number of app comments. to address this issue, we first perform a simple content analysis on app reviews from the developer's standpoint. we then propose an algorithm that automatically identifies informative reviews reflecting user involvements. the preliminary evaluation results document the efficiency of our algorithm.\"",
            "contribution_ids": [
                "R108210"
            ]
        },
        {
            "instance_id": "R112387xR112033",
            "comparison_id": "R112387",
            "paper_id": "R112033",
            "text": "Listening to the Crowd for the Release Planning of Mobile Apps the market for mobile apps is getting bigger and bigger, and it is expected to be worth over 100 billion dollars in 2020. to have a chance to succeed in such a competitive environment, developers need to build and maintain high-quality apps, continuously astonishing their users with the coolest new features. mobile app marketplaces allow users to release reviews. despite reviews are aimed at recommending apps among users, they also contain precious information for developers, reporting bugs and suggesting new features. to exploit such a source of information, developers are supposed to manually read user reviews, something not doable when hundreds of them are collected per day. to help developers dealing with such a task, we developed clap (crowd listener for release planning), a web application able to (i) categorize user reviews based on the information they carry out, (ii) cluster together related reviews, and (iii) prioritize the clusters of reviews to be implemented when planning the subsequent app release. we evaluated all the steps behind clap, showing its high accuracy in categorizing and clustering reviews and the meaningfulness of the recommended prioritizations. also, given the availability of clap as a working tool, we assessed its applicability in industrial environments.",
            "contribution_ids": [
                "R112040"
            ]
        },
        {
            "instance_id": "R112387xR112044",
            "comparison_id": "R112387",
            "paper_id": "R112044",
            "text": "Can app changelogs improve requirements classification from app reviews?: an exploratory study [background] recent research on mining app reviews for software evolution indicated that the elicitation and analysis of user requirements can benefit from supplementing user reviews by data from other sources. however, only a few studies reported results of leveraging app changelogs together with app reviews. [aims] motivated by those findings, this exploratory experimental study looks into the role of app changelogs in the classification of requirements derived from app reviews. we aim at understanding if the use of app changelogs can lead to more accurate identification and classification of functional and non-functional requirements from app reviews. we also want to know which classification technique works better in this context. [method] we did a case study on the effect of app changelogs on automatic classification of app reviews. specifically, manual labeling, text preprocessing, and four supervised machine learning algorithms were applied to a series of experiments, varying in the number of app changelogs in the experimental data. [results] we compared the accuracy of requirements classification from app reviews, by training the four classifiers with varying combinations of app reviews and changelogs. among the four algorithms, na\u00efve bayes was found to be more accurate for categorizing app reviews. [conclusions] the results show that official app changelogs did not contribute to more accurate identification and classification of requirements from app reviews. in addition, na\u00efve bayes seems to be more suitable for our further research on this topic.",
            "contribution_ids": [
                "R112046"
            ]
        },
        {
            "instance_id": "R114155xR76123",
            "comparison_id": "R114155",
            "paper_id": "R76123",
            "text": "Crowdsourcing to elicit requirements for MyERP application crowdsourcing is an emerging method to collect requirements for software systems. applications seeking global acceptance need to meet the expectations of a wide range of users. collecting requirements and arriving at consensus with a wide range of users is difficult using traditional method of requirements elicitation. this paper presents crowdsourcing based approach for german medium-size software company myerp that might help the company to get access to requirements from non-german customers. we present the tasks involved in the proposed solution that would help the company meet the goal of eliciting requirements at a fast pace with non-german customers.",
            "contribution_ids": [
                "R76125"
            ]
        },
        {
            "instance_id": "R114155xR111441",
            "comparison_id": "R114155",
            "paper_id": "R111441",
            "text": "Crowd Out the Competition myerp is a fictional developer of an enterprise resource planning (erp) system. driven by the competition, they face the challenge of losing market share if they fail to de-ploy a software as a service (saas) erp system to the european market quickly, but with high quality product. this also means that the requirements engineering (re) activities will have to be performed efficiently and provide solid results. an additional problem they face is that their (potential) stakeholders are phys-ically distributed, it makes sense to consider them a \"crowd\". this competition paper suggests a crowd-based re approach that first identifies the crowd, then collects and analyzes their feedback to derive wishes and needs, and validate the results through prototyping. for this, techniques are introduced that have so far been rarely employed within re, but more \"traditional\" re techniques, will also be integrated and/or adapted to attain the best possible result in the case of myerp.",
            "contribution_ids": [
                "R111443"
            ]
        },
        {
            "instance_id": "R114155xR112407",
            "comparison_id": "R114155",
            "paper_id": "R112407",
            "text": "Which Feature is Unusable? Detecting Usability and User Experience Issues from User Reviews \"usability and user experience (uux) strongly affect software quality and success. user reviews allow software users to report uux issues. however, this information can be difficult to access due to the varying quality of the reviews, its large numbers and unstructured nature. in this work we propose an approach to automatically detect the uux strengths and issues of software features according to user reviews. we use a collocation algorithm for extracting the features, lexical sentiment analysis for uncovering users' satisfaction about a particular feature and machine learning for detecting the specific uux issues affecting the software application. additionally, we present two visualizations of the results. an initial evaluation of the approach against human judgement obtained mixed results.\"",
            "contribution_ids": [
                "R112409"
            ]
        },
        {
            "instance_id": "R114155xR112434",
            "comparison_id": "R114155",
            "paper_id": "R112434",
            "text": "Users \u00e2\u0080\u0094 The Hidden Software Product Quality Experts?: A Study on How App Users Report Quality Aspects in Online Reviews [context and motivation] research on eliciting requirements from a large number of online reviews using automated means has focused on functional aspects. assuring the quality of an app is vital for its success. this is why user feedback concerning quality issues should be considered as well [question/problem] but to what extent do online reviews of apps address quality characteristics? and how much potential is there to extract such knowledge through automation? [principal ideas/results] by tagging online reviews, we found that users mainly write about \"usability\" and \"reliability\", but the majority of statements are on a subcharacteristic level, most notably regarding \"operability\", \"adaptability\", \"fault tolerance\", and \"interoperability\". a set of 16 language patterns regarding \"usability\" correctly identified 1,528 statements from a large dataset far more efficiently than our manual analysis of a small subset. [contribution] we found that statements can especially be derived from online reviews about qualities by which users are directly affected, although with some ambiguity. language patterns can identify statements about qualities with high precision, though the recall is modest at this time. nevertheless, our results have shown that online reviews are an unused big data source for quality requirements.",
            "contribution_ids": [
                "R112436",
                "R195568"
            ]
        },
        {
            "instance_id": "R114155xR113008",
            "comparison_id": "R114155",
            "paper_id": "R113008",
            "text": "Canary: Extracting Requirements-Related Information from Online Discussions online discussions about software applications generate a large amount of requirements-related information. this information can potentially be usefully applied in requirements engineering; however currently, there are few systematic approaches for extracting such information. to address this gap, we propose canary, an approach for extracting and querying requirements-related information in online discussions. the highlight of our approach is a high-level query language that combines aspects of both requirements and discussion in online forums. we give the semantics of the query language in terms of relational databases and sql. we demonstrate the usefulness of the language using examples on real data extracted from online discussions. our approach relies on human annotations of online discussions. we highlight the subtleties involved in interpreting the content in online discussions and the assumptions and choices we made to effectively address them. we demonstrate the feasibility of generating high-quality annotations by obtaining them from lay amazon mechanical turk users.",
            "contribution_ids": [
                "R113010",
                "R195498"
            ]
        },
        {
            "instance_id": "R114155xR113030",
            "comparison_id": "R114155",
            "paper_id": "R113030",
            "text": "Conceptualising, extracting and analysing requirements arguments in users' forums: The CrowdRE\u00e2\u0080\u0090Arg framework \"due to the pervasive use of online forums and social media, users' feedback are more accessible today and can be used within a requirements engineering context. however, such information is often fragmented, with multiple perspectives from multiple parties involved during on\u2010going interactions. in this paper, the authors propose a crowd\u2010based requirements engineering approach by argumentation (crowdre\u2010arg). the framework is based on the analysis of the textual conversations found in user forums, identification of features, issues and the arguments that are in favour or opposing a given requirements statement. the analysis is to generate an argumentation model of the involved user statements, retrieve the conflicting\u2010viewpoints, reason about the winning\u2010arguments and present that to systems analysts to make informed\u2010requirements decisions. for this purpose, the authors adopted a bipolar argumentation framework and a coalition\u2010based meta\u2010argumentation framework as well as user voting techniques. the crowdre\u2010arg approach and its algorithms are illustrated through two sample conversations threads taken from the reddit forum. additionally, the authors devised algorithms that can identify conflict\u2010free features or issues based on their supporting and attacking arguments. the authors tested these machine learning algorithms on a set of 3,051 user comments, preprocessed using the content analysis technique. the results show that the proposed algorithms correctly and efficiently identify conflict\u2010free features and issues along with their winning arguments.\"",
            "contribution_ids": [
                "R113033"
            ]
        },
        {
            "instance_id": "R114155xR113173",
            "comparison_id": "R114155",
            "paper_id": "R113173",
            "text": "Software Feature Request Detection in Issue Tracking Systems communication about requirements is often handled in issue tracking systems, especially in a distributed setting. as issue tracking systems also contain bug reports or programming tasks, the software feature requests of the users are often difficult to identify. this paper investigates natural language processing and machine learning features to detect software feature requests in natural language data of issue tracking systems. it compares traditional linguistic machine learning features, such as \"bag of words\", with more advanced features, such as subject-action-object, and evaluates combinations of machine learning features derived from the natural language and features taken from the issue tracking system meta-data. our investigation shows that some combinations of machine learning features derived from natural language and the issue tracking system meta-data outperform traditional approaches. we show that issues or data fields (e.g. descriptions or comments), which contain software feature requests, can be identified reasonably well, but hardly the exact sentence. finally, we show that the choice of machine learning algorithms should depend on the goal, e.g. maximization of the detection rate or balance between detection rate and precision. in addition, the paper contributes a double coded gold standard and an open-source implementation to further pursue this topic.",
            "contribution_ids": [
                "R113175"
            ]
        },
        {
            "instance_id": "R114155xR113204",
            "comparison_id": "R114155",
            "paper_id": "R113204",
            "text": "Mining Android App Descriptions for Permission Requirements Recommendation \"during the development or maintenance of an android app, the app developer needs to determine the app's security and privacy requirements such as permission requirements. permission requirements include two folds. first, what permissions (i.e., access to sensitive resources, e.g., location or contact list) the app needs to request. second, how to explain the reason of permission usages to users. in this paper, we focus on the multiple challenges that developers face when creating permission-usage explanations. we propose a novel framework, clap, that mines potential explanations from the descriptions of similar apps. clap leverages information retrieval and text summarization techniques to find frequent permission usages. we evaluate clap on a large dataset containing 1.4 million android apps. the evaluation results outperform existing state-of-the-art approaches, showing great promise of clap as a tool for assisting developers and permission requirements discovery.\"",
            "contribution_ids": [
                "R113206",
                "R195127"
            ]
        },
        {
            "instance_id": "R12250xR12231",
            "comparison_id": "R12250",
            "paper_id": "R12231",
            "text": "Novel coronavirus 2019-nCoV: early estimation of epidemiological parameters and epidemic predictions abstract since first identified, the epidemic scale of the recently emerged novel coronavirus (2019-ncov) in wuhan, china, has increased rapidly, with cases arising across china and other countries and regions. using a transmission model, we estimate a basic reproductive number of 3.11 (95%ci, 2.39\u20134.13); 58\u201376% of transmissions must be prevented to stop increasing; wuhan case ascertainment of 5.0% (3.6\u20137.4); 21022 (11090\u201333490) total infections in wuhan 1 to 22 january. changes to previous version case data updated to include 22 jan 2020; we did not use cases reported after this period as cases were reported at the province level hereafter, and large-scale control interventions were initiated on 23 jan 2020; improved likelihood function, better accounting for first 41 confirmed cases, and now using all infections (rather than just cases detected) in wuhan for prediction of infection in international travellers; improved characterization of uncertainty in parameters, and calculation of epidemic trajectory confidence intervals using a more statistically rigorous method; extended range of latent period in sensitivity analysis to reflect reports of up to 6 day incubation period in household clusters; removed travel restriction analysis, as different modelling approaches (e.g. stochastic transmission, rather than deterministic transmission) are more appropriate to such analyses.",
            "contribution_ids": [
                "R12232"
            ]
        },
        {
            "instance_id": "R12251xR36138",
            "comparison_id": "R12251",
            "paper_id": "R36138",
            "text": "Estimating the generation interval for COVID-19 based on symptom onset data abstract background estimating key infectious disease parameters from the covid-19 outbreak is quintessential for modelling studies and guiding intervention strategies. whereas different estimates for the incubation period distribution and the serial interval distribution have been reported, estimates of the generation interval for covid-19 have not been provided. methods we used outbreak data from clusters in singapore and tianjin, china to estimate the generation interval from symptom onset data while acknowledging uncertainty about the incubation period distribution and the underlying transmission network. from those estimates we obtained the proportions pre-symptomatic transmission and reproduction numbers. results the mean generation interval was 5.20 (95%ci 3.78-6.78) days for singapore and 3.95 (95%ci 3.01-4.91) days for tianjin, china when relying on a previously reported incubation period with mean 5.2 and sd 2.8 days. the proportion of pre-symptomatic transmission was 48% (95%ci 32-67%) for singapore and 62% (95%ci 50-76%) for tianjin, china. estimates of the reproduction number based on the generation interval distribution were slightly higher than those based on the serial interval distribution. conclusions estimating generation and serial interval distributions from outbreak data requires careful investigation of the underlying transmission network. detailed contact tracing information is essential for correctly estimating these quantities.",
            "contribution_ids": [
                "R36139",
                "R36140",
                "R36141",
                "R36142"
            ]
        },
        {
            "instance_id": "R12251xR37008",
            "comparison_id": "R12251",
            "paper_id": "R37008",
            "text": "Estimation of the Transmission Risk of the 2019-nCoV and Its Implication for Public Health Interventions since the emergence of the first cases in wuhan, china, the novel coronavirus (2019-ncov) infection has been quickly spreading out to other provinces and neighboring countries. estimation of the basic reproduction number by means of mathematical modeling can be helpful for determining the potential and severity of an outbreak and providing critical information for identifying the type of disease interventions and intensity. a deterministic compartmental model was devised based on the clinical progression of the disease, epidemiological status of the individuals, and intervention measures. the estimations based on likelihood and model analysis show that the control reproduction number may be as high as 6.47 (95% ci 5.71\u20137.23). sensitivity analyses show that interventions, such as intensive contact tracing followed by quarantine and isolation, can effectively reduce the control reproduction number and transmission risk, with the effect of travel restriction adopted by wuhan on 2019-ncov infection in beijing being almost equivalent to increasing quarantine by a 100 thousand baseline value. it is essential to assess how the expensive, resource-intensive measures implemented by the chinese authorities can contribute to the prevention and control of the 2019-ncov infection, and how long they should be maintained. under the most restrictive measures, the outbreak is expected to peak within two weeks (since 23 january 2020) with a significant low peak value. with travel restriction (no imported exposed individuals to beijing), the number of infected individuals in seven days will decrease by 91.14% in beijing, compared with the scenario of no travel restriction.",
            "contribution_ids": [
                "R37009"
            ]
        },
        {
            "instance_id": "R137469xR137380",
            "comparison_id": "R137469",
            "paper_id": "R137380",
            "text": "Deposition of a TMDSO-Based Film by a Non-Equilibrium Atmospheric Pressure DC Plasma Jet: Deposition of a TMDSO-Based Film\u00e2\u0080\u00a6 this work deals with the deposition of thin films using an atmospheric pressure direct current nitrogen plasma jet with tetramethyldisiloxane as precursor. the effect of o-2 flow and plasma discharge power on film deposition rate and film chemical characteristics is investigated in detail by surface profilometry, fourier transform infrared spectroscopy, and x-ray photoelectron spectroscopy. it is found that a higher deposition rate is obtained at higher oxygen flow rates and higher discharge powers. increasing discharge power shows a certain amount of capability to transfer low oxygen content bonds to high oxygen content bonds. organic films can be deposited in a pure nitrogen atmosphere. the film chemical composition can be tuned to a more inorganic structure by admixture of o-2 leading to an increase in sio4 units at high oxygen flow rates.",
            "contribution_ids": [
                "R137382"
            ]
        },
        {
            "instance_id": "R137469xR137398",
            "comparison_id": "R137469",
            "paper_id": "R137398",
            "text": "Transitions Between and Control of Guided and Branching Streamers in DC Nanosecond Pulsed Excited Plasma Jets plasma bullets are ionization fronts created in atmospheric-pressure plasma jets. the propagation behavior of those bullets is, in the literature, explained by the formation of an interface between the inert gas and the ambient air created by the gas flow of the plasma jet, which guides these discharges in the formed gas channel. in this paper, we examine this ionization phenomenon in uniform gases at atmospheric pressure where this interface between two gases is not present. by changing electrical parameters and adding admixtures such as oxygen, nitrogen, and air to the gas flow, the conditions for which plasma bullets are present are investigated. nanosecond time-resolved images have been taken with an iccd camera to observe the propagation behavior of these discharges. it is argued that the inhomogeneous spatial concentration of metastable atoms and ions, due to the laminar gas flow and the operation frequency of the discharge in the range of a few kilohertz, is responsible for the guidance of the ionization fronts. furthermore, conditions have been observed at where the branching of the discharge is stable and reproducible over time in the case of a helium plasma by adding admixtures of oxygen. possible mechanisms for this phenomenon are discussed.",
            "contribution_ids": [
                "R137400"
            ]
        },
        {
            "instance_id": "R137469xR137410",
            "comparison_id": "R137469",
            "paper_id": "R137410",
            "text": "A brush-shaped air plasma jet operated in glow discharge mode at atmospheric pressure using ambient air as working gas, a direct-current plasma jet is developed to generate a brush-shaped plasma plume with fairly large volume. although a direct-current power supply is used, the discharge shows a pulsed characteristic. based on the voltage-current curve and fast photography, the brush-shaped plume, like the gliding arc plasma, is in fact a temporal superposition of a moving discharge filament in an arched shape. during it moves away from the nozzle, the discharge evolves from a low-current arc into a normal glow in one discharge cycle. the emission profile is explained qualitatively based on the dynamics of the plasma brush.",
            "contribution_ids": [
                "R137412"
            ]
        },
        {
            "instance_id": "R137469xR137416",
            "comparison_id": "R137469",
            "paper_id": "R137416",
            "text": "Flux of OH and O radicals onto a surface by an atmospheric-pressure helium plasma jet measured by laser-induced fluorescence the atmospheric-pressure helium plasma jet is of emerging interest as a cutting-edge biomedical device for cancer treatment, wound healing and sterilization. reactive oxygen species such as oh and o radicals are considered to be major factors in the application of biological plasma. in this study, density distribution, temporal behaviour and flux of oh and o radicals on a surface are measured using laser-induced fluorescence. a helium plasma jet is generated by applying pulsed high voltage of 8 kv with 10 khz using a quartz tube with an inner diameter of 4 mm. to evaluate the relation between the surface condition and active species production, three surfaces are used: dry, wet and rat skin. when the helium flow rate is 1.5 l min\u22121, radial distribution of oh density on the rat skin surface shows a maximum density of 1.2 \u00d7 1013 cm\u22123 at the centre of the plasma-mediated area, while o atom density shows a maximum of 1.0 \u00d7 1015 cm\u22123 at 2.0 mm radius from the centre of the plasma-mediated area. their densities in the effluent of the plasma jet are almost constant during the intervals of the discharge pulses because their lifetimes are longer than the pulse interval. their density distribution depends on the helium flow rate and the surface humidity. with these results, oh and o production mechanisms in the plasma jet and their flux onto the surface are discussed.",
            "contribution_ids": [
                "R137418"
            ]
        },
        {
            "instance_id": "R137469xR137422",
            "comparison_id": "R137469",
            "paper_id": "R137422",
            "text": "Phase-resolved measurement of electric charge deposited by an atmospheric pressure plasma jet on a dielectric surface the surface charge distribution deposited by the effluent of a dielectric barrier discharge driven atmospheric pressure plasma jet on a dielectric surface has been studied. for the first time, the deposition of charge was observed phase resolved. it takes place in either one or two events in each half cycle of the driving voltage. the charge transfer could also be detected in the electrode current of the jet. the periodic change of surface charge polarity has been found to correspond well with the appearance of ionized channels left behind by guided streamers (bullets) that have been identified in similar experimental situations. the distribution of negative surface charge turned out to be significantly broader than for positive charge. with increasing distance of the jet nozzle from the target surface, the charge transfer decreases until finally the effluent loses contact and the charge transfer stops.",
            "contribution_ids": [
                "R137424"
            ]
        },
        {
            "instance_id": "R137469xR137429",
            "comparison_id": "R137469",
            "paper_id": "R137429",
            "text": "Plasma Processes and Plasma Sources in Medicine the use of plasma for healthcare can be dated back as far as the middle of the 19th century. only the development of room temperature atmospheric pressure plasma sources in the past decade, however, has opened the new and fast growing interdisciplinary research field of plasma medicine. three main topics can be distinguished: plasma treated implants, plasma decontamination, and plasmas in medical therapy. understanding of the plasma sources and the plasma processes involved is still incomplete. with the aim of a more fundamental insight we investigate plasmas in a) functionalization of implants with antimicrobial as well as cell attachment enhancing surfaces b) atmospheric pressure plasmas (apps) in inactivation of bacteria, decontamination of bottles and food products, as well as medical equipment and c) apps in medical therapy and their effects on cell viability as a means to finding a plasma \u201cdosage\u201d. the possibilities of an application focused designing of plasma sources will be emphasized. on the example of feed gas humidity and its significant influence the importance of determining and controlling unobvious or hidden parameter is demonstrated (\u00a9 2012 wiley\u2010vch verlag gmbh & co. kgaa, weinheim)",
            "contribution_ids": [
                "R137431"
            ]
        },
        {
            "instance_id": "R137469xR137453",
            "comparison_id": "R137469",
            "paper_id": "R137453",
            "text": "Integrated Microwave Atmospheric Plasma Source (IMAPlaS): thermal and spectroscopic properties and antimicrobial effect onB. atrophaeusspores the integrated microwave atmospheric plasma source (imaplas) operating with a microwave resonator at 2.45 ghz driven by a solid-state transistor oscillator generates a core plasma of high temperature (t > 1000 k), therefore producing reactive species such as no very effectively. the effluent of the plasma source is much colder, which enables direct treatment of thermolabile materials or even living tissue. in this study the source was operated with argon, helium and nitrogen with gas flow rates between 0.3 and 1.0 slm. depending on working gas and distance, axial gas temperatures between 30 and 250 \u00b0c were determined in front of the nozzle. reactive species were identified by emission spectroscopy in the spectral range from vacuum ultraviolet to near infrared. the irradiance in the ultraviolet range was also measured. using b. atrophaeus spores to test antimicrobial efficiency, we determined log10-reduction rates of up to a factor of 4.",
            "contribution_ids": [
                "R137455"
            ]
        },
        {
            "instance_id": "R137469xR137456",
            "comparison_id": "R137469",
            "paper_id": "R137456",
            "text": "The antibacterial activity of a microwave argon plasma jet at atmospheric pressure relies mainly on UV-C radiations the main bactericidal sources produced by a microwave induced cold argon plasma jet in open air are identified and their relative proportion in the biocide efficiency of the jet is assessed on planktonic gram-negative bacteria (wild-type strains and deletion mutants of escherichia coli) diluted in water. in these conditions ultraviolet light (uv) most probably in the uv-c region of the electromagnetic spectrum, is responsible for 86.7 \u00b1 3.2% of the observed bactericidal efficiency of the jet whereas hydrogen peroxide represents 9.9 \u00b1 5.5% of it. the exposition level of the bacteria to uv-c radiations is estimated at 20 mj cm\u22122 using a specific photodiode and the influence of the initial bacteria concentration on the apparent antibacterial efficiency of the jet is highlighted.",
            "contribution_ids": [
                "R137458"
            ]
        },
        {
            "instance_id": "R138127xR137522",
            "comparison_id": "R138127",
            "paper_id": "R137522",
            "text": "Paclitaxel-loaded poly(D,L-lactide-co-glycolide) nanoparticles for radiotherapy in hypoxic human tumor cells in vitro radioresistant hypoxic cells may contribute to the failure of radiation therapy in controlling certain tumors. some studies have suggested the radiosensitizing effect of paclitaxel. the poly(d,l-lactide-co-glycolide)(plga) nanoparticles containing paclitaxel were prepared by o/w emulsification-solvent evaporation method. the physicochemical characteristics of the nanoparticles (i.e. encapsulation efficiency, particle size distribution, morphology, in vitro release) were studied. the morphology of the two human tumor cell lines: a carcinoma cervicis (hela) and a hepatoma (hepg2), treated with paclitaxel-loaded nanoparticles was photomicrographed. flow cytometry was used to quantify the number of the tumor cells held in the g2/m phase of the cell cycle. the cellular uptake of nanoparticles was evaluated by transmission electronic microscopy. cell viability was determined by the ability of single cell to form colonies in vitro. the prepared nanoparticles were spherical in shape with size between 200nm and 800nm. the encapsulation efficiency was 85.5\uff05. the release behaviour of paclitaxel from the nanoparticles exhibited a biphasic pattern characterised by a fast initial release during the first 24 h, followed by a slower and continuous release. co-culture of the two tumor cell lines with paclitaxel-loaded nanoparticles demonstrated that the cell morphology was changed and the released paclitaxel retained its bioactivity to block cells in the g2/m phase. the cellular uptake of nanoparticles was observed. the free paclitaxel and paclitaxel-loaded nanoparticles effectively sensitized hypoxic hela and hepg2 cells to radiation. under this experimental condition, the radiosensitization of paclitaxel-loaded nanoparticles was more significant than that of free paclitaxel.keywords: paclitaxel\uff1bdrug delivery\uff1bnanoparticle\uff1bradiotherapy\uff1bhypoxia\uff1bhuman tumor cells\uff1bcellular uptake",
            "contribution_ids": [
                "R137524"
            ]
        },
        {
            "instance_id": "R139050xR138687",
            "comparison_id": "R139050",
            "paper_id": "R138687",
            "text": "Diagnosis of attention deficit hyperactivity disorder using deep belief network based on greedy approach attention deficit hyperactivity disorder creates conditions for the child as s/he cannot sit calm and still, control his/her behavior and focus his/her attention on a particular issue. five out of every hundred children are affected by the disease. boys are three times more than girls at risk for this complication. the disorder often begins before age seven, and parents may not realize their children problem until they get older. children with hyperactivity and attention deficit are at high risk of conduct disorder, antisocial personality, and drug abuse. most children suffering from the disease will develop a feeling of depression, anxiety and lack of self-confidence. given the importance of diagnosis the disease, deep belief networks (dbns) were used as a deep learning model to predict the disease. in this system, in addition to fmri images features, sophisticated features such as age and iq as well as functional characteristics, etc. were used. the proposed method was evaluated by two standard data sets of adhd-200 global competitions, including neuroimage and nyu data sets, and compared with state-of-the-art algorithms. the results showed the superiority of the proposed method rather than other systems. the prediction accuracy has improved respectively as +12.04 and +27.81 over neuroimage and nyu datasets compared to the best proposed method in the adhd-200 global competition.",
            "contribution_ids": [
                "R138689"
            ]
        },
        {
            "instance_id": "R139050xR138690",
            "comparison_id": "R139050",
            "paper_id": "R138690",
            "text": "Deep learning based automatic diagnoses of attention deficit hyperactive disorder in this paper, we aim to develop a deep learning based automatic attention deficit hyperactive disorder (adhd) diagnosis algorithm using resting state functional magnetic resonance imaging (rs-fmri) scans. however, relative to millions of parameters in deep neural networks (dnn), the number of fmri samples is still limited to learn discriminative features from the raw data. in light of this, we first encode our prior knowledge on 3d features voxel-wisely, including regional homogeneity (reho), fractional amplitude of low frequency fluctuations (falff) and voxel-mirrored homotopic connectivity (vmhc), and take these 3d images as the input to the dnn. inspired by the way that radiologists examine brain images, we further investigate a novel 3d convolutional neural network (cnn) architecture to learn 3d local patterns which may boost the diagnosis accuracy. investigation on the hold-out testing data of the adhd-200 global competition demonstrates that the proposed 3d cnn approach yields superior performances when compared to the reported classifiers in the literature, even with less training samples.",
            "contribution_ids": [
                "R138692"
            ]
        },
        {
            "instance_id": "R139050xR138710",
            "comparison_id": "R139050",
            "paper_id": "R138710",
            "text": "A general prediction model for the detection of ADHD and Autism using structural and functional MRI this work presents a novel method for learning a model that can diagnose attention deficit hyperactivity disorder (adhd), as well as autism, using structural texture and functional connectivity features obtained from 3-dimensional structural magnetic resonance imaging (mri) and 4-dimensional resting-state functional magnetic resonance imaging (fmri) scans of subjects. we explore a series of three learners: (1) the lefms learner first extracts features from the structural mri images using the texture-based filters produced by a sparse autoencoder. these filters are then convolved with the original mri image using an unsupervised convolutional network. the resulting features are used as input to a linear support vector machine (svm) classifier. (2) the lefmf learner produces a diagnostic model by first computing spatial non-stationary independent components of the fmri scans, which it uses to decompose each subject\u2019s fmri scan into the time courses of these common spatial components. these features can then be used with a learner by themselves or in combination with other features to produce the model. regardless of which approach is used, the final set of features are input to a linear support vector machine (svm) classifier. (3) finally, the overall lefmsf learner uses the combined features obtained from the two feature extraction processes in (1) and (2) above as input to an svm classifier, achieving an accuracy of 0.673 on the adhd-200 holdout data and 0.643 on the abide holdout data. both of these results, obtained with the same lefmsf framework, are the best known, over all hold-out accuracies on these datasets when only using imaging data\u2014exceeding previously-published results by 0.012 for adhd and 0.042 for autism. our results show that combining multi-modal features can yield good classification accuracy for diagnosis of adhd and autism, which is an important step towards computer-aided diagnosis of these psychiatric diseases and perhaps others as well.",
            "contribution_ids": [
                "R138713"
            ]
        },
        {
            "instance_id": "R139050xR138729",
            "comparison_id": "R139050",
            "paper_id": "R138729",
            "text": "fMRIPrep: a robust preprocessing pipeline for functional MRI preprocessing of functional mri (fmri) involves numerous steps to clean and standardize data before statistical analysis. generally, researchers create ad hoc preprocessing workflows for each new dataset, building upon a large inventory of tools available for each step. the complexity of these workflows has snowballed with rapid advances in mr data acquisition and image processing techniques. we introduce fmriprep , an analysis-agnostic tool that addresses the challenge of robust and reproducible preprocessing for task-based and resting fmri data. fmriprep automatically adapts a best-in-breed workflow to the idiosyncrasies of virtually any dataset, ensuring high-quality preprocessing with no manual intervention. by introducing visual assessment checkpoints into an iterative integration framework for software-testing, we show that fmriprep robustly produces high-quality results on a diverse fmri data collection comprising participants from 54 different studies in the openfmri repository. we review the distinctive features of fmriprep in a qualitative comparison to other preprocessing workflows. we demonstrate that fmriprep achieves higher spatial accuracy as it introduces less uncontrolled spatial smoothness than commonly used preprocessing tools. fmriprep has the potential to transform fmri research by equipping neuroscientists with a high-quality, robust, easy-to-use and transparent preprocessing workflow which can help ensure the validity of inference and the interpretability of their results.",
            "contribution_ids": [
                "R138740"
            ]
        },
        {
            "instance_id": "R139050xR138796",
            "comparison_id": "R139050",
            "paper_id": "R138796",
            "text": "A Deep Learning Approach for Predicting Antidepressant Response in Major Depression Using Clinical and Genetic Biomarkers in the wake of recent advances in scientific research, personalized medicine using deep learning techniques represents a new paradigm. in this work, our goal was to establish deep learning models which distinguish responders from non-responders, and also to predict possible antidepressant treatment outcomes in major depressive disorder (mdd). to uncover relationships between the responsiveness of antidepressant treatment and biomarkers, we developed a deep learning prediction approach resulting from the analysis of genetic and clinical factors such as single nucleotide polymorphisms (snps), age, sex, baseline hamilton rating scale for depression score, depressive episodes, marital status, and suicide attempt status of mdd patients. the cohort consisted of 455 patients who were treated with selective serotonin reuptake inhibitors (treatment-response rate = 61.0%; remission rate = 33.0%). by using the snp dataset that was original to a genome-wide association study, we selected 10 snps (including abca13 rs4917029, bnip3 rs9419139, cacna1e rs704329, exoc4 rs6978272, grin2b rs7954376, lhfpl3 rs4352778, nell1 rs2139423, nuak1 rs2956406, prex1 rs4810894, and slit3 rs139863958) which were associated with antidepressant treatment response. furthermore, we pinpointed 10 snps (including arntl rs11022778, camk1d rs2724812, gabrb3 rs12904459, grm8 rs35864549, naaladl2 rs9878985, ncald rs483986, pla2g4a rs12046378, prok2 rs73103153, rbfox1 rs17134927, and znf536 rs77554113) in relation to remission. then, we employed multilayer feedforward neural networks (mfnns) containing 1\u20133 hidden layers and compared mfnn models with logistic regression models. our analysis results revealed that the mfnn model with 2 hidden layers (area under the receiver operating characteristic curve (auc) = 0.8228 \u00b1 0.0571; sensitivity = 0.7546 \u00b1 0.0619; specificity = 0.6922 \u00b1 0.0765) performed maximally among predictive models to infer the complex relationship between antidepressant treatment response and biomarkers. in addition, the mfnn model with 3 hidden layers (auc = 0.8060 \u00b1 0.0722; sensitivity = 0.7732 \u00b1 0.0583; specificity = 0.6623 \u00b1 0.0853) achieved best among predictive models to predict remission. our study indicates that the deep mfnn framework may provide a suitable method to establish a tool for distinguishing treatment responders from non-responders prior to antidepressant therapy.",
            "contribution_ids": [
                "R138798"
            ]
        },
        {
            "instance_id": "R139050xR138859",
            "comparison_id": "R139050",
            "paper_id": "R138859",
            "text": "Multi task sequence learning for depression scale prediction from video depression is a typical mood disorder, which affects people in mental and even physical problems. people who suffer depression always behave abnormal in visual behavior and the voice. in this paper, an audio visual based multimodal depression scale prediction system is proposed. firstly, features are extracted from video and audio are fused in feature level to represent the audio visual behavior. secondly, long short memory recurrent neural network (lstm-rnn) is utilized to encode the dynamic temporal information of the abnormal audio visual behavior. thirdly, emotion information is utilized by multi-task learning to boost the performance further. the proposed approach is evaluated on the audio-visual emotion challenge (avec2014) dataset. experiments results show the dimensional emotion recognition helps to depression scale prediction.",
            "contribution_ids": [
                "R138861"
            ]
        },
        {
            "instance_id": "R139050xR138884",
            "comparison_id": "R139050",
            "paper_id": "R138884",
            "text": "Automatic Detection of ADHD and ASD from Expressive Behaviour in RGBD Data attention deficit hyperactivity disorder (adhd) and autism spectrum disorder (asd) are neurodevelopmental conditions which impact on a significant number of children and adults. currently, the diagnosis of such disorders is done by experts who employ standard questionnaires and look for certain behavioural markers through manual observation. such methods for their diagnosis are not only subjective, difficult to repeat, and costly but also extremely time consuming. in this work, we present a novel methodology to aid diagnostic predictions about the presence/absence of adhd and asd by automatic visual analysis of a persons behaviour. to do so, we conduct the questionnaires in a computer-mediated way while recording participants with modern rgbd (colour+depth) sensors. in contrast to previous automatic approaches which have focussed only on detecting certain behavioural markers, our approach provides a fully automatic end-to-end system to directly predict adhd and asd in adults. using state of the art facial expression analysis based on dynamic deep learning and 3d analysis of behaviour, we attain classification rates of 96% for controls vs condition (adhd/asd) groups and 94% for comorbid (adhd+asd) vs asd only group. we show that our system is a potentially useful time saving contribution to the clinical diagnosis of adhd and asd.",
            "contribution_ids": [
                "R138886"
            ]
        },
        {
            "instance_id": "R139050xR138959",
            "comparison_id": "R139050",
            "paper_id": "R138959",
            "text": "Automated Depression Diagnosis Based on Deep Networks to Encode Facial Appearance and Dynamics as a severe psychiatric disorder disease, depression is a state of low mood and aversion to activity, which prevents a person from functioning normally in both work and daily lives. the study on automated mental health assessment has been given increasing attentions in recent years. in this paper, we study the problem of automatic diagnosis of depression. a new approach to predict the beck depression inventory ii (bdi-ii) values from video data is proposed based on the deep networks. the proposed framework is designed in a two stream manner, aiming at capturing both the facial appearance and dynamics. further, we employ joint tuning layers that can implicitly integrate the appearance and dynamic information. experiments are conducted on two depression databases, avec2013 and avec2014. the experimental results show that our proposed approach significantly improve the depression prediction performance, compared to other visual-based approaches.",
            "contribution_ids": [
                "R138962"
            ]
        },
        {
            "instance_id": "R139050xR138969",
            "comparison_id": "R139050",
            "paper_id": "R138969",
            "text": "Artificial Intelligent System for Automatic Depression Level Analysis Through Visual and Vocal Expressions a human being\u2019s cognitive system can be simulated by artificial intelligent systems. machines and robots equipped with cognitive capability can automatically recognize a humans mental state through their gestures and facial expressions. in this paper, an artificial intelligent system is proposed to monitor depression. it can predict the scales of beck depression inventory ii (bdi-ii) from vocal and visual expressions. first, different visual features are extracted from facial expression images. deep learning method is utilized to extract key visual features from the facial expression frames. second, spectral low-level descriptors and mel-frequency cepstral coefficients features are extracted from short audio segments to capture the vocal expressions. third, feature dynamic history histogram (fdhh) is proposed to capture the temporal movement on the feature space. finally, these fdhh and audio features are fused using regression techniques for the prediction of the bdi-ii scales. the proposed method has been tested on the public audio/visual emotion challenges 2014 dataset as it is tuned to be more focused on the study of depression. the results outperform all the other existing methods on the same dataset.",
            "contribution_ids": [
                "R138972"
            ]
        },
        {
            "instance_id": "R139050xR139019",
            "comparison_id": "R139050",
            "paper_id": "R139019",
            "text": "UArizona at the CLEF eRisk 2017 Pilot Task: Linear and Recurrent Models for Early Depression Detection \"the 2017 clef erisk pilot task focuses on automatically detecting depression as early as possible from a users' posts to reddit. in this paper we present the techniques employed for the university of arizona team's participation in this early risk detection shared task. we leveraged external information beyond the small training set, including a preexisting depression lexicon and concepts from the unified medical language system as features. for prediction, we used both sequential (recurrent neural network) and non-sequential (support vector machine) models. our models perform decently on the test data, and the recurrent neural models perform better than the non-sequential support vector machines while using the same feature sets.\"",
            "contribution_ids": [
                "R139021"
            ]
        },
        {
            "instance_id": "R139050xR139028",
            "comparison_id": "R139050",
            "paper_id": "R139028",
            "text": "Natural Language Processing of Social Media as Screening for Suicide Risk suicide is among the 10 most common causes of death, as assessed by the world health organization. for every death by suicide, an estimated 138 people\u2019s lives are meaningfully affected, and almost any other statistic around suicide deaths is equally alarming. the pervasiveness of social media\u2014and the near-ubiquity of mobile devices used to access social media networks\u2014offers new types of data for understanding the behavior of those who (attempt to) take their own lives and suggests new possibilities for preventive intervention. we demonstrate the feasibility of using social media data to detect those at risk for suicide. specifically, we use natural language processing and machine learning (specifically deep learning) techniques to detect quantifiable signals around suicide attempts, and describe designs for an automated system for estimating suicide risk, usable by those without specialized mental health training (eg, a primary care doctor). we also discuss the ethical use of such technology and examine privacy implications. currently, this technology is only used for intervention for individuals who have \u201copted in\u201d for the analysis and intervention, but the technology enables scalable screening for suicide risk, potentially identifying many people who are at risk preventively and prior to any engagement with a health care system. this raises a significant cultural question about the trade-off between privacy and prevention\u2014we have potentially life-saving technology that is currently reaching only a fraction of the possible people at risk because of respect for their privacy. is the current trade-off between privacy and prevention the right one?",
            "contribution_ids": [
                "R139030"
            ]
        },
        {
            "instance_id": "R139050xR139038",
            "comparison_id": "R139050",
            "paper_id": "R139038",
            "text": "Hierarchical neural model with attention mechanisms for the\n            classification of social media text related to mental health mental health problems represent a major public health challenge. automated analysis of text related to mental health is aimed to help medical decision-making, public health policies and to improve health care. such analysis may involve text classification. traditionally, automated classification has been performed mainly using machine learning methods involving costly feature engineering. recently, the performance of those methods has been dramatically improved by neural methods. however, mainly convolutional neural networks (cnns) have been explored. in this paper, we apply a hierarchical recurrent neural network (rnn) architecture with an attention mechanism on social media data related to mental health. we show that this architecture improves overall classification results as compared to previously reported results on the same data. benefitting from the attention mechanism, it can also efficiently select text elements crucial for classification decisions, which can also be used for in-depth analysis.",
            "contribution_ids": [
                "R139040"
            ]
        },
        {
            "instance_id": "R139050xR138825",
            "comparison_id": "R139050",
            "paper_id": "R138825",
            "text": "Comprehensive functional genomic resource and integrative model for the human brain \\n introduction \\n strong genetic associations have been found for a number of psychiatric disorders. however, understanding the underlying molecular mechanisms remains challenging. \\n \\n \\n rationale \\n to address this challenge, the psychencode consortium has developed a comprehensive online resource and integrative models for the functional genomics of the human brain. \\n \\n \\n results \\n the base of the pyramidal resource is the datasets generated by psychencode, including bulk transcriptome, chromatin, genotype, and hi-c datasets and single-cell transcriptomic data from ~32,000 cells for major brain regions. we have merged these with data from genotype-tissue expression (gtex), encode, roadmap epigenomics, and single-cell analyses. via uniform processing, we created a harmonized resource, allowing us to survey functional genomics data on the brain over a sample size of 1866 individuals. \\n from this uniformly processed dataset, we created derived data products. these include lists of brain-expressed genes, coexpression modules, and single-cell expression profiles for many brain cell types; ~79,000 brain-active enhancers with associated hi-c loops and topologically associating domains; and ~2.5 million expression quantitative-trait loci (qtls) comprising ~238,000 linkage-disequilibrium\u2013independent single-nucleotide polymorphisms and of other types of qtls associated with splice isoforms, cell fractions, and chromatin activity. by using these, we found that &gt;88% of the cross-population variation in brain gene expression can be accounted for by cell fraction changes. furthermore, a number of disorders and aging are associated with changes in cell-type proportions. the derived data also enable comparison between the brain and other tissues. in particular, by using spectral analyses, we found that the brain has distinct expression and epigenetic patterns, including a greater extent of noncoding transcription than other tissues. \\n the top level of the resource consists of integrative networks for regulation and machine-learning models for disease prediction. the networks include a full gene regulatory network (grn) for the brain, linking transcription factors, enhancers, and target genes from merging of the qtls, generalized element-activity correlations, and hi-c data. by using this network, we link disease genes to genome-wide association study (gwas) variants for psychiatric disorders. for schizophrenia, we linked 321 genes to the 142 reported gwas loci. we then embedded the regulatory network into a deep-learning model to predict psychiatric phenotypes from genotype and expression. our model gives a ~6-fold improvement in prediction over additive polygenic risk scores. moreover, it achieves a ~3-fold improvement over additive models, even when the gene expression data are imputed, highlighting the value of having just a small amount of transcriptome data for disease prediction. lastly, it highlights key genes and pathways associated with disorder prediction, including immunological, synaptic, and metabolic pathways, recapitulating de novo results from more targeted analyses. \\n \\n \\n conclusion \\n our resource and integrative analyses have uncovered genomic elements and networks in the brain, which in turn have provided insight into the molecular mechanisms underlying psychiatric disorders. our deep-learning model improves disease risk prediction over traditional approaches and can be extended with additional data types (e.g., microrna and neuroimaging). \\n \\n \\n a comprehensive functional genomic resource for the adult human brain. \\n the resource forms a three-layer pyramid. the bottom layer includes sequencing datasets for traits, such as schizophrenia. the middle layer represents derived datasets, including functional genomic elements and qtls. the top layer contains integrated models, which link genotypes to phenotypes. dspn, deep structured phenotype network; pc1 and pc2, principal components 1 and 2; ref, reference; alt, alternate; h3k27ac, histone h3 acetylation at lysine 27. \\n \\n \\n \\n",
            "contribution_ids": [
                "R138856"
            ]
        },
        {
            "instance_id": "R139190xR139077",
            "comparison_id": "R139190",
            "paper_id": "R139077",
            "text": "Spatially resolved diagnostics on a microscale atmospheric pressure plasma jet despite enormous potential for technological applications, fundamentals of stable non-equilibrium micro-plasmas at ambient pressure are still only partly understood. micro-plasma jets are one sub-group of these plasma sources. for an understanding it is particularly important to analyse transport phenomena of energy and particles within and between the core and effluent of the discharge. the complexity of the problem requires the combination and correlation of various highly sophisticated diagnostics yielding different information with an extremely high temporal and spatial resolution. a specially designed rf microscale atmospheric pressure plasma jet (\u03bc-appj) provides excellent access for optical diagnostics to the discharge volume and the effluent region. this allows detailed investigations of the discharge dynamics and energy transport mechanisms from the discharge to the effluent. here we present examples for diagnostics applicable to different regions and combine the results. the diagnostics applied are optical emission spectroscopy (oes) in the visible and ultraviolet and two-photon absorption laser-induced fluorescence spectroscopy. by the latter spatially resolved absolutely calibrated density maps of atomic oxygen have been determined for the effluent. oes yields an insight into energy transport mechanisms from the core into the effluent. the first results of spatially and phase-resolved oes measurements of the discharge dynamics of the core are presented.",
            "contribution_ids": [
                "R139169"
            ]
        },
        {
            "instance_id": "R139190xR139080",
            "comparison_id": "R139190",
            "paper_id": "R139080",
            "text": "Diagnostics on an atmospheric pressure plasma jet the atmospheric pressure plasma jet (appj) is a homogeneous non-equilibrium discharge at ambient pressure. it operates with a noble base gas and a percentage-volume admixture of a molecular gas. applications of the discharge are mainly based on reactive species in the effluent. the effluent region of a discharge operated in helium with an oxygen admixture has been investigated. the optical emission from atomic oxygen decreases with distance from the discharge but can still be observed several centimetres in the effluent. ground state atomic oxygen, measured using absolutely calibrated two-photon laser induced fluorescence spectroscopy, shows a similar behaviour. detailed understanding of energy transport mechanisms requires investigations of the discharge volume and the effluent region. an atmospheric pressure plasma jet has been designed providing excellent diagnostics access and a simple geometry ideally suited for modelling and simulation. laser spectroscopy and optical emission spectroscopy can be applied in the discharge volume and the effluent region.",
            "contribution_ids": [
                "R139170"
            ]
        },
        {
            "instance_id": "R139190xR139086",
            "comparison_id": "R139190",
            "paper_id": "R139086",
            "text": "Generation of atomic oxygen in the effluent of an atmospheric pressure plasma jet \"the planar 13.56\\u2009mhz rf-excited low temperature atmospheric pressure plasma jet (appj) investigated in this study is operated with helium feed gas and a small molecular oxygen admixture. the effluent leaving the discharge through the jet's nozzle contains very few charged particles and a high reactive oxygen species' density. as its main reactive radical, essential for numerous applications, the ground state atomic oxygen density in the appj's effluent is measured spatially resolved with two-photon absorption laser induced fluorescence spectroscopy. the atomic oxygen density at the nozzle reaches a value of \u223c1016\\u2009cm\u22123. even at several centimetres distance still 1% of this initial atomic oxygen density can be detected. optical emission spectroscopy (oes) reveals the presence of short living excited oxygen atoms up to 10\\u2009cm distance from the jet's nozzle. the measured high ground state atomic oxygen density and the unaccounted for presence of excited atomic oxygen require further investigations on a possible energy transfer from the appj's discharge region into the effluent: energetic vacuum ultraviolet radiation, measured by oes down to 110\\u2009nm, reaches far into the effluent where it is presumed to be responsible for the generation of atomic oxygen.4 this study forms part of: s reuter 2007 formation mechanisms of atomic oxygen in an atmospheric pressure plasma jet characterised by spectroscopic methods dissertation duisburg-essen university and was presented at the 59th gaseous electronics conference (gec) (columbus, oh).\"",
            "contribution_ids": [
                "R139172"
            ]
        },
        {
            "instance_id": "R139190xR139089",
            "comparison_id": "R139190",
            "paper_id": "R139089",
            "text": "The dynamics of radio-frequency driven atmospheric pressure plasma jets the complex dynamics of radio-frequency driven atmospheric pressure plasma jets is investigated using various optical diagnostic techniques and numerical simulations. absolute number densities of ground state atomic oxygen radicals in the plasma effluent are measured by two-photon absorption laser induced fluorescence spectroscopy (talif). spatial profiles are compared with (vacuum) ultra-violet radiation from excited states of atomic oxygen and molecular oxygen, respectively. the excitation and ionization dynamics in the plasma core are dominated by electron impact and observed by space and phase resolved optical emission spectroscopy (proes). the electron dynamics is governed through the motion of the plasma boundary sheaths in front of the electrodes as illustrated in numerical simulations using a hybrid code based on fluid equations and kinetic treatment of electrons.",
            "contribution_ids": [
                "R139173"
            ]
        },
        {
            "instance_id": "R139190xR139106",
            "comparison_id": "R139190",
            "paper_id": "R139106",
            "text": "Concepts and characteristics of the \u00e2\u0080\u0098COST Reference Microplasma Jet\u00e2\u0080\u0099 biomedical applications of non-equilibrium atmospheric pressure plasmas have attracted intense interest in the past few years. many plasma sources of diverse design have been proposed for these applications, but the relationship between source characteristics and application performance is not well-understood, and indeed many sources are poorly characterized. this circumstance is an impediment to progress in application development. a reference source with well-understood and highly reproducible characteristics may be an important tool in this context. researchers around the world should be able to compare the characteristics of their own sources and also their results with this device. in this paper, we describe such a reference source, developed from the simple and robust micro-scaled atmospheric pressure plasma jet (\u03bc-appj) concept. this development occurred under the auspices of cost action mp1101 \u2018biomedical applications of atmospheric pressure plasmas\u2019. gas contamination and power measurement are shown to be major causes of irreproducible results in earlier source designs. these problems are resolved in the reference source by refinement of the mechanical and electrical design and by specifying an operating protocol. these measures are shown to be absolutely necessary for reproducible operation. they include the integration of current and voltage probes into the jet. the usual combination of matching unit and power supply is replaced by an integrated lc power coupling circuit and a 5\\u2009w single frequency generator. the design specification and operating protocol for the reference source are being made freely available.",
            "contribution_ids": [
                "R139179"
            ]
        },
        {
            "instance_id": "R139190xR139115",
            "comparison_id": "R139190",
            "paper_id": "R139115",
            "text": "Chemical kinetics in an atmospheric pressure helium plasma containing humidity investigating the formation and kinetics of o and oh in a he\u2013h 2 o plasma jet using absorption spectroscopy and 0d modelling.",
            "contribution_ids": [
                "R139182"
            ]
        },
        {
            "instance_id": "R139190xR139132",
            "comparison_id": "R139190",
            "paper_id": "R139132",
            "text": "Characterization of an RF-driven argon plasma at atmospheric pressure using broadband absorption and optical emission spectroscopy atmospheric pressure plasmas in argon are of particular interest due to the production of highly excited and reactive species enabling numerous plasma-aided applications. in this contribution, we report on absolute optical emission and absorption spectroscopy of a radio frequency (rf) driven capacitively coupled argon glow discharge operated in a parallel-plate configuration. this enabled the study of all key parameters including electron density and temperature, gas temperature, and absolute densities of atoms in highly electronically excited states. space and time-averaged electron density and temperature were determined from the measurement of the absolute intensity of the electron-atom bremsstrahlung in the visible range. considering the non-maxwellian electron energy distribution function, an electron temperature ( t e) of 2.1\\u2009ev and an electron density ( n e) of 1.1 \u00d7 10 19 m \u2212 3 were obtained. the time-averaged and spatially resolved absolute densities of atoms in the metastable ( 1 s 5 and 1 s 3) and resonant ( 1 s 4 and 1 s 2) states of argon in the pure ar and ar/he mixture were obtained by broadband absorption spectroscopy. the 1 s 5 metastable atoms had the largest density near the sheath region with a maximum value of 8 \u00d7 10 17 m \u2212 3, while all other 1s states had densities of at most 2 \u00d7 10 17 m \u2212 3. the dominant production and loss mechanisms of these atoms were discussed, in particular, the role of radiation trapping. we conclude with comparison of the plasma properties of the argon rf glow discharges with the more common he equivalent and highlight their differences.",
            "contribution_ids": [
                "R139188"
            ]
        },
        {
            "instance_id": "R139526xR139469",
            "comparison_id": "R139526",
            "paper_id": "R139469",
            "text": "PENYELESAIAN MULTI-OBJECTIVE FLEXIBLE JOB SHOP SCHEDULING PROBLEM  MENGGUNAKAN  HYBRID ALGORITMA IMUN flexible job shop scheduling problem (fjssp) is one of scheduling problems with specification: there is a job to be done in a certain order, each job contains a number of operations and each operation is processed on a machine of some available machine. the purpose of this paper is to solve multi-objective flexible job shop scheduling problem with minimizing the makespan, the biggest workload and the total workload of all machines. because of complexity these problem, a integrated approach immune algorithm (ia) and simulated annealing (sa) algorithm are combined to solve the multi-objective fjssp. a clonal selection is a strategy for generating new antibody based on selecting the antibody for reproduction. sa is used as a local search search algorithm for enhancing the local ability with certain probability to avoid becoming trapped in a local optimum. the simulation result have proved that this hybrid immune algorithm is an efficient and effective approach to solve the multi-objective fjssp",
            "contribution_ids": [
                "R139471"
            ]
        },
        {
            "instance_id": "R139526xR139522",
            "comparison_id": "R139526",
            "paper_id": "R139522",
            "text": "Multisystem Optimization for an Integrated Production Scheduling with Resource Saving Problem in Textile Printing and Dyeing resource saving has become an integral aspect of manufacturing in industry 4.0. this paper proposes a multisystem optimization (mso) algorithm, inspired by implicit parallelism of heuristic methods, to solve an integrated production scheduling with resource saving problem in textile printing and dyeing. first, a real-world integrated production scheduling with resource saving is formulated as a multisystem optimization problem. then, the mso algorithm is proposed to solve multisystem optimization problems that consist of several coupled subsystems, and each of the subsystems may contain multiple objectives and multiple constraints. the proposed mso algorithm is composed of within-subsystem evolution and cross-subsystem migration operators, and the former is to optimize each subsystem by excellent evolution operators and the later is to complete information sharing between multiple subsystems, to accelerate the global optimization of the whole system. performance is tested on a set of multisystem benchmark functions and compared with improved nsga-ii and multiobjective multifactorial evolutionary algorithm (mo-mfea). simulation results show that the mso algorithm is better than compared algorithms for the benchmark functions studied in this paper. finally, the mso algorithm is successfully applied to the proposed integrated production scheduling with resource saving problem, and the results show that mso is a promising algorithm for the studied problem.",
            "contribution_ids": [
                "R139525"
            ]
        },
        {
            "instance_id": "R139567xR139313",
            "comparison_id": "R139567",
            "paper_id": "R139313",
            "text": "A hybrid Semantic driven recommender for services in the eGovernment domain in its way towards the maturity of egovernment solutions a number of paths are being explored. among them, one of the not fully explored mechanisms are the use of social features for a better provisioning of domain services. this paper explores how to provide support for the discovery of services from public administrations using folksonomies. taking advantage of these, authors develop a social site and they provide a complete mechanism to recommend new services to users using techniques from cf and cbf recommenders. also, some conclusions are presented to enlighten future practitioners and researchers.",
            "contribution_ids": [
                "R139315"
            ]
        },
        {
            "instance_id": "R139567xR138300",
            "comparison_id": "R139567",
            "paper_id": "R138300",
            "text": "Bridging the Gap between Citizens and Local Administrations with Knowledge-Based Service Bundle Recommendations the italian public administration services (ipas) is a registry of services provided to italian citizens likewise the local government service list (uk), or the european service list for local authorities from other nations. unlike existing registries, ipas presents the novelty of modelling public services from the view point of the value they have for the consumers and the providers. a value-added-service (vas) is linked to a life event that requires its fruition, addresses consumer categories to identify market opportunities for private providers, and is described by non-functional-properties such as price and time of fruition. where italian local authorities leave the citizen-users in a daedalus of references to understand whether they can/have to apply for a service, the ipas model captures the necessary back-ground knowledge about the connection between administrative legislation and service specifications, life events, and application contexts to support the citizen-users to fulfill their needs. as a proof of concept, we developed an operational web environment named asso, designed to assist the citizen-user to intuitively create bundles of mandatory-by-legislation and recommended services, to accomplish his bureaucratic fulfillments. although asso is an ongoing project, domain experts gave preliminary positive feedback on the innovativeness and effectiveness of the proposed approach.",
            "contribution_ids": [
                "R138302"
            ]
        },
        {
            "instance_id": "R139642xR139605",
            "comparison_id": "R139642",
            "paper_id": "R139605",
            "text": "Device modeling of perovskite solar cells based on structural similarity with thin film inorganic semiconductor solar cells device modeling of ch3nh3pbi3\u2212xcl3 perovskite-based solar cells was performed. the perovskite solar cells employ a similar structure with inorganic semiconductor solar cells, such as cu(in,ga)se2, and the exciton in the perovskite is wannier-type. we, therefore, applied one-dimensional device simulator widely used in the cu(in,ga)se2 solar cells. a high open-circuit voltage of 1.0\\u2009v reported experimentally was successfully reproduced in the simulation, and also other solar cell parameters well consistent with real devices were obtained. in addition, the effect of carrier diffusion length of the absorber and interface defect densities at front and back sides and the optimum thickness of the absorber were analyzed. the results revealed that the diffusion length experimentally reported is long enough for high efficiency, and the defect density at the front interface is critical for high efficiency. also, the optimum absorber thickness well consistent with the thickness range of real devices was derived.",
            "contribution_ids": [
                "R139607"
            ]
        },
        {
            "instance_id": "R139642xR139614",
            "comparison_id": "R139642",
            "paper_id": "R139614",
            "text": "Highly Efficient and Stable Sn-Rich Perovskite Solar Cells by Introducing Bromine compositional engineering of recently arising methylammonium (ma) lead (pb) halide based perovskites is an essential approach for finding better perovskite compositions to resolve still remaining issues of toxic pb, long-term instability, etc. in this work, we carried out crystallographic, morphological, optical, and photovoltaic characterization of compositional masn0.6pb0.4i3-xbrx by gradually introducing bromine (br) into parental pb-sn binary perovskite (masn0.6pb0.4i3) to elucidate its function in sn-rich (sn:pb = 6:4) perovskites. we found significant advances in crystallinity and dense coverage of the perovskite films by inserting the br into sn-rich perovskite lattice. furthermore, light-intensity-dependent open circuit voltage (voc) measurement revealed much suppressed trap-assisted recombination for a proper br-added (x = 0.4) device. these contributed to attaining the unprecedented power conversion efficiency of 12.1% and voc of 0.78 v, which are, to the best of our knowledge, the highest performance in the sn-rich (\u226560%) perovskite solar cells reported so far. in addition, impressive enhancement of photocurrent-output stability and little hysteresis were found, which paves the way for the development of environmentally benign (pb reduction), stable monolithic tandem cells using the developed low band gap (1.24-1.26 ev) masn0.6pb0.4i3-xbrx with suggested composition (x = 0.2-0.4).",
            "contribution_ids": [
                "R139617"
            ]
        },
        {
            "instance_id": "R139642xR139634",
            "comparison_id": "R139642",
            "paper_id": "R139634",
            "text": "Highly Reproducible Sn-Based Hybrid Perovskite Solar Cells with 9% Efficiency the low power conversion efficiency (pce) of tin\u2010based hybrid perovskite solar cells (hpscs) is mainly attributed to the high background carrier density due to a high density of intrinsic defects such as sn vacancies and oxidized species (sn4+) that characterize sn\u2010based hpscs. herein, this study reports on the successful reduction of the background carrier density by more than one order of magnitude by depositing near\u2010single\u2010crystalline formamidinium tin iodide (fasni3) films with the orthorhombic a\u2010axis in the out\u2010of\u2010plane direction. using these highly crystalline films, obtained by mixing a very small amount (0.08 m) of layered (2d) sn perovskite with 0.92 m (3d) fasni3, for the first time a pce as high as 9.0% in a planar p\u2013i\u2013n device structure is achieved. these devices display negligible hysteresis and light soaking, as they benefit from very low trap\u2010assisted recombination, low shunt losses, and more efficient charge collection. this represents a 50% improvement in pce compared to the best reference cell based on a pure fasni3 film using snf2 as a reducing agent. moreover, the 2d/3d\u2010based hpscs show considerable improved stability due to the enhanced robustness of the perovskite film compared to the reference cell.",
            "contribution_ids": [
                "R139637"
            ]
        },
        {
            "instance_id": "R139972xR139938",
            "comparison_id": "R139972",
            "paper_id": "R139938",
            "text": "Micromachined accelerometer with no proof mass this paper describes a revolutionary micromachined accelerometer which is simple, reliable, and inexpensive to make. the operating principle of this accelerometer is based on free-convection heat transfer of a tiny hot air bubble in an enclosed chamber. an experimental device has demonstrated a 0.6 milli-g sensitivity which can theoretically be extended to sub-micro-g level.",
            "contribution_ids": [
                "R139940"
            ]
        },
        {
            "instance_id": "R139972xR139963",
            "comparison_id": "R139972",
            "paper_id": "R139963",
            "text": "Theoretical Modeling, Numerical Simulations and Experimental Study of Micro Thermal Convective Accelerometers we present a one-dimensional (1d) theoretical model for the design analysis of a micro thermal convective accelerometer (mtca). systematical design analysis was conducted on the sensor performance covering the sensor output, sensitivity, and power consumption. the sensor output was further normalized as a function of normalized input acceleration in terms of rayleigh number r $_{\\\\mathrm {a}}$ (the product of grashof number g $_{\\\\mathrm {r}}$ and prandtl number p $_{\\\\mathrm {r}}$ ) for different fluids. a critical rayleigh number ( r a c = 3,000) is founded, for the first time, to determine the boundary between the linear and nonlinear response regime of mtca. based on the proposed 1d model, key parameters, including the location of the detectors, sensor length, thin film thickness, cavity height, heater temperature, and fluid types, were optimized to improve sensor performance. accordingly, a cmos compatible mtca was designed and fabricated based on the theoretical analysis, which showed a high sensitivity of 1,289 mv/g. therefore, this efficient 1d model, one million times faster than cfd simulation, can be a promising tool for the system-level cmos mems design.",
            "contribution_ids": [
                "R139968"
            ]
        },
        {
            "instance_id": "R140131xR140106",
            "comparison_id": "R140131",
            "paper_id": "R140106",
            "text": "Smart Cities in Europe \"urban performance currently depends not only on a city's endowment of hard infrastructure (physical capital), but also, and increasingly so, on the availability and quality of knowledge communication and social infrastructure (human and social capital). the latter form of capital is decisive for urban competitiveness. against this background, the concept of the \u201csmart city\u201d has recently been introduced as a strategic device to encompass modern urban production factors in a common framework and, in particular, to highlight the importance of information and communication technologies (icts) in the last 20 years for enhancing the competitive profile of a city. the present paper aims to shed light on the often elusive definition of the concept of the \u201csmart city.\u201d we provide a focused and operational definition of this construct and present consistent evidence on the geography of smart cities in the eu27. our statistical and graphical analyses exploit in depth, for the first time to our knowledge, the most recent version of the urban audit data set in order to analyze the factors determining the performance of smart cities. we find that the presence of a creative class, the quality of and dedicated attention to the urban environment, the level of education, and the accessibility to and use of icts for public administration are all positively correlated with urban wealth. this result prompts the formulation of a new strategic agenda for european cities that will allow them to achieve sustainable urban development and a better urban landscape.\"",
            "contribution_ids": [
                "R140108"
            ]
        },
        {
            "instance_id": "R140131xR139853",
            "comparison_id": "R140131",
            "paper_id": "R139853",
            "text": "SMART CITIES AND HERITAGE CONSERVATION: DEVELOPING A SMARTHERITAGE AGENDA FOR SUSTAINABLE INCLUSIVE COMMUNITIES this paper discusses the potential of current advancements in information communication technologies (ict) for cultural heritage preservation, valorization and management within contemporary cities. the paper highlights the potential of virtual environments to assess the impacts of heritage policies on urban development. it does so by discussing the implications of virtual globes and crowdsourcing to support the participatory valuation and management of cultural heritage assets. to this purpose, a review of available valuation techniques is here presented together with a discussion on how these techniques might be coupled with ict tools to promote inclusive governance.\\xa0",
            "contribution_ids": [
                "R139855"
            ]
        },
        {
            "instance_id": "R140131xR140030",
            "comparison_id": "R140131",
            "paper_id": "R140030",
            "text": "World Heritage meets Smart City in an Urban-Educational Hackathon in Rauma \"during recent years, the \u2018smart city\u2019 concept has emerged in literature (e.g., kunttu, 2019; markkula & kune, 2018; \u00f6berg, graham, & hennelly, 2017; visvizi & lytras, 2018). inherently, the smart city concept includes urban innovation; therefore, simply developing and applying technology is not enough for success. for cities to be 'smart,' they also have to be innovative, apply new ways of thinking among businesses, citizens, and academia, as well as integrate diverse actors, especially universities, in their innovation practices (kunttu, 2019; markkula & kune, 2018).\"",
            "contribution_ids": [
                "R140034"
            ]
        },
        {
            "instance_id": "R140347xR135750",
            "comparison_id": "R140347",
            "paper_id": "R135750",
            "text": "Characterization and comparison of poorly known moth communities through DNA barcoding in two Afrotropical environments in Gabon biodiversity research in tropical ecosystems\u2014popularized as the most biodiverse habitats on earth\u2014often neglects invertebrates, yet invertebrates represent the bulk of local species richness. insect communities in particular remain strongly impeded by both linnaean and wallacean shortfalls, and identifying species often remains a formidable challenge inhibiting the use of these organisms as indicators for ecological and conservation studies. here we use dna barcoding as an alternative to the traditional taxonomic approach for characterizing and comparing the diversity of moth communities in two different ecosystems in gabon. though sampling remains very incomplete, as evidenced by the high proportion (59%) of species represented by singletons, our results reveal an outstanding diversity. with about 3500 specimens sequenced and representing 1385 bins (barcode index numbers, used as a proxy to species) in 23 families, the diversity of moths in the two sites sampled is higher than the current number of species listed for the entire country, highlighting the huge gap in biodiversity knowledge for this country. both seasonal and spatial turnovers are strikingly high (18.3% of bins shared between seasons, and 13.3% between sites) and draw attention to the need to account for these when running regional surveys. our results also highlight the richness and singularity of savannah environments and emphasize the status of central african ecosystems as hotspots of biodiversity.",
            "contribution_ids": [
                "R135752"
            ]
        },
        {
            "instance_id": "R140348xR140132",
            "comparison_id": "R140348",
            "paper_id": "R140132",
            "text": "DeepWalk: online learning of social representations \"we present deepwalk, a novel approach for learning latent representations of vertices in a network. these latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models. deepwalk generalizes recent advancements in language modeling and unsupervised feature learning (or deep learning) from sequences of words to graphs. deepwalk uses local information obtained from truncated random walks to learn latent representations by treating walks as the equivalent of sentences. we demonstrate deepwalk's latent representations on several multi-label network classification tasks for social networks such as blogcatalog, flickr, and youtube. our results show that deepwalk outperforms challenging baselines which are allowed a global view of the network, especially in the presence of missing information. deepwalk's representations can provide f1 scores up to 10% higher than competing methods when labeled data is sparse. in some experiments, deepwalk's representations are able to outperform all baseline methods while using 60% less training data. deepwalk is also scalable. it is an online learning algorithm which builds useful incremental results, and is trivially parallelizable. these qualities make it suitable for a broad class of real world applications such as network classification, and anomaly detection.\"",
            "contribution_ids": [
                "R140134"
            ]
        },
        {
            "instance_id": "R140348xR140159",
            "comparison_id": "R140348",
            "paper_id": "R140159",
            "text": "LogicENN: A Neural Based Knowledge Graphs Embedding Model with Logical Rules knowledge graph embedding models have gained significant attention in ai research. the aim of knowledge graph embedding is to embed the graphs into a vector space in which the structure of the graph is preserved. recent works have shown that the inclusion of background knowledge, such as logical rules, can improve the performance of embeddings in downstream machine learning tasks. however, so far, most existing models do not allow the inclusion of rules. we address the challenge of including rules and present a new neural based embedding model (logicenn). we prove that logicenn can learn every ground truth of encoded rules in a knowledge graph. to the best of our knowledge, this has not been proved so far for the neural based family of embedding models. moreover, we derive formulae for the inclusion of various rules, including (anti-)symmetric, inverse, irreflexive and transitive, implication, composition, equivalence, and negation. our formulation allows avoiding grounding for implication and equivalence relations. our experiments show that logicenn outperforms the existing models in link prediction.",
            "contribution_ids": [
                "R140160"
            ]
        },
        {
            "instance_id": "R140348xR140164",
            "comparison_id": "R140348",
            "paper_id": "R140164",
            "text": "OPA2Vec: combining formal and informal content of biomedical ontologies to improve similarity-based prediction motivation\\nontologies are widely used in biology for data annotation, integration and analysis. in addition to formally structured axioms, ontologies contain meta-data in the form of annotation axioms which provide valuable pieces of information that characterize ontology classes. annotation axioms commonly used in ontologies include class labels, descriptions or synonyms. despite being a rich source of semantic information, the ontology meta-data are generally unexploited by ontology-based analysis methods such as semantic similarity measures.\\n\\n\\nresults\\nwe propose a novel method, opa2vec, to generate vector representations of biological entities in ontologies by combining formal ontology axioms and annotation axioms from the ontology meta-data. we apply a word2vec model that has been pre-trained on either a corpus or abstracts or full-text articles to produce feature vectors from our collected data. we validate our method in two different ways: first, we use the obtained vector representations of proteins in a similarity measure to predict protein-protein interaction on two different datasets. second, we evaluate our method on predicting gene-disease associations based on phenotype similarity by generating vector representations of genes and diseases using a phenotype ontology, and applying the obtained vectors to predict gene-disease associations using mouse model phenotypes. we demonstrate that opa2vec significantly outperforms existing methods for predicting gene-disease associations. using evidence from mouse models, we apply opa2vec to identify candidate genes for several thousand rare and orphan diseases. opa2vec can be used to produce vector representations of any biomedical entity given any type of biomedical ontology.\\n\\n\\navailability and implementation\\nhttps://github.com/bio-ontology-research-group/opa2vec.\\n\\n\\nsupplementary information\\nsupplementary data are available at bioinformatics online.",
            "contribution_ids": [
                "R140167"
            ]
        },
        {
            "instance_id": "R140348xR140171",
            "comparison_id": "R140348",
            "paper_id": "R140171",
            "text": "On2vec: Embedding-based relation prediction for ontology population populating ontology graphs represents a long-standing problem for the semantic web community. recent advances in translation-based graph embedding methods for populating instance-level knowledge graphs lead to promising new approaching for the ontology population problem. however, unlike instance-level graphs, the majority of relation facts in ontology graphs come with comprehensive semantic relations, which often include the properties of transitivity and symmetry, as well as hierarchical relations. these comprehensive relations are often too complex for existing graph embedding methods, and direct application of such methods is not feasible. hence, we propose on2vec, a novel translation-based graph embedding method for ontology population. on2vec integrates two model components that effectively characterize comprehensive relation facts in ontology graphs. the first is the component-specific model that encodes concepts and relations into low-dimensional embedding spaces without a loss of relational properties; the second is the hierarchy model that performs focused learning of hierarchical relation facts. experiments on several well-known ontology graphs demonstrate the promising capabilities of on2vec in predicting and verifying new relation facts. these promising results also make possible significant improvements in related methods.",
            "contribution_ids": [
                "R140173"
            ]
        },
        {
            "instance_id": "R140543xR139324",
            "comparison_id": "R140543",
            "paper_id": "R139324",
            "text": "Graphene Nanomesh As Highly Sensitive Chemiresistor Gas Sensor graphene is a one atom thick carbon allotrope with all surface atoms that has attracted significant attention as a promising material as the conduction channel of a field-effect transistor and chemical field-effect transistor sensors. however, the zero bandgap of semimetal graphene still limits its application for these devices. in this work, ethanol-chemical vapor deposition (cvd) of a grown p-type semiconducting large-area monolayer graphene film was patterned into a nanomesh by the combination of nanosphere lithography and reactive ion etching and evaluated as a field-effect transistor and chemiresistor gas sensors. the resulting neck-width of the synthesized nanomesh was about \u223c20 nm and was comprised of the gap between polystyrene (ps) spheres that was formed during the reactive ion etching (rie) process. the neck-width and the periodicities of the graphene nanomesh (gnm) could be easily controlled depending on the duration/power of the rie and the size of the ps nanospheres. the fabricated gnm transistor device exhibited promising electronic properties featuring a high drive current and an i(on)/i(off) ratio of about 6, significantly higher than its film counterpart. similarly, when applied as a chemiresistor gas sensor at room temperature, the graphene nanomesh sensor showed excellent sensitivity toward no(2) and nh(3), significantly higher than their film counterparts. the ethanol-based graphene nanomesh sensors exhibited sensitivities of about 4.32%/ppm in no(2) and 0.71%/ppm in nh(3) with limits of detection of 15 and 160 ppb, respectively. our demonstrated studies on controlling the neck width of the nanomesh would lead to further improvement of graphene-based transistors and sensors.",
            "contribution_ids": [
                "R139326",
                "R140513"
            ]
        },
        {
            "instance_id": "R140543xR139343",
            "comparison_id": "R140543",
            "paper_id": "R139343",
            "text": "Exfoliated black phosphorus gas sensing properties at room temperature room temperature gas sensing properties of chemically exfoliated black phosphorus (bp) to oxidizing (no2, co2) and reducing (nh3, h2, co) gases in a dry air carrier have been reported. to study the gas sensing properties of bp, chemically exfoliated bp flakes have been drop casted on si3n4 substrates provided with pt comb-type interdigitated electrodes in n2 atmosphere. scanning electron microscopy and x-ray photoelectron spectroscopy characterizations show respectively the occurrence of a mixed structure, composed of bp coarse aggregates dispersed on bp exfoliated few layer flakes bridging the electrodes, and a clear 2p doublet belonging to bp, which excludes the occurrence of surface oxidation. room temperature electrical tests in dry air show a p-type response of multilayer bp with measured detection limits of 20 ppb and 10 ppm to no2 and nh3 respectively. no response to co and co2 has been detected, while a slight but steady sensitivity to h2 has been recorded. the reported results confirm, on an experimental basis, what was previously theoretically predicted, demonstrating the promising sensing properties of exfoliated bp.",
            "contribution_ids": [
                "R139345",
                "R140503"
            ]
        },
        {
            "instance_id": "R140543xR140539",
            "comparison_id": "R140543",
            "paper_id": "R140539",
            "text": "Porous ZnO Polygonal Nanoflakes: Synthesis, Use in High-Sensitivity NO2 Gas Sensor, and Proposed Mechanism of Gas Sensing unique porous zno polygonal nanoflakes were synthesized by the microwave hydrothermal method. the structural properties of the products were investigated by using x-ray diffraction, scanning electron microscopy, transmission electron microscopy (tem), and high-resolution tem techniques. in situ diffuse reflectance infrared fourier transform spectroscopy technique was employed to investigate the mechanism of no2 sensing. free nitrate ions, nitrate ions, and nitrite anions were the main adsorbed species. n2o was formed via no\u2013 and n2o2\u2013 that were stemmed from no. comparative tests for gas sensing between gas sensors based on the as-prepared porous zno nanoflakes and purchased zno nanoparticles clearly showed that the former exhibited more excellent no2 sensing performances. photoluminescence and x-ray photoelectron spectroscopy spectra further proved that the intensities of donors (oxygen vacancy (vo) and/or zinc interstitial (zni)) and surface oxygen species (o2\u2013 and o2), which were involved in the mechani...",
            "contribution_ids": [
                "R140541"
            ]
        },
        {
            "instance_id": "R141156xR141119",
            "comparison_id": "R141156",
            "paper_id": "R141119",
            "text": "High-isolation CPW MEMS shunt switches-part 1: modeling  this paper, the first of two parts, presents an electromagnetic model for membrane microelectromechanical systems (mems) shunt switches for microwave/millimeter-wave applications. the up-state capacitance can be accurately modeled using three-dimensional static solvers, and full-wave solvers are used to predict the current distribution and inductance of the switch. the loss in the up-state position is equivalent to the coplanar waveguide line loss and is 0.01-0.02 db at 10-30 ghz for a 2-/spl mu/m-thick au mems shunt switch. it is seen that the capacitance, inductance, and series resistance can be accurately extracted from dc-40 ghz s-parameter measurements. it is also shown that dramatic increase in the down-state isolation (20/sup +/ db) can be achieved with the choice of the correct lc series resonant frequency of the switch. in part 2 of this paper, the equivalent capacitor-inductor-resistor model is used in the design of tuned high isolation switches at 10 and 30 ghz.",
            "contribution_ids": [
                "R141121"
            ]
        },
        {
            "instance_id": "R141156xR141136",
            "comparison_id": "R141156",
            "paper_id": "R141136",
            "text": "A zipper RF MEMS tunable capacitor with interdigitated RF and actuation electrodes this paper presents a new rf mems tunable capacitor based on the zipper principle and with interdigitated rf and actuation electrodes. the electrode configuration prevents dielectric charging under high actuation voltages. it also increases the capacitance ratio and the tunable analog range. the effect of the residual stress on the capacitance tunability is also investigated. two devices with different interdigital rf and actuation electrodes are fabricated on an alumina substrate and result in a capacitance ratio around 3.0 (cmin = 70\u201390 ff, cmax = 240\u2013270 ff) and with a q > 100 at 3 ghz. this design can be used in wideband tunable filters and matching networks.",
            "contribution_ids": [
                "R141138"
            ]
        },
        {
            "instance_id": "R141156xR141150",
            "comparison_id": "R141156",
            "paper_id": "R141150",
            "text": "Investigation of Charge Injection and Relaxation in Multilayer Dielectric Stacks for Capacitive RF MEMS Switch Application this paper proposes a new approach to the problem of irreversible stiction of capacitive radio frequency (rf) microelectromechanical (mems) switch attributed to the dielectric charging. we investigate how charge accumulates in multi- and single-layer dielectric structures for a capacitive rf mems switch using metal-insulator-semiconductor (mis) capacitor structure. two multidielectric-layers are structured, which are sio2+si3n4 and sio2+si3n4+sio2 stack films. meanwhile, si3n4 single-layer dielectric structure is also fabricated for comparison. in the experiments, the space charges are first injected into the dielectric layers by stressing mis devices with a dc bias; then the injected charge kinetics are monitored by capacitance-voltage measurement before and after charge injection. we found that the polarity of charge accumulated in the dielectric is strongly influenced by the dielectric structure. when the metal electrode is positively biased, a negative charge accumulates in the single and triple-layer devices, while a positive charge accumulates in the double-layer devices. furthermore, the experiment results also show that the lowest charge accumulation can be achieved using double-layer dielectric structure even though the fastest relaxation process takes place in triple-layer dielectric structure.",
            "contribution_ids": [
                "R141152"
            ]
        },
        {
            "instance_id": "R141425xR141401",
            "comparison_id": "R141425",
            "paper_id": "R141401",
            "text": "Application of camelid heavy-chain variable domains (VHHs) in prevention and treatment of bacterial and viral infections abstract camelid heavy-chain variable domains (vhhs) are the smallest, intact, antigen-binding units to occur in nature. vhhs possess high degrees of solubility and robustness enabling generation of multivalent constructs with increased avidity \u2013 characteristics that mark their superiority to other antibody fragments and monoclonal antibodies. capable of effectively binding to molecular targets inaccessible to classical immunotherapeutic agents and easily produced in microbial culture, vhhs are considered promising tools for pharmaceutical biotechnology. with the aim to demonstrate the perspective and potential of vhhs for the development of prophylactic and therapeutic drugs to target diseases caused by bacterial and viral infections, this review article will initially describe the structural features that underlie the unique properties of vhhs and explain the methods currently used for the selection and recombinant production of pathogen-specific vhhs, and then thoroughly summarize the experimental findings of five distinct studies that employed vhhs as inhibitors of host\u2013pathogen interactions or neutralizers of infectious agents. past and recent studies suggest the potential of camelid heavy-chain variable domains as a novel modality of immunotherapeutic drugs and a promising alternative to monoclonal antibodies. vhhs demonstrate the ability to interfere with bacterial pathogenesis by preventing adhesion to host tissue and sequestering disease-causing bacterial toxins. to protect from viral infections, vhhs may be employed as inhibitors of viral entry by binding to viral coat proteins or blocking interactions with cell-surface receptors. the implementation of vhhs as immunotherapeutic agents for infectious diseases is of considerable potential and set to contribute to public health in the near future.",
            "contribution_ids": [
                "R141402"
            ]
        },
        {
            "instance_id": "R141425xR141413",
            "comparison_id": "R141425",
            "paper_id": "R141413",
            "text": "Novel coronavirus-like particles targeting cells lining the respiratory tract virus like particles (vlps) produced by the expression of viral structural proteins can serve as versatile nanovectors or potential vaccine candidates. in this study we describe for the first time the generation of hcov-nl63 vlps using baculovirus system. major structural proteins of hcov-nl63 have been expressed in tagged or native form, and their assembly to form vlps was evaluated. additionally, a novel procedure for chromatography purification of hcov-nl63 vlps was developed. interestingly, we show that these nanoparticles may deliver cargo and selectively transduce cells expressing the ace2 protein such as ciliated cells of the respiratory tract. production of a specific delivery vector is a major challenge for research concerning targeting molecules. the obtained results show that hcov-nl63 vlps may be efficiently produced, purified, modified and serve as a delivery platform. this study constitutes an important basis for further development of a promising viral vector displaying narrow tissue tropism.",
            "contribution_ids": [
                "R141414"
            ]
        },
        {
            "instance_id": "R141425xR141415",
            "comparison_id": "R141425",
            "paper_id": "R141415",
            "text": "Development of Label-Free Colorimetric Assay for MERS-CoV Using Gold Nanoparticles worldwide outbreaks of infectious diseases necessitate the development of rapid and accurate diagnostic methods. colorimetric assays are a representative tool to simply identify the target molecules in specimens through color changes of an indicator (e.g., nanosized metallic particle, and dye molecules). the detection method is used to confirm the presence of biomarkers visually and measure absorbance of the colored compounds at a specific wavelength. in this study, we propose a colorimetric assay based on an extended form of double-stranded dna (dsdna) self-assembly shielded gold nanoparticles (aunps) under positive electrolyte (e.g., 0.1 m mgcl2) for detection of middle east respiratory syndrome coronavirus (mers-cov). this platform is able to verify the existence of viral molecules through a localized surface plasmon resonance (lspr) shift and color changes of aunps in the uv\u2013vis wavelength range. we designed a pair of thiol-modified probes at either the 5\u2032 end or 3\u2032 end to organize complementary base pairs with upstream of the e protein gene (upe) and open reading frames (orf) 1a on mers-cov. the dsdna of the target and probes forms a disulfide-induced long self-assembled complex, which protects aunps from salt-induced aggregation and transition of optical properties. this colorimetric assay could discriminate down to 1 pmol/\u03bcl of 30 bp mers-cov and further be adapted for convenient on-site detection of other infectious diseases, especially in resource-limited settings.",
            "contribution_ids": [
                "R141416"
            ]
        },
        {
            "instance_id": "R141425xR141419",
            "comparison_id": "R141425",
            "paper_id": "R141419",
            "text": "Identification of sialic acid-binding function for the Middle East respiratory syndrome coronavirus spike glycoprotein significance \\n middle east respiratory syndrome coronavirus (mers-cov) recurrently infects humans from its dromedary camel reservoir, causing severe respiratory disease with an \u223c35% fatality rate. the virus binds to the dipeptidyl peptidase 4 (dpp4) entry receptor on respiratory epithelial cells via its spike protein. we here report that the mers-cov spike protein selectively binds to sialic acid (sia) and demonstrate that cell-surface sialoglycoconjugates can serve as an attachment factor. our observations warrant further research into the role of sia binding in the virus\u2019s host and tissue tropism and transmission, which may be influenced by the observed sia-binding fine specificity and by differences in sialoglycomes among host species.",
            "contribution_ids": [
                "R141420"
            ]
        },
        {
            "instance_id": "R141593xR141444",
            "comparison_id": "R141593",
            "paper_id": "R141444",
            "text": "Low-kfilms modification under EUV and VUV radiation modification of ultra-low-k films by extreme ultraviolet (euv) and vacuum ultraviolet (vuv) emission with 13.5, 58.4, 106, 147 and 193 nm wavelengths and fluences up to 6 \u00d7 1018 photons cm\u22122 is studied experimentally and theoretically to reveal the damage mechanism and the most \u2018damaging\u2019 spectral region. organosilicate glass (osg) and organic low-k films with k-values of 1.8\u20132.5 and porosity of 24\u201351% are used in these experiments. the si\u2013ch3 bonds depletion is used as a criterion of vuv damage of osg low-k films. it is shown that the low-k damage is described by two fundamental parameters: photoabsorption (pa) cross-section \u03c3pa and effective quantum yield \u03c6 of si\u2013ch3 photodissociation. the obtained \u03c3pa and \u03c6 values demonstrate that the effect of wavelength is defined by light absorption spectra, which in osg materials is similar to fused silica. this is the reason why vuv light in the range of \u223c58\u2013106 nm having the highest pa cross-sections causes strong si\u2013ch3 depletion only in the top part of the films (\u223c50\u2013100 nm). the deepest damage is observed after exposure to 147 nm vuv light since this emission is located at the edge of si\u2013o absorption, has the smallest pa cross-section and provides extensive si\u2013ch3 depletion over the whole film thickness. the effective quantum yield slowly increases with the increasing porosity but starts to grow quickly when the porosity exceeds the critical threshold located close to a porosity of \u223c50%. the high degree of pore interconnectivity of these films allows easy movement of the detached methyl radicals. the obtained results have a fundamental character and can be used for prediction of ulk material damage under vuv light with different wavelengths.",
            "contribution_ids": [
                "R141584",
                "R141771"
            ]
        },
        {
            "instance_id": "R141593xR141460",
            "comparison_id": "R141593",
            "paper_id": "R141460",
            "text": "An In Situ Comparison between VUV Photon and Ion Energy Fluxes to Polymer Surfaces Immersed in an RF Plasma absolutely calibrated vacuum ultraviolet (vuv) spectroscopy has been used to determine the energy fluxes of vuv photons at an electrically floating substrate in a low-pressure 13.56-mhz radiofrequency plasma reactor used for polymer surface treatments. these fluxes have been compared with the positive ion flux that was reported in an earlier study. at the typical operating parameters of 10-mtorr pressure and 10-w power, the total vuv energy flux is 2.2 mw cm-2, compared with a value of 3.3 mw cm-2 from the ions. with increasing power (from 0.5 to 12 w), both the ion and vuv energy fluxes increase monotonically. however, as the pressure increases, (1\u2212100 mtorr), the ion energy flux declines, while the vuv component increases. at discharge powers of 10 w, and pressures greater than 25 mtorr, the greater part of the energy flux to the surface is from the vuv photons. these measurements are used to determine which of the plasma components, vuv or ions, will be most effective in the treatment of polystyrene su...",
            "contribution_ids": [
                "R141592",
                "R141779"
            ]
        },
        {
            "instance_id": "R141593xR141532",
            "comparison_id": "R141593",
            "paper_id": "R141532",
            "text": "VUV Spectral Irradiance Measurements in H\n                    2\n                    /He/Ar Microwave Plasmas and Comparison with Solar Data microwave plasmas with h2 and h2/rare gas mixtures are convenient sources of vuv radiation for laboratory simulations of astrophysical media. we recently undertook an extensive study to characterize microwave plasmas in an h2/he gas mixture in order to optimize a vuv solar simulator over the 115\u2013170 nm spectral range. in this paper, we extend our investigation to the effect of the addition of ar into h2/he plasma on the vuv spectral irradiance. our study combines various optical diagnostics such as a vuv spectrometer and optical emission spectroscopy. quantitative measurements of the spectral irradiance and photons flux in different mixtures are accomplished using a combination of vuv spectrometry and chemical actinometry. results show that the ar addition into h2/he plasma largely affects the predominant emissions of the hydrogen ly\u03b1 line (121.6 nm) and h2 (b\u03c3u\u2013x \u03c3g) band (150\u2013170 nm). while a microwave plasma with 1.4% h2/he is required to mimic the entire vuv solar spectrum in the 115\u2013170 nm range, the combination with 1.28% h2/35% ar/he is the best alternative to obtain a quasi-monochromatic spectrum with emission dominated by the ly\u03b1 line. the maximum of the spectral irradiance is significantly higher in the ternary mixtures compared to the binary mixture of 1.4% h2/he. further ar increase yielded lower spectral irradiance and absolute photon fluxes. our measured spectral irradiances are compared to vuv solar data in the 115\u2013170 nm range, emphasizing the use of microwave plasmas in astrophysical studies and laboratory simulations of planetary atmospheres.",
            "contribution_ids": [
                "R141577",
                "R141764"
            ]
        },
        {
            "instance_id": "R141593xR108936",
            "comparison_id": "R141593",
            "paper_id": "R108936",
            "text": "Absolute vacuum ultraviolet flux in inductively coupled plasmas and chemical modifications of 193 nm photoresist vacuum ultraviolet (vuv) photons in plasma processing systems are known to alter surface chemistry and may damage gate dielectrics and photoresist. we characterize absolute vuv fluxes to surfaces exposed in an inductively coupled argon plasma, 1\u201350 mtorr, 25\u2013400 w, using a calibrated vuv spectrometer. we also demonstrate an alternative method to estimate vuv fluence in an inductively coupled plasma (icp) reactor using a chemical dosimeter-type monitor. we illustrate the technique with argon icp and xenon lamp exposure experiments, comparing direct vuv measurements with measured chemical changes in 193 nm photoresist-covered si wafers following vuv exposure.",
            "contribution_ids": [
                "R141590",
                "R141777"
            ]
        },
        {
            "instance_id": "R141699xR141621",
            "comparison_id": "R141699",
            "paper_id": "R141621",
            "text": "Probing the highly efficient room temperature ammonia gas sensing properties of a luminescent ZnO nanowire array prepared via an AAO-assisted template route a highly ordered luminescent zno nanowire array was synthesized which has excellent sensitivity and fast response to nh 3 gas.",
            "contribution_ids": [
                "R141623"
            ]
        },
        {
            "instance_id": "R141699xR141631",
            "comparison_id": "R141699",
            "paper_id": "R141631",
            "text": "Rice Husk Templated Mesoporous ZnO Nanostructures for Ethanol Sensing at Room Temperature mesoporous zinc oxide nanostructures are successfully synthesized via the sol-gel route by using a rice husk as the template for ethanol sensing at room temperature. the structure and morphology of the nanostructures are characterized by x-ray diffraction, scanning electron microscopy (sem), transmission electron microscopy (tem), and nitrogen adsorption\u2013desorption analyses. the mechanism for the growth of zinc oxide nanostructures over the biotemplate is proposed. sem and tem observations also reveal the formation of spherical zinc oxide nanoparticles over the interwoven fibrous network. multiple sized pores having pore diameter ranging from 10\u201340 nm is also evidenced from the pore size distribution plot. the larger surface area and porous nature of the material lead to high sensitivity (40.93% for 300 ppm of ethanol), quick response (42 s) and recovery (40 s) towards ethanol at 300 k. the porous nature of the interwoven fibre-like network affords mass transportation of ethanol vapor, which results in faster surface accessibility, and hence it acts as a potential candidate for ethanol sensing at room temperature.",
            "contribution_ids": [
                "R141633"
            ]
        },
        {
            "instance_id": "R141752xR141205",
            "comparison_id": "R141752",
            "paper_id": "R141205",
            "text": "Governance Infrastructures in 2020 a governance infrastructure is the collection of technologies and systems, people, policies, practices, and relationships that interact to support governing activities. information technology, especially communication and computational technologies, continues to augment society\u2019s ability to organize, interact, and govern. as we think about the future of governance, this article challenges us to move beyond questions of how to best manage government institutions to how to design smart governance systems with the appropriate incentives and rules to harness and coordinate the enthusiasm and capabilities of those governed. this article anticipates how the interaction of technology and society can be leveraged to mindfully design an interaction-defined, participation-based governance infrastructure to return power to the people while increasing accountability. supporting examples of such governance approaches already exist and are regularly emerging in distributed organizations, online communities, nonprofits, and governments.",
            "contribution_ids": [
                "R141207",
                "R142079"
            ]
        },
        {
            "instance_id": "R141752xR141214",
            "comparison_id": "R141752",
            "paper_id": "R141214",
            "text": "Conceptualizing smart city with dimensions of technology, people, and institutions this conceptual paper discusses how we can consider a particular city as a smart one, drawing on recent practices to make cities smart. a set of the common multidimensional components underlying the smart city concept and the core factors for a successful smart city initiative is identified by exploring current working definitions of smart city and a diversity of various conceptual relatives similar to smart city. the paper offers strategic principles aligning to the three main dimensions (technology, people, and institutions) of smart city: integration of infrastructures and technology-mediated services, social learning for strengthening human infrastructure, and governance for institutional improvement and citizen engagement.",
            "contribution_ids": [
                "R141216",
                "R142076"
            ]
        },
        {
            "instance_id": "R141752xR141250",
            "comparison_id": "R141752",
            "paper_id": "R141250",
            "text": "Aspirations and Realizations: The Smart City of Seattle smart city initiatives have been launched on every continent. that notwithstanding the concept of \u201csmart city\u201d has remained ambiguous. we systematically interviewed officials of an acclaimed smart city (seattle) and explicitly asked the officials for their own definitions of \u201csmart city,\u201d which we then compared to the respective projects run by that city. while the definitions given by the practitioners were found different from those in the literature, the smart city projects lived up and matched the practitioner definitions to a high degree. we document the projects and their expected and realized benefits, which illustrate where a leading city government is headed in terms of smart government. however, \u201csmart city\u201d initiatives in local government might be only a steppingstone in making the greater urban space a \u201csmart city,\u201d which appears to be a more challenging undertaking.",
            "contribution_ids": [
                "R141252",
                "R141757",
                "R142064"
            ]
        },
        {
            "instance_id": "R141780xR141661",
            "comparison_id": "R141780",
            "paper_id": "R141661",
            "text": "Fluorescent N-Doped Carbon Dots as in Vitro and in Vivo Nanothermometer the fluorescent n-doped carbon dots (n-cds) obtained from c3n4 emit strong blue fluorescence, which is stable with different ionic strengths and time. the fluorescence intensity of n-cds decreases with the temperature increasing, while it can recover to the initial one with the temperature decreasing. it is an accurate linear response of fluorescence intensity to temperature, which may be attributed to the synergistic effect of abundant oxygen-containing functional groups and hydrogen bonds. further experiments also demonstrate that n-cds can serve as effective in vitro and in vivo fluorescence-based nanothermometer.",
            "contribution_ids": [
                "R141663"
            ]
        },
        {
            "instance_id": "R141780xR141708",
            "comparison_id": "R141780",
            "paper_id": "R141708",
            "text": "N,S co-doped carbon dots as a stable bio-imaging probe for detection of intracellular temperature and tetracycline n,s-cds display an unambiguous bioimaging ability in the detection of intracellular temperature and tetracycline with satisfactory results.",
            "contribution_ids": [
                "R141713"
            ]
        },
        {
            "instance_id": "R142850xR142837",
            "comparison_id": "R142850",
            "paper_id": "R142837",
            "text": "New Method for Delivering a Hydrophobic Drug for Photodynamic Therapy Using Pure Nanocrystal Form of the Drug a carrier-free method for delivery of a hydrophobic drug in its pure form, using nanocrystals (nanosized crystals), is proposed. to demonstrate this technique, nanocrystals of a hydrophobic photosensitizing anticancer drug, 2-devinyl-2-(1-hexyloxyethyl)pyropheophorbide (hpph), have been synthesized using the reprecipitation method. the resulting drug nanocrystals were monodispersed and stable in aqueous dispersion, without the necessity of an additional stabilizer (surfactant). as shown by confocal microscopy, these pure drug nanocrystals were taken up by the cancer cells with high avidity. though the fluorescence and photodynamic activity of the drug were substantially quenched in the form of nanocrystals in aqueous suspension, both these characteristics were recovered under in vitro and in vivo conditions. this recovery of drug activity and fluorescence is possibly due to the interaction of nanocrystals with serum albumin, resulting in conversion of the drug nanocrystals into the molecular form. this was confirmed by demonstrating similar recovery in presence of fetal bovine serum (fbs) or bovine serum albumin (bsa). under similar treatment conditions, the hpph in nanocrystal form or in 1% tween-80/water formulation showed comparable in vitro and in vivo efficacy.",
            "contribution_ids": [
                "R142839"
            ]
        },
        {
            "instance_id": "R144121xR143919",
            "comparison_id": "R144121",
            "paper_id": "R143919",
            "text": "Enabling Folksonomies for Knowledge Extraction: A Semantic Grounding Approach folksonomies emerge as the result of the free tagging activity of a large number of users over a variety of resources. they can be considered as valuable sources from which it is possible to obtain emerging vocabularies that can be leveraged in knowledge extraction tasks. however, when it comes to understanding the meaning of tags in folksonomies, several problems mainly related to the appearance of synonymous and ambiguous tags arise, specifically in the context of multilinguality. the authors aim to turn folksonomies into knowledge structures where tag meanings are identified, and relations between them are asserted. for such purpose, they use dbpedia as a general knowledge base from which they leverage its multilingual capabilities.",
            "contribution_ids": [
                "R143921"
            ]
        },
        {
            "instance_id": "R144512xR144378",
            "comparison_id": "R144512",
            "paper_id": "R144378",
            "text": "In vivo biodistribution of venlafaxine-PLGA nanoparticles for brain delivery: plain vs. functionalized nanoparticles abstract background: actually, no drugs provide therapeutic benefit to approximately one-third of depressed patients. depression is predicted to become the first global disease by 2030. so, new therapeutic interventions are imperative. research design and methods: venlafaxine-loaded poly(lactic-co-glycolic acid) (plga) nanoparticles (nps) were surface functionalized with two ligands against transferrin receptor to enhance access to brain. an in vitro blood\u2013brain barrier model using hcmec/d3 cell line was developed to evaluate permeability. in vivo biodistribution studies were performed using c57/bl6 mice. particles were administered intranasal and main organs were analyzed. results: particles were obtained as a lyophilized powder easily to re-suspend. internalization and permeability studies showed the following cell association sequence: tfrp-nps>tf-nps>plain nps. permeability studies also showed that encapsulated vlf was not affected by p-gp pump efflux increasing its concentration in the basolateral side after 24 h. in vivo studies showed that 25% of plain nps reach the brain after 30 min of one intranasal administration while less than 5% of functionalized nps get the target. conclusions: plain nps showed the highest ability to reach the brain vs. functionalized nps after 30 min by intranasal administration. we suggest plain nps probably travel via direct nose-to-brian route whereas functionalized nps reach the brain by receptor-mediated endocytosis.",
            "contribution_ids": [
                "R144381",
                "R144382"
            ]
        },
        {
            "instance_id": "R144512xR144478",
            "comparison_id": "R144512",
            "paper_id": "R144478",
            "text": "Co-delivery of doxorubicin and siRNA for glioma therapy by a brain targeting system: angiopep-2-modified poly(lactic-co-glycolic acid) nanoparticles abstract it is very challenging to treat brain cancer because of the blood\u2013brain barrier (bbb) restricting therapeutic drug or gene to access the brain. in this research project, angiopep-2 (ang) was used as a brain-targeted peptide for preparing multifunctional ang-modified poly(lactic-co-glycolic acid) (plga) nanoparticles (nps), which encapsulated both doxorubicin (dox) and epidermal growth factor receptor (egfr) sirna, designated as ang/plga/dox/sirna. this system could efficiently deliver dox and sirna into u87mg cells leading to significant cell inhibition, apoptosis and egfr silencing in vitro. it demonstrated that this drug system was capable of penetrating the bbb in vivo, resulting in more drugs accumulation in the brain. the animal study using the brain orthotopic u87mg glioma xenograft model indicated that the ang-targeted co-delivery of dox and egfr sirna resulted in not only the prolongation of the life span of the glioma-bearing mice but also an obvious cell apoptosis in glioma tissue.",
            "contribution_ids": [
                "R144480"
            ]
        },
        {
            "instance_id": "R145685xR145174",
            "comparison_id": "R145685",
            "paper_id": "R145174",
            "text": "Theory of Line Broadening in Multiplet Spectra \"a theory of line broadening in the impect approximation is developed which includes the case of overlapping lines. it is assumed that the collisions which give rise to the broadening do not cause transitions between states with different principal quantam numbers. the theory was worked out in detail in two cases: (1) the broadening arises only from perturbations of the upper state with arbitrary splitting of the substates. this approximation may be used if the perturbations of the lower state are relatively unimportant (e.g.. the higher series members of the balmer lines), and is exact if the perturbations do not affect the lower state as in the case of the ground stute of hydrogen perturbed by electron collisions; (2) complete degeneracy of the initial and final states. this approximation is also valid on the far wing of the line if there is splitting, i.e.. for frequencies large compared to thc splitting, and is a generalization of anderson's theory. the formal theory is worked out by two different methods. the method of calculation for nearly degenerate initial and final states with splitting is indicated. method i is particularly suited for calculating the wing distribution while method ii is more suitable formore\\xa0\u00bb finding tbe intensity distribution at the line center for overlapping lines. the line profile is made up of a sum of dispersion profiles and asymmetric terms whicb arise from interferences when the transition operator is not diagonal. the shift and half-width parameters are found from the roots of a secular equation and depend on the splitting as well as the density. temperature. and the character of the perturbation. (auth)\u00ab\\xa0less\"",
            "contribution_ids": [
                "R145225"
            ]
        },
        {
            "instance_id": "R145685xR145180",
            "comparison_id": "R145685",
            "paper_id": "R145180",
            "text": "Stark Broadening of Neutral Helium Lines in a Plasma \"the frequency distributions of spectral lines of nonhydrogenic atoms broadened by local fields of both electrons and ions in a plasma are calculated in the classical path approximation. the electron collisions are treated by an impact theory which takes into account deviations from adiabaticity. for the ion effects, the adiabatic approximation can be used to describe the time-dependent wave functions. the various approximations employed were examined for self-consistency, and an accuracy of about 20% in the resulting line profiles is expected. good agreement with wulff's experimental helium line profiles was obtained while there are large deviations from the adiabatic theory, especially for the line shifts. asymptotic distributions for the line wings are given for astrophysical applications. here the ion effects can be as important as the electron effects and lead to large asymmetries, but near the line core electrons usually dominate. numerical results are tabulated for 24 neutral helium lines with principal quantum numbers up to five.\"",
            "contribution_ids": [
                "R145227"
            ]
        },
        {
            "instance_id": "R145685xR145210",
            "comparison_id": "R145685",
            "paper_id": "R145210",
            "text": "Stark broadening of the B III2s\u00e2\u0088\u00922plines we present a quantum-mechanical calculation of stark linewidths from electron-ion collisions for the 2s{sub 1/2}-2p{sub 1/2,3/2}, {lambda}=2066 and 2067 {angstrom}, resonance transitions in biii. the results confirm previous quantum-mechanical r-matrix calculations, but contradict recent measurements and semiclassical and some semiempirical calculations. the differences between the calculations can be attributed to the dominance of small l partial waves in the electron-atom scattering, while the large stark widths inferred from the measurements would be substantially reduced if allowance is made for hydrodynamic turbulence from high-reynolds-number flows and the associated doppler broadening. {copyright} {ital 1997} {ital the american physical society}",
            "contribution_ids": [
                "R145238"
            ]
        },
        {
            "instance_id": "R145685xR145213",
            "comparison_id": "R145685",
            "paper_id": "R145213",
            "text": "Electron impact broadening of spectral lines in Be-like ions: quantum calculations we present in this paper quantum mechanical calculations for the electron impact stark linewidths of the 2s3s\u20132s3p transitions for the four beryllium-like ions from n iv to ne vii. calculations are made in the frame of the impact approximation and intermediate coupling, taking into account fine-structure effects. a comparison between our calculations, experimental and other theoretical results, shows a good agreement. this is the first time that such a good agreement is found between quantum and experimental linewidths of highly charged ions.",
            "contribution_ids": [
                "R145239"
            ]
        },
        {
            "instance_id": "R145950xR142709",
            "comparison_id": "R145950",
            "paper_id": "R142709",
            "text": "Unified IoT ontology to enable interoperability and federation of testbeds \"after a thorough analysis of existing internet of things (iot) related ontologies, in this paper we propose a solution that aims to achieve semantic interoperability among heterogeneous testbeds. our model is framed within the eu h2020's fiesta-iot project, that aims to seamlessly support the federation of testbeds through the usage of semantic-based technologies. our proposed model (ontology) takes inspiration from the well-known noy et al. methodology for reusing and interconnecting existing ontologies. to build the ontology, we leverage a number of core concepts from various mainstream ontologies and taxonomies, such as semantic sensor network (ssn), m3-lite (a lite version of m3 and also an outcome of this study), wgs84, iot-lite, time, and dul. in addition, we also introduce a set of tools that aims to help external testbeds adapt their respective datasets to the developed ontology.\"",
            "contribution_ids": [
                "R142711",
                "R142852",
                "R144804"
            ]
        },
        {
            "instance_id": "R146458xR146051",
            "comparison_id": "R146458",
            "paper_id": "R146051",
            "text": "Innovation Management in the Context of Smart Cities Digital Transformation the paper introduces important aspects of doctoral research concerning innovation management in the context of business management challenges posed by digital transformation. the research was conducted as part of the research centre of business administration in the bucharest university of economic studies, romania. the study aims to identify and display key components of innovation management \u2013 with a primary focus on topics spurred by the recent wave of digital evolution. against this background, the issue of smart city solutions makes for an interesting case \u2013 firstly, because it affects a large number of people and businesses around the globe and secondly, the complexity of the topic forces companies to pursue different innovation management approaches to successfully manage its associated challenges as well as opportunities. the paper consists of an overview on the existing literature and a concise outline of our research. both researches from professional associations as well as recognized publishers were considered. furthermore, market data were gathered and processed. more than 50 publications were analyzed to better understand trends in digital transformation and its impact on innovation management. our research revealed that in the light of the fundamental challenges posed by digitization, companies are required to take a structured approach towards their innovation management options. in the context of smart city solutions, the adoption of the \u201c4i solutions model\u201d enables businesses to choose the strategic option suitable to their individual case. concisely, this framework includes four different approaches ranging from initiating groundwork innovation internally to establishing partnerships with selected external parties.",
            "contribution_ids": [
                "R146053"
            ]
        },
        {
            "instance_id": "R146458xR146090",
            "comparison_id": "R146458",
            "paper_id": "R146090",
            "text": "Internet of Things, legal and regulatory framework in digital transformation from smart to intelligent cities \"digital transformation from \u201csmart\u201d to \u201cintelligent city\u201d is based on new information technologies and knowledge, as well as on organizational and security processes. the authors of this paper will present the legal and regulatory framework and challenges of internet of things in development of smart cities on the way to become intelligent cities. the special contribution of the paper will be an overview of new legal and regulatory framework general data protection regulation (gdpr) which is of great importance for european union legal and regulation framework and bringing novelties in citizen's privacy and protection of personal data.\"",
            "contribution_ids": [
                "R146092"
            ]
        },
        {
            "instance_id": "R146458xR146157",
            "comparison_id": "R146458",
            "paper_id": "R146157",
            "text": "The digital transformation and smart data analytics: An overview of enabling developments and application areas the digital transformation enables new business models and enhanced business processes by utilizing available data for analytics, prediction, and decision support. we give an overview of the enabling developments for the digital transformation, the areas of application, and concrete use case examples. we summarize our findings in a framework for the digital transformation and discuss the potential for new and adapted business models.",
            "contribution_ids": [
                "R146159"
            ]
        },
        {
            "instance_id": "R146851xR145085",
            "comparison_id": "R146851",
            "paper_id": "R145085",
            "text": "Developing open source, self-contained disease surveillance software applications for use in resource-limited settings abstract background emerging public health threats often originate in resource-limited countries. in recognition of this fact, the world health organization issued revised international health regulations in 2005, which call for significantly increased reporting and response capabilities for all signatory nations. electronic biosurveillance systems can improve the timeliness of public health data collection, aid in the early detection of and response to disease outbreaks, and enhance situational awareness. methods as components of its suite for automated global biosurveillance (sages) program, the johns hopkins university applied physics laboratory developed two open-source, electronic biosurveillance systems for use in resource-limited settings. openessence provides web-based data entry, analysis, and reporting. essence desktop edition provides similar capabilities for settings without internet access. both systems may be configured to collect data using locally available cell phone technologies. results essence desktop edition has been deployed for two years in the republic of the philippines. local health clinics have rapidly adopted the new technology to provide daily reporting, thus eliminating the two-to-three week data lag of the previous paper-based system. conclusions openessence and essence desktop edition are two open-source software products with the capability of significantly improving disease surveillance in a wide range of resource-limited settings. these products, and other emerging surveillance technologies, can assist resource-limited countries compliance with the revised international health regulations.",
            "contribution_ids": [
                "R145087",
                "R145088",
                "R145089"
            ]
        },
        {
            "instance_id": "R146851xR145318",
            "comparison_id": "R146851",
            "paper_id": "R145318",
            "text": "Electronic Surveillance System for the Early Notification of Community-Based Epidemics (ESSENCE): Overview, Components, and Public Health Applications \\n background \\n the electronic surveillance system for the early notification of community-based epidemics (essence) is a secure web-based tool that enables health care practitioners to monitor health indicators of public health importance for the detection and tracking of disease outbreaks, consequences of severe weather, and other events of concern. the essence concept began in an internally funded project at the johns hopkins university applied physics laboratory, advanced with funding from the state of maryland, and broadened in 1999 as a collaboration with the walter reed army institute for research. versions of the system have been further developed by johns hopkins university applied physics laboratory in multiple military and civilian programs for the timely detection and tracking of health threats. \\n \\n \\n objective \\n this study aims to describe the components and development of a biosurveillance system increasingly coordinating all-hazards health surveillance and infectious disease monitoring among large and small health departments, to list the key features and lessons learned in the growth of this system, and to describe the range of initiatives and accomplishments of local epidemiologists using it. \\n \\n \\n methods \\n the features of essence include spatial and temporal statistical alerting, custom querying, user-defined alert notifications, geographical mapping, remote data capture, and event communications. to expedite visualization, configurable and interactive modes of data stratification and filtering, graphical and tabular customization, user preference management, and sharing features allow users to query data and view geographic representations, time series and data details pages, and reports. these features allow essence users to gather and organize the resulting wealth of information into a coherent view of population health status and communicate findings among users. \\n \\n \\n results \\n the resulting broad utility, applicability, and adaptability of this system led to the adoption of essence by the centers for disease control and prevention, numerous state and local health departments, and the department of defense, both nationally and globally. the open-source version of suite for automated global electronic biosurveillance is available for global, resource-limited settings. resourceful users of the us national syndromic surveillance program essence have applied it to the surveillance of infectious diseases, severe weather and natural disaster events, mass gatherings, chronic diseases and mental health, and injury and substance abuse. \\n \\n \\n conclusions \\n with emerging high-consequence communicable diseases and other health conditions, the continued user requirement\u2013driven enhancements of essence demonstrate an adaptable disease surveillance capability focused on the everyday needs of public health. the challenge of a live system for widely distributed users with multiple different data sources and high throughput requirements has driven a novel, evolving architecture design. \\n",
            "contribution_ids": [
                "R145327"
            ]
        },
        {
            "instance_id": "R146851xR145901",
            "comparison_id": "R146851",
            "paper_id": "R145901",
            "text": "Evaluating the electronic tuberculosis register surveillance system in Eden District, Western Cape, South Africa, 2015 abstract background: tuberculosis (tb) surveillance data are crucial to the effectiveness of national tb control programs. in south africa, few surveillance system evaluations have been undertaken to provide a rigorous assessment of the platform from which the national and district health systems draws data to inform programs and policies. objective: evaluate the attributes of eden district\u2019s tb surveillance system, western cape province, south africa. methods: data quality, sensitivity and positive predictive value were assessed using secondary data from 40,033 tb cases entered in eden district\u2019s etr.net from 2007 to 2013, and 79 purposively selected tb blue cards (tbcs), a medical patient file and source document for data entered into etr.net. simplicity, flexibility, acceptability, stability and usefulness of the etr.net were assessed qualitatively through interviews with tb nurses, information health officers, sub-district and district coordinators involved in the tb surveillance. results: tb surveillance system stakeholders report that eden district\u2019s etr.net system was simple, acceptable, flexible and stable, and achieves its objective of informing tb control program, policies and activities. data were less complete in the etr.net (66\u2013100%) than in the tbcs (76\u2013100%), and concordant for most variables except pre-treatment smear results, antiretroviral therapy (art) and treatment outcome. the sensitivity of recorded variables in etr.net was 98% for gender, 97% for patient category, 93% for art, 92% for treatment outcome and 90% for pre-treatment smear grading. conclusions: our results reveal that the system provides useful information to guide tb control program activities in eden district. however, urgent attention is needed to address gaps in clinical recording on the tbc and data capturing into the etr.net system. we recommend continuous training and support of tb personnel involved with tb care, management and surveillance on tb data recording into the tbcs and etr.net as well as the implementation of a well-structured quality control and assurance system.",
            "contribution_ids": [
                "R145904",
                "R145914",
                "R145915"
            ]
        },
        {
            "instance_id": "R146851xR146256",
            "comparison_id": "R146851",
            "paper_id": "R146256",
            "text": "Improving national surveillance of Lyme neuroborreliosis in Denmark through electronic reporting of specific antibody index testing from 2010 to 2012 our aim was to evaluate the results of automated surveillance of lyme neuroborreliosis (lnb) in denmark using the national microbiology database (miba), and to describe the epidemiology of laboratory-confirmed lnb at a national level. miba-based surveillance includes electronic transfer of laboratory results, in contrast to the statutory surveillance based on manually processed notifications. antibody index (ai) testing is the recommend laboratory test to support the diagnosis of lnb in denmark. in the period from 2010 to 2012, 217 clinical cases of lnb were notified to the statutory surveillance system, while 533 cases were reported ai positive by the miba system. thirty-five unconfirmed cases (29 ai-negative and 6 not tested) were notified, but not captured by miba. using miba, the number of reported cases was increased almost 2.5 times. furthermore, the reporting was timelier (median lag time: 6 vs 58 days). average annual incidence of ai-confirmed lnb in denmark was 3.2/100,000 population and incidences stratified by municipality ranged from none to above 10/100,000. this is the first study reporting nationwide incidence of lnb using objective laboratory criteria. laboratory-based surveillance with electronic data-transfer was more accurate, complete and timely compared to the surveillance based on manually processed notifications. we propose using ai test results for lnb surveillance instead of clinical reporting.\\n",
            "contribution_ids": [
                "R146258"
            ]
        },
        {
            "instance_id": "R147040xR145554",
            "comparison_id": "R147040",
            "paper_id": "R145554",
            "text": "Identifying the Main Mosquito Species in China Based on DNA Barcoding mosquitoes are insects of the diptera, nematocera, and culicidae families, some species of which are important disease vectors. identifying mosquito species based on morphological characteristics is difficult, particularly the identification of specimens collected in the field as part of disease surveillance programs. because of this difficulty, we constructed dna barcodes of the cytochrome c oxidase subunit 1, the coi gene, for the more common mosquito species in china, including the major disease vectors. a total of 404 mosquito specimens were collected and assigned to 15 genera and 122 species and subspecies on the basis of morphological characteristics. individuals of the same species grouped closely together in a neighborhood-joining tree based on coi sequence similarity, regardless of collection site. coi gene sequence divergence was approximately 30 times higher for species in the same genus than for members of the same species. divergence in over 98% of congeneric species ranged from 2.3% to 21.8%, whereas divergence in conspecific individuals ranged from 0% to 1.67%. cryptic species may be common and a few pseudogenes were detected.",
            "contribution_ids": [
                "R145555",
                "R155680"
            ]
        },
        {
            "instance_id": "R148381xR148267",
            "comparison_id": "R148381",
            "paper_id": "R148267",
            "text": "Enhanced delivery of etoposide across the blood\u00e2\u0080\u0093brain barrier to restrain brain tumor growth using melanotransferrin antibody- and tamoxifen-conjugated solid lipid nanoparticles abstract melanotransferrin antibody (ma) and tamoxifen (tx) were conjugated on etoposide (etp)-entrapped solid lipid nanoparticles (etp-slns) to target the blood\u2013brain barrier (bbb) and glioblastom multiforme (gbm). ma- and tx-conjugated etp-slns (ma\u2013tx\u2013etp\u2013slns) were used to infiltrate the bbb comprising a monolayer of human astrocyte-regulated human brain-microvascular endothelial cells (hbmecs) and to restrain the proliferation of malignant u87mg cells. tx-grafted etp-slns (tx\u2013etp\u2013slns) significantly enhanced the bbb permeability coefficient for etp and raised the fluorescent intensity of calcein-am when compared with etp-slns. in addition, surface ma could increase the bbb permeability coefficient for etp about twofold. the viability of hbmecs was higher than 86%, suggesting a high biocompatibility of ma\u2013tx\u2013etp-slns. moreover, the efficiency in antiproliferation against u87mg cells was in the order of ma\u2013tx\u2013etp-slns\\u2009\\u2009>\\u2009\\u2009tx\u2013etp-slns\\u2009\\u2009>\\u2009\\u2009etp-slns\\u2009\\u2009>\\u2009\\u2009slns. the capability of ma\u2013tx\u2013etp-slns to target hbmecs and u87mg cells during internalization was verified by immunochemical staining of expressed melanotransferrin. ma\u2013tx\u2013etp-slns can be a potent pharmacotherapy to deliver etp across the bbb to gbm.",
            "contribution_ids": [
                "R148269"
            ]
        },
        {
            "instance_id": "R148381xR148289",
            "comparison_id": "R148381",
            "paper_id": "R148289",
            "text": "Vincristine and temozolomide combined chemotherapy for the treatment of glioma: a comparison of solid lipid nanoparticles and nanostructured lipid carriers for dual drugs delivery abstract context: glioma is a common malignant brain tumor originating in the central nervous system. efficient delivery of therapeutic agents to the cells and tissues is a difficult challenge. co-delivery of anticancer drugs into the cancer cells or tissues by multifunctional nanocarriers may provide a new paradigm in cancer treatment. objective: in this study, solid lipid nanoparticles (slns) and nanostructured lipid carriers (nlcs) were constructed for co-delivery of vincristine (vcr) and temozolomide (tmz) to develop the synergetic therapeutic action of the two drugs. the antitumor effects of these two systems were compared to provide a better choice for gliomatosis cerebri treatment. methods: vcr- and tmz-loaded slns (vt-slns) and nlcs (vt-nlcs) were formulated. their particle size, zeta potential, drug encapsulation efficiency (ee) and drug loading capacity were evaluated. the single tmz-loaded slns and nlcs were also prepared as contrast. anti-tumor efficacies of the two kinds of carriers were evaluated on u87 malignant glioma cells and mice bearing malignant glioma model. results: significantly better glioma inhibition was observed on nlcs formulations than slns, and dual drugs displayed the highest antitumor efficacy in vivo and in vitro than all the other formulations used. conclusion: vt-nlcs can deliver vcr and tmz into u87mg cells more efficiently, and inhibition efficacy is higher than vt-slns. this dual drugs-loaded nlcs could be an outstanding drug delivery system to achieve excellent therapeutic efficiency for the treatment of malignant gliomatosis cerebri.",
            "contribution_ids": [
                "R148291",
                "R148292"
            ]
        },
        {
            "instance_id": "R150058xR145757",
            "comparison_id": "R150058",
            "paper_id": "R145757",
            "text": "SemEval-2018 Task 7: Semantic Relation Extraction and Classification in Scientific Papers this paper describes the first task on semantic relation extraction and classification in scientific paper abstracts at semeval 2018. the challenge focuses on domain-specific semantic relations and includes three different subtasks. the subtasks were designed so as to compare and quantify the effect of different pre-processing steps on the relation classification results. we expect the task to be relevant for a broad range of researchers working on extracting specialized knowledge from domain corpora, for example but not limited to scientific or bio-medical information extraction. the task attracted a total of 32 participants, with 158 submissions across different scenarios.",
            "contribution_ids": [
                "R145759",
                "R145770",
                "R145773"
            ]
        },
        {
            "instance_id": "R150058xR146853",
            "comparison_id": "R150058",
            "paper_id": "R146853",
            "text": "SciREX: A Challenge Dataset for Document-Level Information Extraction extracting information from full documents is an important problem in many domains, but most previous work focus on identifying relationships within a sentence or a paragraph. it is challenging to create a large-scale information extraction (ie) dataset at the document level since it requires an understanding of the whole document to annotate entities and their document-level relationships that usually span beyond sentences or even sections. in this paper, we introduce scirex, a document level ie dataset that encompasses multiple ie tasks, including salient entity identification and document level n-ary relation identification from scientific articles. we annotate our dataset by integrating automatic and human annotations, leveraging existing scientific knowledge resources. we develop a neural model as a strong baseline that extends previous state-of-the-art ie models to document-level ie. analyzing the model performance shows a significant gap between human performance and current baselines, inviting the community to use our dataset as a challenge to develop document-level ie models. our data and code are publicly available at https://github.com/allenai/scirex .",
            "contribution_ids": [
                "R146855"
            ]
        },
        {
            "instance_id": "R150058xR147638",
            "comparison_id": "R150058",
            "paper_id": "R147638",
            "text": "Identifying used methods and datasets in scientific publications although it has become common to assess publications and researchers by means of their citation count (e.g., using the h-index), measuring the impact of scientific methods and datasets (e.g., using an \u201ch-index for datasets\u201d) has been performed only to a limited extent. this is not surprising because the usage information of methods and datasets is typically not explicitly provided by the authors, but hidden in a publication\u2019s text. in this paper, we propose an approach to identifying methods and datasets in texts that have actually been used by the authors. our approach first recognizes datasets and methods in the text by means of a domain-specific named entity recognition method with minimal human interaction. it then classifies these mentions into used vs. non-used based on the textual contexts. the obtained labels are aggregated on the document level and integrated into the microsoft academic knowledge graph modeling publications\u2019 metadata. in experiments based on the microsoft academic graph, we show that both method and dataset mentions can be identified and correctly classified with respect to their usage to a high degree. overall, our approach facilitates method and dataset recommendation, enhanced paper recommendation, and scientific impact quantification. it can be extended in such a way that it can identify mentions of any entity type (e.g., task).",
            "contribution_ids": [
                "R147640"
            ]
        },
        {
            "instance_id": "R150058xR69282",
            "comparison_id": "R150058",
            "paper_id": "R69282",
            "text": "SemEval 2017 Task 10: ScienceIE - Extracting Keyphrases and Relations from Scientific Publications we describe the semeval task of extracting keyphrases and relations between them from scientific documents, which is crucial for understanding which publications describe which processes, tasks and materials. although this was a new task, we had a total of 26 submissions across 3 evaluation scenarios. we expect the task and the findings reported in this paper to be relevant for researchers working on understanding scientific content, as well as the broader knowledge base population and information extraction communities.",
            "contribution_ids": [
                "R69283"
            ]
        },
        {
            "instance_id": "R150570xR148576",
            "comparison_id": "R150570",
            "paper_id": "R148576",
            "text": "Exploiting syntax when detecting protein names in text this paper presents work on a method to detect names of proteins in running text. \\n \\nour system - yapex - uses a combination of lexical and syntactic knowledge, heuristic filters and a local dynamic dictionary. the syntactic information given by a general-purpose off-the-shelf parser supports the correct identification of the boundaries of protein names, and the local dynamic dictionary finds protein names in positions incompletely analysed by the parser. \\n \\nwe present the different steps involved in our approach to protein tagging, and show how combinations of them influence recall and precision. \\n \\nwe evaluate the system on a corpus of medline abstracts and compare it with the kex system (fukuda et al., 1998) along four different notions of correctness.",
            "contribution_ids": [
                "R148578"
            ]
        },
        {
            "instance_id": "R150570xR148501",
            "comparison_id": "R150570",
            "paper_id": "R148501",
            "text": "Integrated Annotation for Biomedical Information Extraction we describe an approach to two areas of biomedical information extraction, drug development and cancer genomics. we have developed a framework which includes corpus annotation integrated at multiple levels: a treebank containing syntactic structure, a propbank containing predicate-argument structure, and annotation of entities and relations among the entities. crucial to this approach is the proper characterization of entities as relation components, which allows the integration of the entity annotation with the syntactic structure while retaining the capacity to annotate and extract more complex events. we are training statistical taggers using this annotation for such extraction as well as using them for improving the annotation process.",
            "contribution_ids": [
                "R148503"
            ]
        },
        {
            "instance_id": "R151435xR151352",
            "comparison_id": "R151435",
            "paper_id": "R151352",
            "text": "Enzymatic glucose biosensor based on ZnO nanorod array grown by hydrothermal decomposition we report herein a glucose biosensor based on glucose oxidase (gox) immobilized on zno nanorod array grown by hydrothermal decomposition. in a phosphate buffer solution with a ph value of 7.4, negatively charged gox was immobilized on positively charged zno nanorods through electrostatic interaction. at an applied potential of +0.8v versus ag\u2215agcl reference electrode, zno nanorods based biosensor presented a high and reproducible sensitivity of 23.1\u03bcacm\u22122mm\u22121 with a response time of less than 5s. the biosensor shows a linear range from 0.01to3.45mm and an experiment limit of detection of 0.01mm. an apparent michaelis-menten constant of 2.9mm shows a high affinity between glucose and gox immobilized on zno nanorods.",
            "contribution_ids": [
                "R151354"
            ]
        },
        {
            "instance_id": "R151435xR151376",
            "comparison_id": "R151435",
            "paper_id": "R151376",
            "text": "ZnO/Cu Nanocomposite: A Platform for Direct Electrochemistry of Enzymes and Biosensing Applications unique structured nanomaterials can facilitate the direct electron transfer between redox proteins and the electrodes. here, in situ directed growth on an electrode of a zno/cu nanocomposite was prepared by a simple corrosion approach, which enables robust mechanical adhesion and electrical contact between the nanostructured zno and the electrodes. this is great help to realize the direct electron transfer between the electrode surface and the redox protein. sem images demonstrate that the morphology of the zno/cu nanocomposite has a large specific surface area, which is favorable to immobilize the biomolecules and construct biosensors. using glucose oxidase (gox) as a model, this zno/cu nanocomposite is employed for immobilization of gox and the construction of the glucose biosensor. direct electron transfer of gox is achieved at zno/cu nanocomposite with a high heterogeneous electron transfer rate constant of 0.67 \u00b1 0.06 s(-1). such zno/cu nanocomposite provides a good matrix for direct electrochemistry of enzymes and mediator-free enzymatic biosensors.",
            "contribution_ids": [
                "R151378"
            ]
        },
        {
            "instance_id": "R152186xR151947",
            "comparison_id": "R152186",
            "paper_id": "R151947",
            "text": "Evidence of lasing on the Balmer-\u00ce\u00b1 line of OVIII in an ablative capillary discharge in a low-inductance ablative discharge through a capillary made of polyacetal (pom), lasing on the balmer-\u03b1 line of oviii at 10.24 nm is identified. in line with previous studies of lasing on cvi ions, it is argued to be the consequence of charge exchange collisions after a m=0 instability. lasing in both cases occurred at about the same time after beginning of the discharge, although lasing on the balmer-\u03b1 line of oviii was less frequently observed, i.e., in approximately one out of ten discharges. lasing on the cvi ion was seen in one out of three discharges. this is probably due to the need of reaching higher electron temperatures to completely strip oxygen ions simultaneously in the hot constrictions (necks) of the plasma instability.",
            "contribution_ids": [
                "R151949"
            ]
        },
        {
            "instance_id": "R152186xR152081",
            "comparison_id": "R152186",
            "paper_id": "R152081",
            "text": "Soft-x-ray amplification in a capillary discharge soft-x-ray amplification in the c vi balmer \\\\ensuremath{\\\\alpha} transition is observed in a capillary discharge. the capillary is made of polyethylene with a bore diameter of 1.2 mm. a hot and dense carbon plasma which is formed on the capillary axis region expands radially and collides with the wall where it undergoes a rapid cooling and subsequent recombination. the amplification takes place in this cool (${\\\\mathit{t}}_{\\\\mathit{e}}$\\\\ensuremath{\\\\sim}13 ev) plasma region, according to space-resolved spectral data obtained using a 2-m grazing incidence spectrograph. the gain coefficient is measured to be 2.8 ${\\\\mathrm{cm}}^{\\\\mathrm{\\\\ensuremath{-}}1}$.",
            "contribution_ids": [
                "R152083"
            ]
        },
        {
            "instance_id": "R152186xR152133",
            "comparison_id": "R152186",
            "paper_id": "R152133",
            "text": "High-power-density capillary discharge plasma columns for shorter wavelength discharge-pumped soft-x-ray lasers we report the generation of plasma columns in gas-filled capillary channels using discharge excitation powers that exceed those of previous studies by one to two orders of magnitude. current pulses up to 200 ka and 10-90 % rise time of about 10 ns (current increase rate equivalent to 1.5 x 10(13) a/s) were utilized to excite plasmas in 3.3 and 4 mm diameter channels. time resolved soft-x-ray spectra and pinhole images of the plasma were obtained. the experimental data and its comparison with model computations suggest that dense argon plasma columns 300 mum in diameter with electron temperatures >250 ev have been obtained. these characteristics make these plasmas of interest for extending discharge-pumped lasers to shorter wavelengths.",
            "contribution_ids": [
                "R152135"
            ]
        },
        {
            "instance_id": "R152282xR149037",
            "comparison_id": "R152282",
            "paper_id": "R149037",
            "text": "The Competent Boundary Spanner inter-organizational frameworks of intervention dominate the resolution of complex societal problems facing the uk and many other countries. strategic alliances, joint working arrangements, networks, partnerships and many other forms of collaboration across sectoral and organizational boundaries currently proliferate across the policy landscape. however, the discourse is positioned at an institutional and organizational level, and comparatively little attention is accorded to the pivotal role of individual actors in the management of inter-organizational relationships. this paper attempts to redress this balance by focusing on the skills, competencies and behaviour of boundary spanners. a critical review of the relevant literature, both from an institutional and relational perspective, is undertaken. this is complemented by some new empirical research that involves an engagement with groups of particular types of boundary spanner using a combination of surveys and in-depth interviews. finally, a discussion makes connections between the existing literature and the research findings and offers suggestions for future areas of enquiry.",
            "contribution_ids": [
                "R149039"
            ]
        },
        {
            "instance_id": "R152282xR149072",
            "comparison_id": "R152282",
            "paper_id": "R149072",
            "text": "Defining the Role of the Smart-City Manager: An Analysis of Responsibilities and Skills abstract increasing social problems are challenging public administrations to adopt new strategies in order to create smarter cities. with regard to this, some cities have created a dedicated organizational unit focused on planning and implementation of smart city (sc) projects, led by an sc manager. however, the sc manager\u2019s responsibilities and curricula remain overlooked. the objective of this paper is to theoretically explore the role of the sc manager in municipalities and to analyze their main responsibilities and skills. based on an empirical questionnaire administered to public managers and politicians, a responsibility index (ri) is defined to identify the domains under the responsibility of the newly-established role of sc manager. the questionnaire is also an opportunity for understanding the main competencies and skills required through a factor analysis and qualitative investigation of the responses.",
            "contribution_ids": [
                "R149074"
            ]
        },
        {
            "instance_id": "R152282xR149075",
            "comparison_id": "R152282",
            "paper_id": "R149075",
            "text": "Required competencies in public administration study programs in the evaluation of undergraduate and graduate study programs, there is an important issue about which competencies must be acquired by graduates. this study tested the importance of competencies in public administration study programs in the light of expectations of employers in slovenian public administration. the aim of the research was to find out how various competencies acquired in higher education (undergraduate and graduate study in public administration) are evaluated by employers in public administration. on the basis of analysis of findings of similar research projects, the competencies contained in programs by renowned universities and competencies defined for the work positions, a set of discipline-specific competencies (61) were designed. research was conducted in 2015 and involved 343 respondents. a qualitative research method (survey) was used to collect the data which were then analyzed with the spss statistical program and microsoft excel. the results show that the competencies related to ethics and ethical behavior were evaluated as the most important; generic competencies are better assessed than specific ones and on average the competencies received a higher assessment for graduates (compare to undergraduates) positions",
            "contribution_ids": [
                "R149077"
            ]
        },
        {
            "instance_id": "R152282xR149078",
            "comparison_id": "R152282",
            "paper_id": "R149078",
            "text": "Administrative Skills and Degrees: The \u00e2\u0080\u009cBest Place\u00e2\u0080\u009d Debate Rages On abstract what should human service administration students learn? where is the best place for them to receive their education? nonprofit administrators, government agency managers, social work professors and public administration educators exhibit considerable agreement regarding what should be taught but little agreement regarding which degree is best. thus, the widespread debate concerning the best degree for non-profit administrators will rage on, with most practitioners preferring the mba and mpa degrees at the top level and academics believing that \u201ctheir\u201d degree is best. despite the disagreement, the msw degree is perceived well at the entry and middle levels of management.",
            "contribution_ids": [
                "R149080"
            ]
        },
        {
            "instance_id": "R152282xR149207",
            "comparison_id": "R152282",
            "paper_id": "R149207",
            "text": "Changing competencies for human resource management: examining e-government scorecard and Federal Human Capital Survey evidence \"as of this writing, effective human capital management is one of the key provisions of the president's management agenda (pma), which is committed to improving management processes on the us federal level to achieve results. while us federal organisations have made significant strides in improving human capital management, a connected component of the pma, e-government, lags behind for several large federal organisations. the connection between human capital management and e-government is a recent one. this manuscript seeks to investigate the connection between these two key components of the president's management agenda to answer the question: 'how are human resource management competencies evolving to reflect changing technology and knowledge management needs?' using data from the president's management scorecard (between 2002 and 2006), and two federal human capital surveys (2004, 2006), this manuscript gives special attention to the association between leading and lagging federal e-government agencies and it and knowledge competence.\"",
            "contribution_ids": [
                "R149209"
            ]
        },
        {
            "instance_id": "R152282xR149211",
            "comparison_id": "R152282",
            "paper_id": "R149211",
            "text": "Identifying government chief information officer education and training needs: the case of Saudi Arabia this paper identifies education and training needs of government chief information officers (gcio) in the kingdom of saudi arabia (ksa). it aims to provide foundation that would assist the ksa national e-government program (yesser) in identifying and prioritizing initiatives oriented towards building the capacity of gcios. based on the results of a survey conducted among gcios and highest it officials of 30 government agencies and the results of four semi-structured interviews, the paper identifies the knowledge areas and skills that should be developed by gcio educational programs, the stages of public sector ict in which gcios are most involved, the preferred delivery modes for the training, the preferred institutions for hosting gcios education and training programs, and the prerequisites for those who should participate in gcio educational programs. in addition to the policy recommendations for the ksa government, the main contribution of the paper is the validation of a methodology that can be applied by any government for designing capacity-building programs for their it leaders.",
            "contribution_ids": [
                "R149213"
            ]
        },
        {
            "instance_id": "R152282xR149221",
            "comparison_id": "R152282",
            "paper_id": "R149221",
            "text": "Conceptualizing Electronic Governance Education responding to the issues of complexity, relevance, cost and risk of electronic governance (egov), we witness a specialization of the roles responsible for egov development and operation, professionalizationof the personnel playing such roles, and utilization of the egov services and information to fulfill citizen needs. in order to build competencies required by such(managerial, professional, technician and user) roles, education becomes a key success factor, and a growing variety of egov learning opportunities emerges. however, lacking conceptual underpinnings for ego education, the discovery, analysis and integration of such opportunities is difficult. to address this need, the paper develops a theoretical construct for ego education, applies six measures to this construct: who-- learners, why -- roles, what -- competencies, how --programs, where -- schools, and when -- prerequisites, and validates it through a landscaping exercise focusing on egov university programs.",
            "contribution_ids": [
                "R149223"
            ]
        },
        {
            "instance_id": "R152282xR149726",
            "comparison_id": "R152282",
            "paper_id": "R149726",
            "text": "Competency Frameworks in The Belgian Governments: Causes, Construction and Contents the belgian federal government and the belgian flemish government have picked up competency management as a multifaceted tool to suit their own visions of organizational change rather than simply responding to a new management trend in the private sector. both governments have used it to foster both vertical and horizontal integration in their fragmented administrations, and to deal with problems of recruitment and retention of qualified personnel. the analysis presented here also reveals that the seemingly uniform use of \u2018competency speak\u2019 hides multiple dimensions that provide several solutions to different organizational problems. at the same time, the cases examined demonstrate how the new tools both serve and disconcert the diverse bureau-political interests of top civil servants, trade unions and human resource management units. in addition, we examine how the new tools break with at least two traditional features of the highly formal and rigid career systems and the relatively low status of officials in the belgian administrations.",
            "contribution_ids": [
                "R149728"
            ]
        },
        {
            "instance_id": "R152282xR149740",
            "comparison_id": "R152282",
            "paper_id": "R149740",
            "text": "Requisite competencies for government Chief Information Officer in Sri Lanka \"developed countries such as usa, australia and eu have technology savvy executives in certain government sector organizations performing the cio\u2019s role. these countries have managed to improve their government sector delivery of services to citizens leveraging on it/is. however, in sri lanka there is very low recognition for the role of a cio in government sector organizations and even in private sector organizations. \\ndifferent cios may be equipped with their own set of different skills. however, it is undoubtedly important for cios to acquire the particularly necessary set of skills, knowledge and experience that would enable them to act as catalysts in strategically and efficiently using it to improve their organization's service delivery. \\nconsidering the above facts, the authors did an empirical research study based on an extensive literature review. the research goals were to, (1) evaluate the set of competencies required of sri lankan cios and, (2) provide an understanding of the way the cio role should be formulated, such that it will have an impact on the strategy of sri lankan organizations. it is envisioned that the recommendations of this study will provide the necessary information to it directors and senior executives in government organizations to develop the competencies required to enable them to effectively function as cios.\"",
            "contribution_ids": [
                "R149742"
            ]
        },
        {
            "instance_id": "R152282xR149772",
            "comparison_id": "R152282",
            "paper_id": "R149772",
            "text": "The Skill Set of the Successful Collaborator in this article, the authors focus on members of the u.s. senior executive service who choose collaboration as a management strategy to increase performance and, in particular, their views of the skill set of a successful collaborator. based on the current literature on collaboration and networks, these executives might be expected to identify strategic thinking and strategic management as the most important skills. contrary to expectations, the federal executives most frequently mentioned individual attributes and interpersonal skills as essential for successful collaboration, followed by group process skills, strategic leadership skills, and substantive/technical expertise. the article provides empirical substantiation of the previous literature, with one major difference: the strong reporting of the importance of individual attributes by federal executives (much more than previously reported by other scholars in the field). strategic leadership skills, strategic management skills, and technical skills matter, but they are not the most important factors behind successful collaborations, according to federal executives.",
            "contribution_ids": [
                "R149774"
            ]
        },
        {
            "instance_id": "R154289xR147129",
            "comparison_id": "R154289",
            "paper_id": "R147129",
            "text": "A Hierarchical Attention Retrieval Model for Healthcare Question Answering the growth of the web in recent years has resulted in the development of various online platforms that provide healthcare information services. these platforms contain an enormous amount of information, which could be beneficial for a large number of people. however, navigating through such knowledgebases to answer specific queries of healthcare consumers is a challenging task. a majority of such queries might be non-factoid in nature, and hence, traditional keyword-based retrieval models do not work well for such cases. furthermore, in many scenarios, it might be desirable to get a short answer that sufficiently answers the query, instead of a long document with only a small amount of useful information. in this paper, we propose a neural network model for ranking documents for question answering in the healthcare domain. the proposed model uses a deep attention mechanism at word, sentence, and document levels, for efficient retrieval for both factoid and non-factoid queries, on documents of varied lengths. specifically, the word-level cross-attention allows the model to identify words that might be most relevant for a query, and the hierarchical attention at sentence and document levels allows it to do effective retrieval on both long and short documents. we also construct a new large-scale healthcare question-answering dataset, which we use to evaluate our model. experimental evaluation results against several state-of-the-art baselines show that our model outperforms the existing retrieval techniques.",
            "contribution_ids": [
                "R147131"
            ]
        },
        {
            "instance_id": "R154289xR147992",
            "comparison_id": "R154289",
            "paper_id": "R147992",
            "text": "Large-scale semantic parsing via schema matching and lexicon extension supervised training procedures for semantic parsers produce high-quality semantic parsers, but they have difficulty scaling to large databases because of the sheer number of logical constants for which they must see labeled training data. we present a technique for developing semantic parsers for large databases based on a reduction to standard supervised training algorithms, schema matching, and pattern learning. leveraging techniques from each of these areas, we develop a semantic parser for freebase that is capable of parsing questions with an f1 that improves by 0.42 over a purely-supervised learning algorithm.",
            "contribution_ids": [
                "R147994"
            ]
        },
        {
            "instance_id": "R155101xR154337",
            "comparison_id": "R155101",
            "paper_id": "R154337",
            "text": "High-Repetition-Rate Grazing-Incidence Pumped X-Ray Laser Operating at 18.9\u00c2\u00a0nm we have demonstrated a 10 hz ni-like mo x-ray laser operating at 18.9 nm with 150 mj total pump energy by employing a novel pumping scheme. the grazing-incidence scheme is described, where a picosecond pulse is incident at a grazing angle to a mo plasma column produced by a slab target irradiated by a 200 ps laser pulse. this scheme uses refraction of the short pulse at a predetermined electron density to increase absorption to pump a specific gain region. the higher coupling efficiency inherent to this scheme allows a reduction in the pump energy where 70 mj long pulse energy and 80 mj short pulse energy are sufficient to produce lasing at a 10 hz repetition rate. under these conditions and by optimizing the delay between the pulses, we achieve strong amplification and close to saturation for 4 mm long targets.",
            "contribution_ids": [
                "R154338"
            ]
        },
        {
            "instance_id": "R155101xR154866",
            "comparison_id": "R155101",
            "paper_id": "R154866",
            "text": "High-energy 139\u00e2\u0080\u0089nm table-top soft-x-ray laser at 25\u00e2\u0080\u0089Hz repetition rate excited by a slab-pumped Ti:sapphire laser we have demonstrated repetitive operation of a table-top lambda=13.9 nm ni-like ag soft-x-ray laser that generates laser pulses with 10 microj energy. the soft-x-ray laser is enabled by a ti:sapphire laser pumped by high-repetition-rate frequency-doubled high-energy nd:glass slab amplifiers. soft-x-ray laser operation at 2.5 hz repetition rate resulted in 20 microwatt average power.",
            "contribution_ids": [
                "R154868"
            ]
        },
        {
            "instance_id": "R155101xR155047",
            "comparison_id": "R155101",
            "paper_id": "R155047",
            "text": "Compact gain-saturated x-ray lasers down to 685\u00e2\u0080\u0089\u00e2\u0080\u0089nm and amplification down to 585\u00e2\u0080\u0089\u00e2\u0080\u0089nm plasma-based x-ray lasers allow single-shot nano-scale imaging and other experiments requiring a large number of photons per pulse to be conducted in compact facilities. however, compact repetitively fired gain-saturated x-ray lasers have been limited to wavelengths above \u03bb=8.85\\u2009\\u2009nm. here we extend their range to \u03bb=6.85\\u2009\\u2009nm by transient traveling wave excitation of ni-like gd ions in a plasma created with an optimized pre-pulse followed by rapid heating with an intense sub-picosecond pump pulse. isoelectronic scaling also produced strong lasing at 6.67\\xa0nm and 6.11\\xa0nm in ni-like tb and amplification at 6.41\\xa0nm and 5.85\\xa0nm in ni-like dy. this scaling to shorter wavelengths was obtained by progressively increasing the pump pulse grazing incidence angle to access increased plasma densities. we experimentally demonstrate that the optimum grazing incidence angle increases linearly with atomic number from 17\\xa0deg for z=42 (mo) to 43\\xa0deg for z=66 (dy). the results will enable applications of sub-7\\xa0nm lasers at compact facilities.",
            "contribution_ids": [
                "R155050"
            ]
        },
        {
            "instance_id": "R155621xR151517",
            "comparison_id": "R155621",
            "paper_id": "R151517",
            "text": "Cyclodextrins in eye drop formulations: enhanced topical delivery of corticosteroids to the eye: Acta\n Ophthalmologica\n Scandinavica\n 2002 \"cyclodextrins are cylindrical oligosaccharides with a lipophilic central cavity and hydrophilic outer surface. they can form water-soluble complexes with lipophilic drugs, which 'hide' in the cavity. cyclodextrins can be used to form aqueous eye drop solutions with lipophilic drugs, such as steroids and some carbonic anhydrase inhibitors. the cyclodextrins increase the water solubility of the drug, enhance drug absorption into the eye, improve aqueous stability and reduce local irritation. cyclodextrins are useful excipients in eye drop formulations of various drugs, including steroids of any kind, carbonic anhydrase inhibitors, pilocarpine, cyclosporins, etc. their use in ophthalmology has already begun and is likely to expand the selection of drugs available as eye drops. in this paper we review the properties of cyclodextrins and their application in eye drop formulations, of which their use in the formulation of dexamethasone eye drops is an example. cyclodextrins have been used to formulate eye drops containing corticosteroids, such as dexamethasone, with levels of concentration and ocular absorption which, according to human and animal studies, are many times those seen with presently available formulations. cyclodextrin-based dexamethasone eye drops are well tolerated in the eye and seem to provide a higher degree of bioavailability and clinical efficiency than the steroid eye drop formulations presently available. such formulations offer the possibility of once per day application of corticosteroid eye drops after eye surgery, and more intensive topical steroid treatment in severe inflammation. while cyclodextrins have been known for more than a century, their use in ophthalmology is just starting. cyclodextrins are useful excipients in eye drop formulations for a variety of lipophilic drugs. they will facilitate eye drop formulations for drugs that otherwise might not be available for topical use, while improving absorption and stability and decreasing local irritation.\"",
            "contribution_ids": [
                "R151519"
            ]
        },
        {
            "instance_id": "R155621xR151616",
            "comparison_id": "R155621",
            "paper_id": "R151616",
            "text": "Influence of Hydroxypropyl \u00ce\u00b2-Cyclodextrin on the Corneal Permeation of Pilocarpine abstract the influence of hydroxypropyl \u03b2-cyclodextrin (hp\u03b2cd) on the corneal permeation of pilocarpine nitrate was investigated by an in vitro permeability study using isolated rabbit cornea. pupillary-response pattern to pilocarpine nitrate with and without hp\u03b2cd was examined in rabbit eye. corneal permeation of pilocarpine nitrate was found to be four times higher after adding hp\u03b2cd into the formulation. the reduction of pupil diameter (miosis) by pilocarpine nitrate was significantly increased as a result of hp\u03b2cd addition into the simple aqueous solution of the active substance. the highest miotic response was obtained with the formulation prepared in a vehicle of carbopol\u00ae 940. it is suggested that ocular bioavailability of pilocarpine nitrate could be improved by the addition of hp\u03b2cd.",
            "contribution_ids": [
                "R151618"
            ]
        },
        {
            "instance_id": "R155621xR151628",
            "comparison_id": "R155621",
            "paper_id": "R151628",
            "text": "Improvement of Nasal Bioavailability of Luteinizing Hormone-Releasing Hormone Agonist, Buserelin, by Cyclodextrin Derivatives in Rats the effects of chemically modified cyclodextrins on the nasal absorption of buserelin, an agonist of luteinizing hormone-releasing hormone, were investigated in anesthetized rats. of the cyclodextrins tested, dimethyl-beta-cyclodextrin (dm-beta-cyd) was the most effective in improving the rate and extent of the nasal bioavailability of buserelin. fluorescence spectroscopic studies indicated that the cyclodextrins formed inclusion complexes with buserelin, which may reduce the diffusibility of buserelin across the nasal epithelium and may participate in the protection of the peptide against enzymatic degradation in the nasal mucosa. additionally, the cyclodextrins increased the permeability of the nasal mucosa, which was the primary determinant based on the multiple regression analysis of the nasal absorption enhancement of buserelin. scanning electron microscopic observations revealed that dm-beta-cyd induced no remarkable changes in the surface morphology of the nasal mucosa at a minimal concentration necessary to achieve substantial absorption enhancement. the present results suggest that dm-beta-cyd could improve the nasal bioavailability of buserelin and is well-tolerated by the nasal mucosa of the rat.",
            "contribution_ids": [
                "R151630"
            ]
        },
        {
            "instance_id": "R155621xR155590",
            "comparison_id": "R155621",
            "paper_id": "R155590",
            "text": "The Effect of Cyclodextrins on the In Vitro and In Vivo Properties of Insulin-Loaded Poly (D,L-Lactic-Co-Glycolic Acid) Microspheres: EFFECT OF CYCLODEXTRINS ON MICROSPHERES in this work we describe the development and characterization of a new formulation of insulin (ins). insulin was complexed with cyclodextrins (cd) in order to improve its solubility and stability being available as a dry powder, after encapsulation into poly (d,l-lactic-co-glycolic acid) (plga) microspheres. the complex ins : cd was encapsulated into microspheres in order to obtain particles with an average diameter between 2 and 6 microm. this system was able to induce significant reduction of the plasma glucose level in two rodent models, normal mice and diabetic rats, after intratracheal administration.",
            "contribution_ids": [
                "R155592"
            ]
        },
        {
            "instance_id": "R157326xR156333",
            "comparison_id": "R157326",
            "paper_id": "R156333",
            "text": "Demonstration of a Soft X-Ray Amplifier we report observations of amplified spontaneous emission at soft x-ray wavelengths. an optical laser ionized thin foils of selenium to produce a population inversion of the $2{p}^{5}3p$ and $2{p}^{5}3s$ levels of the neonlike ion. using three time-resolved, spectroscopic measurements we demonstrated gain-length products up to 6.5 and gain coefficients of 5.5\\\\ifmmode\\\\pm\\\\else\\\\textpm\\\\fi{}1.0 ${\\\\mathrm{cm}}^{\\\\ensuremath{-}1}$ for the $j=2 \\\\mathrm{to} 1$ lines at 206.3 and 209.6 \\\\aa{}. we also observed considerable amplification for the same transitions in yttrium at 155.0 and 157.1 \\\\aa{}.",
            "contribution_ids": [
                "R156334"
            ]
        },
        {
            "instance_id": "R157326xR156663",
            "comparison_id": "R157326",
            "paper_id": "R156663",
            "text": "Short wavelength x\u00e2\u0080\u0090ray laser research at the Lawrence Livermore National Laboratory laboratory x\u2010ray lasers are currently being studied by researchers worldwide. this paper reviews some of the recent work carried out at lawrence livermore national laboratory. laser action has been demonstrated at wavelengths as short as 35.6 a while saturation of the small signal gain has been observed with longer wavelength schemes. some of the most successful schemes to date have been collisionally pumped x\u2010ray lasers that use the thermal electron distribution within a laser\u2010produced plasma to excite electrons from closed shells in neon\u2010 and nickel\u2010like ions to metastable levels in the next shell. attempts to quantify and improve the longitudinal and transverse coherence of collisionally pumped x\u2010ray lasers are motivated by the desire to produce sources for specific applications. toward this goal there is a large effort underway to enhance the power output of the ni\u2010like ta x\u2010ray laser at 44.83 a as a source for x\u2010ray imaging of live cells. improving the efficiency of x\u2010ray lasers in order to produce s...",
            "contribution_ids": [
                "R156665"
            ]
        },
        {
            "instance_id": "R157326xR156908",
            "comparison_id": "R157326",
            "paper_id": "R156908",
            "text": "Saturated and Short Pulse Duration X-Ray Lasers the basis of a model of the relationship between gain and output laser intensity is reviewed and the measurement of the duration of x\u2010ray lasing with a streak camera with 700 fs temporal resolution is described. combined with a temporal smearing due to the spectrometer employed, we have measured x\u2010ray laser pulse durations for ni\u2010like silver at 13.9 nm and ne\u2010like nickel at 23.1 nm with a total time resolution of 1.1 ps. an extension of the model is shown to consistently relate the measured x\u2010ray laser pulse duration to estimates of the gain duration obtained by temporally resolving resonance line emission from states near in energy to the upper lasing level.",
            "contribution_ids": [
                "R156910"
            ]
        },
        {
            "instance_id": "R160742xR160723",
            "comparison_id": "R160742",
            "paper_id": "R160723",
            "text": "Ocean carbon cycling in the Indian Ocean: 1. Spatiotemporal variability of inorganic carbon and air-sea CO2gas exchange: INDIAN OCEAN CARBON CYCLE, 1 the spatiotemporal variability of upper ocean inorganic carbon parameters and air\u2010sea co2 exchange in the indian ocean was examined using inorganic carbon data collected as part of the world ocean circulation experiment (woce) cruises in 1995. multiple linear regression methods were used to interpolate and extrapolate the temporally and geographically limited inorganic carbon data set to the entire indian ocean basin using other climatological hydrographic and biogeochemical data. the spatiotemporal distributions of total carbon dioxide (tco2), alkalinity, and seawater pco2 were evaluated for the indian ocean and regions of interest including the arabian sea, bay of bengal, and 10\u00b0n\u201335\u00b0s zones. the indian ocean was a net source of co2 to the atmosphere, and a net sea\u2010to\u2010air co2 flux of +237 \u00b1 132 tg c yr\u22121 (+0.24 pg c yr\u22121) was estimated. regionally, the arabian sea, bay of bengal, and 10\u00b0n\u201310\u00b0s zones were perennial sources of co2 to the atmosphere. in the 10\u00b0s\u201335\u00b0s zone, the co2 sink or source status of the surface ocean shifts seasonally, although the region is a net oceanic sink of atmospheric co2.",
            "contribution_ids": [
                "R160724"
            ]
        },
        {
            "instance_id": "R160742xR160733",
            "comparison_id": "R160742",
            "paper_id": "R160733",
            "text": "Environmental controls on the seasonal carbon dioxide fluxes in the northeastern Indian Ocean total carbon dioxide (tco 2) and computations of partial pressure of carbon dioxide (pco 2) had been examined in northerneastern region of indian ocean. it exhibit seasonal and spatial variability. north-south gradients in the pco 2 levels were closely related to gradients in salinity caused by fresh water discharge received from rivers. eddies observed in this region helped to elevate the nutrients availability and the biological controls by increasing the productivity. these phenomena elevated the carbon dioxide draw down during the fair seasons. seasonal fluxes estimated from local wind speed and air-sea carbon dioxide difference indicate that during southwest monsoon, the northeastern indian ocean acts as a strong sink of carbon dioxide (-20.04 mmol m \u20132 d -1 ). also during fall intermonsoon the area acts as a weak sink of carbon dioxide (-4.69 mmol m \u20132 d -1 ). during winter monsoon, this region behaves as a weak carbon dioxide source with an average sea to air flux of 4.77 mmol m -2 d -1 . in the northern region, salinity levels in the surface level are high during winter compared to the other two seasons. northeastern indian ocean shows significant intraseasonal variability in carbon dioxide fluxes that are mediated by eddies which provide carbon dioxide and nutrients from the subsurface waters to the mixed layer.",
            "contribution_ids": [
                "R160734"
            ]
        },
        {
            "instance_id": "R160847xR160810",
            "comparison_id": "R160847",
            "paper_id": "R160810",
            "text": "Influence of Process and Formulation Parameters on Dissolution and Stability Characteristics of Kollidon\u00c2\u00ae VA 64 Hot-Melt Extrudates the objective of the present study was to investigate the effects of processing variables and formulation factors on the characteristics of hot-melt extrudates containing a copolymer (kollidon\u00ae va 64). nifedipine was used as a model drug in all of the extrudates. differential scanning calorimetry (dsc) was utilized on the physical mixtures and melts of varying drug\u2013polymer concentrations to study their miscibility. the drug\u2013polymer binary mixtures were studied for powder flow, drug release, and physical and chemical stabilities. the effects of moisture absorption on the content uniformity of the extrudates were also studied. processing the materials at lower barrel temperatures (115\u2013135\u00b0c) and higher screw speeds (50\u2013100\\xa0rpm) exhibited higher post-processing drug content (~99\u2013100%). dsc and x-ray diffraction studies confirmed that melt extrusion of drug\u2013polymer mixtures led to the formation of solid dispersions. interestingly, the extrusion process also enhanced the powder flow characteristics, which occurred irrespective of the drug load (up to 40% w/w). moreover, the content uniformity of the extrudates, unlike the physical mixtures, was not sensitive to the amount of moisture absorbed. the extrusion conditions did not influence drug release from the extrudates; however, release was greatly affected by the drug loading. additionally, the drug release from the physical mixture of nifedipine\u2013kollidon\u00ae va 64 was significantly different when compared to the corresponding extrudates (f2\\u2009=\\u200936.70). the extrudates exhibited both physical and chemical stabilities throughout the period of study. overall, hot-melt extrusion technology in combination with kollidon\u00ae va 64 produced extrudates capable of higher drug loading, with enhanced flow characteristics, and excellent stability.",
            "contribution_ids": [
                "R160812"
            ]
        },
        {
            "instance_id": "R160847xR160844",
            "comparison_id": "R160847",
            "paper_id": "R160844",
            "text": "Solid-state characterization of Felodipine\u00e2\u0080\u0093Soluplus amorphous solid dispersions abstract the aim of the current study is to develop amorphous solid dispersion (sd) via hot melt extrusion technology to improve the solubility of a water-insoluble compound, felodipine (fel). the solubility was dramatically increased by preparation of amorphous sds via hot-melt extrusion with an amphiphilic polymer, soluplus\u00ae (sol). fel was found to be miscible with sol by calculating the solubility parameters. the solubility of fel within sol was determined to be in the range of 6.2\u20139.9% (w/w). various techniques were applied to characterize the solid-state properties of the amorphous sds. these included fourier transform infrared spectrometry spectroscopy and raman spectroscopy to detect the formation of hydrogen bonding between the drug and the polymer. scanning electron microscopy was performed to study the morphology of the sds. among all the hot-melt extrudates, fel was found to be molecularly dispersed within the polymer matrix for the extrudates containing 10% drug, while few small crystals were detected in the 30 and 50% extrudates. in conclusion, solubility of fel was enhanced while a homogeneous sd was achieved for 10% drug loading.",
            "contribution_ids": [
                "R160846"
            ]
        },
        {
            "instance_id": "R161728xR160274",
            "comparison_id": "R161728",
            "paper_id": "R160274",
            "text": "Smart City Digital Twin\u00e2\u0080\u0093Enabled Energy Management: Toward Real-Time Urban Building Energy Benchmarking abstractto meet energy-reduction goals, cities are challenged with assessing building energy performance and prioritizing efficiency upgrades across existing buildings. although current top-down bu...",
            "contribution_ids": [
                "R160277"
            ]
        },
        {
            "instance_id": "R161728xR160331",
            "comparison_id": "R161728",
            "paper_id": "R160331",
            "text": "An Architecture for Blockchain over Edge-enabled IoT for Smart Circular Cities \"circular economy is a novel economic model, where every 'asset' is not wasted but reused and upscaled. the internet of things-iot paradigm can underpin the transition to a circular economy by enabling fine-grained and continuous asset tracking. however, there are issues related to security and privacy of iot devices that generate and handle sensitive and personal data. the use of blockchain technology provides an answer to this issue, however, its application raises issues related to the highly-constrained nature of these networks. in this paper, edge computing is presented as a solution to this issue, providing a way in which blockchain and edge computing can be used together to address the constrained nature of iot. furthermore, we present the challenges that this combination poses and the opportunities that it brings. we propose an architecture that decreases the iot devices requirements for memory capacity and increases the overall performance. we also discuss the architecture design and the challenges that it has, comparing it to the traditional blockchain architecture as well as an edge computing architecture for mobile blockchain. the paper closes with a discussion and future extensions of our work are presented, as well.\"",
            "contribution_ids": [
                "R160333"
            ]
        },
        {
            "instance_id": "R161728xR160374",
            "comparison_id": "R161728",
            "paper_id": "R160374",
            "text": "A Digital Twin Paradigm: Vehicle-to-Cloud Based Advanced Driver Assistance Systems digital twin, an emerging representation of cyberphysical systems, has attracted increasing attentions very recently. it opens the way to real-time monitoring and synchronization of real-world activities with the virtual counterparts. in this study, we develop a digital twin paradigm using an advanced driver assistance system (adas) for connected vehicles. by leveraging vehicle-to-cloud (v2c) communication, on-board devices can upload the data to the server through cellular network. the server creates a virtual world based on the received data, processes them with the proposed models, and sends them back to the connected vehicles. drivers can benefit from this v2c based adas, even if all computations are conducted on the cloud. the cooperative ramp merging case study is conducted, and the field implementation results show the proposed digital twin framework can benefit the transportation systems regarding mobility and environmental sustainability with acceptable communication delays and packet losses.",
            "contribution_ids": [
                "R160376"
            ]
        },
        {
            "instance_id": "R161728xR160384",
            "comparison_id": "R161728",
            "paper_id": "R160384",
            "text": "A Digital Twin-based Privacy Enhancement Mechanism for the Automotive Industry this paper discusses a digital twin demonstrator for privacy enhancement in the automotive industry. here, the digital twin demonstrator is presented as a method for the design and implementation of privacy enhancement mechanisms, and is used to detect privacy concerns and minimize breaches and associated risks to which smart car drivers can be exposed through connected infotainment applications and services. the digital twin-based privacy enhancement demonstrator is designed to simulate variety of conditions that can occur in the smart car ecosystem. we firstly identify the core stakeholders (actors) in the smart car ecosystem, their roles and exposure to privacy vulnerabilities and associated risks. secondly, we identify assets that consume and generate sensitive privacy data in smart cars, their functionalities, and relevant privacy concerns and risks. thirdly, we design an infrastructure for collecting (i) real-time sensor data from smart cars and their assets, and (ii) environmental data, road and traffic data, generated through operational driving lifecycle. in order to ensure compliance of the collected data with privacy policies and regulations, e.g. with gdpr requirements for enforcement of the data subject\u2019s rights, we design methods for the digital twin-based privacy enhancement demonstrator that are based on behavioural analytics informed by gdpr. we also perform data anonymization to minimize privacy risks and enable actions such as sending an automatic informed consent to the stakeholders.",
            "contribution_ids": [
                "R160386"
            ]
        },
        {
            "instance_id": "R161728xR160390",
            "comparison_id": "R161728",
            "paper_id": "R160390",
            "text": "Collaborative city digital twin for the COVID-19 pandemic: A federated learning solution \"in this work, we propose a collaborative city digital twin based on fl, a novel paradigm that allowing multiple city dt to share the local strategy and status in a timely manner. in particular, an fl central server manages the local updates of multiple collaborators (city dt), provides a global model which is trained in multiple iterations at different city dt systems, until the model gains the correlations between various response plan and infection trend. that means, a collaborative city dt paradigm based on fl techniques can obtain knowledge and patterns from multiple dts, and eventually establish a `global view' for city crisis management. meanwhile, it also helps to improve each city digital twin selves by consolidating other dt's respective data without violating privacy rules. to validate the proposed solution, we take covid-19 pandemic as a case study. the experimental results on the real dataset with various response plan validate our proposed solution and demonstrate the superior performance.\"",
            "contribution_ids": [
                "R160392"
            ]
        },
        {
            "instance_id": "R161728xR160395",
            "comparison_id": "R161728",
            "paper_id": "R160395",
            "text": "Building and exploiting a Digital Twin for the management of drinking water distribution networks abstract digital twins (dts) are starting to be exploited to improve the management of water distribution systems (wdss) and, in the future, they will be crucial for decision making. in this paper, the authors propose several requirements that a dt of a water distribution system should accomplish. developing a dt is a challenge, and a continuous process of adjustments and learning is required. due to the advantages of having a dt of the wds always available, during the last years a strategy to build and maintain a dt of the water distribution network of valencia (spain) and its metropolitan area (1.6 million inhabitants) was developed. this is one of the first dts built of a water utility, being currently in operation. the great benefits of their use in the daily operation of the system ensure that they will begin to be usual in the most advanced smart cities.",
            "contribution_ids": [
                "R160398"
            ]
        },
        {
            "instance_id": "R161728xR160402",
            "comparison_id": "R161728",
            "paper_id": "R160402",
            "text": "BIM and IoT: A Synopsis from GIS Perspective abstract. internet-of-things (iot) focuses on enabling communication between all devices, things that are existent in real life or that are virtual. building information models (bims) and building information modelling is a hype that has been the buzzword of the construction industry for last 15 years. bims emerged as a result of a push by the software companies, to tackle the problems of inefficient information exchange between different software and to enable true interoperability. in bim approach most up-to-date an accurate models of a building are stored in shared central databases during the design and the construction of a project and at post-construction stages. gis based city monitoring / city management applications require the fusion of information acquired from multiple resources, bims, city models and sensors. this paper focuses on providing a method for facilitating the gis based fusion of information residing in digital building \u201cmodels\u201d and information acquired from the city objects i.e. \u201cthings\u201d. once this information fusion is accomplished, many fields ranging from emergency response, urban surveillance, urban monitoring to smart buildings will have potential benefits.\\n",
            "contribution_ids": [
                "R160404"
            ]
        },
        {
            "instance_id": "R161729xR159456",
            "comparison_id": "R161729",
            "paper_id": "R159456",
            "text": "Geospatial Artificial Intelligence: Potentials of Machine Learning for 3D Point Clouds and Geospatial Digital Twins abstract artificial intelligence (ai) is changing fundamentally the way how it solutions are implemented and operated across all application domains, including the geospatial domain. this contribution outlines ai-based techniques for 3d point clouds and geospatial digital twins as generic components of geospatial ai. first, we briefly reflect on the term \u201cai\u201d and outline technology developments needed to apply ai to it solutions, seen from a software engineering perspective. next, we characterize 3d point clouds as key category of geodata and their role for creating the basis for geospatial digital twins; we explain the feasibility of machine learning (ml) and deep learning (dl) approaches for 3d point clouds. in particular, we argue that 3d point clouds can be seen as a corpus with similar properties as natural language corpora and formulate a \u201cnaturalness hypothesis\u201d for 3d point clouds. in the main part, we introduce a workflow for interpreting 3d point clouds based on ml/dl approaches that derive domain-specific and application-specific semantics for 3d point clouds without having to create explicit spatial 3d models or explicit rule sets. finally, examples are shown how ml/dl enables us to efficiently build and maintain base data for geospatial digital twins such as virtual 3d city models, indoor models, or building information models.",
            "contribution_ids": [
                "R159458"
            ]
        },
        {
            "instance_id": "R161729xR160217",
            "comparison_id": "R161729",
            "paper_id": "R160217",
            "text": "Methodological Framework for Digital Transition and Performance Assessment of Smart Cities the ultimate goal of smart cities is to improve citizens\u2019 quality of life in a scenario where technological solutions challenge urban governance. however, the knowledge and framework for data use for smart cities remain relatively unknown. the actual translation of city problems into diverse actions requires specific methodologies to guide digital transitions of cities and to assess to what extent the smart cities\u2019 initiatives pursue sustainable development goals. this paper proposes a methodological framework for digital modelling of cities allowing assessment of their performance and supporting decision making. the city model adopts the concept of digital twin as a powerful tool for discussion between stakeholders, as well as citizens to find the smartest solutions and get valuable insight after their deployment. the methodological framework is presented as a set of digital twin concept, stages of digital twinning and implementation strategy. furthermore, the most common city information models, suitable for implementation of digital twins are summarized.",
            "contribution_ids": [
                "R160219"
            ]
        },
        {
            "instance_id": "R161729xR160256",
            "comparison_id": "R161729",
            "paper_id": "R160256",
            "text": "Devising a Game Theoretic Approach to Enable Smart City Digital Twin Analytics despite investments in advancing information and communications technology (ict)-integrated infrastructure systems toward becoming smarter cities, cities often face a large gap between smart sustainable supply and demand. here, we review the core concepts of ict-integrated infrastructure systems as they pertain to developing smart and sustainable cities, and describe how a game theoretic-based digital twin of a city can enable more visibility and insight into the successful implementation of such systems. this study is a foundational step toward enabling participation of all city stakeholders (i.e., government, industry, and citizens) in the decision making process and the creation of smart sustainable cities. engaging city stakeholders in such a manner allows for collective participation in changes, which can enable continuous adaptation toward more sustaining growth and prosperity. 1. smart sustainable cities 1.1. urbanization, growth of supply and demand, and urge for efficiency between 1950 and 2018, the world\u2019s urban population have grown from 751 to more than 4.2 billion. projections anticipate that, by 2050, they will constitute nearly 70% of the world population [1]. in the united states, currently the most urbanized region in the world, this percentage is expected to increase to",
            "contribution_ids": [
                "R160258"
            ]
        },
        {
            "instance_id": "R162329xR162021",
            "comparison_id": "R162329",
            "paper_id": "R162021",
            "text": "Sub-38 nm resolution tabletop microscopy with 13 nm wavelength laser light we have acquired images with a spatial resolution better than 38 nm by using a tabletop microscope that combines 13 nm wavelength light from a high-brightness tabletop laser and fresnel zone plate optics. these results open a gateway to the development of compact and widely available extreme-ultraviolet imaging tools capable of inspecting samples in a variety of environments with a 15-20 nm spatial resolution and a picosecond time resolution.",
            "contribution_ids": [
                "R162023"
            ]
        },
        {
            "instance_id": "R162329xR162104",
            "comparison_id": "R162329",
            "paper_id": "R162104",
            "text": "Single-shot soft-x-ray digital holographic microscopy with an adjustable field of view and magnification single-shot digital holographic microscopy with an adjustable field of view and magnification was demonstrated by using a tabletop 32.8 nm soft-x-ray laser. the holographic images were reconstructed with a two-dimensional fast-fourier-transform algorithm, and a new configuration of imaging was developed to overcome the pixel-size limit of the recording device without reducing the effective na. the image of an atomic-force-microscope cantilever was reconstructed with a lateral resolution of 480 nm, and the phase contrast image of a 20 nm carbon mesh foil demonstrated that profiles of sample thickness can be reconstructed with few-nanometers uncertainty. the ultrashort x-ray pulse duration combined with single-shot capability offers great advantage for flash imaging of delicate samples.",
            "contribution_ids": [
                "R162106"
            ]
        },
        {
            "instance_id": "R162329xR162244",
            "comparison_id": "R162329",
            "paper_id": "R162244",
            "text": "Single-shot soft x-ray laser linewidth measurement using a grating interferometer the linewidth of a 14.7 nm wavelength ni-like pd soft x-ray laser was measured in a single shot using a soft x-ray diffraction grating interferometer. the instrument uses the time delay introduced by the gratings across the beam to measure the temporal coherence. the spectral linewidth of the 4d1s0-4p1p1 ni-like pd lasing line was measured to be \u03b4\u03bb/\u03bb=3\u00d710(-5) from the fourier transform of the fringe visibility. this single shot linewidth measurement technique provides a rapid and accurate way to determine the temporal coherence of soft x-ray lasers that can contribute to the development of femtosecond plasma-based soft x-ray lasers.",
            "contribution_ids": [
                "R162245"
            ]
        },
        {
            "instance_id": "R162329xR162271",
            "comparison_id": "R162329",
            "paper_id": "R162271",
            "text": "Tabletop single-shot extreme ultraviolet Fourier transform holography of an extended object we demonstrate single and multi-shot fourier transform holography with the use of a tabletop extreme ultraviolet laser. the reference wave was produced by a fresnel zone plate with a central opening that allowed the incident beam to illuminate the sample directly. the high reference wave intensity allows for larger objects to be imaged compared to mask-based lensless fourier transform holography techniques. we obtain a spatial resolution of 169 nm from a single laser pulse and a resolution of 128 nm from an accumulation of 20 laser pulses for an object ~11x11\u03bcm(2) in size. this experiment utilized a tabletop extreme ultraviolet laser that produces a highly coherent ~1.2 ns laser pulse at 46.9 nm wavelength.",
            "contribution_ids": [
                "R162273"
            ]
        },
        {
            "instance_id": "R162574xR162457",
            "comparison_id": "R162574",
            "paper_id": "R162457",
            "text": "Overview of the CHEMDNER patents task a considerable effort has been made to extract biological and chemical entities, as well as their relationships, from the scientific literature, either manually through traditional literature curation or by using information extraction and text mining technologies. medicinal chemistry patents contain a wealth of information, for instance to uncover potential biomarkers that might play a role in cancer treatment and prognosis. however, current biomedical annotation databases do not cover such information, partly due to limitations of publicly available biomedical patent mining software. as part of the biocreative v chemdner patents track, we present the results of the first named entity recognition (ner) assignment carried out to detect mentions of chemical compounds and genes/proteins in running patent text. more specifically, this task aimed to evaluate the performance of automatic name recognition strategies capable of isolating chemical names and gene and gene product mentions from surrounding text within patent titles and abstracts. a total of 22 unique teams submitted results for at least one of the three chemdner subtasks. the first subtask, called the cemp (chemical entity mention in patents) task, focused on the detection of chemical named entity mentions in patents, requesting teams to return the start and end indices corresponding to all the chemical entities found in a given record. a total of 21 teams submitted 93 runs, for this subtask. the top performing team reached an f-measure of 0.89 with a precision of 0.87 and a recall of 0.91. the cpd (chemical passage detection) task required the classification of patent titles and abstracts whether they do or do not contain chemical compound mentions. nine teams returned predictions for this task (40 runs). the top run in terms of matthew\u2019s correlation coefficient (mcc) had a score of 0.88, the highest sensitivity ? corresponding author",
            "contribution_ids": [
                "R162459",
                "R171956",
                "R171968",
                "R171966"
            ]
        },
        {
            "instance_id": "R163265xR163224",
            "comparison_id": "R163265",
            "paper_id": "R163224",
            "text": "An empirical evaluation of resources for the identification of diseases and adverse effects in biomedical literature the mentions of human health perturbations such as the diseases and adverse effects denote a special entity class in the biomedical \\nliterature. they help in understanding the underlying risk factors and develop a preventive rationale. the recognition of these named \\nentities in texts through dictionary-based approaches relies on the availability of appropriate terminological resources. although few \\nresources are publicly available, not all are suitable for the text mining needs. therefore, this work provides an overview of the well \\nknown resources with respect to human diseases and adverse effects such as the mesh, meddra, icd-10, snomed ct, and umls. \\nindividual dictionaries are generated from these resources and their performance in recognizing the named entities is evaluated over a \\nmanually annotated corpus. in addition, the steps for curating the dictionaries, rule-based acronym disambiguation and their impact \\non the dictionary performance is discussed. the results show that the meddra and umls achieve the best recall. besides this, \\nmeddra provides an additional benefit of achieving a higher precision. the combination of search results of all the dictionaries achieve \\na considerably high recall. the corpus is available on http://www.scai.fraunhofer.de/disease-ae-corpus.html",
            "contribution_ids": [
                "R163226"
            ]
        },
        {
            "instance_id": "R163742xR163725",
            "comparison_id": "R163742",
            "paper_id": "R163725",
            "text": "RDoC Task at BioNLP-OST 2019 bionlp open shared tasks (bionlp-ost) is an international competition organized to facilitate development and sharing of computational tasks of biomedical text mining and solutions to them. for bionlp-ost 2019, we introduced a new mental health informatics task called \u201crdoc task\u201d, which is composed of two subtasks: information retrieval and sentence extraction through national institutes of mental health\u2019s research domain criteria framework. five and four teams around the world participated in the two tasks, respectively. according to the performance on the two tasks, we observe that there is room for improvement for text mining on brain research and mental illness.",
            "contribution_ids": [
                "R163727"
            ]
        },
        {
            "instance_id": "R164231xR164050",
            "comparison_id": "R164231",
            "paper_id": "R164050",
            "text": "Static Relations: a Piece in the Biomedical Information Extraction Puzzle \"we propose a static relation extraction task to complement biomedical information extraction approaches. we argue that static relations such as part-whole are implicitly involved in many common extraction settings, define a task setting making them explicit, and discuss their integration into previously proposed tasks and extraction methods. we further identify a specific static relation extraction task motivated by the bionlp'09 shared task on event extraction, introduce an annotated corpus for the task, and demonstrate the feasibility of the task by experiments showing that the defined relations can be reliably extracted. the task setting and corpus can serve to support several forms of domain information extraction.\"",
            "contribution_ids": [
                "R164052"
            ]
        },
        {
            "instance_id": "R164231xR163865",
            "comparison_id": "R164231",
            "paper_id": "R163865",
            "text": "Part-of-Speech Annotation of Biology Research Abstracts a part-of-speech (pos) tagged corpus was built on research abstracts in biomedical domain with the penn treebank scheme. as consistent annotation was difficult without domain-specific knowledge we made use of the existing term annotation of the genia corpus. a list of frequent terms annotated in the genia corpus was compiled and the pos of each constituent of those terms were determined with assistance from domain specialists. the pos of the terms in the list are pre-assigned, then a tagger assigns pos to remaining words preserving the pre-assigned pos, whose results are corrected by human annotators. we also modified the ptb scheme slightly. an inter-annotator agreement tested on new 50 abstracts was 98.5%. a pos tagger trained with the annotated abstracts was tested against a gold-standard set made from the interannotator agreement. the untrained tagger had the accuracy of 83.0%. trained with 2000 annotated abstracts the accuracy rose to 98.2%. the 2000 annotated abstracts are publicly available.",
            "contribution_ids": [
                "R163867"
            ]
        },
        {
            "instance_id": "R166240xR163050",
            "comparison_id": "R166240",
            "paper_id": "R163050",
            "text": "Named Entity Recognition in Wikipedia \"named entity recognition (ner) is used in many domains beyond the newswire text that comprises current gold-standard corpora. recent work has used wikipedia's link structure to automatically generate near gold-standard annotations. until now, these resources have only been evaluated on newswire corpora or themselves. \\n \\nwe present the first ner evaluation on a wikipedia gold standard (wg) corpus. our analysis of cross-corpus performance on wg shows that wikipedia text may be a harder ner domain than newswire. we find that an automatic annotation of wikipedia has high agreement with wg and, when used as training data, outperforms newswire models by up to 7.7%.\"",
            "contribution_ids": [
                "R163052"
            ]
        },
        {
            "instance_id": "R166240xR163109",
            "comparison_id": "R166240",
            "paper_id": "R163109",
            "text": "WiNER: A Wikipedia Annotated Corpus for Named Entity Recognition we revisit the idea of mining wikipedia in order to generate named-entity annotations. we propose a new methodology that we applied to english wikipedia to build winer, a large, high quality, annotated corpus. we evaluate its usefulness on 6 ner tasks, comparing 4 popular state-of-the art approaches. we show that lstm-crf is the approach that benefits the most from our corpus. we report impressive gains with this model when using a small portion of winer on top of the conll training material. last, we propose a simple but efficient method for exploiting the full range of winer, leading to further improvements.",
            "contribution_ids": [
                "R163111"
            ]
        },
        {
            "instance_id": "R166240xR166178",
            "comparison_id": "R166240",
            "paper_id": "R166178",
            "text": "Exploiting Wikipedia as external knowledge for named entity recognition we explore the use of wikipedia as external knowledge to improve named entity recognition (ner). our method retrieves the corresponding wikipedia entry for each candidate word sequence and extracts a category label from the first sentence of the entry, which can be thought of as a definition part. these category labels are used as features in a crf-based ne tagger. we demonstrate using the conll 2003 dataset that the wikipedia category labels extracted by such a simple method actually improve the accuracy of ner.",
            "contribution_ids": [
                "R166180"
            ]
        },
        {
            "instance_id": "R172155xR171842",
            "comparison_id": "R172155",
            "paper_id": "R171842",
            "text": "BC4GO: a full-text corpus for the BioCreative IV GO task gene function curation via gene ontology (go) annotation is a common task among model organism database groups. owing to its manual nature, this task is considered one of the bottlenecks in literature curation. there have been many previous attempts at automatic identification of go terms and supporting information from full text. however, few systems have delivered an accuracy that is comparable with humans. one recognized challenge in developing such systems is the lack of marked sentence-level evidence text that provides the basis for making go annotations. we aim to create a corpus that includes the go evidence text along with the three core elements of go annotations: (i) a gene or gene product, (ii) a go term and (iii) a go evidence code. to ensure our results are consistent with real-life go data, we recruited eight professional go curators and asked them to follow their routine go annotation protocols. our annotators marked up more than 5000 text passages in 200 articles for 1356 distinct go terms. for evidence sentence selection, the inter-annotator agreement (iaa) results are 9.3% (strict) and 42.7% (relaxed) in f1-measures. for go term selection, the iaas are 47% (strict) and 62.9% (hierarchical). our corpus analysis further shows that abstracts contain \u223c10% of relevant evidence sentences and 30% distinct go terms, while the results/experiment section has nearly 60% relevant sentences and >70% go terms. further, of those evidence sentences found in abstracts, less than one-third contain enough experimental detail to fulfill the three core criteria of a go annotation. this result demonstrates the need of using full-text articles for text mining go annotations. through its use at the biocreative iv go (bc4go) task, we expect our corpus to become a valuable resource for the bionlp research community. database url: http://www.biocreative.org/resources/corpora/bc-iv-go-task-corpus/.",
            "contribution_ids": [
                "R171844",
                "R171845"
            ]
        },
        {
            "instance_id": "R182358xR182107",
            "comparison_id": "R182358",
            "paper_id": "R182107",
            "text": "Multi-Task Learning for Calorie Prediction on a Novel Large-Scale Recipe Dataset Enriched with Nutritional Information a rapidly growing amount of content posted online, such as food recipes, opens doors to new exciting applications at the intersection of vision and language. in this work, we aim to estimate the calorie amount of a meal directly from an image by learning from recipes people have published on the internet, thus skipping time-consuming manual data annotation. since there are few large-scale publicly available datasets captured in unconstrained environments, we propose the pic2kcal benchmark comprising 308 000 images from over 70 000 recipes including photographs, ingredients, and instructions. to obtain nutritional information of the ingredients and automatically determine the ground-truth calorie value, we match the items in the recipes with structured information from a food item database. we evaluate various neural networks for regression of the calorie quantity and extend them with the multi-task paradigm. our learning procedure combines the calorie estimation with prediction of proteins, carbohydrates, and fat amounts as well as a multi-label ingredient classification. our experiments demonstrate clear benefits of multi-task learning for calorie estimation, surpassing the single-task calorie regression by 9.9%. to encourage further research on this task, we make the code for generating the dataset and the models publicly available.",
            "contribution_ids": [
                "R182109",
                "R182111",
                "R182130",
                "R182145",
                "R182156",
                "R182171",
                "R182172",
                "R182174",
                "R182175",
                "R182176",
                "R182178",
                "R182179",
                "R182181",
                "R182182",
                "R182183",
                "R182185",
                "R182186",
                "R182187",
                "R182188",
                "R182189"
            ]
        },
        {
            "instance_id": "R182358xR182316",
            "comparison_id": "R182358",
            "paper_id": "R182316",
            "text": "Automatic Chinese food identification and quantity estimation computer-aided food identification and quantity estimation have caught more attention in recent years because of the growing concern of our health. the identification problem is usually defined as an image categorization or classification problem and several researches have been proposed. in this paper, we address the issues of feature descriptors in the food identification problem and introduce a preliminary approach for the quantity estimation using depth information. sparse coding is utilized in the sift and local binary pattern feature descriptors, and these features combined with gabor and color features are used to represent food items. a multi-label svm classifier is trained for each feature, and these classifiers are combined with multi-class adaboost algorithm. for evaluation, 50 categories of worldwide food are used, and each category contains 100 photographs from different sources, such as manually taken or from internet web albums. an overall accuracy of 68.3% is achieved, and success at top-n candidates achieved 80.6%, 84.8%, and 90.9% accuracy accordingly when n equals 2, 3, and 5, thus making mobile application practical. the experimental results show that the proposed methods greatly improve the performance of original sift and lbp feature descriptors. on the other hand, for quantity estimation using depth information, a straight forward method is proposed for certain food, while transparent food ingredients such as pure water and cooked rice are temporarily excluded.",
            "contribution_ids": [
                "R182318"
            ]
        },
        {
            "instance_id": "R182358xR182352",
            "comparison_id": "R182358",
            "paper_id": "R182352",
            "text": "Real-Time Mobile Food Recognition System \"we propose a mobile food recognition system the poses of which are estimating calorie and nutritious of foods and recording a user's eating habits. since all the processes on image recognition performed on a smart-phone, the system does not need to send images to a server and runs on an ordinary smartphone in a real-time way. to recognize food items, a user draws bounding boxes by touching the screen first, and then the system starts food item recognition within the indicated bounding boxes. to recognize them more accurately, we segment each food item region by grubcut, extract a color histogram and surf-based bag-of-features, and finally classify it into one of the fifty food categories with linear svm and fast 2 kernel. in addition, the system estimates the direction of food regions where the higher svm output score is expected to be obtained, show it as an arrow on the screen in order to ask a user to move a smartphone camera. this recognition process is performed repeatedly about once a second. we implemented this system as an android smartphone application so as to use multiple cpu cores effectively for real-time recognition. in the experiments, we have achieved the 81.55% classification rate for the top 5 category candidates when the ground-truth bounding boxes are given. in addition, we obtained positive evaluation by user study compared to the food recording system without object recognition.\"",
            "contribution_ids": [
                "R182354"
            ]
        },
        {
            "instance_id": "R184018xR182127",
            "comparison_id": "R184018",
            "paper_id": "R182127",
            "text": "Crop diversity is associated with higher child diet diversity in Ethiopia, particularly among low-income households, but not in Vietnam abstract objectives: to examine associations of household crop diversity with school-aged child dietary diversity in vietnam and ethiopia and mechanisms underlying these associations. design: we created a child diet diversity score (dds) using data on seven food groups consumed in the last 24 h. generalised estimating equations were used to model associations of household-level crop diversity, measured as a count of crop species richness (csr) and of plant crop nutritional functional richness (cnfr), with dds. we examined effect modification by household wealth and subsistence orientation, and mediation by the farm\u2019s market orientation. setting: two survey years of longitudinal data from the young lives cohort. participants: children (aged 5 years in 2006 and 8 years in 2009) from rural farming households in ethiopia ( n 1012) and vietnam ( n 1083). results: there was a small, positive association between household cnfr and dds in ethiopia (cnfr\u2013dds, \u03b2 = 0\u00b713; (95 % ci 0\u00b707, 0\u00b719)), but not in vietnam. associations of crop diversity and child diet diversity were strongest among poor households in ethiopia and among subsistence-oriented households in vietnam. agricultural earnings positively mediated the crop diversity\u2013diet diversity association in ethiopia. discussion: children from households that are poorer and those that rely more on their own agricultural production for food may benefit most from increased crop diversity.",
            "contribution_ids": [
                "R182129"
            ]
        },
        {
            "instance_id": "R184018xR182137",
            "comparison_id": "R184018",
            "paper_id": "R182137",
            "text": "Understanding the Linkages between Crop Diversity and Household Dietary Diversity in the Semi-Arid Regions of India agriculture is fundamental to achieving nutrition goals; it provides the food, energy, and nutrients essential \\nfor human health and well-being. this paper has examined crop diversity and dietary diversity in six \\nvillages using the icrisat village level studies (vls) data from the telangana and maharashtra states \\nof india. the study has used the data of cultivating households for constructing the crop diversity index \\nwhile dietary diversity data is from the special purpose nutritional surveys conducted by icrisat in the \\nsix villages. the study has revealed that the cropping pattern is not uniform across the six study villages \\nwith dominance of mono cropping in telangana villages and of mixed cropping in maharashtra villages. \\nthe analysis has indicated a positive and significant correlation between crop diversity and household \\ndietary diversity at the bivariate level. in multiple linear regression model, controlling for the other \\ncovariates, crop diversity has not shown a significant association with household dietary diversity. however, \\nother covariates have shown strong association with dietary diversity. the regression results have revealed \\nthat households which cultivated minimum one food crop in a single cropping year have a significant and \\npositive relationship with dietary diversity. from the study it can be inferred that crop diversity alone \\ndoes not affect the household dietary diversity in the semi-arid tropics. enhancing the evidence base and \\nfuture research, especially in the fragile environment of semi-arid tropics, is highly recommended.",
            "contribution_ids": [
                "R182139"
            ]
        },
        {
            "instance_id": "R184018xR182396",
            "comparison_id": "R184018",
            "paper_id": "R182396",
            "text": "The influence of crop production and socioeconomic factors on seasonal household dietary diversity in Burkina Faso households in low-income settings are vulnerable to seasonal changes in dietary diversity because of fluctuations in food availability and access. we assessed seasonal differences in household dietary diversity in burkina faso, and determined the extent to which household socioeconomic status and crop production diversity modify changes in dietary diversity across seasons, using data from the nationally representative 2014 burkina faso continuous multisectoral survey (emc). a household dietary diversity score based on nine food groups was created from household food consumption data collected during four rounds of the 2014 emc. plot-level crop production data, and data on household assets and education were used to create variables on crop diversity and household socioeconomic status, respectively. analyses included data for 10,790 households for which food consumption data were available for at least one round. accounting for repeated measurements and controlling for the complex survey design and confounding covariates using a weighted multi-level model, household dietary diversity was significantly higher during both lean seasons periods, and higher still during the harvest season as compared to the post-harvest season (mean: post-harvest: 4.76 (se 0.04); beginning of lean: 5.13 (se 0.05); end of lean: 5.21 (se 0.05); harvest: 5.72 (se 0.04)), but was not different between the beginning and the end of lean season. seasonal differences in household dietary diversity were greater among households with higher food expenditures, greater crop production, and greater monetary value of crops sale (p<0.05). seasonal changes in household dietary diversity in burkina faso may reflect nutritional differences among agricultural households, and may be modified both by households\u2019 socioeconomic status and agricultural characteristics.",
            "contribution_ids": [
                "R182397"
            ]
        },
        {
            "instance_id": "R184018xR184012",
            "comparison_id": "R184018",
            "paper_id": "R184012",
            "text": "If They Grow It, Will They Eat and Grow? Evidence from Zambia on Agricultural Diversity and Child Undernutrition abstract in this article we address a gap in our understanding of how household agricultural production diversity affects the diets and nutrition of young children living in rural farming communities in sub-saharan africa. the specific objectives of this article are to assess: (1) the association between household agricultural production diversity and child dietary diversity; and (2) the association between household agricultural production diversity and child nutritional status. we use household survey data collected from 3,040 households as part of the realigning agriculture for improved nutrition (rain) intervention in zambia. the data indicate low agricultural diversity, low dietary diversity and high levels of chronic malnutrition overall in this area. we find a strong positive association between production diversity and dietary diversity among younger children aged 6\u201323 months, and significant positive associations between production diversity and height for age z-scores and stunting among older children aged 24\u201359 months.",
            "contribution_ids": [
                "R184014"
            ]
        },
        {
            "instance_id": "R186048xR180001",
            "comparison_id": "R186048",
            "paper_id": "R180001",
            "text": "A Deep Learning based Approach for Precise Video Tagging with the increase in smart devices and abundance of video contents, efficient techniques for the indexing, analysis and retrieval of videos are becoming more and more desirable. improved indexing and automated analysis of millions of videos could be accomplished by getting videos tagged automatically. a lot of existing methods fail to precisely tag videos because of their lack of ability to capture the video context. the context in a video represents the interactions of objects in a scene and their overall meaning. in this work, we propose a novel approach that integrates the video scene ontology with cnn (convolutional neural network) for improved video tagging. our method captures the content of a video by extracting the information from individual key frames. the key frames are then fed to a cnn based deep learning model to train its parameters. the trained parameters are used to generate the most frequent tags. highly frequent tags are used to summarize the input video. the proposed technique is benchmarked on the most widely used dataset of video activities, namely, ucf-101. our method managed to achieve an overall accuracy of 99.8% with an f1- score of 96.2%.",
            "contribution_ids": [
                "R180003",
                "R180014",
                "R180016"
            ]
        },
        {
            "instance_id": "R186111xR186093",
            "comparison_id": "R186111",
            "paper_id": "R186093",
            "text": "Assessing Business-IT Allignment Maturity strategic alignment focuses on the activities that management performs to achieve cohesive goals across the it (information technology) and other functional organizations (e.g., finance, marketing, h/r, r&amp;d, manufacturing). therefore, alignment addresses both how it is in harmony with the business, and how the business should, or could, be in harmony with it. alignment evolves into a relationship where the function of it and other business functions adapt their strategies together. achieving alignment is evolutionary and dynamic. it requires strong support from senior management, good working relationships, strong leadership, appropriate prioritization, trust, and effective communication, as well as a thorough understanding of the business and technical environments. the strategic alignment maturity assessment provides organizations with a vehicle to evaluate these activities. knowing the maturity of its strategic choices and alignment practices make it possible for a firm to see where it stands and how it can improve. this chapter discusses an approach for assessing the maturity of the business-it alignment. once maturity is understood, an organization can identify opportunities for enhancing the harmonious relationship of business and it.",
            "contribution_ids": [
                "R186095"
            ]
        },
        {
            "instance_id": "R189691xR189572",
            "comparison_id": "R189691",
            "paper_id": "R189572",
            "text": "Ionic supramolecular bonds preserve mechanical properties and enable synergetic performance at high humidity in water-borne, self-assembled nacre-mimetics \"although tremendous effort has been focused on enhancing the mechanical properties of nacre-mimetic materials, conservation of high stiffness and strength against hydration-induced decay of mechanical properties at high humidity remains a fundamental challenge in such water-borne high-performance materials. herein, we demonstrate that ionic supramolecular bonds, introduced by infiltration of divalent cu(2+) ions, allow efficient stabilization of the mechanical properties of self-assembled water-borne nacre-mimetics based on sustainable sodium carboxymethylcellulose (na(+)cmc) and natural sodium montmorillonite nanoclay (na(+)mtm) against high humidity (95% rh). the mechanical properties in the highly hydrated state (young's modulus up to 13.5 gpa and tensile strength up to 125 mpa) are in fact comparable to a range of non-crosslinked nacre-mimetic materials in the dry state. moreover, the cu(2+)-treated nacre-inspired materials display synergetic mechanical properties as found in a simultaneous improvement of stiffness, strength and toughness, as compared to the pristine material. significant inelastic deformation takes place considering the highly reinforced state. this contrasts the typical behaviour of tight, covalent crosslinks and is suggested to originate from a sacrificial, dynamic breakage and rebinding of transient supramolecular ionic bonds. considering easy access to a large range of ionic interactions and alteration of counter-ion charge via external stimuli, we foresee responsive and adaptive mechanical properties in highly reinforced and stiff bio-inspired bulk nanocomposites and in other bio-inspired materials, e.g. nanocellulose papers and peptide-based materials.\"",
            "contribution_ids": [
                "R189574"
            ]
        },
        {
            "instance_id": "R189691xR189668",
            "comparison_id": "R189691",
            "paper_id": "R189668",
            "text": "Nacre-Mimetic Clay/Xyloglucan Bionanocomposites: A Chemical Modification Route for Hygromechanical Performance at High Humidity \"nacre-mimetic bionanocomposites of high montmorillonite (mtm) clay content, prepared from hydrocolloidal suspensions, suffer from reduced strength and stiffness at high relative humidity. we address this problem by chemical modification of xyloglucan in (xg)/mtm nacre-mimetic nanocomposites, by subjecting the xg to regioselective periodate oxidation of side chains to enable it to form covalent cross-links to hydroxyl groups in neighboring xg chains or to the mtm surface. the resulting materials are analyzed by ftir spectroscopy, thermogravimetric analysis, carbohydrate analysis, calorimetry, x-ray diffraction, scanning electron microscopy, tensile tests, and oxygen barrier properties. we compare the resulting mechanical properties at low and high relative humidity. the periodate oxidation leads to a strong increase in modulus and strength of the materials. a modulus of 30 gpa for cross-linked composite at 50% relative humidity compared with 13.7 gpa for neat xg/mtm demonstrates that periodate oxidation of the xg side chains leads to crucially improved stress transfer at the xg/mtm interface, possibly through covalent bond formation. this enhanced interfacial adhesion and internal cross-linking of the matrix moreover preserves the mechanical properties at high humidity condition and leads to a young's modulus of 21 gpa at 90%rh.\"",
            "contribution_ids": [
                "R189670"
            ]
        },
        {
            "instance_id": "R189691xR189677",
            "comparison_id": "R189691",
            "paper_id": "R189677",
            "text": "Multifunctional Nanoclay Hybrids of High Toughness, Thermal, and Barrier Performances to address brittleness of nanoclay hybrids of high inorganic content, ductile polymers (polyethylene oxide and hydroxyethyl cellulose) and montmorillonite (mtm) have been assembled into hybrid films using a water-based filtration process. nacre-mimetic layered films resulted and were characterized by fe-sem and xrd. mechanical properties at ambient condition were studied by tensile test, while performance at elevated temperature and moisture conditions were evaluated by tga, dynamic vapor sorption, and dynamic thermomechanical and hygromechanical analyses. antiflammability and barrier properties against oxygen and water vapor were also investigated. despite their high mtm content in the 60-85 wt % range, the hybrids exhibit remarkable ductility and a storage modulus above 2 gpa even in severe conditions (300\u00b0c or 94% rh). moreover, they present fire-shielding property and are amongst the best oxygen and water vapor barrier hybrids reported in the literature. this study thus demonstrates nanostructure property advantages for synergistic effects in hybrids combining inexpensive, available, and environmentally benign constituents.",
            "contribution_ids": [
                "R189678"
            ]
        },
        {
            "instance_id": "R189691xR189685",
            "comparison_id": "R189691",
            "paper_id": "R189685",
            "text": "Deoxyguanosine Phosphate Mediated Sacrificial Bonds Promote Synergistic Mechanical Properties in Nacre-Mimetic Nanocomposites \"we show that functionalizing polymer-coated colloidal nanoplatelets with guanosine groups allows synergistic increase of mechanical properties in nacre-mimetic lamellar self-assemblies. anionic montmorillonite (mtm) was first coated using cationic poly(diallyldimethylammonium chloride) (pdadmac) to prepare core-shell colloidal platelets, and subsequently the remaining chloride counterions allowed exchange to functional anionic 2'-deoxyguanosine 5'-monophosphate (dgmp) counterions, containing hydrogen bonding donors and acceptors. the compositions were studied using elemental analysis, scanning and transmission electron microscopy, wide-angle x-ray scattering, and tensile testing. the lamellar spacing between the clays increases from 1.85 to 2.14 nm upon addition of the dgmp. adding dgmp increases the elastic modulus, tensile strength, and strain 33.0%, 40.9%, and 5.6%, respectively, to 13.5 gpa, 67 mpa, and 1.24%, at 50% relative humidity. this leads to an improved toughness seen as a ca. 50% increase of the work-to-failure. this is noteworthy, as previously it has been observed that connecting the core-shell nanoclay platelets covalently or ionically leads to increase of the stiffness but to reduced strain. we suggest that the dynamic supramolecular bonds allow slippage and sacrificial bonds between the self-assembling nanoplatelets, thus promoting toughness, still providing dynamic interactions between the platelets.\"",
            "contribution_ids": [
                "R189688"
            ]
        },
        {
            "instance_id": "R190010xR189600",
            "comparison_id": "R190010",
            "paper_id": "R189600",
            "text": "Intrusion detection system based on the analysis of time intervals of CAN messages for in-vehicle network controller area network (can) bus in the vehicles is a de facto standard for serial communication to provide an efficient, reliable and economical link between electronic control units (ecu). however, can bus does not have enough security features to protect itself from inside or outside attacks. intrusion detection system (ids) is one of the best ways to enhance the vehicle security level. unlike the traditional ids for network security, ids for vehicle requires light-weight detection algorithm because of the limitations of the computing power of electronic devices reside in cars. in this paper, we propose a light-weight intrusion detection algorithm for in-vehicle network based on the analysis of time intervals of can messages. we captured can messages from the cars made by a famous manufacturer and performed three kinds of message injection attacks. as a result, we find the time interval is a meaningful feature to detect attacks in the can traffic. also, our intrusion detection system detects all of message injection attacks without making false positive errors.",
            "contribution_ids": [
                "R189602"
            ]
        },
        {
            "instance_id": "R191054xR190018",
            "comparison_id": "R191054",
            "paper_id": "R190018",
            "text": "Clinical Characteristics of COVID-19 Patients With Digestive Symptoms in Hubei, China: A Descriptive, Cross-Sectional, Multicenter Study objective: since the outbreak of coronavirus disease 2019 (covid-19) in december 2019, various digestive symptoms have been frequently reported in patients infected with the virus. in this study, we aimed to further investigate the prevalence and outcomes of covid-19 patients with digestive symptoms. methods: in this descriptive, cross-sectional, multicenter study, we enrolled confirmed patients with covid-19 who presented to 3 hospitals from january 18, 2020, to february 28, 2020. all patients were confirmed by real-time polymerase chain reaction and were analyzed for clinical characteristics, laboratory data, and treatment. data were followed up until march 18, 2020. results: in the present study, 204 patients with covid-19 and full laboratory, imaging, and historical data were analyzed. the average age was 52.9 years (sd \u00b1 16), including 107 men and 97 women. although most patients presented to the hospital with fever or respiratory symptoms, we found that 103 patients (50.5%) reported a digestive symptom, including lack of appetite (81 [78.6%] cases), diarrhea (35 [34%] cases), vomiting (4 [3.9%] cases), and abdominal pain (2 [1.9%] cases). if lack of appetite is excluded from the analysis (because it is less specific for the gastrointestinal tract), there were 38 total cases (18.6%) where patients presented with a gastrointestinal-specific symptom, including diarrhea, vomiting, or abdominal pain. patients with digestive symptoms had a significantly longer time from onset to admission than patients without digestive symptoms (9.0 days vs 7.3 days). in 6 cases, there were digestive symptoms, but no respiratory symptoms. as the severity of the disease increased, digestive symptoms became more pronounced. patients with digestive symptoms had higher mean liver enzyme levels, lower monocyte count, longer prothrombin time, and received more antimicrobial treatment than those without digestive symptoms. discussion: we found that digestive symptoms are common in patients with covid-19. moreover, these patients have a longer time from onset to admission, evidence of longer coagulation, and higher liver enzyme levels. clinicians should recognize that digestive symptoms, such as diarrhea, are commonly among the presenting features of covid-19 and that the index of suspicion may need to be raised earlier in at-risk patients presenting with digestive symptoms. however, further large sample studies are needed to confirm these findings.",
            "contribution_ids": [
                "R190020"
            ]
        },
        {
            "instance_id": "R191054xR190022",
            "comparison_id": "R191054",
            "paper_id": "R190022",
            "text": "Effect of Gastrointestinal Symptoms in Patients With COVID-19 because of accumulating evidence pointing to continuous person-to-person transmission of coronavirus disease 2019 (covid-19) in hospital and family settings,1,2 the world health organization has recently declared covid-19 a public health emergency of international concern. fever and respiratory symptoms tend to be initial and major, whereas gastrointestinal (gi) symptoms were also observed in a significant portion of patients.3 positive findings of reverse transcription polymerase chain reaction further showed that covid-19 may spread by fecal-oral transmission.",
            "contribution_ids": [
                "R190025"
            ]
        },
        {
            "instance_id": "R191054xR190053",
            "comparison_id": "R191054",
            "paper_id": "R190053",
            "text": "Association of Gastrointestinal System With Severity and Mortality of COVID-19: A Systematic Review and Meta-Analysis at present, the novel coronavirus disease (covid-19) is causing a major pandemic. covid-19 is caused by the severe acute respiratory syndrome coronavirus 2 (sars-cov-2). in covid-19, the patient usually presents with fever, dry cough, and respiratory manifestations. however, the involvement of other systems has also been reported in the literature. abdominal pain, diarrhea, vomiting, and nausea are the predominant gastrointestinal (gi) manifestations underlined in the literature. we conducted a literature search using four databases (pubmed, web of science, google scholar, and clinicaltrials.gov). our search strategy included medical subject headings (mesh) terms and keywords for covid-19, sars-cov-2, and gi system from inception to october 2020. after excluding duplicates, review articles, and non-relevant articles, we included 20 studies out of 842 articles reporting gi manifestations in covid-19 patients. using cochrane revman version 5.4 (cochrane, london, uk), a compute pooled analysis using a random-effect model was performed. our study included 6,022 patients with a median age of 49.5 years. pooled analysis via random effect model revealed an increased risk of severe covid-19 in patients manifesting gi symptoms with an odds ratio (or) of 2.07 (95% confidence interval [ci]: 1.34-3.18) with i2=41%). odds of mortality in covid-19 with gi manifestation and hepatic abnormalities included 0.92 (95% ci: 0.50-1.69) (i2=57%) and 1.26 (95% ci: 0.67-2.37) (i2=0%), respectively. severe covid-19 may have a strong association with gi manifestations and have a significant impact on gi practice. holistic knowledge of the spectrum of the gi consequences in covid-19 is crucial to get a hold of virus spread. in this article, we have summarized the association of gi manifestations in severe covid-19 patients.",
            "contribution_ids": [
                "R190055"
            ]
        },
        {
            "instance_id": "R191407xR191192",
            "comparison_id": "R191407",
            "paper_id": "R191192",
            "text": "Embracing Domain Differences in Fake News: Cross-domain Fake News Detection using Multi-modal Data with the rapid evolution of social media, fake news has become a significant social problem, which cannot be addressed in a timely manner using manual investigation. this has motivated numerous studies on automating fake news detection. most studies explore supervised training models with different modalities (e.g., text, images, and propagation networks) of news records to identify fake news. however, the performance of such techniques generally drops if news records are coming from different domains (e.g., politics, entertainment), especially for domains that are unseen or rarely-seen during training. as motivation, we empirically show that news records from different domains have significantly different word usage and propagation patterns. furthermore, due to the sheer volume of unlabelled news records, it is challenging to select news records for manual labelling so that the domain-coverage of the labelled dataset is maximized. hence, this work: (1) proposes a novel framework that jointly preserves domain-specific and cross-domain knowledge in news records to detect fake news from different domains; and (2) introduces an unsupervised technique to select a set of unlabelled informative news records for manual labelling, which can be ultimately used to train a fake news detection model that performs well for many domains while minimizing the labelling cost. our experiments show that the integration of the proposed fake news model and the selective annotation approach achieves state-of-the-art performance for cross-domain news datasets, while yielding notable improvements for rarely-appearing domains in news datasets.",
            "contribution_ids": [
                "R191194"
            ]
        },
        {
            "instance_id": "R191407xR191219",
            "comparison_id": "R191407",
            "paper_id": "R191219",
            "text": "Embedding Partial Propagation Network for Fake News Early Detection detecting fake news as early as possible has attracted growing attention due to its fast-spreading nature and the significant harm it can cause. as demonstrated in recent studies, the propagation pattern of fake news on social media differs from that of real news, and a number of works have extracted different types of features from the propagation pattern for detection. however, a major limitation of this approach is that the propagation network is not fully available in the early stages, and may take a long time to complete. as a result, existing network-based fake news detection methods yield low accuracy during the early stages of propagation. to bridge the research gap, in this work we: (1) propose a novel network embedding algorithm, based on the investigation of a wide range of features obtained from the propagation network, which are not well studied in previous work; and (2) design an autoencoder-based neural architecture to predict the embedding of the complete propagation network using the partially available network in the early stages of propagation. our experiments show that with the predicted embedding for the complete propagation network, our model can achieve state-of-the-art performance while only having access to the early stage propagation network.",
            "contribution_ids": [
                "R191221"
            ]
        },
        {
            "instance_id": "R191407xR191241",
            "comparison_id": "R191407",
            "paper_id": "R191241",
            "text": "dEFEND: Explainable Fake News Detection in recent years, to mitigate the problem of fake news, computational detection of fake news has been studied, producing some promising early results. while important, however, we argue that a critical missing piece of the study be the explainability of such detection, i.e., why a particular piece of news is detected as fake. in this paper, therefore, we study the explainable detection of fake news. we develop a sentence-comment co-attention sub-network to exploit both news contents and user comments to jointly capture explainable top-k check-worthy sentences and user comments for fake news detection. we conduct extensive experiments on real-world datasets and demonstrate that the proposed method not only significantly outperforms 7 state-of-the-art fake news detection methods by at least 5.33% in f1-score, but also (concurrently) identifies top-k user comments that explain why a news piece is fake, better than baselines by 28.2% in ndcg and 30.7% in precision.",
            "contribution_ids": [
                "R191243"
            ]
        },
        {
            "instance_id": "R191976xR189876",
            "comparison_id": "R191976",
            "paper_id": "R189876",
            "text": "Precision Wavelength Determination of 2^1P_1 - 1^1S_0 and 2^3P_1 - 1^1S_0 Transitions in Helium-Like Sulfur Ions transitions from the 21p1 - and 23p1 -state to the ground state 11s0 in helium-like sulphur ions have been measured with an accuracy of 4 \u00d7 10-5. energy calibration is described in detail and two reference wavelengths have been reevaluated. substantial line-blending was observed, due to long-lived spectator electrons. the two transition energies were corrected for doppler shift and compared with most refined theoretical calculations, including terms of order \u03b14z6 in the breit operator and terms of order \u03b15z6 in the quantum-electrodynamical corrections. the experimental contributions to the ground-state qed shifts agree within its error (\u223c 15%) with the theoretical values.",
            "contribution_ids": [
                "R189878"
            ]
        },
        {
            "instance_id": "R191976xR190068",
            "comparison_id": "R191976",
            "paper_id": "R190068",
            "text": "Precision X-ray wavelength measurements in helium-like argon recoil ions \"the authors report precise wavelength measurements of the 1s2 1s0-1s2p3p1,2,1p1 transitions in ar16+ produced by collisions of 5.9 mev amu-1 u66+ ions with an argon gas target. by use of this 'recoil source', the precision is not limited by doppler shifts while the influence of spectator electrons is minimised by observation of their relative importance as a function of gas pressure. the accuracy obtained is at the 12 p.p.m. level dominated by the x-ray calibration standard. the measurement is thus sensitive to quantum-electrodynamic (qed) and electron correlation effects.\"",
            "contribution_ids": [
                "R190070",
                "R190101",
                "R190133"
            ]
        },
        {
            "instance_id": "R191984xR191915",
            "comparison_id": "R191984",
            "paper_id": "R191915",
            "text": "A Methodology of CAN Communication Encryption Using a shuffling algorithm in-vehicle communication uses can bus, and for this, communication speed and security are important. since the current can communication is used without encryption, many cases have been reported of vehicle hacking over time. with the advent of autonomous driving and connected cars, vehicles no longer remain independent; they can be invaded from the outside and personal information such as vehicle location and driving habits can be accessed through the vehicle, which poses a serious threat to personal privacy and life. therefore, communication data must be encrypted in order to increase the security of the communication. in this paper, data frames are encrypted using a shuffling algorithm in the can communication system environment. to put it more precisely, the data frame is divided into bits and structured into blocks, which are then shuffled for data hiding. this method determines the level of obfuscation based on blockage and shuffle criteria. the encryption time was measured by changing both. this suggest ways to increase the security and communication speed in the vehicle.",
            "contribution_ids": [
                "R191917"
            ]
        },
        {
            "instance_id": "R191984xR191933",
            "comparison_id": "R191984",
            "paper_id": "R191933",
            "text": "A PUF Based CAN Security Framework we propose a method to include security and reliability to the messages sent over the can bus. our approach adheres to can standard iso 11898-1. a reliable puf response is used in key generation to create a unique shared aes-256 key between each ecu, allowing for all message paths to be encrypted. in addition, an hmac system with a counter is implemented to help protect against replay attacks and message tampering within the network.",
            "contribution_ids": [
                "R191935"
            ]
        },
        {
            "instance_id": "R191984xR191942",
            "comparison_id": "R191984",
            "paper_id": "R191942",
            "text": "Improving Timing Behavior on Encrypted CAN Buses \"can is probably the most successful bus in the automotive domain, especially, due to its low cost and robustness. however, with increasing connectivity, there is a need to encrypt data to avoid attacks such as spoofing and sniffing. this ends up exposing can's severe limitations. in particular, each encrypted message requires sending two frames due to its restrictive payload in can. moreover, each frame of an encrypted message undergoes a separate arbitration process which negatively impacts timing and makes it difficult to meet deadlines. in this paper, to work around this problem, we propose a technique that consists in assigning different priorities to encrypted can frames so as to compensate for increased delay. the basic idea is that, once the first frame of an encrypted can message wins arbitration, its second frame will always win arbitration within a specified scope and can be sent with lesser delay. we have conducted experiments on real hardware and performed extensive simulations indicating that the proposed technique reduces transmission delay to one half or even one third compared with the standard approach allowing us to still meet typical automotive deadlines on an encrypted can bus.\"",
            "contribution_ids": [
                "R191944"
            ]
        },
        {
            "instance_id": "R193278xR193173",
            "comparison_id": "R193278",
            "paper_id": "R193173",
            "text": "Representation of IP Routing Policies in a Routing Registry (ripe-81++) \"this document was originally published as a ripe document known as ripe-181 but is also being published as an informational rfc to reach a larger audience than its original scope. it has received community wide interest and acknowledgment throughout the internet service provider community and will be used as the basic starting point for future work on internet routing registries and routing policy representation. it can also be referred to as ripe-81++. this document is an update to the original `ripe-81'[1] proposal for representing and storing routing polices within the ripe database. it incorporates several extensions proposed by merit inc.[2] and gives details of a generalized ip routing policy representation to be used by all internet routing registries. it acts as both tutorial and provides details of database objects and attributes that use and make up a routing registry.\"",
            "contribution_ids": [
                "R193175"
            ]
        },
        {
            "instance_id": "R193278xR193197",
            "comparison_id": "R193278",
            "paper_id": "R193197",
            "text": "Origin authentication in interdomain routing attacks against internet routing are increasing in number and severity. contributing greatly to these attacks is the absence of origin authentication: there is no way to validate claims of address ownership or location. the lack of such services enables not only attacks by malicious entities, but indirectly allow seemingly inconsequential miconfigurations to disrupt large portions of the internet. this paper considers the semantics, design, and costs of origin authentication in interdomain routing. we formalize the semantics of address delegation and use on the internet, and develop and characterize broad classes of origin authentication proof systems. we estimate the address delegation graph representing the current use of ipv4 address space using available routing data. this effort reveals that current address delegation is dense and relatively static: as few as 16 entities perform 80% of the delegation on the internet. we conclude by evaluating the proposed services via traced based simulation. our simulation shows the enhanced proof systems can reduce significantly reduce resource costs associated with origin authentication.",
            "contribution_ids": [
                "R193199"
            ]
        },
        {
            "instance_id": "R193278xR193200",
            "comparison_id": "R193278",
            "paper_id": "R193200",
            "text": "SPV: Secure path vector routing for securing BGP as our economy and critical infrastructure increasingly relies on the internet, the insecurity of the underlying border gateway routing protocol (bgp) stands out as the achilles heel. recent misconfigurations and attacks have demonstrated the brittleness of bgp. securing bgp has become a priority.in this paper, we focus on a viable deployment path to secure bgp. we analyze security requirements, and consider tradeoffs of mechanisms that achieve the requirements. in particular, we study how to secure bgp update messages against attacks. we design an efficient cryptographic mechanism that relies only on symmetric cryptographic primitives to guard an aspath from alteration, and propose the secure path vector (spv) protocol. in contrast to the previously proposed s-bgp protocol, spv is around 22 times faster. with the current effort to secure bgp, we anticipate that spv will contribute several alternative mechanisms to secure bgp, especially for the case of incremental deployments.",
            "contribution_ids": [
                "R193202"
            ]
        },
        {
            "instance_id": "R193278xR193209",
            "comparison_id": "R193278",
            "paper_id": "R193209",
            "text": "Optimizing BGP security by exploiting path stability the border gateway protocol (bgp) is the de facto interdomain routing protocol on the internet. while the serious vulnerabilities of bgp are well known, no security solution has been widely deployed. the lack of adoption is largely caused by a failure to find a balance between deployability, cost, and security. in this paper, we consider the design and performance of bgp path authentication constructions that limit resource costs by exploiting route stability. based on a year-long study of bgp traffic and indirectly supported by findings within the networking community, we observe that routing paths are highly stable. this observation leads to comprehensive and efficient constructions for path authentication. we empirically analyze the resource consumption of the proposed constructions via trace-based simulations. this latter study indicates that our constructions can reduce validation costs by as much as 97.3% over existing proposals while requiring nominal storage resources. we conclude by considering operational issues related to incremental deployment of our solution.",
            "contribution_ids": [
                "R193211"
            ]
        },
        {
            "instance_id": "R193278xR193255",
            "comparison_id": "R193278",
            "paper_id": "R193255",
            "text": "An infrastructure to support secure internet routing this document describes an architecture for an infrastructure to\\nsupport secure internet routing. the foundation of this architecture\\nis a public key infrastructure (pki) that represents the allocation\\nhierarchy of ip address space and autonomous system numbers;\\ncertificates from this pki are used to verify signed objects that\\nauthorize autonomous systems to originate routes for specified ip\\naddress prefixes. the data objects that comprise the pki, as well as\\nother signed objects necessary for secure routing, are stored and\\ndisseminated through a distributed repository system. this document\\nalso describes at a high level how this architecture can be used to\\nadd security features to common operations such as ip address space\\nallocation and route filter construction.",
            "contribution_ids": [
                "R193257"
            ]
        },
        {
            "instance_id": "R193505xR178376",
            "comparison_id": "R193505",
            "paper_id": "R178376",
            "text": "SARS-CoV-2 viral load as a predictor for disease severity in outpatients and hospitalised patients with COVID-19: A prospective cohort study \\n introduction \\n we aimed to examine if severe acute respiratory syndrome coronavirus 2 (sars-cov-2) polymerase chain reaction (pcr) cycle quantification (c q ) value, as a surrogate for sars-cov-2 viral load, could predict hospitalisation and disease severity in adult patients with coronavirus disease 2019 (covid-19). \\n \\n \\n methods \\n we performed a prospective cohort study of adult patients with pcr positive sars-cov-2 airway samples including all out-patients registered at the department of infectious diseases, odense university hospital (ouh) march 9-march 17 2020, and all hospitalised patients at ouh march 10-april 21 2020. to identify associations between c q -values and a) hospital admission and b) a severe outcome, logistic regression analyses were used to compute odds ratios (or) and 95% confidence intervals (ci), adjusting for confounding factors (aor). \\n \\n \\n results \\n we included 87 non-hospitalised and 82 hospitalised patients. the median baseline c q -value was 25.5 (interquartile range 22.3\u201329.0). we found a significant association between increasing c q -value and hospital-admission in univariate analysis (or 1.11, 95% ci 1.04\u20131.19). however, this was due to an association between time from symptom onset to testing and c q -values, and no association was found in the adjusted analysis (aor 1.08, 95% ci 0.94\u20131.23). in hospitalised patients, a significant association between lower c q -values and higher risk of severe disease was found (aor 0.89, 95% ci 0.81\u20130.98), independent of timing of testing. \\n \\n \\n conclusions \\n sars-cov-2 pcr c q -values in outpatients correlated with time after symptom onset, but was not a predictor of hospitalisation. however, in hospitalised patients lower c q -values were associated with higher risk of severe disease. \\n",
            "contribution_ids": [
                "R178379",
                "R178429"
            ]
        },
        {
            "instance_id": "R193505xR191188",
            "comparison_id": "R193505",
            "paper_id": "R191188",
            "text": "Epidemiological Correlates of Polymerase Chain Reaction Cycle Threshold Values in the Detection of Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) abstract \\n \\n background \\n detection of severe acute respiratory syndrome coronavirus 2 (sars-cov-2) infection has principally been performed through the use of real-time reverse-transcription polymerase chain reaction testing. results of such tests can be reported as cycle threshold (ct) values, which may provide semi-quantitative or indirect measurements of viral load. previous reports have examined temporal trends in ct values over the course of a sars-cov-2 infection. \\n \\n \\n methods \\n using testing data collected during a prospective household transmission investigation of outpatient and mild coronavirus disease 2019 cases, we examined the relationships between ct values of the viral rna n1 target and demographic, clinical, and epidemiological characteristics collected through participant interviews and daily symptom diaries. \\n \\n \\n results \\n we found that ct values are lowest (corresponding to a higher viral rna concentration) soon after symptom onset and are significantly correlated with the time elapsed since onset (p\\u2005&amp;lt;\\u2005.001); within 7 days after symptom onset, the median ct value was 26.5, compared with a median ct value of 35.0 occurring 21 days after onset. ct values were significantly lower among participants under 18 years of age (p\\u2005=\\u2005.01) and those reporting upper respiratory symptoms at the time of sample collection (p\\u2005=\\u2005.001), and were higher among participants reporting no symptoms (p\\u2005=\\u2005.05). \\n \\n \\n conclusions \\n these results emphasize the importance of early testing for sars-cov-2 among individuals with symptoms of respiratory illness, and allow cases to be identified and isolated when their viral shedding may be highest. \\n",
            "contribution_ids": [
                "R191191"
            ]
        },
        {
            "instance_id": "R193505xR191238",
            "comparison_id": "R193505",
            "paper_id": "R191238",
            "text": "SARS-CoV-2 Viral Load on Admission Is Associated With 30-Day Mortality abstract \\n severe acute respiratory syndrome coronavirus 2 (sars-cov-2) viral load on admission was associated with a significantly increased 30-day mortality (odds ratio [or], 4.20; 95% ci, 1.62\u201310.86), and anti-sars-cov-2 nucleocapisid igg seropositivity on admission trended toward a reduced 30-day mortality (or, 0.43; 95% ci, 0.15\u20131.26). reporting of quantitative sars-cov-2 viral load and serologic assays may offer prognostic clinical information.",
            "contribution_ids": [
                "R191240"
            ]
        },
        {
            "instance_id": "R193505xR191301",
            "comparison_id": "R193505",
            "paper_id": "R191301",
            "text": "Impact of Severe Acute Respiratory Syndrome Coronavirus 2 Viral Load on Risk of Intubation and Mortality Among Hospitalized Patients With Coronavirus Disease 2019 abstract \\n \\n background \\n patients hospitalized with coronavirus disease 2019 (covid-19) frequently require mechanical ventilation and have high mortality rates. however, the impact of viral burden on these outcomes is unknown. \\n \\n \\n methods \\n we conducted a retrospective cohort study of patients hospitalized with covid-19 from 30 march 2020 to 30 april 2020 at 2 hospitals in new york city. severe acute respiratory syndrome coronavirus 2 (sars-cov-2) viral load was assessed using cycle threshold (ct) values from a reverse transcription-polymerase chain reaction assay applied to nasopharyngeal swab samples. we compared characteristics and outcomes of patients with high, medium, and low admission viral loads and assessed whether viral load was independently associated with intubation and in-hospital mortality. \\n \\n \\n results \\n we evaluated 678 patients with covid-19. higher viral load was associated with increased age, comorbidities, smoking status, and recent chemotherapy. in-hospital mortality was 35.0% (ct\\u2005&amp;lt;25; n\\u2005=\\u2005220), 17.6% (ct 25\u201330; n\\u2005=\\u2005216), and 6.2% (ct\\u2005&amp;gt;30; n\\u2005=\\u2005242) with high, medium, and low viral loads, respectively (p &amp;lt; .001). the risk of intubation was also higher in patients with a high viral load (29.1%) compared with those with a medium (20.8%) or low viral load (14.9%; p\\u2005&amp;lt;\\u2005.001). high viral load was independently associated with mortality (adjusted odds ratio [aor], 6.05; 95% confidence interval [ci], 2.92\u201312.52) and intubation (aor, 2.73; 95% ci, 1.68\u20134.44). \\n \\n \\n conclusions \\n admission sars-cov-2 viral load among hospitalized patients with covid-19 independently correlates with the risk of intubation and in-hospital mortality. providing this information to clinicians could potentially be used to guide patient care. \\n",
            "contribution_ids": [
                "R191303"
            ]
        },
        {
            "instance_id": "R193505xR191318",
            "comparison_id": "R193505",
            "paper_id": "R191318",
            "text": "Characteristics of viral specimens collected from asymptomatic and fatal cases of COVID-19 we sought to determine the characteristics of viral specimens associated with fatal cases, asymptomatic cases and non-fatal symptomatic cases of covid-19. this included the analysis of 1264 specimens found reactive for at least two sars-cov-2 specific loci from people screened for infection in northern nevada in march-may of 2020. of these, 30 were specimens from fatal cases, while 23 were from positive, asymptomatic cases. we assessed the relative amounts of sars-cov-2 rna from sample swabs by real-time pcr and use of the threshold crossing value (ct). moreover, we compared the amount of human rnase p found on the same swabs. a considerably higher viral load was found to be associated with swabs from cases involving fatality and the difference was found to be strongly statistically significant. noting this difference, we sought to assess whether any genetic correlation could be found in association with virus from fatal cases using whole genome sequencing. while no common genetic elements were discerned, one branch of epidemiologically linked fatal cases did have two point mutations, which no other of 156 sequenced cases from northern nevada had. the mutations caused amino acid changes in the 3\u2032-5\u2032 exonuclease protein, and the product of the gene, orf8.",
            "contribution_ids": [
                "R191320"
            ]
        },
        {
            "instance_id": "R193505xR191339",
            "comparison_id": "R193505",
            "paper_id": "R191339",
            "text": "SARS-CoV-2 viral load predicts COVID-19 mortality abstract the need for reliable and widely available sars-cov-2 testing is well recognized, but it will be equally necessary to develop quantitative methods that determine viral load in order to guide patient triage and medical decision making. we are the first to report that sars-cov-2 viral load at the time of presentation is an independent predictor of covid-19 mortality in a large patient cohort (n=1,145). viral loads should be used to identify higher-risk patients that may require more aggressive care and should be included as a key biomarker in the development of predictive algorithms.",
            "contribution_ids": [
                "R191341"
            ]
        },
        {
            "instance_id": "R193565xR192191",
            "comparison_id": "R193565",
            "paper_id": "R192191",
            "text": "Analysis of closed loop supply chain using genetic algorithm and particle swarm optimisation there are many reasons for the growing interest in reverse logistics. the most prominent reasons are the growing concern for the environment and cost reduction. next to environment, consumers demand for clean manufacturing and recycling. hence, customers and retailers expect original equipment manufacturers to set up a proper reverse logistics system and expect the returned products to be processed and recovered in an environmentally responsible way and another reason is cost reduction. a well-managed reverse logistics programme can provide important cost savings in procurement, disposal, inventory carrying and transportation. in this context, looking at the entire supply chain is the best starting point for solutions. supply chain management aims at the integration of traditional \u2018forward\u2019 supply chain processes, avoiding local optimisation by emphasising integrality. the main objective of this paper is to design an integrated forward logistics multi-echelon distribution inventory supply chain model (flmedim) and closed loop multi-echelon distribution inventory supply chain model (clmedim) for the built-to-order environment using genetic algorithm and particle swarm optimisation. in this paper, the proposed model is validated by considering two case studies: one for a tyre manufacturer and the other for a plastic goods manufacturer both located in the southern part of india. this paper utilises the multi-echelon distribution inventory supply chain model proposed by haq and kannan (2006a) for the flmedim. the software used was written in the java programming language.",
            "contribution_ids": [
                "R192193"
            ]
        },
        {
            "instance_id": "R193700xR193677",
            "comparison_id": "R193700",
            "paper_id": "R193677",
            "text": "Simulation analysis of supply chain risk management system based on IoT information platform abstract in this paper, iot (internet of things) information technology has been widely applied to the supply chain risk management (scrm). firstly, the source of risks has been sorted out, the external and internal risks have been described in detail with the risk management of supply chain system. secondly, the supply chain risk and case reasoning were mentioned. finally, the work actively explored the supply chain risk management by the iot information, such as 3g network, rfid and gps. the research on scrm based on iot information contributes to the construction and improvement of supply chain informatisation.",
            "contribution_ids": [
                "R193679"
            ]
        },
        {
            "instance_id": "R193700xR193694",
            "comparison_id": "R193700",
            "paper_id": "R193694",
            "text": "Assessing supply chain risk for apparel production in low cost countries using newsfeed analysis \\n purpose \\n with the growth of unstructured data, opportunities to generate insights into supply chain risks in low cost countries (lccs) are emerging. sourcing risk has primarily focused on short-term mitigation. this paper aims to offer an approach that uses newsfeed data to assess regional supply base risk in lcc\u2019s for the apparel sector, which managers can use to plan for future risk on a long-term planning horizon. \\n \\n \\n design/methodology/approach \\n this paper demonstrates that the bulk of supplier risk assessments focus on short-term responses to disruptions in developed countries, revealing a gap in assessments of long-term risks for supply base expansion in lccs. this paper develops an approach for predicting and planning for long-term supply base risk in lcc\u2019s to address this shortfall. a machine-based learning algorithm is developed that uses the analysis of competing hypotheses heuristic to convert data from multiple news feeds into numerical risk scores and visual maps of supply chain risk. this paper demonstrates the approach by converting large amounts of unstructured data into two measures, risk impact and risk probability, leading to visualization of country-level supply base risks for a global apparel company. \\n \\n \\n findings \\n this paper produced probability and impact scores for 23 distinct supply base risks across 10 countries in the apparel sector. the results suggest that the most significant long-term risks of supply disruption for apparel in lcc\u2019s are human resource regulatory risks, workplace issues, inflation costs, safety violations and social welfare violations. the results suggest that apparel brands seeking suppliers in the regions of cambodia, india, bangladesh, brazil and vietnam should be aware of the significant risks in these regions that may require mitigative action. \\n \\n \\n originality/value \\n this approach establishes a novel approach for objectively projecting future global sourcing risk, and yields visually mapped outcomes that can be applied in forecasting and planning for future risks when considering sourcing locations in lcc\u2019s. \\n",
            "contribution_ids": [
                "R193696"
            ]
        },
        {
            "instance_id": "R193700xR193697",
            "comparison_id": "R193700",
            "paper_id": "R193697",
            "text": "Extracting supply chain maps from news articles using deep neural networks \"supply chains are increasingly global, complex and multi-tiered. consequently, companies often struggle to maintain complete visibility of their supply network. this poses a problem as visibility of the network structure is required for tasks like effectively managing supply chain risk. in this paper, we discuss automated supply chain mapping as a means of maintaining structural visibility of a company's supply chain, and we use deep learning to automatically extract buyer\u2013supplier relations from natural language text. early results show that supply chain mapping solutions using natural language processing and deep learning could enable companies to (a) automatically generate rudimentary supply chain maps, (b) verify existing supply chain maps, or (c) augment existing maps with additional supplier information.\"",
            "contribution_ids": [
                "R193699"
            ]
        },
        {
            "instance_id": "R194697xR129608",
            "comparison_id": "R194697",
            "paper_id": "R129608",
            "text": "Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing \\n pretraining large neural language models, such as bert, has led to impressive gains on many natural language processing (nlp) tasks. however, most pretraining efforts focus on general domain corpora, such as newswire and web. a prevailing assumption is that even domain-specific pretraining can benefit by starting from general-domain language models. in this article, we challenge this assumption by showing that for domains with abundant unlabeled text, such as biomedicine, pretraining language models from scratch results in substantial gains over continual pretraining of general-domain language models. to facilitate this investigation, we compile a comprehensive biomedical nlp benchmark from publicly available datasets. our experiments show that domain-specific pretraining serves as a solid foundation for a wide range of biomedical nlp tasks, leading to new state-of-the-art results across the board. further, in conducting a thorough evaluation of modeling choices, both for pretraining and task-specific fine-tuning, we discover that some common practices are unnecessary with bert models, such as using complex tagging schemes in named entity recognition. to help accelerate research in biomedical nlp, we have released our state-of-the-art pretrained and task-specific models for the community, and created a leaderboard featuring our blurb benchmark (short for biomedical language understanding &amp; reasoning benchmark) at\\n https://aka.ms/blurb \\n .\\n",
            "contribution_ids": [
                "R129609",
                "R194667",
                "R194670",
                "R194672",
                "R194674",
                "R194681",
                "R194682",
                "R194683",
                "R194684",
                "R194685"
            ]
        },
        {
            "instance_id": "R196613xR196553",
            "comparison_id": "R196613",
            "paper_id": "R196553",
            "text": "Domain Independent Automatic Labeling system for Large-scale Social Data using Lexicon and Web-based Augmentation recently, with the large-scale adoption of social media, people have begun to express their opinion on these sites in the form of reviews. potential consumers often forced to wade through huge amount of reviews to make informed decision. sentiment analysis has become rapid and effective way to automatically gauge consumers\u2019 opinion. however, such analysis often requires tedious process of manual tagging of large training examples or manually building a lexicon for the purpose of classifying reviews as positive or negative. in this paper, we present a method to automate the tedious process of labeling large textual data in an unsupervised, domain independent and scalable manner. the proposed method combines the lexicon-based and web-based point wise mutual information (pmi) statistics to find the semantic orientation (so) of opinion expressed in a review.\\xa0 based on proposed methods a system called domain independent automatic labeling system (dials) has been implemented, which takes collection of text from any domain as input and generates fully labeled dataset in an unsupervised and scalable manner. the result generated can be used to track and summarize online discussion and/or use to train any classifier in the next stage of development. the effectiveness of system is tested by comparing it with baseline machine learning and lexicon-based methods. experiments on multi-domains dataset has shown that proposed method consistently shown improved recall and accuracy as compared to baseline machine learning and lexicon-based methods.\\xa0\\xa0\\xa0",
            "contribution_ids": [
                "R196555"
            ]
        },
        {
            "instance_id": "R196613xR196605",
            "comparison_id": "R196613",
            "paper_id": "R196605",
            "text": "Sentiment Analysis of Persian Movie Reviews Using Deep Learning sentiment analysis aims to automatically classify the subject\u2019s sentiment (e.g., positive, negative, or neutral) towards a particular aspect such as a topic, product, movie, news, etc. deep learning has recently emerged as a powerful machine learning technique to tackle the growing demand for accurate sentiment analysis. however, the majority of research efforts are devoted to english-language only, while information of great importance is also available in other languages. this paper presents a novel, context-aware, deep-learning-driven, persian sentiment analysis approach. specifically, the proposed deep-learning-driven automated feature-engineering approach classifies persian movie reviews as having positive or negative sentiments. two deep learning algorithms, convolutional neural networks (cnn) and long-short-term memory (lstm), are applied and compared with our previously proposed manual-feature-engineering-driven, svm-based approach. simulation results demonstrate that lstm obtained a better performance as compared to multilayer perceptron (mlp), autoencoder, support vector machine (svm), logistic regression and cnn algorithms.",
            "contribution_ids": [
                "R196608"
            ]
        },
        {
            "instance_id": "R197259xR196928",
            "comparison_id": "R197259",
            "paper_id": "R196928",
            "text": "Detection of human norovirus in intestinal biopsies from immunocompromised transplant patients human noroviruses (hunovs) can often cause chronic infections in solid organ and haematopoietic stem cell transplant (hsct) patients. based on histopathological changes observed during hunov infections, the intestine is the presumed site of virus replication in patients; however, the cell types infected by hunovs remain unknown. the objective of this study was to characterize histopathological changes during hunov infection and to determine the cell types that may be permissive for hunov replication in transplant patients. we analysed biopsies from hunov-infected and non-infected (control) transplant patients to assess histopathological changes in conjunction with detection of hunov antigens to identify the infected cell types. hunov infection in immunocompromised patients was associated with histopathological changes such as disorganization and flattening of the intestinal epithelium. the hunov major capsid protein, vp1, was detected in all segments of the small intestine, in areas of biopsies that showed histopathological changes. specifically, vp1 was detected in enterocytes, macrophages, t cells and dendritic cells. hunov replication was investigated by detecting the non-structural proteins, rdrp and vpg. we detected rdrp and vpg along with vp1 in duodenal and jejunal enterocytes. these results provide critical insights into histological changes due to hunov infection in immunocompromised patients and propose human enterocytes as a physiologically relevant cell type for hunov cultivation.",
            "contribution_ids": [
                "R196930",
                "R196956"
            ]
        },
        {
            "instance_id": "R197259xR196942",
            "comparison_id": "R197259",
            "paper_id": "R196942",
            "text": "Human norovirus targets enteroendocrine epithelial cells in the small intestine abstract human noroviruses are a major cause of diarrheal illness, but pathogenesis is poorly understood. here, we investigate the cellular tropism of norovirus in specimens from four immunocompromised patients. abundant norovirus antigen and rna are detected throughout the small intestinal tract in jejunal and ileal tissue from one pediatric intestinal transplant recipient with severe gastroenteritis. negative-sense viral rna, a marker of active viral replication, is found predominantly in intestinal epithelial cells, with chromogranin a-positive enteroendocrine cells (eecs) identified as a permissive cell type in this patient. these findings are consistent with the detection of norovirus-positive eecs in the other three immunocompromised patients. investigation of the signaling pathways induced in eecs that mediate communication between the gut and brain may clarify mechanisms of pathogenesis and lead to the development of in vitro model systems in which to evaluate norovirus vaccines and treatment.",
            "contribution_ids": [
                "R196946",
                "R196989"
            ]
        },
        {
            "instance_id": "R197259xR197081",
            "comparison_id": "R197259",
            "paper_id": "R197081",
            "text": "Chimpanzees as an animal model for human norovirus infection and vaccine development noroviruses are global agents of acute gastroenteritis, but the development of control strategies has been hampered by the absence of a robust animal model. studies in chimpanzees have played a key role in the characterization of several fastidious hepatitis viruses, and we investigated the feasibility of such studies for the noroviruses. seronegative chimpanzees inoculated i.v. with the human norovirus strain norwalk virus (nv) did not show clinical signs of gastroenteritis, but the onset and duration of virus shedding in stool and serum antibody responses were similar to that observed in humans. nv rna was detected in intestinal and liver biopsies concurrent with the detection of viral shedding in stool, and nv antigen expression was observed in cells of the small intestinal lamina propria. two infected chimpanzees rechallenged 4, 10, or 24 mo later with nv were resistant to reinfection, and the presence of nv-specific serum antibodies correlated with protection. we evaluated the immunogenicity and efficacy of virus-like particles (vlps) derived from nv (genogroup i, gi) and md145 (genogroup ii, gii) noroviruses as vaccines. chimpanzees vaccinated intramuscularly with gi vlps were protected from nv infection when challenged 2 and 18 mo after vaccination, whereas chimpanzees that received gii vlps vaccine or a placebo were not. this study establishes the chimpanzee as a viable animal model for the study of norovirus replication and immunity, and shows that nv vlp vaccines could induce protective homologous immunity even after extended periods of time.",
            "contribution_ids": [
                "R197083",
                "R197114"
            ]
        },
        {
            "instance_id": "R197375xR193559",
            "comparison_id": "R197375",
            "paper_id": "R193559",
            "text": "Animal-vehicle collisions during the COVID-19 lockdown in early 2020 in the Krakow metropolitan region, Poland abstract the interrelations between human activity and animal populations are of increasing interest due to the emergence of the novel covid-19 and the consequent pandemic across the world. anthropogenic impacts of the pandemic on animals in urban-suburban environments are largely unknown. in this study, the temporal and spatial patterns of urban animal response to the covid-19 lockdown were assessed using animal-vehicle collisions (avc) data. we collected avc data over two 6-month periods in 2019 and 2020 (january to june) from the largest metropolis in southern poland, which included lockdown months. furthermore, we used traffic data to understand the impact of lockdown on avc in the urban area. our analysis of 1063 avc incidents revealed that covid-19 related lockdown decreased avc rates in suburban areas. however, in the urban area, even though traffic volume had significantly reduced, avc did not decrease significantly, suggesting that lockdown did not influence the collision rates in the urban area. our results suggest that there is a need to focus on understanding the effects of changes in traffic volume on both human behaviour and wildlife space use on the resulting impacts on avc in the urban area.",
            "contribution_ids": [
                "R194716",
                "R195871",
                "R195873",
                "R195946",
                "R195947",
                "R195956"
            ]
        },
        {
            "instance_id": "R198562xR195616",
            "comparison_id": "R198562",
            "paper_id": "R195616",
            "text": "Emission Variations of Primary Air Pollutants from Highway Vehicles and Implications during the COVID-19 Pandemic in Beijing, China according to the traffic flow variation from january 2019 to august 2020, emissions of primary air pollutants from highway vehicles were calculated based on the emission factor method, which integrated the actual structure of on-road vehicles. the characteristics of on-highway traffic flow and pollution emissions were compared during various progression stages of coronavirus disease (covid-19). the results showed that the average daily traffic volume decreased by 38.2% in 2020, with a decrease of 62% during the strict lockdown due to the impact of covid-19. the daily emissions of primary atmospheric pollutants decreased by 29.2% in 2020 compared to the same period in 2019. as for the structure of on-highway vehicle types, the small and medium-sized passenger vehicles predominated, which accounted for 76.3% of traffic, while trucks and large passenger vehicles accounted for 19.7% and 4.0%, but contributed 58.4% and 33.9% of nitrogen oxide (nox) emissions, respectively. according to the simulation results of the adms model, the average concentrations of nox were reduced by 12.0 \u00b5g/m3 compared with the same period in 2019. as for the implication for future pollution control, it is necessary to further optimize the structure of on-highway and the road traffic vehicle types and increase the proportions of new-energy vehicles and vehicles with high emission standards.",
            "contribution_ids": [
                "R195619",
                "R200031"
            ]
        },
        {
            "instance_id": "R198562xR196747",
            "comparison_id": "R198562",
            "paper_id": "R196747",
            "text": "Differential Effects of the COVID-19 Lockdown and Regional Fire on the Air Quality of Medell\u00c3\u00adn, Colombia governments\u2019 responses to the covid-19 pandemic provide a unique opportunity to study the effects of restricted socioeconomic activity on air quality. here, we study the changes in air pollution levels during the lockdown in medell\u00edn and its metropolitan area, colombia, for periods with and without enhanced regional fire activity, considering the effects of meteorology using random forest and multiple linear regression methods. the lockdown measures, which reduced mean traffic volume by 70% compared to 2016\u20132019, resulted in reductions for pm2.5 (50\u201363%), pm10 (59\u201364%), no (75\u201376%), no2 (43\u201347%), and co (40\u201347%), while o3 concentration increased by 19\u201322%. in contrast, when fire activity was high, the effects of the lockdown on air quality were shadowed by the long-range transport of biomass burning emissions, increasing fine particulate matter and ozone. this study shows that healthier levels are achievable through significant efforts from decision-makers and society. the results highlight the need to develop integral measures that do not only consider reductions in the local emissions from transportation and industry, but also the role of fire activity in the region, as well as the difficulties of achieving reductions in ozone from measures that are effective at reducing primary pollutants.",
            "contribution_ids": [
                "R196748",
                "R200063",
                "R200087",
                "R200133",
                "R200136",
                "R200139",
                "R200142"
            ]
        },
        {
            "instance_id": "R198562xR196778",
            "comparison_id": "R198562",
            "paper_id": "R196778",
            "text": "Risk-Compensation Trends in Road Safety during COVID-19 the covid-19 pandemic has had a global impact, disrupting the normal trends of our everyday life. more specifically, the effects of covid-19 on road safety are still largely unexplored. hence, this study aims to investigate the change in road safety trends due to covid-19 using real-time traffic parameters. results from the extensive analyses of the 2017 to 2020 data of interstate-4 show that traffic volume decreased by 13.6% in 2020 compared to the average of 2017\u20132019\u2019s volume, whereas there is a decreasing number of crashes at the higher volume. average speed increased by 11.3% during the covid-19 period; however, the increase in average speed during the covid-19 period has an insignificant relationship with crash severities. fatal crashes increased, while total crashes decreased, during the covid-19 period; severe crashes decreased with the total crashes. alcohol-related crashes decreased by 22% from 2019 to 2020. thus, the road-safety trend due to the impact of covid-19 has evidently changed and presents a unique trend. the findings of the study suggest a larger need for a more in-depth study to analyze the impact of covid-19 on road safety, to minimize fatalities on roads through appropriate policy measures.",
            "contribution_ids": [
                "R196780"
            ]
        },
        {
            "instance_id": "R199173xR197551",
            "comparison_id": "R199173",
            "paper_id": "R197551",
            "text": "Non-Uniform Adversarially Robust Pruning neural networks often are highly redundant and can thus be effectively compressed to a fraction of their initial size using model pruning techniques without harming the overall prediction accuracy. additionally, pruned networks need to maintain robustness against attacks such as adversarial examples. recent research on combining all these objectives has shown significant advances using uniform compression strategies, that is, all weights or channels are compressed equally according to a preset compression ratio. in this paper, we show that employing non-uniform compression strategies allows to significantly improve clean data accuracy as well as adversarial robustness under high overall compression. we leverage reinforcement learning for finding an optimal trade-off and demonstrate that the resulting compression strategy can be used as a plug-in replacement for uniform compression ratios of existing state-of-the-art approaches.",
            "contribution_ids": [
                "R197552"
            ]
        },
        {
            "instance_id": "R199173xR197592",
            "comparison_id": "R199173",
            "paper_id": "R197592",
            "text": "What to expect of hardware metric predictors in NAS modern neural architecture search (nas) focuses on finding the best performing architectures in hardware-aware settings; e.g., those with an optimal tradeoff of accuracy and latency. due to many advantages of prediction models over live measurements, the search process is often guided by estimates of how well each considered network architecture performs on the desired metrics. typical prediction models range from operation-wise lookup tables over gradient-boosted trees and neural networks, with little known information on how they compare. we evaluate 18 different performance predictors on ten combinations of metrics, devices, network types, and training tasks, and find that mlp models are the most promising. we then simulate and evaluate how the guidance of such prediction models affects the subsequent architecture selection. due to inaccurate predictions, the selected architectures are generally suboptimal, which we quantify as an expected reduction in accuracy and hypervolume. we show that simply verifying the predictions of just the selected architectures can lead to substantially improved results. under a time budget, we find it preferable to use a fast and inaccurate prediction model over accurate but slow live measurements. code and results are available at https://github.com/cogsys-tuebingen/naslib",
            "contribution_ids": [
                "R197593"
            ]
        },
        {
            "instance_id": "R199173xR197596",
            "comparison_id": "R199173",
            "paper_id": "R197596",
            "text": "Differentiable Architecture Search for Reinforcement Learning in this paper, we investigate the fundamental question: to what extent are gradient-based neural architecture search (nas) techniques applicable to rl? using the original darts as a convenient baseline, we discover that the discrete architectures found can achieve up to 250% performance compared to manual architecture designs on both discrete and continuous action space environments across o-policy and on-policy rl algorithms, at only 3x more computation time. furthermore, through numerous ablation studies, we systematically verify that not only does darts correctly upweight operations during its supernet phrase, but also gradually improves resulting discrete cells up to 30x more eciently than random search, suggesting darts is surprisingly an eective tool for improving architectures in rl.",
            "contribution_ids": [
                "R197597"
            ]
        },
        {
            "instance_id": "R199176xR194747",
            "comparison_id": "R199176",
            "paper_id": "R194747",
            "text": "A health consumer ontology of fast food information a variety of severe health issues can be attributed to poor nutrition and poor eating behaviors. research has explored the impact of nutritional knowledge on an individual\u2019s inclination to purchase and consume certain foods. this paper introduces the ontology of fast food facts, a knowledge base that models consumer nutritional data from major fast food establishments. this artifact serves as an aggregate knowledge base to centralize nutritional information for consumers. as a semantically-linked data source, the ontology of fast food facts could engender methods and tools to further the research and impact the health consumers\u2019 diet and behavior, which is a factor in many severe health outcomes. we describe the initial development of this ontology and future directions we plan with this knowledge base.",
            "contribution_ids": [
                "R194750",
                "R194756",
                "R194757"
            ]
        },
        {
            "instance_id": "R200035xR199183",
            "comparison_id": "R200035",
            "paper_id": "R199183",
            "text": "Exposure to Human and Bovine Noroviruses in a Birth Cohort in Southern India from 2002 to 2006 abstract \\n human and bovine norovirus virus-like particles were used to evaluate antibodies in indian children at ages 6 and 36 months and their mothers. antibodies to genogroup ii viruses were acquired early and were more prevalent than antibodies to genogroup i. low levels of igg antibodies against bovine noroviruses indicate possible zoonotic transmission.",
            "contribution_ids": [
                "R199185",
                "R199194",
                "R199195"
            ]
        },
        {
            "instance_id": "R200035xR200014",
            "comparison_id": "R200035",
            "paper_id": "R200014",
            "text": "Presence of Antibodies against Genogroup VI Norovirus in Humans abstract \\n \\n background \\n noroviruses are important enteric pathogens in humans and animals. recently, we reported a novel canine norovirus (canov) in dogs with diarrhea belonging to a new genogroup (gvi). no data are available on exposure of humans to this virus. \\n \\n \\n methods \\n sera from 373 small animal veterinarians and 120 age-matched population controls were tested for igg antibodies to canov by a recombinant virus like particle based enzyme-linked immunosorbent assay. \\n \\n \\n results \\n antibodies to canov were found in 22.3% of the veterinarians and 5.8% of the control group (p\\u2009&lt;\\u20090.001). mean corrected od 450 values for canov antibodies were significantly higher in small animal veterinarians compared to the control group. \\n \\n \\n conclusions \\n these findings suggest that canov may infect humans and small animal veterinarians are at an increased risk for exposure to this virus. additional studies are needed to assess if this virus is able to cause disease in humans. \\n",
            "contribution_ids": [
                "R200016",
                "R200017"
            ]
        },
        {
            "instance_id": "R201263xR189415",
            "comparison_id": "R201263",
            "paper_id": "R189415",
            "text": "Byssal threads inspired ionic cross-linked narce-like graphene oxide paper with superior mechanical strength \"artificial nacre-like graphene oxide paper has sparked great excitement in the scientific community for its unique properties. the preparation of a bioinspired high-strength nanocomposite paper via a simple vacuum-assisted assembly technique from graphene oxide (go), tannic acid (ta) and fe3+ ions is reported in this article. the fabricated papers were characterized by x-ray diffraction (xrd), scanning electron microscopy (sem), thermogravimetric analysis (tga), fourier transformed infrared (ftir) spectroscopy, x-ray photoelectron spectroscopy (xps) and dynamic mechanical analysis (dma). we show that fe3+ ions only induce limited improvement in the mechanical properties of the graphene oxide paper, while the efficient cross-linking of neighboring sheets by fe3+\u2013ta complex network can significantly improve the fracture strength and young's modulus of graphene oxide paper by 150% and 521%, respectively, with an optimal content of 5.7 wt% fe3+. with general surface binding affinity, ta molecules can be adsorbed to go sheets and provide binding sites for fe3+. the fe3+\u2013ta coordinated compound serves as the \u201cmortar\u201d to stick the go \u201cbricks\u201d together. the mechanical properties of our paper can be simply varied by controlling the cross-linking condition. the obtained nacre-like ultrastrong go papers could find potential in energy and sustainability applications.\"",
            "contribution_ids": [
                "R189417"
            ]
        },
        {
            "instance_id": "R201263xR189421",
            "comparison_id": "R201263",
            "paper_id": "R189421",
            "text": "Bio-Inspired Borate Cross-Linking in Ultra-Stiff Graphene Oxide Thin Films adjacent graphene oxide nanosheets in a thin-film structure have been covalently cross-linked in a fashion similar to the cell walls of higher-order plants. the resulting ultra-stiff structure exhibits a maximum storage modulus of 127 gpa that can be tuned by varying borate concentration.",
            "contribution_ids": [
                "R189422"
            ]
        },
        {
            "instance_id": "R201263xR189429",
            "comparison_id": "R201263",
            "paper_id": "R189429",
            "text": "The Effect of Interlayer Adhesion on the Mechanical Behaviors of Macroscopic Graphene Oxide Papers \"high mechanical performances of macroscopic graphene oxide (go) papers are attracting great interest owing to their merits of lightweight and multiple functionalities. however, the loading role of individual nanosheets and its effect on the mechanical properties of the macroscopic go papers are not yet well understood. herein, we effectively tailored the interlayer adhesions of the go papers by introducing small molecules, that is, glutaraldehyde (ga) and water molecules, into the gallery regions. with the help of in situ raman spectroscopy, we compared the varied load-reinforcing roles of nanosheets, and further predicted the young's moduli of the go papers. systematic mechanical tests have proven that the enhancement of the tensile modulus and strength of the ga-treated go paper arose from the improved load-bearing capability of the nanosheets. on the basis of raman and macroscopic mechanical tests, the influences of interlayer adhesions on the fracture mechanisms of the strained go papers were inferred.\"",
            "contribution_ids": [
                "R189431"
            ]
        },
        {
            "instance_id": "R201972xR201885",
            "comparison_id": "R201972",
            "paper_id": "R201885",
            "text": "Upper limb joint angle measurement in occupational health usual human motion capture systems are designed to work in controlled laboratory conditions. for occupational health, instruments that can measure during normal daily life are essential, as the evaluation of the workers' movements is a key factor to reduce employee injury- and illness-related costs. in this paper, we present a method for joint angle measurement, combining inertial sensors (accelerometers and gyroscopes) and magnetic sensors. this method estimates wrist flexion, wrist lateral deviation, elbow flexion, elbow pronation, shoulder flexion, shoulder abduction and shoulder internal rotation. the algorithms avoid numerical integration of the signals, which allows for long-time estimations without angle estimation drift. the system has been tested both under laboratory and field conditions. controlled laboratory tests show mean estimation errors between 0.06\u00b0 and of 1.05\u00b0, and standard deviation between 2.18\u00b0 and 9.20\u00b0. field tests seem to confirm these results when no ferromagnetic materials are close to the measurement system.",
            "contribution_ids": [
                "R201887"
            ]
        },
        {
            "instance_id": "R201972xR201888",
            "comparison_id": "R201972",
            "paper_id": "R201888",
            "text": "A Novel Kalman Filter for Human Motion Tracking With an Inertial-Based Dynamic Inclinometer goal: design and development of a linear kalman filter to create an inertial-based inclinometer targeted to dynamic conditions of motion. methods: the estimation of the body attitude (i.e., the inclination with respect to the vertical) was treated as a source separation problem to discriminate the gravity and the body acceleration from the specific force measured by a triaxial accelerometer. the sensor fusion between triaxial gyroscope and triaxial accelerometer data was performed using a linear kalman filter. wrist-worn inertial measurement unit data from ten participants were acquired while performing two dynamic tasks: 60-s sequence of seven manual activities and 90 s of walking at natural speed. stereophotogrammetric data were used as a reference. a statistical analysis was performed to assess the significance of the accuracy improvement over state-of-the-art approaches. results: the proposed method achieved, on an average, a root mean square attitude error of 3.6\u00b0 and 1.8\u00b0 in manual activities and locomotion tasks (respectively). the statistical analysis showed that, when compared to few competing methods, the proposed method improved the attitude estimation accuracy. conclusion: a novel kalman filter for inertial-based attitude estimation was presented in this study. a significant accuracy improvement was achieved over state-of-the-art approaches, due to a filter design that better matched the basic optimality assumptions of kalman filtering. significance: human motion tracking is the main application field of the proposed method. accurately discriminating the two components present in the triaxial accelerometer signal is well suited for studying both the rotational and the linear body kinematics.",
            "contribution_ids": [
                "R201890"
            ]
        },
        {
            "instance_id": "R201972xR201900",
            "comparison_id": "R201972",
            "paper_id": "R201900",
            "text": "A wearable inertial-sensing-based body sensor network for shoulder range of motion assessment this paper presents a wearable inertial-sensing-based body sensor network (bsn) composed of two inertial modules that are placed on human upper limb for real-time human motion capture applications. each inertial module consists of an arm-based 32-bit microcontroller (mcu), a triaxial accelerometer, a triaxial gyroscope, and a triaxial magnetometer. to estimate shoulder range of motion (rom), the accelerations, angular velocities, and magnetic signals are collected and processed by a quaternion-based complementary nonlinear filter for minimizing the cumulative errors caused by the intrinsic noise/drift of the inertial sensors. the proposed bsn is a cost-effective tool and can be used anywhere without any external reference device for shoulder rom. the sensor fusion algorithm can reduce orientation error effectively and thus can assess shoulder joint motions accurately.",
            "contribution_ids": [
                "R201902"
            ]
        },
        {
            "instance_id": "R201972xR201909",
            "comparison_id": "R201972",
            "paper_id": "R201909",
            "text": "Ambulatory human upper limb joint motion monitoring in order to make an ergonomic analysis of laborer working conditions, we need to measure the different joint angles along the daily work. these angles will be used to define the requirements of each workstation. this information, together with the medical examination of each worker, is then used to determine whether a worker can develop a task, or if the task may have caused an occupational disease. usual human motion capture systems are designed to work in laboratory controlled conditions. this paper presents a method of angular joint measurement, combining inertial sensors (accelerometers and gyroscopes) and magnetic sensors, which allows the ambulatory estimation of the 7 degrees of freedom of the upper limb, for a long time, without problems due to time integration of the signal.",
            "contribution_ids": [
                "R201911"
            ]
        },
        {
            "instance_id": "R201972xR201921",
            "comparison_id": "R201972",
            "paper_id": "R201921",
            "text": "Towards Miniaturization of a MEMS-Based Wearable Motion Capture System this paper presents a modular architecture to develop a wearable system for real-time human motion capture. the system is based on a network of smart inertial measurement units (imus) distributed on the human body. each of these modules is provided with a 32-bit risc microcontroller (mcu) and miniaturized mems sensors: three-axis accelerometer, three-axis gyroscopes, and three-axis magnetometer. the mcu collects measurements from the sensors and implement the sensor fusion algorithm, a quaternion-based extended kalman filter to estimate the attitude and the gyroscope biases. the design of the proposed imu, in order to overcome the problems of the commercial solution, aims to improve performance and to reduce size and weight. in this way, it can be easily embedded in a tracksuit for total body motion reconstruction with considerable enhancement of the wearability and comfort. furthermore, the main achievements will be presented with a performance comparison between the proposed imu and some commercial platforms.",
            "contribution_ids": [
                "R201923"
            ]
        },
        {
            "instance_id": "R201972xR201933",
            "comparison_id": "R201972",
            "paper_id": "R201933",
            "text": "A Fast Quaternion-Based Orientation Optimizer via Virtual Rotation for Human Motion Tracking for real-time ambulatory human motion tracking with low-cost inertial/magnetic sensors, a computationally efficient and robust algorithm for estimating orientation is critical. this paper presents a quaternion-based orientation optimizer for tracking human body motion, using triaxis rate gyro, accelerometer, and magnetometer signals. the proposed optimizer uses a gauss-newton (g-n) method for finding the best-fit quaternion. in order to decrease the computing time, the optimizer is formulated using a virtual rotation concept that allows very fast quaternion updates compared to the conventional g-n method. in addition, to guard against the effects of fast body motions and temporary ferromagnetic disturbances, a situational measurement vector selection procedure is adopted in conjunction with the g-n optimizer. the accuracy of orientation estimates is validated experimentally, using arm motion trials.",
            "contribution_ids": [
                "R201935"
            ]
        },
        {
            "instance_id": "R202077xR201686",
            "comparison_id": "R202077",
            "paper_id": "R201686",
            "text": "Accuracy Assessment of Kriging, artificial neural network, and a hybrid approach integrating spatial and terrain data in estimating and mapping of soil organic carbon this study aimed to produce a soil organic carbon (soc) content map with high accuracy and spatial resolution using the most effective factors in the model. the spatial soc estimation success of inverse distance weighting (idw), ordinary kriging (ok), empirical bayesian kriging (ebk), multi-layered perception network (mlp) and mlp-ok hybrid models were compared to obtain the most reliable model in estimating the soc content. the study area was located in besni district in the southeastern anatolia region of turkey. total of 132 surface (0\u201330 cm) soil samples were collected from the covers 1330 km 2 land and analyzed for soc, lime, clay and sand content and soil reaction included in the estimation models. mean annual precipitation and temperature, elevation, compound topographic index, enhanced vegetation and normalized difference vegetation index, were also used as the inputs in the modelling. the spatial distribution of soc was determined using a mlp and a two-stage ensemble model (mlp-ok) combining the estimation of ok residuals. soil surveys and covariates were used to train and validate the mlp-ok hybrid model. the mlp-ok model provided a more accurate estimation of soc content with minimal estimation errors (me: -0.028, 45 mae: 0.042, rmse: 0.066) for validation points compared to the other models. the mlp-ok model outperformed other models by 75.09 to 77.92%. the mlp-ok model estimated the lower and upper limits of the estimated and the measured values in a consistent manner compared to the other models. the spatial distribution map of soc content obtained by ann-kriging approach was significantly affected by ancillary variables, and revealed more detail than other interpolation methods in the northern, central, southwestern and southeastern parts of the study area. the results revealed that the assembling of mlp with ok model can contribute to obtain more reliable regional, national and global spatial soil information.",
            "contribution_ids": [
                "R201688"
            ]
        },
        {
            "instance_id": "R202077xR201997",
            "comparison_id": "R202077",
            "paper_id": "R201997",
            "text": "Ensemble Machine Learning Approach Improves Predicted Spatial Variation of Surface Soil Organic Carbon Stocks in Data-Limited Northern Circumpolar Region various approaches of differing mathematical complexities are being applied for spatial prediction of soil properties. regression kriging is a widely used hybrid approach of spatial variation that combines correlation between soil properties and environmental factors with spatial autocorrelation between soil observations. in this study, we compared four machine learning approaches (gradient boosting machine, multinarrative adaptive regression spline, random forest, and support vector machine) with regression kriging to predict the spatial variation of surface (0\u201330 cm) soil organic carbon (soc) stocks at 250-m spatial resolution across the northern circumpolar permafrost region. we combined 2,374 soil profile observations (calibration datasets) with georeferenced datasets of environmental factors (climate, topography, land cover, bedrock geology, and soil types) to predict the spatial variation of surface soc stocks. we evaluated the prediction accuracy at randomly selected sites (validation datasets) across the study area. we found that different techniques inferred different numbers of environmental factors and their relative importance for prediction of soc stocks. regression kriging produced lower prediction errors in comparison to multinarrative adaptive regression spline and support vector machine, and comparable prediction accuracy to gradient boosting machine and random forest. however, the ensemble median prediction of soc stocks obtained from all four machine learning techniques showed highest prediction accuracy. although the use of different approaches in spatial prediction of soil properties will depend on the availability of soil and environmental datasets and computational resources, we conclude that the ensemble median prediction obtained from multiple machine learning approaches provides greater spatial details and produces the highest prediction accuracy. thus an ensemble prediction approach can be a better choice than any single prediction technique for predicting the spatial variation of soc stocks.",
            "contribution_ids": [
                "R201999"
            ]
        },
        {
            "instance_id": "R202360xR202236",
            "comparison_id": "R202360",
            "paper_id": "R202236",
            "text": "xTSeH: A Trusted Platform Module Sharing Scheme Towards Smart IoT-eHealth Devices iot based ehealth system brings a revolution to healthcare industry, with which the old healthcare systems can be updated into smarter and more personalized ones. the practitioners can continue monitoring the physical status of the patients at anytime and anywhere, and develop more precise treatment plans by analyzing the collected data, such as heart rate, blood pressure, blood glucose. actually, these smart sensors used in ehealth system are smart embedded devices (sed). due to the limitations on hardware capabilities, these inter-connected seds lack of security considerations in design and implementation, and face the threats from the network. to prevent the malicious users (or programs) from tampering with the seds, trusted platform module (tpm) is adopted, which can guarantee the system integrity via detecting unauthorized modifications to data and system environment. however, due to the limited scalability and insufficient system resources, not all seds can be deployed with tpm chips. to address this issue, in this paper, a tpm extension scheme (xtseh) is proposed. in xtseh, we have extended the functions of a tpm deployed in a sed (tsed) to those non-tpm-protected seds (n-tsed) via network. a shadow tpm in the form of a kernel module is designed as the trust base for the n-tsed, which is the representative of the tpm in tsed. then, three protocols are proposed to implement the integrity verification and inter-sed authentication. finally, a raspberry pi based prototype system is designed and implemented. the feasibility and usability of our scheme are proved by the analysis of the experimental results of system performance.",
            "contribution_ids": [
                "R202243"
            ]
        },
        {
            "instance_id": "R202360xR202258",
            "comparison_id": "R202360",
            "paper_id": "R202258",
            "text": "PSL-MAAKA: Provably Secure and Lightweight Mutual Authentication and Key Agreement Protocol for Fully Public Channels in Internet of Medical Things designing efficient and secure mutual authentication and key agreement (maaka) protocols for internet of medical things (iomt) has been shown to be challenging, mainly due to the different security and privacy requirements in complex settings. existing schemes generally are subject to a number of limitations, ranging from performance to security issues. in this article, we introduce a provably secure and lightweight maaka (psl-maaka) protocol for fully public channels in iomt. first, the proposed scheme is lightweight since the major operations in the stage of authentication and key agreement are hash operation and xor operation, respectively. second, this article proves the security of the presented protocol taking the advantage of the random oracle model. next, this article gives that security requirements in iomt could be satisfied through our presented maaka protocol. finally, we demonstrate that it enjoys optimal performance than other competing schemes, in terms of communication overhead, computation overhead, and storage overhead.",
            "contribution_ids": [
                "R202264"
            ]
        },
        {
            "instance_id": "R203903xR203594",
            "comparison_id": "R203903",
            "paper_id": "R203594",
            "text": "Gaussian versus Uniform Distribution for Intrusion Detection in Wireless Sensor Networks in a wireless sensor network (wsn), intrusion detection is of significant importance in many applications in detecting malicious or unexpected intruder(s). the intruder can be an enemy in a battlefield, or a malicious moving object in the area of interest. with uniform sensor deployment, the detection probability is the same for any point in a wsn. however, some applications may require different degrees of detection probability at different locations. for example, an intrusion detection application may need improved detection probability around important entities. gaussian-distributed wsns can provide differentiated detection capabilities at different locations but related work is limited. this paper analyzes the problem of intrusion detection in a gaussian-distributed wsn by characterizing the detection probability with respect to the application requirements and the network parameters under both single-sensing detection and multiple-sensing detection scenarios. effects of different network parameters on the detection probability are examined in detail. furthermore, performance of gaussian-distributed wsns is compared with uniformly distributed wsns. this work allows us to analytically formulate detection probability in a random wsn and provides guidelines in selecting an appropriate deployment strategy and determining critical network parameters.",
            "contribution_ids": [
                "R203596"
            ]
        },
        {
            "instance_id": "R204005xR201735",
            "comparison_id": "R204005",
            "paper_id": "R201735",
            "text": "Frequent Detection of Noroviruses and Sapoviruses in Swine and High Genetic Diversity of Porcine Sapovirus in Japan during Fiscal Year 2008 abstract a molecular biological survey on porcine norovirus (nov) and sapovirus (sav) was conducted in toyama prefecture, japan, during fiscal year 2008. both nov and sav were detected from swine fecal samples throughout the surveillance period, indicating that these viruses were circulating in this region. nov strains detected in this study belonged to three genotypes that are known as typical swine novs. although human novs were occasionally detected, it was unclear whether they replicated in pigs. as for sav, genogroup vii (gvii) and other divergent genogroups were identified in addition to the dominant genogroup, giii, which is the prototypic porcine sav. in addition, 3 strains genetically related to human sav were detected. two of these 3 strains were closely related to human sav gv. our study showed that genetic diversification of porcine sav is currently progressing in the swine population.",
            "contribution_ids": [
                "R201737"
            ]
        },
        {
            "instance_id": "R204005xR201760",
            "comparison_id": "R204005",
            "paper_id": "R201760",
            "text": "Human Noroviruses in Swine and Cattle detection of gii.4 norovirus sequences in animal fecal samples and retail meats demonstrates that noroviruses may be transmitted zoonotically.",
            "contribution_ids": [
                "R201762",
                "R201764"
            ]
        },
        {
            "instance_id": "R204005xR201779",
            "comparison_id": "R204005",
            "paper_id": "R201779",
            "text": "Natural Norovirus Infections in Rhesus Macaques using a recently developed real-time reverse transcription pcr, i retested 500 fecal samples from rhesus macaques collected in 2008. previous conventional reverse transcription pcr testing identified 1 isolate of gii norovirus; retesting found gi, gii, and possible giv noroviruses in the samples, indicating the natural circulation of noroviruses in nonhuman primate colonies.",
            "contribution_ids": [
                "R201781"
            ]
        },
        {
            "instance_id": "R204005xR201975",
            "comparison_id": "R204005",
            "paper_id": "R201975",
            "text": "Complete Genome Sequence of a GII.17 Norovirus Isolated from a Rhesus Monkey in China abstract the previously silent gii.17 norovirus was found to be the predominant genotype causing major epidemics in china in the 2014\u20132015 winter epidemic season. we report here the complete genomic sequence of a gii.17 norovirus (mky/gii.17/km1509/chn/2015) that infected rhesus monkeys at a monkey farm in southwestern china.",
            "contribution_ids": [
                "R201977"
            ]
        },
        {
            "instance_id": "R204005xR203981",
            "comparison_id": "R204005",
            "paper_id": "R203981",
            "text": "Evidence for Human Norovirus Infection of Dogs in the United Kingdom abstract human noroviruses (hunovs) are a major cause of viral gastroenteritis, with an estimated 3 million cases per year in the united kingdom. hunovs have recently been isolated from pet dogs in europe (m. summa, c.-h. von bonsdorff, and l. maunula, j clin virol 53:244\u2013247, 2012, http://dx.doi.org/10.1016/j.jcv.2011.12.014 ), raising concerns about potential zoonotic infections. with 31% of united kingdom households owning a dog, this could prove to be an important transmission route. to examine this risk, canine tissues were studied for their ability to bind to hunov in vitro . in addition, canine stool samples were analyzed for the presence of viral nucleic acid, and canine serum samples were tested for the presence of anti-hunov antibodies. the results showed that seven different genotypes of hunov virus-like particles (vlps) can bind to canine gastrointestinal tissue, suggesting that infection is at least theoretically possible. although hunov rna was not identified in stool samples from 248 dogs, serological evidence of previous exposure to hunov was obtained in 43/325 canine serum samples. remarkably, canine seroprevalence for different hunov genotypes mirrored the seroprevalence in the human population. though entry and replication within cells have not been demonstrated, the canine serological data indicate that dogs produce an immune response to hunov, implying productive infection. in conclusion, this study reveals zoonotic implications for hunov, and to elucidate the significance of this finding, further epidemiological and molecular investigations will be essential.",
            "contribution_ids": [
                "R203984",
                "R203985"
            ]
        },
        {
            "instance_id": "R204080xR204018",
            "comparison_id": "R204080",
            "paper_id": "R204018",
            "text": "Cryptodl: Deep neural networks over encrypted data machine learning algorithms based on deep neural networks have achieved remarkable results and are being extensively used in different domains. however, the machine learning algorithms requires access to raw data which is often privacy sensitive. to address this issue, we develop new techniques to provide solutions for running deep neural networks over encrypted data. in this paper, we develop new techniques to adopt deep neural networks within the practical limitation of current homomorphic encryption schemes. more specifically, we focus on classification of the well-known convolutional neural networks (cnn). first, we design methods for approximation of the activation functions commonly used in cnns (i.e. relu, sigmoid, and tanh) with low degree polynomials which is essential for efficient homomorphic encryption schemes. then, we train convolutional neural networks with the approximation polynomials instead of original activation functions and analyze the performance of the models. finally, we implement convolutional neural networks over encrypted data and measure performance of the models. our experimental results validate the soundness of our approach with several convolutional neural networks with varying number of layers and structures. when applied to the mnist optical character recognition tasks, our approach achieves 99.52\\% accuracy which significantly outperforms the state-of-the-art solutions and is very close to the accuracy of the best non-private version, 99.77\\%. also, it can make close to 164000 predictions per hour. we also applied our approach to cifar-10, which is much more complex compared to mnist, and were able to achieve 91.5\\% accuracy with approximation polynomials used as activation functions. these results show that cryptodl provides efficient, accurate and scalable privacy-preserving predictions.",
            "contribution_ids": [
                "R204020"
            ]
        },
        {
            "instance_id": "R204080xR204022",
            "comparison_id": "R204080",
            "paper_id": "R204022",
            "text": "TAPAS: Tricks to accelerate (encrypted) prediction as a service machine learning methods are widely used for a variety of prediction problems. \\emph{prediction as a service} is a paradigm in which service providers with technological expertise and computational resources may perform predictions for clients. however, data privacy severely restricts the applicability of such services, unless measures to keep client data private (even from the service provider) are designed. equally important is to minimize the amount of computation and communication required between client and server. fully homomorphic encryption offers a possible way out, whereby clients may encrypt their data, and on which the server may perform arithmetic computations. the main drawback of using fully homomorphic encryption is the amount of time required to evaluate large machine learning models on encrypted data. we combine ideas from the machine learning literature, particularly work on binarization and sparsification of neural networks, together with algorithmic tools to speed-up and parallelize computation using encrypted data.",
            "contribution_ids": [
                "R204024"
            ]
        },
        {
            "instance_id": "R204080xR204030",
            "comparison_id": "R204080",
            "paper_id": "R204030",
            "text": "Secure outsourced matrix computation and application to neural networks homomorphic encryption (he) is a powerful cryptographic primitive to address privacy and security issues in outsourcing computation on sensitive data to an untrusted computation environment. comparing to secure multi-party computation (mpc), he has advantages in supporting non-interactive operations and saving on communication costs. however, it has not come up with an optimal solution for modern learning frameworks, partially due to a lack of efficient matrix computation mechanisms. in this work, we present a practical solution to encrypt a matrix homomorphically and perform arithmetic operations on encrypted matrices. our solution includes a novel matrix encoding method and an efficient evaluation strategy for basic matrix operations such as addition, multiplication, and transposition. we also explain how to encrypt more than one matrix in a single ciphertext, yielding better amortized performance. our solution is generic in the sense that it can be applied to most of the existing he schemes. it also achieves reasonable performance for practical use; for example, our implementation takes 9.21 seconds to multiply two encrypted square matrices of order 64 and 2.56 seconds to transpose a square matrix of order 64. our secure matrix computation mechanism has a wide applicability to our new framework edm, which stands for encrypted data and encrypted model. to the best of our knowledge, this is the first work that supports secure evaluation of the prediction phase based on both encrypted data and encrypted model, whereas previous work only supported applying a plain model to encrypted data. as a benchmark, we report an experimental result to classify handwritten images using convolutional neural networks (cnn). our implementation on the mnist dataset takes 28.59 seconds to compute ten likelihoods of 64 input images simultaneously, yielding an amortized rate of 0.45 seconds per image.",
            "contribution_ids": [
                "R204032"
            ]
        },
        {
            "instance_id": "R204080xR204076",
            "comparison_id": "R204080",
            "paper_id": "R204076",
            "text": "Cryptflow: Secure tensorflow inference we present cryptflow, a first of its kind system that converts tensorflow inference code into secure multi-party computation (mpc) protocols at the push of a button. to do this, we build three components. our first component, athos, is an end-to-end compiler from tensorflow to a variety of semihonest mpc protocols. the second component, porthos, is an improved semi-honest 3-party protocol that provides significant speedups for tensorflow like applications. finally, to provide malicious secure mpc protocols, our third component, aramis, is a novel technique that uses hardware with integrity guarantees to convert any semi-honest mpc protocol into an mpc protocol that provides malicious security. the malicious security of the protocols output by aramis relies on integrity of the hardware and semi-honest security of mpc. moreover, our system matches the inference accuracy of plaintext tensorflow.we experimentally demonstrate the power of our system by showing the secure inference of real-world neural networks such as resnet50 and densenet121 over the imagenet dataset with running times of about 30 seconds for semi-honest security and under two minutes for malicious security. prior work in the area of secure inference has been limited to semi-honest security of small networks over tiny datasets such as mnist or cifar. even on mnist/cifar, cryptflow outperforms prior work.",
            "contribution_ids": [
                "R204078"
            ]
        },
        {
            "instance_id": "R204130xR204088",
            "comparison_id": "R204130",
            "paper_id": "R204088",
            "text": "FlowRanger: A request prioritizing algorithm for controller DoS attacks in Software Defined Networks software defined networking (sdn) introduces a new communication network management paradigm and has gained much attention from academia and industry. however, the centralized nature of sdn is a potential vulnerability to the system since attackers may launch denial of services (dos) attacks against the controller. existing solutions limit requests rate to the controller by dropping overflowed requests, but they also drop legitimate requests to the controller. to address this problem, we propose flowranger, a buffer prioritizing solution for controllers to handle routing requests based on their likelihood to be attacking requests, which derives the trust values of the requesting sources. based on their trust values, flowranger classifies routing requests into multiple buffer queues with different priorities. thus, attacking requests are served with a lower priority than regular requests. our simulation results demonstrates that flowranger can significantly enhance the request serving rate of regular users under dos attacks against the controller. to the best of our knowledge, our work is the first solution to battle against controller dos attacks on the controller side.",
            "contribution_ids": [
                "R204090"
            ]
        },
        {
            "instance_id": "R204130xR204101",
            "comparison_id": "R204130",
            "paper_id": "R204101",
            "text": "Tolerating SDN application failures with LegoSDN despite software defined network's (sdn) proven benefits, there remains significant reluctance in adopting it. among the issues that hamper sdn's adoption two stand out: reliability and fault tolerance. at the heart of these issues is a set of fate-sharing relationships: the first between the sdn-apps and controllers, where-in the crash of the former induces a crash of the latter, and thereby affecting availability; and, the second between the sdn-app and the network, where-in a byzantine failure e.g., black-holes and network-loops, induces a failure in the network, and thereby affecting network availability. the principal position of this paper is that availability is of utmost concern -- second only to security. to this end, we present a re-design of the controller architecture centering around a set of abstractions to eliminate these fate-sharing relationships, and make the controllers and network resilient to sdn-app failures. we illustrate how these abstractions can be used to improve the reliability of an sdn environment, thus eliminating one of the barriers to sdn's adoption.",
            "contribution_ids": [
                "R204103"
            ]
        },
        {
            "instance_id": "R204130xR204120",
            "comparison_id": "R204130",
            "paper_id": "R204120",
            "text": "Study on authentication protocol of SDN trusted domain currently software define network (sdn) architecture has become a hot topic. aiming at the authentication security issues of sdn network architecture, we introduce an authentication protocol based on sdn network architecture without any trusted third party between trusted domains. by applying avispa security analysis system of network interaction protocol, we can guarantee protocol security and provide complete safety tests. our work fill the gap of mutual trust between different trusted domains and provide security foundation for interaction between different trusted domains.",
            "contribution_ids": [
                "R204122"
            ]
        },
        {
            "instance_id": "R204130xR204124",
            "comparison_id": "R204130",
            "paper_id": "R204124",
            "text": "A secure northbound interface for SDN applications software-defined networking (sdn) promises to introduce flexibility and programmability into networks by offering a northbound interface (nbi) for developers to create sdn applications. however, current designs and implementations have several drawbacks, including the lack of extended security features. in this paper, we present a secure northbound interface, through which an sdn controller can offer network resources, such as statistics, flow information or topology data, via a rest-like api to registered sdn applications. a trust manager ensures that only authenticated and trusted applications can utilize the interface. furthermore, a permission system allows for fine-grained authorization and access control to the aforementioned resources. we present a prototypical implementation of our interface and developed example applications using our interface, including an sdn management dashboard.",
            "contribution_ids": [
                "R204126"
            ]
        },
        {
            "instance_id": "R204209xR204174",
            "comparison_id": "R204209",
            "paper_id": "R204174",
            "text": "Enigma: Decentralized computation platform with guaranteed privacy a peer-to-peer network, enabling different parties to jointly store and run computations on data while keeping the data completely private. enigma's computational model is based on a highly optimized version of secure multi-party computation, guaranteed by a verifiable secret-sharing scheme. for storage, we use a modified distributed hashtable for holding secret-shared data. an external blockchain is utilized as the controller of the network, manages access control, identities and serves as a tamper-proof log of events. security deposits and fees incentivize operation, correctness and fairness of the system. similar to bitcoin, enigma removes the need for a trusted third party, enabling autonomous control of personal data. for the first time, users are able to share their data with cryptographic guarantees regarding their privacy.",
            "contribution_ids": [
                "R204176"
            ]
        },
        {
            "instance_id": "R204209xR204183",
            "comparison_id": "R204209",
            "paper_id": "R204183",
            "text": "Provchain: A blockchain-based data provenance architecture in cloud environment with enhanced privacy and availability cloud data provenance is metadata that records the history of the creation and operations performed on a cloud data object. secure data provenance is crucial for data accountability, forensics and privacy. in this paper, we propose a decentralized and trusted cloud data provenance architecture using blockchain technology. blockchain-based data provenance can provide tamper-proof records, enable the transparency of data accountability in the cloud, and help to enhance the privacy and availability of the provenance data. we make use of the cloud storage scenario and choose the cloud file as a data unit to detect user operations for collecting provenance data. we design and implement provchain, an architecture to collect and verify cloud data provenance, by embedding the provenance data into blockchain transactions. provchain operates mainly in three phases: (1) provenance data collection, (2) provenance data storage, and (3) provenance data validation. results from performance evaluation demonstrate that provchain provides security features including tamper-proof provenance, user privacy and reliability with low overhead for the cloud storage applications.",
            "contribution_ids": [
                "R204185"
            ]
        },
        {
            "instance_id": "R204209xR204207",
            "comparison_id": "R204209",
            "paper_id": "R204207",
            "text": "A blockchain-based framework for data sharing with fine-grained access control in decentralized storage systems in traditional cloud storage systems, attribute-based encryption (abe) is regarded as an important technology for solving the problem of data privacy and fine-grained access control. however, in all abe schemes, the private key generator has the ability to decrypt all data stored in the cloud server, which may bring serious problems such as key abuse and privacy data leakage. meanwhile, the traditional cloud storage model runs in a centralized storage manner, so single point of failure may leads to the collapse of system. with the development of blockchain technology, decentralized storage mode has entered the public view. the decentralized storage approach can solve the problem of single point of failure in traditional cloud storage systems and enjoy a number of advantages over centralized storage, such as low price and high throughput. in this paper, we study the data storage and sharing scheme for decentralized storage systems and propose a framework that combines the decentralized storage system interplanetary file system, the ethereum blockchain, and abe technology. in this framework, the data owner has the ability to distribute secret key for data users and encrypt shared data by specifying access policy, and the scheme achieves fine-grained access control over data. at the same time, based on smart contract on the ethereum blockchain, the keyword search function on the cipher text of the decentralized storage systems is implemented, which solves the problem that the cloud server may not return all of the results searched or return wrong results in the traditional cloud storage systems. finally, we simulated the scheme in the linux system and the ethereum official test network rinkeby, and the experimental results show that our scheme is feasible.",
            "contribution_ids": [
                "R204208"
            ]
        },
        {
            "instance_id": "R206187xR206100",
            "comparison_id": "R206187",
            "paper_id": "R206100",
            "text": "A multi-objective optimization model for sustainable supply chain network with using genetic algorithm purpose the purpose of this paper is to design and optimize economic and environmental dimensions in a sustainable supply chain (ssc) network. this paper developed a mixed-integer linear programing (milp) model to incorporate economical and environmental data for multi-objective optimization of the ssc network. design/methodology/approach the overall objective of the present study is to use high-quality raw materials, at the same time the lowest amount of pollution emission and the highest profitability is achieved. the model in the problem is solved using two algorithms, namely, multi-objective genetic and multi-objective particle swarm. in this research, to integrate sustainable supplier selection and optimization of sustainability performance indicators in supply chain network design considering minimization of cost and time and maximization of sustainability indexes of the system. findings the differences found between the genetic algorithms (gas) and the milp approaches can be explained by handling the constraints and their various logics. the solutions are contrasted with the original crisp model based on either milp or ga, offering more robustness to the proposed approach. practical implications the model is applied to mega motor company to optimize the sustainability performance of the supply chain i.e. economic (cost), social (time) and environmental (pollution of raw material). the research method has two approaches, namely, applied and mathematical modeling. originality/value there is limited research designing and optimizing the ssc network. this study is among the first to integrate sustainable supplier selection and optimization of sustainability performance indicators in supply chain network design considering minimization of cost and time and maximization of sustainability indexes of the system.",
            "contribution_ids": [
                "R206103"
            ]
        },
        {
            "instance_id": "R206309xR206216",
            "comparison_id": "R206309",
            "paper_id": "R206216",
            "text": "Ambulatory Position and Orientation Tracking Fusing Magnetic and Inertial Sensing this paper presents the design and testing of a portable magnetic system combined with miniature inertial sensors for ambulatory 6 degrees of freedom ( dof) human motion tracking. the magnetic system consists of three orthogonal coils, the source, fixed to the body and 3-d magnetic sensors, fixed to remote body segments, which measure the fields generated by the source. based on the measured signals, a processor calculates the relative positions and orientations between source and sensor. magnetic actuation requires a substantial amount of energy which limits the update rate with a set of batteries. moreover, the magnetic field can easily be disturbed by ferromagnetic materials or other sources. inertial sensors can be sampled at high rates, require only little energy and do not suffer from magnetic interferences. however, accelerometers and gyroscopes can only measure changes in position and orientation and suffer from integration drift. by combing measurements from both systems in a complementary kalman filter structure, an optimal solution for position and orientation estimates is obtained. the magnetic system provides 6 dof measurements at a relatively low update rate while the inertial sensors track the changes position and orientation in between the magnetic updates. the implemented system is tested against a lab-bound camera tracking system for several functional body movements. the accuracy was about 5 mm for position and 3 degrees for orientation measurements. errors were higher during movements with high velocities due to relative movement between source and sensor within one cycle of magnetic actuation",
            "contribution_ids": [
                "R206218"
            ]
        },
        {
            "instance_id": "R206309xR206222",
            "comparison_id": "R206309",
            "paper_id": "R206222",
            "text": "Reducing Drifts in the Inertial Measurements of Wrist and Elbow Positions in this paper, we present an inertial-sensor-based monitoring system for measuring the movement of human upper limbs. two wearable inertial sensors are placed near the wrist and elbow joints, respectively. the measurement drift in segment orientation is dramatically reduced after a kalman filter is applied to estimate inclinations using accelerations and turning rates from gyroscopes. using premeasured lengths of the upper and lower arms, we compute the position of the wrist and elbow joints via a proposed kinematic model. experimental results demonstrate that this new motion capture system, in comparison to an optical motion tracker, possesses an rms position error of less than 0.009 m, with a drift of less than 0.005 ms-1 in five daily activities. in addition, the rms angle error is less than 3\u00b0. this indicates that the proposed approach has performed well in terms of accuracy and reliability.",
            "contribution_ids": [
                "R206224"
            ]
        },
        {
            "instance_id": "R207120xR206262",
            "comparison_id": "R207120",
            "paper_id": "R206262",
            "text": "A Deep Learning Framework for Detection of COVID-19 Fake News on Social Media Platforms the fast growth of technology in online communication and social media platforms alleviated numerous difficulties during the covid-19 epidemic. however, it was utilized to propagate falsehoods and misleading information about the disease and the vaccination. in this study, we investigate the ability of deep neural networks, namely, long short-term memory (lstm), bi-directional lstm, convolutional neural network (cnn), and a hybrid of cnn and lstm networks, to automatically classify and identify fake news content related to the covid-19 pandemic posted on social media platforms. these deep neural networks have been trained and tested using the \u201ccovid-19 fake news\u201d dataset, which contains 21,379 real and fake news instances for the covid-19 pandemic and its vaccines. the real news data were collected from independent and internationally reliable institutions on the web, such as the world health organization (who), the international committee of the red cross (icrc), the united nations (un), the united nations children\u2019s fund (unicef), and their official accounts on twitter. the fake news data were collected from different fact-checking websites (such as snopes, politifact, and factcheck). the evaluation results showed that the cnn model outperforms the other deep neural networks with the best accuracy of 94.2%.",
            "contribution_ids": [
                "R206265"
            ]
        },
        {
            "instance_id": "R207120xR206370",
            "comparison_id": "R207120",
            "paper_id": "R206370",
            "text": "FANG: Leveraging Social Context for Fake News Detection Using Graph Representation we propose factual news graph (fang), a novel graphical social context representation and learning framework for fake news detection. unlike previous contextual models that have targeted performance, our focus is on representation learning. compared to transductive models, fang is scalable in training as it does not have to maintain all nodes, and it is efficient at inference time, without the need to re-process the entire graph. our experimental results show that fang is better at capturing the social context into a high fidelity representation, compared to recent graphical and non-graphical models. in particular, fang yields significant improvements for the task of fake news detection, and it is robust in the case of limited training data. we further demonstrate that the representations learned by fang generalize to related tasks, such as predicting the factuality of reporting of a news medium.",
            "contribution_ids": [
                "R206372"
            ]
        },
        {
            "instance_id": "R207120xR207084",
            "comparison_id": "R207120",
            "paper_id": "R207084",
            "text": "exBAKE: Automatic Fake News Detection Model Based on Bidirectional Encoder Representations from Transformers (BERT) news currently spreads rapidly through the internet. because fake news stories are designed to attract readers, they tend to spread faster. for most readers, detecting fake news can be challenging and such readers usually end up believing that the fake news story is fact. because fake news can be socially problematic, a model that automatically detects such fake news is required. in this paper, we focus on data-driven automatic fake news detection methods. we first apply the bidirectional encoder representations from transformers model (bert) model to detect fake news by analyzing the relationship between the headline and the body text of news. to further improve performance, additional news data are gathered and used to pre-train this model. we determine that the deep-contextualizing nature of bert is best suited for this task and improves the 0.14 f-score over older state-of-the-art models.",
            "contribution_ids": [
                "R207086"
            ]
        },
        {
            "instance_id": "R209290xR209021",
            "comparison_id": "R209290",
            "paper_id": "R209021",
            "text": "A large-scale benchmark dataset for event recognition in surveillance video we introduce a new large-scale video dataset designed to assess the performance of diverse visual event recognition algorithms with a focus on continuous visual event recognition (cver) in outdoor areas with wide coverage. previous datasets for action recognition are unrealistic for real-world surveillance because they consist of short clips showing one action by one individual [15, 8]. datasets have been developed for movies [11] and sports [12], but, these actions and scene conditions do not apply effectively to surveillance videos. our dataset consists of many outdoor scenes with actions occurring naturally by non-actors in continuously captured videos of the real world. the dataset includes large numbers of instances for 23 event types distributed throughout 29 hours of video. this data is accompanied by detailed annotations which include both moving object tracks and event examples, which will provide solid basis for large-scale evaluation. additionally, we propose different types of evaluation modes for visual recognition tasks and evaluation metrics along with our preliminary experimental results. we believe that this dataset will stimulate diverse aspects of computer vision research and help us to advance the cver tasks in the years ahead.",
            "contribution_ids": [
                "R209023"
            ]
        },
        {
            "instance_id": "R209290xR209045",
            "comparison_id": "R209290",
            "paper_id": "R209045",
            "text": "The highD Dataset: A Drone Dataset of Naturalistic Vehicle Trajectories on German Highways for Validation of Highly Automated Driving Systems scenario-based testing for the safety validation of highly automated vehicles is a promising approach that is being examined in research and industry. this approach heavily relies on data from real-world scenarios to derive the necessary scenario information for testing. measurement data should be collected at a reasonable effort, contain naturalistic behavior of road users and include all data relevant for a description of the identified scenarios in sufficient quality. however, the current measurement methods fail to meet at least one of the requirements. thus, we propose a novel method to measure data from an aerial perspective for scenario-based validation fulfilling the mentioned requirements. furthermore, we provide a large-scale naturalistic vehicle trajectory dataset from german highways called highd. we evaluate the data in terms of quantity, variety and contained scenarios. our dataset consists of 16.5 hours of measurements from six locations with 110 000 vehicles, a total driven distance of 45 000 km and 5600 recorded complete lane changes. the highd dataset is available online at: http://www.highd-dataset.com",
            "contribution_ids": [
                "R209047"
            ]
        },
        {
            "instance_id": "R209290xR209042",
            "comparison_id": "R209290",
            "paper_id": "R209042",
            "text": "An Evaluation of Trajectory Prediction Approaches and Notes on the TrajNet Benchmark in recent years, there is a shift from modeling the tracking problem based on bayesian formulation towards using deep neural networks. towards this end, in this paper the effectiveness of various deep neural networks for predicting future pedestrian paths are evaluated. the analyzed deep networks solely rely, like in the traditional approaches, on observed tracklets without human-human interaction information. the evaluation is done on the publicly available trajnet benchmark dataset, which builds up a repository of considerable and popular datasets for trajectory-based activity forecasting. we show that a recurrent-encoder with a dense layer stacked on top, referred to as red-predictor, is able to achieve sophisticated results compared to elaborated models in such scenarios. further, we investigate failure cases and give explanations for observed phenomena and give some recommendations for overcoming demonstrated shortcomings.",
            "contribution_ids": [
                "R209044"
            ]
        },
        {
            "instance_id": "R209290xR209016",
            "comparison_id": "R209290",
            "paper_id": "R209016",
            "text": "Statistical models of pedestrian behaviour in the Forum this dissertation describes an msc project for which the purpose was to develop a system that could be used for automated surveillance. the main novelty is the use of a vertical camera. the project investigates whether such a system can effectively detect moving objects, track their trajectories, and use these to recognise anomalous events.",
            "contribution_ids": [
                "R209017"
            ]
        },
        {
            "instance_id": "R210471xR203395",
            "comparison_id": "R210471",
            "paper_id": "R203395",
            "text": "Use of Synergistic Interactions to Fabricate Strong, Tough, and Conductive Artificial Nacre Based on Graphene Oxide and Chitosan graphene is the strongest and stiffest material, leading to the development of promising applications in many fields. however, the assembly of graphene nanosheets into macrosized nanocomposites for practical applications remains a challenge. nacre in its natural form sets the \"gold standard\" for toughness and strength, which serves as a guide to the assembly of graphene nanosheets into high-performance nanocomposites. here we show the strong, tough, conductive artificial nacre based on graphene oxide through synergistic interactions of hydrogen and covalent bonding. tensile strength and toughness was 4 and 10 times higher, respectively, than that of natural nacre. the exceptional integrated strong and tough artificial nacre has promising applications in aerospace, artificial muscle, and tissue engineering, especially for flexible supercapacitor electrodes due to its high electrical conductivity. the use of synergistic interactions is a strategy for the development of high-performance nanocomposites.",
            "contribution_ids": [
                "R203396"
            ]
        },
        {
            "instance_id": "R210471xR203397",
            "comparison_id": "R210471",
            "paper_id": "R203397",
            "text": "Superior Fatigue Resistant Bioinspired Graphene-Based Nanocomposite via Synergistic Interfacial Interactions excellent fatigue resistance is a prerequisite for flexible energy devices to achieve high and stable performance under repeated deformation state. inspired by the sophisticated interfacial architecture of nacre, herein a super fatigue\u2010resistant graphene\u2010based nanocomposite with integrated high tensile strength and toughness through poly(dopamine)\u2010nickel ion (ni2+) chelate architecture that mimics byssal threads is demonstrated. these kind of synergistic interfacial interactions of covalent and ionic bonding effectively suppress the crack propagation in the process of fatigue testing, resulting in superhigh fatigue life of this bioinspired graphene\u2010based nanocomposite (bgbn). in addition, the electrical conductivity is well kept after fatigue testing. the proposed synergistic interfacial interactions could serve as a guideline for fabricating high\u2010performance multifunctional bgbns with promising applications in flexible energy devices, such as flexible electrodes for supercapacitors and lithium batteries, etc.",
            "contribution_ids": [
                "R203399"
            ]
        },
        {
            "instance_id": "R211056xR207034",
            "comparison_id": "R211056",
            "paper_id": "R207034",
            "text": "Postmortem examination of COVID\u00e2\u0080\u009019 patients reveals diffuse alveolar damage with severe capillary congestion and variegated findings in lungs and other organs suggesting vascular dysfunction coronavirus disease 2019 (covid\u201019), caused by severe acute respiratory syndrome coronavirus 2 (sars\u2010cov\u20102), has rapidly evolved into a sweeping pandemic. its major manifestation is in the respiratory tract, and the general extent of organ involvement and the microscopic changes in the lungs remain insufficiently characterised. autopsies are essential to elucidate covid\u201019\u2010associated organ alterations.",
            "contribution_ids": [
                "R207038",
                "R209149"
            ]
        },
        {
            "instance_id": "R211056xR209082",
            "comparison_id": "R211056",
            "paper_id": "R209082",
            "text": "Multiorgan and Renal Tropism of SARS-CoV-2 multiorgan and renal tropism of sars-cov-2 in this autopsy series, the authors found that sars-cov-2 has an organotropism beyond the respiratory tract, including the kidneys, heart, liver, and brai...",
            "contribution_ids": [
                "R209086",
                "R209126",
                "R209127",
                "R209128",
                "R209129"
            ]
        },
        {
            "instance_id": "R211056xR209253",
            "comparison_id": "R211056",
            "paper_id": "R209253",
            "text": "Ultrastructural examination of lung \u00e2\u0080\u009ccryobiopsies\u00e2\u0080\u009d from a series of fatal COVID-19 cases hardly revealed infected cells abstract ultrastructural analysis of autopsy samples from covid-19 patients usually suffers from significant structural impairment possibly caused by the rather long latency between death of the patient and an appropriate sample fixation. to improve structural preservation of the tissue, we obtained samples from ventilated patients using a trans-bronchial \u201ccryobiopsy\u201d within 30 min after their death and fixed them immediately for electron microscopy. samples of six covid-19 patients with a documented histopathology were systematically investigated by thin section electron microscopy. the different samples and areas inspected revealed the ultrastructural correlates of the different phases of diffuse alveolar damage, including detachment of the alveolar epithelium, hyperplasia of type 2 cells, exudates, and accumulation of extracellular material, such as the hyaline membranes and fibrin. macrophages and neutrophilic granulocytes were regularly detected. structural integrity of endothelium was intact in regions where the alveolar epithelium was already detached. aggregates of erythrocytes, leukocytes with fibrin, and thrombocytes were not observed. coronavirus particles were only found in and around very few cells in one of the six patient samples. the type and origin of these cells could not be assessed although the overall structural preservation of the samples allowed the identification of pulmonary cell types. hence, the observed alveolar damage is not associated with virus presence or structural impairment due to ongoing replication at later stages of the disease in fatal cases, which implies that the lung damage in these patients is at least propagated by alternative mechanisms, perhaps, an inappropriate immune or stress response.",
            "contribution_ids": [
                "R209256"
            ]
        },
        {
            "instance_id": "R211935xR193044",
            "comparison_id": "R211935",
            "paper_id": "R193044",
            "text": "From Ideas to Expressed Needs: an Empirical Study on the Evolution of Requirements during Elicitation requirements are elicited from the customer and other stakeholders through an iterative process of interviews, prototyping, and other interactive sessions. many communication phenomena may emerge in these early iterations, that lead initial ideas to be transformed, renegotiated, or reframed. understanding how this process takes place can help in solving possible communication issues as well as their consequences. in this work, we perform an exploratory study of descriptive nature to understand in which way requirements get transformed from initial ideas into documented needs. to this end, we select 30 subjects that act as requirements analysts, and we perform a set of elicitation sessions with a fictional customer. the customer is required to study a sample requirements document for a system beforehand and to answer the questions of the analysts about the system. after the elicitation sessions, the analysts produce user stories for the system. these are compared with the original ones by two researchers to assess to which extent and in which way the initial requirements evolved throughout the interactive sessions. our results show that between 30% and 38% of the produced user stories include content that can be fully traced to the initial ones, while the rest of the content is dedicated to new requirements. we also show what types of requirements are introduced through the elicitation process, and how they vary depending on the analyst. our work contributes to theory in requirements engineering, with empirically grounded, quantitative data, concerning the impact of elicitation activities with respect to initial ideas.",
            "contribution_ids": [
                "R193046"
            ]
        },
        {
            "instance_id": "R211935xR193089",
            "comparison_id": "R211935",
            "paper_id": "R193089",
            "text": "On the Role of User Feedback in Software Evolution: a Practitioners\u00e2\u0080\u0099 Perspective user feedback is indispensable in software evolution. previous work has proposed ways for automatically extracting requirements, bug reports and other valuable information from feedback. however, little is actually known about how user feedback\u2014 especially the one available through newer channels, such as social media\u2014is incorporated in development processes. to date, only a few case studies discuss the matter and the results are not always consistent. we carried out a mixed methods study to understand the current state of practice of harnessing user feedback in software development. qualitatively, we performed interviews with 18 software practitioners to get a deeper understanding of the role of user feedback in software evolution. quantitatively, we surveyed 101 software practitioners to cross-validate the interview findings and improve the generalizability of the results. we found that feedback is captured to (1) identify bugs, features and usability issues, (2) get a better understanding of the user, and (3) prioritize requirements. our results indicate that analyzing feedback is time-consuming and has a number of challenges. among them, feedback is typically analyzed manually and is spread over a wide range of channels and company departments. our findings stress the current importance for cross-department cooperation and call for the exploration of tools that can centralize user feedback.",
            "contribution_ids": [
                "R193091"
            ]
        },
        {
            "instance_id": "R211935xR193308",
            "comparison_id": "R211935",
            "paper_id": "R193308",
            "text": "The Role of Linguistic Relativity on the Identification of Sustainability Requirements: An Empirical Study linguistic-relativity-theory states that language and its structure influence people\u2019s world view and cognition. we investigate how this theory impacts the identification of requirements in practice. to this end, we conducted two controlled experiments with 101 participants. we randomly showed participants a set of requirements dimensions (i.e. a language structure) either with a focus on software quality or on sustainability and asked them to identify the requirements for a grocery shopping app according to these dimensions. participants of the control group were not given any dimensions. the results show that the use of requirements dimensions significantly increases the number of identified requirements in comparison to the control group. furthermore, participants who were given the sustainability dimensions identified more sustainability requirements. in follow up interviews with 16 practitioners, the interviewees reported benefits of the dimensions such as a holistic guidance but were also concerned about the customers acceptance. furthermore, they stated challenges of implementing sustainability dimensions in the daily business but also suggested solutions like establishing sustainability as a common standard. our study indicates that carefully structuring requirements engineering along sustainability dimensions can guide development teams towards considering and ensuring software sustainability.",
            "contribution_ids": [
                "R193309"
            ]
        },
        {
            "instance_id": "R211935xR193357",
            "comparison_id": "R211935",
            "paper_id": "R193357",
            "text": "What\u00e2\u0080\u0099s up with Requirements Engineering for Artificial Intelligence Systems? in traditional approaches to building software systems (that do not include an artificial intelligent (ai) or machine learning (ml) component), requirements engineering (re) activities are well-established and researched. however, building software systems with one or more ai components may depend heavily on data with limited or no insight into the system\u2019s workings. therefore, engineering such systems poses significant new challenges to re. our search showed that literature has focused on using ai to manage re activities, with limited research on re for ai (re4ai). our study\u2019s main objective was to investigate current approaches in writing requirements for ai/ml systems, identify available tools and techniques used to model requirements, and find existing challenges and limitations. we performed a systematic literature review (slr) of current re4ai methods and identified 27 primary studies. using these studies, we analysed the key tools and techniques used to specify and model requirements and found several challenges and limitations of existing re4ai practices. we further provide recommendations for future research, based on our analysis of the primary studies and mapping to industry guidelines in google pair). the slr findings highlighted that present re applications were not adaptive to manage most ai/ml systems and emphasised the need to provide new techniques and tools to support re4ai.",
            "contribution_ids": [
                "R193358"
            ]
        },
        {
            "instance_id": "R211935xR193828",
            "comparison_id": "R211935",
            "paper_id": "R193828",
            "text": "Mining reddit as a new source for software requirements mining app stores and social media has proven to be a good source for collecting user feedback to foster requirements engineering and software evolution. recent literature on mining software-related data from social platforms, such as twitter and facebook, shows that it complements app store mining. however, there are many other platforms where users discuss and provide feedback on software applications that are not thoroughly researched and analysed. one of such platforms is reddit. in this paper, we introduce reddit as a new potential data source and explore if and how requirements engineering and software evolution can benefit from obtaining user feedback from reddit. we also present an exploratory study in which we analysed the usage characteristics (i.e., frequency of posts, number of comments, and number of users for each subreddit) of reddit posts about software applications. furthermore, we examined the content of the posts and the results reveal that almost 54% of posts contain useful information. finally, we investigated the potential of automatic classification and applied machine learning algorithms to unstructured and noisy reddit data to perform automated classification into the categories of bug reports, feature related, and irrelevant. we found that the support vector machine algorithm with the f1-score of 84% can be effective in categorizing reddit posts. our results show that reddit posts provide useful feedback on software applications that can foster requirements engineering and software evolution.",
            "contribution_ids": [
                "R193829"
            ]
        },
        {
            "instance_id": "R211935xR193849",
            "comparison_id": "R211935",
            "paper_id": "R193849",
            "text": "TEM: a transparency engineering methodology enabling users\u00e2\u0080\u0099 trust judgement transparency is key to enhancing users\u2019 trust by enabling their judgment on the outcomes and consequences of a system\u2019s operations. this paper presents the transparency engineering methodology (tem) to generate transparency requirements that enable users\u2019 trust judgement. the idea is to identify where transparency is lacking and to address this through patterns augmenting the specification of data, use case, and process requirements. due to the complexity of software, it is impossible (and undesirable) to achieve full transparency throughout the system. however, transparency can be improved for selected system aspects. this is demonstrated using the results from an industrial case study with a medical technology company where, with the help of tem, existing functional requirements were refined, and transparency requirements generated systematically.",
            "contribution_ids": [
                "R193850"
            ]
        },
        {
            "instance_id": "R211935xR193866",
            "comparison_id": "R211935",
            "paper_id": "R193866",
            "text": "The Rise and Fall of COVID-19 Contact-Tracing Apps: when NFRs Collide with Pandemic to complement the manual contact-tracing methods, a flood of coronavirus-related apps was launched in the first half of 2020. despite the incredible promises made by the governments, contact-tracing apps did not live up to expectations. we provide a contextual perspective of the government commissioned contact-tracing apps from four countries to understand the non-functional requirements (nfrs) and socio-technical factors that hindered the success of these apps. we collected the user reviews from the app stores for ios and android versions and identified top news articles related to each app. our analysis revealed that the dominant factors behind the negligible success of these apps are complex and entangled with the cultural and political dimensions rather than being just technical. the multilayer diversity of the target users also impacted the design and development of contact-tracing apps in an extremely challenging situation. this perspective paper brings into light important elements, such as politics and socio-cultural aspects that should be studied in the design of contact-tracing apps, and public apps in general.",
            "contribution_ids": [
                "R193868"
            ]
        },
        {
            "instance_id": "R212902xR209382",
            "comparison_id": "R212902",
            "paper_id": "R209382",
            "text": "ThinkHome: A smart home as digital ecosystem smart homes have become increasingly popular in the past few years. similarly, new buildings are nowadays planned and built following sustainability guidelines. energy efficient residential homes have gained importance for two reasons. they contribute to the protection of our environment and they simultaneously reduce operational costs over the whole building lifecycle. however, the full potential of smart homes still lies fallow due to the high complexity of the underlying automation systems as well as the physical processes that are to be controlled. this is the motivation to review smart homes under a digital ecosystem perspective. with respect to this viewpoint, this paper proposes a system concept that applies artificial intelligence in smart homes. main goals are to minimize energy consumption while at the same time guaranteeing user comfort. therefore, intelligent control strategies are developed that take a multitude of parameters into consideration and operate automatically. for this purpose, an agent part populated by a society of autonomous agents that implement artificial intelligence is developed. it is supported by an ontology based knowledge representation that contains all relevant data in a structured way.",
            "contribution_ids": [
                "R209384"
            ]
        },
        {
            "instance_id": "R212902xR209385",
            "comparison_id": "R212902",
            "paper_id": "R209385",
            "text": "A Unified Semantic Ontology for Energy Management Applications current research evidences an increase of use of semantic web technologies within city energy management solutions. different ontologies have been developed in order to improve energy data interoperability. however, these ontologies represent different energy domains, with different level of detail and using different terminology. this heterogeneity leads to an interoperability problem that hinders the full adoption of these ontologies in real scenarios. this paper presents the oema (ontology for energy management applications) ontology network. this ontology is an attempt to unify existing heterogeneous ontologies that represent energy performance and contextual data. the paper describes the oema ontology network development process, which has included ontology reuse, ontology engineering and ontology integration activities. the paper also describes the main oema ontology network modules.",
            "contribution_ids": [
                "R209387"
            ]
        },
        {
            "instance_id": "R213443xR190039",
            "comparison_id": "R213443",
            "paper_id": "R190039",
            "text": "JOTR: Join-Optimistic Triple Reordering Approach for SPARQL Query Optimization on Big RDF Data resource description framework (rdf) is increasingly being used for representing information on the web. this popularity has made storage of large rdf data a difficult task. to overcome these issues many distributed rdf systems are being proposed that can store and efficiently process big rdf data. hadoop framework is widely being used for storing and handling a large amount of rdf data. one of the major obstacles faced while handling this large amount of rdf data is query processing on such large datasets. in this paper, we present jotr: a sparql query optimization technique for big rdf data using triple pattern reordering on a distributed hadoop based rdf system. the proposed technique is based on selectivity calculation and has been tested on one of the popular rdf benchmark datasets, lubm dataset. we have tested jotr on large sized rdf datasets and compared it with other optimization approaches in respect to the query execution time. from the results, it can be concluded that our approach gives a notable performance on distributed rdf systems and thus is applicable to centralized systems as well.",
            "contribution_ids": [
                "R191323",
                "R191332",
                "R191335",
                "R191338",
                "R191348",
                "R200115",
                "R200125",
                "R202133",
                "R202136",
                "R202138"
            ]
        },
        {
            "instance_id": "R25093xR25066",
            "comparison_id": "R25093",
            "paper_id": "R25066",
            "text": "Predicting Personality from Twitter \"social media is a place where users present themselves to the world, revealing personal details and insights into their lives. we are beginning to understand how some of this information can be utilized to improve the users' experiences with interfaces and with one another. in this paper, we are interested in the personality of users. personality has been shown to be relevant to many types of interactions, it has been shown to be useful in predicting job satisfaction, professional and romantic relationship success, and even preference for different interfaces. until now, to accurately gauge users' personalities, they needed to take a personality test. this made it impractical to use personality analysis in many social media domains. in this paper, we present a method by which a user's personality can be accurately predicted through the publicly available information on their twitter profile. we will describe the type of data collected, our methods of analysis, and the machine learning techniques that allow us to successfully predict personality. we then discuss the implications this has for social media design, interface design, and broader domains.\"",
            "contribution_ids": [
                "R25067",
                "R25072"
            ]
        },
        {
            "instance_id": "R25093xR25068",
            "comparison_id": "R25093",
            "paper_id": "R25068",
            "text": "Our Twitter Profiles, Our Selves: Predicting Personality with Twitter \"psychological personality has been shown to affect a variety of aspects: preferences for interaction styles in the digital world and for music genres, for example. consequently, the design of personalized user interfaces and music recommender systems might benefit from understanding the relationship between personality and use of social media. since there has not been a study between personality and use of twitter at large, we set out to analyze the relationship between personality and different types of twitter users, including popular users and influentials. for 335 users, we gather personality data, analyze it, and find that both popular users and influentials are extroverts and emotionally stable (low in the trait of neuroticism). interestingly, we also find that popular users are `imaginative' (high in openness), while influentials tend to be `organized' (high in conscientiousness). we then show a way of accurately predicting a user's personality simply based on three counts publicly available on profiles: following, followers, and listed counts. knowing these three quantities about an active user, one can predict the user's five personality traits with a root-mean-squared error below 0.88 on a $[1,5]$ scale. based on these promising results, we argue that being able to predict user personality goes well beyond our initial goal of informing the design of new personalized applications as it, for example, expands current studies on privacy in social media.\"",
            "contribution_ids": [
                "R25069"
            ]
        },
        {
            "instance_id": "R25093xR25083",
            "comparison_id": "R25093",
            "paper_id": "R25083",
            "text": "Evaluating Content-Independent Features for Personality Recognition this paper describes our submission for the wcpr14 shared task on computational personality recognition. we have investigated whether the features proposed by soler and wanner (2014) for gender prediction might also be useful in personality recognition. we have compared these features with simple approaches using token unigrams, character trigrams and liwc features. although the newly investigated features seem to work quite well on certain personality traits, they do not outperform the simple approaches.",
            "contribution_ids": [
                "R25084"
            ]
        },
        {
            "instance_id": "R25093xR25085",
            "comparison_id": "R25093",
            "paper_id": "R25085",
            "text": "Recognising personality traits using facebook status updates \"gaining insight in a web user's personality is very valuable for applications that rely on personalisation, such as recommender systems and personalised advertising. in this paper we explore the use of machine learning techniques for inferring a user's personality traits from their facebook status updates. even with a small set of training examples we can outperform the majority class baseline algorithm. furthermore, the results are improved by adding training examples from another source. this is an interesting result because it indicates that personality trait recognition generalises across social media platforms.\"",
            "contribution_ids": [
                "R25086"
            ]
        },
        {
            "instance_id": "R25115xR25107",
            "comparison_id": "R25115",
            "paper_id": "R25107",
            "text": "Participants' view on personal gains and PD process \"while it is commonly claimed that users of participatory design projects reap benefits from their participation, little research exists that shows if this truly occurs in the real world. in this paper, we introduce the method and results of assessing the participants' perception of their personal benefits and the degree of participation in a large project in the healthcare field. our research shows that a well-executed participatory design project can produce most of the benefits hypothesized in the literature but also highlights the challenges of assessing individual benefits and the pd process.\"",
            "contribution_ids": [
                "R25108"
            ]
        },
        {
            "instance_id": "R25115xR25111",
            "comparison_id": "R25115",
            "paper_id": "R25111",
            "text": "How much participation is enough? \"this paper considers the relationship between depth of participation (i.e., the effort and resources invested in participation) versus (tangible) outcomes. the discussion is based on experiences from six participatory research projects of different sizes and durations all taking place within a two year period and all aiming to develop new digital technologies to address an identified social need. the paper asks the fundamental question: how much participation is enough? that is, it challenges the notion that more participation is necessarily better, and, by using the experience of these six projects, it asks whether a more light touch or 'lean' participatory process can still achieve good outcomes, but at reduced cost. the paper concludes that participatory design researchers could consider 'agile' principles from the software development field as one way to streamline participatory processes.\"",
            "contribution_ids": [
                "R25112"
            ]
        },
        {
            "instance_id": "R25160xR25124",
            "comparison_id": "R25160",
            "paper_id": "R25124",
            "text": "\"Should I stay or should I go?\" \"ambient lighting systems have been introduced by several manufacturers to increase the driver's comfort. also, some works proposed warning systems based on light displays. expanding on those works, we are searching for designs of lumicons (i.e. light patterns) that can not only warn drivers in critical situations but also keep them informed in a non-distracting way. we present first ideas for lumicons for a given scenario coming from a participatory design process.\"",
            "contribution_ids": [
                "R25125"
            ]
        },
        {
            "instance_id": "R25160xR25129",
            "comparison_id": "R25160",
            "paper_id": "R25129",
            "text": "A New Driving Assistant for Automobiles this paper introduces an inexpensive car security system which addresses the needs for broader area coverage around the vehicle and stronger indication signals to drivers. the new driving assistant features simple ultrasonic-based sensors, implemented at the two front corners and the two blind spots of the vehicle. in order to report the close-by objects to the driver, the system employs a multitude of feedback devices, including tactile vibrators attached to the steering wheel, audible signals, and an led display mounted on the dash board. the sensor system and the feedback devices are controlled in real-time by microcontrollers over a wireless communication network the final prototype system was installed and tested on a ride-on toy car.",
            "contribution_ids": [
                "R25130"
            ]
        },
        {
            "instance_id": "R25160xR25131",
            "comparison_id": "R25160",
            "paper_id": "R25131",
            "text": "Evaluation of Six Night Vision Enhancement Systems: Qualitative and Quantitative Support for Intelligent Image Processing objective: an evaluation study was conducted to answer the question of which system properties of night vision enhancement systems (nvess) provide a benefit for drivers without increasing their workload. background: different infrared sensor, image processing, and display technologies can be integrated into an nves to support nighttime driving. because each of these components has its specific strengths and weaknesses, careful testing is required to determine their best combination. method: six prototypical systems were assessed in two steps. first, a heuristic evaluation with experts from ergonomics, perception, and traffic psychology was conducted. it produced a broad overview of possible effects of system properties on driving. based on these results, an experimental field study with 15 experienced drivers was performed. criteria used to evaluate the development potential of the six prototypes were the usability dimensions of effectiveness, efficiency, and user satisfaction (international organization for standardization, 1998). results: results showed that the intelligibility of information, the easiness with which obstacles could be located in the environment, and the position of the display presenting the output of the system were of crucial importance for the usability of the nves and its acceptance. conclusion: all relevant requirements are met best by nvess that are positioned at an unobtrusive location and are equipped with functions for the automatic identification of objects and for event-based warnings. application: these design recommendations and the presented approach to evaluate the systems can be directly incorporated into the development process of future nvess.",
            "contribution_ids": [
                "R25132"
            ]
        },
        {
            "instance_id": "R25160xR25144",
            "comparison_id": "R25160",
            "paper_id": "R25144",
            "text": "GPS enabled speed control embedded system speed limiting device with display and engine control interface \"in the past decade, there have been close to 350,000 fatal crashes in the united states [1]. with various improvements in traffic and vehicle safety, the number of such crashes is decreasing every year. one of the ways to reduce vehicle crashes is to prevent excessive speeding in the roads and highways. the paper aims to outline the design of an embedded system that will automatically control the speed of a motor vehicle based on its location determined by a gps device. the embedded system will make use of an avr atmega128 microcontroller connected to an em-406a gps receiver. the large amount of location input data justifies the use of an atmega128 microcontroller which has 128kb of programmable flash memory as well as 4kb sram, and a 4kb eeprom memory [2]. the output of the atmega128 will be a dogmi63w-a lcd module which will display information of the current and the set-point speed of the vehicle at the current position. a discrete indicator led will flash at a pre-determined frequency when the speed of the vehicle has exceeded the recommended speed limit. finally, the system will have outputs that will communicate with the engine control unit (ecu) of the vehicle. for the limited scope of this project, the ecu is simulated as an external device with two inputs that will acknowledge pulse-trains of particular frequencies to limit the speed of a vehicle. the speed control system will be programmed using mixed language c and assembly with the latter in use for some pre-written subroutines to drive the lcd module. the gps module will transmit national marine electronics association (nmea) data strings to the microcontroller (mcu) using serial peripheral interface (spi). the mcu will use the location coordinates (latitude and longitude) and the speed from the nmea rmc output string. the current speed is then compared against the recommended speed for the vehicle's location. the memory locations in the atmega128 can be used to store set-point speed values against a particular set of location co-ordinates. apart from its implementation in human operated vehicles, the project can be used to control speed of autonomous cars and to implement the idea of a variable speed limit on roads introduced by the department of transportation [3].\"",
            "contribution_ids": [
                "R25145"
            ]
        },
        {
            "instance_id": "R25160xR25151",
            "comparison_id": "R25160",
            "paper_id": "R25151",
            "text": "Light my way \"in demanding driving situations, the front-seat passenger can become a supporter of the driver by, e.g., monitoring the scene or providing hints about upcoming hazards or turning points. a fast and efficient communication of such spatial information can help the driver to react properly, with more foresight. as shown in previous research, this spatial referencing can be facilitated by providing the driver a visualization of the front-seat passenger's gaze. in this paper, we focus on the question how the gaze should be visualized for the driver, taking into account the feasibility of implementation in a real car. we present the results from a driving simulator study, where we compared an led visualization (glowing leds on an led stripe mounted at the bottom of the windshield, indicating the horizontal position of the gaze) with a visualization of the gaze as a dot in the simulated environment. our results show that led visualization comes with benefits with regard to driver distraction but also bears disadvantages with regard to accuracy and control for the front-seat passenger.\"",
            "contribution_ids": [
                "R25152"
            ]
        },
        {
            "instance_id": "R25160xR25154",
            "comparison_id": "R25160",
            "paper_id": "R25154",
            "text": "A color scenario of Eco & Healthy Driving for the RGB LED based interface display of a climate control device the study demonstrates a process of synergizing both exploratory and confirmatory research approaches to design the color for a luminescent surface facilitated by rgb leds. focusing on the relationship between color and in-door climate of automobiles, the study consists of three parts: in part i, a workshop of ten designers was executed in which ideas were exploited to find in-car scenarios. the scenarios were evaluated based on the criteria of interesting, informative, and inspiring aspects to conclusively derive the scenario labeled \u201ceco & healthy driving\u201d in part ii, a user test was carried out to investigate the relationship between the attributes of luminescent color-hue, brightness, and purity- and an indoor climate condition. in the user test (n= 36), subjects were instructed to match a luminescent color to a given in-car climate condition. the user test results revealed that hue category of luminescent surface is related to temperature while brightness of luminescent color is correlated with blow level; lastly, in part iii, by employing the results of user test, a guideline for implementing the new design scenario, \u201ceco & healthy driving\u201d was projected for further development and application.",
            "contribution_ids": [
                "R25155"
            ]
        },
        {
            "instance_id": "R25201xR25175",
            "comparison_id": "R25201",
            "paper_id": "R25175",
            "text": "Offline Signature Verification Using Classifier Combination of HOG and LBP Features \"we present an offline signature verification system based on a signature's local histogram features. the signature is divided into zones using both the cartesian and polar coordinate systems and two different histogram features are calculated for each zone: histogram of oriented gradients (hog) and histogram of local binary patterns (lbp).\"",
            "contribution_ids": [
                "R25176"
            ]
        },
        {
            "instance_id": "R25201xR25182",
            "comparison_id": "R25201",
            "paper_id": "R25182",
            "text": "Off-line Signature Verification Based on Chain Code Histogram and Support Vector Machine \"in this paper, we present an approach based on chain code histogram features enhanced through laplacian of gaussian filter for off-line signature verification. in the proposed approach, the four-directional chain code histogram of each grid on the contour of the signature image is extracted. the laplacian of gaussian filter is used to enhance the extracted features of each signature sample. thus, the extracted and enhanced features of all signature samples of the off-line signature dataset constitute the knowledge base. subsequently, the support vector machine (svm) classifier is used as the verification tool. the svm is trained with the randomly selected training sample's features including genuine and random forgeries and tested with the remaining untrained genuine along with the skilled forge sample features to classify the tested/questioned sample as genuine or forge. similar to the real time scenario, in the proposed approach we have not considered the skilled fore sample to train the classifier. extensive experimentations have been conducted to exhibit the performance of the proposed approach on the publicly available datasets namely, cedar, gpds-100 and mukos, a regional language dataset. the state-of-art off-line signature verification methods are considered for comparative study to justify the feasibility of the proposed approach for off-line signature verification and to reveal its accuracy over the existing approaches.\"",
            "contribution_ids": [
                "R25183"
            ]
        },
        {
            "instance_id": "R25201xR25188",
            "comparison_id": "R25201",
            "paper_id": "R25188",
            "text": "Offline Signature Verification Using Shape Dissimilarities \"offline signature verification is a challenging and important form of biometric identification. other biometric measures don't have variability as that of signatures which poses difficult problem in verification of signatures. in this paper, we explore a novel approach for verification of signatures based on curve matching using shape descriptor and euclidian distance. in our approach, the measurement of similarities are proceeded by 1)finding correspondences between signatures, we attach shape descriptor (shape context) with euclidian distance between the sample points of one signature and the sample point of other signature for better results, 2)we estimate aligning transforms by using this correspondences between signatures, 3) classify the signatures using linear discriminant analysis and measures of shape dissimilarity between signatures based on shape context distance, bending energy, registration residual, anisotropic scaling.\"",
            "contribution_ids": [
                "R25189"
            ]
        },
        {
            "instance_id": "R25223xR25207",
            "comparison_id": "R25223",
            "paper_id": "R25207",
            "text": "Replica Placement Algorithms in Content Distribution Networks the replica placement problems (rpps) in the content distribution networks have been widely studied. in this paper, we propose an optimization model for the rpps and design efficient algorithms to minimize the total cost of the network. the algorithms include three parts: replication algorithm preprocess, constraint p-median model and algorithm of solving constraint p-median models. in the simulation, we compare our algorithms to other heuristic methods numerically. the results show that our algorithms perform better with less cost.",
            "contribution_ids": [
                "R25208"
            ]
        },
        {
            "instance_id": "R25223xR25211",
            "comparison_id": "R25223",
            "paper_id": "R25211",
            "text": "Distributed Selfish Caching although cooperation generally increases the amount of resources available to a community of nodes, thus improving individual and collective performance, it also allows for the appearance of potential mistreatment problems through the exposition of one node\\'s resources to others. we study such concerns by considering a group of independent, rational, self-aware nodes that cooperate using online caching algorithms, where the exposed resource is the storage at each node. motivated by content networking applications - including web caching, content delivery networks (cdns), and peer-to-peer (p2p) - this paper extends our previous work on the offline version of the problem, which was conducted under a game-theoretic framework and limited to object replication. we identify and investigate two causes of mistreatment: 1) cache state interactions (due to the cooperative servicing of requests) and 2) the adoption of a common scheme for cache management policies. using analytic models, numerical solutions of these models, and simulation experiments, we show that online cooperation schemes using caching are fairly robust to mistreatment caused by state interactions. to appear in a substantial manner, the interaction through the exchange of miss streams has to be very intense, making it feasible for the mistreated nodes to detect and react to exploitation. this robustness ceases to exist when nodes fetch and store objects in response to remote requests, that is, when they operate as level-2 caches (or proxies) for other nodes. regarding mistreatment due to a common scheme, we show that this can easily take place when the \"outlier\" characteristics of some of the nodes get overlooked. this finding underscores the importance of allowing cooperative caching nodes the flexibility of choosing from a diverse set of schemes to fit the peculiarities of individual nodes. to that end, we outline an emulation-based framework for the development of mistreatment-resilient distributed selfish caching schemes.",
            "contribution_ids": [
                "R25212"
            ]
        },
        {
            "instance_id": "R25223xR25205",
            "comparison_id": "R25223",
            "paper_id": "R25205",
            "text": "A QOS-Aware Intelligent Replica Management Architecture for Content Distribution in Peer-to-Peer Overlay Networks the large scale content distribution systems were improved broadly using the replication techniques. the demanded contents can be brought closer to the clients by multiplying the source of information geographically, which in turn reduce both the access latency and the network traffic. the system scalability can be improved by distributing the load across multiple servers which is proposed by replication. if a copy of the requested object (e.g., a web page or an image) is located in its closer proximity then the clients would feel low access latency. depending on the position of the replicas, the effectiveness of replication tends to a large extent. a qos based overlay network architecture involving an intelligent replica placement algorithm is proposed in this paper. its main goal is to improve the network utilization and fault tolerance of the p2p system. in addition to the replica placement, it also has a caching technique, to reduce the search latency. we are able to show that our proposed architecture attains less latency and better throughput with reduced bandwidth usage, through the simulation results. keywords-clusters, content, overlay, qos, replica, routing",
            "contribution_ids": [
                "R25206"
            ]
        },
        {
            "instance_id": "R25255xR25235",
            "comparison_id": "R25255",
            "paper_id": "R25235",
            "text": "Automatic Lexicon Construction for Arabic Sentiment Analysis sentiment analysis (sa) is the process of determining the sentiment of a text written in a natural language to be positive, negative or neutral. it is one of the most interesting subfields of natural language processing (nlp) and web mining due to its diverse applications and the challenges associated with applying it on the massive amounts of textual data available online (especially, on social networks). most of the current works on sa focus on the english language and follow one of two main approaches, (corpus-based and lexicon-based) or a hybrid of them. this work focuses on a less studied aspect of sa, which is lexicon-based sa for the arabic language. in addition to experimenting and comparing three different lexicon construction techniques, an arabic sa tool is designed and implemented to effectively take advantage of the constructed lexicons. the proposed sa tool possesses many novel features such as the way negation and intensification are handled. the experimental results show encouraging outcomes with 74.6% accuracy in addition to revealing new insights and guidelines that could direct the future research efforts.",
            "contribution_ids": [
                "R25236"
            ]
        },
        {
            "instance_id": "R25255xR25251",
            "comparison_id": "R25255",
            "paper_id": "R25251",
            "text": "Arabic senti-lexicon: Constructing publicly available language resources for Arabic sentiment analysis sentiment analysis is held to be one of the highly dynamic recent research fields in natural language processing, facilitated by the quickly growing volume of web opinion data. most of the approaches in this field are focused on english due to the lack of sentiment resources in other languages such as the arabic language and its large variety of dialects. in most sentiment analysis applications, good sentiment resources play a critical role. based on that, in this article, several publicly available sentiment analysis resources for arabic are introduced. this article introduces the arabic senti-lexicon, a list of 3880 positive and negative synsets annotated with their part of speech, polarity scores, dialects synsets and inflected forms. this article also presents a multi-domain arabic sentiment corpus (masc) with a size of 8860 positive and negative reviews from different domains. in this article, an in-depth study has been conducted on five types of feature sets for exploiting effective features and investigating their effect on performance of arabic sentiment analysis. the aim is to assess the quality of the developed language resources and to integrate different feature sets and classification algorithms to synthesise a more accurate sentiment analysis method. the arabic senti-lexicon is used for generating feature vectors. five well-known machine learning algorithms: na\u00efve bayes, k-nearest neighbours, support vector machines (svms), logistic linear regression and neural network are employed as base-classifiers for each of the feature sets. a wide range of comparative experiments on standard arabic data sets were conducted, discussion is presented and conclusions are drawn. the experimental results show that the arabic senti-lexicon is a very useful resource for arabic sentiment analysis. moreover, results show that classifiers which are trained on feature vectors derived from the corpus using the arabic sentiment lexicon are more accurate than classifiers trained using the raw corpus.",
            "contribution_ids": [
                "R25252"
            ]
        },
        {
            "instance_id": "R25255xR25253",
            "comparison_id": "R25255",
            "paper_id": "R25253",
            "text": "AraSenTi: Large-Scale Twitter-Specific Arabic Sentiment Lexicons sentiment analysis (sa) is an active research area nowadays due to the tremendous interest in aggregating and evaluating opinions being disseminated by users on the web. sa of english has been thoroughly researched; however research on sa of arabic has just flourished. twitter is considered a powerful tool for disseminating information and a rich resource for opinionated text containing views on many different topics. in this paper we attempt to bridge a gap in arabic sa of twitter which is the lack of sentiment lexicons that are tailored for the informal language of twitter. we generate two lexicons extracted from a large dataset of tweets using two approaches and evaluate their use in a simple lexicon based method. the evaluation is performed on internal and external datasets. the performance of these automatically generated lexicons was very promising, albeit the simple method used for classification. the best f-score obtained was 89.58% on the internal dataset and 63.1-64.7% on the exter-",
            "contribution_ids": [
                "R25254"
            ]
        },
        {
            "instance_id": "R25358xR25280",
            "comparison_id": "R25358",
            "paper_id": "R25280",
            "text": "Discovering semantic Web services via advanced graph-based matching one of the main advantages of web services is that they can be composed into more complex processes in order to achieve a given business goal. however, such potentiality cannot be fully exploited until suitable methods and techniques allowing us to enable automatic discovery of composed processes are provided. indeed, nowadays service discovery still focuses on matching atomic services by typically checking the similarity of functional parameters, such as inputs and outputs. however, a more profitable process discovering can be reached if both internal structure and component services are taken into account. based on this main intuition, in this paper we describe a method for discovering composite owl-s processes that founds on the following main contributions: (i) proposing a graph-based representation of composite owl-s processes; and (ii) introducing an algorithm that matches over such (graph-based) representations and computes their degree of matching via combining the similarity of the atomic services they comprise and the similarity of the control flow among them. finally, as another contribution of our research, we conducted a comprehensive experimental campaign where we tested our proposed algorithm by deriving insightful trade-offs of benefits and limitations of the overall framework for discovering semantic web services.",
            "contribution_ids": [
                "R25281"
            ]
        },
        {
            "instance_id": "R25358xR25285",
            "comparison_id": "R25358",
            "paper_id": "R25285",
            "text": "YASA-M: A Semantic Web Service Matchmaker in this paper, we present new algorithms for matching web services described in yasa4wsdl (yasa for short). we have already defined yasa, a semantic description of services that overcomes some issues in wsdl or sawsdl. in this paper, we continue on our contribution and show how yasa web services are matched based on the specificities of yasa descriptions. our matching algorithm consists of three variants based on three different semantic matching degree aggregations. this algorithm was implemented in yasa-m, a new web service matchmaker. yasa-m is evaluated and compared to well known approaches for service matching. experiments show that yasa-m provides better results, in terms of precision, response time, and scalability, than a well known matchmaker.",
            "contribution_ids": [
                "R25286"
            ]
        },
        {
            "instance_id": "R25358xR25288",
            "comparison_id": "R25358",
            "paper_id": "R25288",
            "text": "A QoS Broker Based Architecture for Dynamic Web Service Selection \"the increasing number of web services over the web makes the requester to use tools to search for suitable web services available throughout the globe. uddi is the first step towards meeting these demands. however the requester's demand may include not only functional aspects of web services but also nonfunctional aspects like quality of service (qos). there is a need to select the most suitable (qualitatively optimal) web service based on the requester's qos requirements and preferences. in this paper we explore the different types of requester's qos requirements (demands) with illustrations. we propose the qos broker based architecture for dynamic web service selection which facilitates the requester to specify his/her qos requirements along with functional requirements. the paper presents the web service selection mechanism which selects the best (most suitable) web service based on the requester's functional and quality requirements.\"",
            "contribution_ids": [
                "R25289"
            ]
        },
        {
            "instance_id": "R25358xR25298",
            "comparison_id": "R25358",
            "paper_id": "R25298",
            "text": "Research on Services Matching and Ranking Based on Fuzzy QoS Ontology services discovery based on the non-functional qos service features has received increasing attention by service-oriented computing research community. in order to implement qos description provided the express of the uncertain knowledge, in this paper, a fuzzy qos ontology is proposed firstly. then, services match based on fuzzy qos description can be transformed to reasoning in fuzzy description logic, and the rationality of this method be illustrated through an example. at last, a novel rank algorithm for the match results is proposed.",
            "contribution_ids": [
                "R25299"
            ]
        },
        {
            "instance_id": "R25358xR25311",
            "comparison_id": "R25358",
            "paper_id": "R25311",
            "text": "Web Service Matching by Ontology Instance Categorization identifying similar web services is becoming increasingly important to ensure the success of dynamically integrated web-service-based applications. we propose a categorization-based scheme to match equivalent web services that can operate on heterogeneous domain ontologies. given the upper ontology for services and domain ontologies, our service matching scheme determines whether a given web service is a possible replacement using a categorization utility called onexcat. onexcat categorizes ontology instances extracted from the service descriptions by a probabilistic categorization measurement that incorporates the concept relationships in the upper ontology for services. in addition to tackling the issue of heterogeneity of domain ontology in service descriptions using categorization, our matching scheme also adapts itself by enhancing the known ontologies with newly discovered ontology instances. experiments on service matching using our matching scheme based on the onexcat utility have been performed with promising results, a correct matching rate of over 85%.",
            "contribution_ids": [
                "R25312"
            ]
        },
        {
            "instance_id": "R25358xR25323",
            "comparison_id": "R25358",
            "paper_id": "R25323",
            "text": "Semantic Web Service Selection Based on Business Offering semantic web service discovery finds a match between service requirement and service advertisements based on the semantic description. the discovery mechanism does not consider quality and business offers of advertised web services. in this paper, we propose ontology based semantic web service architecture for selection which recommends the best match for the requester. we design semantic broker which allows providers to advertise their services by creating owl-s service profile consisting of functional, quality and business offers. the broker computes and records information for matchmaking during service publishing to improve the performance. the broker reads requirements from the requester and finds the best (profitable) web service by matching functionality, capability, quality and business offers.",
            "contribution_ids": [
                "R25324"
            ]
        },
        {
            "instance_id": "R25358xR25334",
            "comparison_id": "R25358",
            "paper_id": "R25334",
            "text": "URBE: Web Service Retrieval Based on Similarity Evaluation in this work, we present uddi registry by example (urbe), a novel approach for web service retrieval based on the evaluation of similarity between web service interfaces. our approach assumes that the web service interfaces are defined with web service description language (wsdl) and the algorithm combines the analysis of their structures and the analysis of the terms used inside them. the higher the similarity, the less are the differences among their interfaces. as a consequence, urbe is useful when we need to find a web service suitable to replace an existing one that fails. especially in autonomic systems, this situation is very common since we need to ensure the self-management, the self-configuration, the self-optimization, the self-healing, and the self-protection of the application that is based on the failed web service. a semantic-oriented variant of the approach is also proposed, where we take advantage of annotations semantically enriching wsdl specifications. semantic annotation for wsdl (sawsdl) is adopted as a language to annotate a wsdl description. the urbe approach has been implemented in a prototype that extends a universal description, discovery and integration (uddi) compliant web service registry.",
            "contribution_ids": [
                "R25335"
            ]
        },
        {
            "instance_id": "R25400xR25367",
            "comparison_id": "R25400",
            "paper_id": "R25367",
            "text": "Evolving object oriented design to improve code traceability traceability is a key issue to ensure consistency among software artifacts of subsequent phases of the development cycle. however, few works have so far addressed the theme of tracing object oriented design into its implementation and evolving it. the paper presents an approach to checking the compliance of oo design with respect to source code and support its evolution. the process works on design artifacts expressed in the omt notation and accepts c++ source code. it recovers an \"as is\" design from the code, compares recovered design with the actual design and helps the user to deal with inconsistencies. the recovery process exploits the edit distance computation and the maximum match algorithm to determine traceability links between design and code. the output is a similarity measure associated to each matched class, plus a set of unmatched classes. a graphic display of the design with different colors associated to different levels of match is provided as a support to update the design and improve its traceability to the code.",
            "contribution_ids": [
                "R25368"
            ]
        },
        {
            "instance_id": "R25400xR25374",
            "comparison_id": "R25400",
            "paper_id": "R25374",
            "text": "DSL-based support for semi-automated architectural component model abstraction throughout the software lifecycle in this paper we present an approach for supporting the semi-automated abstraction of architectural models throughout the software lifecycle. it addresses the problem that the design and the implementation of a software system often drift apart as software systems evolve, leading to architectural knowledge evaporation. our approach provides concepts and tool support for the semi-automatic abstraction of architectural knowledge from implemented systems and keeping the abstracted architectural knowledge up-to-date. in particular, we propose architecture abstraction concepts that are supported through a domain-specific language (dsl). our main focus is on providing architectural abstraction specifications in the dsl that only need to be changed, if the architecture changes, but can tolerate non-architectural changes in the underlying source code. the dsl and its tools support abstracting the source code into uml component models for describing the architecture. once the software architect has defined an architectural abstraction in the dsl, we can automatically generate uml component models from the source code and check whether the architectural design constraints are fulfilled by the models. our approach supports full traceability between source code elements and architectural abstractions, and allows software architects to compare different versions of the generated uml component model with each other. we evaluate our research results by studying the evolution of architectural abstractions in different consecutive versions and the execution times for five existing open source systems.",
            "contribution_ids": [
                "R25375"
            ]
        },
        {
            "instance_id": "R25400xR25384",
            "comparison_id": "R25400",
            "paper_id": "R25384",
            "text": "A tactic-centric approach for automating traceability of quality concerns the software architectures of business, mission, or safety critical systems must be carefully designed to balance an exacting set of quality concerns describing characteristics such as security, reliability, and performance. unfortunately, software architectures tend to degrade over time as maintainers modify the system without understanding the underlying architectural decisions. although this problem can be mitigated by manually tracing architectural decisions into the code, the cost and effort required to do this can be prohibitively expensive. in this paper we therefore present a novel approach for automating the construction of traceability links for architectural tactics. our approach utilizes machine learning methods and lightweight structural analysis to detect tactic-related classes. the detected tactic-related classes are then mapped to a tactic traceability information model. we train our trace algorithm using code extracted from fifteen performance-centric and safety-critical open source software systems and then evaluate it against the apache hadoop framework. our results show that automatically generated traceability links can support software maintenance activities while helping to preserve architectural qualities.",
            "contribution_ids": [
                "R25385"
            ]
        },
        {
            "instance_id": "R25447xR25426",
            "comparison_id": "R25447",
            "paper_id": "R25426",
            "text": "An Enhance Approach For Web Services Discovery with QoS \"the quality of service for web services here mainly refers to the quality aspect of a web service. the qos for web services is becoming increasingly important to service providers and service requesters due to increasing use of web services. web services providing similar functionalities, more emphasis is being placed on how to find the service that best fits the consumer's requirements. in order to find services that best meet their qos requirements, the service consumers and/or discovery agents need to know both the qos information for the services and the reliability of this information. in this paper first of all we implement reputation-enhanced web services discovery protocol. and after implementation we enhance the protocol over memory used, time to discovery and response time of given web service.\"",
            "contribution_ids": [
                "R25427"
            ]
        },
        {
            "instance_id": "R25447xR25423",
            "comparison_id": "R25447",
            "paper_id": "R25423",
            "text": "Reliability Modeling for SOA Systems service-oriented architecture (soa) is a popular paradigm for development of distributed systems by composing the functionality provided by the services exposed on the network. in effect, the services can use functionalities of other services to accomplish their own goals. although such an architecture provides an elegant solution to simple construction of loosely coupled distributed systems, it also introduces additional concerns. one of the primary concerns in designing a soa system is the overall system reliability. since the building blocks are services provided by various third parties, it is often not possible to apply the well established fault removal techniques during the development phases. therefore, in order to reach desirable system reliability for soa systems, the focus shifts towards fault prediction and fault tolerance techniques. in this paper an overview of existing reliability modeling techniques for soa-based systems is given. furthermore, we present a model for reliability estimation of a service composition using directed acyclic graphs. the model is applied to the service composition based on the orchestration model. a case study for the proposed model is presented by analyzing a simple web service composition scenario.",
            "contribution_ids": [
                "R25424"
            ]
        },
        {
            "instance_id": "R25447xR25442",
            "comparison_id": "R25447",
            "paper_id": "R25442",
            "text": "Synergies between SOA and Grid computing service oriented architecture (soa) is an architectural style for developing and integrating enterprise applications to enable an enterprise to deliver self-describing and platform independent business functionality. grid computing (gc) is a framework that allows pooling of physical resources to enable virtualisation of distributed computing, enterprise data and enterprise functionality. the two are synergetic in the sense that, whereas soa can provide a strong basis for gc, technical framework based on gc provides the optimum foundation for soa. this paper discusses the two paradigms and provides some useful information for the benefit of large enterprises that wish to embark on the development and implementation of soa based on grid computing.",
            "contribution_ids": [
                "R25443"
            ]
        },
        {
            "instance_id": "R25495xR25457",
            "comparison_id": "R25495",
            "paper_id": "R25457",
            "text": "Event-Triggered Model Predictive Control for Embedded Artificial Pancreas Systems objective: the development of artificial pancreas (ap) technology for deployment in low-energy, embedded devices is contingent upon selecting an efficient control algorithm for regulating glucose in people with type 1 diabetes mellitus. in this paper, we aim to lower the energy consumption of the ap by reducing controller updates, that is, the number of times the decision-making algorithm is invoked to compute an appropriate insulin dose. methods: physiological insights into glucose management are leveraged to design an event-triggered model predictive controller (mpc) that operates efficiently, without compromising patient safety. the proposed event-triggered mpc is deployed on a wearable platform. its robustness to latent hypoglycemia, model mismatch, and meal misinformation is tested, with and without meal announcement, on the full version of the us-fda accepted uva/padova metabolic simulator. results: the event-based controller remains on for 18\\xa0h of 41\\xa0h in closed loop with unannounced meals, while maintaining glucose in 70\u2013180\\xa0mg/dl for 25\\xa0h, compared to 27\\xa0h for a standard mpc controller. with meal announcement, the time in 70\u2013180\\xa0mg/dl is almost identical, with the controller operating a mere 25.88% of the time in comparison with a standard mpc. conclusion: a novel control architecture for ap systems enables safe glycemic regulation with reduced processor computations. significance: our proposed framework integrated seamlessly with a wide variety of popular mpc variants reported in ap research, customizes tradeoff between glycemic regulation and efficacy according to prior design specifications, and eliminates judicious prior selection of controller sampling times.",
            "contribution_ids": [
                "R25458"
            ]
        },
        {
            "instance_id": "R25495xR25473",
            "comparison_id": "R25495",
            "paper_id": "R25473",
            "text": "Toward a Run-to-Run Adaptive Artificial Pancreas: In Silico Results objective : contemporary and future outpatient long-term artificial pancreas (ap) studies need to cope with the well-known large intra- and interday glucose variability occurring in type 1 diabetic (t1d) subjects. here, we propose an adaptive model predictive control (mpc) strategy to account for it and test it in silico. methods : a run-to-run (r2r) approach adapts the subcutaneous basal insulin delivery during the night and the carbohydrate-to-insulin ratio (cr) during the day, based on some performance indices calculated from subcutaneous continuous glucose sensor data. in particular, r2r aims, first, to reduce the percentage of time in hypoglycemia and, secondarily, to improve the percentage of time in euglycemia and average glucose. in silico simulations are performed by using the university of virginia/padova t1d simulator enriched by incorporating three novel features: intra- and interday variability of insulin sensitivity, different distributions of cr at breakfast, lunch, and dinner, and dawn phenomenon. results : after about two months, using the r2r approach with a scenario characterized by a random $\\\\pm$ 30% variation of the nominal insulin sensitivity the time in range and the time in tight range are increased by 11.39% and 44.87%, respectively, and the time spent above 180 mg/dl is reduced by 48.74%. conclusions : an adaptive mpc algorithm based on r2r shows in silico great potential to capture intra- and interday glucose variability by improving both overnight and postprandial glucose control without increasing hypoglycemia. significance : making an ap adaptive is key for long-term real-life outpatient studies. these good in silico results are very encouraging and worth testing in vivo .",
            "contribution_ids": [
                "R25474"
            ]
        },
        {
            "instance_id": "R25495xR25479",
            "comparison_id": "R25495",
            "paper_id": "R25479",
            "text": "A Long-Term Model of the Glucose-Insulin Dynamics of Type 1 Diabetes a new glucose-insulin model is introduced which fits with the clinical data from in- and outpatients for two days. its stability property is consistent with the glycemia behavior for type 1 diabetes. this is in contrast to traditional glucose-insulin models. prior models fit with clinical data for a few hours only or display some nonnatural equilibria. the parameters of this new model are identifiable from standard clinical data as continuous glucose monitoring, insulin injection, and carbohydrate estimate. moreover, it is shown that the parameters from the model allow the computation of the standard tools used in functional insulin therapy as the basal rate of insulin and the insulin sensitivity factor. this is a major outcome as they are required in therapeutic education of type 1 diabetic patients.",
            "contribution_ids": [
                "R25480"
            ]
        },
        {
            "instance_id": "R25529xR25505",
            "comparison_id": "R25529",
            "paper_id": "R25505",
            "text": "Social finance and crowdfunding for social enterprises: a public\u00e2\u0080\u0093private case study providing legitimacy and leverage the authors work closely with academia and governmental organizations in the uk and abroad to develop new, innovative schemes for social impact investing. such schemes include considerations for public\u2013private collaborations, legislative actions, and especially in this case, for the leveraged use of public and philanthropic funds in crowdfunding (cf). the relatively new phenomenon of cf can not only provide necessary funds for the social enterprises, it may also lead to a higher legitimacy of these through early societal interaction and participation. this legitimacy can be understood as a strong positive signal for further investors. governmental tax-reliefs and guarantees from venture-philanthropic funds provide additional incentives for investment and endorse future scaling by leveraging additional debt-finance from specialized social banks. this case study identifies idiosyncratic hurdles to why an efficient social finance market has yet to be created and examines a schema as a case of how individual players\u2019 strengths and weaknesses can be balanced out by a concerted action. the paper discusses the necessary actions, benefits and implications for the involved actors from the public, private and third sector.",
            "contribution_ids": [
                "R25506"
            ]
        },
        {
            "instance_id": "R25529xR25525",
            "comparison_id": "R25529",
            "paper_id": "R25525",
            "text": "Effects of Social Interaction Dynamics on Platforms abstract despite the increasing relevance of online social interactions on platforms, there is still little research on the temporal interaction dynamics between electronic word-of-mouth (ewom, a form of opinion-based social interaction), popularity information (a form of action-based social interaction), and consumer decision making. drawing on a panel data set of more than 23,300 crowdfunding campaigns from indiegogo, we investigate the dynamic effects of these social interactions on consumers\u2019 funding decisions using the panel vector autoregressive methodology. our analysis shows that both ewom and popularity information are critical influencing mechanisms in crowdfunding. however, our overarching finding is that ewom surrounding crowdfunding campaigns on indiegogo or facebook has a significant yet substantially weaker predictive power than popularity information. we also find that whereas popularity information has a more immediate effect on consumers\u2019 funding behavior, its effectiveness decays rather quickly, while the impact of ewom recedes more slowly. this study contributes to the extant literature by (1) providing a more nuanced understanding of the dynamic effects of opinion-based and action-based social interactions, (2) unraveling both within-platform and cross-platform dynamics, and (3) showing that social interactions are perceived as quality indicators on crowdfunding platforms that help consumers reduce risks associated with their investment decisions. these results can help platform providers and complementors to stimulate contribution behavior and increase the prosperity of a platform.",
            "contribution_ids": [
                "R25526"
            ]
        },
        {
            "instance_id": "R25529xR25527",
            "comparison_id": "R25529",
            "paper_id": "R25527",
            "text": "What Goes around Comes Around? Rewards as Strategic Assets in Crowdfunding in crowdfunding, rewards can make or break success. yet reward design, choice, and planning still occur based on availability rather than strategy. to address this challenge, this article provides an empirically derived crowd-funding reward toolbox offering guidance in strategically selecting rewards. based on a large-scale analysis of successful and unsuccessful kickstarter projects, this article classifies rewards that are currently offered along eight dimensions. it identifies emerging patterns and derives five strategic core tools and two add-on tools. finally, it delivers exploratory insights into the relative effectiveness of different tools that can facilitate decision making and strategic planning for entrepreneurs and individuals who plan to launch a crowdfunding project and who seek ways to reward their supporters.",
            "contribution_ids": [
                "R25528"
            ]
        },
        {
            "instance_id": "R25583xR25531",
            "comparison_id": "R25583",
            "paper_id": "R25531",
            "text": "A DSL for rapid prototyping of cross-platform tower defense games because of the increasing expansion of the videogame industry, shorten videogame time to market for diverse platforms (e.g, mac, android, ios, blackberry) is a quest. this paper presents how a domain specific language (dsl) in conjunction with model-driven engineering (mde) techniques can automate the development of games, in particular, tower defense games such as plants vs. zombies. the dsl allows the expression of structural and behavioral aspects of tower defense games. the mde techniques allow us to generate code from the game expressed in the dsl. the generated code is written in an existing open source language that leverages the portability of the games. we present our approach using an example so-called space attack. the example shows the significant benefits offered by our proposal in terms of productivity and portability.",
            "contribution_ids": [
                "R25532"
            ]
        },
        {
            "instance_id": "R25583xR25533",
            "comparison_id": "R25583",
            "paper_id": "R25533",
            "text": "A Flexible Model-Driven Game Development Approach game developers are facing an increasing demand for new games every year. game development tools can be of great help, but require highly specialized professionals. also, just as any software development effort, game development has some challenges. model-driven game development (mdgd) is suggested as a means to solve some of these challenges, but with a loss in flexibility. we propose a mdgd approach that combines multiple domain-specific languages (dsls) with design patterns to provide flexibility and allow generated code to be integrated with manual code. after experimentation, we observed that, with the approach, less experienced developers can create games faster and more easily, and the product of code generation can be customized with manually written code, providing flexibility. however, with mdgd, developers become less familiar with the code, making manual codification more difficult.",
            "contribution_ids": [
                "R25534"
            ]
        },
        {
            "instance_id": "R25583xR25537",
            "comparison_id": "R25583",
            "paper_id": "R25537",
            "text": "Building a Game Engine: A Tale of Modern Model-Driven Engineering game engines enable developers to reuse assets from previously developed games, thus easing the software-engineering challenges around the video-game development experience and making the implementation of games less expensive, less technologically brittle, and more efficient. however, the construction of game engines is challenging in itself, it involves the specification of well defined architectures and typical game play behaviors, flexible enough to enable game designers to implement their vision, while, at the same time, simplifying the implementation through asset and code reuse. in this paper we present a set of lessons learned through the design and construction phydsl-2, a game engine for 2d physics-based games. our experience involves the active use of modern model-driven engineering technologies, to overcome the complexity of the engine design and to systematize its maintenance and evolution.",
            "contribution_ids": [
                "R25538"
            ]
        },
        {
            "instance_id": "R25583xR25551",
            "comparison_id": "R25583",
            "paper_id": "R25551",
            "text": "Model-driven development of interactive and integrated 2D and 3D user interfaces using mml while there is a lot of research done in the area of 2d or 3d user interfaces (uis) construction, comparatively little is known about systematic approaches to designing and developing integrated 2d/3d uis and applications. the previously developed multimedia modeling language (mml) provides a top down approach for a model driven development of 2d/3d uis and applications. the mml structure model and media components provide support for including x3d based content and automatic generation of application skeletons. we use a work instruction manual for a woodchipper as an example to illustrate how to apply mml. we discuss the ramifications of this approach and opportunities for some improvements.",
            "contribution_ids": [
                "R25552"
            ]
        },
        {
            "instance_id": "R25583xR25569",
            "comparison_id": "R25583",
            "paper_id": "R25569",
            "text": "Engine- Cooperative Game Modeling (ECGM) today game engines are popular in commercial game development, as they lower the threshold of game production by providing common technologies and convenient content-creation tools. game engine based development is therefore the mainstream methodology in the game industry. model-driven game development (mdgd) is an emerging game development methodology, which applies the model-driven software development (mdsd) method in the game development domain. this simplifies game development by reducing the gap between game design and implementation. mdgd has to take advantage of the existing game engines in order to be useful in commercial game development practice. however, none of the existing mdgd approaches in literature has convincingly demonstrated good integration of its tools with the game engine tool-chain. in this paper, we propose a hybrid approach named ecgm to address the integration challenges of two methodologies with a focus on the technical aspects. the approach makes a run-time engine the base of the domain framework, and uses the game engine tool-chain together with the mdgd tool-chain. ecgm minimizes the change to the existing workflow and technology, thus reducing the cost and risk of adopting mdgd in commercial game development. our contribution is one important step towards mdgd industrialization.",
            "contribution_ids": [
                "R25570"
            ]
        },
        {
            "instance_id": "R25583xR25577",
            "comparison_id": "R25583",
            "paper_id": "R25577",
            "text": "How to integrate domain-specific languages into the game development process domain-specific languages make the relevant details of a domain explicit while omitting the distracting ones. this implies many benefits regarding development speed and quality as well as the exchange of information between expert groups. in order to utilize these benefits for game development, we present a language engineering workflow that describes best practices to identify a reasonable domain abstraction, illustrated by means of a language for 2d point &click adventures. we discuss how this process can be integrated into an agile, iterative development process and what thereby needs to be considered.",
            "contribution_ids": [
                "R25578"
            ]
        },
        {
            "instance_id": "R25583xR25565",
            "comparison_id": "R25583",
            "paper_id": "R25565",
            "text": "Using domain-specific modeling towards computer games development industrialization this paper proposes that computer games development, in spite of its inherently creative and innovative nature, is subject of systematic industrialization targeted at predictability and productivity. the proposed approach encompasses visual domain-specific languages, semantic validators and code generators to make game developers and designers to work more productively, with a higher level of abstraction and closer to their application domain. such concepts were implemented and deployed into a host development environment, and a real-world scenario was developed to illustrate and validate the proposal.",
            "contribution_ids": [
                "R25566"
            ]
        },
        {
            "instance_id": "R25629xR25595",
            "comparison_id": "R25629",
            "paper_id": "R25595",
            "text": "Agile systems development and stakeholder satisfaction: a South African empirical study \"the high rate of systems development (sd) failure is often attributed to the complexity of traditional sd methodologies (e.g. waterfall) and their inability to cope with changes brought about by today's dynamic and evolving business environment. agile methodologies (am) have emerged to challenge traditional sd and overcome their limitations. yet empirical research into am is sparse. this paper develops and tests a research model that hypothesizes the effects of five characteristics of agile systems development (iterative development; continuous integration; test-driven design; feedback; and collective ownership) on two dependent stakeholder satisfaction measures, namely stakeholder satisfaction with the development process and with the development outcome. an empirical study of 59 south african development projects (using self reported data) provided support for all hypothesized relationships and generally supports the efficacy of am. iteration and integration together with collective ownership have the strongest effects on the dependent satisfaction measures.\"",
            "contribution_ids": [
                "R25596"
            ]
        },
        {
            "instance_id": "R25629xR25599",
            "comparison_id": "R25629",
            "paper_id": "R25599",
            "text": "Effects of agile practices on social factors programmers are living in an age of accelerated change. state of the art technology that was employed to facilitate projects a few years ago are typically obsolete today. presently, there are requirements for higher quality software with less tolerance for errors, produced in compressed timelines with fewer people. therefore, project success is more elusive than ever and is contingent upon many key aspects. one of the most crucial aspects is social factors. these social factors, such as knowledge sharing. motivation, and customer collaboration, can be addressed through agile practices. this paper will demonstrate two successful industrial software projects which are different in all aspects; however, both still apply agile practices to address social factors. the readers will see how agile practices in both projects were adapted to fit each unique team environment. the paper will also provide lessons learned and recommendations based on retrospective reviews and observations. these recommendations can lead to an improved chance of success in a software development project.",
            "contribution_ids": [
                "R25600"
            ]
        },
        {
            "instance_id": "R25629xR25605",
            "comparison_id": "R25629",
            "paper_id": "R25605",
            "text": "Agile Team Perceptions of Productivity Factors in this paper, we investigate agile team perceptions of factors impacting their productivity. within this overall goal, we also investigate which productivity concept was adopted by the agile teams studied. we here conducted two case studies in the industry and analyzed data from two projects that we followed for six months. from the perspective of agile team members, the three most perceived factors impacting on their productivity were appropriate team composition and allocation, external dependencies, and staff turnover. teams also mentioned pair programming and collocation as agile practices that impact productivity. as a secondary finding, most team members did not share the same understanding of the concept of productivity. while some known factors still impact agile team productivity, new factors emerged from the interviews as potential productivity factors impacting agile teams.",
            "contribution_ids": [
                "R25606"
            ]
        },
        {
            "instance_id": "R25629xR25625",
            "comparison_id": "R25629",
            "paper_id": "R25625",
            "text": "Assimilation of agile practices in use agile method use in information systems development (isd) has grown dramatically in recent years. the emergence of these alternative approaches was very much industry\u2010led at the outset, and while agile method research is growing, the vast majority of these studies are descriptive and often lack a strong theoretical and conceptual base. insights from innovation adoption research can provide a new perspective on analysing agile method use. this paper is based on an exploratory study of the application of the innovation assimilation stages to understand the use of agile practices, focusing in particular on the later stages of assimilation, namely acceptance, routinisation and infusion. four case studies were conducted, and based on the case study findings, the concepts of acceptance, routinisation and infusion were adapted and applied to agile software development. these adapted concepts were used to glean interesting insights into agile practice use. for example, it was shown that the period of use of agile practices does not have a proportional effect on their assimilation depths. we also reflected on the sequential assumption underlying the assimilation stages, showing that adopting teams do not always move through the assimilation stages in a linear manner.",
            "contribution_ids": [
                "R25626"
            ]
        },
        {
            "instance_id": "R25663xR25641",
            "comparison_id": "R25663",
            "paper_id": "R25641",
            "text": "An empirical task analysis of warehouse order picking using head-mounted displays evaluations of task guidance systems often focus on evaluations of new technologies rather than comparing the nuances of interaction across the various systems. one common domain for task guidance systems is warehouse order picking. we present a method involving an easily reproducible ecologically motivated order picking environment for quantitative user studies designed to reveal differences in interactions. using this environment, we perform a 12 participant within-subjects experiment demonstrating the advantages of a head-mounted display based picking chart over a traditional text-based pick list, a paper-based graphical pick chart, and a mobile pick-by-voice system. the test environment proved sufficiently sensitive, showing statistically significant results along several metrics with the head-mounted display system performing the best. we also provide a detailed analysis of the strategies adopted by our participants.",
            "contribution_ids": [
                "R25642"
            ]
        },
        {
            "instance_id": "R25663xR25657",
            "comparison_id": "R25663",
            "paper_id": "R25657",
            "text": "Pick from here! order picking is not only one of the most important but also most mentally demanding and error-prone tasks in the industry. both stationary and wearable systems have been introduced to facilitate this task. existing stationary systems are not scalable because of the high cost and wearable systems have issues being accepted by the workers. in this paper, we introduce a mobile camera-projector cart called orderpickar, which combines the benefits of both stationary and mobile systems to support order picking through augmented reality. our system dynamically projects in-situ picking information into the storage system and automatically detects when a picking task is done. in a lab study, we compare our system to existing approaches, i.e, pick-by-paper, pick-by-voice, and pick-by-vision. the results show that using the proposed system, order picking is almost twice as fast as other approaches, the error rate is decreased up to 9 times, and mental demands are reduced up to 50%.",
            "contribution_ids": [
                "R25658"
            ]
        },
        {
            "instance_id": "R25663xR25659",
            "comparison_id": "R25663",
            "paper_id": "R25659",
            "text": "Exploring the role of picker personality in predicting picking performance with pick by voice, pick to light and RF-terminal picking order pickers and individual differences between them could have a substantial impact on picking performance, but are largely ignored in studies on order picking. this paper explores the role of individual differences in picking performance with various picking tools (pick by voice, rf-terminal picking and pick to light) and methods (parallel, zone and dynamic zone picking). a unique realistic field experiment with 101 participants (academic students, vocational students and professional pickers) is employed to investigate the influence of individual differences, especially the big five personality traits, on picking performance in terms of productivity and quality. the results suggest that (pbv) performs better than rf-terminal picking, and that neuroticism, extraversion, conscientiousness and the age of the picker play a significant role in predicting picking performance with voice and rf-terminals. furthermore, achieving higher productivity appears to be possible without sacrificing quality. managers can increase picking performance by incorporating the insights in assigning the right pickers to work with a particular picking tool or method, leading to increased picking performance and reduced warehousing costs.",
            "contribution_ids": [
                "R25660"
            ]
        },
        {
            "instance_id": "R25694xR6499",
            "comparison_id": "R25694",
            "paper_id": "R6499",
            "text": "Facets and Pivoting for Flexible and Usable Linked Data Exploration the success of open data initiatives has increased the amount of data available on the web. unfortunately, most of this data is only available in raw tabular form, what makes analysis and reuse quite difficult for non-experts. linked data principles allow for a more sophisticated approach by making explicit both the structure and semantics of the data. however, from the end-user viewpoint, they continue to be monolithic files completely opaque or difficult to explore by making tedious semantic queries. our objective is to facilitate the user to grasp what kind of entities are in the dataset, how they are interrelated, which are their main properties and values, etc. rhizomer is a tool for data publishing whose interface provides a set of components borrowed from information architecture (ia) that facilitate awareness of the dataset at hand. it automatically generates navigation menus and facets based on the kinds of things in the dataset and how they are described through metadata properties and values. moreover, motivated by recent tests with end-users, it also provides the possibility to pivot among the faceted views created for each class of resources in the dataset.",
            "contribution_ids": [
                "R25668",
                "R6500"
            ]
        },
        {
            "instance_id": "R25726xR25701",
            "comparison_id": "R25726",
            "paper_id": "R25701",
            "text": "GrOWL: A Tool for Visualization and Editing of OWL Ontologies in an effort to optimize visualization and editing of owl ontologies we have developed growl-a browser and visual editor for owl that accurately visualizes the underlying dl semantics of owl ontologies while avoiding the difficulties of the verbose owl syntax. in this paper, we discuss growl visualization model and the essential visualization techniques implemented in growl.",
            "contribution_ids": [
                "R25702"
            ]
        },
        {
            "instance_id": "R25726xR25724",
            "comparison_id": "R25726",
            "paper_id": "R25724",
            "text": "graphVizdb: A scalable platform for interactive large graph visualization we present a novel platform for the interactive visualization of very large graphs. the platform enables the user to interact with the visualized graph in a way that is very similar to the exploration of maps at multiple levels. our approach involves an offline preprocessing phase that builds the layout of the graph by assigning coordinates to its nodes with respect to a euclidean plane. the respective points are indexed with a spatial data structure, i.e., an r-tree, and stored in a database. multiple abstraction layers of the graph based on various criteria are also created offline, and they are indexed similarly so that the user can explore the dataset at different levels of granularity, depending on her particular needs. then, our system translates user operations into simple and very efficient spatial operations (i.e., window queries) in the backend. this technique allows for a fine-grained access to very large graphs with extremely low latency and memory requirements and without compromising the functionality of the tool. our web-based prototype supports three main operations: (1) interactive navigation, (2) multi-level exploration, and (3) keyword search on the graph metadata.",
            "contribution_ids": [
                "R25725"
            ]
        },
        {
            "instance_id": "R25726xR25706",
            "comparison_id": "R25726",
            "paper_id": "R25706",
            "text": "Gephi: An Open Source Software for Exploring and Manipulating Networks gephi is an open source software for graph and network analysis. it uses a 3d render engine to display large networks in real-time and to speed up the exploration. a flexible and multi-task architecture brings new possibilities to work with complex data sets and produce valuable visual results.\\xa0 we present several key features of gephi in the context of interactive exploration and interpretation of networks. it provides easy and broad access to network data and allows for spatializing, filtering, navigating, manipulating and clustering. finally, by presenting dynamic features of gephi, we highlight key aspects of dynamic network visualization.",
            "contribution_ids": [
                "R25707"
            ]
        },
        {
            "instance_id": "R25726xR6445",
            "comparison_id": "R25726",
            "paper_id": "R6445",
            "text": "ZoomRDF: semantic fisheye zooming on RDF data. with the development of semantic web in recent years, an increasing amount of semantic data has been created in form of resource description framework (rdf). current visualization techniques help users quickly understand the underlying rdf data by displaying its structure in an overview. however, detailed information can only be accessed by further navigation. an alternative approach is to display the global context as well as the local details simultaneously in a unified view. this view supports the visualization and navigation on rdf data in an integrated way. in this demonstration, we present zoomrdf, a framework that: i) adapts a space-optimized visualization algorithm for rdf, which allows more resources to be displayed, thus maximizes the utilization of display space, ii) combines the visualization with a fisheye zooming concept, which assigns more space to some individual nodes while still preserving the overview structure of the data, iii) considers both the importance of resources and the user interaction on them, which offers more display space to those elements the user may be interested in. we implement the framework based on the gene ontology and demonstrate that it facilitates tasks like rdf data exploration and editing.",
            "contribution_ids": [
                "R25713",
                "R6446"
            ]
        },
        {
            "instance_id": "R25762xR25728",
            "comparison_id": "R25762",
            "paper_id": "R25728",
            "text": "A fast high utility itemsets mining algorithm association rule mining (arm) identifies frequent itemsets from databases and generates association rules by considering each item in equal value. however, items are actually different in many aspects in a number of real applications, such as retail marketing, network log, etc. the difference between items makes a strong impact on the decision making in these applications. therefore, traditional arm cannot meet the demands arising from these applications. by considering the different values of individual items as utilities, utility mining focuses on identifying the itemsets with high utilities. as \"downward closure property\" doesn\\'t apply to utility mining, the generation of candidate itemsets is the most costly in terms of time and memory space. in this paper, we present a two-phase algorithm to efficiently prune down the number of candidates and can precisely obtain the complete set of high utility itemsets. in the first phase, we propose a model that applies the \"transaction-weighted downward closure property\" on the search space to expedite the identification of candidates. in the second phase, one extra database scan is performed to identify the high utility itemsets. we also parallelize our algorithm on shared memory multi-process architecture using common count partitioned database (ccpd) strategy. we verify our algorithm by applying it to both synthetic and real databases. it performs very efficiently in terms of speed and memory cost, and shows good scalability on multiple processors, even on large databases that are difficult for existing algorithms to handle.",
            "contribution_ids": [
                "R25729"
            ]
        },
        {
            "instance_id": "R25762xR25742",
            "comparison_id": "R25762",
            "paper_id": "R25742",
            "text": "A transaction mapping algorithm for frequent itemsets mining in this paper, we present a novel algorithm for mining complete frequent itemsets. this algorithm is referred to as the tm (transaction mapping) algorithm from hereon. in this algorithm, transaction ids of each itemset are mapped and compressed to continuous transaction intervals in a different space and the counting of itemsets is performed by intersecting these interval lists in a depth-first order along the lexicographic tree. when the compression coefficient becomes smaller than the average number of comparisons for intervals intersection at a certain level, the algorithm switches to transaction id intersection. we have evaluated the algorithm against two popular frequent itemset mining algorithms, fp-growth and declat, using a variety of data sets with short and long frequent patterns. experimental data show that the tm algorithm outperforms these two algorithms.",
            "contribution_ids": [
                "R25743"
            ]
        },
        {
            "instance_id": "R25762xR25746",
            "comparison_id": "R25762",
            "paper_id": "R25746",
            "text": "Mining High Utility Itemsets in Large High Dimensional Data existing algorithms for utility mining are inadequate on datasets with high dimensions or long patterns. this paper proposes a hybrid method, which is composed of a row enumeration algorithm (i.e., inter-transaction) and a column enumeration algorithm (i.e., two-phase), to discover high utility itemsets from two directions: two-phase seeks short high utility itemsets from the bottom, while inter-transaction seeks long high utility itemsets from the top. in addition, optimization technique is adopted to improve the performance of computing the intersection of transactions. experiments on synthetic data show that the hybrid method achieves high performance in large high dimensional datasets.",
            "contribution_ids": [
                "R25747"
            ]
        },
        {
            "instance_id": "R25857xR25787",
            "comparison_id": "R25857",
            "paper_id": "R25787",
            "text": "Promotional effect of Pd single atoms on Au nanoparticles supported on silica for the selective hydrogenation of acetylene in excess ethylene a pd single-atom alloy (saa) structure was constructed by alloying pd with au supported on silica. the xrd and hrtem results demonstrated that the addition of a small amount of pd efficiently prevented the sintering of au nanoparticles. the drifts and exafs results confirmed that the pd saa structure was formed when the atomic ratios of pd/au were lower than 0.025. the pd saa structure exhibits a much better catalytic performance for the selective hydrogenation of acetylene in excess ethylene than the corresponding monometallic au or pd systems.",
            "contribution_ids": [
                "R25788"
            ]
        },
        {
            "instance_id": "R25857xR25791",
            "comparison_id": "R25857",
            "paper_id": "R25791",
            "text": "Performance of Cu-Alloyed Pd Single-Atom Catalyst for Semihydrogenation of Acetylene under Simulated Front-End Conditions selective hydrogenation of acetylene to ethylene is an industrially important reaction. pd-based catalysts have been proved to be efficient for the acetylene conversion, while enhancing the selectivity to ethylene is challenging. here, we chose cu as the partner of pd, fabricated an alloyed pd single-atom catalyst (sac), and investigated its catalytic performance for the selective hydrogenation of acetylene to ethylene under a simulated front-end hydrogenation process in industry: that is, with a high concentration of hydrogen and ethylene. the cu-alloyed pd sac showed \u223c85% selectivity to ethylene and 100% acetylene elimination. in comparison with the au- or ag-alloyed pd sac, the cu-alloyed analogue exceeded both of them in conversion, while the selectivity rivaled that of the ag-alloyed pd sac and surpassed that of the au-alloyed pd sac. as cu is a low-cost metal, cu-alloyed pd sac would minimize the noble-metal usage and possess high utilization potential for industry. the cu-alloyed pd sac was verifie...",
            "contribution_ids": [
                "R25792"
            ]
        },
        {
            "instance_id": "R25857xR25816",
            "comparison_id": "R25857",
            "paper_id": "R25816",
            "text": "Single-Atom Pd1/Graphene Catalyst Achieved by Atomic Layer Deposition: Remarkable Performance in Selective Hydrogenation of 1,3-Butadiene we reported that atomically dispersed pd on graphene can be fabricated using the atomic layer deposition technique. aberration-corrected high-angle annular dark-field scanning transmission electron microscopy and x-ray absorption fine structure spectroscopy both confirmed that isolated pd single atoms dominantly existed on the graphene support. in selective hydrogenation of 1,3-butadiene, the single-atom pd1/graphene catalyst showed about 100% butenes selectivity at 95% conversion at a mild reaction condition of about 50 \u00b0c, which is likely due to the changes of 1,3-butadiene adsorption mode and enhanced steric effect on the isolated pd atoms. more importantly, excellent durability against deactivation via either aggregation of metal atoms or carbonaceous deposits during a total 100 h of reaction time on stream was achieved. therefore, the single-atom catalysts may open up more opportunities to optimize the activity, selectivity, and durability in selective hydrogenation reactions.",
            "contribution_ids": [
                "R25817"
            ]
        },
        {
            "instance_id": "R25857xR25820",
            "comparison_id": "R25857",
            "paper_id": "R25820",
            "text": "Atomically Dispersed Pd on Nanodiamond/Graphene Hybrid for Selective Hydrogenation of Acetylene we reported here a strategy to use a defective nanodiamond-graphene (nd@g) to prepare an atomically dispersed metal catalyst, i.e., in the current case atomically dispersed palladium catalyst which is used for selective hydrogenation of acetylene in the presence of abundant ethylene. the catalyst exhibits remarkable performance for the selective conversion of acetylene to ethylene: high conversion (100%), ethylene selectivity (90%), and good stability. the unique structure of the catalyst (i.e., atomically dispersion of pd atoms on graphene through pd-c bond anchoring) blocks the formation of unselective subsurface hydrogen species and ensures the facile desorption of ethylene against the overhydrogenation to undesired ethane, which is the key for the outstanding selectivity of the catalyst.",
            "contribution_ids": [
                "R25821"
            ]
        },
        {
            "instance_id": "R25857xR25842",
            "comparison_id": "R25857",
            "paper_id": "R25842",
            "text": "Cooperative Effects in Ternary Cu\u00e2\u0088\u0092Ni\u00e2\u0088\u0092Fe Catalysts Lead to Enhanced Alkene Selectivity in Alkyne Hydrogenation a new generation of heterogeneous cu-ni-fe catalysts with appropriate metal ratios displayed outstanding alkene selectivity in the gas-phase hydrogenation of propyne (s(c(3)h(6)) up to 100%) and ethyne (s(c(2)h(4)) up to 80%). the design was accomplished by orchestrating key functions in the catalyst: copper is the base hydrogenation metal, nickel increases the hydrogen coverage to minimize oligomerization, and iron acts as structural promoter. in addition to the largely improved alkene selectivity compared to that of the commonly applied pd catalysts, the ternary cu-ni-fe catalysts promise substantial process advantages, since they do not require co feeding as selectivity enhancer and they yield high alkene selectivity in a broad window of h(2)/alkyne ratios. the ternary system requires higher operating temperatures compared to those for palladium.",
            "contribution_ids": [
                "R25843"
            ]
        },
        {
            "instance_id": "R25857xR25853",
            "comparison_id": "R25857",
            "paper_id": "R25853",
            "text": "Semihydrogenation of Acetylene on Indium Oxide: Proposed Single-Ensemble Catalysis indium oxide catalyzes acetylene hydrogenation with high selectivity to ethylene (>85\\u2009%); even with a large excess of the alkene. in\\u2005situ characterization reveals the formation of oxygen vacancies under reaction conditions, while an in depth theoretical analysis links the surface reduction with the creation of well-defined vacancies and surrounding in3 o5 ensembles, which are considered responsible for this outstanding catalytic function. this behavior, which differs from that of other common reducible oxides, originates from the presence of four crystallographically inequivalent oxygen sites in the indium oxide surface. these resulting ensembles are 1)\\u2005stable against deactivation, 2)\\u2005homogeneously and densely distributed, and 3)\\u2005spatially isolated and confined against transport; thereby broadening the scope of oxides in hydrogenation catalysis.",
            "contribution_ids": [
                "R25854"
            ]
        },
        {
            "instance_id": "R25900xR25865",
            "comparison_id": "R25900",
            "paper_id": "R25865",
            "text": "Pd-Pb Alloy Nanocrystals with Tailored Composition for Semihydrogenation: Taking Advantage of Catalyst Poisoning metallic nanocrystals (ncs) with well-defined sizes and shapes represent a new family of model systems for establishing structure-function relationships in heterogeneous catalysis. here in this study, we show that catalyst poisoning can be utilized as an efficient strategy for nanocrystals shape and composition control, as well as a way to tune the catalytic activity of catalysts. lead species, a well-known poison for noble-metal catalysts, was investigated in the growth of pd ncs. we discovered that pb atoms can be incorporated into the lattice of pd ncs and form pd-pb alloy ncs with tunable composition and crystal facets. as model catalysts, the alloy ncs with different compositions showed different selectivity in the semihydrogenation of phenylacetylene. pd-pb alloy ncs with better selectivity than that of the commercial lindlar catalyst were discovered. this study exemplified that the poisoning effect in catalysis can be explored as efficient shape-directing reagents in nc growth, and more importantly, as a strategy to tailor the performance of catalysts with high selectivity.",
            "contribution_ids": [
                "R25866",
                "R25867"
            ]
        },
        {
            "instance_id": "R25900xR25872",
            "comparison_id": "R25900",
            "paper_id": "R25872",
            "text": "Metal-Ligand Core-Shell Nanocomposite Catalysts for the Selective Semihydrogenation of Alkynes in recent years, hybrid nanocomposites with core\u2013shell structures have increasingly attracted enormous attention in many important research areas such as quantum dots, optical, magnetic, and electronic devices, and catalysts. in the catalytic applications of core\u2013shell materials, core-metals having magnetic properties enable easy separation of the catalysts from the reaction mixtures by a magnet. the core-metals can also affect the active shell-metals, delivering significant improvements in their activities and selectivities. however, it is difficult for core-metals to act directly as the catalytic active species because they are entirely covered by the shell. thus, few successful designs of core\u2013shell nanocomposite catalysts having active metal species in the core have appeared to date. recently, we have demonstrated the design of a core\u2013shell catalyst consisting of active metal nanoparticles (nps) in the core and closely assembled oxides with nano-gaps in the shell, allowing the access of substrates to the core-metal. the shell acted as a macro ligand (shell ligand) for the core-metal and the core\u2013shell structure maximized the metal\u2013ligand interaction (ligand effect), promoting highly selective reactions. the design concept of core\u2013shell catalysts having core-metal nps with a shell ligand is highly useful for selective organic transformations owing to the ideal structure of these catalysts for maximizing the ligand effect, leading to superior catalytic performances compared to those of conventional supported metal nps. semihydrogenation of alkynes is a powerful tool to synthesize (z)-alkenes which are important building blocks for fine chemicals, such as bioactive molecules, flavors, and natural products. in this context, the lindlar catalyst (pd/ caco3 treated with pb(oac)2) has been widely used. [13] unfortunately, the lindlar catalyst has serious drawbacks including the requirement of a toxic lead salt and the addition of large amounts of quinoline to suppress the over-hydrogenation of the product alkenes. furthermore, the lindlar catalyst has a limited substrate scope; terminal alkynes cannot be converted selectively into terminal alkenes because of the rapid over-hydrogenation of the resulting alkenes to alkanes. aiming at the development of environmentally benign catalyst systems, a number of alternative lead-free catalysts have been reported. 15] recently, we also developed a leadfree catalytic system for the selective semihydrogenation consisting of sio2-supported pd nanoparticles (pdnps) and dimethylsulfoxide (dmso), in which the addition of dmso drastically suppressed the over-hydrogenation and isomerization of the alkene products even after complete consumption of the alkynes. this effect is due to the coordination of dmso to the pdnps. dmso adsorbed on the surface of pdnps inhibits the coordination of alkenes to the pdnps, while alkynes can adsorb onto the pdnps surface because they have a higher coordination ability than dmso. this phenomenon inspired us to design pdnps coordinated with a dmso-like species in a solid matrix. if a core\u2013shell structured nanocomposite involving pdnps encapsulated by a shell having a dmso-like species could be constructed, it would act as an efficient and functional solid catalyst for the selective semihydrogenation of alkynes. herein, we successfully synthesized core\u2013shell nanocomposites of pdnps covered with a dmso-like matrix on the surface of sio2 (pd@mpso/sio2). the shell, consisting of an alkyl sulfoxide network, acted as a macroligand and allowed the selective access of alkynes to the active center of the pdnps, promoting the selective semihydrogenation of not only internal but also terminal alkynes without any additives. moreover, these catalysts were reusable while maintaining high activity and selectivity. pd@mpso/sio2 catalysts were synthesized as follows. pd/ sio2 prepared according to our procedure [16] was stirred in n-heptane with small amounts of 3,5-di-tert-butyl-4-hydroxytoluene (bht) and water at room temperature. next, methyl3-trimethoxysilylpropylsulfoxide (mpso) was added to the mixture and the mixture was heated. the slurry obtained was collected by filtration, washed, and dried in vacuo, affording pd@mpso/sio2 as a gray powder. altering the molar ratios of mpso to pd gave two kinds of catalysts: pd@mpso/sio21 (mpso:pd = 7:1), and pd@mpso/sio2-2 (mpso:pd = 100:1). [*] dr. t. mitsudome, y. takahashi, dr. t. mizugaki, prof. dr. k. jitsukawa, prof. dr. k. kaneda department of materials engineering science graduate school of engineering science, osaka university 1\u20133, machikaneyama, toyonaka, osaka 560-8531 (japan) e-mail: kaneda@cheng.es.osaka-u.ac.jp",
            "contribution_ids": [
                "R25873"
            ]
        },
        {
            "instance_id": "R25900xR25874",
            "comparison_id": "R25900",
            "paper_id": "R25874",
            "text": "Dual Pd and CuFe2O4 nanoparticles encapsulated in a core/shell silica microsphere for selective hydrogenation of arylacetylenes a dual catalyst containing pd and cufe(2)o(4) nanoparticles in a silica shell exhibits >98% conversion of arylacetylenes to related styrenes with selectivity greater than 98%, which are better than those obtained using a commercial lindlar catalyst. the excellent synergy was likely a result of the proximal interaction between pd and cufe(2)o(4) nanoparticles.",
            "contribution_ids": [
                "R25875"
            ]
        },
        {
            "instance_id": "R25900xR25878",
            "comparison_id": "R25900",
            "paper_id": "R25878",
            "text": "Selective Semihydrogenation of Alkynes Catalyzed by Pd Nanoparticles Immobilized on Heteroatom-Doped Hierarchical Porous Carbon Derived from Bamboo Shoots highly dispersed palladium nanoparticles (pd nps) immobilized on heteroatom-doped hierarchical porous carbon supports (n,o-carbon) with large specific surface areas are synthesized by a wet chemical reduction method. the n,o-carbon derived from naturally abundant bamboo shoots is fabricated by a tandem hydrothermal-carbonization process without assistance of any templates, chemical activation reagents, or exogenous n or o sources in a simple and ecofriendly manner. the prepared pd/n,o-carbon catalyst shows extremely high activity and excellent chemoselectivity for semihydrogenation of a broad range of alkynes to versatile and valuable alkenes under ambient conditions. the catalyst can be readily recovered for successive reuse with negligible loss in activity and selectivity, and is also applicable for practical gram-scale reactions.",
            "contribution_ids": [
                "R25879"
            ]
        },
        {
            "instance_id": "R25900xR25880",
            "comparison_id": "R25900",
            "paper_id": "R25880",
            "text": "Palladium nanoparticles supported on mpg-C3N4 as active catalyst for semihydrogenation of phenylacetylene under mild conditions pd-nanoparticles supported on mesoporous graphitic carbon nitride is found to be an effective, heterogeneous catalyst for the liquid-phase semihydrogenation of phenylacetylenes under mild conditions.",
            "contribution_ids": [
                "R25881"
            ]
        },
        {
            "instance_id": "R25900xR25886",
            "comparison_id": "R25900",
            "paper_id": "R25886",
            "text": "Achieving the Trade-Off between Selectivity and Activity in Semihydrogenation of Alkynes by Fabrication of (Asymmetrical Pd@Ag Core)@(CeO2 Shell) Nanocatalysts via Autoredox Reaction (asymmetrical pd@ag core)@(ceo2 shell) nanostructures are successfully fabricated via a clean and facile modified autoredox reaction by the preaddition of pd seeds in the growth solution. in a subsequent catalytic test, it is found that the as-obtained bimetallic core@shell nanoparticles exhibit excellent catalytic performance in semihydrogenation of alkynes. the trade-off between selectivity and activity is well realized.",
            "contribution_ids": [
                "R25887"
            ]
        },
        {
            "instance_id": "R25999xR25983",
            "comparison_id": "R25999",
            "paper_id": "R25983",
            "text": "Using stochastic syntactic analysis for extracting a logical structure from a document image \"a method of stochastic syntactic analysis is applied to extracting the logical structure of a printed document from its physical layout and keywords indicating logical components. the document is parsed as a sentence consisting of text lines and graphic objects according to a stochastic regular grammar with attributes. by using stochastic analysis, the parser can retain possible results in order of their probability, and thus, if ambiguity occurs, it selects an optimal result more appropriately than deterministic systems. a mark up system applying the method was constructed, and 87% of the logical components of manuals and 82% of those of technical papers are correctly marked up. the rate improved to 89% when the second candidates were considered, showing the advantage of the authors' approach over the deterministic approach.\"",
            "contribution_ids": [
                "R25984",
                "R26010"
            ]
        },
        {
            "instance_id": "R26063xR26023",
            "comparison_id": "R26063",
            "paper_id": "R26023",
            "text": "Two Dimensional Displacement-Stress Distributions in Adhesive Bonded Composite Structures abstract computerized analysis of composite structures formed by the adhesive bonding of materials is presented. the adhesive is considered to be a part of a linearly elastic system whose components are individually characterized by two bulk property elastic constants. solution is obtained by finite difference minimization of the internal energy distribution in a discretized, piecewise homogeneous continuum. the plane-stress, plane-strain problems are considered, and yield displacement and stress distributions for the composite system. displacement and/or stress boundary conditions are allowed. acute contour angles are not allowed. this is the only restriction for otherwise arbitrary plane geometries. results are presented for typical lap shear specimens as well as for a particular case of a butt joint in which a void exists in the adhesive layer.",
            "contribution_ids": [
                "R26024"
            ]
        },
        {
            "instance_id": "R26063xR26027",
            "comparison_id": "R26063",
            "paper_id": "R26027",
            "text": "The efficient design of adhesive bonded joints \"abstract a concise method of analysis is used to study the numerous parameters influencing the stress distribution within the adhesive of a single lap joint. the formulation includes transverse shear and normal strain deformations. both isotropic or anisotropic material systems of similar or dissimilar adherends are analysed. results indicate that the primary young's modulus of the adherend, the overlap length, and the adhesive's material properties are the parameters most influential in optimizing the design of a single lap joint.\"",
            "contribution_ids": [
                "R26028"
            ]
        },
        {
            "instance_id": "R26063xR26035",
            "comparison_id": "R26063",
            "paper_id": "R26035",
            "text": "Stresses in Adhesively Bonded Joints: A Closed-Form Solution in this paper the general plane strain problem of adhesively bonded struc tures which consist of two different orthotropic adherends is considered. assuming that the thicknesses of the adherends are constant and are small in relation to the lateral dimensions of the bonded region, the adherends are treated as plates. also, assuming that the thickness of the adhesive is small compared to that of the adherends, the thickness variation of the stresses in the adhesive layer is neglected. however, the transverse shear effects in the adherends and the in-plane normal strain in the adhesive are taken into ac count. the problem is reduced to a system of differential equations for the adhesive stresses which is solved in closed form. a single lap joint and a stif fened plate under various loading conditions are considered as examples. to verify the basic trend of the solutions obtained from the plate theory and to give some idea about the validity of the plate assumption itself, a sample pro blem is solved by using the finite element method and by treating the adherends and the adhesive as elastic continua. it is found that the plate theory used in the analysis not only predicts the correct trend for the adhesive stresses but also gives rather surprisingly accurate results. the solution is ob tained by assuming linear stress-strain relations for the adhesive. in the ap pendix the problem is formulated by using a nonlinear material for the adhesive and by following two different approaches.",
            "contribution_ids": [
                "R26036"
            ]
        },
        {
            "instance_id": "R26107xR26089",
            "comparison_id": "R26107",
            "paper_id": "R26089",
            "text": "Environmental and human factors influencing thermal comfort of office occupants in hot\u00e2\u0080\u0094humid and hot\u00e2\u0080\u0094arid climates the effects of environmental and individual factors on thermal sensation in air-conditioned office environments were analysed for two large, fully compatible thermal comfort field studies in contrasting australian climates. in the hot\u2014humid location of townsville, 836 office workers were surveyed; 935 workers participated in hot\u2014arid kalgoorlie-boulder. overall perceived work area temperature and measured indoor operative temperature correlated moderately with thermal sensation for townsville (t) subjects but only perceived temperature correlated with kalgoorlie-boulder (kb) sensation. multiple regression analyses confirmed that indoor climatic variables (including predicted mean vote) contributed to actual thermal sensation vote (24% t; 15% kb), with operative temperature having more of an effect in t than in kb. subsequent analyses of individual characteristics showed no linear contributions to thermal sensation. the remaining variances were significantly related to perceived work area temperature (7% additional explained variance in t; 12% in kb). mann whitney analyses (after correction for climatic variables) showed that t subjects with higher job satisfaction had thermal sensations closer to \u2018neutral\u2019. males, healthier subjects, non-smokers, respondents with earlier survey times and underweight occupants had lower median thermal sensations in kb. townsville occupants appeared more adapted to their outdoor climatic conditions than kalgoorlie-boulder respondents, perhaps due to limited home air-conditioning. further research into non-thermal impacts on gender-related thermal acceptability is suggested.",
            "contribution_ids": [
                "R26090"
            ]
        },
        {
            "instance_id": "R26107xR26105",
            "comparison_id": "R26107",
            "paper_id": "R26105",
            "text": "Subjective indoor air quality in schools in relation to exposure this paper presents data on indoor air quality in schools as perceived by those working in them and relates these data to exposure measurements. data on subjective air quality, domestic exposures and health aspects were gathered by means of a questionnaire which was sent to all personnel in 38 schools; it was completed by 1410 persons (85\u20194 of the total). data on exposure were gathered by exposure measurements in classrooms. the results indicate that 53% of the personnel perceived the indoor air quality as bad or very bad. it was perceived as worse by those who were younger, those who were dissatisfied with their psychosocial work climate and those who were not exposed to tobacco smoke at home. in older school buildings and buildings with displacement ventilation there was less dissatisfaction with the air quality. there were no significant relations between complaints and air exchange rate or concentration of carbon dioxide. the air quality was perceived as worse at higher levels of exposure to a number of airborne compounds including volatile organic compounds, moulds, bacteria and respirable dust. it was concluded that exposure to indoor pollutants affects perception even at the low concentrations normally found indoors in nonindustrial buildings.",
            "contribution_ids": [
                "R26106"
            ]
        },
        {
            "instance_id": "R26127xR26115",
            "comparison_id": "R26127",
            "paper_id": "R26115",
            "text": "The underground economy in the United States: Reply to comments by Feige, Thomas, and Zilberfarb the fate that an author should dread the most is to see his/her writings ignored. while i have experienced this fate with some of my writings, this is definitely not what has happened to my articles on the underground economy in the united states. for these i have been \"flattered\" by more attention than i would perhaps have liked. the three comments and criticisms discussed here are quite different: they deal in part with the methodology of my work in this area and in part with the empirical results. there are several ways in which i could deal with them but perhaps the simplest is to take the authors\\' comments alphabetically. i shall allocate far more space to feige\\'s \"comment\" than to the other two, largely because his is not just a comment on my paper but is also an attempt to \"sell\" his work to the readers of staff papers. thus, i must inevitably discuss his method and results while attempting to answer his specific criticism of my work.",
            "contribution_ids": [
                "R26116"
            ]
        },
        {
            "instance_id": "R26146xR26128",
            "comparison_id": "R26146",
            "paper_id": "R26128",
            "text": "Small scale entrepreneurs in Ghana and development planning summary this article attempts an assessment of entrepreneurial contributions to the solution of some of the objectives of central economic development planning\u2014contributions which are ignored by planners for reasons that are described in this social anthropological study of one aspect of economic development in ghana. the author wishes to express his gratitude to the managers of the smuts\u2019 memorial fund for providing much of his financial backing during field\u2010work; also to the ling roth fund, the anthony wilkin fund, the bartle frere fund, the mary euphrasia mosley fund, the west african research unit, and the warmington fund. he held a department of education and science studentship during the years 1965\u201368. the author also wishes to thank jack goody, esther goody, enid schild\u2010krout and jeremy eades for discussing a preliminary draft of this paper; and marion pearsall for comments on later versions; richard cornes and mike faber have also been most helpful. responsibility for the final draft is entirely ...",
            "contribution_ids": [
                "R26129"
            ]
        },
        {
            "instance_id": "R26194xR26156",
            "comparison_id": "R26194",
            "paper_id": "R26156",
            "text": "A Combined Vehicle Routing and Inventory Allocation Problem we address the combined problem of allocating a scarce resource among several locations, and planning deliveries using a fleet of vehicles. demands are random, and holding and shortage costs must be considered in the decision along with transportation costs. we show how to extend some of the available methods for the deterministic vehicle routing problem to this case. computational results using one such adaptation show that the algorithm is fast enough for practical work, and that substantial cost savings can be achieved with this approach.",
            "contribution_ids": [
                "R26157"
            ]
        },
        {
            "instance_id": "R26194xR26173",
            "comparison_id": "R26194",
            "paper_id": "R26173",
            "text": "An Integrated Inventory Allocation and Vehicle Routing Problem we address the problem of distributing a limited amount of inventory among customers using a fleet of vehicles so as to maximize profit. both the inventory allocation and the vehicle routing problems are important logistical decisions. in many practical situations, these two decisions are closely interrelated, and therefore, require a systematic approach to take into account both activities jointly. we formulate the integrated problem as a mixed integer program and develop a lagrangian-based procedure to generate both good upper bounds and heuristic solutions. computational results show that the procedure is able to generate solutions with small gaps between the upper and lower bounds for a wide range of cost structures.",
            "contribution_ids": [
                "R26174"
            ]
        },
        {
            "instance_id": "R26194xR26175",
            "comparison_id": "R26194",
            "paper_id": "R26175",
            "text": "Stochastic Inventory Routing: Route Design with Stockouts and Route Failures \" the stochastic inventory routing problem involves the distribution of a commodity such as heating oil over a long period of time to a large set of customers. the customers maintain a local inventory of the commodity which they consume at a daily rate. their consumption varies daily and seasonally and their exact demand is known only upon the arrival of the delivery vehicle. this paper presentes a detailed analysis of this problem incorporating the stochastic nature of customers' consumptions and the possibility of route failures when the actual demand on a route exceeds the capacity of a vehicle. a number of solution procedures are compared on a large set of real life data for a period of 12 consecutive weeks. the winning strategy, though computationally more expensive, provides the best system performance and reduces (almost eliminates) the stockout phenomena. \"",
            "contribution_ids": [
                "R26176"
            ]
        },
        {
            "instance_id": "R26262xR26244",
            "comparison_id": "R26262",
            "paper_id": "R26244",
            "text": "A branch-and-cut algorithm for a vendor-managed inventory-routing problem we consider a distribution problem in which a product has to be shipped from a supplier to several retailers over a given time horizon. each retailer defines a maximum inventory level. the supplier monitors the inventory of each retailer and determines its replenishment policy, guaranteeing that no stockout occurs at the retailer (vendor-managed inventory policy). every time a retailer is visited, the quantity delivered by the supplier is such that the maximum inventory level is reached (deterministic order-up-to level policy). shipments from the supplier to the retailers are performed by a vehicle of given capacity. the problem is to determine for each discrete time instant the quantity to ship to each retailer and the vehicle route. we present a mixed-integer linear programming model and derive new additional valid inequalities used to strengthen the linear relaxation of the model. we implement a branch-and-cut algorithm to solve the model optimally. we then compare the optimal solution of the problem with the optimal solution of two problems obtained by relaxing in different ways the deterministic order-up-to level policy. computational results are presented on a set of randomly generated problem instances.",
            "contribution_ids": [
                "R26245"
            ]
        },
        {
            "instance_id": "R26352xR26274",
            "comparison_id": "R26352",
            "paper_id": "R26274",
            "text": "Two-echelon distribution systems with vehicle routing costs and central inventory we consider distribution systems with a single depot and many retailers each of which faces external demands for a single item that occurs at a specific deterministic demand rate. all stock enters the systems through the depot where it can be stored and then picked up and distributed to the retailers by a fleet of vehicles, combining deliveries into efficient routes. we extend earlier methods for obtaining low complexity lower bounds and heuristics for systems without central stock. we show under mild probabilistic assumptions that the generated solutions and bounds come asymptotically within a few percentage points of optimality (within the considered class of strategies). a numerical study exhibits the performance of these heuristics and bounds for problems of moderate size.",
            "contribution_ids": [
                "R26275"
            ]
        },
        {
            "instance_id": "R26352xR26279",
            "comparison_id": "R26352",
            "paper_id": "R26279",
            "text": "A Markov Decision Model and Decomposition Heuristic for Dynamic Vehicle Dispatching \" we describe a dynamic and stochastic vehicle dispatching problem called the delivery dispatching problem. this problem is modeled as a markov decision process. because exact solution of this model is impractical, we adopt a heuristic approach for handling the problem. the heuristic is based in part on a decomposition of the problem by customer, where customer subproblems generate penalty functions that are applied in a master dispatching problem. we describe how to compute bounds on the algorithm's performance, and apply it to several examples with good results. \"",
            "contribution_ids": [
                "R26280"
            ]
        },
        {
            "instance_id": "R26352xR26288",
            "comparison_id": "R26352",
            "paper_id": "R26288",
            "text": "A Location Based Heuristic for General Routing Problems we present a general framework for modeling routing problems based on formulating them as a traditional location problem called the capacitated concentrator location problem. we apply this framework to two classical routing problems: the capacitated vehicle routing problem and the inventory routing problem. in the former case, the heuristic is proven to be asymptotically optimal for any distribution of customer demands and locations. computational experiments show that the heuristic performs well for both problems and, in most cases, outperforms all published heuristics on a set of standard test problems.",
            "contribution_ids": [
                "R26289"
            ]
        },
        {
            "instance_id": "R26352xR26302",
            "comparison_id": "R26352",
            "paper_id": "R26302",
            "text": "Probabilistic Analyses and Algorithms for Three-Level Distribution Systems we consider the problem of integrating inventory control and vehicle routing into a cost-effective strategy for a distribution system consisting of a single outside vendor, a fixed number of warehouses and many geographically dispersed retailers. each retailer faces a constant, retailer specific, demand rate and inventory holding cost is charged at the retailers and the warehouses. we show that, in an effective strategy which minimizes the asymptotic long run average cost, each warehouse receives fully loaded trucks from the vendor but never holds inventory. that is, each warehouse serves only as a coordinator of the frequency, time and sizes of deliveries to the retailers. this insight is used to construct an inventory control policy and vehicle routing strategy for multi-echelon distribution systems. computational results are also reported.",
            "contribution_ids": [
                "R26303"
            ]
        },
        {
            "instance_id": "R26352xR26321",
            "comparison_id": "R26352",
            "paper_id": "R26321",
            "text": "Dynamic Programming Approximations for a Stochastic Inventory Routing Problem this work is motivated by the need to solve the inventory routing problem when implementing a business practice called vendor managed inventory replenishment (vmi). with vmi, vendors monitor their customers\u2032 inventories and decide when and how much inventory should be replenished at each customer. the inventory routing problem attempts to coordinate inventory replenishment and transportation in such a way that the cost is minimized over the long run. we formulate a markov decision process model of the stochastic inventory routing problem and propose approximation methods to find good solutions with reasonable computational effort. we indicate how the proposed approach can be used for other markov decision processes involving the control of multiple resources.",
            "contribution_ids": [
                "R26322"
            ]
        },
        {
            "instance_id": "R26352xR26336",
            "comparison_id": "R26352",
            "paper_id": "R26336",
            "text": "The storage constrained, inbound inventory routing problem purpose this paper aims to describe the storage constrained, inbound inventory routeing problem and presents bounds and heuristics for solutions to this problem. it also seeks to analyze various characteristics of this problem by comparing the solutions generated by the two proposed heuristics with each other and with the lower bound solutions. design/methodology/approach the proposed heuristics use a sequential decomposition strategy for generating solutions for this problem. these heuristics are evaluated on a set of problem instances which are based on an actual application in the automotive manufacturing industry. findings the storage space clearly has a significant effect on both the routeing and inventory decisions, and there are complex and interesting interactions between the problem factors and performance measures. practical implications facility design decisions for the storage of inbound materials should carefully consider the impact of storage space on transportation and logistics costs. originality/value this problem occurs in a number of different industrial applications while most of the existing literature addresses outbound distribution. other papers that address similar problems do not consider all of the practical constraints in the problem or do not adequately benchmark and analyze their proposed solutions.",
            "contribution_ids": [
                "R26337"
            ]
        },
        {
            "instance_id": "R26377xR26359",
            "comparison_id": "R26377",
            "paper_id": "R26359",
            "text": "Reducing Logistics Costs at General Motors \" automobile and truck production at general motors involves shipping a broad variety of materials, parts, and components from 20,000 supplier plants to over 160 gm plants. to help reduce logistics costs at gm, the decision tool transpart was developed. in its initial application for gm's delco electronics division, transpart identified a 26 percent logistics cost savings opportunity ($2.9 million per year). today, transpart ii\u2014a commercial version of the tool\u2014is being used in more than 40 gm plants. \"",
            "contribution_ids": [
                "R26360"
            ]
        },
        {
            "instance_id": "R26421xR26399",
            "comparison_id": "R26421",
            "paper_id": "R26399",
            "text": "Production of Two Chitosanases from a Chitosan-Assimilating Bacterium, Acinetobacter sp. Strain CHB101. a bacterial strain capable of utilizing chitosan as a sole carbon source was isolated from soil and was identified as a member of the genus acinetobacter. this strain, designated chb101, produced extracellular chitosan-degrading enzymes in the absence of chitosan. the chitosan-degrading activity in the culture fluid increased when cultures reached the early stationary phase, although the level of activity was low in the exponential growth phase. two chitosanases, chitosanases i and ii, which had molecular weights of 37,000 and 30,000, respectively, were purified from the culture fluid. chitosanase i exhibited substrate specificity for chitosan that had a low degree of acetylation (10 to 30%), while chitosanase ii degraded colloidal chitin and glycol chitin, as well as chitosan that had a degree of acetylation of 30%. rapid decreases in the viscosities of chitosan solutions suggested that both chitosanases catalyzed an endo type of cleavage reaction; however, chitosan oligomers (molecules smaller than pentamers) were not produced after a prolonged reaction.",
            "contribution_ids": [
                "R26400"
            ]
        },
        {
            "instance_id": "R26421xR26403",
            "comparison_id": "R26421",
            "paper_id": "R26403",
            "text": "Purification and Mode of Action of Chitosanolytic Enzyme fromEnterobactersp. G-1 a chitosanolytic enzyme was purified from enterobacter sp. g-1 by fractionation of 30% saturation with ammonium sulfate, isoelectric focusing, and sephadex g-100 gel chromatography. the purified enzyme. showed a single band on sodium dodecyl sulfate polyacrylamide gel electrophoresis, and the molecular mass was estimated to be 50 kda. the enzyme degraded n-acetyl-chitooligosaccharides, glycol chitin, colloidal chitin, and colloidal chitosan (about 80% deacetylated), but did not degrade chitooligosaccharides, colloidal chitosan (100% deacetylated), or micrococcus lysodeikticus cell walls. it hydrolyzed glcnac4\u20136 and colloidal chitin to glcnac2, finally. the main cleavage site with glcnac3\u20136 was the second linkage from the non-reducing end, based on the pattern of pnp-glcnac2\u20135. colloidal chitosan was hydrolyzed to glcnac2 and to similar partially n-acetylated chitooligosaccharides.",
            "contribution_ids": [
                "R26404"
            ]
        },
        {
            "instance_id": "R26421xR26405",
            "comparison_id": "R26421",
            "paper_id": "R26405",
            "text": "Purification, Characterization, and Gene Analysis of a Chitosanase (ChoA) from Matsuebacter chitosanotabidus3001 abstract \\n \\n the extracellular chitosanase (34,000\\n m \\n r \\n ) produced by a novel gram-negative bacterium\\n matsuebacter chitosanotabidus \\n 3001 was purified. the optimal ph of this chitosanase was 4.0, and the optimal temperature was between 30 and 40\u00b0c. the purified chitosanase was most active on 90% deacetylated colloidal chitosan and glycol chitosan, both of which were hydrolyzed in an endosplitting manner, but this did not hydrolyze chitin, cellulose, or their derivatives. among potential inhibitors, the purified chitosanase was only inhibited by ag\\n + \\n . internal amino acid sequences of the purified chitosanase were obtained. a pcr fragment corresponding to one of these amino acid sequences was then used to screen a genomic library for the entire\\n choa \\n gene encoding chitosanase. sequencing of the\\n choa \\n gene revealed an open reading frame encoding a 391-amino-acid protein. the n-terminal amino acid sequence had an excretion signal, but the sequence did not show any significant homology to other proteins, including known chitosanases. the 80-amino-acid excretion signal of choa fused to green fluorescent protein was functional in\\n escherichia coli \\n . taken together, these results suggest that we have identified a novel, previously unreported chitosanase.\\n",
            "contribution_ids": [
                "R26406"
            ]
        },
        {
            "instance_id": "R26421xR26413",
            "comparison_id": "R26421",
            "paper_id": "R26413",
            "text": "An Aspergillus chitosanase with potential for large-scale preparation of chitosan oligosaccharides a chitosan\u2010degrading fungus, designated aspergillus sp. y2k, was isolated from soil. the micro\u2010organism was used for producing chitosanase (ec 3.2.1.132) in a minimal medium containing chitosan as the sole carbon source. the induced chitosanase was purified to homogeneity from the culture filtrate by concentration and cationic sp\u2010sepharose chromatography. the purified enzyme is a monomer with an estimated molecular mass of 25 kda by sds/page and of 22 kda by gel\u2010filtration chromatography. pi, optimum ph and optimum temperature values were 8.4, 6.5 and 65\u201370 \u00b0c, respectively. the chitosanase is stable in the ph range from 4 to 7.5 at 55 \u00b0c. higher deacetylated chitosan is a better substrate. chitin, xylan, 6\u2010o \u2010sulphated chitosan and o \u2010carboxymethyl chitin were indigestible by the purified enzyme. by endo\u2010splitting activity, the chitosanase hydrolysed chitosan to form chitosan oligomers with chitotriose, chitotetraose and chitopentaose as the major products. the enzyme hydrolyses chitohexaose to form chitotriose, while the chitopentaose and shorter oligomers remain intact. the n\u2010terminal amino acid sequence of the enzyme was determined as ynlpnnlkqiyddhk, which provides useful information for further gene cloning of this enzyme. a 275 g\u2010scale hydrolysis of chitosan was performed. the product distribution was virtually identical to that of the small\u2010scale reaction. owing to the simple purification process and high stability of the enzyme, it is potentially valuable for industrial applications.",
            "contribution_ids": [
                "R26414"
            ]
        },
        {
            "instance_id": "R26550xR26435",
            "comparison_id": "R26550",
            "paper_id": "R26435",
            "text": "Um sistema simples para prepara\u00c3\u00a7\u00c3\u00a3o de microesferas de quitosana this article describes the construction and optimization of an inexpensive apparatus for the production of uniform and porous chitosan microspheres. it also describes the control of the main operational parameters and strategies for the production of uniform chitosan microspheres.",
            "contribution_ids": [
                "R26436"
            ]
        },
        {
            "instance_id": "R26550xR26471",
            "comparison_id": "R26550",
            "paper_id": "R26471",
            "text": "Antidiabetic Effects of Chitosan Oligosaccharides in Neonatal Streptozotocin-Induced Noninsulin-Dependent Diabetes Mellitus in Rats the antidiabetic effect of chitosan oligosaccharide (cos) was investigated in neonatal streptozotocin (stz)-induced noninsulin-dependent diabetes mellitus rats. the fasting glucose level was reduced by about 19% in diabetic rats after treatment with 0.3% cos. glucose tolerance was lower in the diabetic group compared with the normal group. after diabetic rats had been treated with 0.3% cos for 4 weeks, glucose tolerance increased significantly versus the diabetic control group, and glucose-inducible insulin expression increased significantly. in addition, fed-triglyceride (tg) levels in diabetic rats drinking 0.3% cos were reduced by 49% compared with those in diabetic control rats. the cholesterol levels of animals treated with cos were reduced by about 10% in fed or fasting conditions versus the corresponding controls, although the difference was not statistically significant. it was found that cos has a tg-lowering effect in diabetic rats, and that cos reduces signs of diabetic cardiomyopathy such as vacuolation of mitochondria and the separation and degeneration of myofibrils. in conclusion, these results indicate that cos can be used as an antidiabetic agent because it increases glucose tolerance and insulin secretion and decreases tg.",
            "contribution_ids": [
                "R26472"
            ]
        },
        {
            "instance_id": "R26550xR26477",
            "comparison_id": "R26550",
            "paper_id": "R26477",
            "text": "Chitosan Induces Apoptosis via Caspase-3 Activation in Bladder Tumor Cells recently, because of its low toxicity and biological effects, chitosan has been widely used in the medical and pharmaceutical fields, e.g., for nasal or oral delivery of peptide or polar drug delivery. here, we report a growth\u2010inhibitory effect of chitosan on tumor cells. the growth inhibition was examined by wst\u20101 colorimetric assay and cell counting. we also observed dna fragmentation, which is characteristic of apoptosis, and elevated caspase\u20103\u2010like activity in chitosan\u2010treated cancer cells. the findings suggest that chitosan may have potential value in cancer therapy.",
            "contribution_ids": [
                "R26478"
            ]
        },
        {
            "instance_id": "R26550xR26489",
            "comparison_id": "R26550",
            "paper_id": "R26489",
            "text": "EFFECTS OF SHRIMP (MACROBRACIUM ROSENBERGII)-DERIVED CHITOSAN ON PLASMA LIPID PROFILE AND LIVER LIPID PEROXIDE LEVELS IN NORMO- AND HYPERCHOLESTEROLAEMIC RATS 1 the effects of chitosan (cs) derived from the exoskeleton of the shrimp macrobracium rosenbergii on bodyweight, plasma lipid profile, fatty acid composition, liver lipid peroxide (lpo) levels and plasma levels of glutamate pyruvate transaminase (gpt) were determined in normocholesterolaemic (nc) and hypercholesterolaemic (hc) long evans rats. 2 the nc rats were fed a diet containing 2% cs and the hc rats were fed a diet containing 2 and 4% cs for 8 weeks. chitosan significantly reduced bodyweight gain only in hc + 4% cs rats compared with hc rats, but not in nc + 2% cs or hc + 2% cs rats. 3 chitosan reduced plasma total cholesterol in the hc + 2% cs, hc + 4% cs and nc + 2% cs rats; however, low density lipoprotein\u2013cholesterol decreased only in the first two groups. high\u2010density lipoprotein\u2013cholesterol (hdl\u2010c) increased in the hc + 4% cs rats by 24% compared with the hc + 2% cs group and by 30% compared with hc rats; however, hdl\u2010c did not increase in the nc + 2% cs group compared with nc rats. the level of plasma triglycerides decreased significantly only in hc + 2% cs rats compared with hc rats. 4 chitosan significantly decreased plasma levels of arachidonic acid in the hc + 2% cs and hc + 4% cs groups, with a concurrent increase in the molar ratio of total unsaturated fatty acid (tufa) to total saturated fatty acid (tsfa). 5 moreover, cs increased liver lpo levels without affecting plasma levels of gpt. liver lpo levels were positively correlated with the tufa/tsfa molar ratio. 6 the present study suggests that dietary cs decreases the atherogenic lipid profiles of both nc and hc rats and reduces the bodyweight gain of hc rats.",
            "contribution_ids": [
                "R26490"
            ]
        },
        {
            "instance_id": "R26550xR26524",
            "comparison_id": "R26550",
            "paper_id": "R26524",
            "text": "Antimicrobial actions of degraded and native chitosan against spoilage organisms in laboratory media and foods abstract \\n the objective of this study was to determine whether chitosan (poly-\u03b2-1,4-glucosamine) and hydrolysates of chitosan can be used as novel preservatives in foods. chitosan was hydrolyzed by using oxidative-reductive degradation, crude papaya latex, and lysozyme. mild hydrolysis of chitosan resulted in improved microbial inactivation in saline and greater inhibition of growth of several spoilage yeasts in laboratory media, but highly degraded products of chitosan exhibited no antimicrobial activity. in pasteurized apple-elderflower juice stored at 7\u00b0c, addition of 0.3 g of chitosan per liter eliminated yeasts entirely for the duration of the experiment (13 days), while the total counts and the lactic acid bacterial counts increased at a slower rate than they increased in the control. addition of 0.3 or 1.0 g of chitosan per kg had no effect on the microbial flora of houmous, a chickpea dip; in the presence of 5.0 g of chitosan per kg, bacterial growth but not yeast growth was substantially reduced compared with growth in control dip stored at 7\u00b0c for 6 days. improved antimicrobial potency of chitosan hydrolysates like that observed in the saline and laboratory medium experiments was not observed in juice and dip experiments. we concluded that native chitosan has potential for use as a preservative in certain types of food but that the increase in antimicrobial activity that occurs following partial hydrolysis is too small to justify the extra processing involved.",
            "contribution_ids": [
                "R26525"
            ]
        },
        {
            "instance_id": "R26550xR26527",
            "comparison_id": "R26550",
            "paper_id": "R26527",
            "text": "Antimicrobial Edible Films and Coatings increasing consumer demand for microbiologicallysafer foods, greater convenience,smaller packages, and longer product shelf life is forcing the industry to develop new food-processing,cooking, handling, and packaging strategies. nonfluid ready-to-eat foods are frequently exposed to postprocess surface contamination, leading to a reduction in shelf life. the food industry has at its disposal a wide range of nonedible polypropylene- and polyethylene-based packaging materials and various biodegradable protein- and polysaccharide-based edible films that can potentially serve as packaging materials. research on the use of edible films as packaging materials continues because of the potential for these films to enhance food quality, food safety, and product shelf life. besides acting as a barrier against mass diffusion (moisture, gases, and volatiles), edible films can serve as carriers for a wide range of food additives, including flavoring agents, antioxidants, vitamins, and colorants. when antimicrobial agents such as benzoic acid, sorbic acid, propionic acid, lactic acid, nisin, and lysozyme have been incorporated into edible films, such films retarded surface growth of bacteria, yeasts, and molds on a wide range of products, including meats and cheeses. various antimicrobial edible films have been developed to minimize growth of spoilage and pathogenic microorganisms, including listeria monocytogenes, which may contaminate the surface of cooked ready-to-eat foods after processing. here, we review the various types of protein-based (wheat gluten, collagen, corn zein, soy, casein, and whey protein), polysaccharide-based (cellulose, chitosan, alginate, starch, pectin, and dextrin), and lipid-based (waxes, acylglycerols, and fatty acids) edible films and a wide range of antimicrobial agents that have been or could potentially be incorporated into such films during manufacture to enhance the safety and shelf life of ready-to-eat foods.",
            "contribution_ids": [
                "R26528"
            ]
        },
        {
            "instance_id": "R26654xR26624",
            "comparison_id": "R26654",
            "paper_id": "R26624",
            "text": "APTEEN: a hybrid protocol for efficient routing and comprehensive information retrieval in wireless wireless sensor networks with thousands of tiny sensor nodes, are expected to find wide applicability and increasing deployment in coming years, as they enable reliable monitoring and analysis of the environment. in this paper, we propose a hybrid routing protocol (apteen) which allows for comprehensive information retrieval. the nodes in such a network not only react to time-critical situations, but also give an overall picture of the network at periodic intervals in a very energy efficient manner. such a network enables the user to request past, present and future data from the network in the form of historical, one-time and persistent queries respectively. we evaluated the performance of these protocols and observe that these protocols are observed to outperform existing protocols in terms of energy consumption and longevity of the network.",
            "contribution_ids": [
                "R26625"
            ]
        },
        {
            "instance_id": "R26654xR26631",
            "comparison_id": "R26654",
            "paper_id": "R26631",
            "text": "Low energy adaptive clustering hierarchy with deterministic cluster-head selection \"this paper focuses on reducing the power consumption of wireless microsensor networks. therefore, a communication protocol named leach (low-energy adaptive clustering hierarchy) is modified. we extend leach's stochastic cluster-head selection algorithm by a deterministic component. depending on the network configuration an increase of network lifetime by about 30% can be accomplished. furthermore, we present a new approach to define lifetime of microsensor networks using three new metrics fnd (first node dies), hna (half of the nodes alive), and lnd (last node dies).\"",
            "contribution_ids": [
                "R26632"
            ]
        },
        {
            "instance_id": "R26654xR26652",
            "comparison_id": "R26654",
            "paper_id": "R26652",
            "text": "Distance based thresholds for cluster head selection in wireless sensor networks central to the cluster-based routing protocols is the cluster head (ch) selection procedure that allows even distribution of energy consumption among the sensors, and therefore prolonging the lifespan of a sensor network. we propose a distributed ch selection algorithm that takes into account the distances from sensors to a base station that optimally balances the energy consumption among the sensors. ns-2 simulations show that our proposed scheme outperforms existing algorithms in terms of the average node lifespan and the time to first node death.",
            "contribution_ids": [
                "R26653"
            ]
        },
        {
            "instance_id": "R26729xR26679",
            "comparison_id": "R26729",
            "paper_id": "R26679",
            "text": "Distributed clustering with directional antennas for wireless sensor networks this paper proposes a decentralized algorithm for organizing an ad hoc sensor network into clusters with directional antennas. the proposed autonomous clustering scheme aims to reduce the sensing redundancy and maintain sufficient sensing coverage and network connectivity in sensor networks. with directional antennas, random waiting timers, and local criterions, cluster performance may be substantially improved and sensing redundancy can be drastically suppressed. the simulation results show that the proposed scheme achieves connected coverage and provides efficient network topology management.",
            "contribution_ids": [
                "R26680"
            ]
        },
        {
            "instance_id": "R26729xR26704",
            "comparison_id": "R26729",
            "paper_id": "R26704",
            "text": "A centralized energy-efficient routing protocol for wireless sensor networks wireless sensor networks consist of small battery powered devices with limited energy resources. once deployed, the small sensor nodes are usually inaccessible to the user, and thus replacement of the energy source is not feasible. hence, energy efficiency is a key design issue that needs to be enhanced in order to improve the life span of the network. several network layer protocols have been proposed to improve the effective lifetime of a network with a limited energy supply. in this article we propose a centralized routing protocol called base-station controlled dynamic clustering protocol (bcdcp), which distributes the energy dissipation evenly among all sensor nodes to improve network lifetime and average energy savings. the performance of bcdcp is then compared to clustering-based schemes such as low-energy adaptive clustering hierarchy (leach), leach-centralized (leach-c), and power-efficient gathering in sensor information systems (pegasis). simulation results show that bcdcp reduces overall energy consumption and improves network lifetime over its comparatives.",
            "contribution_ids": [
                "R26705"
            ]
        },
        {
            "instance_id": "R26729xR26727",
            "comparison_id": "R26729",
            "paper_id": "R26727",
            "text": "LCM: A Link-Aware Clustering Mechanism for Energy-Efficient Routing in Wireless Sensor Networks in wireless sensor networks, nodes in the area of interest must report sensing readings to the sink, and this report always satisfies the report frequency required by the sink. this paper proposes a link-aware clustering mechanism, called lcm, to determine an energy-efficient and reliable routing path. the lcm primarily considers node status and link condition, and uses a novel clustering metric called the predicted transmission count (ptx), to evaluate the qualification of nodes for clusterheads and gateways to construct clusters. each clusterhead or gateway candidate depends on the ptx to derive its priority, and the candidate with the highest priority becomes the clusterhead or gateway. simulation results validate that the proposed lcm significantly outperforms the clustering mechanisms using random selection and by considering only link quality and residual energy in the packet delivery ratio, energy consumption, and delivery latency.",
            "contribution_ids": [
                "R26728"
            ]
        },
        {
            "instance_id": "R26775xR26739",
            "comparison_id": "R26775",
            "paper_id": "R26739",
            "text": "PRODUCE: A Probability-Driven Unequal Clustering Mechanism for Wireless Sensor Networks there has been proliferation of research on seeking for distributing the energy consumption among nodes in each cluster and between cluster heads to extend the network lifetime. however, they hardly consider the hot spots problem caused by heavy relay traffic forwarded. in this paper, we propose a distributed and randomized clustering algorithm that consists of unequal sized clusters. the cluster heads closer to the base station may focus more on inter-cluster communication while distant cluster heads concentrate more on intra-cluster communication. as a result, it nearly guarantees no communication in the network gets excessively long communication distance that significantly attenuates signal strength. simulation results show that our algorithm achieves abundant improvement in terms of the coverage time and network lifetime, especially when the density of distributed nodes is high.",
            "contribution_ids": [
                "R26740"
            ]
        },
        {
            "instance_id": "R26775xR26754",
            "comparison_id": "R26775",
            "paper_id": "R26754",
            "text": "An Energy-Aware Distributed Unequal Clustering Protocol for Wireless Sensor Networks due to the imbalance of energy consumption of nodes in wireless sensor networks (wsns), some local nodes die prematurely, which causes the network partitions and then shortens the lifetime of the network. the phenomenon is called \u201chot spot\u201d or \u201cenergy hole\u201d problem. for this problem, an energy-aware distributed unequal clustering protocol (eaduc) in multihop heterogeneous wsns is proposed. compared with the previous protocols, the cluster heads obtained by eaduc can achieve balanced energy, good distribution, and seamless coverage for all the nodes. moreover, the complexity of time and control message is low. simulation experiments show that eaduc can prolong the lifetime of the network significantly.",
            "contribution_ids": [
                "R26755"
            ]
        },
        {
            "instance_id": "R26775xR26757",
            "comparison_id": "R26775",
            "paper_id": "R26757",
            "text": "Unequal clustering scheme based leach for wireless sensor networks clustering technique is an effective topology control approach which can improve the scalability and lifetime in wireless sensor networks (wsns). leach is a classical clustering algorithm for low energy scheme, however, it still have some deficiencies. this paper studies leach protocol, and put an improved leach protocol which has more reasonable set-up phase. in the cluster heads election phase, we put the energy ratio and competition distance as two elements to join the cluster head election. simulation results demonstrate that improved leach algorithm has better energy balance and prolong network lifetime.",
            "contribution_ids": [
                "R26758"
            ]
        },
        {
            "instance_id": "R26850xR26819",
            "comparison_id": "R26850",
            "paper_id": "R26819",
            "text": "The Heterogeneous Vehicle-Routing Game in this paper, we study a cost-allocation problem that arises in a distribution-planning situation at the logistics department at norsk hydro olje ab, stockholm, sweden. we consider the routes from one depot during one day. the total distribution cost for these routes is to be divided among the customers that are visited. this cost-allocation problem is formulated as a vehicle-routing game (vrg), allowing the use of vehicles with different capacities. cost-allocation methods based on different concepts from cooperative game theory, such as the core and the nucleolus, are discussed. a procedure that can be used to investigate whether the core is empty or not is presented, as well as a procedure to compute the nucleolus. computational results for the norsk hydro case are presented and discussed.",
            "contribution_ids": [
                "R26820"
            ]
        },
        {
            "instance_id": "R26850xR26839",
            "comparison_id": "R26850",
            "paper_id": "R26839",
            "text": "Valid inequalities for the fleet size and mix vehicle routing problem with fixed costs in the well\u2010known vehicle routing problem (vrp), a set of identical vehicles located at a central depot is to be optimally routed to supply customers with known demands subject to vehicle capacity constraints. an important variant of the vrp arises when a mixed fleet of vehicles, characterized by different capacities and costs, is available for distribution activities. the problem is known as fleet size and mix vrp with fixed costs fsmf and has several practical applications. in this article, we present a new mixed integer programming formulation for fsmf based on a two\u2010commodity network flow approach. new valid inequalities are proposed to strengthen the linear programming relaxation of the mathematical formulation. the effectiveness of the proposed cuts is extensively tested on benchmark instances. \u00a9 2009 wiley periodicals, inc. networks, 2009",
            "contribution_ids": [
                "R26840"
            ]
        },
        {
            "instance_id": "R26918xR26906",
            "comparison_id": "R26918",
            "paper_id": "R26906",
            "text": "Heuristic Approaches for the Fleet Size and Mix Vehicle Routing Problem with Time Windows the fleet size and mix vehicle routing problem with time windows (fsmvrptw) is the problem of determining, at the same time, the composition and the routing of a fleet of heterogeneous vehicles aimed to serve a given set of customers. the routing problem requires us to design a set of minimum-cost routes originating and terminating at a central depot and serving customers with known demands, within given time windows. this paper develops a constructive insertion heuristic and a metaheuristic algorithm for fsmvrptw. extensive computational experiments on benchmark instances show that the proposed method is robust and efficient, and outperforms the previously published results.",
            "contribution_ids": [
                "R26907"
            ]
        },
        {
            "instance_id": "R26918xR26910",
            "comparison_id": "R26918",
            "paper_id": "R26910",
            "text": "An Effective Multirestart Deterministic Annealing Metaheuristic for the Fleet Size and Mix Vehicle-Routing Problem with Time Windows this paper presents a new deterministic annealing metaheuristic for the fleet size and mix vehicle-routing problem with time windows. the objective is to service, at minimal total cost, a set of customers within their time windows by a heterogeneous capacitated vehicle fleet. first, we motivate and define the problem. we then give a mathematical formulation of the most studied variant in the literature in the form of a mixed-integer linear program. we also suggest an industrially relevant, alternative definition that leads to a linear mixed-integer formulation. the suggested metaheuristic solution method solves both problem variants and comprises three phases. in phase 1, high-quality initial solutions are generated by means of a savings-based heuristic that combines diversification strategies with learning mechanisms. in phase 2, an attempt is made to reduce the number of routes in the initial solution with a new local search procedure. in phase 3, the solution from phase 2 is further improved by a set of four local search operators that are embedded in a deterministic annealing framework to guide the improvement process. some new implementation strategies are also suggested for efficient time window feasibility checks. extensive computational experiments on the 168 benchmark instances have shown that the suggested method outperforms the previously published results and found 167 best-known solutions. experimental results are also given for the new problem variant.",
            "contribution_ids": [
                "R26911"
            ]
        },
        {
            "instance_id": "R26982xR26929",
            "comparison_id": "R26982",
            "paper_id": "R26929",
            "text": "A Decision Support System for Fleet Management: A Linear Programming Approach this paper describes a successful implementation of a decision support system that is used by the fleet management division at north american van lines to plan fleet configuration. at the heart of the system is a large linear programming (lp) model that helps management decide what type of tractors to sell to owner/operators or to trade in each week. the system is used to answer a wide variety of \u201cwhat if\u201d questions, many of which have significant financial impact.",
            "contribution_ids": [
                "R26930"
            ]
        },
        {
            "instance_id": "R26982xR26936",
            "comparison_id": "R26982",
            "paper_id": "R26936",
            "text": "Vehicle fleet planning the road transportation industry planning the composition of a vehicle fleet in order to satisfy transportation service demands is an important resource management activity for any trucking company. its complexity is such, however, that formal fleet management cannot be done adequately without the help of a decision support system. an important part of such a system is the generation of minimal discounted cost plans covering the purchase, replacement, sale, and/or rental of the vehicles necessary to deal with a seasonal stochastic demand. a stochastic programming model is formulated to address this problem. it reduces to a separable program based on information about the service demand, the state of the current fleet, and the cash flows generated by an acquisition/disposal plan. an efficient algorithm for solving the model is also presented. the discussion concerns the operations of a number of canadian road carriers. >",
            "contribution_ids": [
                "R26937"
            ]
        },
        {
            "instance_id": "R27039xR26987",
            "comparison_id": "R27039",
            "paper_id": "R26987",
            "text": "An Industrial Ocean-Cargo Shipping Problem this paper reports the modeling and solution of an industrial ocean-cargo shipping problem. the problem involves the delivery of bulk products from an overseas port to transshipment ports on the atlantic coast, and then over land to customers. the decisions made include the number and the size of ships to charter in each time period during the planning horizon, the number and location of transshipment ports to use, and transportation from ports to customers. the complexity of this problem is compounded by the cost structure, which includes fixed charges in both ship charters and port operations. such a large scale, dynamic, and stochastic problem is reduced to a solvable stationary, deterministic, and cyclical model. the process of modeling the problem and the solution of the resultant mixed integer program are described in detail. recommendations from this study have been implemented.",
            "contribution_ids": [
                "R26988"
            ]
        },
        {
            "instance_id": "R27039xR27002",
            "comparison_id": "R27039",
            "paper_id": "R27002",
            "text": "Scheduling short-term marine transport of bulk products a multinational company uses a personal computer to schedule a fleet of coastal tankers and barges transporting liquid bulk products among plants, distribution centres (tank farms), and industrial customers. a simple spreadsheet interface cloaks a sophisticated optimization-based decision support system and makes this system useable via a varity of natural languages. the dispatchers, whose native language is not english, and some of whom presumably speak no english at all, communicate via the spreadsheet, and view recommended schedules displayed in gantt charts both internationally familiar tools. inside the spreadsheet, a highly detailed simulation can generate every feasible alternate vessel employment schedule, and an integer linear set partitioning model selects one schedule for each vessel so that all loads and deliveries are completed at minimal cost while satisfying all operational requirements. the optimized fleet employment schedule is displyed graphically with hourly time resolution over a planning horizon of 2-3 weeks. each vessel will customarily make several voyages and many port calls to load and unload products during this time.",
            "contribution_ids": [
                "R27003"
            ]
        },
        {
            "instance_id": "R27039xR27005",
            "comparison_id": "R27039",
            "paper_id": "R27005",
            "text": "Fleet management models and algorithms for an oil-tanker routing and scheduling problem this paper explores models and algorithms for routing and scheduling ships in a maritime transportation system. the principal thrust of this research effort is focused on the kuwait petroleum corporation (kpc) problem. this problem is of great economic significance to the state of kuwait, whose economy has been traditionally dominated to a large extent by the oil sector, and any enhancement in the existing ad-hoc scheduling procedure has the potential for significant savings. a mixed-integer programming model for the kpc problem is constructed in this paper. the resulting mathematical formulation is rather complex to solve due to the integrality conditions and the overwhelming size of the problem for a typical demand contract scenario. consequently, an alternate aggregate model that retains the principal features of the kpc problem is formulated. the latter model is computationally far more tractable than the initial model, and a specialized rolling horizon heuristic is developed to solve it. the proposed heuristic procedure enables us to derive solutions for practical sized problems that could not be handled by directly solving even the aggregate model. the initial formulation is solved using cplex-4.0-mip capabilities for a number of relatively small-sized test cases, whereas for larger problem instances, the aggregate formulation is solved using cplex-4.0-mip in concert with the developed rolling horizon heuristic, and related results are reported. an ad-hoc routing procedure that is intended to simulate the current kpc scheduling practice is also described and implemented. the results demonstrate that the proposed approach substantially improves upon the results obtained using the current scheduling practice at kpc.",
            "contribution_ids": [
                "R27006"
            ]
        },
        {
            "instance_id": "R27039xR27027",
            "comparison_id": "R27039",
            "paper_id": "R27027",
            "text": "Ship Routing and Scheduling: Status and Perspectives the objective of this paper is to review the current status of ship routing and scheduling. we focus on literature published during the last decade. because routing and scheduling problems are closely related to many other fleet planning problems, we have divided this review into several parts. we start at the strategic fleet planning level and discuss the design of fleets and sea transport systems. we continue with the tactical and operational fleet planning level and consider problems that comprise various ship routing and scheduling aspects. here, we separately discuss the different modes of operations: industrial, tramp, and liner shipping. finally, we take a glimpse at naval applications and other related problems that do not naturally fall into these categories. the paper also presents some perspectives regarding future developments and use of optimization-based decision-support systems for ship routing and scheduling. several of the trends indicate both accelerating needs for and benefits from such systems and, hopefully, this paper will stimulate further research in this area.",
            "contribution_ids": [
                "R27028"
            ]
        },
        {
            "instance_id": "R27061xR27057",
            "comparison_id": "R27061",
            "paper_id": "R27057",
            "text": "Smart City Development: A Business Process-centric Conceptualisation smart city development has been proposed as a response to urbanisation challenges and changing citizen \\nneeds in the cities. it allows the city as a complex system of systems to be efficient and integrated, in order to \\nwork as a whole, and provide effective services to citizens through its inter-connected sector. this research \\nattempts to conceptualise smart city, by looking at its requirements and components from a process change \\nperspective, not a merely technology-led innovation within a city. in view of that, the research also gains \\nbenefits from the principles of smart city development such as systems thinking approach, city as a system of \\nsystems, and the necessity of systems integration. the outcome of this study emphasises the significance of \\nconsidering a city as a system of systems and necessity of city systems integration and city process change \\nfor smart city development. consequently, the research offers a city process-centric conceptualisation of smart \\ncity.",
            "contribution_ids": [
                "R27058"
            ]
        },
        {
            "instance_id": "R27061xR27059",
            "comparison_id": "R27061",
            "paper_id": "R27059",
            "text": "Using cloud technologies for large-scale house data in smart city in the smart city environment, a wide variety of data are collected from sensors and devices to achieve value-added services. in this paper, we especially focus on data taken from smart houses in the smart city, and propose a platform, called scallop4sc, that stores and processes the large-scale house data. the house data is classified into log data or configuration data. since the amount of the log is extremely large, we introduce the hadoop/mapreduce with a multi-node cluster. on top of this, we use hbase key-value store to manage heterogeneous log data in a schemaless manner. on the other hand, to manage the configuration data, we choose mysql to process various queries to the house data efficiently. we propose practical data models of the log data and the configuration data on hbase and mysql, respectively. we then show how scallop4sc works as a efficient data platform for smart city services. we implement a prototype with 12 linux servers. we conduct an experimental evaluation to calculate device-wise energy consumption, using actual house log recorded for one year in our smart house. based on the result, we discuss the applicability of scallop4sc to city-scale data processing.",
            "contribution_ids": [
                "R27060"
            ]
        },
        {
            "instance_id": "R27235xR27168",
            "comparison_id": "R27235",
            "paper_id": "R27168",
            "text": "Exchange Rate Volatility and International Prices \"we examine how exchange rate volatility affects exporter's pricing decisions in the presence of optimal forward covering. by taking account of forward covering, we are able to derive an expression for the risk premium in the foreign exchange market, which is then estimated as a generalized arch model to obtain the time-dependent variance of the exchange rate. our theory implies a connection between the estimated risk premium equation, and the influence of exchange rate volatility on export prices. in particular, we argue that if there is no risk premium, then exchange rate variance can only have a negative impact on export prices. in the presence of a risk premium, however, the effect of exchange rate variance on export prices is ambiguous, and may be statistically insignificant with aggregate data. these results are supported using data on aggregate u.s. imports and exchange rates of the dollar against the pound. yen and mark.\"",
            "contribution_ids": [
                "R27169"
            ]
        },
        {
            "instance_id": "R27235xR27190",
            "comparison_id": "R27235",
            "paper_id": "R27190",
            "text": "Does Exchange Rate Volatility Depress Trade Flows? Evidence from Error- Correction Models this paper examines the impact of exchange rate volatility on the trade flows of the g-7 countries in the context of a multivariate error-correction model. the error-correction models do not show any sign of parameter instability. the results indicate that the exchange rate volatility has a significant negative impact on the volume of exports in each of the g-7 countries. assuming market participants are risk averse, these results imply that exchange rate uncertainty causes them to reduce their activities, change prices, or shift sources of demand and supply in order to minimize their exposure to the effects of exchange rate volatility. this, in turn, can change the distribution of output across many sectors in these countries. it is quite possible that the surprisingly weak relationship between trade flows and exchange rate volatility reported in several previous studies are due to insufficient attention to the stochastic properties of the relevant time series. copyright 1993 by mit press.",
            "contribution_ids": [
                "R27191"
            ]
        },
        {
            "instance_id": "R27235xR27209",
            "comparison_id": "R27235",
            "paper_id": "R27209",
            "text": "Estimating the impact of exchange rate volatility on exports: evidence from Asian countries the paper examines the impact of exchange rate volatility on the exports of five asian countries. the countries are turkey, south korea, malaysia, indonesia and pakistan. the impact of a volatility term on exports is examined by using an engle-granger residual-based cointegrating technique. the results indicate that the exchange rate volatility reduced real exports for these countries. this might mean that producers in these countries are risk-averse. the producers will prefer to sell in domestic markets rather than foreign markets if the exchange rate volatility increases.",
            "contribution_ids": [
                "R27210"
            ]
        },
        {
            "instance_id": "R27235xR27220",
            "comparison_id": "R27235",
            "paper_id": "R27220",
            "text": "On the Trade Impact of Nominal Exchange Rate Volatility what is the effect of nominal exchange rate variability on trade? i argue that the methods conventionally used to answer this perennial question are plagued by a variety of sources of systematic bias. i propose a novel approach that simultaneously addresses all of these biases, and present new estimates from a broad sample of countries from 1970 to 1997. the answer to the question is: not much.",
            "contribution_ids": [
                "R27221"
            ]
        },
        {
            "instance_id": "R27264xR27259",
            "comparison_id": "R27264",
            "paper_id": "R27259",
            "text": "Cyberbotics ltd. webots professional mobile robot simulation cyberbotics ltd. develops webots \u2122 , a mobile robotics simulation software that provides you with a rapid prototyping environment for modelling, programming and simulating mobile robots. the provided robot libraries enable you to transfer your control programs to several commercially available real mobile robots. webots \u2122 lets you define and modify a complete mobile robotics setup, even several different robots sharing the same environment. for each object, you can define a number of properties, such as shape, color, texture, mass, friction, etc. you can equip each robot with a large number of available sensors and actuators. you can program these robots using your favorite development environment, simulate them and optionally transfer the resulting programs onto your real robots. webots \u2122 has been developed in collaboration with the swiss federal institute of technology in lausanne, thoroughly tested, well documented and continuously maintained for over 7 years. it is now the main commercial product available from cyberbotics ltd.",
            "contribution_ids": [
                "R27260"
            ]
        },
        {
            "instance_id": "R27380xR27281",
            "comparison_id": "R27380",
            "paper_id": "R27281",
            "text": "On the Changes in Residual Stress Produced by Plastic Torsion Due to Repeated Stressing setting process is often practiced on coil springs in order to improve their fatigue resistance and prevent their creep deflection. torsional residual stresses are produced by this process, and it is generally understood that these stresses would play a role in improving the fatigue properties. in this experiment, round bar specimens of the spring steel sup2 were used, and after being twisted by the torsional moment 25% beyond that corresponding to the yield point, they were subjected to the fatigue test in alternating torsion. the distribution of residual stresses was measured by the etching method, by measuring the angle of torsion during the etching process. three stress levels were employed in repeated stressing and the number of stress cycles was made to be the same in each stress level. as a new attempt, we studied the fading of residual stresses under repeated stressing in successive two stress levels.the results obtained are summariaed as follows:(1) residual stresses produced by plastic torsion are of the thermal stress type near the surface, being negative at the surface layers.(2) residual stresses subjected to repeated stressing fade noticeably in the first stage of fading and then gradually with the repetition of stress cycles. in the second stage of fading, the relation obtained between the ratio of surface residual stresses \u03c4r/\u03c4o, (\u03c4r is the current value and \u03c4o is the initial value of surface residual stress) and the logarithm of cycle ratio n/n, formed straight lines, and experimental formulas concerning the fading of residual stresses were established.(3) in repeated stressing under successive two stress levels, the fading of residual stresses is larger in the case of descending stressing than in the case of ascending stressing, when the same numbers of stress cycles are given to each stress level, respectively. hardness has also the same tendency as the residual stress.",
            "contribution_ids": [
                "R27282"
            ]
        },
        {
            "instance_id": "R27380xR27354",
            "comparison_id": "R27380",
            "paper_id": "R27354",
            "text": "Contact fatigue of automotive gears: evolution and effects of residual stresses introduced by surface treatments helical gears from an automotive gearbox, previously subjected to the surface treatments of carbo-nitriding and shot-peening, were submitted to contact fatigue tests. the x-ray diffraction technique was used to characterize the evolution of different mechanical and metallurgical parameters as a function of gear damage. particular attention was paid to residual stress relief. a numerical model was developed to predict residual stress relaxation and estimate the most likely localization of contact fatigue crack initiation. the stress\u2013strain laws of the surface-treated layers were determined by means of two separate experimental methods, based on locally measured parameters. the dang van multiaxial fatigue criterion was used to analyse the failure of the gears, taking into account the effects of friction and roughness.",
            "contribution_ids": [
                "R27355"
            ]
        },
        {
            "instance_id": "R27380xR27366",
            "comparison_id": "R27380",
            "paper_id": "R27366",
            "text": "Consideration of shot peening treatment applied to a high strength aeronautical steel with different hardnesses one of the most important components in a aircraft is its landing gear, due to the high load that it is submitted to during, principally, the take off and landing. for this reason, the aisi 4340 steel is widely used in the aircraft industry for fabrication of structural components, in which strength and toughness are fundamental design requirements [i]. fatigue is an important parameter to be considered in the behavior of mechanical components subjected to constant and variable amplitude loading. one of the known ways to improve fatigue resistance is by using the shot peening process to induce a conlpressive residual stress in the surface layers of the material, making the nucleation and propagation of fatigue cracks more difficult [2,3]. the shot peening results depend on various parameters. these parameters can be grouped in three different classes according to i<. fathallah et a1 (41: parameters describing the treated part, parameters of stream energy produced by the process and parameters describing the contact conditions. furthermore, relaxation of the cksf induced by shot peening has been observed during the fatigue process 15-71. in the present research the gain in fatigue life of aisi 4340 steel, obtained by shot peening treatment, is evaluated under the two different hardnesses used in landing gear. rotating bending fatigue tests were conducted and the crsf was measured by an x-ray tensometry prior and during fatigue tests. the evaluation of fatigue life due the shot peening in relation to the relaxation of crsf, of crack sources position and roughness variation is done.",
            "contribution_ids": [
                "R27367"
            ]
        },
        {
            "instance_id": "R27380xR27347",
            "comparison_id": "R27380",
            "paper_id": "R27347",
            "text": "Influence of the shot peening temperature on the relaxation behaviour of residual stresses during cyclic bending shot peening of steels at elevated temperatures (warm peening) can improve the fatigue behaviour of workpieces. for the steel ai sf 4140 (german grade 42crm04) in a quenched and tempered condition, it is shown that this is not only caused by the higher compressive residual stresses induced but also due to an enlarged stability of these residual stresses during cyclic bending. this can be explained by strain aging effects during shot peening, which cause different and more stable dislocation structures.",
            "contribution_ids": [
                "R27348"
            ]
        },
        {
            "instance_id": "R27461xR27413",
            "comparison_id": "R27461",
            "paper_id": "R27413",
            "text": "Approximate Correlations for Chevron-Type Plate Heat Exchangers there exists very little useful data representing the performance of industrial plate heat exchangers (phes) in the open literature. as a result, it has been difficult to arrive at any generalized correlations. while every phe manufacturer is believed to have a comprehensive set of performance curves for their own designs, there exists the need to generate an approximate set of generalized correlations for the heat-transfer community. such correlations can be used for preliminary designs and analytical studies. this paper attempts to develop such a set of generalized correlations to quantify the heat-transfer and pressure-drop performance of chevron-type phes. for this purpose, the experimental data reported by heavner et al. were used for the turbulent region. for the laminar region, a semi-theoretical approach was used to express, for example, the friction factor as a function of the reynolds number and the chevron angle. asymptotic curves were used for the transitional region. physical explanations are provided for the trends shown by the generalized correlations. the correlations are compared against the open-literature data, where appropriate. these correlations are expected to be improved in the future when more data become available.",
            "contribution_ids": [
                "R27414"
            ]
        },
        {
            "instance_id": "R27620xR27527",
            "comparison_id": "R27620",
            "paper_id": "R27527",
            "text": "The relationship between energy consumption and economic growth in Pakistan energy is substantial for economic development. this study aims to unveil the causal relationship and long-term association between economic growth and energy consumption in pakistan. the granger-causality test finds that; natural gas consumption, electricity consumption and coal consumption have uni-directional causal relationship with economic growth as (gc, ec and cc\u2192gdp), however, gdp growth rate, natural gas consumption and coal consumption unilaterally granger causes inflation (gdp, gc and cc\u2192cpi) and lastly coal consumption\u2192natural gas consumption (gc), electricity consumption (ec)\u2192gc. the ardl estimations delineate natural gas consumption and oil consumption having a positive and negative association with gdp growth rate may have significant long term impacts respectively on the the economic growth of pakistan.",
            "contribution_ids": [
                "R27528",
                "R27666"
            ]
        },
        {
            "instance_id": "R27705xR27682",
            "comparison_id": "R27705",
            "paper_id": "R27682",
            "text": "Electricity consumption, income, foreign direct investment, and population in Malaysia: new evidence from multivariate framework analysis purpose this study attempts to re\u2010investigate the electricity consumption function for malaysia through the cointegration and causality analyses over the period 1970 to 2005. design/methodology/approach the study employed the bounds\u2010testing procedure for cointegration to examine the potential long\u2010run relationship, while an autoregressive distributed lag model is used to derive the short\u2010 and long\u2010run coefficients. the granger causality test is applied to determine the causality direction between electricity consumption and its determinants. findings new evidence is found in this study: first, electricity consumption, income, foreign direct investment, and population in malaysia are cointegrated. second, the influx of foreign direct investment and population growth are positively related to electricity consumption in malaysia and the granger causality evidence indicates that electricity consumption, income, and foreign direct investment are of bilateral causality. originality/value the estimated multivariate electricity consumption function for malaysia implies that malaysia is an energy\u2010dependent country; thus energy\u2010saving policies may have an inverse effect on current and also future economic development in malaysia.",
            "contribution_ids": [
                "R27683"
            ]
        },
        {
            "instance_id": "R27835xR27761",
            "comparison_id": "R27835",
            "paper_id": "R27761",
            "text": "Blending video games with learning: Issues and challenges with classroom implementations in the Turkish context the research design for this study focuses on examining the core issues and challenges when video games are used in the classroom. for this purpose three naturalistic contexts in turkey were examined in which educational video games were used as the basis for teaching units on world continents and countries, first aid, and basic computer hardware and peripherals, in primary, secondary and higher education contexts respectively. methods employed in the data collection include observing lessons, taking field notes, interviewing students and teachers, saving online discourse data, and collecting student artifacts and reflections. findings identified issues related to (1) the design of the video game environment, (2) school infrastructure, (3) the nature of learning, the role of the teacher and classroom culture, and (4) engagement.",
            "contribution_ids": [
                "R27762"
            ]
        },
        {
            "instance_id": "R27835xR27781",
            "comparison_id": "R27835",
            "paper_id": "R27781",
            "text": "Gameplaying for maths learning: cooperative or not? this study investigated the effects of gameplaying on fifth-graders\u2019 maths performance and attitudes. one hundred twenty five fifth graders were recruited and assigned to a cooperative teams-games-tournament (tgt), interpersonal competitive or no gameplaying condition. a state standards-based maths exam and an inventory on attitudes towards maths were used for the pretest and posttest. the students\u2019 gender, socio-economic status and prior maths ability were examined as the moderating variables and covariate. multivariate analysis of covariance (mancova) indicated that gameplaying was more effective than drills in promoting maths performance, and cooperative gameplaying was most effective for promoting positive maths attitudes regardless of students\u2019 individual differences.",
            "contribution_ids": [
                "R27782"
            ]
        },
        {
            "instance_id": "R27835xR27790",
            "comparison_id": "R27835",
            "paper_id": "R27790",
            "text": "New Directions for Traditional Lessons\u00e2\u0080\u009d: Can Handheld Game Consoles Enhance Mental Mathematics Skills? this paper reports on a pilot study that compared the use of commercial off-the-shelf (cots) handheld game consoles (hgcs) with traditional teaching methods to develop the automaticity of mathematical calculations and self-concept towards mathematics for year 4 students in two metropolitan schools. one class conducted daily sessions using the hgcs and the dr kawashima\u2019s brain training software to enhance their mental maths skills while the comparison class engaged in mental maths lessons using more traditional classroom approaches. students were assessed using standardised tests at the beginning and completion of the term and findings indicated that students who undertook the brain training pilot study using the hgcs showed significant improvement in both the speed and accuracy of their mathematical calculations and selfconcept compared to students in the control school. an exploration of the intervention, discussion of methodology and the implications of the use of hgcs in the primary classroom are presented.",
            "contribution_ids": [
                "R27791"
            ]
        },
        {
            "instance_id": "R27835xR27833",
            "comparison_id": "R27835",
            "paper_id": "R27833",
            "text": "Learning blood management in orthopedic surgery through gameplay \"orthopedic surgery treats the musculoskeletal system, in which bleeding is common and can be fatal. to help train future surgeons in this complex practice, researchers designed and implemented a serious game for learning orthopedic surgery. the game focuses on teaching trainees blood management skills, which are critical for safe operations. using state-of-the-art graphics technologies, the game provides an interactive and realistic virtual environment. it also integrates game elements, including task-oriented and time-attack scenarios, bonuses, game levels, and performance evaluation tools. to study the system's effect, the researchers conducted experiments on player completion time and off-target contacts to test their learning of psychomotor skills in blood management.\"",
            "contribution_ids": [
                "R27834"
            ]
        },
        {
            "instance_id": "R27835xR27753",
            "comparison_id": "R27835",
            "paper_id": "R27753",
            "text": "International Evaluation of a Localized Geography Educational Software a report on the implementation and evaluation of an intelligent learning system; the multimedia geography tutor and game software titled lainos world sm was localized into english, french, spanish, german, portuguese, russian and simplified chinese. thereafter, multilingual online surveys were setup to which high school students were globally invited via mails to schools, targeted adverts and recruitment on facebook, google, etc. 1125 respondents from selected nations completed both the initial and final surveys. the effect of the software on students\u2019 geographical knowledge was analyzed through pre and post achievement test scores. in general, the mean score were higher after exposure to the educational software for fifteen days and it was established that the score differences were statistically significant. this positive effect and other qualitative data show that the localized software from students\u2019 perspective is a widely acceptable and effective educational tool for learning geography in an interactive and gaming environment..",
            "contribution_ids": [
                "R27754"
            ]
        },
        {
            "instance_id": "R27835xR27757",
            "comparison_id": "R27835",
            "paper_id": "R27757",
            "text": "Combining software games with education: Evaluation of its educational effectiveness computer games are very popular among children and adolescents. in this respect, they could be exploited by educational software designers to render educational software more attractive and motivating. however, it remains to be explored what the educational scope of educational software games is. in this paper, we explore several issues concerning the educational effectiveness, appeal and scope of educational software games through an evaluation study of an intelligent tutoring system (its) that operates as a virtual reality educational game. the results of the evaluation show that educational virtual reality games can be very motivating while retaining or even improving the educational effects on students. moreover, one important finding of the study was that the educational effectiveness of the game was particularly high for students who used to have poor performance in the domain taught prior to their learning experience with the game.",
            "contribution_ids": [
                "R27758"
            ]
        },
        {
            "instance_id": "R27835xR27792",
            "comparison_id": "R27835",
            "paper_id": "R27792",
            "text": "A Study on Exploiting Commercial Digital Games into School Context digital game-based learning is a research field within the context of technology-enhanced learning that has attracted significant research interest. commercial off-the-shelf digital games have the potential to provide concrete learning experiences and allow for drawing links between abstract concepts and real-world situations. the aim of this paper is to provide evidence for the effect of a general-purpose commercial digital game (namely, the \u201csims 2-open for business\u201d) on the achievement of standard curriculum mathematics educational objectives as well as general educational objectives as defined by standard taxonomies. furthermore, students\u2019 opinions about their participation in the proposed game-supported educational scenario and potential changes in their attitudes toward math teaching and learning in junior high school are investigated. the results of the conducted research showed that: (i) students engaged in the game-supported educational activities achieved the same results with those who did not, with regard to the subject matter educational objectives, (ii) digital gamesupported educational activities resulted in better achievement of the general educational objectives, and (iii) no significant differences were observed with regard to students\u2019 attitudes towards math teaching and learning.",
            "contribution_ids": [
                "R27793"
            ]
        },
        {
            "instance_id": "R28099xR27851",
            "comparison_id": "R28099",
            "paper_id": "R27851",
            "text": "How Far Can We Go with Local Optimization in Real-Time Stereo Matching applications such as robot navigation and augmented reality require high-accuracy dense disparity maps in real-time and online. due to time constraint, most realtime stereo applications rely on local winner-take-all optimization in the disparity computation process. these local approaches are generally outperformed by offline global optimization based algorithms. however, recent research shows that, through carefully selecting and aggregating the matching costs of neighboring pixels, the disparity maps produced by a local approach can be more accurate than those generated by many global optimization techniques. we are therefore motivated to investigate whether these cost aggregation approaches can be adopted in real-time stereo applications and, if so, how well they perform under the real-time constraint. the evaluation is conducted on a real-time stereo platform, which utilizes the processing power of programmable graphics hardware. several recent cost aggregation approaches are also implemented and optimized for graphics hardware so that real-time speed can be achieved. the performances of these aggregation approaches in terms of both processing speed and result quality are reported.",
            "contribution_ids": [
                "R27852"
            ]
        },
        {
            "instance_id": "R28099xR27902",
            "comparison_id": "R28099",
            "paper_id": "R27902",
            "text": "On building an accurate stereo matching system on graphics hardware this paper presents a gpu-based stereo matching system with good performance in both accuracy and speed. the matching cost volume is initialized with an ad-census measure, aggregated in dynamic cross-based regions, and updated in a scanline optimization framework to produce the disparity results. various errors in the disparity results are effectively handled in a multi-step refinement process. each stage of the system is designed with parallelism considerations such that the computations can be accelerated with cuda implementations. experimental results demonstrate the accuracy and the efficiency of the system: currently it is the top performer in the middlebury benchmark, and the results are achieved on gpu within 0.1 seconds. we also provide extra examples on stereo video sequences and discuss the limitations of the system.",
            "contribution_ids": [
                "R27903"
            ]
        },
        {
            "instance_id": "R28099xR27971",
            "comparison_id": "R28099",
            "paper_id": "R27971",
            "text": "Efficient GPU-Based Graph Cuts for Stereo Matching \"although graph cuts (gc) is popularly used in many computer vision problems, slow execution time due to its high complexity hinders wide usage. manycore solution using graphics processing unit (gpu) may solve this problem. however, conventional gc implementation does not fully exploit gpu's computing power. to address this issue, a new gc algorithm which is suitable for gpu environment is presented in this paper. first, we present a novel graph construction method that accelerates the convergence speed of gc. next, a repetitive block-based push and relabel method is used to increase the data transfer efficiency. finally, we propose a low-overhead global relabeling algorithm to increase the gpu occupancy ratio. the experiments on middlebury stereo dataset shows that 5.2x speedup can be achieved over the baseline implementation, with identical gpu platform and parameters.\"",
            "contribution_ids": [
                "R27972"
            ]
        },
        {
            "instance_id": "R28099xR27978",
            "comparison_id": "R28099",
            "paper_id": "R27978",
            "text": "Real-time stereo vision: Optimizing Semi-Global Matching \"semi-global matching (sgm) is arguably one of the most popular algorithms for real-time stereo vision. it is already employed in mass production vehicles today. thinking of applications in intelligent vehicles (and fully autonomous vehicles in the long term), we aim at further improving sgm regarding its accuracy. in this study, we propose a straight-forward extension of the algorithm's parametrization. we consider individual penalties for different path orientations, weighted integration of paths, and penalties depending on intensity gradients. in order to tune all parameters, we applied evolutionary optimization. for a more efficient offline optimization and evaluation, we implemented sgm on graphics hardware. we describe the implementation using cuda in detail. for our experiments, we consider two publicly available datasets: the popular middlebury benchmark as well as a synthetic sequence from the .enpeda. project. the proposed extensions significantly improve the performance of sgm. the number of incorrect disparities was reduced by up to 27.5 % compared to the original approach, while the runtime was not increased.\"",
            "contribution_ids": [
                "R27979"
            ]
        },
        {
            "instance_id": "R28099xR28000",
            "comparison_id": "R28099",
            "paper_id": "R28000",
            "text": "Real-Time Stereo Matching on CUDA Using an Iterative Refinement Method for Adaptive Support-Weight Correspondences high-quality real-time stereo matching has the potential to enable various computer vision applications including semi-automated robotic surgery, teleimmersion, and 3-d video surveillance. a novel real-time stereo matching method is presented that uses a two-pass approximation of adaptive support-weight aggregation, and a low-complexity iterative disparity refinement technique. through an evaluation of computationally efficient approaches to adaptive support-weight cost aggregation, it is shown that the two-pass method produces an accurate approximation of the support weights while greatly reducing the complexity of aggregation. the refinement technique, constructed using a probabilistic framework, incorporates an additive term into matching cost minimization and facilitates iterative processing to improve the accuracy of the disparity map. this method has been implemented on massively parallel high-performance graphics hardware using the compute unified device architecture computing engine. results show that the proposed method is the most accurate among all of the real-time stereo matching methods listed on the middlebury stereo benchmark.",
            "contribution_ids": [
                "R28001"
            ]
        },
        {
            "instance_id": "R28099xR28024",
            "comparison_id": "R28099",
            "paper_id": "R28024",
            "text": "Stereo matching by adaptive weighting selection based cost aggregation cost aggregation is the most essential step for dense stereo correspondence searching, which measures the similarity between pixels in the stereo images. in this paper, based on the analysis of the optimal adaptive weight, we propose a novel support aggregation strategy by adaptive weighting selection. the proposed method calculates the aggregation cost by the joint optimization of both left and right matching cost. by assigning more reasonable weighting coefficients, we exclude the occlusion pixels while preserving sufficient support region for accurate matching. the proposed optimal strategy can be integrated by any other adaptive weighting based cost aggregation method to generate more reasonable similarity measurement. experimental results show that, compare with traditional methods, our algorithm can reduce the foreground fatten phenomenon while increasing the accuracy in the high texture regions.",
            "contribution_ids": [
                "R28025"
            ]
        },
        {
            "instance_id": "R28099xR28035",
            "comparison_id": "R28099",
            "paper_id": "R28035",
            "text": "A new high resolution depth map estimation system using stereo vision and depth sensing device depth map estimation is a classical problem in computer vision. conventional depth estimation relies on stereo/multi-view matching or depth sensing devices alone. in this paper, we propose a system which addresses high resolution and high quality depth estimation based on joint fusion of stereo and kinect data. the problem is formulated as a maximum a posteriori probability (map) estimation problem and reliability of two devices are derived. the depth map estimated is further refined by color image guided depth matting and a 2d polynomial regression (lpr)-based filtering. experimental results show that our system can provide high quality and resolution depth map, which complements the strengths of stereo vision and kinect depth sensor.",
            "contribution_ids": [
                "R28036"
            ]
        },
        {
            "instance_id": "R28099xR28044",
            "comparison_id": "R28099",
            "paper_id": "R28044",
            "text": "A modified census transform based on the neighborhood information for stereo matching algorithm census transform is a non-parametric local transform. its weakness is that the results relied on the center pixel too much. this paper proposes a modified census transform based on the neighborhood information for stereo matching. by improving the classic census transform, the new technique utilizes more bits to represent the differences between the pixel and its neighborhood information. the result image of the modified census transform has more detailed information at depth discontinuity. after stereo correspondence, sub-pixel interpolation and the disparity refinement, a better dense disparity map can be obtained. the experiments present that the proposed algorithm has simple mechanism and strong robustness. it can improve the accuracy of matching and is applicable to hardware systems.",
            "contribution_ids": [
                "R28045"
            ]
        },
        {
            "instance_id": "R28099xR28053",
            "comparison_id": "R28099",
            "paper_id": "R28053",
            "text": "Fast stereo matching using adaptive guided filtering dense disparity map is required by many great 3d applications. in this paper, a novel stereo matching algorithm is presented. the main contributions of this work are three-fold. firstly, a new cost...",
            "contribution_ids": [
                "R28054"
            ]
        },
        {
            "instance_id": "R28099xR28067",
            "comparison_id": "R28099",
            "paper_id": "R28067",
            "text": "Hardware-Efficient Design of Real-Time Profile Shape Matching Stereo Vision Algorithm on FPGA a variety of platforms, such as micro-unmanned vehicles, are limited in the amount of computational hardware they can support due to weight and power constraints. an efficient stereo vision algorithm implemented on an fpga would be able to minimize payload and power consumption in microunmanned vehicles, while providing 3d information and still leaving computational resources available for other processing tasks. this work presents a hardware design of the efficient profile shape matching stereo vision algorithm. hardware resource usage is presented for the targeted micro-uv platform, helio-copter, that uses the xilinx virtex 4 fx60 fpga. less than a fifth of the resources on this fgpa were used to produce dense disparity maps for image sizes up to 450 \u00d7 375, with the ability to scale up easily by increasing bram usage. a comparison is given of accuracy, speed performance, and resource usage of a census transform-based stereo vision fpga implementation by jin et al. results show that the profile shape matching algorithm is an efficient real-time stereo vision algorithm for hardware implementation for resource limited systems such as microunmanned vehicles.",
            "contribution_ids": [
                "R28068"
            ]
        },
        {
            "instance_id": "R28099xR28078",
            "comparison_id": "R28099",
            "paper_id": "R28078",
            "text": "High-speed segmentation-driven high-resolution matching this paper proposes a segmentation-based approach for matching of high-resolution stereo images in real time. the approach employs direct region matching in a raster scan fashion influenced by scanline approaches, but with pixel decoupling. to enable real-time performance it is implemented as a heterogeneous system of an fpga and a sequential processor. additionally, the approach is designed for low resource usage in order to qualify as part of unified image processing in an embedded system.",
            "contribution_ids": [
                "R28079"
            ]
        },
        {
            "instance_id": "R28099xR27916",
            "comparison_id": "R28099",
            "paper_id": "R27916",
            "text": "A local iterative refinement method for adaptive support-weight stereo matching a new stereo matching algorithm is introduced that performs iterative refinement on the results of adaptive support-weight stereo matching. during each iteration of disparity refinement, adaptive support-weights are used by the algorithm to penalize disparity differences within local windows. analytical results show that the addition of iterative refinement to adaptive support-weight stereo matching does not significantly increase complexity. in addition, this new algorithm does not rely on image segmentation or plane fitting, which are used by the majority of the most accurate stereo matching algorithms. as a result, this algorithm has lower complexity, is more suitable for parallel implementation, and does not force locally planar surfaces within the scene. when compared to other algorithms that do not rely on image segmentation or plane fitting, results show that the new stereo matching algorithm is one of the most accurate listed on the middlebury performance benchmark.",
            "contribution_ids": [
                "R27917"
            ]
        },
        {
            "instance_id": "R28099xR28012",
            "comparison_id": "R28099",
            "paper_id": "R28012",
            "text": "A near real-time color stereo matching method for GPU this paper presents a near real-time stereo matching method with acceptable matching results. this method consists of three important steps: sad-ald cost measure, cost aggregation in adaptive window in cross-based support regions and a refinement step. these three steps are well organized to be adopted by the gpu\u2019s parallel architecture. the parallelism brought by gpu and cuda implementations provides significant acceleration in running time. this method is tested on six pairs of images from middlebury dataset, each possibly declined within different sizes. for each pair of images it can generate acceptable matching results in roughly less than 100 milliseconds. the method is also compared with three gpu-based methods and one cpu-based method on increasing size image pairs.",
            "contribution_ids": [
                "R28013"
            ]
        },
        {
            "instance_id": "R28140xR28104",
            "comparison_id": "R28140",
            "paper_id": "R28104",
            "text": "A Metastatic Endocrine-Neurogenic Tumor of the Ampulla of Vater with Multiple Endocrine Immunoreaction Malignant Paraganglioma? the present case report demonstrates the history of a 50-year-old man with a mixed endocrine-neurogenous tumor of the ampulla of vater. the tumor was localized endoscopically after an attack of melena. there were no signs of endocrinopathy. a local resection with suturing of the pancreatic duct was performed. morphologically, there were two different tissue types (neurogenous and carcinoid-like) with numerous cells and nerve fibers reacting immunohistochemically with somatostatin and neurotensin antisera: some immunoreactivity to pp-antibodies was observed. still, after 20 months, the patient seems to have been cured by local resection.",
            "contribution_ids": [
                "R28105"
            ]
        },
        {
            "instance_id": "R28140xR28135",
            "comparison_id": "R28140",
            "paper_id": "R28135",
            "text": "Duodenal gangliocytic paraganglioma showing lymph node metastasis: A rare case report abstract \\n we describe a case of duodenal gangliocytic paraganglioma showing lymph node metastasis. a 61-year-old japanese man underwent pylorus preserving pancreaticoduodenectomy to remove a tumor at the papilla of vater. the section of the tumor extending from the mucosa to submucosa of the duodenum was sharply demarcated, solid, and white-yellowish. neither necrosis nor hemorrhage was present. histological examination confirmed the immunohistochemical identification of three components comprising epithelioid cells, spindle-shaped cells, and ganglion-like cells. epithelioid cells showed positive reactivity for synaptophysin, somatostatin, and cd56. in contrast, spindle-shaped cells showed positive reactivity for s-100 protein, but not for synaptophysin, somatostatin or cd56. furthermore, we found lymph node metastasis despite lack of bcl-2 and p53 expression. in addition to the rarity of the tumor, we are describing here the present case suggests the malignant potency of the tumor despite lack of acceptable prognostic indicators for neuroendocrine tumor.",
            "contribution_ids": [
                "R28136"
            ]
        },
        {
            "instance_id": "R28191xR28177",
            "comparison_id": "R28191",
            "paper_id": "R28177",
            "text": "On cost-efficiency of the global container shipping network this paper presents a simple formulation in the form of a pipe network for modelling the global container-shipping network. the cost-efficiency and movement-patterns of the current container-shipping network have been investigated using heuristic methods. the model is able to reproduce the overall incomes, costs, and container movement patterns for the industry as well as for the individual shipping lines and ports. it was found that the cost of repositioning empties is 27% of the total world fleet running cost and that overcapacity continues to be a problem. the model is computationally efficient. implemented in the java language, it takes one minute to run a full-scale network on a pentium iv computer.",
            "contribution_ids": [
                "R28178"
            ]
        },
        {
            "instance_id": "R28191xR28166",
            "comparison_id": "R28191",
            "paper_id": "R28166",
            "text": "Seasonal slot allocation planning for a container liner shipping service this research addresses a slot allocation planning problem of the container shipping company for satisfying the estimated seasonal demands on a liner service. we explore in detail the influenced factors of planning and construct a quantitative model for the optimum allocation of the ship\u2019s slot spaces. an integer programming model is formulated to maximize the potential profits per round trip voyage for a liner company, and a real life example of an eastern asia short sea service has been studied. analysis results reveal that containers with the higher contributions like reefers and 40 feet dry containers have priorities to be allocated more than others, but not all because of satisfying necessary operational constraints. our model is not only providing a higher space utilization rate and more detailed allocation results, but also helpful for the ship size assessment in long-term planning.",
            "contribution_ids": [
                "R28167"
            ]
        },
        {
            "instance_id": "R28235xR28200",
            "comparison_id": "R28235",
            "paper_id": "R28200",
            "text": "Empty container reposition planning for intra-Asia liner shipping this paper addresses empty container reposition planning by plainly considering safety stock management and geographical regions. this plan could avoid drawback in practice which collects mass empty containers at a port then repositions most empty containers at a time. empty containers occupy slots on vessel and the liner shipping company loses chance to yield freight revenue. the problem is drawn up as a two-stage problem. the upper problem is identified to estimate the empty container stock at each port and the lower problem models the empty container reposition planning with shipping service network as the transportation problem by liner problem. we looked at case studies of the taiwan liner shipping company to show the application of the proposed model. the results show the model provides optimization techniques to minimize cost of empty container reposition and to provide an evidence to adjust strategy of restructuring the shipping service network.",
            "contribution_ids": [
                "R28201"
            ]
        },
        {
            "instance_id": "R28333xR28260",
            "comparison_id": "R28333",
            "paper_id": "R28260",
            "text": "Analysis of an exact algorithm for the vessel speed optimization problem increased fuel costs together with environmental concerns have led shipping companies to consider the optimization of vessel speeds. given a fixed sequence of port calls, each with a time window, and fuel cost as a convex function of vessel speed, we show that optimal speeds can be found in quadratic time. \u00a9 2013 wiley periodicals, inc. networks, 2013",
            "contribution_ids": [
                "R28261"
            ]
        },
        {
            "instance_id": "R28333xR28268",
            "comparison_id": "R28333",
            "paper_id": "R28268",
            "text": "A chance constrained programming model for short-term liner ship fleet planning problems this article deals with a short-term liner ship fleet planning (lsfp) problem with cargo shipment demand uncertainty for a single liner container shipping company. the cargo shipment demand uncertainty enables us to propose a chance constraint for each liner service route, which guarantees that the liner service route can satisfy the customers\u2019 demand at least with a predetermined probability. assuming that cargo shipment demand between any two ports on each liner service route is normally distributed, this article develops an integer linear programming model with chance constraints for the short-term lsfp problem. the proposed integer linear programming model can be efficiently solved by any optimization solver such as cplex. finally, a numerical example is carried out to assess the model and analyze impact of the chance constraints and cargo shipment demand.",
            "contribution_ids": [
                "R28269"
            ]
        },
        {
            "instance_id": "R28333xR28280",
            "comparison_id": "R28333",
            "paper_id": "R28280",
            "text": "Ship assignment with hub and spoke constraints \"as the shipping industry enters the future, an increasing number of technological developments are being introduced into this market. this has led to a significant change in business operations, such as the innovative design of hub and spoke systems, resulting in cargo consolidation and a better use of the ship's capacity. in the light of this new scenario, the authors present a successful application of integer linear programming to support the decision-making process of assigning ships to previously defined voyages \u2014 the rosters. the tool used to build the final models was the ms-excel solver (microsoft\u00ae excel 97 sr-2, 1997), a package that enabled the real case studies addressed to be solved. the results of the experiment prompted the authors to favour the assignment of very small fleets, as opposed to the existing high number of ships employed in such real trades,\"",
            "contribution_ids": [
                "R28281"
            ]
        },
        {
            "instance_id": "R28369xR28356",
            "comparison_id": "R28369",
            "paper_id": "R28356",
            "text": "A model and solution algorithm for optimal routing of a time-chartered containership we formulate a mathematical programming model for optimally routing a chartered container ship. our model helps in evaluating whether a container ship should be chartered or not. the model calculates the optimal sequence of port calls, the number of containers transported between port pairs, and the number of trips the ship makes in the chartered period. a specialized algorithm is developed to solve the integer network subprograms which determine the sequence of port calls. our algorithm, which solves an integer program optimally, is quite efficient. comparison of computational results with a lagrangean relaxation method and an embedded dynamic program are also presented.",
            "contribution_ids": [
                "R28357"
            ]
        },
        {
            "instance_id": "R28369xR28349",
            "comparison_id": "R28369",
            "paper_id": "R28349",
            "text": "A mixed integer programming model for routing containerships in this paper, we formulate a mixed integer programming model for routing containerships. our model helps in evaluating the optimal sequence of port calls and the number of containers transported between port pairs given the trip cycle time. some numerical examples and a real world application of the trans pacific route are presented. the computational results show that our model, which solve the mixed integer programming optimally, is quite efficient and applicable to real world problem.",
            "contribution_ids": [
                "R28350"
            ]
        },
        {
            "instance_id": "R28407xR28375",
            "comparison_id": "R28407",
            "paper_id": "R28375",
            "text": "Network Design and Allocation Mechanisms for Carrier Alliances in Liner Shipping many real-world systems operate in a decentralized manner, where individual operators interact with varying degrees of cooperation and self motive. in this paper, we study transportation networks that operate as an alliance among different carriers. in particular, we study alliance formation among carriers in liner shipping. we address tactical problems such as the design of large-scale networks (that result from integrating the service networks of different carriers in an alliance) and operational problems such as the allocation of limited capacity on a transportation network among the carriers in the alliance. we utilize concepts from mathematical programming and game theory and design a mechanism to guide the carriers in an alliance to pursue an optimal collaborative strategy. the mechanism provides side payments to the carriers, as an added incentive, to motivate them to act in the best interest of the alliance while maximizing their own profits. our computational results suggest that the mechanism can be used to help carriers form sustainable alliances.",
            "contribution_ids": [
                "R28376"
            ]
        },
        {
            "instance_id": "R28407xR28388",
            "comparison_id": "R28407",
            "paper_id": "R28388",
            "text": "A path based model for a green liner shipping network design problem abstract\u2014liner shipping networks are the backbone ofinternational trade providing low transportation cost, whichis a major driver of globalization. these networks are underconstant pressure to deliver capacity, cost effectiveness and envi-ronmentally conscious transport solutions. this article proposesa new path based mip model for the liner shipping networkdesign problem minimizing the cost of vessels and their fuelconsumption facilitating a green network. the proposed modelreduces problem size using a novel aggregation of demands.a decomposition method enabling delayed column generationis presented. the subproblems have similar structure to ve-hicle routing problems, which can be solved using dynamicprogramming.index terms\u2014liner shipping, network design, mathematicalprogramming, column generation, green logistics i. i ntroduction g lobal liner shipping companies provide port to porttransport of containers, on a network which representsa billion dollar investment in assets and operational costs.the liner shipping network can be viewed as a transporta-tion system for general cargo not unlike an urban mass transitsystem for commuters, where each route (service) providestransportation links between ports and the ports allow fortranshipment in between routes (services). the liner shippingindustry is distinct from other maritime transportation modesprimarily due to a \ufb01xed public schedule with weekly fre-quency of port calls as an industry standard (stopford 1997).the network consists of a set of services. a service connectsa sequence of ports in a cycle at a given frequency, usuallyweekly. in figure 1 a service connecting montreal-halifaxand europe is illustrated. the weekly frequency means thatseveral vessels are committed to the service as illustrated byfigure 1, where four vessels cover a round trip of 28 daysplaced with one week in between vessels. this roundtrip forthe vessel is referred to as a rotation. note that the montrealservice carries cargo to the mediterranean and asia. thisillustrates that transhipments to other connecting servicesis at the core of liner shipping. therefore, the design of aservice is complex, as the set of rotations and their interactionthrough transhipment is a transportation system extending thesupply chains of a multiplum of businesses. figure 2 illus-trates two services interacting in transporting goods betweenmontreal-halifax and the mediterranean, while individually",
            "contribution_ids": [
                "R28389"
            ]
        },
        {
            "instance_id": "R28446xR28439",
            "comparison_id": "R28446",
            "paper_id": "R28439",
            "text": "Dynamic programming of port position and scale in the hierarchized container ports network \"a hierarchized container ports network, with several super hubs and many multilevel hub ports, will be established, mainly serving transshipment and carrying out most of its business in the hub-spoke mode. this paper sums up a programming model, in which the elementary statistic units, cost and expense of every phase of any shipment are the straight objects, and the minimum cost of the whole network is taken as the objective. this is established based on a dynamic system to make out the hierarchical structure of the container ports network, i.e. the trunk hub and feeder hubs can be planned in a economic zone, then the optimal scale vector can also be obtained for all container ports concerned with the network. the vector is a standard measurement to decide a port's position and their scale distribution in the whole network.\"",
            "contribution_ids": [
                "R28440"
            ]
        },
        {
            "instance_id": "R28487xR28485",
            "comparison_id": "R28487",
            "paper_id": "R28485",
            "text": "Optimization of shipping network of trunk and feeder lines for inter-regional and intra-regional container transport this paper firstly analyzes the structure of the existing container shipping network, which covers several areas located respectively in two counties, and develops a new kind of shipping network that consists of trunk and feeder lines. secondly, the paper constructs a bi-level programming model that can be used to optimize the container shipping network with the aim to minimize the generalized transport costs. then the model is tested with container o-d data between the ports in the surrounding bohai area in china and two ports in the west of the usa. through the test calculation, a feasible optimized shipping network consisting of trunk and feeder lines is founded for the case study area.",
            "contribution_ids": [
                "R28486"
            ]
        },
        {
            "instance_id": "R28614xR28532",
            "comparison_id": "R28614",
            "paper_id": "R28532",
            "text": "A Case of Primary Undifferentiated Sarcoma of the Liver: Diagnosed by Peritoneoscopy and Guided Biopsy the authors report a case of primary undifferentiated sarcoma of the liver, observed in a 36-year-old man. diagnosis was established at peritoneoscopy and guided biopsy, and confirmed by autopsy two months later.",
            "contribution_ids": [
                "R28533"
            ]
        },
        {
            "instance_id": "R28614xR28535",
            "comparison_id": "R28614",
            "paper_id": "R28535",
            "text": "Undifferentiated (embryonal) sarcoma of the liver.Report of 31 cases thirty\u2010one cases of undifferentiated (embryonal) sarcoma of the liver are presented. the tumor is found predominantly in the pediatric age group, the majority of patients (51.6%) being between 6 and 10 years of age. an abdominal mass and pain are the usual presenting symptoms. radiographic examination is nonspecific except to demonstrate a space\u2010occupying lesion of the liver. the tumors are large, single, usually globular and well demarcated, and have multiple cystic areas of hemorrhage, necrosis, and gelatinous degeneration. histologic examination shows a pseudocapsule partially separating the normal liver from undifferentiated sarcomatous cells that, near the periphery of the tumor, surround entrapped hyperplastic or degenerating bile duct\u2010like structures. eosinophilic globules that are pas positive are usually found within and adjacent to tumor cells. areas of necrosis and hemorrhage are prominent. the prognosis is poor, with a median survival of less than 1 year following diagnosis.",
            "contribution_ids": [
                "R28536",
                "R28537",
                "R28538",
                "R28539"
            ]
        },
        {
            "instance_id": "R28614xR28544",
            "comparison_id": "R28614",
            "paper_id": "R28544",
            "text": "Primary sarcoma of the liver in the adult primary undifferentiated saroma of the liver is a rare tumor, being documented primarily in the pediatric age group. this report describes the occurrence of such a tumor in a 55\u2010year\u2010old white woman with meyenburg\u2010s complexes of the liver and the crst syndrome. the clinicopathologic features of the tumor in the adult are characterized and the literature is reviewed.",
            "contribution_ids": [
                "R28545"
            ]
        },
        {
            "instance_id": "R28614xR28554",
            "comparison_id": "R28614",
            "paper_id": "R28554",
            "text": "Hepatic undifferentiated (embryonal) sarcoma and rhabdomyosarcoma in children. Results of therapy \"from july 1972 through september 1984, 8 of 44 children diagnosed as having primary malignant hepatic tumors, who were treated at st. jude children's research hospital, had undifferentiated (embryonal) sarcoma (five patients) or rhabdomyosarcoma (three patients). the natural history and response to multimodal therapy of these rare tumors are described. the pathologic material was reviewed and evidence for the differentiating potential of undifferentiated (embryonal) sarcoma is presented. at diagnosis, disease was restricted to the right lobe of the liver in three patients, was bilobar in four patients, and extended from the left lobe into the diaphragm in one patient. lung metastases were present in two patients at diagnosis. all three patients with rhabdomyosarcoma had intrahepatic lesions without involvement of the biliary tree. survival ranged from 6 to 73 months from diagnosis (median, 19.5 months); two patients are surviving disease\u2010free for 55+ and 73+ months, and one patient recently underwent resection of a recurrent pulmonary nodule 22 months from initial diagnosis. three patients died of progressive intrahepatic and extrahepatic abdominal tumors, and two patients, who died of progressive pulmonary tumor, also had bone or brain metastasis but no recurrence of intra\u2010abdominal tumor. six patients had objective evidence of response to chemotherapy. the authors suggest an aggressive multimodal approach to the treatment of these rare tumors in children.\"",
            "contribution_ids": [
                "R28555"
            ]
        },
        {
            "instance_id": "R28614xR28583",
            "comparison_id": "R28614",
            "paper_id": "R28583",
            "text": "Hepatic Undifferentiated (Embryonal) Sarcoma Arising in a Mesenchymal Hamartoma we report the case of a hepatic undifferentiated (embryonal) sarcoma (ues) arising within a mesenchymal hamartoma (mh) in a 15-year-old girl. mapping of the tumor demonstrated a typical mh transforming gradually into a ues composed of anaplastic stromal cells. when evaluated by flow cytometry, the mh was diploid and the ues showed a prominent aneuploid peak. karyotypic analysis of the ues showed structural alterations of chromosome 19, which have been implicated as a potential genetic marker of mh. the histogenesis of mh and ues is still debated, and reports of a relationship between them, although suggested on the basis of histomorphologic similarities, have never been convincing. the histologic, flow cytometric, and cytogenetic evidence reported herein suggests a link between these two hepatic tumors of the pediatric population.",
            "contribution_ids": [
                "R28584"
            ]
        },
        {
            "instance_id": "R28614xR28593",
            "comparison_id": "R28614",
            "paper_id": "R28593",
            "text": "Undifferentiated (embryonal) sarcoma of the liver in middle-aged adults: Smooth muscle differentiation determined by immunohistochemistry and electron microscopy undifferentiated (embryonal) sarcoma of the liver (uesl) is a rare pediatric liver malignancy that is extremely uncommon in middle-aged individuals. we studied 2 cases of uesl in middle-aged adults (1 case in a 49-year-old woman and the other in a 62-year-old man) by histology, immunohistochemistry, and electron microscopy to clarify the cellular characteristics of this peculiar tumor. one tumor showed a mixture of spindle cells, polygonal cells, and multinucleated giant cells within a myxoid matrix and also revealed focal areas of a storiform pattern in a metastatic lesion. the other tumor was composed mainly of anaplastic large cells admixed with few fibrous or spindle-shaped components and many multinucleated giant cells. in both cases, some tumor cells contained eosinophilic hyaline globules that were diastase resistant and periodic acid-schiff positive. immunohistochemically, the tumor cells showed positive staining for smooth muscle markers, such as desmin, alpha-smooth muscle actin, and muscle-specific actin, and also for histiocytic markers, such as alpha-1-antitrypsin, alpha-1-antichymotrypsin, and cd68. electron microscope examination revealed thin myofilaments with focal densities and intermediate filaments in the cytoplasm of tumor cells. our studies suggest that uesl exhibits at least a partial smooth muscle phenotype in middle-aged adults, and this specific differentiation may be more common in this age group than in children. tumor cells of uesl with smooth muscle differentiation in middle-aged adults show phenotypic diversity comparable to those of malignant fibrous histiocytoma with myofibroblastic differentiation.",
            "contribution_ids": [
                "R28594",
                "R28595"
            ]
        },
        {
            "instance_id": "R28614xR28599",
            "comparison_id": "R28614",
            "paper_id": "R28599",
            "text": "Undifferentiated (embryonal) sarcoma of liver in adult: a case report we report a case of undifferentiated (embryonal) sarcoma of the liver (uesl), which showed cystic formation in a 20-year-old man with no prior history of any hepatitis or liver cirrhosis. he was admitted with abdominal pain and a palpable epigastric mass. the physical examination findings were unremarkable except for a tenderness mass and the results of routine laboratory studies were all within normal limits. abdominal ultrasound and computed tomography (ct) both showed a cystic mass in the left hepatic lobe. subsequently, the patient underwent a tumor excision and another two times of hepatectomy because of tumor recurrence. immunohistochemical study results showed that the tumor cells were positive for vimentin, alpha-1-antichymotrypsin (aact) and desmin staining, and negative for alpha-fetoprotein (afp), and eosinophilic hyaline globules in the cytoplasm of some giant cells were strongly positive for periodic acid-schiff (pas) staining. the pathological diagnosis was uesl. the patient is still alive with no tumor recurrence for four months.",
            "contribution_ids": [
                "R28600"
            ]
        },
        {
            "instance_id": "R28889xR28626",
            "comparison_id": "R28889",
            "paper_id": "R28626",
            "text": "A Study of the Multi-Objective Next Release Problem one of the first issues which has to be taken into account by software companies is to determine what should be included in the next release of their products, in such a way that the highest possible number of customers get satisfied while this entails a minimum cost for the company. this problem is known as the next release problem (nrp). since minimizing the total cost of including new features into a software package and maximizing the total satisfaction of customers are contradictory objectives, the problem has a multi-objective nature. in this work we study the nrp problem from the multi-objective point of view, paying attention to the quality of the obtained solutions, the number of solutions, the range of solutions covered by these fronts, and the number of optimal solutions obtained.also, we evaluate the performance of two state-of-the-art multi-objective metaheuristics for solving nrp: nsga-ii and mocell. the obtained results show that mocell outperforms nsga-ii in terms of the range of solutions covered, while this latter is able of obtaining better solutions than mocell in large instances. furthermore, we have observed that the optimal solutions found are composed of a high percentage of low-cost requirements and, also, the requirements that produce most satisfaction on the customers.",
            "contribution_ids": [
                "R28627",
                "R28776"
            ]
        },
        {
            "instance_id": "R28889xR28633",
            "comparison_id": "R28889",
            "paper_id": "R28633",
            "text": "A Multiobjective Optimization Approach to the Software Release Planning with Undefined Number of Releases and Interdependent Requirements release planning is an important and complex activity in software development. it involves several aspects related to which functionalities are going to be developed in each release of the system. consistent planning must meet the customers\u2019 needs and comply with existing constraints. optimization techniques have been successfully applied to solve problems in the software engineering field, including the software release planning problem. in this context, this work presents an approach based on multiobjective optimization for the problem when the number of releases is not known a priori or when the number of releases is a value expected by stakeholders. the strategy regards on the stakeholders\u2019 satisfaction, business value and risk management, as well as provides ways for handling requirements interdependencies. experiments show the feasibility of the proposed approach.",
            "contribution_ids": [
                "R28634",
                "R28779"
            ]
        },
        {
            "instance_id": "R28889xR28652",
            "comparison_id": "R28889",
            "paper_id": "R28652",
            "text": "On the value of user preferences in search-based software engineering: A case study in software product lines software design is a process of trading off competing objectives. if the user objective space is rich, then we should use optimizers that can fully exploit that richness. for example, this study configures software product lines (expressed as feature maps) using various search-based software engineering methods. as we increase the number of optimization objectives, we find that methods in widespread use (e.g. nsga-ii, spea2) perform much worse than ibea (indicator-based evolutionary algorithm). ibea works best since it makes most use of user preference knowledge. hence it does better on the standard measures (hypervolume and spread) but it also generates far more products with 0% violations of domain constraints. our conclusion is that we need to change our methods for search-based software engineering, particularly when studying complex decision spaces.",
            "contribution_ids": [
                "R28653",
                "R28783"
            ]
        },
        {
            "instance_id": "R28889xR28657",
            "comparison_id": "R28889",
            "paper_id": "R28657",
            "text": "Identifying \"Good\" Architectural Design Alternatives with Multi-Objective Optimization Strategies architecture trade-off analysis methods are appropriate techniques to evaluate design decisions and design alternatives with respect to conflicting quality requirements. however, the identification of good design alternatives is a time consuming task, which is currently performed manually. to automate this task, this paper proposes to use evolutionary algorithms and multi-objective optimization strategies based on architecture refactorings to identify a sufficient set of design alternatives. this approach will reduce development costs and improve the quality of the final system, because an automated and systematic search will identify more and better design alternatives.",
            "contribution_ids": [
                "R28658",
                "R28785"
            ]
        },
        {
            "instance_id": "R28889xR28664",
            "comparison_id": "R28889",
            "paper_id": "R28664",
            "text": "Pareto Optimal Search Based Refactoring at the Design Level \"refactoring aims to improve the quality of a software systems' structure, which tends to degrade as the system evolves. while manually determining useful refactorings can be challenging, search based techniques can automatically discover useful refactorings. current search based refactoring approaches require metrics to be combined in a complex fashion, and producea single sequence of refactorings. in this paper we show how pareto optimality can improve search based refactoring, making the combination of metrics easier, and aiding the presentation of multiple sequences of optimal refactorings to users.\"",
            "contribution_ids": [
                "R28665",
                "R28787"
            ]
        },
        {
            "instance_id": "R28889xR28795",
            "comparison_id": "R28889",
            "paper_id": "R28795",
            "text": "User-centered, Evolutionary Search in Conceptual Software Design although much evidence exists to suggest that conceptual software engineering design is a difficult task for software engineers to perform, current computationally intelligent tool support for software engineers is limited. while search-based approaches involving module clustering and refactoring have been proposed and show promise, such approaches are downstream in terms of the software development lifecycle - the designer must manually produce a design before search-based clustering and refactoring can take place. interactive, user-centered search-based approaches, on the other hand, support the designer at the beginning of, and during, conceptual software design, and are investigated in this paper by means of a case study. results show that interactive evolutionary search, supported by software agents, appears highly promising. as an open system, search is steered jointly by designer preferences and software agents. directly traceable to the design problem domain, a mass of useful and interesting conceptual class designs are arrived at which may be visualized by the designer with quantitative measures of structural integrity such as design coupling and class cohesion. the conceptual class designs are found to be of equivalent or better coupling and cohesion when compared to a manual conceptual design of the case study, and by exploiting concurrent execution, the performance of the software agents is highly favorable.",
            "contribution_ids": [
                "R28796"
            ]
        },
        {
            "instance_id": "R28889xR28801",
            "comparison_id": "R28889",
            "paper_id": "R28801",
            "text": "Generating Software Architecture Spectrum with Multi-Objective Genetic Algorithms a possible approach to partly automated software architecture design is the application of heuristic search methods like genetic algorithms. however, traditional genetic algorithms use a single fitness function with weighted terms for different quality attributes. this is inadequate for software architecture design that has to satisfy multiple incomparable quality requirements simultaneously. to overcome this problem, the use of pareto optimality is proposed. this technique is studied in the presence of two central quality attributes of software architectures, modifiability and efficiency. the technique produces a spectrum of architecture proposals, ranging from highly modifiable (and less efficient) to highly efficient (and less modifiable). the technique has been implemented and evaluated using an example system. the results demonstrate that pareto optimality has potential for producing a sensible set of architectures in the efficiency-modifiability space.",
            "contribution_ids": [
                "R28802"
            ]
        },
        {
            "instance_id": "R28889xR28820",
            "comparison_id": "R28889",
            "paper_id": "R28820",
            "text": "Pareto efficient multi-objective test case selection previous work has treated test case selection as a single objective optimisation problem. this paper introduces the concept of pareto efficiency to test case selection. the pareto efficient approach takes multiple objectives such as code coverage, past fault-detection history and execution cost, and constructs a group of non-dominating, equivalently optimal test case subsets. the paper describes the potential bene?ts of pareto efficient multi-objective test case selection, illustrating with empirical studies of two and three objective formulations.",
            "contribution_ids": [
                "R28821"
            ]
        },
        {
            "instance_id": "R28889xR28833",
            "comparison_id": "R28889",
            "paper_id": "R28833",
            "text": "A Multi-Objective Genetic Algorithm to Test Data Generation evolutionary testing has successfully applied search based optimization algorithms to the test data generation problem. the existing works use different techniques and fitness functions. however, the used functions consider only one objective, which is, in general, related to the coverage of a testing criterion. but, in practice, there are many factors that can influence the generation of test data, such as memory consumption, execution time, revealed faults, and etc. considering this fact, this work explores a ultiobjective optimization approach for test data generation. a framework that implements a multi-objective genetic algorithm is described. two different representations for the population are used, which allows the test of procedural and object-oriented code. combinations of three objectives are experimentally evaluated: coverage of structural test criteria, ability to reveal faults, and execution time.",
            "contribution_ids": [
                "R28834"
            ]
        },
        {
            "instance_id": "R28889xR28851",
            "comparison_id": "R28889",
            "paper_id": "R28851",
            "text": "Establishing Integration Test Orders of Classes with Several Coupling Measures during the inter-class test, a common problem, named class integration and test order (cito) problem, involves the determination of a test class order that minimizes stub creation effort, and consequently test costs. the approach based on multi-objective evolutionary algorithms (moeas) has achieved promising results because it allows the use of different factors and measures that can affect the stubbing process. many times these factors are in conflict and usually there is no a single solution for the problem. existing works on moeas present some limitations. the approach was evaluated with only two coupling measures, based on the number of attributes and methods of the stubs to be created. other moeas can be explored and also other coupling measures. considering this fact, this paper investigates the performance of two evolutionary algorithms: nsga-ii and spea2, for the cito problem with four coupling measures (objectives) related to: attributes, methods, number of distinct return types and distinct parameter types. an experimental study was performed with four real systems developed in java. the obtained results point out that the moeas can be efficiently used to solve this problem with several objectives, achieving solutions with balanced compromise between the measures, and of minimal effort to test.",
            "contribution_ids": [
                "R28852"
            ]
        },
        {
            "instance_id": "R28889xR28859",
            "comparison_id": "R28889",
            "paper_id": "R28859",
            "text": "Evolutionary Algorithms for the Multi-objective Test Data Generation Problem automatic test data generation is a very popular domain in the field of search\u2010based software engineering. traditionally, the main goal has been to maximize coverage. however, other objectives can be defined, such as the oracle cost, which is the cost of executing the entire test suite and the cost of checking the system behavior. indeed, in very large software systems, the cost spent to test the system can be an issue, and then it makes sense by considering two conflicting objectives: maximizing the coverage and minimizing the oracle cost. this is what we did in this paper. we mainly compared two approaches to deal with the multi\u2010objective test data generation problem: a direct multi\u2010objective approach and a combination of a mono\u2010objective algorithm together with multi\u2010objective test case selection optimization. concretely, in this work, we used four state\u2010of\u2010the\u2010art multi\u2010objective algorithms and two mono\u2010objective evolutionary algorithms followed by a multi\u2010objective test case selection based on pareto efficiency. the experimental analysis compares these techniques on two different benchmarks. the first one is composed of 800 java programs created through a program generator. the second benchmark is composed of 13 real programs extracted from the literature. in the direct multi\u2010objective approach, the results indicate that the oracle cost can be properly optimized; however, the full branch coverage of the system poses a great challenge. regarding the mono\u2010objective algorithms, although they need a second phase of test case selection for reducing the oracle cost, they are very effective in maximizing the branch coverage. copyright \u00a9 2011 john wiley & sons, ltd.",
            "contribution_ids": [
                "R28860"
            ]
        },
        {
            "instance_id": "R28889xR28863",
            "comparison_id": "R28889",
            "paper_id": "R28863",
            "text": "Software Project Planning for Robustness and Completion Time in the Presence of Uncertainty using Multi Objective Search Based Software Engineering all large-scale projects contain a degree of risk and uncertainty. software projects are particularly vulnerable to overruns, due to the this uncertainty and the inherent difficulty of software project cost estimation. in this paper we introduce a search based approach to software project robustness. the approach is to formulate this problem as a multi objective search based software engineering problem, in which robustness and completion time are treated as two competing objectives. the paper presents the results of the application of this new approach to four large real-world software projects, using two different models of uncertainty.",
            "contribution_ids": [
                "R28864"
            ]
        },
        {
            "instance_id": "R28889xR28875",
            "comparison_id": "R28889",
            "paper_id": "R28875",
            "text": "Multiobjective Simulation Optimisation in Software Project Management traditionally, simulation has been used by project managers in optimising decision making. however, current simulation packages only include simulation optimisation which considers a single objective (or multiple objectives combined into a single fitness function). this paper aims to describe an approach that consists of using multiobjective optimisation techniques via simulation in order to help software project managers find the best values for initial team size and schedule estimates for a given project so that cost, time and productivity are optimised. using a system dynamics (sd) simulation model of a software project, the sensitivity of the output variables regarding productivity, cost and schedule using different initial team size and schedule estimations is determined. the generated data is combined with a well-known multiobjective optimisation algorithm, nsga-ii, to find optimal solutions for the output variables. the nsga-ii algorithm was able to quickly converge to a set of optimal solutions composed of multiple and conflicting variables from a medium size software project simulation model. multiobjective optimisation and sd simulation modeling are complementary techniques that can generate the pareto front needed by project managers for decision making. furthermore, visual representations of such solutions are intuitive and can help project managers in their decision making process.",
            "contribution_ids": [
                "R28876"
            ]
        },
        {
            "instance_id": "R29012xR29000",
            "comparison_id": "R29012",
            "paper_id": "R29000",
            "text": "Localizing Parts of Faces Using a Consensus of Exemplars we present a novel approach to localizing parts in images of human faces. the approach combines the output of local detectors with a nonparametric set of global models for the part locations based on over 1,000 hand-labeled exemplar images. by assuming that the global models generate the part locations as hidden variables, we derive a bayesian objective function. this function is optimized using a consensus of models for these hidden variables. the resulting localizer handles a much wider range of expression, pose, lighting, and occlusion than prior ones. we show excellent performance on real-world face datasets such as labeled faces in the wild (lfw) and a new labeled face parts in the wild (lfpw) and show that our localizer achieves state-of-the-art performance on the less challenging bioid dataset.",
            "contribution_ids": [
                "R29001",
                "R29017",
                "R29102"
            ]
        },
        {
            "instance_id": "R29012xR29008",
            "comparison_id": "R29012",
            "paper_id": "R29008",
            "text": "The First Facial Landmark Tracking in-the-Wild Challenge: Benchmark and Results \"detection and tracking of faces in image sequences is among the most well studied problems in the intersection of statistical machine learning and computer vision. often, tracking and detection methodologies use a rigid representation to describe the facial region 1, hence they can neither capture nor exploit the non-rigid facial deformations, which are crucial for countless of applications (e.g., facial expression analysis, facial motion capture, high-performance face recognition etc.). usually, the non-rigid deformations are captured by locating and tracking the position of a set of fiducial facial landmarks (e.g., eyes, nose, mouth etc.). recently, we witnessed a burst of research in automatic facial landmark localisation in static imagery. this is partly attributed to the availability of large amount of annotated data, many of which have been provided by the first facial landmark localisation challenge (also known as 300-w challenge). even though now well established benchmarks exist for facial landmark localisation in static imagery, to the best of our knowledge, there is no established benchmark for assessing the performance of facial landmark tracking methodologies, containing an adequate number of annotated face videos. in conjunction with iccv'2015 we run the first competition/challenge on facial landmark tracking in long-term videos. in this paper, we present the first benchmark for long-term facial landmark tracking, containing currently over 110 annotated videos, and we summarise the results of the competition.\"",
            "contribution_ids": [
                "R29009"
            ]
        },
        {
            "instance_id": "R29034xR28973",
            "comparison_id": "R29034",
            "paper_id": "R28973",
            "text": "Hyperface: A deep multi-task learning framework for face detection, land- mark localization, pose estimation, and gender recognition we present an algorithm for simultaneous face detection, landmarks localization, pose estimation and gender recognition using deep convolutional neural networks (cnn). the proposed method called, hyperface, fuses the intermediate layers of a deep cnn using a separate cnn followed by a multi-task learning algorithm that operates on the fused features. it exploits the synergy among the tasks which boosts up their individual performances. additionally, we propose two variants of hyperface: (1)\\xa0hyperface-resnet that builds on the resnet-101 model and achieves significant improvement in performance, and (2)\\xa0fast-hyperface that uses a high recall fast face detector for generating region proposals to improve the speed of the algorithm. extensive experiments show that the proposed models are able to capture both global and local information in faces and performs significantly better than many competitive algorithms for each of these four tasks.",
            "contribution_ids": [
                "R28974",
                "R29015"
            ]
        },
        {
            "instance_id": "R29034xR29021",
            "comparison_id": "R29034",
            "paper_id": "R29021",
            "text": "Face alignment by coarse-to-fine shape searching we present a novel face alignment framework based on coarse-to-fine shape searching. unlike the conventional cascaded regression approaches that start with an initial shape and refine the shape in a cascaded manner, our approach begins with a coarse search over a shape space that contains diverse shapes, and employs the coarse solution to constrain subsequent finer search of shapes. the unique stage-by-stage progressive and adaptive search i) prevents the final solution from being trapped in local optima due to poor initialisation, a common problem encountered by cascaded regression approaches; and ii) improves the robustness in coping with large pose variations. the framework demonstrates real-time performance and state-of-the-art results on various benchmarks including the challenging 300-w dataset.",
            "contribution_ids": [
                "R29022"
            ]
        },
        {
            "instance_id": "R29080xR29047",
            "comparison_id": "R29080",
            "paper_id": "R29047",
            "text": "Pose-Free Facial Landmark Fitting via Optimized Part Mixtures and Cascaded Deformable Shape Model this paper addresses the problem of facial landmark localization and tracking from a single camera. we present a two-stage cascaded deformable shape model to effectively and efficiently localize facial landmarks with large head pose variations. for face detection, we propose a group sparse learning method to automatically select the most salient facial landmarks. by introducing 3d face shape model, we use procrustes analysis to achieve pose-free facial landmark initialization. for deformation, the first step uses mean-shift local search with constrained local model to rapidly approach the global optimum. the second step uses component-wise active contours to discriminatively refine the subtle shape variation. our framework can simultaneously handle face detection, pose-free landmark localization and tracking in real time. extensive experiments are conducted on both laboratory environmental face databases and face-in-the-wild databases. all results demonstrate that our approach has certain advantages over state-of-the-art methods in handling pose variations.",
            "contribution_ids": [
                "R29048"
            ]
        },
        {
            "instance_id": "R29080xR29050",
            "comparison_id": "R29080",
            "paper_id": "R29050",
            "text": "Detector of facial landmarks learned by the structured output SVM in this paper we describe a detector of facial landmarks based on the deformable part models. we treat the task of landmark detection as an instance of the structured output classification problem. we propose to learn the parameters of the detector from data by the structured output support vector machines algorithm. in contrast to the previous works, the objective function of the learning algorithm is directly related to the performance of the resulting detector which is controlled by a user-defined loss function. the resulting detector is real-time on a standard pc, simple to implement and it can be easily modified for detection of a different set of landmarks. we evaluate performance of the proposed landmark detector on a challenging \u201clabeled faces in the wild\u201d (lfw) database. the empirical results demonstrate that the proposed detector is consistently more accurate than two public domain implementations based on the active appearance models and the deformable part models. we provide an open-source implementation of the proposed detector and the manual annotation of the facial landmarks for all images in the lfw database.",
            "contribution_ids": [
                "R29051"
            ]
        },
        {
            "instance_id": "R29080xR29053",
            "comparison_id": "R29080",
            "paper_id": "R29053",
            "text": "Facial point detection using boosted regression and graph models \"finding fiducial facial points in any frame of a video showing rich naturalistic facial behaviour is an unsolved problem. yet this is a crucial step for geometric-feature-based facial expression analysis, and methods that use appearance-based features extracted at fiducial facial point locations. in this paper we present a method based on a combination of support vector regression and markov random fields to drastically reduce the time needed to search for a point's location and increase the accuracy and robustness of the algorithm. using markov random fields allows us to constrain the search space by exploiting the constellations that facial points can form. the regressors on the other hand learn a mapping between the appearance of the area surrounding a point and the positions of these points, which makes detection of the points very fast and can make the algorithm robust to variations of appearance due to facial expression and moderate changes in head pose. the proposed point detection algorithm was tested on 1855 images, the results of which showed we outperform current state of the art point detectors.\"",
            "contribution_ids": [
                "R29054"
            ]
        },
        {
            "instance_id": "R29080xR29056",
            "comparison_id": "R29080",
            "paper_id": "R29056",
            "text": "Robust Discriminative Response Map Fitting with Constrained Local Models we present a novel discriminative regression based approach for the constrained local models (clms) framework, referred to as the discriminative response map fitting (drmf) method, which shows impressive performance in the generic face fitting scenario. the motivation behind this approach is that, unlike the holistic texture based features used in the discriminative aam approaches, the response map can be represented by a small set of parameters and these parameters can be very efficiently used for reconstructing unseen response maps. furthermore, we show that by adopting very simple off-the-shelf regression techniques, it is possible to learn robust functions from response maps to the shape parameters updates. the experiments, conducted on multi-pie, xm2vts and lfpw database, show that the proposed drmf method outperforms state-of-the-art algorithms for the task of generic face fitting. moreover, the drmf method is computationally very efficient and is real-time capable. the current matlab implementation takes 1 second per image. to facilitate future comparisons, we release the matlab code and the pre-trained models for research purposes.",
            "contribution_ids": [
                "R29057"
            ]
        },
        {
            "instance_id": "R29153xR29123",
            "comparison_id": "R29153",
            "paper_id": "R29123",
            "text": "The emergence of enterprise systems management: a challenge to the IS curriculum this paper proposes four cornerstones of a future information systems (is) curriculum. it analyses the challenges of the is curriculum based on the development of enterprise systems, and further argues that the practice and the research into enterprise systems have progressed to a new stage resulting in the emergence of enterprise systems management (esm). esm calls for new competences and consequently represents new challenges to the is curriculum. the paper outlines potential teaching issues and discusses the impact on the is curriculum. finally the paper suggests ways of approaching the challenges.",
            "contribution_ids": [
                "R29124"
            ]
        },
        {
            "instance_id": "R29153xR29140",
            "comparison_id": "R29153",
            "paper_id": "R29140",
            "text": "An Updated ERP Systems Annotated Bibliography: 2001-2005 this study provides an updated annotated bibliography of erp publications published in the main is conferences and journals during the period 2001-2005, categorizing them through an erp lifecycle-based framework that is structured in phases. the first version of this bibliography was published in 2001 (esteves and pastor, 2001c). however, so far, we have extended the bibliography with a significant number of new publications in all the categories used in this paper. we also reviewed the categories and some incongruities were eliminated.",
            "contribution_ids": [
                "R29141"
            ]
        },
        {
            "instance_id": "R29153xR29143",
            "comparison_id": "R29153",
            "paper_id": "R29143",
            "text": "Enterprise Resource Planning (ERP): a review of the literature this article is a review of work published in various journals on the topics of enterprise resource planning (erp) between january 2000 and may 2006. a total of 313 articles from 79 journals are reviewed. the article intends to serve three goals. first, it will be useful to researchers who are interested in understanding what kinds of questions have been addressed in the area of erp. second, the article will be a useful resource for searching for research topics. third, it will serve as a comprehensive bibliography of the articles published during the period. the literature is analysed under six major themes and nine sub-themes.",
            "contribution_ids": [
                "R29144"
            ]
        },
        {
            "instance_id": "R29153xR29146",
            "comparison_id": "R29153",
            "paper_id": "R29146",
            "text": "A review of literature on Enterprise Resource Planning systems enterprise resource planning (erp) systems are currently involved into every aspect of organization as they provide a highly integrated solution to meet the information system needs. erp systems have attracted a large amount of researchers and practitioners attention and received a variety of investigate and study. in this paper, we have selected a certain number of papers concerning erp systems between 1998 and 2006, and this is by no means a comprehensive review. the literature is further classified by its topic and the major outcomes and research methods of each study are addressed. following implications for future research are provided.",
            "contribution_ids": [
                "R29147"
            ]
        },
        {
            "instance_id": "R29184xR29159",
            "comparison_id": "R29184",
            "paper_id": "R29159",
            "text": "Planning for ERP systems: analysis and future trend the successful implementation of various enterprise resource planning (erp) systems has provoked considerable interest over the last few years. management has recently been enticed to look toward these new information technologies and philosophies of manufacturing for the key to survival or competitive edges. although there is no shortage of glowing reports on the success of erp installations, many companies have tossed millions of dollars in this direction with little to show for it. since many of the erp failures today can be attributed to inadequate planning prior to installation, we choose to analyze several critical planning issues including needs assessment and choosing a right erp system, matching business process with the erp system, understanding the organizational requirements, and economic and strategic justification. in addition, this study also identifies new windows of opportunity as well as challenges facing companies today as enterprise systems continue to evolve and expand.",
            "contribution_ids": [
                "R29160"
            ]
        },
        {
            "instance_id": "R29184xR29161",
            "comparison_id": "R29184",
            "paper_id": "R29161",
            "text": "Enterprise resource planning (ERP) systems: a research agenda the continuing development of enterprise resource planning (erp) systems has been considered by many researchers and practitioners as one of the major it innovations in this decade. erp solutions seek to integrate and streamline business processes and their associated information and work flows. what makes this technology more appealing to organizations is increasing capability to integrate with the most advanced electronic and mobile commerce technologies. however, as is the case with any new it field, research in the erp area is still lacking and the gap in the erp literature is huge. attempts to fill this gap by proposing a novel taxonomy for erp research. also presents the current status with some major themes of erp research relating to erp adoption, technical aspects of erp and erp in is curricula. the discussion presented on these issues should be of value to researchers and practitioners. future research work will continue to survey other major areas presented in the taxonomy framework.",
            "contribution_ids": [
                "R29162"
            ]
        },
        {
            "instance_id": "R29240xR29191",
            "comparison_id": "R29240",
            "paper_id": "R29191",
            "text": "Critical factors for successful implementation of enterprise systems enterprise resource planning (erp) systems have emerged as the core of successful information management and the enterprise backbone of organizations. the difficulties of erp implementations have been widely cited in the literature but research on the critical factors for initial and ongoing erp implementation success is rare and fragmented. through a comprehensive review of the literature, 11 factors were found to be critical to erp implementation success \u2013 erp teamwork and composition; change management program and culture; top management support; business plan and vision; business process reengineering with minimum customization; project management; monitoring and evaluation of performance; effective communication; software development, testing and troubleshooting; project champion; appropriate business and it legacy systems. the classification of these factors into the respective phases (chartering, project, shakedown, onward and upward) in markus and tanis\u2019 erp life cycle model is presented and the importance of each factor is discussed.",
            "contribution_ids": [
                "R29192"
            ]
        },
        {
            "instance_id": "R29240xR29208",
            "comparison_id": "R29240",
            "paper_id": "R29208",
            "text": "A Review of Critical Success Factors for ERP-Projects erp projects are complex purposes which influence main internal and external operations of companies. the success of the project directly influences the performance and the survival of the organisation. recent research has me- thodically collected plausible data in the field of critical success factors (csfs) within erp projects. this article describes how the collected publications were used to identify the main csfs and how they can be ranked according to the impor- tance of success or failure through a literature review. because of the influence of csfs to erp-projects in general, the term \"erp project\" is used in the further parts of this paper. the second part of this paper proposes how csfs can be in- tegrated into classical erp project phases. past researches did nearly not investigate how csfs which were mentioned in different publications can influence the erp-project phases. at the end of the paper the trend of csf in relation of the publication year and the origin of the author are shown.",
            "contribution_ids": [
                "R29209"
            ]
        },
        {
            "instance_id": "R29240xR29217",
            "comparison_id": "R29240",
            "paper_id": "R29217",
            "text": "The Core Critical Success Factors in Implementation of Enterprise Resource Planning Systems the implementation of enterprise resource planning (erp) systems require huge investments while ineffective implementations of such projects are commonly observed. a considerable number of these projects have been reported to fail or take longer than it was initially planned, while previous studies show that the aim of rapid implementation of such projects has not been successful and the failure of the fundamental goals in these projects have imposed huge amounts of costs on investors. some of the major consequences are the reduction in demand for such products and the introduction of further skepticism to the managers and investors of erp systems. in this regard, it is important to understand the factors determining success or failure of erp implementation. the aim of this paper is to study the critical success factors (csfs) in implementing erp systems and to develop a conceptual model which can serve as a basis for erp project managers. these critical success factors that are called \u201ccore critical success factors\u201d are extracted from 62 published papers using the content analysis and the entropy method. the proposed conceptual model has been verified in the context of five multinational companies.",
            "contribution_ids": [
                "R29218"
            ]
        },
        {
            "instance_id": "R29240xR29194",
            "comparison_id": "R29240",
            "paper_id": "R29194",
            "text": "Critical successful factors of ERP implementation: a review recently e -business has become the focus of management interest both in academics and in business. among the major components of e -business, erp (enterprise resource planning) is the backbone of other applications. therefore more and more enterprises attempt to adopt this new application in order to improve their business competitiveness. owing to the specific characteristics of erp, its implementation is more difficult than that of traditional information systems. for this reason, how to implement erp successfully becomes an important issue for both academics and practitioners. in this paper, a review on critical successful factors of erp in important mis publications will be presented. additionally traditional is implementatio n and erp implementation will be compared and the findings will be served as the basis for further research.",
            "contribution_ids": [
                "R29195"
            ]
        },
        {
            "instance_id": "R29240xR29203",
            "comparison_id": "R29240",
            "paper_id": "R29203",
            "text": "Critical success factors in ERP implementation: a review erp systems have become vital strategic tools in today\u2019s competitive business environment. this ongoing research study presents a review of recent research work in erp systems. it attempts to identify the main benefits of erp systems, the drawbacks and the critical success factors for implementation discussed in the relevant literature. the findings revealed that despite some organizations have faced challenges undertaking erp implementations, many others have enjoyed the benefits that the systems have brought to the organizations. erp system facilitates the smooth flow of common functional information and practices across the entire organization. in addition, it improves the performance of the supply chain and reduces the cycle times. however, without top management support, having appropriate business plan and vision, re-engineering business process, effective project management, user involvement and education and training, organizations can not embrace the full benefits of such complex system and the risk of failure might be at high level.",
            "contribution_ids": [
                "R29204"
            ]
        },
        {
            "instance_id": "R29240xR29229",
            "comparison_id": "R29240",
            "paper_id": "R29229",
            "text": "Strategic success factors in ERP system implementation different ways of approaching erp implementation give different results. in order to successfully implement an erp system it is necessary to properly balance critical success factors. by researching what the critical success factors in erp implementation are, why they are critical, and to what extent they are relevant to users, consultants and suppliers, this paper seeks to identify strategic critical success factors in erp implementation and to understand the impact of each factor on the success of erp system introduction. this paper lists strategic critical success factors (csf), which are influence the long-term goals. key-words: erp implementation, measuring success, cost, critical success factors, management, it project",
            "contribution_ids": [
                "R29230"
            ]
        },
        {
            "instance_id": "R29351xR29304",
            "comparison_id": "R29351",
            "paper_id": "R29304",
            "text": "Deconstructing information packages: organizational and behavioural implications of ERP systems argues that the organizational involvement of large scale information technology packages, such as those known as enterprise resource planning (erp), has important implications that go far beyond the acknowledged effects of keeping the organizational operations accountable and integrated across functions and production sites. claims that erp packages are predicated on an understanding of human agency as a procedural affair and of organizations as an extended series of functional or cross\u2010functional transactions. accordingly, the massive introduction of erp packages to organizations is bound to have serious implications that precisely recount the procedural forms by which such packages instrument organizational operations and fashion organizational roles. the conception of human agency and organizational operations in procedural terms may seem reasonable yet it recounts a very specific and, in a sense, limited understanding of humans and organizations. the distinctive status of framing human agency and organizations in procedural terms becomes evident in its juxtaposition with other forms of human action like improvisation, exploration or playing. these latter forms of human involvement stand out against the serial fragmentation underlying procedural action. they imply acting on the world on loose premises that trade off a variety of forms of knowledge and courses of action in attempts to explore and discover alternative ways of coping with reality.",
            "contribution_ids": [
                "R29305"
            ]
        },
        {
            "instance_id": "R29351xR29312",
            "comparison_id": "R29351",
            "paper_id": "R29312",
            "text": "Extended-enterprise systems\u00e2\u0080\u0099 impact on enterprise risk management\u00e2\u0080\u009d \" purpose \u2013 this article aims to focus on raising awareness of the limitations of traditional \u201centerprise\u2010centric\u201d views of enterprise risk management that ignore the risks that are inherited from key business and supply chain partners. in essence, enterprise systems implementations have allowed organizations to couple their operations more tightly with other business partners, particularly in the area of supply chain management, and in the process enterprise systems applications are redefining the boundaries of the entity in terms of risk management concerns and the scope of financial audits. design/methodology/approach \u2013 the prior literature that has begun to explore aspects of assessing key risk components in these relationships is reviewed with an eye to highlighting the limitations of what is understood about risk in interorganizational relationships. this analysis of the prior research establishes the basis for the logical formation of a framework for future enterprise risk management research in the area of e\u2010commerce relationships. findings \u2013 conclusions focus on the overall framework of risks that should be considered when interorganizational relationships are critical to an enterprise's operations and advocate an \u201cextended\u2010enterprise\u201d view of enterprise risk management. research limitations/implications \u2013 the framework introduced in this paper provides guidance for future research in the area of interorganizational systems control and risk assessment. practical implications \u2013 the framework further highlights areas of risk that auditors and corporate risk managers should consider in assessing the risk inherited through interorganizational relationships. originality/value \u2013 the paper highlights the need to shift from an enterprise\u2010centric view of risk management to an extended\u2010enterprise risk management view. \"",
            "contribution_ids": [
                "R29313"
            ]
        },
        {
            "instance_id": "R29351xR29328",
            "comparison_id": "R29351",
            "paper_id": "R29328",
            "text": "A comparison of ERP-success measurement approaches\u00e2\u0080\u009d erp projects are complex purposes which influence main internal and external operations of companies. there are different research approaches which try to develop models for is / erp success measurement or it-success measurement in general. each model has its own area of application and sometimes a specific measurement approach based, for instance, on different systems or different stakeholders involved. this research paper shows some of the most important models developed in the literature and an overview of the different approaches of the models. an analysis which shows the strengths, weaknesses and the cases in which the specific model could be used is made.",
            "contribution_ids": [
                "R29329"
            ]
        },
        {
            "instance_id": "R29351xR29332",
            "comparison_id": "R29351",
            "paper_id": "R29332",
            "text": "Taking knowledge management on the ERP road: a two-dimensional analysis\u00e2\u0080\u009d \"in today's fierce business competition, companies face the tremendous challenge of expanding markets, improving their products, services and processes and exploiting their intellectual capital in a dynamic network of knowledge-intensive relations inside and outside their borders. in order to accomplish these objectives, more and more companies are turning to the enterprise resource planning systems (erp). on the other hand, knowledge management (km) has received considerable attention in the last decade and is continuously gaining interest by industry, enterprises and academia. as we are moving into an era of \u201cknowledge capitalism\u201d, knowledge management will play a fundamental role in the success of today's businesses. this paper aims at throwing light on the role of km in the erp success first and on their possible integration second. a wide range of academic and practitioner literature related to km and erp is reviewed. on the basis of this review, the paper gives answers to specific research questions and analyses future research directions.\"",
            "contribution_ids": [
                "R29333"
            ]
        },
        {
            "instance_id": "R29351xR29349",
            "comparison_id": "R29351",
            "paper_id": "R29349",
            "text": "Factors for the acceptance of enterprise resource planning (ERP) systems and financial performance\u00e2\u0080\u009d this paper examined the effects of ntbs on maize price received by smallholder famers and traders in mbozi and momba districts of mbeya region in tanzania. cross sectional data were collected from 240 smallholder farmers and 50 traders from selected villages and markets using structure questionnaires and focused group discussion. a two stage - stratified sampling procedures were used in the selection of farmers. findings from study show that, ntbs has an inversely relationship with maize prices having coefficient valued at -0.062. this implies that, for a unit increase in ntbs costs there would be a 6.2% decline in farmer\u2019s prices in the rural areas and rise in consumer\u2019 prices by the same percent in the urban centers. moreover, maize prices seem to decrease with an increase in distance from the rural markets to urban markets and that contributions of ntbs on producer prices were higher between rural and districts markets. the paper concluded that, ntbs play a significant contribution on the increase in transaction costs which leads to lowering farm gate prices in the rural and increased consumer prices in the urban areas. it is therefore recommended that, protective food policy such as ntbs strategies should be minimized in order to maintain reasonably high prices in rural areas and low prices in urban areas.",
            "contribution_ids": [
                "R29350"
            ]
        },
        {
            "instance_id": "R29351xR29316",
            "comparison_id": "R29351",
            "paper_id": "R29316",
            "text": "Organisations and vanilla software: what do we know about ERP systems and competitive advantage? enterprise resource planning (erp) systems have become a de facto standard for integrating business functions. but an obvious question arises: if every business is using the same socalled \u201cvanilla\u201d software (e.g. an sap erp system) what happens to the competitive advantage from implementing it systems? if we discard our custom-built legacy systems in favour of enterprise systems do we also jettison our valued competitive advantage from it? while for some organisations erps have become just a necessity for conducting business, others want to exploit them to outperform their competitors. in the last few years, researchers have begun to study the link between erp systems and competitive advantage. this link will be the focus of this paper. we outline a framework summarizing prior research and suggest two researchable questions. a future article will develop the framework with two empirical case studies from within part of the european food industry.",
            "contribution_ids": [
                "R29317"
            ]
        },
        {
            "instance_id": "R30476xR29422",
            "comparison_id": "R30476",
            "paper_id": "R29422",
            "text": "Growth and the Environment in Canada: An Empirical Analysis standard reduced form models are estimated for canada to examine the relationships between real per capita gdp and four measures of environmental degradation. of the four chosen measures of environmental degradation, only concentrations of carbon monoxide appear to decline in the long run with increases in real per capita income. the data used in the reduced form models are also tested for the presence of unit roots and for the existence of cointegration between each of the measures of environmental degradation and per capita income. unit root tests indicate nonstationarity in logs of the measures of environmental degradation and per capita income. the engle-granger test and the maximum eigenvalue test suggest that per capita income and the measures of environmental degradation are not cointegrated, or that a long-term relationship between the variables does not exist. causality tests also indicate a bi-directional causality, rather than a uni-directional causality, from income to the environment. the results suggest that canada does not have the luxury of being able to grow out of its environmental problems. the implication is that to prevent further environmental degradation, canada requires concerted policies and incentives to reduce pollution intensity per unit of output across sectors, to shift from more to less pollution-producing-outputs and to lower the environmental damage associated with aggregate consumption.",
            "contribution_ids": [
                "R29423"
            ]
        },
        {
            "instance_id": "R30476xR29502",
            "comparison_id": "R30476",
            "paper_id": "R29502",
            "text": "Environmental Kuznets Curves for CO2: Heterogeneity versus Homogeneity we explore the emissions income relationship for co2 in oecd countries using various modelling strategies.even for this relatively homogeneous sample, we find that the inverted-u-shaped curve is quite sensitive to the degree of heterogeneity included in the panel estimations.this finding is robust, not only across different model specifications but also across estimation techniques, including the more flexible non-parametric approach.differences in restrictions applied in panel estimations are therefore responsible for the widely divergent findings for an inverted-u shape for co2.our findings suggest that allowing for enough heterogeneity is essential to prevent spurious correlation from reduced-form panel estimations.moreover, this inverted u for co2 is likely to exist for many, but not for all, countries.",
            "contribution_ids": [
                "R29503"
            ]
        },
        {
            "instance_id": "R30476xR29637",
            "comparison_id": "R30476",
            "paper_id": "R29637",
            "text": "Environmental Kuznets curve for CO2 in Canada the environmental kuznets curve hypothesis is a theory by which the relationship between per capita gdp and per capita pollutant emissions has an inverted u shape. this implies that, past a certain point, economic growth may actually be profitable for environmental quality. most studies on this subject are based on estimating fully parametric quadratic or cubic regression models. while this is not technhically wrong, such an approach somewhat lacks flexibility since it may fail to detect the true shape of the relationship if it happens not to be of the specified form. we use semiparametric and flexible nonlinear parametric modelling methods in an attempt to provide more robust inferences. we find little evidence in favour of the environmental kuznets curve hypothesis. our main results could be interpreted as indicating that the oil shock of the 1970s has had an important impact on progress towards less polluting technology and production.",
            "contribution_ids": [
                "R29638"
            ]
        },
        {
            "instance_id": "R30476xR29816",
            "comparison_id": "R30476",
            "paper_id": "R29816",
            "text": "Environmental Kuznets curve and growth source in Iran recent empirical research has examined the relationship between certain\\n indicators of environmental degradation and income, concluding that in some\\n cases an inverted u-shaped relationship, which has been called an\\n environmental kuznets curve (ekc), exists between these variables. the source\\n of growth explanation is important for two reasons. first, it demonstrates\\n how the pollution consequences of growth depend on the source of growth.\\n therefore, the analogy drawn by some in the environmental community between\\n the damaging effects of economic development and those of liberalized trade\\n is, at best, incomplete. second, the source of growth explanation\\n demonstrates that a strong policy response to income gains is not necessary\\n for pollution to fall with growth. the aim of this paper investigates the\\n role of differences source of growth in environmental quality of iran. the\\n results show the two growth resources in iran cause, in the early stages, co2\\n emission decreases until turning point but beyond this level of income per\\n capita, economic growth leads to environmental degradation. i find a u\\n relationship between environmental degradation (co2 emission) and economic\\n growth in iran.",
            "contribution_ids": [
                "R29817"
            ]
        },
        {
            "instance_id": "R30476xR29881",
            "comparison_id": "R30476",
            "paper_id": "R29881",
            "text": "Environmental Kuznets curve: evidences from developed and developing economies previous studies show that the environmental quality and economic growth can be represented by the inverted u curve called environmental kuznets curve (ekc). in this study, we conduct empirical analyses on detecting the existence of ekc using the five common pollutants emissions (i.e. co2, so2, bod, spm10, and ghg) as proxy for environmental quality. the data spanning from year 1961 to 2009 and cover 40 countries. we seek to investigate if the ekc hypothesis holds in two groups of economies, i.e. developed versus developing economies. applying panel data approach, our results show that the ekc does not hold in all countries. we also detect the existence of u shape and increasing trend in other cases. the results reveal that co2 and spm10 are good data to proxy for environmental pollutant and they can be explained well by gdp. also, it is observed that the developed countries have higher turning points than the developing countries. higher economic growth may lead to different impacts on environmental quality in different economies.",
            "contribution_ids": [
                "R29882"
            ]
        },
        {
            "instance_id": "R30476xR29973",
            "comparison_id": "R30476",
            "paper_id": "R29973",
            "text": "The environmental Kuznets curve in Asia: the case of sulphur and carbon emissions\u00e2\u0080\u009d the present study examines whether the race to the bottom and revised ekc scenarios presented by dasgupta and others (2002) are, with regard to the analytical framework of the environmental kuznets curve (ekc), applicable in asia to representative environmental indices, such as sulphur emissions and carbon emissions. to carry out this study, a generalized method of moments (gmm) estimation was made, using panel data of 19 economies for the period 1950-2009. the main findings of the analysis on the validity of ekc indicate that sulphur emissions follow the expected inverted u-shape pattern, while carbon emissions tend to increase in line with per capita income in the observed range. as for the race to the bottom and revised ekc scenarios, the latter was verified in sulphur emissions, as their ekc trajectories represent a linkage of the later development of the economy with the lower level of emissions while the former one was not present in neither sulphur nor carbon emissions.",
            "contribution_ids": [
                "R29974"
            ]
        },
        {
            "instance_id": "R30476xR30076",
            "comparison_id": "R30476",
            "paper_id": "R30076",
            "text": "Beyond the Environmental Kuznets Curve in Africa: Evidence from Panel Cointegration abstract the main objective of this study is to establish the applicability of the environmental kuznets curve (ekc) hypothesis in explaining the relationship between environmental pollution and development in africa. the ekc has been used to explain such relationships in a variety of contexts, yet rarely applied in africa, despite it hosting both the poorest countries in the world, 60% of those with extreme environmental pollution vulnerability and having a distinct socio-economic and institutional profile that tests the validity of such a model. this paper describes an empirical model that applies the ekc hypothesis and its modifications to 50 african countries, using data from 1995\u20132010. the empirical analysis suggests that there is a long-term relationship between co2 and particulate matter emissions with per capita income and other variables, including institutional factors and trade, leading to specific recommendations on future strategies for sustainable development in an african context.",
            "contribution_ids": [
                "R30077"
            ]
        },
        {
            "instance_id": "R30476xR30088",
            "comparison_id": "R30476",
            "paper_id": "R30088",
            "text": "Environmental Kuznets curve in an open economy: a bounds testing and causality analysis for Tunisia the aim of this paper is to investigate the existence of environmental kuznets curve (ekc) in an open economy like tunisia using annual time series data for the period of 1971-2010. the ardl bounds testing approach to cointegration is applied to test long run relationship in the presence of structural breaks and vector error correction model (vecm) to detect the causality among the variables. the robustness of causality analysis has been tested by applying the innovative accounting approach (iaa). the findings of this paper confirmed the long run relationship between economic growth, energy consumption, trade openness and co2 emissions in tunisian economy. the results also indicated the existence of ekc confirmed by the vecm and iaa approaches. the study has significant contribution for policy implications to curtail energy pollutants by implementing environment friendly regulations to sustain the economic development in tunisia.",
            "contribution_ids": [
                "R30089"
            ]
        },
        {
            "instance_id": "R30476xR30260",
            "comparison_id": "R30476",
            "paper_id": "R30260",
            "text": "The environmental Kuznets curve at different levels of economic development: a counterfactual quantile regression analysis for CO2emissions \"this paper applies the quantile fixed effects technique in exploring the co2 environmental kuznets curve within two groups of economic development (oecd and non-oecd countries) and six geographical regions \u2013 west, east europe, latin america, east asia, west asia and africa. a comparison of the findings resulting from the use of this technique with those of conventional fixed effects method reveals that the latter may depict a flawed summary of the prevailing income\u2013emissions nexus depending on the conditional quantile examined. the paper also extends the machado and mata decomposition method to the kuznets curve framework to explore the most important explanations for co2 emissions gap between oecd and non-oecd countries. we find a statistically significant oecd--non-oecd emissions gap and the decomposition reveals that there are non-income related factors working against the non-oecd group's greening. we tentatively conclude that deliberate and systematic mitigation of current co2 emissions in the non-oecd group is required.\"",
            "contribution_ids": [
                "R30261"
            ]
        },
        {
            "instance_id": "R30476xR30284",
            "comparison_id": "R30476",
            "paper_id": "R30284",
            "text": "The Relationship between CO2 Emission, Energy Consumption, Urbanization and Trade Openness for Selected CEECs this paper investigates the relationship between co2 emission, real gdp, energy consumption, urbanization and trade openness for 10 for selected central and eastern european countries (ceecs), including, albania, bulgaria, croatia, czech republic, macedonia, hungary, poland, romania, slovak republic and slovenia for the period of 1991\u20132011. the results show that the environmental kuznets curve (ekc) hypothesis holds for these countries. the fully modified ordinary least squares (fmols) results reveal that a 1% increase in energy consumption leads to a %1.0863 increase in co2 emissions. results for the existence and direction of panel vector error correction model (vecm) granger causality method show that there is bidirectional causal relationship between co2 emissions - real gdp and energy consumption-real gdp as well.",
            "contribution_ids": [
                "R30285"
            ]
        },
        {
            "instance_id": "R30476xR30373",
            "comparison_id": "R30476",
            "paper_id": "R30373",
            "text": "CO2emissions in Australia: economic and non-economic drivers in the long-run abstract australia has sustained a relatively high economic growth rate since the 1980s compared to other developed countries. per capita co2 emissions tend to be highest amongst oecd countries, creating new challenges to cut back emissions towards international standards. this research explores the long-run dynamics of co2 emissions, economic and population growth along with the effects of globalization tested as contributing factors. we find economic growth is not emission-intensive in australia, while energy consumption is emissions intensive. second, in an environment of increasing population, our findings suggest australia needs to be energy efficient at the household level, creating appropriate infrastructure for sustainable population growth. high population growth and open migration policy can be detrimental in reducing co2 emissions. finally, we establish globalized environment has been conducive in combating emissions. in this respect, we establish the beneficial effect of economic globalization compared to social and political dimensions of globalization in curbing emissions.",
            "contribution_ids": [
                "R30374"
            ]
        },
        {
            "instance_id": "R30476xR29741",
            "comparison_id": "R30476",
            "paper_id": "R29741",
            "text": "Economic Development and Environmental Quality in Nigeria: Is There an Environmental Kuznets Curve? this study utilizes standard- and nested-ekc models to investigate the income-environment relation for nigeria, between 1960 and 2008. the results from the standard-ekc model provides weak evidence of an inverted-u shaped relationship with turning point (t.p) around $280.84, while the nested model presents strong evidence of an n-shaped relationship between income and emissions in nigeria, with a t.p around $237.23. tests for structural breaks caused by the 1973 oil price shocks and 1986 structural adjustment are not rejected, implying that these factors have not significantly affected the income-environment relationship in nigeria. further, results from the rolling interdecadal analysis shows that the observed relationship is stable and insensitive to the sample interval chosen. overall, our findings imply that economic development is compatible with environmental improvements in nigeria. however, tighter and concentrated environmental policy regimes will be required to ensure that the relationship is maintained around the first two-strands of the n-shape",
            "contribution_ids": [
                "R29742"
            ]
        },
        {
            "instance_id": "R30476xR30390",
            "comparison_id": "R30476",
            "paper_id": "R30390",
            "text": "Relationship between economic growth and environmental degradation: is there evidence of an environmental Kuznets curve for Brazil? this study investigates the relationship between co2 emissions, economic growth, energy use and electricity production by hydroelectric sources in brazil. to verify the environmental kuznets curve (ekc) hypothesis we use time-series data for the period 1971-2011. the autoregressive distributed lag methodology was used to test for cointegration in the long run. additionally, the vector error correction model granger causality test was applied to verify the predictive value of independent variables. empirical results find that there is a quadratic long run relationship between co2emissions and economic growth, confirming the existence of an ekc for brazil. furthermore, energy use shows increasing effects on emissions, while electricity production by hydropower sources has an inverse relationship with environmental degradation. the short run model does not provide evidence for the ekc theory. the differences between the results in the long and short run models can be considered for establishing environmental policies. this suggests that special attention to both variables-energy use and the electricity production by hydroelectric sources- could be an effective way to mitigate co2 emissions in brazil",
            "contribution_ids": [
                "R30391"
            ]
        },
        {
            "instance_id": "R30512xR30482",
            "comparison_id": "R30512",
            "paper_id": "R30482",
            "text": "BeWell+ \"smartphone sensing and persuasive feedback design is enabling a new generation of wellbeing applications capable of automatically monitoring multiple aspects of physical and mental health. in this paper, we present bewell+ the next generation of the bewell smartphone health app, which continuously monitors user behavior along three distinct health dimensions, namely sleep, physical activity, and social interaction. bewell promotes improved behavioral patterns via feedback rendered as an ambient display on the smartphone's wallpaper. with bewell+, we introduce new wellbeing mechanisms to address challenges identified during the initial deployment of the bewell app; specifically, (i) community adaptive wellbeing feedback, which automatically generalize to diverse user communities (e.g., elderly, young adults, children) by balancing the need to promote better behavior yet remains realistic to the user's goals; and, (ii) wellbeing adaptive energy allocation, which prioritizes monitoring fidelity and feedback responsiveness on specific health dimensions of wellbeing (e.g., social interaction) where the user needs most help. we evaluate the performance of these mechanisms as part of an initial deployment and user study that includes 27 people using bewell+ over a 19 day field trial. our findings show that not only can bewell+ operate successfully on consumer-grade smartphones, but users understand feedback and respond by taking positive steps towards leading healthier lifestyles.\"",
            "contribution_ids": [
                "R30483"
            ]
        },
        {
            "instance_id": "R30512xR30484",
            "comparison_id": "R30512",
            "paper_id": "R30484",
            "text": "Activmon \"in this paper we discuss the use of low-complexity interfaces to encourage users to increase their level of physical activity. we present activmon - a wearable device capable of representing a user's individual activity level, and that of a group, using an ambient display. we discuss the results of a preliminary usability evaluation of activmon.\"",
            "contribution_ids": [
                "R30485"
            ]
        },
        {
            "instance_id": "R30512xR30504",
            "comparison_id": "R30512",
            "paper_id": "R30504",
            "text": "TripleBeat \"we present triplebeat, a mobile phone based system that assists runners in achieving predefined exercise goals via musical feedback and two persuasive techniques: a glanceable interface for increased personal awareness and a virtual competition. triplebeat is based on a previous system named mptrain. first, we describe triplebeat's hardware and software, emphasizing how it differs from its predecessor mptrain. then, we present the results of a runner study with 10 runners. the study compared the runners efficacy and enjoyment in achieving predefined workout goals when running with mptrain and triplebeat. the conclusions from the study include: (1) significantly higher efficacy and enjoyment with triplebeat, and (2) a unanimous preference for triplebeat over mptrain. the glanceable interface and the virtual competition are the two main reasons for the improvements in the running experience. we believe that systems like triplebeat will play an important role in enhancing the exercise experience and in assisting users towards more active lifestyles.\"",
            "contribution_ids": [
                "R30505"
            ]
        },
        {
            "instance_id": "R30512xR30508",
            "comparison_id": "R30512",
            "paper_id": "R30508",
            "text": "Mobile system to motivate teenagers' physical activity this paper reports a mobile persuasive application to motivate teenagers to start and continue being physically active. being physically active can lead to reduced risks of having weight and cardiovascular problems; however efforts in this direction had variable success. designing technology that will be engaging and motivating for teenagers requires an understanding of the factors that contribute to behavior adoption in teenagers. to understand these, we approach the design from several theoretical models: theory of planned behavior, theory of meaning behavior, and personality theory. we found that 1) personality traits affect perceptions on physical activities and the usefulness of devices that motivate them; 2) favored motivational phrases are universal across traits; 3) those who tried our prototype was generally positive and stated that they would use it on their own; 5) the characteristics of games that are desired are: social or competitive, outdoor, simple to learn and with large variations.",
            "contribution_ids": [
                "R30509"
            ]
        },
        {
            "instance_id": "R30512xR30510",
            "comparison_id": "R30512",
            "paper_id": "R30510",
            "text": "Self-setting of physical activity goals and effects on perceived difficulty, importance and competence goal setting can be a powerful method for persuading individuals to adopt an active lifestyle. in order for this to be the case, it is important to set concrete and challenging goals, and to strongly commit to them. in this study, we explored how people set goals for physical activity and how these goals were reflected in self-regulatory mechanisms to drive goal attainment. our approach is novel in two ways: first, we used an unobtrusive wearable sensor to accurately measure physical activity throughout the day rather than rely on self-report, and second, we provided individuals with feedback about the contribution of their common daily activities (e.g., household activities) to their physical activity level. our results showed that on the basis of this feedback, participants were able to indicate to what degree they intended to change their behavior. nevertheless, they failed to set concrete goals that matched their intentions precisely. in particular, we observed that overall the set goals were in accordance with intentions (i.e., goals were set in the desired direction), but we saw a strong tendency to focus on enhancing vigorous activity at the cost of moderate intensity activity. this suggests that many individuals have intentions to change and goal setting support is needed to compose goals that accurately reflect these intentions. technology-mediated interventions might be ideal to support individuals along that path.",
            "contribution_ids": [
                "R30511"
            ]
        },
        {
            "instance_id": "R30579xR30567",
            "comparison_id": "R30579",
            "paper_id": "R30567",
            "text": "A distributed key management framework with cooperative message authentication in VANETs in this paper, we propose a distributed key management framework based on group signature to provision privacy in vehicular ad hoc networks (vanets). distributed key management is expected to facilitate the revocation of malicious vehicles, maintenance of the system, and heterogeneous security policies, compared with the centralized key management assumed by the existing group signature schemes. in our framework, each road side unit (rsu) acts as the key distributor for the group, where a new issue incurred is that the semi-trust rsus may be compromised. thus, we develop security protocols for the scheme which are able to detect compromised rsus and their colluding malicious vehicles. moreover, we address the issue of large computation overhead due to the group signature implementation. a practical cooperative message authentication protocol is thus proposed to alleviate the verification burden, where each vehicle just needs to verify a small amount of messages. details of possible attacks and the corresponding solutions are discussed. we further develop a medium access control (mac) layer analytical model and carry out ns2 simulations to examine the key distribution delay and missed detection ratio of malicious messages, with the proposed key management framework being implemented over 802.11 based vanets.",
            "contribution_ids": [
                "R30568"
            ]
        },
        {
            "instance_id": "R30579xR30570",
            "comparison_id": "R30579",
            "paper_id": "R30570",
            "text": "A Group Signature Based Secure and Privacy-Preserving Vehicular Communication Framework we propose a novel group signature based security framework for vehicular communications. compared to the traditional digital signature scheme, the new scheme achieves authenticity, data integrity, anonymity, and accountability at the same time. furthermore, we describe a scalable role-based access control approach for vehicular networks. finally, we present a probabilistic signature verification scheme that can efficiently detect the tampered messages or the messages from an unauthorized node.",
            "contribution_ids": [
                "R30571"
            ]
        },
        {
            "instance_id": "R30579xR30573",
            "comparison_id": "R30579",
            "paper_id": "R30573",
            "text": "Defense against Sybil attack in vehicular ad hoc network based on roadside unit support in this paper, we propose a timestamp series approach to defend against sybil attack in a vehicular ad hoc network (vanet) based on roadside unit support. the proposed approach targets the initial deployment stage of vanet when basic roadside unit (rsu) support infrastructure is available and a small fraction of vehicles have network communication capability. unlike previously proposed schemes that require a dedicated vehicular public key infrastructure to certify individual vehicles, in our approach rsus are the only components issuing the certificates. due to the differences of moving dynamics among vehicles, it is rare to have two vehicles passing by multiple rsus at exactly the same time. by exploiting this spatial and temporal correlation between vehicles and rsus, two messages will be treated as sybil attack issued by one vehicle if they have the similar timestamp series issued by rsus. the timestamp series approach needs neither vehicular-based public-key infrastructure nor internet accessible rsus, which makes it an economical solution suitable for the initial stage of vanet.",
            "contribution_ids": [
                "R30574"
            ]
        },
        {
            "instance_id": "R30646xR30584",
            "comparison_id": "R30646",
            "paper_id": "R30584",
            "text": "Precise eye localization through a general-to-specific model definition we present a method for precise eye localization that uses two support vector machines trained on properly selected haar wavelet coefficients. the evaluation of our technique on many standard databases exhibits very good performance. furthermore, we study the strong correlation between the eye localization error and the face recognition rate.",
            "contribution_ids": [
                "R30585",
                "R30642"
            ]
        },
        {
            "instance_id": "R30646xR30586",
            "comparison_id": "R30646",
            "paper_id": "R30586",
            "text": "PRECISE EYE AND MOUTH LOCALIZATION the literature on the topic has shown a strong correlation between the degree of precision of face localization and the face recognition performance. hence, there is a need for precise facial feature detectors, as well as objective measures for their evaluation and comparison. in this paper, we will present significant improvements to a previous method for precise eye center localization, by integrating a module for mouth localization. the technique is based on support vector machines trained on optimally chosen haar wavelet coefficients. the method has been tested on several public databases; the results are reported and compared according to a standard error measure. the tests show that the algorithm achieves high precision of localization.",
            "contribution_ids": [
                "R30587",
                "R30619",
                "R30639",
                "R30640"
            ]
        },
        {
            "instance_id": "R30646xR30590",
            "comparison_id": "R30646",
            "paper_id": "R30590",
            "text": "Average of Synthetic Exact Filters this paper introduces a class of correlation filters called average of synthetic exact filters (asef). for asef, the correlation output is completely specified for each training image. this is in marked contrast to prior methods such as synthetic discriminant functions (sdfs) which only specify a single output value per training image. advantages of asef training include: insensitivity to over-fitting, greater flexibility with regard to training images, and more robust behavior in the presence of structured backgrounds. the theory and design of asef filters is presented using eye localization on the feret database as an example task. asef is compared to other popular correlation filters including sdf, mace, otf, and umace, and with other eye localization methods including gabor jets and the opencv cascade classifier. asef is shown to outperform all these methods, locating the eye to within the radius of the iris approximately 98.5% of the time.",
            "contribution_ids": [
                "R30591"
            ]
        },
        {
            "instance_id": "R30646xR30602",
            "comparison_id": "R30646",
            "paper_id": "R30602",
            "text": "Robust precise eye location under probabilistic framework eye feature location is an important step in automatic visual interpretation and human face recognition. in this paper, a novel approach for locating eye centers in face areas under probabilistic framework is devised. after grossly locating a face, we first find the areas which left and right eyes lies in. then an appearance-based eye detector is used to detect the possible left and right eye separately. according to their probabilities, the candidates are subsampled to merge those in near positions. finally, the remaining left and right eye candidates are paired; each possible eye pair is normalized and verified. according to their probabilities, the precise eye positions are decided. the experimental results demonstrate that our method can effectively cope with different eye variations and achieve better location performance on diverse test sets than some newly proposed methods. and the influence of precision of eye location on face recognition is also probed. the location of other face organs such as mouth and nose can be incorporated in the framework easily.",
            "contribution_ids": [
                "R30603"
            ]
        },
        {
            "instance_id": "R30646xR30620",
            "comparison_id": "R30646",
            "paper_id": "R30620",
            "text": "Eye localization through multiscale sparse dictionaries this paper presents a new eye localization method via multiscale sparse dictionaries (msd). we built a pyramid of dictionaries that models context information at multiple scales. eye locations are estimated at each scale by fitting the image through sparse coefficients of the dictionary. by using context information, our method is robust to various eye appearances. the method also works efficiently since it avoids sliding a search window in the image during localization. the experiments in bioid database prove the effectiveness of our method.",
            "contribution_ids": [
                "R30621"
            ]
        },
        {
            "instance_id": "R30698xR30662",
            "comparison_id": "R30698",
            "paper_id": "R30662",
            "text": "The prevalence of dental erosion in preschool children in China 00-5712/$ see front matter q 200 i:10.1016/j.jdent.2004.08.007 * corresponding author. tel.: c44 7 5 1282. e-mail address: r.bedi@eastman.uc summary objective. to describe the prevalence of dental erosion and associated factors in preschool children in guangxi and hubei provinces of china. methods. dental examinations were carried out on 1949 children aged 3\u20135 years. measurement of erosion was confined to primary maxillary incisors. the erosion index used was based upon the 1993 uk national survey of children\u2019s dental health. the children\u2019s general information as well as social background and dietary habits were collected based on a structured questionnaire. results. a total of 112 children (5.7%) showed erosion on their maxillary incisors. ninety-five (4.9%) was scored as being confined to enamel and 17 (0.9%) as erosion extending into dentine or pulp. there was a positive association between erosion and social class in terms of parental education. a significantly higher prevalence of erosion was observed in children whose parents had post-secondary education than those whose parents had secondary or lower level of education. there was also a correlation between the presence of dental erosion and intake of fruit drink from a feeding bottle or consumption of fruit drinks at bedtime. conclusion. erosion is not a serious problem for dental heath in chinese preschool children. the prevalence of erosion is associated with social and dietary factors in this sample of children. q 2004 elsevier ltd. all rights reserved.",
            "contribution_ids": [
                "R30663"
            ]
        },
        {
            "instance_id": "R30698xR30676",
            "comparison_id": "R30698",
            "paper_id": "R30676",
            "text": "Comparison of factors potentially related to the occurrence of dental erosion in high- and low-erosion groups soft drink intake, method of drinking, ph variations, plaque topography, and various salivary, microbial and clinical factors were compared in saudi men with high (n = 10, mean = 20.5 yr) and low (n = 9, mean = 20.3 yr) dental erosion. ph-measurements were carried out with a microtouch electrode at six different intraoral locations after the subjects had consumed 330 ml of regular cola-type drink in their customary manner. the results showed that higher intake of cola-type drinks was more common in the high- (253 l yr(-1)) than in the low-erosion group (140 l yr(-1)). high erosion was associated with a method of drinking whereby the drink was kept in the mouth for a longer period (71 s vs. 40 s). ph after drinking did not differ between the groups for any of the six measuring sites. plaque accumulation on the palatal surfaces of maxillary anterior teeth and urea concentration in unstimulated saliva were lower in high-erosion subjects. aside from these, there were no differences in salivary and microbial factors between the groups. first molar cuppings, buccal cervical defects, and mouth breathing were more common in the high- than in the low-erosion group. in summary, consumption of cola-type drink, method of drinking, amount of palatal plaque on anterior teeth, and salivary urea concentration are factors associated with dental erosion.",
            "contribution_ids": [
                "R30677",
                "R30732"
            ]
        },
        {
            "instance_id": "R30698xR30684",
            "comparison_id": "R30698",
            "paper_id": "R30684",
            "text": "Is there a relationship between asthma and dental erosion? A case control study objectives\\nthe aims of this study were firstly to assess and compare the prevalence of dental erosion and dietary intake between three groups of children; children with asthma, those with significant tooth erosion but with no history of asthma, and children with no history of asthma or other medical problems. secondly, to discover whether there was a relationship between medical history and dietary practises of these children and the levels of dental erosion. thirdly, to measure and compare their salivary flow rates, ph and buffering capacity.\\n\\n\\nmethods\\nthe study consisted of 3 groups of children aged 11-18 years attending birmingham dental hospital: 20 children with asthma requiring long-term medication, 20 children referred with dental erosion, and 20 children in the age and sex matched control group. tooth wear was recorded using a modification of the tooth wear index (twi) of smith and knight. data on the medical and dietary history were obtained from a self-reported questionnaire supplemented by a structured interview. the salivary samples were collected under standard methods for measurements.\\n\\n\\nresults\\nfifty percent of the children in the control group had low erosion and 50% moderate erosion. however, high levels were recorded in 35% of children in the asthma group and 65% in the erosion group. there appeared to be no overall differences in diet between the groups. there was an association between dental erosion and the consumption of soft drinks, carbonated beverages and fresh fruits in all the three groups. more variables related to erosion were found in the erosion and asthma groups. a comparison between the three groups showed no significant differences in unstimulated and stimulated salivary flow rates, or ph and buffering capacity.\\n\\n\\nconclusion\\nthere were significant differences in the prevalence of erosion between the three groups, children with asthma having a higher prevalence than the control group. although there was a relationship between the levels of erosion and some medical history and acidic dietary components, these did not explain the higher levels in asthmatic children. further investigation is required into the factors affecting the increased prevalence of erosion in children with asthma.",
            "contribution_ids": [
                "R30685"
            ]
        },
        {
            "instance_id": "R30698xR30693",
            "comparison_id": "R30698",
            "paper_id": "R30693",
            "text": "The oral health of children with clefts of the lip, palate, or both \" objective: the purpose of this study was to assess the prevalence of dental caries, developmental defects of enamel, and related factors in children with clefts. design: this cross-sectional prevalence study used standard dental indices for assessment. setting: children underwent a dental examination under standard conditions of seating and lighting in the outpatient department of a dental hospital as part of an ongoing audit to monitor clinical outcomes. participants: ninety-one children aged 4, 8, and 12 years were included in the study. outcome measurements dental caries were assessed by use of the decayed, missing, and filled index for primary teeth (dmft); decayed, missing, and filled index for permanent teeth (dmft) according to the criteria as used in the national survey of children's dental health in the united kingdom (o'brien, 1994). developmental defects were assessed using the modified developmental defects of enamel index (clarkson and o'mullane, 1989). dental erosion was assessed using the criteria derived for the national survey of children's dental health (o'brien, 1994). results: caries prevalence increased with age; 63% of patients at 4 years and 34% at 12 years were caries free. the mean dmft for the 4-year-olds was 1.3 with a mean dmft for the 12-year-olds of 1.8. all the 4-year-olds had evidence of erosion of enamel in the primary teeth (incisors and first molars) and 56% of the 12-year-olds had erosion of permanent teeth (incisors and first permanent molars). developmental defects of enamel became more prevalent with age, with at least one opacity in 56% of 4-year-olds and 100% of 12-year-olds. hypoplasia was not found in the primary dentition but affected permanent teeth in 38% of 8-year-olds and 23% of the 12-year-olds. conclusion: this study has shown that dental disease is prevalent in these patients. these assessments not only provide a baseline on oral health parameters in young people with clefts but underline the need for a more aggressive approach to prevention of oral disease to optimize clinical outcome. \"",
            "contribution_ids": [
                "R30694"
            ]
        },
        {
            "instance_id": "R30739xR30700",
            "comparison_id": "R30739",
            "paper_id": "R30700",
            "text": "Tooth surface loss in adult subjects attending a university dental clinic in Trinidad objectives\\nto determine the prevalence of tooth surface loss (tsl) in a sample of subjects attending a university dental clinic in trinidad and to investigate the relationship to tooth brushing, medical history, parafunction and dietary habits.\\n\\n\\ndesign\\ntooth surface loss was measured clinically by the index used in the 1998 uk, adult dental health survey.\\n\\n\\nsetting\\ntrinidad, west indies.\\n\\n\\nparticipants\\nconvenience sample of adult subjects attending the university of the west indies dental school polyclinic, mount hope.\\n\\n\\nmethods\\na questionnaire was administered and tooth surface loss measured clinically.\\n\\n\\nmain outcome measures\\nmild, moderate and severe tooth surface loss.\\n\\n\\nresults\\n155 subjects were examined (mean age 40.6 years) of whom 72% had some degree of tsl with the majority (52%), exhibiting mild, 16% with moderate and 4% with severe tsl. there were associations found between tsl and age (or=3.14), reflux (or=1.37), parafunction (or=1.06), weekly consumption of citrus fruits (or=1.31) and soft drinks (or=1.78), daily consumption of alcohol (or=1.40) and a vegetarian diet (or=2.79).\\n\\n\\nconclusions\\ntooth surface loss in this trinidadian population group appears to be common. data supports an association between tsl and age, reflux parafunction and certain dietary patterns.",
            "contribution_ids": [
                "R30701"
            ]
        },
        {
            "instance_id": "R30739xR30723",
            "comparison_id": "R30739",
            "paper_id": "R30723",
            "text": "Associated factors of tooth wear in southern Thailand the purpose of this study was to evaluate the possible risk factors connected with tooth wear. using the tooth wear index (twi) and the charting of pre-disposing factors tooth surface loss was recorded in 506 patients, of the dental hospital, prince of songkla university. we found that age, sex, number of tooth loss, frequency of alcohol, sour fruit and carbonate intake were significant risk factors. regarding the tooth position, the first molar showed the greatest degree of wear, while the canine and premolar showed the least, respectively. the occlusal surface showed the greatest wear and the cervical, lingual and buccal surfaces showed the least, respectively.",
            "contribution_ids": [
                "R30724"
            ]
        },
        {
            "instance_id": "R31214xR31182",
            "comparison_id": "R31214",
            "paper_id": "R31182",
            "text": "Advanced models of cellular genetic algorithms evaluated on SAT cellular genetic algorithms (cgas) are mainly characterized by their spatially decentralized population, in which individuals can only interact with their neighbors. in this work, we study the behavior of a large number of different cgas when solving the well-known 3-sat problem. these cellular algorithms differ in the policy of individuals update and the population shape, since these two features affect the balance between exploration and exploitation of the algorithm. we study in this work both synchronous and asynchronous cgas, having static and dynamically adaptive shapes for the population. our main conclusion is that the proposed adaptive cgas outperform other more traditional genetic algorithms for a well known benchmark of 3-sat.",
            "contribution_ids": [
                "R31183"
            ]
        },
        {
            "instance_id": "R31214xR31191",
            "comparison_id": "R31214",
            "paper_id": "R31191",
            "text": "Multinational evolutionary algorithms since practical problems often are very complex with a large number of objectives, it can be difficult or impossible to create an objective function expressing all the criteria of good solutions. sometimes a simpler function can be used where local optimas could be both valid and interesting. because evolutionary algorithms are population based, they have the best potential for finding more of the best solutions among the possible solutions. however, standard eas often converge to one solution and leave therefore only this single option for a final human selection. so far, at least two methods, sharing and tagging, have been proposed to solve the problem. the paper presents a new method for finding more quality solutions, not only global optimas but local as well. the method tries to adapt its search strategy to the problem by taking the topology of the fitness landscape into account. the idea is to use the topology to group the individuals into sub-populations, each covering a part of the fitness landscape.",
            "contribution_ids": [
                "R31192"
            ]
        },
        {
            "instance_id": "R31281xR31228",
            "comparison_id": "R31281",
            "paper_id": "R31228",
            "text": "Middle-Income Transitions: Trap or Myth? during the last few years, the newly coined term middle-income trap has been widely used by policymakers to refer to the middle-income economies that seem to be stuck in the middle-income range. however, there is no accepted definition of the term in the literature. in this paper, we study historical transitions across income groups to see whether there is any evidence that supports the claim that economies do not advance. overall, the data rejects this proposition. instead, we argue that what distinguishes economies in their transition from middle to high income is fast versus slow transitions. we find that, historically, it has taken a \u201ctypical\u201d economy 55 years to graduate from lower-middle income ($2,000 in 1990 purchasing power parity [ppp] $) to upper-middle income ($7,250 in 1990 ppp $). likewise, we find that, historically, it has taken 15 years for an economy to graduate from upper-middle income to high income (above $11,750 in 1990 ppp $). our analysis implies that as of 2013, there were 10 (out of 39) lower-middle-income economies and that 4 (out of 15) upper-middle-income economies that were experiencing slow transitions (i.e., above 55 and 15 years, respectively). the historical evidence presented in this paper indicates that economies move up across income groups. analyzing a large sample of economies over many decades, indicates that experiences are wide, including many economies that today are high income that spent many decades traversing the middle-income segment.",
            "contribution_ids": [
                "R31229",
                "R31268"
            ]
        },
        {
            "instance_id": "R31281xR31247",
            "comparison_id": "R31281",
            "paper_id": "R31247",
            "text": "On the Existence of a Middle-Income Trap. University of Western Australia Working the term \"middle income trap\" has been widely used in the literature, without having been clearly de ned or formally tested. we propose a statistical de nition of a middle income trap and derive a simple time-series test. we nd that the concept survives a rigorous scrutiny of the data, with the growth patterns of 19 countries being consistent with our de nition of a middle income trap..",
            "contribution_ids": [
                "R31248",
                "R31270"
            ]
        },
        {
            "instance_id": "R31669xR31336",
            "comparison_id": "R31669",
            "paper_id": "R31336",
            "text": "Composition estimations in a middle-vessel batch distillation column using artificial neural networks a virtual sensor that estimates product compositions in a middle-vessel batch distillation column has been developed. the sensor is based on a recurrent artificial neural network, and uses information available from secondary measurements (such as temperatures and flow rates). the criteria adopted for selecting the most suitable training data set and the benefits deriving from pre-processing these data by means of principal component analysis are demonstrated by simulation. the effects of sensor location, model initialization, and noisy temperature measurements on the performance of the soft sensor are also investigated. it is shown that the estimated compositions are in good agreement with the actual values.",
            "contribution_ids": [
                "R31337"
            ]
        },
        {
            "instance_id": "R31669xR31413",
            "comparison_id": "R31669",
            "paper_id": "R31413",
            "text": "Online prediction of polymer product quality in an industrial reactor using recurrent neural networks in this paper, internally recurrent neural networks (irnn) are used to predict a key polymer product quality variable from an industrial polymerization reactor. irnn are selected as the modeling tools for two reasons: 1) over the wide range of operating regions required to make multiple polymer grades, the process is highly nonlinear; and 2) the finishing of the polymer product after it leaves the reactor imparts significant dynamics to the process by \"mixing\" effects. irnn are shown to be very effective tools for predicting key polymer quality variables from secondary measurements taken around the reactor.",
            "contribution_ids": [
                "R31414"
            ]
        },
        {
            "instance_id": "R31669xR31456",
            "comparison_id": "R31669",
            "paper_id": "R31456",
            "text": "Applications of Artificial Neural Network for the Prediction of Flow Boiling Curves \"an artificial neural network (ann) was applied successfully to predict flow boiling curves. the databases used in the analysis are from the 1960's, including 1,305 data points which cover these parameter ranges: pressure p=100\u20131,000 kpa, mass flow rate g=40\u2013500 kg/m2-s, inlet subcooling \u03b4tsub =0\u201335\u00b0c, wall superheat \u03b4tw = 10\u2013300\u00b0c and heat flux q=20\u20138,000kw/m2. the proposed methodology allows us to achieve accurate results, thus it is suitable for the processing of the boiling curve data. the effects of the main parameters on flow boiling curves were analyzed using the ann. the heat flux increases with increasing inlet subcooling for all heat transfer modes. mass flow rate has no significant effects on nucleate boiling curves. the transition boiling and film boiling heat fluxes will increase with an increase in the mass flow rate. pressure plays a predominant role and improves heat transfer in all boiling regions except the film boiling region. there are slight differences between the steady and the transient boiling curves in all boiling regions except the nucleate region. the transient boiling curve lies below the corresponding steady boiling curve.\"",
            "contribution_ids": [
                "R31457"
            ]
        },
        {
            "instance_id": "R31669xR31638",
            "comparison_id": "R31669",
            "paper_id": "R31638",
            "text": "Dynamic modeling and optimal control of batch reactors, based on structure approaching hybrid neural networks a novel structure approaching hybrid neural network (sahnn) approach to model batch reactors is presented. the virtual supervisor\u2212artificial immune algorithm method is utilized for the training of sahnn, especially for the batch processes with partial unmeasurable state variables. sahnn involves the use of approximate mechanistic equations to characterize unmeasured state variables. since the main interest in batch process operation is on the end-of-batch product quality, an extended integral square error control index based on the sahnn model is applied to track the desired temperature profile of a batch process. this approach introduces model mismatches and unmeasured disturbances into the optimal control strategy and provides a feedback channel for control. the performance of robustness and antidisturbances of the control system are then enhanced. the simulation result indicates that the sahnn model and model-based optimal control strategy of the batch process are effective.",
            "contribution_ids": [
                "R31639"
            ]
        },
        {
            "instance_id": "R31669xR31460",
            "comparison_id": "R31669",
            "paper_id": "R31460",
            "text": "Using artificial neural network to predict the pressure drop in a rotating packed bed although rotating beds are good equipments for intensified separations and multiphase reactions, but the fundamentals of its hydrodynamics are still unknown. in the wide range of operating conditions, the pressure drop across an irrigated bed is significantly lower than dry bed. in this regard, an approach based on artificial intelligence, that is, artificial neural network (ann) has been proposed for prediction of the pressure drop across the rotating packed beds (rpb). the experimental data sets used as input data (280 data points) were divided into training and testing subsets. the training data set has been used to develop the ann model while the testing data set was used to validate the performance of the trained ann model. the results of the predicted pressure drop values with the experimental values show a good agreement between the prediction and experimental results regarding to some statistical parameters, for example (aard% = 4.70, mse = 2.0 \u00d7 10\u22125 and r2 = 0.9994). the designed ann model can estimate the pressure drop in the countercurrent flow rotating packed bed with unexpected phenomena for higher pressure drop in dry bed than in wet bed. also, the designed ann model has been able to predict the pressure drop in a wet bed with the good accuracy with experimental.",
            "contribution_ids": [
                "R31461"
            ]
        },
        {
            "instance_id": "R31689xR31683",
            "comparison_id": "R31689",
            "paper_id": "R31683",
            "text": "A probabilistic active support vector learning algorithm the paper describes a probabilistic active learning strategy for support vector machine (svm) design in large data applications. the learning strategy is motivated by the statistical query model. while most existing methods of active svm learning query for points based on their proximity to the current separating hyperplane, the proposed method queries for a set of points according to a distribution as determined by the current separating hyperplane and a newly defined concept of an adaptive confidence factor. this enables the algorithm to have more robust and efficient learning capabilities. the confidence factor is estimated from local information using the k nearest neighbor principle. the effectiveness of the method is demonstrated on real-life data sets both in terms of generalization performance, query complexity, and training time.",
            "contribution_ids": [
                "R31684"
            ]
        },
        {
            "instance_id": "R31689xR31687",
            "comparison_id": "R31689",
            "paper_id": "R31687",
            "text": "Balancing Exploration and Exploitation: A New Algorithm for Active Machine Learning active machine learning algorithms are used when large numbers of unlabeled examples are available and getting labels for them is costly (e.g. requiring consulting a human expert). many conventional active learning algorithms focus on refining the decision boundary, at the expense of exploring new regions that the current hypothesis misclassifies. we propose a new active learning algorithm that balances such exploration with refining of the decision boundary by dynamically adjusting the probability to explore at each step. our experimental results demonstrate improved performance on data sets that require extensive exploration while remaining competitive on data sets that do not. our algorithm also shows significant tolerance of noise.",
            "contribution_ids": [
                "R31688"
            ]
        },
        {
            "instance_id": "R31689xR31674",
            "comparison_id": "R31689",
            "paper_id": "R31674",
            "text": "Query learning with large margin classifiers the active selection of instances can significantly improve the generalisation performance of a learning machine. large margin classifiers such as support vector machines classify data using the most informative instances (the support vectors). this makes them natural candidates for instance selection strategies. in this paper we propose an algorithm for the training of support vector machines using instance selection. we give a theoretical justification for the strategy and experimental results on real and artificial data demonstrating its effectiveness. the technique is most efficient when the data set can be learnt using few support vectors.",
            "contribution_ids": [
                "R31675"
            ]
        },
        {
            "instance_id": "R31725xR31695",
            "comparison_id": "R31725",
            "paper_id": "R31695",
            "text": "Design Patterns in Software Maintenance: An Experiment Replication at Freie Universit\u00e4t Berlin \"an article published in 2001 reported a controlled experiment that compared maintenance of small programs using design patterns with maintenance of equivalent programs using simplified design solutions. a replication of that experiment was published in 2004. in 2010, a group of researchers from multiple countries picked this experiment as the subject of an attempt to perform a joint replication: many groups performing an experiment using the same setup, each contributing a few data points to a larger overall data set. this article reports on one of those sub-replications. only one of the results is statistically significant; it confirms the result of the original experiment stating that the simplified version of the gr program could be extended more quickly than the pattern version which used the abstract factory and composite patterns. the article's main contributions, however, are (a) its description of the peculiarities of this particular subdataset and (b) its (implicit) suggestions for possible evaluation methods.\"",
            "contribution_ids": [
                "R31696"
            ]
        },
        {
            "instance_id": "R31725xR31701",
            "comparison_id": "R31725",
            "paper_id": "R31701",
            "text": "Design Patterns in Software Maintenance: An Experiment Replication at Brigham Young University \"in 2001 prechelt et al. published the results of a controlled experiment in software maintenance comparing design patterns to simpler solutions. since that time, only one replication of the experiment has been performed (published in 2004). the replication found remarkably (though not surprisingly) different results. in this paper we present the results of another replication of prechelt's experiment, conducted at brigham young university (byu) in 2010. this replication was performed as part of a joint replication project hosted by the 2011 workshop on replication in empirical software engineering research (reser). the data and results from this experiment are meant to be considered in connection with the results of other contributions to the joint replication project.\"",
            "contribution_ids": [
                "R31702"
            ]
        },
        {
            "instance_id": "R31725xR31715",
            "comparison_id": "R31725",
            "paper_id": "R31715",
            "text": "State Design Pattern Implementation of a DSP processor: A case study of TMS5416C \"this paper presents an empirical study of the impact of state design pattern implementation on the memory and execution time of popular fixed-point dsp processor from texas instruments; tms320vc5416. actually, the object-oriented approach is known to introduce a significant performance penalty compared to classical procedural programming [1]. one can find the studies of the object-oriented penalty on the system performance, in terms of execution time and memory overheads in the literature. since, to the author's best knowledge the study of the overheads of design patterns (dp) in the embedded system programming is not widely published in the literature. the main contribution of the paper is to bring further evidence that embedded system software developers have to consider the memory and the execution time overheads of dps in their implementations. the results of the experiment show that implementation in c++ with dp increases the memory usage and the execution time but meanwhile these overheads would not prevent embedded system software developers to use dps.\"",
            "contribution_ids": [
                "R31716"
            ]
        },
        {
            "instance_id": "R31725xR31721",
            "comparison_id": "R31725",
            "paper_id": "R31721",
            "text": "Defect frequency and design patterns: an empirical study of industrial code software \"design patterns\" seek to package proven solutions to design problems in a form that makes it possible to find, adapt, and reuse them. a common claim is that a design based on properly applied patterns will have fewer defects than more ad hoc solutions. this case study analyzes the weekly evolution and maintenance of a large commercial product (c++, 500,000 loc) over three years, comparing defect rates for classes that participated in selected design patterns to the code at large. we found that there are significant differences in defect rates among the patterns, ranging from 63 percent to 154 percent of the average rate. we developed a new set of tools able to extract design pattern information at a rate of 3/spl times/10/sup 6/ lines of code per hour, with relatively high precision. based on a qualitative analysis of the code and the nature of the patterns, we conclude that the observer and singleton patterns are correlated with larger code structures and, so, can serve as indicators of code that requires special attention. conversely, code designed with the factory pattern is more compact and possibly less closely coupled and, consequently, has lower defect numbers. the template method pattern was used in both simple and complex situations, leading to no clear tendency.",
            "contribution_ids": [
                "R31722"
            ]
        },
        {
            "instance_id": "R31768xR31731",
            "comparison_id": "R31768",
            "paper_id": "R31731",
            "text": "Comparison of the Loop-Mediated Isothermal Amplification (LAMP) Method and Conventional Culture Method for the Detection of Campylobacter Species from Retail Chickens \u65b0\u305f\u306bc.jejuni\u304a\u3088\u3073c.coli\u306elamp\u30d7\u30e9\u30a4\u30de\u30fc\u304c\u8a2d\u8a08\u3055\u308c\u305f\u3053\u3068\u3092\u6a5f\u306b, lamp\u6cd5\u3092\u7528\u3044\u3066\u5e02\u8ca9\u9d8f\u8089134\u691c\u4f53\u304b\u3089\u30ab\u30f3\u30d4\u30ed\u30d0\u30af\u30bf\u30fc\u306e\u691c\u51fa\u3092\u8a66\u307f, \u57f9\u990a\u6cd5\u3068\u306e\u6bd4\u8f03\u3092\u884c\u3044, lamp\u6cd5\u306e\u6709\u7528\u6027\u306b\u3064\u3044\u3066\u691c\u8a0e\u3057\u305f.\u4e21\u8a66\u9a13\u65b9\u6cd5\u306b\u304a\u3044\u3066, \u3068\u3082\u306b\u967d\u6027\u306e\u691c\u4f53\u304c24\u691c\u4f53 (17.9%), \u9670\u6027\u306e\u691c\u4f53\u304c99\u691c\u4f53 (73.9%) \u3042\u308a, \u4e21\u6cd5\u306e\u4e00\u81f4\u7387\u306f91.8%\u3068\u9ad8\u304b\u3063\u305f.\u307e\u305f, \u6210\u7e3e\u304c\u7570\u306a\u3063\u305f\u691c\u4f53\u306f, lamp\u6cd5\u967d\u6027, \u57f9\u990a\u6cd5\u9670\u6027\u304c10\u691c\u4f53 (7.5%), \u9006\u306b\u57f9\u990a\u6cd5\u967d\u6027, lamp\u6cd5\u9670\u6027\u304c\u308f\u305a\u304b\u306b1\u691c\u4f53 (0.7%) \u3067\u3042\u3063\u305f.\u3053\u308c\u3089lamp\u6cd5\u3068\u57f9\u990a\u6cd5\u306b\u3088\u308b\u691c\u51fa\u72b6\u6cc1\u306b\u3064\u3044\u3066x2\u691c\u5b9a\u3092\u884c\u3063\u305f\u304c, \u4e21\u8a66\u9a13\u6cd5\u306e\u9593\u306b\u6709\u610f\u5dee\u306f\u8a8d\u3081\u3089\u308c\u306a\u304b\u3063\u305f.\u6750\u6599\u306e\u7a2e\u985e\u5225\u306b\u304a\u3051\u308b\u30ab\u30f3\u30d4\u30ed\u30d0\u30af\u30bf\u30fc\u306e\u691c\u51fa\u72b6\u6cc1\u3067\u306f\u624b\u7fbd23\u691c\u4f53\u306b\u304a\u3044\u3066, lamp\u6cd5\u3067\u306f5\u691c\u4f53 (21.7%) \u304c\u967d\u6027\u3067\u3042\u3063\u305f\u304c, \u57f9\u990a\u6cd5\u3067\u306f1\u691c\u4f53\u3082\u5206\u96e2\u3055\u308c\u306a\u304b\u3063\u305f, \u305d\u306e\u4ed6, \u30e2\u30e2\u8089, \u30ec\u30d0\u30fc, \u633d\u8089, \u30e0\u30cd\u8089, \u30b5\u30b5\u30df\u306a\u3069\u3067\u306f\u4e21\u8a66\u9a13\u6cd5\u306b\u3088\u308b\u691c\u51fa\u7387\u306b\u5dee\u7570\u306f\u8a8d\u3081\u3089\u308c\u306a\u304b\u3063\u305f.\u4eca\u56de\u306elamp\u6cd5\u306e\u6210\u7e3e\u306f, \u57f9\u990a\u6cd5\u3068\u6bd4\u8f03\u3057\u3066\u905c\u8272\u306a\u3044\u826f\u597d\u306a\u3082\u306e\u3067\u3042\u3063\u305f.\u306a\u304a, \u672c\u7a3f\u306e\u8981\u65e8\u306f\u65e5\u672c\u9632\u83cc\u9632\u5fbd\u5b66\u4f1a\u7b2c33\u56de\u5e74\u6b21\u5927\u4f1a (\u6771\u4eac) \u306b\u304a\u3044\u3066\u767a\u8868\u3057\u305f.",
            "contribution_ids": [
                "R31732",
                "R31741"
            ]
        },
        {
            "instance_id": "R31809xR31787",
            "comparison_id": "R31809",
            "paper_id": "R31787",
            "text": "DNA methylation and embryogenic compe- tence in leaves and callus of napiergrass (Pennisetum purpureum Schum quantitative and qualitative levels of dna methylation were evaluated in leaves and callus of pennisetum purpureum schum. the level of methylation did not change during leaf differentiation or aging and similar levels of methylation were found in embryogenic and nonembryogenic callus.",
            "contribution_ids": [
                "R31788"
            ]
        },
        {
            "instance_id": "R31809xR31801",
            "comparison_id": "R31809",
            "paper_id": "R31801",
            "text": "Genetic characterization of late-flowering traits induced by DNA hypomethylation mutation in Arabidopsis thaliana arabidopsis dna hypomethylation mutation, ddm1, results in a variety of developmental abnormalities by slowly inducing heritable lesions at unlinked loci. here, late-flowering traits observed at high frequencies in independently-established ddm1 lines were genetically characterized. in all of the four late-flowering lines examined the traits were dominant and mapped to the same chromosomal region, which is close or possibly identical to the fwa locus. the ddm1-induced phenotypic onsets are apparently not random mutation events, but specific to a group of genes, suggesting the underlying epigenetic mechanism. the dna methylation mutant provide useful system for identifying epigenetically-regulated genes important for plant development.",
            "contribution_ids": [
                "R31802"
            ]
        },
        {
            "instance_id": "R31928xR31908",
            "comparison_id": "R31928",
            "paper_id": "R31908",
            "text": "Cost estimate for biosynfuel production via biosyncrude gasification production of synthetic fuels from lignocellulose like wood or straw involves complex technology. there\u2010fore, a large btl (biomass to liquid) plant for biosynfuel production is more economic than many small facilities. a reasonable btl\u2010plant capacity is \u22651 mt/a biosynfuel similar to the already existing commercial ctl and gtl (coal to liquid, gas to liquid) plants of sasol and shell, corresponding to at least 10% of the capacity of a modern oil refinery. btl\u2010plant cost estimates are therefore based on reported experience with ctl and gtl plants. direct supply of large btl plants with low bulk density biomass by trucks is limited by high transport costs and intolerable local traffic density. biomass densification by liquefaction in a fast pyrolysis process generates a compact bioslurry or biopaste, also denoted as biosyncrude as produced by the bioliq\u00ae process. the densified biosyncrude intermediate can now be cheaply transported from many local facilities in silo wagons by electric rail over long distances to a large and more economic central biosynfuel plant. in addition to the capital expenditure (capex) for the large and complex central biosynfuel plant, a comparable investment effort is required for the construction of several dozen regional pyrolysis plants with simpler technology. investment costs estimated for fast pyrolysis plants reported in the literature have been complemented by own studies for plants with ca. 100 mwth biomass input. the breakdown of btl synfuel manufacturing costs of ca. 1 \u20ac /kg in central eu shows that about half of the costs are caused by the biofeedstock, including transport. this helps to generate new income for farmers. the other half is caused by technical costs, which are about proportional to the total capital investment (tci) for the pyrolysis and biosynfuel production plants. labor is a minor contribution in the relatively large facilities. \u00a9 2009 society of chemical industry and john wiley & sons, ltd",
            "contribution_ids": [
                "R31909"
            ]
        },
        {
            "instance_id": "R32061xR32040",
            "comparison_id": "R32061",
            "paper_id": "R32040",
            "text": "A two-stage approach to domain adaptation for statistical classifiers in this paper, we consider the problem of adapting statistical classifiers trained from some source domains where labeled examples are available to a target domain where no labeled example is available. one characteristic of such a domain adaptation problem is that the examples in the source domains and the target domain are known to follow different distributions. thus a regular classification method would tend to overfit the source domains. we present a two-stage approach to domain adaptation, where at the first <generalization stage, we look for a set of features generalizable across domains, and at the second adaptation stage, we pick up useful features specific to the target domain. observing that the exact objective function is hard to optimize, we then propose a number of heuristics to approximately achieve the goal of generalization and adaptation. our experiments on gene name recognition using a real data set show the effectiveness of our general framework and the heuristics.",
            "contribution_ids": [
                "R32041"
            ]
        },
        {
            "instance_id": "R32061xR32050",
            "comparison_id": "R32061",
            "paper_id": "R32050",
            "text": "Hierarchical Bayesian domain adaptation multi-task learning is the problem of maximizing the performance of a system across a number of related tasks. when applied to multiple domains for the same task, it is similar to domain adaptation, but symmetric, rather than limited to improving performance on a target domain. we present a more principled, better performing model for this problem, based on the use of a hierarchical bayesian prior. each domain has its own domain-specific parameter for each feature but, rather than a constant prior over these parameters, the model instead links them via a hierarchical bayesian global prior. this prior encourages the features to have similar weights across domains, unless there is good evidence to the contrary. we show that the method of (daume iii, 2007), which was presented as a simple \"preprocessing step,\" is actually equivalent, except our representation explicitly separates hyperparameters which were tied in his work. we demonstrate that allowing different values for these hyperparameters significantly improves performance over both a strong baseline and (daume iii, 2007) within both a conditional random field sequence model for named entity recognition and a discriminatively trained dependency parser.",
            "contribution_ids": [
                "R32051"
            ]
        },
        {
            "instance_id": "R32061xR32059",
            "comparison_id": "R32061",
            "paper_id": "R32059",
            "text": "Instance weighting for domain adaptation in nlp domain adaptation is an important problem in natural language processing (nlp) due to the lack of labeled data in novel domains. in this paper, we study the domain adaptation problem from the instance weighting perspective. we formally analyze and characterize the domain adaptation problem from a distributional view, and show that there are two distinct needs for adaptation, corresponding to the different distributions of instances and classification functions in the source and the target domains. we then propose a general instance weighting framework for domain adaptation. our empirical results on three nlp tasks show that incorporating and exploiting more information from the target domain through instance weighting is effective.",
            "contribution_ids": [
                "R32060"
            ]
        },
        {
            "instance_id": "R32189xR32077",
            "comparison_id": "R32189",
            "paper_id": "R32077",
            "text": "Development of a real-time learning scheduler using reinforcement learning concepts a scheme for the scheduling of flexible manufacturing systems (fms) has been developed which divides the scheduling function (built upon a generic controller architecture) into four different steps: candidate rule selection, transient phenomena analysis, multicriteria compromise analysis, and learning. this scheme is based on a hybrid architecture which utilizes neural networks, simulation, genetic algorithms, and induction mechanism. this paper investigates the candidate rule selection process, which selects a small list of scheduling rules from a larger list of such rules. this candidate rule selector is developed by using the integration of dynamic programming and neural networks. the system achieves real-time learning using this approach. in addition, since an expert scheduler is not available, it utilizes reinforcement signals from the environment (a measure of how desirable the achieved state is as measured by the resulting performance criteria). the approach is discussed and further research issues are presented. >",
            "contribution_ids": [
                "R32078"
            ]
        },
        {
            "instance_id": "R32189xR32081",
            "comparison_id": "R32189",
            "paper_id": "R32081",
            "text": "Applications of genetic algorithm and simulation to dispatching rule-based FMS scheduling this paper presents a hybrid intelligent approach to a production scheduling problem in fms. an fms scheduling system is modelled as a four-level simultaneous decision-making problem. the genetic algorithm and simulation approaches are integrated to seek efficiently the best combination of dispatching rules in order to obtain an appropriate production schedule under specific performance measures.",
            "contribution_ids": [
                "R32082"
            ]
        },
        {
            "instance_id": "R32189xR32085",
            "comparison_id": "R32189",
            "paper_id": "R32085",
            "text": "A GA embedded dynamic search algorithm over a Petri Net model an FMS scheduling in this paper, a genetic algorithm (ga) embedded dynamic search strategy over a petri net model provides a new scheduling method for a flexible manufacturing system (fms). the chromosome representation of the search nodes is constructed directly from the petri net model of an fms, recording the information about all conflict resolutions, such as resource assignments and orders for resource allocation. the ga operators may enforce some change to the chromosome information in the next generation. a petri net based schedule builder receives a chromosome and an initial marking as input, and then produces a near-optimal schedule. due to the np-complete nature of the scheduling problem of an fms, we also propose a dynamic fms scheduler incorporating the proposed ga embedded search scheme, which generates successive partial schedules, instead of generating a full schedule for all raw parts, as the production evolves.",
            "contribution_ids": [
                "R32086"
            ]
        },
        {
            "instance_id": "R32189xR32091",
            "comparison_id": "R32189",
            "paper_id": "R32091",
            "text": "Genetically tuned fuzzy scheduling for flexible manufacturing systems this paper focuses on the development and implementation of a genetically tuned fuzzy scheduler (gtfs) for heterogeneous fms under uncertainty. the scheduling system takes input from a table and creates an optimum master schedule. the gtfs uses fuzzy rulebase and inferencing where fuzzy sets are generated by a genetic algorithm to tune the optimization. the fuzzy optimization is based on time criticality in deadline and machine need, taking into account machine availability, uniformity, process time and selectability.",
            "contribution_ids": [
                "R32092"
            ]
        },
        {
            "instance_id": "R32189xR32142",
            "comparison_id": "R32189",
            "paper_id": "R32142",
            "text": "A pareto based multi-objective genetic algorithm for scheduling of FMS many real-world engineering and scientific problems involve simultaneous optimization of multiple objectives that often are competing. in this work, we have addressed issues relating to scheduling with multiple (and competing) objectives of flexible manufacturing system (fms) and have developed a mechanism by employing a pareto based ga to generate nearer optimal schedules. in the proposed method we have applied pareto ranking to identify the elite solutions and their fitness values are derated using fitness sharing method. the procedure is evaluated with sample problem environment found in literature and results are compared with other available heuristics found in literature. the proposed niched pareto genetic algorithm (npga) exhibits a superiority over the other heuristics and scheduling rules",
            "contribution_ids": [
                "R32143"
            ]
        },
        {
            "instance_id": "R32189xR32165",
            "comparison_id": "R32189",
            "paper_id": "R32165",
            "text": "A hybrid multi-objective GA for simultaneous scheduling of machines and AGVs in FMS a carefully designed and efficiently managed material handling system plays an important role in planning and operation of a flexiblemanufacturing system.most of the researchers have addressed machine and vehicle scheduling as two independent problems and most of the research has been emphasized only on single objective optimization. multiobjective problems in scheduling with conflicting objectives are more complex and combinatorial in nature and hardly have a unique solution. this paper addresses multiobjective scheduling problems in a flexiblemanufacturing environment using evolutionary algorithms. in this paper the authors made an attempt to consider simultaneously the machine and vehicle scheduling aspects in an fms and addressed the combined problem for the minimization of makespan, mean flow time and mean tardiness objectives.",
            "contribution_ids": [
                "R32166"
            ]
        },
        {
            "instance_id": "R32189xR32168",
            "comparison_id": "R32189",
            "paper_id": "R32168",
            "text": "Multi-objective Genetic Algorithm for Multistage-based Job Processing Schedules in FMS Environment in this paper, we propose a multi-objective genetic algorithm for effectively solving multistage-based job processing schedules in fms environment. the proposed method is random-weight approach to obtaining a variable search direction toward pareto solution. the objectives are to minimize the makespan and the total flow time, simultaneously. the feasibility and adaptability of the proposed moga are investigated through experimental results.",
            "contribution_ids": [
                "R32169"
            ]
        },
        {
            "instance_id": "R32189xR32187",
            "comparison_id": "R32189",
            "paper_id": "R32187",
            "text": "HPA-PN: a new algorithm for scheduling FMS using combinational genetic algorithm and Timed Petri Net in flexible manufacturing systems (fms), each job is formed of a set of operations that should be executed consecutive. determining the sequence of operations and assigning proper machine to each operation are two important problems in scheduling fms\u2019s. this is an np-hard problem. recently using heuristic methods, numerous algorithms are presented for solving this problem. in this paper for scheduling of flexible manufacturing systems, a new algorithm called hybrid genetic algorithm-petri net (hga-pn) is presented using timed petri net and combinational genetic algorithm. in our purposed algorithm, first the flexible manufacturing system is modeled by using timed petri net, and then an appropriate scheduling is manufactured using combinational genetic algorithm. the experimental results illustrates that our proposed algorithm has higher efficiency over other existing algorithms.",
            "contribution_ids": [
                "R32188"
            ]
        },
        {
            "instance_id": "R32424xR32210",
            "comparison_id": "R32424",
            "paper_id": "R32210",
            "text": "Extraction by Steam Distillation ofArtemisia herba-albsEssential Oil from Algeria: Kinetic Study and Optimization of the Operating Conditions abstract in order to study the extraction process of essential oil from artemisia herba-alba, kinetic studies as well as an optimization of the operating conditions were achieved. the optimization was carried out by a parametric study and experiments planning method. three operational parameters were chosen: artemisia mass to be treated, steam flow rate and extraction time. the optimal extraction conditions obtained by the parametric study correspond to: a mass of 30 g, a steam flow rate of 1.65 ml.min\u22121 and the extraction time of 60 min. the results reveal that the combined effects of two parameters, the steam water flow rate and the extraction time, are the most significant. the yield is also affected by the interaction of the three parameters. the essential oil obtained with optimal conditions was analyzed by gc-ms and a kinetic study was realised.",
            "contribution_ids": [
                "R32211"
            ]
        },
        {
            "instance_id": "R32424xR32233",
            "comparison_id": "R32424",
            "paper_id": "R32233",
            "text": "Fungicidal Activity of Artemisia herba alba Asso (Asteraceae) the antifungal activity of artemisia herba alba was found to be associated with two major volatile compounds isolated from the fresh leaves of the plant. carvone and piperitone were isolated and identified by gc/ms, gc/ir, and nmr spectroscopy. antifungal activity was measured against penicillium citrinum (atcc 10499) and mucora rouxii (atcc 24905). the antifungal activity (ic50) of the purified compounds was estimated to be 5 \u03bc g/ml, 2 \u03bc g/ml against penicillium citrinum and 7 \u03bc g/ml, 1.5 \u03bc g/ml against mucora rouxii carvone and piperitone, respectively.",
            "contribution_ids": [
                "R32234"
            ]
        },
        {
            "instance_id": "R32424xR32258",
            "comparison_id": "R32424",
            "paper_id": "R32258",
            "text": "Chemovariation ofArtemisia herba albaAsso. Aromatic Plants of the Holy Land and the Sinai. Part XVI. abstract in continuation of our investigation of aromatic flora of the holy land, the systematic study of artemisia herba alba essential oils has been conducted. the detailed composition of five relatively rare chemotypes of a. herba alba obtained through gc and gc/ms analysis are presented. to ensure the integrity of each chemotype the volatiles were extracted from individual plant specimens and bulked only if the gc profiles were substantially similar. the major constituents were: type 1: 1,8 cineole (10.8%), \u03b1-thujone (40.9%) and \u03b2-thujone (34.9%); type 2: 1,8 cineole (26.0%) and camphor (42.1%); type 3; 1,8 cineole (26.6%) and \u03b2-thujone (44.0%); type 4: cis-chrysanthenyl acetate (8.9%) and cis-chrysanthenol (30.0%); type 5: cis-chysanthenol (6.8%) and cis-chrysanthenyl acetate (69.0%). this study showed that the population of a. herba alba in israel consists of a much greater number of chemovarieties than was previously believed. though chemovarieties are unevenly distributed in different geographic areas, no clear relation between the plant type and environmental conditions could be established.",
            "contribution_ids": [
                "R32259"
            ]
        },
        {
            "instance_id": "R32424xR32286",
            "comparison_id": "R32424",
            "paper_id": "R32286",
            "text": "Chemical variability of Artemisia herba-alba Asso essential oils from East Morocco abstract chemical compositions of 16 artemisia herba-alba oil samples harvested in eight east moroccan locations were investigated by gc and gc/ms. chemical variability of the a. herba-alba oils is also discussed using statistical analysis. detailed analysis of the essential oils led to the identification of 52 components amounting to 80.5\u201398.6 % of the total oil. the investigated chemical compositions showed significant qualitative and quantitative differences. according to their major components (camphor, chrysanthenone, and \u03b1- and \u03b2-thujone), three main groups of essential oils were found. this study also found regional specificity of the major components.",
            "contribution_ids": [
                "R32287"
            ]
        },
        {
            "instance_id": "R32424xR32385",
            "comparison_id": "R32424",
            "paper_id": "R32385",
            "text": "Composition and intraspecific chemical vari- ability of the essential oil from Artemisia herba alba growing wild in a Tunisian arid zone the intraspecific chemical variability of essential oils (50 samples) isolated from the aerial parts of artemisia herba\u2010alba asso growing wild in the arid zone of southeastern tunisia was investigated. analysis by gc (ri) and gc/ms allowed the identification of 54 essential oil components. the main compounds were \u03b2\u2010thujone and \u03b1\u2010thujone, followed by 1,8\u2010cineole, camphor, chrysanthenone, trans\u2010sabinyl acetate, trans\u2010pinocarveol, and borneol. chemometric analysis (k\u2010means clustering and pca) led to the partitioning into three groups. the composition of two thirds of the samples was dominated by \u03b1\u2010thujone or \u03b2\u2010thujone. therefore, it could be expected that wild plants of a. herba\u2010alba randomly harvested in the area of kirchaou and transplanted by local farmers for the cultivation in arid zones of southern tunisia produce an essential oil belonging to the \u03b1\u2010thujone/\u03b2\u2010thujone chemotype and containing also 1,8\u2010cineole, camphor, and trans\u2010sabinyl acetate at appreciable amounts.",
            "contribution_ids": [
                "R32386"
            ]
        },
        {
            "instance_id": "R32424xR32369",
            "comparison_id": "R32424",
            "paper_id": "R32369",
            "text": "The essential oil from Artemisia herba-alba Asso cultivated in Arid Land (South Tunisia) abstract seedlings of artemisia herba-alba asso collected from kirchaou area were transplanted in an experimental garden near the institut des r\u00e9gions arides of m\u00e9denine (tunisia). during three years, the aerials parts were harvested (three levels of cutting, 25%, 50% and 75% of the plant), at full blossom and during the vegetative stage. the essential oil was isolated by hydrodistillation and its chemical composition was determined by gc(ri) and 13c-nmr. with respect to the quantity of vegetable material and the yield of hydrodistillation, it appears that the best results were obtained for plants cut at 50% of their height and during the full blossom. the chemical composition of the essential oil was dominated by \u03b2-thujone, \u03b1-thujone, 1,8-cineole, camphor and trans-sabinyl acetate, irrespective of the level of cutting and the period of harvest. it remains similar to that of plants growing wild in the same area.",
            "contribution_ids": [
                "R32370"
            ]
        },
        {
            "instance_id": "R32541xR32437",
            "comparison_id": "R32541",
            "paper_id": "R32437",
            "text": "\u00c2\u00abOver and Undereducation in the UK Graduate Labour Market\u00c2\u00bb abstract the authors examine the apparent underutilisation of the skills of employed graduates. as in the usa, concern has arisen in britain over the numbers of graduates working in jobs which might be carried out equally well by those with subdegree qualifications. the authors discuss whether or not overeducation represents a serious problem, outlining theoretical explanations of over- and undereducation. two measures of over/undereducation are then used to examine the british graduate jobs market. drawing on labour force survey data, the authors relate over- and undereducation to a range of personal and employment characteristics. they conclude that the significance of the problem of overeducation can be exaggerated, since it may represent a rational response of individuals to labour market conditions. they also point out that undereducation\u2014where people hold graduate-level jobs without possessing degrees\u2014is a form of labour market advantage which accrues disproportionately to white males.",
            "contribution_ids": [
                "R32438"
            ]
        },
        {
            "instance_id": "R32541xR32457",
            "comparison_id": "R32541",
            "paper_id": "R32457",
            "text": "\u00c2\u00abOvereducation and the Skills of UK Graduates\u00c2\u00bb summary.\\u2002 during the early 1990s the proportion of a cohort entering higher education in the uk doubled over a short period of time. the paper investigates the effect of the expansion on graduates\u2019 early labour market attainment, focusing on overeducation. we define overeducation by combining occupation codes and a self\u2010reported measure for the appropriateness of the match between qualification and the job. we therefore define three groups of graduates: matched, apparently overeducated and genuinely overeducated. this measure is well correlated with alternative definitions of overeducation. comparing pre\u2010 and post\u2010expansion cohorts of graduates, we find with this measure that the proportion of overeducated graduates has doubled, even though overeducation wage penalties have remained stable. we do not find that type of institution affects the probability of genuine overeducation. apparently overeducated graduates are mostly indistinguishable from matched graduates, whereas genuinely overeducated graduates principally lack non\u2010academic skills and suffer a large wage penalty. individual unobserved heterogeneity differs between the three groups of graduates but controlling for it does not alter these conclusions.",
            "contribution_ids": [
                "R32458",
                "R32504"
            ]
        },
        {
            "instance_id": "R32541xR32475",
            "comparison_id": "R32541",
            "paper_id": "R32475",
            "text": "\u00c2\u00abRecruitment of Overeducated Personnel: Insider-Outsider Effects on Fair Employee Selection Practice we analyze a standard employee selection model given two institutional constraints: first, professional experience perfectly substitutes insufficient formal education for insiders while this substitution is imperfect for outsiders. second, in the latter case the respective substitution rate increases with the advertised minimum educational requirement. optimal selection implies that the expected level of formal education is higher for outsider than for insider recruits. moreover, this difference in educational attainments increases with lower optimal minimum educational job requirements. investigating data of a large us public employer confirms both of the above theoretical implications. generally, the econometric model exhibits a \ufffdgood fit\ufffd.",
            "contribution_ids": [
                "R32476"
            ]
        },
        {
            "instance_id": "R32541xR32502",
            "comparison_id": "R32541",
            "paper_id": "R32502",
            "text": "OPTIMAL \u00e2\u0080\u0098MISMATCH\u00e2\u0080\u0099 AND PROMOTIONS \"seeming 'mismatches,' in which workers are either under- or overqualified, are shown to be optimal. from the firm's point of view, although turnover will be positively related to overqualification, training costs will be inversely related to overqualification. further, overqualified workers constitute a pool from which promotions are made. workers enter seeming mismatches due to search and mobility costs and because of opportunities for promotion. estimates using a unique data set indicate that workers who are overqualified at hire receive less training and more promotions and that workers overqualified for their current job are more likely to quit. copyright 1995 by oxford university press.\"",
            "contribution_ids": [
                "R32503"
            ]
        },
        {
            "instance_id": "R32541xR32529",
            "comparison_id": "R32541",
            "paper_id": "R32529",
            "text": "Overeducation, Undereducation and the British Labour Market this paper addresses the issue of overeducation and undereducation using for the first time a british dataset which contains explicit information on the level of required education to enter a job across the generality of occupations. three key issues within the overeducation literature are addressed. first, what determines the existence of over and undereducation and to what extent are over and undereducation substitutes for experience, tenure and training? second, to what extent are over and undereducation temporary or permanent phenomena? third, what are the returns to over and undereducation and do certain stylized facts discovered for the us and a number of european countries hold for britain?",
            "contribution_ids": [
                "R32530"
            ]
        },
        {
            "instance_id": "R32541xR32537",
            "comparison_id": "R32541",
            "paper_id": "R32537",
            "text": "The Impact of Schooling Surplus on Earnings: Some Additional Findings\u00c2\u00bb this paper examines the impact of overeducation (or surplus schooling) on earnings. overeducated workers are defined as those with educational attainments substantially above the mean for their specific occupations. two models are estimated using data from the 1980 census. though our models, data, and measure of overeducation are different from those used by rumberger (1987), our results are similar. our results show that overeducated workers often earn less than their adequately educated and undereducated counterparts.",
            "contribution_ids": [
                "R32538"
            ]
        },
        {
            "instance_id": "R32871xR32568",
            "comparison_id": "R32871",
            "paper_id": "R32568",
            "text": "Ship detection and classification from overhead imagery this paper presents a sequence of image-processing algorithms suitable for detecting and classifying ships from nadir panchromatic electro-optical imagery. results are shown of techniques for overcoming the presence of background sea clutter, sea wakes, and non-uniform illumination. techniques are presented to measure vessel length, width, and direction-of-motion. mention is made of the additional value of detecting identifying features such as unique superstructure, weaponry, fuel tanks, helicopter landing pads, cargo containers, etc. various shipping databases are then described as well as a discussion of how measured features can be used as search parameters in these databases to pull out positive ship identification. these are components of a larger effort to develop a low-cost solution for detecting the presence of ships from readily-available overhead commercial imagery and comparing this information against various open-source ship-registry databases to categorize contacts for follow-on analysis.",
            "contribution_ids": [
                "R32569"
            ]
        },
        {
            "instance_id": "R32871xR32571",
            "comparison_id": "R32871",
            "paper_id": "R32571",
            "text": "Measuring Overlap-Rate in Hierarchical Cluster Merging for Image Segmentation and Ship Detection in this paper, we present a definition on the degree of overlap between two clusters and develop an algorithm for calculating the overlap rate. using this theory, we also develop a new hierarchical cluster merging algorithm for image segmentation and apply it to the ship detection in high resolution image. in our experiment, we compare our method with several existing popular methods. experimental results demonstrate the effectiveness of the overlap rate measuring method and the new ship detection method.",
            "contribution_ids": [
                "R32572"
            ]
        },
        {
            "instance_id": "R32871xR32578",
            "comparison_id": "R32871",
            "paper_id": "R32578",
            "text": "Using SPOT-5 HRG Data in Panchromatic Mode for Operational Detection of Small Ships in Tropical Area nowadays, there is a growing interest in applications of space remote sensing systems for maritime surveillance which includes among others traffic surveillance, maritime security, illegal fisheries survey, oil discharge and sea pollution monitoring. within the framework of several french and european projects, an algorithm for automatic ship detection from spot\u20135 hrg data was developed to complement existing fishery control measures, in particular the vessel monitoring system. the algorithm focused on feature\u2013based analysis of satellite imagery. genetic algorithms and neural networks were used to deal with the feature\u2013borne information. based on the described approach, a first prototype was designed to classify small targets such as shrimp boats and tested on panchromatic spot\u20135, 5\u2013m resolution product taking into account the environmental and fishing context. the ability to detect shrimp boats with satisfactory detection rates is an indicator of the robustness of the algorithm. still, the benchmark revealed problems related to increased false alarm rates on particular types of images with a high percentage of cloud cover and a sea cluttered background.",
            "contribution_ids": [
                "R32579"
            ]
        },
        {
            "instance_id": "R32871xR32594",
            "comparison_id": "R32871",
            "paper_id": "R32594",
            "text": "Automatic ship detection in HJ-1A satellite data in this paper, we use hj-1a satellite data to ship detection and a ship target detection algorithm based on optical remote sensing images of moving window and entropy maximum is presented. the method uses a moving window to get ship candidates and the shannon theory to image segmentation. basic principle is that the entropy of the image segmented by the threshold value is max. after completing the image segmentation, an automatic discriminator is used. the identify algorithm is used to get rid of the false alarm caused by spray, cloudy and solar flare. some feature is considered include area, length ratio and extent. the detection results indicate that most ship target can be detected without regard to cloudy.",
            "contribution_ids": [
                "R32595"
            ]
        },
        {
            "instance_id": "R32871xR32610",
            "comparison_id": "R32871",
            "paper_id": "R32610",
            "text": "Ship detection in satellite imagery using rank-order grayscale hit-or-miss transforms \"ship detection from satellite imagery is something that has great utility in various communities. knowing where ships are and their types provides useful intelligence information. however, detecting and recognizing ships is a difficult problem. existing techniques suffer from too many false-alarms. we describe approaches we have taken in trying to build ship detection algorithms that have reduced false alarms. our approach uses a version of the grayscale morphological hit-or-miss transform. while this is well known and used in its standard form, we use a version in which we use a rank-order selection for the dilation and erosion parts of the transform, instead of the standard maximum and minimum operators. this provides some slack in the fitting that the algorithm employs and provides a method for tuning the algorithm's performance for particular detection problems. we describe our algorithms, show the effect of the rank-order parameter on the algorithm's performance and illustrate the use of this approach for real ship detection problems with panchromatic satellite imagery.\"",
            "contribution_ids": [
                "R32611"
            ]
        },
        {
            "instance_id": "R32871xR32612",
            "comparison_id": "R32871",
            "paper_id": "R32612",
            "text": "Ship detection by salient convex boundaries automatic ship detection from remote sensing imagery has many applications, such as maritime security, traffic surveillance, fisheries management. however, it is still a difficult task for noise and distractors. this paper is concerned with perceptual organization, which detect salient convex structures of ships from noisy images. because the line segments of contour of ships compose a convex set, a local gradient analysis is adopted to filter out the edges which are not on the contour as preprocess. for convexity is the significant feature, we apply the salience as the prior probability to detect. feature angle constraint helps us compute probability estimate and choose correct contour in many candidate closed line groups. finally, the experimental results are demonstrated on the satellite imagery from google earth.",
            "contribution_ids": [
                "R32613"
            ]
        },
        {
            "instance_id": "R32871xR32621",
            "comparison_id": "R32871",
            "paper_id": "R32621",
            "text": "Graph-based ship extraction scheme for optical satellite image automatic detection and recognition of ship in satellite images is very important and has a wide array of applications. this paper concentrates on optical satellite sensor, which provides an important approach for ship monitoring. graph-based fore/background segmentation scheme is used to extract ship candidant from optical satellite image chip after the detection step, from course to fine. shadows on the ship are extracted in a cfar scheme. because all the parameters in the graph-based algorithms and cfar are adaptively determined by the algorithms, no parameter tuning problem exists in our method. experiments based on measured optical satellite images shows our method achieved good balance between computation speed and ship extraction accuracy.",
            "contribution_ids": [
                "R32622"
            ]
        },
        {
            "instance_id": "R32871xR32625",
            "comparison_id": "R32871",
            "paper_id": "R32625",
            "text": "Ship detection in MODIS imagery understanding the capabilities of satellite sensors with spatial and spectral characteristics similar to those of modis for maritime domain awareness (mda) is of importance because of the upcoming npoes with 100 minutes revisit time carrying the modis-like viirs multispectral imaging sensor. this paper presents an experimental study of ship detection using modis imagery. we study the use of ship signatures such as contaminant plumes in clouds and the spectral contrast between the ship and the sea background for detection. results show the potential and challenges for such approach in mda.",
            "contribution_ids": [
                "R32626"
            ]
        },
        {
            "instance_id": "R32871xR32628",
            "comparison_id": "R32871",
            "paper_id": "R32628",
            "text": "A novel ship detection method based on sea state analysis from optical imagery this paper proposes a novel ship detection method based on analyzing the sea state in optical images. this method is composed of three phases. first, the image is segmented with the improved region splitting and merging method, which divides the sea into separated regions. then, the sea state of each divided region of sea is analyzed by extracting texture roughness and ripple density of a modified differential box counting (dbc) method. finally, an appropriate algorithm is applied to detect ships for each region of sea. experimental results test on 36 real remote sensing images and 133 images obtained from google earth demonstrate that the method is free of image resolution and has little limitation of sea conditions.",
            "contribution_ids": [
                "R32629"
            ]
        },
        {
            "instance_id": "R32871xR32638",
            "comparison_id": "R32871",
            "paper_id": "R32638",
            "text": "Saliency and gist features for target detection in satellite images reliably detecting objects in broad-area overhead or satellite images has become an increasingly pressing need, as the capabilities for image acquisition are growing rapidly. the problem is particularly difficult in the presence of large intraclass variability, e.g., finding \u201cboats\u201d or \u201cbuildings,\u201d where model-based approaches tend to fail because no good model or template can be defined for the highly variable targets. this paper explores an automatic approach to detect and classify targets in high-resolution broad-area satellite images, which relies on detecting statistical signatures of targets, in terms of a set of biologically-inspired low-level visual features. broad-area images are cut into small image chips, analyzed in two complementary ways: \u201cattention/saliency\u201d analysis exploits local features and their interactions across space, while \u201cgist\u201d analysis focuses on global nonspatial features and their statistics. both feature sets are used to classify each chip as containing target(s) or not, using a support vector machine. four experiments were performed to find \u201cboats\u201d (experiments 1 and 2), \u201cbuildings\u201d (experiment 3) and \u201cairplanes\u201d (experiment 4). in experiment 1, 14 416 image chips were randomly divided into training (300 boat, 300 nonboat) and test sets (13 816), and classification was performed on the test set (roc area: 0.977 \u00b10.003). in experiment 2, classification was performed on another test set of 11 385 chips from another broad-area image, keeping the same training set as in experiment 1 (roc area: 0.952 \u00b10.006). in experiment 3, 600 training chips (300 for each type) were randomly selected from 108 885 chips, and classification was conducted (roc area: 0.922 \u00b10.005). in experiment 4, 20 training chips (10 for each type) were randomly selected to classify the remaining 2581 chips (roc area: 0.976 \u00b10.003). the proposed algorithm outperformed the state-of-the-art sift, hmax, and hidden-scale salient structure methods, and previous gist-only features in all four experiments. this study shows that the proposed target search method can reliably and effectively detect highly variable target objects in large image datasets.",
            "contribution_ids": [
                "R32639"
            ]
        },
        {
            "instance_id": "R32871xR32643",
            "comparison_id": "R32871",
            "paper_id": "R32643",
            "text": "Detection and classification of man-made offshore objects in TerraSAR-X and RapidEye imagery: Selected results of the DeMarine-DEKO project the project deko (detection of artificial objects in sea areas) is integrated in the german demarine-security project and focuses on the detection and classification of ships and offshore artificial objects relying on terrasar-x as well as on rapideye multispectral optical images. the objectives are 1/ the development of reliable detection algorithms and 2/ the definition of effective, customized service concepts. in addition to an earlier publication, we describe in the following paper some selected results of our work. the algorithms for terrasar-x have been extended to a processing chain including all needed steps for ship detection and ship signature analysis, with an emphasis on object segmentation. for rapid eye imagery, a ship detection algorithm has been developed. finally, some applications are described: ship monitoring in the strait of dover based on terrasar-x stripmap using ais information for verification, analyzing terrasar-x highresolution scenes of an industrial harbor and finally an example of surveying a wind farm using change detection.",
            "contribution_ids": [
                "R32644"
            ]
        },
        {
            "instance_id": "R32871xR32651",
            "comparison_id": "R32871",
            "paper_id": "R32651",
            "text": "A Novel Algorithm for Ship Detection Based on Dynamic Fusion Model of Multi-feature and Support Vector Machine ship detection is one of the most important applications of target recognition based on optical remote sensing images. in this paper, we propose an uncertain ship target extraction algorithm based on dynamic fusion model of multi-feature and variance feature of optical remote sensing image. we choose several geometrical features, such as length, wide, rectangular ratio, tightness ratio and so on, using svm to train and predict the uncertain ship targets extracted by our algorithm automatically. experiments show that our algorithm is very robust, and the recognition rate of our algorithm can reach or even better than 95%, with the false alarm rate is kept at 3%.",
            "contribution_ids": [
                "R32652"
            ]
        },
        {
            "instance_id": "R32871xR32656",
            "comparison_id": "R32871",
            "paper_id": "R32656",
            "text": "A sea-land segmentation scheme based on statistical model of sea sea-land segmentation is a key step for target detection. due to the complex texture and uneven gray value of the land in optical remote sensing image, traditional sea-land segmentation algorithms often recognize land as sea incorrectly. a new segmentation scheme is presented in this paper to solve this problem. this scheme determines the threshold according to the adaptively established statistical model of the sea area, and removes the incorrectly classified land according to the difference of the variance in the statistical model between land and sea. experimental results show our segmentation scheme has small computation complexity, and it has better performance and higher robustness compared to the traditional algorithms.",
            "contribution_ids": [
                "R32657"
            ]
        },
        {
            "instance_id": "R32871xR32709",
            "comparison_id": "R32871",
            "paper_id": "R32709",
            "text": "A new method on inshore ship detection in high-resolution satellite images using shape and context information in this letter, we present a new method to detect inshore ships using shape and context information. we first propose a new energy function based on an active contour model to segment water and land and minimize it with an iterative global optimization method. the proposed energy performs well on the different intensity distributions between water and land and produces a result that can be well used in shape and context analyses. in the segmented image, ships are detected with successive shape analysis, including shape analysis in the localization of ship head and region growing in computing the width and length of ship. finally, to locate ships accurately and remove the false alarms, we unify them with a binary linear programming problem by utilizing the context information. experiments on quickbird images show the robustness and precision of our method.",
            "contribution_ids": [
                "R32710"
            ]
        },
        {
            "instance_id": "R32871xR32714",
            "comparison_id": "R32871",
            "paper_id": "R32714",
            "text": "Ship detection in high-resolution optical imagery based on anomaly detector and local shape feature ship detection in high-resolution optical imagery is a challenging task due to the variable appearances of ships and background. this paper aims at further investigating this problem and presents an approach to detect ships in a \u201ccoarse-to-fine\u201d manner. first, to increase the separability between ships and background, we concentrate on the pixels in the vicinities of ships. we rearrange the spatially adjacent pixels into a vector, transforming the panchromatic image into a \u201cfake\u201d hyperspectral form. through this procedure, each produced vector is endowed with some contextual information, which amplifies the separability between ships and background. afterward, for the \u201cfake\u201d hyperspectral image, a hyperspectral algorithm is applied to extract ship candidates preliminarily and quickly by regarding ships as anomalies. finally, to validate real ships out of ship candidates, an extra feature is provided with histograms of oriented gradients (hogs) to generate a hypothesis using adaboost algorithm. this extra feature focuses on the gray values rather than the gradients of an image and includes some information generated by very near but not closely adjacent pixels, which can reinforce hog to some degree. experimental results on real database indicate that the hyperspectral algorithm is robust, even for the ships with low contrast. in addition, in terms of the shape of ships, the extended hog feature turns out to be better than hog itself as well as some other features such as local binary pattern.",
            "contribution_ids": [
                "R32715"
            ]
        },
        {
            "instance_id": "R32871xR32718",
            "comparison_id": "R32871",
            "paper_id": "R32718",
            "text": "A Novel Sea-Land Segmentation Algorithm Based on Local Binary Patterns for Ship Detection ship detection is an important application of optical remote sensing image processing. sea-land segmentation is the key step in ship detection. traditional sea-land segment methods only based on the gray-level information of an image to choose a gray threshold to segment the image; however, it is very difficult to establish a self-adapting mechanism to select a suitable threshold for different images. thus, the segmentation result is greatly influenced by the threshold chosen for sea-land segmentation. in this paper, we are integrating the lbp feature information to propose a novel sea-land segmentation algorithm. moreover, a new ship detection method based on our sea-land segmentation algorithm is proposed for optical remote sensing images. the performance of ship detection is measured in terms of precision and false-alarm-rate. experimental results show that, as compared to minimum error method, the proposed algorithm can decrease the false-alarm-rate from 23.2% to 9.24%. and compared to otsu method, the proposed algorithm improve the precision from 82.9% to 90.2%.",
            "contribution_ids": [
                "R32719"
            ]
        },
        {
            "instance_id": "R32871xR32720",
            "comparison_id": "R32871",
            "paper_id": "R32720",
            "text": "Automatic detection of inshore ships in highresolution remote sensing images using robust invariant generalized Hough transform in this letter, we propose a new detection framework based on robust invariant generalized hough transform (right) to solve the problem of detecting inshore ships in high-resolution remote sensing imagery. the invariant generalized hough transform is an effective shape extraction technique, but it is not adaptive to shape deformation well. in order to improve its adaptability, we use an iterative training method to learn a robust shape model automatically. the model could capture the shape variability of the target contained in the training data set, and every point in the model is equipped with an individual weight according to its importance, which greatly reduces the false-positive rate. through the iteration process, the model performance is gradually improved by extending the shape model with these necessary weighted points. experimental result demonstrates the precision, robustness, and effectiveness of our detection framework based on right.",
            "contribution_ids": [
                "R32721"
            ]
        },
        {
            "instance_id": "R32871xR32731",
            "comparison_id": "R32871",
            "paper_id": "R32731",
            "text": "Rotation Sliding Window of the Hog Feature in Remote Sensing Images for Ship Detection ship detection plays a relatively vital role in the effect of the traditional of military. in remote sensing image, we combined histograms of oriented gradients features and support vector machine for ship detection. however, hog feature does not have a rotation of invariant, ship can be in any direction. consequently, in this paper, we proposes a measure of continuous interval rotating detection sliding window of hog feature. we extract and train hog feature of positive and negative samples. then, continuous interval rotating sliding window of hog feature to improve the accuracy of detecting ship. the experiments reveal that the detection rate can reach high of 72.7% in the vertical direction of test ship. it is of practical significance for civil and military field.",
            "contribution_ids": [
                "R32732"
            ]
        },
        {
            "instance_id": "R32871xR32747",
            "comparison_id": "R32871",
            "paper_id": "R32747",
            "text": "Multi-layer Sparse Coding Based Ship Detection for Remote Sensing Images with the development of remote sensing technology, it becomes possible for the detection and identification of targets from remote sensing images. in this paper, we propose a new method integrating the bottom-up and the top-down mechanisms for the ship detection in high resolution satellite images. we use the multi-layer sparse coding to extract the features of the rs images. then, we get the ship candidate regions by calculating the global saliency map which may have ships in it. deformable part model is used to extract the ship features and latent support vector machine is used for the ship identification. as demonstrated in our experiments, the proposed approach can effectively detect ship in remote sensing images.",
            "contribution_ids": [
                "R32748"
            ]
        },
        {
            "instance_id": "R32871xR32782",
            "comparison_id": "R32871",
            "paper_id": "R32782",
            "text": "Marine vessel detection comparing GPRS and satellite images for security applications unauthorized and unregistered sea going fishing vessels are being used for criminal activities in the coastal areas. the issue of piracy against merchant ships using illegal fishing vessels poses a significant threat to world shipping. unfortunately counter piracy efforts and maritime security of our own and other nation enforcement often affects the innocent fishermen who conduct the trans-border fishing. hence a proper vessel monitoring system is required to protect the maritime security without tampering the routine fishing activity of the sea going fishermen. this paper discusses about the feasibility of a system for the detection of registered marine fishing vessels comparing the satellite images and gprs signal information. a review on various algorithms for identifying marine boats from satellite images is also conducted in this paper.",
            "contribution_ids": [
                "R32783"
            ]
        },
        {
            "instance_id": "R32871xR32794",
            "comparison_id": "R32871",
            "paper_id": "R32794",
            "text": "A Direct and Fast Methodology for Ship Recognition in Sentinel-2 Multispectral Imagery the european space agency satellite sentinel-2 provides multispectral images with pixel sizes down to 10 m. this high resolution allows for ship detection and recognition by determining a number of important ship parameters. we are able to show how a ship position, its heading, length and breadth can be determined down to a subpixel resolution. if the ship is moving, its velocity can also be determined from its kelvin waves. the 13 spectrally different visual and infrared images taken using multispectral imagery (msi) are \u201cfingerprints\u201d that allow for the recognition and identification of ships. furthermore, the multispectral image profiles along the ship allow for discrimination between the ship, its turbulent wakes, and the kelvin waves, such that the ship\u2019s length and breadth can be determined more accurately even when sailing. the ship\u2019s parameters are determined by using satellite imagery taken from several ships, which are then compared to known values from the automatic identification system. the agreement is on the order of the pixel resolution or better.",
            "contribution_ids": [
                "R32795"
            ]
        },
        {
            "instance_id": "R32871xR32804",
            "comparison_id": "R32871",
            "paper_id": "R32804",
            "text": "On-board ship targets detection method based on multi-scale salience enhancement for remote sensing image a on-board ship targets detection method based on multi-scale salience enhancement is proposed. unlike the traditional wavelet filter enhancement methods, the proposed utilizes the wavelet decomposition to obtain the high-low frequency parts, and estimate the salience feature with both parts, which enhance the ship targets efficiently. first, decompose the remote sensing image by 2-d dwt, and obtain the low-frequency part, high-frequency part of horizontal, vertical and diagonal; then, compute the ostu threshold, which is subtracted by the low-frequency coefficients to get the low-frequency salience image; and, the high-frequency parts are used to compose the high-frequency salience image; finally, the high-low parts are fused by addition and normalized to obtain the salience map. the original data of multi sets of remote sensing images are experimented, and the results are compared with the method without the proposed salience enhancement. the proposed shows obvious salience enhancement for the low-resolution, high-noise remote sensing images.",
            "contribution_ids": [
                "R32805"
            ]
        },
        {
            "instance_id": "R32871xR32811",
            "comparison_id": "R32871",
            "paper_id": "R32811",
            "text": "Ship detection in high spatial resolution remote sensing image based on improved sea-land segmentation a new method to detect ship target at sea based on improved segmentation algorithm is proposed in this paper, in which the improved segmentation algorithm is applied to precisely segment land and sea. firstly, mean value is replaced instead of average variance value in otsu method in order to improve the adaptability. secondly, mean shift algorithm is performed to separate the original high spatial resolution remote sensing image into several homogeneous regions. at last, the final sea-land segmentation result can be located combined with the regions in preliminary sea-land segmentation result. the proposed segmentation algorithm performs well on the segment between water and land with affluent texture features and background noise, and produces a result that can be well used in shape and context analyses. ships are detected with settled shape characteristics, including width, length and its compactness. mean shift algorithm can smooth the background noise, utilize the wave\u2019s texture features and helps highlight offshore ships. mean shift algorithm is combined with improved otsu threshold method in order to maximizes their advantages. experimental results show that the improved sea-land segmentation algorithm on high spatial resolution remote sensing image with complex texture and background noise performs well in sea-land segmentation, not only enhances the accuracy of land and sea boarder, but also preserves detail characteristic of ships. compared with traditional methods, this method can achieve accuracy over 90 percent. experiments on worldview images show the superior, robustness and precision of the proposed method.",
            "contribution_ids": [
                "R32812"
            ]
        },
        {
            "instance_id": "R32871xR32813",
            "comparison_id": "R32871",
            "paper_id": "R32813",
            "text": "A Novel Inshore Ship Detection via Ship Head Classification and Body Boundary Determination in this letter, we propose a novel method for inshore ship detection via ship head classification and body boundary determination. compared with some traditional ship head detection methods depending on accurate ship head segmentation, we generate novel ship head features in the transformed domain of polar coordinate, where the ship heads have an approximate trapezoid shape and can be more easily detected. then, these features are used in the classification based on support vector machine to detect the ship head candidates, and give the important information of initial ship head direction. next, the surrounding consistent line segments are utilized to refine the ship direction, and the ship boundary is determined based on the saliency of directional gradient information symmetrical about the ship body. finally, the context information of sea areas is introduced to remove false alarms. experimental results show that the proposed method can accurately and robustly detect the inshore ships in high-resolution optical remote sensing images.",
            "contribution_ids": [
                "R32814"
            ]
        },
        {
            "instance_id": "R32871xR32816",
            "comparison_id": "R32871",
            "paper_id": "R32816",
            "text": "A multi-scale fractal dimension based onboard ship saliency detection algorithm detection of ship targets in the sea area is an important field in remote sensing image target detection. as the ships and the surrounding areas are very different in texture, that makes it a possible solution to detect the ships using the texture feature. aiming at the detection of ship targets, a novel ship target detection algorithm in a large scene of the optical remote sensing image is proposed in this paper. this algorithm is based on the conspicuity of ship targets of multi-scale fractal dimension feature in the sea background, and then the detection of ship targets is realized by the method of visual saliency model. in this paper, the accuracy of fractal dimension feature of small or medium-sized window by using differential box counting algorithm has been improved. the novel algorithm proposed in this paper is based on the significant difference of natural background and man-made objects in multi-scale fractal dimension feature. then, the conspicuous fractal feature is obtained by using center-surround difference arithmetic operator, in order to highlight the target in the saliency map normalization is need in the final step. on the basis of the saliency map the rapid detection of ship targets in the sea background can be realized. experimental results show that ship targets in the sea background can be detected accurately with this algorithm, and also the false alarm rate has been effectively reduced.",
            "contribution_ids": [
                "R32817"
            ]
        },
        {
            "instance_id": "R32871xR32819",
            "comparison_id": "R32871",
            "paper_id": "R32819",
            "text": "Ship detection based on surface fitting modeling for large range background of ocean images \"for the seawater background interference problem in ship detection of high resolution remote sensing images, the characteristics of seawater background are analyzed deeply in this paper. and it's found that there is consistent in local but continuous variation in large range. on the basis of above analysis, a gauss variable surface seawater background model for high resolution remote sensing images is built, and the estimation of mean surface and variance surface are also given. then, a novel ship detection method based on sea background statistical modeling is proposed for large range high resolution remote sensing images. the experimental results show the feasibility of our proposed method in sea background modeling and target detection for different kinds of high resolution remote sensing images. compared with the other relative method, the proposed method has higher recall rate and lower missing rate.\"",
            "contribution_ids": [
                "R32820"
            ]
        },
        {
            "instance_id": "R32871xR32830",
            "comparison_id": "R32871",
            "paper_id": "R32830",
            "text": "Ship Rotated Bounding Box Space for Ship Extraction From High-Resolution Optical Satellite Images With Complex Backgrounds extracting ships from complex backgrounds is the bottleneck of ship detection in high-resolution optical satellite images. in this letter, we propose a nearly closed-form ship rotated bounding box space used for ship detection and design a method to generate a small number of highly potential candidates based on this space. we first analyze the possibility of accurately covering all ships by labeling rotated bounding boxes. moreover, to reduce search space, we construct a nearly closed-form ship rotated bounding box space. then, by scoring for each latent candidate in the space using a two-cascaded linear model followed by binary linear programming, we select a small number of highly potential candidates. moreover, we also propose a fast version of our method. experiments on our data set validate the effectiveness of our method and the efficiency of its fast version, which achieves a close detection rate in near real time.",
            "contribution_ids": [
                "R32831"
            ]
        },
        {
            "instance_id": "R32871xR32833",
            "comparison_id": "R32871",
            "paper_id": "R32833",
            "text": "Attribute learning for ship category recognition in remote sensing imagery object category recognition, in remote sensing imagery, usually relies on exemplar-based training. the latter is achieved by modeling intricate relationships between object categories and visual features. however, for real-world and fine grained object categories - exhibiting complex visual appearance and strong variability - these models may fail especially when training data are scarce. in this paper, we introduce an effective object category recognition approach that alleviates the limitation caused by small training sets. the method learns discriminant mid-level representations (a.k.a. attributes) through nonlinear mappings that make these attributes highly discriminant while being easily trainable and predictable. we demonstrate the effectiveness of our method, through extensive experiments on the challenging task of ship recognition in maritime environments, and we show how our attribute learning model generalizes well in spite of the scarcity of training data.",
            "contribution_ids": [
                "R32834"
            ]
        },
        {
            "instance_id": "R32871xR32858",
            "comparison_id": "R32871",
            "paper_id": "R32858",
            "text": "S-CNN-BASED SHIP DETECTION FROM HIGH-RESOLUTION REMOTE SENSING IMAGES abstract. reliable ship detection plays an important role in both military and civil fields. however, it makes the task difficult with high-resolution remote sensing images with complex background and various types of ships with different poses, shapes and scales. related works mostly used gray and shape features to detect ships, which obtain results with poor robustness and efficiency. to detect ships more automatically and robustly, we propose a novel ship detection method based on the convolutional neural networks (cnns), called scnn, fed with specifically designed proposals extracted from the ship model combined with an improved saliency detection method. firstly we creatively propose two ship models, the \u201cv\u201d ship head model and the \u201c||\u201d ship body one, to localize the ship proposals from the line segments extracted from a test image. next, for offshore ships with relatively small sizes, which cannot be efficiently picked out by the ship models due to the lack of reliable line segments, we propose an improved saliency detection method to find these proposals. therefore, these two kinds of ship proposals are fed to the trained cnn for robust and efficient detection. experimental results on a large amount of representative remote sensing images with different kinds of ships with varied poses, shapes and scales demonstrate the efficiency and robustness of our proposed s-cnn-based ship detector.\\n",
            "contribution_ids": [
                "R32859"
            ]
        },
        {
            "instance_id": "R32871xR32867",
            "comparison_id": "R32871",
            "paper_id": "R32867",
            "text": "A Hierarchical Maritime Target Detection Method for Optical Remote Sensing Imagery maritime target detection from optical remote sensing images plays an important role in related military and civil applications and its weakness lies in its compromised performance under complex uncertain conditions. in this paper, a novel hierarchical ship detection method is proposed to overcome this issue. in the ship detection stage, based on entropy information, we construct a combined saliency model with self-adaptive weights to prescreen ship candidates from across the entire maritime domain. to characterize ship targets and further reduce the false alarms, we introduce a novel and practical descriptor based on gradient features, and this descriptor is robust against clutter introduced by heavy clouds, islands, ship wakes as well as variation in target size. furthermore, the proposed method is effective for not only color images but also gray images. the experimental results obtained using real optical remote sensing images have demonstrated that the locations and the number of ships can be determined accurately and that the false alarm rate is greatly decreased. a comprehensive comparison is performed between the proposed method and the state-of-the-art methods, which shows that the proposed method achieves higher accuracy and outperforms all the competing methods. furthermore, the proposed method is robust under various backgrounds of maritime images and has great potential for providing more accurate target detection in engineering applications.",
            "contribution_ids": [
                "R32868"
            ]
        },
        {
            "instance_id": "R32914xR32881",
            "comparison_id": "R32914",
            "paper_id": "R32881",
            "text": "E-Government and Public Financial Reporting: The Case of Spanish Regional Governments \" technology has changed the way public organizations relate to the public. government's use of the internet and other associated technologies, known as e-government, could become the instrument that makes regular timely information on public finances more forthcoming. new technologies can improve government responsiveness and empower individual citizens. by making government financial information available, the public could continuously assess a government agency through everyday interaction. the financial accountability of government and its response to public demands for information and services are thus a contribution to government openness. it is therefore relevant to determine whether public organizations are also becoming more aware of the importance of placing financial information on their web sites to help in decision-making processes. this article focuses on the e-democracy process, specifically the transparency of government information, by analyzing governmental financial disclosures on the web as a tool for the public to assess its financial accountability. to this end, an empirical study was carried out on regional governments in spain. \"",
            "contribution_ids": [
                "R32882"
            ]
        },
        {
            "instance_id": "R32914xR32895",
            "comparison_id": "R32914",
            "paper_id": "R32895",
            "text": "Accountability Disclosures by Queensland Local Government Councils: 1997\u00e2\u0080\u00931999 the annual report is promoted and regarded as the primary medium of accountability for government agencies. in australia, anecdotal evidence suggests the quality of annual reports is variable. however, there is scant empirical evidence on the quality of reports. the aim of this research is to gauge the quality of annual reporting by local governments in queensland, and to investigate the factors that may contribute to that level of quality. the results of the study indicate that although the quality of reporting by local governments has improved over time, councils generally do not report information on aspects of corporate governance, remuneration of executive staff, personnel, occupational health and safety, equal opportunity policies, and performance information. in addition, the results indicate there is a correlation between the size of the local government and the quality of reporting but the quality of disclosures is not correlated with the timeliness of reports. the study will be of interest to the accounting profession, public sector regulators who are responsible for the integrity of the accountability mechanisms and public sector accounting practitioners. it will form the basis for future longitudinal research, which will map changes in the quality of local government annual reporting.",
            "contribution_ids": [
                "R32896"
            ]
        },
        {
            "instance_id": "R32914xR32911",
            "comparison_id": "R32914",
            "paper_id": "R32911",
            "text": "Economic Incentives and the Choice of State Government Accounting Practices several recent studies have examined possible economic determinants of accounting policy choices of local government entities. for example, zimmerman [1977] and maher and keller [1978] proposed economic reasons for the current (diverse) state of municipal accounting and financial reporting, and evans and patton [1983] identified economic incentives leading to participation in the municipal finance officers association certificate of conformance program. a recent survey by the council on state governments (csg) [1980], in its summary of major accounting and reporting practices for individual state governments, characterizes both the general status of state government accounting and the diversity of accounting practices observed across states. using the data reported by the csg and some of the economic arguments offered in earlier research, this study provides preliminary evidence on the association between economic factors and cross-sectional variations in accounting practices of state governments. the specific evidence presented is characteristic of states that report quantitatively",
            "contribution_ids": [
                "R32912"
            ]
        },
        {
            "instance_id": "R32940xR32928",
            "comparison_id": "R32940",
            "paper_id": "R32928",
            "text": "Risk Factors for Anastomotic Leak and Mortality in Diabetic Patients Undergoing Colectomy objectives\\nto determine the risk factors in diabetic patients that are associated with increased postcolectomy mortality and anastomotic leak.\\n\\n\\ndesign\\na prospectively acquired statewide database of patients who underwent colectomy was reviewed. primary risk factors were diabetes mellitus, hyperglycemia (glucose level \u2265 140 mg/dl), steroid use, and emergency surgery. categorical analysis, univariate logistic regression, and multivariate regression were used to evaluate the effects of these risk factors on outcomes.\\n\\n\\nsetting\\nparticipating hospitals within the michigan surgical quality collaborative.\\n\\n\\npatients\\ndatabase review of patients from hospitals within the michigan surgical quality collaborative.\\n\\n\\nmain outcome measures\\nanastomotic leak and 30- day mortality rate.\\n\\n\\nresults\\nof 5123 patients, 153 (3.0%) had leaks and 153 (3.0%) died. preoperative hyperglycemia occurred in 15.6% of patients, only 54% of whom were known to have diabetes. multivariate analysis showed that the risk of leak for patients with and without diabetes increased only by preoperative steroid use (p<.05). mortality among diabetic patients was associated with emergency surgery (p<.01) and anastomotic leak (p<.05); it was not associated with hyperglycemia. mortality among nondiabetic patients was associated with hyperglycemia (p<.005). the presence of an anastomotic leak was associated with increased mortality among diabetic patients (26.3% vs 4.5%; p<.001) compared with nondiabetic patients (6.0% vs 2.5%; p<.05).\\n\\n\\nconclusions\\nthe presence of diabetes did not have an effect on the presence of an anastomotic leak, but diabetic patients who had a leak had more than a 4-fold higher mortality compared with nondiabetic patients. preoperative steroid use led to increased rates of anastomotic leak in diabetic patients. mortality was associated with hyperglycemia for nondiabetic patients only. improved screening may identify high-risk patients who would benefit from perioperative intervention.",
            "contribution_ids": [
                "R32929"
            ]
        },
        {
            "instance_id": "R32940xR32936",
            "comparison_id": "R32940",
            "paper_id": "R32936",
            "text": "Smoking is a major risk factor for anastomotic leak in patients undergoing low anterior resection aim\\u2002 to examine modifiable risk factors for anastomotic leak in patients undergoing low anterior resection.",
            "contribution_ids": [
                "R32937"
            ]
        },
        {
            "instance_id": "R33008xR32995",
            "comparison_id": "R33008",
            "paper_id": "R32995",
            "text": "Chromosomal abnormalities in untreated patients with non-Hodgkin\u00e2\u0080\u0099s lymphoma: associations with histology, clinical characteristics, and treatment outcome. The Nebraska Lymphoma Study Group \" abstract \\n we describe the chromosomal abnormalities found in 104 previously untreated patients with non-hodgkin's lymphoma (nhl) and the correlations of these abnormalities with disease characteristics. the cytogenetic method used was a 24- to 48-hour culture, followed by g- banding. several significant associations were discovered. a trisomy 3 was correlated with high-grade nhl. in the patients with an immunoblastic nhl, an abnormal chromosome no. 3 or 6 was found significantly more frequently. as previously described, a t(14;18) was significantly correlated with a follicular growth pattern. abnormalities on chromosome no. 17 were correlated with a diffuse histology and a shorter survival. a shorter survival was also correlated with a +5, +6, +18, all abnormalities on chromosome no. 5, or involvement of breakpoint 14q11\u201312. in a multivariate analysis, these chromosomal abnormalities appeared to be independent prognostic factors and correlated with survival more strongly than any traditional prognostic variable. patients with a t(11;14)(q13;q32) had an elevated lactate dehydrogenase (ldh). skin infiltration was correlated with abnormalities on 2p. abnormalities involving breakpoints 6q11\u201316 were correlated with b symptoms. patients with abnormalities involving breakpoints 3q21\u201325 and 13q21\u201324 had more frequent bulky disease. the correlations of certain clinical findings with specific chromosomal abnormalities might help unveil the pathogenetic mechanisms of nhl and tailor treatment regimens. \"",
            "contribution_ids": [
                "R32996"
            ]
        },
        {
            "instance_id": "R33008xR33003",
            "comparison_id": "R33008",
            "paper_id": "R33003",
            "text": "Abnormalities of chromosome 1p \u00e2\u0081\u0084 q are highly associated with chromosome 13 \u00e2\u0081\u0084 13q deletions and are an adverse prognostic factor for the outcome of high-dose chemotherapy in patients with multiple myeloma the prognostic value of chromosomal abnormalities was studied in untreated multiple myeloma patients who were registered into a prospective randomised multicentre phase 3 study for intensified treatment (hovon24). a total of 453 patients aged less than 66\\u2003years with stage ii and iii a/b disease were registered in the clinical study. cytogenetic analysis was introduced as a standard diagnostic assay in 1998. it was performed at diagnosis in 160 patients and was successful in 137/160 patients (86%). an abnormal karyotype was observed in 53/137 (39%) of the patients. abnormalities of chromosome 1p and 1q were found in 19 (36% of patients with an abnormal karyotype) and 21 patients (40%). there was a strong association between chromosome 1p and/or 1q abnormalities and deletion of chromosome 13 or 13q (n\\u2003=\\u200327, p\\u2003<\\u20030\u00b7001). patients with karyotypic abnormalities had a significantly shorter overall survival (os) than patients with normal karyotypes. complex abnormalities, hypodiploidy, chromosome 1p abnormalities, chromosome 1q abnormalities, and chromosome 13 abnormalities were associated with inferior os on univariate analysis, as well as after adjustment for other prognostic factors. in conclusion, chromosome 13 abnormalities and chromosome 1p and/or 1q abnormalities were highly associated, and are risk factors for poor outcome after intensive therapy in multiple myeloma.",
            "contribution_ids": [
                "R33004"
            ]
        },
        {
            "instance_id": "R33091xR33009",
            "comparison_id": "R33091",
            "paper_id": "R33009",
            "text": "Partial trisomy of the long arm of chromosome 1 in myelofibrosis and polycythemia vera we have identified partial trisomy 1q in 2 patients with different hematologic disorders. the first patient was a 55\u2010year\u2010old female with myelosclerosis and myeloid metaplasia diagnosed at age 38 years presenting with anemia, fatigue, bruising, fever, and splenomegaly. at age 56, she had 50\u201395% myeloblast cells and 95\u2013100 nucleated rbc precursors per 100 wbc. chromosome analysis of unstimulated leukocytes with q, g, and c banding showed 46,xx,\u20106,+t(1;6) (q25;p22) in all metaphase cells. in vitro incorporation of fe55 was demonstrated in 90% of metaphases by autoradiography. the second patient, a 49\u2010year\u2010old male, was diagnosed as having polycythemia vera at age 30 during a regular checkup. he since developed hepatosplenomegaly. chromosome analysis from a direct bone marrow preparation at age 44 and 45 showed grossly normal karyotypes. at age 49, his marrow by q and g banding showed almost 100% of cells with 46,xy,\u201313,+t(1;13) (q12;p12). eleven cases of trisomy of 1q have been reported in various hematologic disorders. it is apparent that partial trisomy 1q represents another nonrandom chromosomal abnormality, in addition to the most common nonrandom chromosomal aberrations, such as the philadelphia chromosome, trisomy 8, trisomy 9, and monosomy 7 in hematologic disorders.",
            "contribution_ids": [
                "R33010"
            ]
        },
        {
            "instance_id": "R33091xR33013",
            "comparison_id": "R33091",
            "paper_id": "R33013",
            "text": "An identical translocation between chromosome 1 and 7 in three patients with myelofibrosis and myeloid metaplasia summary. an identical chromosome abnormality was observed in three unrelated patients with myelofibrosis and myeloid metaplasia, two of the patients showing a history of polycythaemia vera (pv) before development of the myelofibrosis. unstimulated peripheral blood cultures showed a translocation between chromosomes 1 and 7 replacing a homologue of pair 7. it was identified by g\u2010 and c\u2010banding as t(1;7)(7pter\u21927p11::1p1?\u21921qter).",
            "contribution_ids": [
                "R33014"
            ]
        },
        {
            "instance_id": "R33091xR33033",
            "comparison_id": "R33091",
            "paper_id": "R33033",
            "text": "Cytogenetic studies and their prognostic significance in agnogenic myeloid metaplasia: a report on 47 cases abstract \\n cytogenetic analysis was performed in 47 newly diagnosed patients with agnogenic myeloid metaplasia (amm); 32 had a normal karyotype (68%, group i), whereas 15 had clonal abnormalities (32%, group ii). the most frequent abnormal findings were a 20q- deletion in six cases (either alone or within complex anomalies), interstitial 13q- deletion in three cases (and monosomy 13 in one case), and acquired trisomy 21 or 21p+ in three cases. four cases exhibited complex aberrations involving several chromosomes, sometimes with a mosaicism. in two patients with an initial abnormal karyotype, further cytogenetic analysis during the disease course showed the appearance of additional clonal anomalies, and particularly of a probable philadelphia (ph1) variant in one case. treatment was essentially supportive. survival was significantly shorter in group ii (median, 30 months) compared with group i (median, not reached at 6 years; p = .015). in univariate analysis, other parameters significantly associated with a poor prognosis (p less than .05) were higher age, anemia, and increased percentage of circulating blasts. however, in a multivariate analysis, only cytogenetic abnormalities and age retained their independent prognostic value.",
            "contribution_ids": [
                "R33034"
            ]
        },
        {
            "instance_id": "R33091xR33086",
            "comparison_id": "R33091",
            "paper_id": "R33086",
            "text": "Prognostic relevance of cytogenetics determined by fluorescent in situ hybridization in patients having myelofibrosis with myeloid metaplasia in chronic myelofibrosis (mf), distinct recurrent cytogenetic aberrations have been identified but their true prognostic relevance remains uncertain. in this disease, cytogenetic studies as assessed by conventional metaphase karyotyping are limited due to the inherent difficulties in obtaining adequate bone marrow aspirates and the low proliferative capacity of the clonal cells. interphase fluorescent in situ hybridization (fish) can partly overcome these limitations and increase the sensitivity of cytogenetic assessment in mf.",
            "contribution_ids": [
                "R33087"
            ]
        },
        {
            "instance_id": "R33581xR33213",
            "comparison_id": "R33581",
            "paper_id": "R33213",
            "text": "Virtual supply-chain management in global business competition, companies believe greater transparency in supply-chain operations and collaboration is very important for success. transparency brings accountability and responsibility. this openness in the supply-chain allows companies to see how their suppliers are performing, from their sourcing of raw materials to their delivery to the retail outlet. achieving greater transparency in the supply chain requires the development of comprehensive e-logistics tools, which provide all players with open communication and shared information in every stage of the order-to-delivery process. supply-chain transparency in ordering, inventory and transportation is a prerequisite for optimization and is critical for making business decisions. in this paper, the experiences of a virtual supply-chain (vsc) company are discussed with reference to the strategies, methods and technologies of its supply-chain. the supply-chain aims for improved customer satisfaction and hence for overall competitiveness in a global market. this discussion will be useful for other companies intending to emulate some of the critical success factors in vsc management.",
            "contribution_ids": [
                "R33214"
            ]
        },
        {
            "instance_id": "R33581xR33245",
            "comparison_id": "R33581",
            "paper_id": "R33245",
            "text": "Assessing supply chain management success factors: a case study purpose the purpose of this study is to examine important operational issues related to strategic success factors that are necessary when implementing scm plans in an organization. design/methodology/approach a questionnaire was distributed to top and middle management within a large manufacturing firm, specializing in producing consumer and building products, to examine the importance and the extent to which the selected manufacturing company practiced the strategies based on these identified operational issues. findings reducing cost of operations, improving inventory, lead times and customer satisfaction, increasing flexibility and cross\u2010functional communication, and remaining competitive appear to be the most important objectives to implement scm strategies. the responses by the survey respondents indicate that not enough resources were allocated to implement and support scm initiatives in their divisions. in addition, they perceived that resource allocation could be improved in the areas of better information systems, greater commitment, setting clear\u2010cut goals, increased training, more personnel, and aligning scm initiatives with current priorities and resource commitments. practical implications the results will help to provide greater understanding of strategic and operational issues that support scm framework and implementing scm strategies to reduce supply chain\u2010wide costs and meeting customer service levels. originality/value the results will be useful for business managers to understand and implement scm plans in terms of their importance and the company\\'s culture.",
            "contribution_ids": [
                "R33246"
            ]
        },
        {
            "instance_id": "R33581xR33328",
            "comparison_id": "R33581",
            "paper_id": "R33328",
            "text": "Critical success factors in the context of humanitarian aid supply chains purpose critical success factors (csfs) have been widely used in the context of commercial supply chains. however, in the context of humanitarian aid (ha) this is a poorly addressed area and this paper therefore aims to set out the key areas for research. design/methodology/approach this paper is based on a conceptual discussion of csfs as applied to the ha sector. a detailed literature review is undertaken to identify csfs in a commercial context and to consider their applicability to the ha sector. findings csfs have not previously been identified for the ha sector, an issue addressed in this paper. research limitations/implications the main constraint on this paper is that csfs have not been previously considered in the literature as applied to ha. the relevance of csfs will therefore need to be tested in the ha environment and qualitative research is needed to inform further work. practical implications this paper informs the ha community of key areas of activity which have not been fully addressed and offers. originality/value this paper contributes to the understanding of supply chain management in an ha context.",
            "contribution_ids": [
                "R33329"
            ]
        },
        {
            "instance_id": "R33581xR33348",
            "comparison_id": "R33581",
            "paper_id": "R33348",
            "text": "Critical success factors for B2B e\u00e2\u0080\u0090commerce use within the UK NHS pharmaceutical supply chain purpose the purpose of this paper is to determine those factors perceived by users to influence the successful on\u2010going use of e\u2010commerce systems in business\u2010to\u2010business (b2b) buying and selling transactions through examination of the views of individuals acting in both purchasing and selling roles within the uk national health service (nhs) pharmaceutical supply chain. design/methodology/approach literature from the fields of operations and supply chain management (scm) and information systems (is) is used to determine candidate factors that might influence the success of the use of e\u2010commerce. a questionnaire based on these is used for primary data collection in the uk nhs pharmaceutical supply chain. factor analysis is used to analyse the data. findings the paper yields five composite factors that are perceived by users to influence successful e\u2010commerce use. \u201csystem quality,\u201d \u201cinformation quality,\u201d \u201cmanagement and use,\u201d \u201cworld wide web \u2013 assurance and empathy,\u201d and \u201ctrust\u201d are proposed as potential critical success factors. of these, all respondents ranked information quality, system quality, and trust as being of most importance, but differences in the rankings between purchasing and selling respondents are evident. research limitations/implications the empirical study is limited to a single supply network, and although the findings seem intuitively to be of relevance to other sectors and supply contexts, there remains an opportunity to test this through further research. there is also an opportunity to extend the survey research, particularly into the wholesaler organisations that operate in the sector of study. practical implications the managerial implications that result from this research provide practical guidance to organisations in this sector on how to ensure that e\u2010commerce systems for b2b buying and selling are used successfully. originality/value this paper furthers knowledge and understanding in the fields of operations management, is, and scm, by suggesting potential determinants of successful e\u2010commerce use in both buying and selling organisations within supply networks.",
            "contribution_ids": [
                "R33349"
            ]
        },
        {
            "instance_id": "R33581xR33358",
            "comparison_id": "R33581",
            "paper_id": "R33358",
            "text": "Requirements for forming an \u00e2\u0080\u0098e-supply chain\u00e2\u0080\u0099 \"in today's digital economy, web-based integration of the enterprises to form an e-supply chain is a critical weapon for orchestrating the whole supply chain towards competitiveness. this paper intends to discuss the requirements for forming an e-supply chain from different perspectives, such as integration with the legacy systems, timing and prior presence of erp (enterprise resources planning) systems, bpr (business process re-engineering) needs of internal and external business processes and business intelligence/decision support needs. a look at technical knowledge and structure to construct an e-supply chain is provided. challenges involved in forming an e-supply chain are also briefly mentioned as a separate section in this paper. during the study, requirements are gathered by making a review of recent literature.\"",
            "contribution_ids": [
                "R33359"
            ]
        },
        {
            "instance_id": "R33581xR33368",
            "comparison_id": "R33581",
            "paper_id": "R33368",
            "text": "Managing Supply Chain at High Technology Companies there is an expectation that high technology companies use unique and leading edge technology, and invest heavily in supply chain management. this research uses multiple case study methodology to determine factors affecting the supply chain management at high technology companies. the research benchmarks the supply chain performance of these high technology companies with supply chain of other supply chains at both strategic at tactical levels. the results indicate that at the strategic level the high technology companies and benchmark companies have a similar approach to supply chain management. however at the tactical, or critical, supply chain factor level, the analysis suggests that the benchmark companies (which happen to be companies dealing in commodity-type products) have a different approach to supply chain management.",
            "contribution_ids": [
                "R33369"
            ]
        },
        {
            "instance_id": "R33581xR33406",
            "comparison_id": "R33581",
            "paper_id": "R33406",
            "text": "A study of supplier selection factors for high-tech industries in the supply chain amid the intensive competition among global industries, the relationship between manufacturers and suppliers has turned from antagonist to cooperative. through partnerships, both parties can be mutually benefited, and the key factor that maintains such relationship lies in how manufacturers select proper suppliers. the purpose of this study is to explore the key factors considered by manufacturers in supplier selection and the relationships between these factors. through a literature review, eight supplier selection factors, comprising price response capability, quality management capability, technological capability, delivery capability, flexible capability, management capability, commercial image, and financial capability are derived. based on the theoretic foundation proposed by previous researchers, a causal model of supplier selection factors is further constructed. the results of a survey on high-tech industries are used to verify the relationships between the eight factors using structural equation modelling (sem). based on the empirical results, conclusions and suggestions are finally proposed as a reference for manufacturers and suppliers.",
            "contribution_ids": [
                "R33407"
            ]
        },
        {
            "instance_id": "R33581xR33436",
            "comparison_id": "R33581",
            "paper_id": "R33436",
            "text": "A Study of Key Success Factors for Supply Chain Management System in Semiconductor Industry \"developing a supply chain management (scm) system is costly, but important. however, because of its complicated nature, not many of such projects are considered successful. few research publications directly relate to key success factors (ksfs) for implementing and operating a scm system. motivated by the above, this research proposes two hierarchies of ksfs for scm system implementation and operation phase respectively in the semiconductor industry by using a two-step approach. first, a literature review indicates the initial hierarchy. the second step includes a focus group approach to finalize the proposed ksf hierarchies by extracting valuable experiences from executives and managers that actively participated in a project, which successfully establish a seamless scm integration between the world's largest semiconductor foundry manufacturing company and the world's largest assembly and testing company. finally, this research compared the ksf's between the two phases and made a conclusion. future project executives may refer the resulting ksf hierarchies as a checklist for scm system implementation and operation in semiconductor or related industries.\"",
            "contribution_ids": [
                "R33437"
            ]
        },
        {
            "instance_id": "R33581xR33447",
            "comparison_id": "R33581",
            "paper_id": "R33447",
            "text": "Linking Success Factors to Financial Performance problem statement: based on a literature survey, an attempt has been made in this study to \\ndevelop a framework for identifying the success factors. in addition, a list of key success factors is \\npresented. the emphasis is on success factors dealing with breadth of services, internationalization of \\noperations, industry focus, customer focus, 3pl experience, relationship with 3pls, investment in \\nquality assets, investment in information systems, availability of skilled professionals and supply chain \\nintegration. in developing the factors an effort has been made to align and relate them to financial \\nperformance. conclusion/recommendations: we found success factors \u201crelationship with 3pls and skilled logistics professionals\u201d would substantially improves financial performance metric profit growth. our findings also contribute to managerial practice by offering a benchmarking tool that can be used by managers in the 3pl service provider industry in india.",
            "contribution_ids": [
                "R33448"
            ]
        },
        {
            "instance_id": "R33581xR33461",
            "comparison_id": "R33581",
            "paper_id": "R33461",
            "text": "Supply chain management: success factors from the Malaysian manufacturer's perspective the purpose of this paper is to shed the light on the critical success factors that lead to high supply chain performance outcomes in a malaysian manufacturing company. the critical success factors consist of relationship with customer and supplier, information communication and technology (ict), material flow management, corporate culture and performance measurement. questionnaire was the main instrument for the study and it was distributed to 84 staff from departments of purchasing, planning, logistics and operation. data analysis was conducted by employing descriptive analysis (mean and standard deviation), reliability analysis, pearson correlation analysis and multiple regression. the findings show that there are relationships exist between relationship with customer and supplier, ict, material flow management, performance measurement and supply chain management (scm) performance, but not for corporate culture. forming a good customer and supplier relationship is the main predictor of scm performance, followed by performance measurement, material flow management and ict. it is recommended that future study to determine additional success factors that are pertinent to firms\u2019 current scm strategies and directions, competitive advantages and missions. logic suggests that further study to include more geographical data coverage, other nature of businesses and research instruments. \\n \\n \\xa0 \\n \\n key words:\\xa0supply chain management, critical success factor.",
            "contribution_ids": [
                "R33462"
            ]
        },
        {
            "instance_id": "R33581xR33482",
            "comparison_id": "R33581",
            "paper_id": "R33482",
            "text": "Key success factors and their performance implications in the Indian third-party logistics (3PL) industry this paper uses the extant literature to identify the key success factors that are associated with performance in the indian third-party logistics service providers (3pl) sector. we contribute to the sparse literature that has examined the relationship between key success factors and performance in the indian 3pl context. this study offers new insights and isolates key success factors that vary in their impact on operations and financial performance measures. specifically, we found that the key success factor of relationship with customers significantly influenced the operations measures of on-time delivery performance and customer satisfaction and the financial measure of profit growth. similarly, the key success factor of skilled logistics professionals improved the operational measure of customer satisfaction and the financial measure of profit growth. the key success factor of breadth of service significantly affected the financial measure of revenue growth, but did not affect any operational measure. to further unravel the patterns of these results, a contingency analysis of these relationships according to firm size was also conducted. relationship with 3pls was significant irrespective of firm size. our findings contribute to academic theory and managerial practice by offering context-specific suggestions on the usefulness of specific key success factors based on their potential influence on operational and financial performance in the indian 3pl industry.",
            "contribution_ids": [
                "R33483"
            ]
        },
        {
            "instance_id": "R33581xR33489",
            "comparison_id": "R33581",
            "paper_id": "R33489",
            "text": "Identifying critical enablers and pathways to high performance supply chain quality management purpose the aim of this paper is threefold: first, to examine the content of supply chain quality management (scqm); second, to identify the structure of scqm; and third, to show ways for finding improvement opportunities and organizing individual institution\\'s resources/actions into collective performance outcomes. design/methodology/approach to meet the goals of this work, the paper uses abductive reasoning and two qualitative methods: content analysis and formal concept analysis (fca). primary data were collected from both original design manufacturers (odms) and original equipment manufacturers (oems) in taiwan. findings according to the qualitative empirical study, modern enterprises need to pay immediate attention to the following two pathways: a compliance approach and a voluntary approach. for the former, three strategic content variables are identified: training programs, iso, and supplier quality audit programs. as for initiating a voluntary effort, modern lead firms need to instill \u201cmotivation\u201d into a supply chain quality system. practical implications the findings based on the abductive model reveal numerous strategic and tactical enablers, key sequences to move firms from their current situation to their preferred one, and critical opportunities for supply chain\u2010wide quality system designs. originality/value this study will be of great value to supply chain policy makers, supply chain operators, and decision makers in lead firms in a supply chain setting and their channel partners. the proactive use of the authors\\' proposed research procedure is indispensable to effective supply chain quality planning.",
            "contribution_ids": [
                "R33490"
            ]
        },
        {
            "instance_id": "R33581xR33521",
            "comparison_id": "R33581",
            "paper_id": "R33521",
            "text": "Evaluating the critical success factors of supplier development: a case study purpose the purpose of this paper is to identify and evaluate the critical success factors (csfs) responsible for supplier development (sd) in a manufacturing supply chain environment. design/methodology/approach in total, 13 csfs for sd are identified (i.e. long\u2010term strategic goal; top management commitment; incentives; supplier\\'s supplier condition; proximity to manufacturing base; supplier certification; innovation capability; information sharing; environmental readiness; external environment; project completion experience; supplier status and direct involvement) through extensive literature review and discussion held with managers/engineers in different indian manufacturing companies. a fuzzy analytic hierarchy process (fahp) is proposed and developed to evaluate the degree of impact of each csf on sd. findings the degree of impact for each csf on sd is established for an indian company. the results are discussed in detail with managerial implications. the long\u2010term strategic goal is found to be the most significant csf for successful sd implementation. research limitations/implications this study has not been statistically validated in a manufacturing supply chain environment for complete acceptability. practical implications the simplicity and clarity of the proposed approach enhances its acceptability for evaluating csfs in manufacturing supply chain environment. it also provides the direction for optimally allocating the efforts and resources for successful implementation of sd in short duration. originality/value although both csfs and sd have been widely researched, but no study has been reported in the literature to prioritize and rank the csfs of sd in an indian manufacturing environment. the paper contributes to research in the supply chain management area in general and sd in particular for manufacturing environment. the proposed approach has the ability to capture the judgment of multiple experts to prioritize and rank csfs for sd.",
            "contribution_ids": [
                "R33522"
            ]
        },
        {
            "instance_id": "R33581xR33343",
            "comparison_id": "R33581",
            "paper_id": "R33343",
            "text": "Critical success factors for improving decision quality on collaborative design in the IC supply chain because the design process of integrated circuit (ic) product is knowledge-intensive and time-consuming, the collaboration among ic designers and manufacturers is crucial for reducing time to market of designing product. to enhance the quality of manufacturing strategic decisions for collaborative ic design, manufacturing practices must be identified as the core elements of manufacturing strategy. however, little research has been done regarding the essentials of implementing collaboration among ic designers. this study aims to clarify terminology of decision quality in manufacturing strategy and define critical success factors (csfs) as manufacturing practices for improving decision quality on collaborative design in the ic supply chain through comprehensive literature review. moreover, this study proposes a framework in which the csfs can be identified for different parties in ic supply chain.",
            "contribution_ids": [
                "R33344"
            ]
        },
        {
            "instance_id": "R33581xR33388",
            "comparison_id": "R33581",
            "paper_id": "R33388",
            "text": "E-procurement, the golden key to optimizing the supply chains system procurement is an important component in the field of operating resource management and e-procurement is the golden key to optimizing the supply chains system. global firms are optimistic on the level of savings that can be achieved through full implementation of e-procurement strategies. e-procurement is an internet-based business process for obtaining materials and services and managing their inflow into the organization. in this paper, the subjects of supply chains and e-procurement and its benefits to organizations have been studied. also, e-procurement in construction and its drivers and barriers have been discussed and a framework of supplier selection in an e-procurement environment has been demonstrated. this paper also has addressed critical success factors in adopting e-procurement in supply chains. keywords\u2014e-procurement, supply chain, benefits, construction, drivers, barriers, supplier selection, cfss.",
            "contribution_ids": [
                "R33389"
            ]
        },
        {
            "instance_id": "R33783xR33645",
            "comparison_id": "R33783",
            "paper_id": "R33645",
            "text": "Estimation and elimination of harmonics in power system using modified FFT with variable learning of Adaline \"this paper presents a new technique for harmonic detection, estimation and elimination in power system. the approach expresses the input signal in the form of fourier transformation and adjusts the fourier coefficients using linear adaptive filters (adaline). two of the existing approaches using conventional fast fourier transformation (fft) and fft with modified w-h learning have been discussed with their merits and demerits. a new approach has been proposed using a network comprising three different adalines and involving variable learning rate. this approach is able to mitigate the shortcomings of the existing techniques and is time efficient as well. the detailed architecture for the proposed approach has been discussed and the algorithm has then been tested on different test signals. the approach has been compared with the existing techniques and it's superiority over these has thus been established.\"",
            "contribution_ids": [
                "R33646",
                "R33736"
            ]
        },
        {
            "instance_id": "R33783xR33647",
            "comparison_id": "R33783",
            "paper_id": "R33647",
            "text": "Improved shunt APF based on using adaptive RBF neural network and modified hysteresis current control in this paper, a new combination is proposed to control shunt active power filters (apf). the recommended system has better specifications in comparison with other control methods. in the proposed combination, an rbf neural network is employed to extract compensation reference currents for a variable non-linear load. in order to make the employed model much simpler and tighter, an adaptive learning algorithm for rbf network is proposed. in addition, a modified hysteresis current control technique based on defining a variable hysteresis band is employed to avoid any power system resonance. in this method the hysteresis band is expressed as a function of source voltage, rate of reference current variations and voltage of dc link capacitor in such a way that the switching frequency of the inverter switches remains almost constant. in summary, extraction of compensation reference current is done with lower amount of computations. beside, the threat of resonance occurrence is cancelled. the simulation results which are done by matlab/simulink illustrate the validity and effectiveness of the proposed combination.",
            "contribution_ids": [
                "R33648",
                "R33737"
            ]
        },
        {
            "instance_id": "R33783xR33651",
            "comparison_id": "R33783",
            "paper_id": "R33651",
            "text": "Neural Network-Based Approach for Identification of the Harmonic Content of a Nonlinear Load in a Single-Phase System in this paper an alternative method based on artificial neural networks is presented to determine harmonic components in the load current of a single-phase electric power system with nonlinear loads, whose parameters can vary so much in reason of the loads characteristic behaviors as because of the human intervention. the first six components in the load current are determined using the information contained in the time-varying waveforms. the effectiveness of this method is verified by using it in a single-phase active power filter with selective compensation of the current drained by an ac controller. the proposed method is compared with the fast fourier transform.",
            "contribution_ids": [
                "R33652",
                "R33739"
            ]
        },
        {
            "instance_id": "R33783xR33655",
            "comparison_id": "R33783",
            "paper_id": "R33655",
            "text": "New Research on Harmonic Detection Based on Neural Network for Power System analysis and control for power quality by neural network is a new research field in electrical power system. rapid and reliable extract the harmonic components determine the overall performance of active power filter (apf). this paper presents a new three-layer feedforward neural network based on error back-propagation algorithm that the training sample without time delay, which can detecting harmonics for power system in real-time. with the simulation study using matlab, the simulation results illustrate that the harmonic detection method based on neural network is feasible, which can quickly detecting the harmonics for non-linear load.",
            "contribution_ids": [
                "R33656",
                "R33741"
            ]
        },
        {
            "instance_id": "R33783xR33675",
            "comparison_id": "R33783",
            "paper_id": "R33675",
            "text": "Predictive and Adaptive ANN (Adaline) Based Harmonic Compensation for Shunt Active Power Filter estimation of the current-reference to compensate for the harmonic and reactive component of the load current is important in a shunt type active power filter. this paper applies ann based predictive and adaptive reference generation technique. predictive scheme extracts the information of the fundamental component through an ann that replaces a low pass filter. this ann based low pass-filter is trained offline with large number of training set to predict the fundamental magnitude of load current. these predictive reference generation techniques work well for load change pattern closer to the trained data and for clean source voltage. however, the performance deteriorates in case of distortion in source voltage and also if training data drifts quite significantly from test data. to overcome this, an adaline based ann is applied after the operation of the predictive algorithm. it has been shown that the combined predictive adaptive approach offers better performance. extensive results from simulation have confirmed the usefulness of the proposed technique.",
            "contribution_ids": [
                "R33676",
                "R33751"
            ]
        },
        {
            "instance_id": "R33783xR33685",
            "comparison_id": "R33783",
            "paper_id": "R33685",
            "text": "A Neural Network Adaptive Detecting Approach of Harmonic Current a neural network adaptive detecting approach of harmonic current for apf (active power filter) is proposed in this paper. it bases on the adaptive noise canceling technology (anct). regarding the fundamental current as noise source, it can be cancelled from the load current, and then the harmonic current is obtained. artificial neural network (ann) with two layers is used to cancel the harmonics. the structure of this neural network and the adaptive adjusting algorithm are presented. the study has been carried out through detail digital dynamic simulation using the matlab simulink power system toolbox. the results of simulation show that this approach can detect harmonic components at real time with high precision, little calculation and strong adaptive ability.",
            "contribution_ids": [
                "R33686",
                "R33756"
            ]
        },
        {
            "instance_id": "R33783xR33689",
            "comparison_id": "R33783",
            "paper_id": "R33689",
            "text": "Active Power Filter of Three-Phase Based on Neural Network this paper presents a novel control design of shunt active power filter to compensate reactive power and reduce the unwanted harmonics. a shunt active filter is realized employing three-phase voltage source inverter (vsi) and a control circuit. the shunt active filter acts as a current source, which is connected in parallel with a nonlinear load and controlled to generate the required compensation currents. the control circuit using neural network controller is proposed. one adaptive neural network (ann) controller is designed to estimate the harmonic components of the distorted load current and supply voltage [1]. a power factor correction function is incorporated in the shunt active filter to achieve a power factor that is near to unity. the different cases are considered and then simulated in order to show validity of the active power filter with neural network control.",
            "contribution_ids": [
                "R33690",
                "R33758"
            ]
        },
        {
            "instance_id": "R33783xR33699",
            "comparison_id": "R33783",
            "paper_id": "R33699",
            "text": "A Single-Phase DG Generation Unit With Shunt Active Power Filter Capability by Adaptive Neural Filtering this paper deals with a single-phase distributed generation (dg) system with active power filtering (apf) capability, devised for utility current harmonic compensation. the idea is to integrate the dg unit functions with the shunt apf capabilities, since the dg is connected in parallel to the grid. with the proposed approach, the control of the dg unit is performed by injecting into the grid a current with the same phase and frequency of the grid voltage and with amplitude depending on the power available from the renewable sources. on the other hand, the load harmonic current compensation is performed by injecting into the ac system harmonic currents as those of the load but with opposite phase, thus keeping the line current almost sinusoidal. both the phase detection of the grid voltage and the computation of the load harmonic compensation current have been performed by two neural adaptive filters with the same structure, one in configuration \"notch\" and the other complementary in configuration \"band\". the methodology has been tested successfully both in numerical simulation and experimentally on a suitably devised test setup",
            "contribution_ids": [
                "R33700",
                "R33763"
            ]
        },
        {
            "instance_id": "R33783xR33709",
            "comparison_id": "R33783",
            "paper_id": "R33709",
            "text": "Design of Single-phase Shunt Active Power Filter Based on ANN in this paper, a single-phase shunt active power filter (apf) is presented to compensate reactive power and eliminate harmonics in power system. sensing load current, dc bus voltage, reference dc bus voltage and source voltage compute reference current of apf through modified adaptive artificial neural network (ann). a modified hysteretic current controller is used to generate the firing pulses of the voltage source inverter which generate reactive and harmonic current to compensate the nonlinear loads. the proposed system is implemented using digital signal processor (dsp). simulating and experimental results are presented to confirm the validity of the scheme.",
            "contribution_ids": [
                "R33710",
                "R33768"
            ]
        },
        {
            "instance_id": "R33783xR33711",
            "comparison_id": "R33783",
            "paper_id": "R33711",
            "text": "A Unified Artificial Neural Network Architecture for Active Power Filters in this paper, an efficient and reliable neural active power filter (apf) to estimate and compensate for harmonic distortions from an ac line is proposed. the proposed filter is completely based on adaline neural networks which are organized in different independent blocks. we introduce a neural method based on adalines for the online extraction of the voltage components to recover a balanced and equilibrated voltage system, and three different methods for harmonic filtering. these three methods efficiently separate the fundamental harmonic from the distortion harmonics of the measured currents. according to either the instantaneous power theory or to the fourier series analysis of the currents, each of these methods are based on a specific decomposition. the original decomposition of the currents or of the powers then allows defining the architecture and the inputs of adaline neural networks. different learning schemes are then used to control the inverter to inject elaborated reference currents in the power system. results obtained by simulation and their real-time validation in experiments are presented to compare the compensation methods. by their learning capabilities, artificial neural networks are able to take into account time-varying parameters, and thus appreciably improve the performance of traditional compensating methods. the effectiveness of the algorithms is demonstrated in their application to harmonics compensation in power systems",
            "contribution_ids": [
                "R33712",
                "R33769"
            ]
        },
        {
            "instance_id": "R33783xR33723",
            "comparison_id": "R33783",
            "paper_id": "R33723",
            "text": "Artificial Neural Networks as Harmonic Detectors \"in order to succeed harmonic mitigation in electrical circuits, it's very important to estimate or extract the compensating harmonic references. any failure in this last procedure will cause failure in the harmonic elimination. in fact, in the literature many harmonic detection or estimation methods were presented, in this paper we focus on a new idea to apply artificial intelligence methods namely artificial neural networks in harmonic detection\"",
            "contribution_ids": [
                "R33724",
                "R33775"
            ]
        },
        {
            "instance_id": "R33783xR33729",
            "comparison_id": "R33783",
            "paper_id": "R33729",
            "text": "Power harmonic identification and compensation with an artificial neural network method this paper introduces a new neural method for harmonic identification and compensation. based on adaline networks, the proposed method is called the diphase currents method. the architecture and the learning are formulated based on an original decomposition of the disturbed currents. these currents are converted in the alphabeta- or dq-spaces to separate each harmonic component in a linear expression. in this harmonic compensation method, the harmonic components may be individually selected and the reactive power may be compensated. the proposed method is robust and has been efficiently compared to other conventional and neural harmonic compensation methods. in order to validate the performance of the diphase currents method, simulation studies are carried out in the presence of plant variations. experiments are also presented to show the performance of the proposed neural method under many practical industrial conditions.",
            "contribution_ids": [
                "R33730",
                "R33778"
            ]
        },
        {
            "instance_id": "R33783xR33779",
            "comparison_id": "R33783",
            "paper_id": "R33779",
            "text": "Neural Network controlled three-phase three-wire shunt active Power Filter \"three-phase shunt active power filters (shunt apfs) are widely used in industrial applications to compensate for harmonics, generated by nonlinear loads. in order to succeed the compensation it's necessary to assure current control in the ac side of the apf and voltage or current control in the dc side of the apf. in real practice pi controllers are the most common, as a novel and intelligent control technique neural network controllers are under study and investigation in such application. in this paper, a neural network controller is used to control a three- phase three-wire voltage source shunt apf, its performance in terms of harmonic compensation and speed of response are compared to those of classic pi controller.\"",
            "contribution_ids": [
                "R33780"
            ]
        },
        {
            "instance_id": "R33783xR33781",
            "comparison_id": "R33783",
            "paper_id": "R33781",
            "text": "Comparison of PI and ANN Control Strategies of Unified Shunt Series Compensator this paper presents the compensation principle using pi and ann control strategies of the ussc in detail. the ussc is an active filter (af) and it compensates the reactive power, harmonics in both the voltage and current caused by loads. the ussc makes use of two back to back connected igbt based voltage source inverters (vsis) with a common dc bus. one inverter is connected in series and the other one is placed in shunt with the load. the shunt inverter works as a current source and it compensates the current harmonics. the series inverter works as a voltage source and it helps in compensating the voltage harmonics. previous works presented a control strategy for shunt active filter with pi control. then, this control strategy was extended to develop the two controllers for shunt and series active filters. the simulation results of these control strategies are listed for comparison and verification of results",
            "contribution_ids": [
                "R33782"
            ]
        },
        {
            "instance_id": "R33783xR33713",
            "comparison_id": "R33783",
            "paper_id": "R33713",
            "text": "Neural Network Controlled Shunt Active Filter For Non Linear Loads as industry power demand become increasingly sensitive, power quality distortion becomes a critical issue. the recent increase in nonlinear loads drawing non-sinusoidal currents has seen the introduction to manage the clean delivery of power. in this paper, a three-phase shunt active power filter (apf) using artificial neural network technique is proposed to mitigate harmonics, to compensate reactive power, to improve power factor and to remedy system unbalance. the simulation is done on a three-phase system and the results are used for comparison.",
            "contribution_ids": [
                "R33714",
                "R33770"
            ]
        },
        {
            "instance_id": "R33851xR33795",
            "comparison_id": "R33851",
            "paper_id": "R33795",
            "text": "Comparative analysis of algorithms for identifying amplifications and deletions in array CGH data motivation\\narray comparative genomic hybridization (cgh) can reveal chromosomal aberrations in the genomic dna. these amplifications and deletions at the dna level are important in the pathogenesis of cancer and other diseases. while a large number of approaches have been proposed for analyzing the large array cgh datasets, the relative merits of these methods in practice are not clear.\\n\\n\\nresults\\nwe compare 11 different algorithms for analyzing array cgh data. these include both segment detection methods and smoothing methods, based on diverse techniques such as mixture models, hidden markov models, maximum likelihood, regression, wavelets and genetic algorithms. we compute the receiver operating characteristic (roc) curves using simulated data to quantify sensitivity and specificity for various levels of signal-to-noise ratio and different sizes of abnormalities. we also characterize their performance on chromosomal regions of interest in a real dataset obtained from patients with glioblastoma multiforme. while comparisons of this type are difficult due to possibly sub-optimal choice of parameters in the methods, they nevertheless reveal general characteristics that are helpful to the biological investigator.",
            "contribution_ids": [
                "R33796"
            ]
        },
        {
            "instance_id": "R33851xR33819",
            "comparison_id": "R33851",
            "paper_id": "R33819",
            "text": "The Effect of Algorithms on Copy Number Variant Detection background the detection of copy number variants (cnvs) and the results of cnv-disease association studies rely on how cnvs are defined, and because array-based technologies can only infer cnvs, cnv-calling algorithms can produce vastly different findings. several authors have noted the large-scale variability between cnv-detection methods, as well as the substantial false positive and false negative rates associated with those methods. in this study, we use variations of four common algorithms for cnv detection (penncnv, quantisnp, hmmseg, and cnvpartition) and two definitions of overlap (any overlap and an overlap of at least 40% of the smaller cnv) to illustrate the effects of varying algorithms and definitions of overlap on cnv discovery. methodology and principal findings we used a 56 k illumina genotyping array enriched for cnv regions to generate hybridization intensities and allele frequencies for 48 caucasian schizophrenia cases and 48 age-, ethnicity-, and gender-matched control subjects. no algorithm found a difference in cnv burden between the two groups. however, the total number of cnvs called ranged from 102 to 3,765 across algorithms. the mean cnv size ranged from 46 kb to 787 kb, and the average number of cnvs per subject ranged from 1 to 39. the number of novel cnvs not previously reported in normal subjects ranged from 0 to 212. conclusions and significance motivated by the availability of multiple publicly available genome-wide snp arrays, investigators are conducting numerous analyses to identify putative additional cnvs in complex genetic disorders. however, the number of cnvs identified in array-based studies, and whether these cnvs are novel or valid, will depend on the algorithm(s) used. thus, given the variety of methods used, there will be many false positives and false negatives. both guidelines for the identification of cnvs inferred from high-density arrays and the establishment of a gold standard for validation of cnvs are needed.",
            "contribution_ids": [
                "R33820"
            ]
        },
        {
            "instance_id": "R33851xR33824",
            "comparison_id": "R33851",
            "paper_id": "R33824",
            "text": "Accuracy of CNV Detection from GWAS Data \"several computer programs are available for detecting copy number variants (cnvs) using genome-wide snp arrays. we evaluated the performance of four cnv detection software suites\u2014birdsuite, partek, helixtree, and penncnv-affy\u2014in the identification of both rare and common cnvs. each program's performance was assessed in two ways. the first was its recovery rate, i.e., its ability to call 893 cnvs previously identified in eight hapmap samples by paired-end sequencing of whole-genome fosmid clones, and 51,440 cnvs identified by array comparative genome hybridization (acgh) followed by validation procedures, in 90 hapmap ceu samples. the second evaluation was program performance calling rare and common cnvs in the bipolar genome study (bigs) data set (1001 bipolar cases and 1033 controls, all of european ancestry) as measured by the affymetrix snp 6.0 array. accuracy in calling rare cnvs was assessed by positive predictive value, based on the proportion of rare cnvs validated by quantitative real-time pcr (qpcr), while accuracy in calling common cnvs was assessed by false positive/false negative rates based on qpcr validation results from a subset of common cnvs. birdsuite recovered the highest percentages of known hapmap cnvs containing >20 markers in two reference cnv datasets. the recovery rate increased with decreased cnv frequency. in the tested rare cnv data, birdsuite and partek had higher positive predictive values than the other software suites. in a test of three common cnvs in the bigs dataset, birdsuite's call was 98.8% consistent with qpcr quantification in one cnv region, but the other two regions showed an unacceptable degree of accuracy. we found relatively poor consistency between the two \u201cgold standards,\u201d the sequence data of kidd et al., and acgh data of conrad et al. algorithms for calling cnvs especially common ones need substantial improvement, and a \u201cgold standard\u201d for detection of cnvs remains to be established.\"",
            "contribution_ids": [
                "R33825"
            ]
        },
        {
            "instance_id": "R33953xR33869",
            "comparison_id": "R33953",
            "paper_id": "R33869",
            "text": "An Ant Colony Optimization Approach to Test Sequence Generation for Statebased Software Testing properly generated test suites may not only locate the defects in software systems, but also help in reducing the high cost associated with software testing, ft is often desired that test sequences in a test suite can be automatically generated to achieve required test coverage. however, automatic test sequence generation remains a major problem in software testing. this paper proposes an ant colony optimization approach to automatic test sequence generation for state-based software testing. the proposed approach can directly use uml artifacts to automatically generate test sequences to achieve required test coverage.",
            "contribution_ids": [
                "R33870"
            ]
        },
        {
            "instance_id": "R33953xR33873",
            "comparison_id": "R33953",
            "paper_id": "R33873",
            "text": "Automatic Mutation Test Input Data Generation via Ant Colony fault-based testing is often advocated to overcome limitations ofother testing approaches; however it is also recognized as beingexpensive. on the other hand, evolutionary algorithms have beenproved suitable for reducing the cost of data generation in the contextof coverage based testing. in this paper, we propose a newevolutionary approach based on ant colony optimization for automatictest input data generation in the context of mutation testingto reduce the cost of such a test strategy. in our approach the antcolony optimization algorithm is enhanced by a probability densityestimation technique. we compare our proposal with otherevolutionary algorithms, e.g., genetic algorithm. our preliminaryresults on java testbeds show that our approach performed significantlybetter than other alternatives.",
            "contribution_ids": [
                "R33874"
            ]
        },
        {
            "instance_id": "R33953xR33894",
            "comparison_id": "R33953",
            "paper_id": "R33894",
            "text": "Variable Strength Interaction Testing with an Ant Colony System Approach interaction testing (also called combinatorial testing) is an cost-effective test generation technique in software testing. most research work focuses on finding effective approaches to build optimal t-way interaction test suites. however, the strength of different factor sets may not be consistent due to the practical test requirements. to solve this problem, a variable strength combinatorial object and several approaches based on it have been proposed. these approaches include simulated annealing (sa) and greedy algorithms. sa starts with a large randomly generated test suite and then uses a binary search process to find the optimal solution. although this approach often generates the minimal test suites, it is time consuming. greedy algorithms avoid this shortcoming but the size of generated test suites is usually not as small as sa. in this paper, we propose a novel approach to generate variable strength interaction test suites (vsits). in our approach, we adopt a one-test-at-a-time strategy to build final test suites. to generate a single test, we adopt ant colony system (acs) strategy, an effective variant of ant colony optimization (aco). in order to successfully adopt acs, we formulize the solution space, the cost function and several heuristic settings in this framework. we also apply our approach to some typical inputs. experimental results show the effectiveness of our approach especially compared to greedy algorithms and several existing tools.",
            "contribution_ids": [
                "R33895"
            ]
        },
        {
            "instance_id": "R33953xR33899",
            "comparison_id": "R33953",
            "paper_id": "R33899",
            "text": "Building Prioritized Pairwise Interaction Test Suites with Ant Colony Optimization interaction testing offers a stable cost-benefit ratio in identifying faults. but in many testing scenarios, the entire test suite cannot be fully executed due to limited time or cost. in these situations, it is essential to take the importance of interactions into account and prioritize these tests. to tackle this issue, the biased covering array is proposed and the weighted density algorithm (wda) is developed. to find a better solution, in this paper we adopt ant colony optimization (aco) to build this prioritized pairwise interaction test suite (pits). in our research, we propose four concrete test generation algorithms based on ant system, ant system with elitist, ant colony system and max-min ant system respectively. we also implement these algorithms and apply them to two typical inputs and report experimental results. the results show the effectiveness of these algorithms.",
            "contribution_ids": [
                "R33900"
            ]
        },
        {
            "instance_id": "R33953xR33907",
            "comparison_id": "R33953",
            "paper_id": "R33907",
            "text": "An approach of optimal path generation using ant colony optimization software testing is one of the indispensable parts of the software development lifecycle and structural testing is one of the most widely used testing paradigms to test various software. structural testing relies on code path identification, which in turn leads to identification of effective paths. aim of the current paper is to present a simple and novel algorithm with the help of an ant colony optimization, for the optimal path identification by using the basic property and behavior of the ants. this novel approach uses certain set of rules to find out all the effective/optimal paths via ant colony optimization (aco) principle. the method concentrates on generation of paths, equal to the cyclomatic complexity. this algorithm guarantees full path coverage.",
            "contribution_ids": [
                "R33908"
            ]
        },
        {
            "instance_id": "R33953xR34961",
            "comparison_id": "R33953",
            "paper_id": "R34961",
            "text": "Introduction: A Survey of the Evolutionary Computation Techniques for Software Engineering this chapter aims to present a part of the computer science literature in which the evolutionary computation techniques, optimization techniques and other bio-inspired techniques are used to solve different search and optimization problems in the area of software engineering.",
            "contribution_ids": [
                "R33948",
                "R34963"
            ]
        },
        {
            "instance_id": "R34099xR33985",
            "comparison_id": "R34099",
            "paper_id": "R33985",
            "text": "Up-estuary dispersal of young-of-the-year bay anchovy Anchoa mitchilli in the Chesapeake Bay: inferences from microprobe analysis of strontium in otoliths young-of-the-year (yoy) bay anchovy anchoa mitchilli occur in higher proportion rel- ative to larvae in the upper chesapeake bay. this has led to the hypothesis that up-bay dispersal favors recruitment. here we test whether recruitment of bay anchovy to different parts of the chesa- peake bay results from differential dispersal rates. electron microprobe analysis of otolith strontium was used to hind-cast patterns and rates of movement across salinity zones. individual chronologies of strontium were constructed for 55 bay anchovy aged 43 to 103 d collected at 5 chesapeake bay mainstem sites representing upper, middle, and lower regions of the bay during september 1998. most yoy anchovy were estimated to have originated in the lower bay. those collected at 5 and 11 psu sites exhibited the highest past dispersal rates, all in an up-estuary direction. no significant net dispersal up- or down-estuary occurred for recruits captured at the polyhaline (\u266218 psu) site. ini- tiation of ingress to lower salinity waters (<15 psu) was estimated to occur near metamorphosis, dur- ing the early juvenile stage, at sizes \u2662 25 mm standard length (sl) and ages \u2662 50 d after hatch. esti- mated maximum upstream dispersal rate (over-the-ground speed) during the first 50 to 100 d of life exceeded 50 mm s -1 .",
            "contribution_ids": [
                "R33986"
            ]
        },
        {
            "instance_id": "R34099xR34053",
            "comparison_id": "R34099",
            "paper_id": "R34053",
            "text": "Coexistence of anadromous and lacustrine life histories of the shirauo, Sala- nichthys microdon the environmental history of the shirauo, salangichthys microdon, was examined in terms of strontium (sr) and calcium (ca) uptake in the otolith, by means of wavelength dispersive x-ray spectrometry on an electron microprobe. anadromous and lacustrine type of the shirauo were found to occur sympatric. otolith sr concentration or sr\\xa0:\\xa0ca ratios of anadromous shirauo fluctuated strongly along the life-history transect in accordance with the migration (habitat) pattern from sea to freshwater. in contrast, the sr concentration or the sr\\xa0:\\xa0ca ratios of lacustrine shirauo remained at consistently low levels throughout the otolith. the higher ratios in anadromous shirauo, in the otolith region from the core to 90\u2013230\\xa0\u03bcm, corresponded to the initial sea-going period, probably reflecting the ambient salinity or the seawater\u2013freshwater gradient in sr concentration. the findings clearly indicated that otolith sr\\xa0:\\xa0ca ratios reflected individual life histories, enabling these anadromous shirauo to be distinguished from lacustrine shirauo.",
            "contribution_ids": [
                "R34054"
            ]
        },
        {
            "instance_id": "R34099xR34057",
            "comparison_id": "R34099",
            "paper_id": "R34057",
            "text": "Migration and rearing histories of chinook salmon (Oncorhynchus tshawytscha) determined by ion microprobe Sr isotope and Sr/Ca transects of otoliths \" strontium isotope and sr/ca ratios measured in situ by ion microprobe along radial transects of otoliths of juvenile chinook salmon (oncorhynchus tshawytscha) vary between watersheds with contrasting geology. otoliths from ocean-type chinook from skagit river estuary, washington, had prehatch regions with 87 sr/ 86 sr ratios of ~0.709, suggesting a maternally inherited marine signature, extensive fresh water growth zones with 87 sr/ 86 sr ratios similar to those of the skagit river at ~0.705, and marine-like 87 sr/ 86 sr ratios near their edges. otoliths from stream-type chinook from central idaho had prehatch 87 sr/ 86 sr ratios \u22650.711, indicating that a maternal marine sr isotopic signature is not preserved after the ~1000- to 1400-km migration from the pacific ocean. 87 sr/ 86 sr ratios in the outer portions of otoliths from these idaho juveniles were similar to those of their respective streams (~0.708\\x960.722). for skagit juveniles, fresh water growth was marked by small decreases in otolith sr/ca, with increases in sr/ca corresponding to increases in 87 sr/ 86 sr with migration into salt water. otoliths of idaho fish had sr/ca radial variation patterns that record seasonal fluctuation in ambient water sr/ca ratios. the ion microprobe's ability to measure both 87 sr/ 86 sr and sr/ca ratios of otoliths at high spatial resolution in situ provides a new tool for studies of fish rearing and migration. \"",
            "contribution_ids": [
                "R34058"
            ]
        },
        {
            "instance_id": "R34099xR34063",
            "comparison_id": "R34099",
            "paper_id": "R34063",
            "text": "Evidence of different habitat use by New Zealand freshwater eels Anguilla australis and A. dieffenbachii, as revealed by otolith microchemistry the apparent use of marine and freshwater habitats by anguilla australis and a. dieffenbachii was examined by analyzing the strontium (sr) and calcium (ca) concentrations in otoliths of silver eels collected from lake ellesmere, which is a shallow brackish-water coastal lagoon in new zealand. the age and growth of these eels was also examined using their otolith annuli. size and ages of females were greater than those of males for both species. growth rates were similar among sex and species, but the highest growth rates were observed in eels that experienced saline environments. line analyses of sr:ca ratios along a life-history transect in each otolith showed peaks (ca. 15 to 21 \u00d7 10 -3 in a. australis, 14 to 20 \u00d7 10 -3 in a. dieffenbachii) between the core and elver mark, which corresponded to the period of their leptocephalus and early glass eel stage in the ocean. out- side the elver mark, the sr:ca ratios indicated that eels had remained in different habitats that included freshwater (average sr:ca ratios, 1.8 to 2.4 \u00d7 10 -3 ), areas with relatively high salinities (aver- age sr:ca ratios, 3.0 to 7.4 \u00d7 10 -3 ), and in some cases individuals showed clear evidence of shifts in the salinity of their environments. these shifts either indicated movements between different loca- tions, or changes in the salinity of the lake. there were more individuals of a. australis that used areas with intermediate or high salinities, at least for a short time (85% of individuals), than a. dief- fenbachii (30%). these findings suggest that these 2 southern temperate species may have the same behavioral plasticity regarding whether or not to enter freshwater or remain in marine environments, as has been recently documented in several northern temperate anguillid species.",
            "contribution_ids": [
                "R34064",
                "R34065"
            ]
        },
        {
            "instance_id": "R34099xR34097",
            "comparison_id": "R34099",
            "paper_id": "R34097",
            "text": "Estimating contemporary early life-history dispersal in an estuarine fish: integrating molecular and otolith elemental approaches \"dispersal during the early life history of the anadromous rainbow smelt, osmerus mordax, was examined using assignment testing and mixture analysis of multilocus genotypes and otolith elemental composition. six spawning areas and associated estuarine nurseries were sampled throughout southeastern newfoundland. samples of adults and juveniles isolated by > 25 km displayed moderate genetic differentiation (fst ~ 0.05), whereas nearby ( 80% self\u2010assignment) with nearby runs self\u2010assigning at rates between 50 % and 70%. assignment and mixture analysis of juveniles using adult baselines indicated high local recruitment at several locations (70\u201390%). nearby (< 25 km) estuaries at the head of st mary's bay showed mixtures of individuals (i.e. 20\u201340% assignment to adjacent spawning location). laser ablation inductively coupled mass spectrometry transects across otoliths of spawning adults of unknown dispersal history were used to estimate dispersal among estuaries across the first year of life. single\u2010element trends and multivariate discriminant function analysis (sr:ca and ba:ca) classified the majority of samples as estuarine suggesting limited movement between estuaries (< 0.5%). the mixtures of juveniles evident in the genetic data at nearby sites and a lack of evidence of straying in the otolith data support a hypothesis of selective mortality of immigrants. if indeed selective mortality of immigrants reduces the survivorship of dispersers, estimates of dispersal in marine environments that neglect survival may significantly overestimate gene flow.\"",
            "contribution_ids": [
                "R34098"
            ]
        },
        {
            "instance_id": "R34126xR34102",
            "comparison_id": "R34126",
            "paper_id": "R34102",
            "text": "Optic neuritis: oligoclo- nal bands increase the risk of multiple sclerosis abstract\u2010 in 1974 we examined 30 patients 0.5\u201314 (mean 5) years after acute unilateral optic neuritis (on), when no clinical signs of multiple sclerosis (ms) were discernable. 11 of the patients had oligoclonal bands in the cerebrospinal fluid (csf). re\u2010examination after an additional 6 years revealed that 9 of the 11 on patients with oligoclonal bands (but only 1 of the 19 without this csf abnormality) had developed ms. the occurrence of oligoclonal bands in csf in a patient with on is \u2010 within the limits of the present observation time \u2010 accompanied by a significantly increased risk of the future development of ms. recurrent on also occurred significantly more often in those on patients who later developed ms.",
            "contribution_ids": [
                "R34103"
            ]
        },
        {
            "instance_id": "R34126xR34108",
            "comparison_id": "R34126",
            "paper_id": "R34108",
            "text": "Optic neuritis: Prognosis for multiple sclerosis from MRI, CSF, and HLA findings we investigated the paraclinical profile of monosymptomatic optic neuritis(on) and its prognosis for multiple sclerosis (ms). the correct identification of patients with very early ms carrying a high risk for conversion to clinically definite ms is important when new treatments are emerging that hopefully will prevent or at least delay future ms. we conducted a prospective single observer and population-based study of 147 consecutive patients (118 women, 80%) with acute monosymptomatic on referred from a catchment area of 1.6 million inhabitants between january 1, 1990 and december 31, 1995. of 116 patients examined with brain mri, 64 (55%) had three or more high signal lesions, 11 (9%) had one to two high signal lesions, and 41 (35%) had a normal brain mri. among 143 patients examined, oligoclonal igg (ob) bands in csf only were demonstrated in 103 patients (72%). of 146 patients analyzed, 68 (47%) carried the dr15,dq6,dw2 haplotype. during the study period, 53 patients (36%) developed clinically definite ms. the presence of three or more ms-like mri lesions as well as the presence of ob were strongly associated with the development of ms (p < 0.001). also, dw2 phenotype was related to the development of ms (p = 0.046). mri and csf studies in patients with on give clinically important information regarding the risk for future ms.",
            "contribution_ids": [
                "R34109"
            ]
        },
        {
            "instance_id": "R34126xR34124",
            "comparison_id": "R34126",
            "paper_id": "R34124",
            "text": "Can CSF predict the course of optic neuritis? to discuss the implications of csf abnormalities for the course of acute monosymptomatic optic neuritis (amon), various csf markers were analysed in patients being randomly selected from a population-based cohort. paired serum and csf were obtained within a few weeks from onset of amon. csf-restricted oligoclonal igg bands, free kappa and free lambda chain bands were observed in 17, 15, and nine of 27 examined patients, respectively. sixteen patients showed a polyspecific intrathecal synthesis of oligoclonal igg antibodies against one or more viruses. at 1 year follow-up five patients had developed clinically definite multiple sclerosis (cdms); all had csf oligoclonal igg bands and virus-specific oligoclonal igg antibodies at onset. due to the relative small number studied at the short-term follow-up, no firm conclusion of the prognostic value of these analyses could be reached. csf myelin basic protein-like material was increased in only two of 29 patients with amon, but may have potential value in reflecting disease activity, as the highest values were obtained among patients with csf sampled soon after the worst visual acuity was reached, and among patients with severe visual impairment. in most previous studies of patients with amon qualitative and quantitative analyses of csf igg had a predictive value for development of cdms, but the results are conflicting.",
            "contribution_ids": [
                "R34125"
            ]
        },
        {
            "instance_id": "R34183xR34136",
            "comparison_id": "R34183",
            "paper_id": "R34136",
            "text": "Case study in benefits and risks of agricultural biotechnology: Roundup Ready soybeans. abstract this case study describes the us regulatory process governing agricultural biotechnology and traces the approval of roundup ready soyabeans (with transgenic tolerance of the herbicide glyphosate), summarizing the information that was submitted to us regulatory agencies by monsanto. estimates of the impact that the adoption of roundup ready soyabeans has had on us agriculture are also provided. the us regulatory structure for agricultural biotechnology has evolved over the past 25 years, as technology allowing for genetic modification developed. the system continues to evolve as new and different applications of the technology emerge. in reviewing the studies that were conducted on the safety of roundup ready soyabeans, no indication of greater health or environmental risks were found compared with conventional varieties. the benefits of the introduction of roundup ready soyabeans include cost savings of us$216 million in annual weed control and 19 million fewer soyabean herbicide applications per year.",
            "contribution_ids": [
                "R34137",
                "R34150",
                "R34170"
            ]
        },
        {
            "instance_id": "R34183xR34163",
            "comparison_id": "R34183",
            "paper_id": "R34163",
            "text": "Genetically modified crops, corporate pricing strategies, and farmers' adoption: the case of Bt cotton in Argentina \"this article analyzes adoption and impacts of bt cotton in argentina against the background of monopoly pricing. based on survey data, it is shown that the technology significantly reduces insecticide applications and increases yields; however, these advantages are curbed by the high price charged for genetically modified seeds. using the contingent valuation method, it is shown that farmers' average willingness to pay is less than half the actual technology price. a lower price would not only increase benefits for growers, but could also multiply company profits, thus, resulting in a pareto improvement. implications of the sub-optimal pricing strategy are discussed.\"",
            "contribution_ids": [
                "R34164",
                "R34165"
            ]
        },
        {
            "instance_id": "R34183xR34179",
            "comparison_id": "R34183",
            "paper_id": "R34179",
            "text": "Potential Benefits of Agricultural Biotechnology: An Example from the Mexican Potato Sector the study analyzes ex ante the socioeconomic effects of transgenic virus resistance technology for potatoes in mexico. all groups of potato growers could significantly gain from the transgenic varieties to be introduced, and the technology could even improve income distribution. nonetheless, public support is needed to fully harness this potential. different policy alternatives are tested within scenario calculations in order to supply information on how to optimize the technological outcome, both from an efficiency and an equity perspective. transgenic disease resistance is a promising technology for developing countries. providing these countries with better access to biotechnology should be given higher political priority.",
            "contribution_ids": [
                "R34180"
            ]
        },
        {
            "instance_id": "R34183xR34140",
            "comparison_id": "R34183",
            "paper_id": "R34140",
            "text": "A critical assessment of methods for analysis of social welfare impacts of genetically modified crops: A literature survey this paper is a review of existing literature on economic and environmental costs and benefits of genetically modified (gm) crops focusing on methodological issues arising from this literature. particular attention is given to the production function framework commonly used to quantify costs and benefits of gm crops at the farm level and to equilibrium displacement models used to quantify impacts of gm crops on social welfare. methods are discussed with respect to their sensitivity to specific parameter values and key areas are identified for further research.",
            "contribution_ids": [
                "R34141",
                "R34142"
            ]
        },
        {
            "instance_id": "R34183xR34145",
            "comparison_id": "R34183",
            "paper_id": "R34145",
            "text": "The distribution of benefits from the introduction of transgenic cotton varieties a handful of vertically coordinated \u201clife science\u201d firms have been the key players in ushering in the biotechnology revolution in the united states. these firms have been successful in linking useful genetic events with high quality germplasm to create genetically modified varieties ( gmvs) with the ability to gain rapid market penetration and to capture value for the creators. these life science firms have fundamentally altered the structure of the seed industry, using mergers, acquisitions and licensing agreements to ally their financial, scientific, and organizational strengths with the genetic resources of traditional seed companies such as pioneer, delta and pineland, asgrow, dekalb and dozens of smaller seed companies. intellectual property right (ipr) laws have been used to provide incentives for inventors to invest in research since the founding of this country. ipr protection provides inventors with limited monopoly power, increasing their ability to appropriate the benefits created by their research effort. the firm producing the ipr-protected innovation is able to price their product above the marginal cost of producing the input, thereby appropriating profit that would otherwise be passed on to consumers through lower prices. major changes have also taken place in t he laws and enforcement of ipr for biological innovations so that protection is now similar to that afforded to discovery in other sectors, but it is really only the specifics of how ipr laws apply to biological innovations that have changed in recent years.",
            "contribution_ids": [
                "R34146"
            ]
        },
        {
            "instance_id": "R34251xR34190",
            "comparison_id": "R34251",
            "paper_id": "R34190",
            "text": "Monetary union in West Africa: who might gain, who might lose, and why? \"we develop a model in which governments' financing needs exceed the socially optimal level because public resources are diverted to serve the narrow interests of the group in power. from a social welfare perspective, this results in undue pressure on the central bank to extract seigniorage. monetary policy also suffers from an expansive bias, owing to the authorities' inability to precommit to price stability. such a conjecture about the fiscal-monetary policy mix appears quite relevant in africa, with deep implications for the incentives of fiscally heterogeneous countries to form a currency union. we calibrate the model to data for west africa and use it to assess proposed ecowas monetary unions. fiscal heterogeneity indeed appears critical in shaping regional currency blocs that would be mutually beneficial for all their members. in particular, nigeria's membership in the configurations currently envisaged would not be in the interests of other ecowas countries unless it were accompanied by effective containment on nigeria's financing needs.\"",
            "contribution_ids": [
                "R34191"
            ]
        },
        {
            "instance_id": "R34251xR34231",
            "comparison_id": "R34251",
            "paper_id": "R34231",
            "text": "West African Single Currency and Competitiveness this paper compares different nominal anchors to promote internal and external competitiveness in the case of a fixed exchange rate regime for the future single regional currency of the economic community of the west african states (ecowas). we use counterfactual analyses and estimate a model of dependent economy for small commodity exporting countries. we consider four foreign anchor currencies: the us dollar, the euro, the yen and the yuan. our simulations show little support for a dominant peg in the ecowas area if they pursue several goals: maximizing the export revenues, minimizing their variability, stabilizing them and minimizing the real exchange rate misalignments from the fundamental value.",
            "contribution_ids": [
                "R34232"
            ]
        },
        {
            "instance_id": "R34251xR34245",
            "comparison_id": "R34251",
            "paper_id": "R34245",
            "text": "Analysis of convergence criteria in a proposed monetary union: a study of the economic community of West African States this study examines the processes of the monetary union of the economic community of west african states (ecowas). it takes a critical look at the convergence criteria and the various conditions under which they are to be met. using the panel least square technique an estimate of the beta convergence was made for the period 2000-2008. the findings show that nearly all the explanatory variables have indirect effects on the income growth rate and that there tends to be convergence in income over time. the speed of adjustment estimated is 0.2% per year and the half-life is -346.92. thus the economies can make up for half of the distance that separates them from their stationary state. from the findings, it was concluded that a well integrated economy could further the achievement of steady growth in these countries in the long run.",
            "contribution_ids": [
                "R34246"
            ]
        },
        {
            "instance_id": "R34282xR34264",
            "comparison_id": "R34282",
            "paper_id": "R34264",
            "text": "A Fast-Track East African Community Monetary Union? Convergence Evidence from a Cointegration Analysis. there is a proposal for a fast-tracked approach to the african community (eac) monetary union. this paper uses cointegration techniques to determine whether the member countries would form a successful monetary union based on the long-run behavior of nominal and real exchange rates and monetary base. the three variables are each analyzed for co-movements among the five countries. the empirical results indicate only partial convergence for the variables considered, suggesting there could be substantial costs for the member countries from a fast-tracked process. this implies the eac countries need significant adjustments to align their monetary policies and to allow a period of monetary policy coordination to foster convergence that will improve the chances of a sustainable currency union.",
            "contribution_ids": [
                "R34265"
            ]
        },
        {
            "instance_id": "R34282xR34270",
            "comparison_id": "R34282",
            "paper_id": "R34270",
            "text": "Design and implementation of a common currency area in the East African community the east african community (eac) has fast-tracked its plans to create a single currency for the five countries making up the region, and hopes to conclude negotiations on a monetary union protocol by the end of 2012. while the benefits of lower transactions costs from a common currency may be significant, countries will also lose the ability to use monetary policy to respond to different shocks. evidence presented shows that the countries differ in a number of respects, facing asymmetric shocks and different production structures. countries have had difficulty meeting convergence criteria, most seriously as concerns fiscal deficits. preparation for monetary union will require effective institutions for macroeconomic surveillance and enforcing fiscal discipline, and euro zone experience indicates that these institutions will be difficult to design and take a considerable time to become effective. this suggests that a timetable for monetary union in the eac should allow for a substantial initial period of institution building. in order to have some visible evidence of the commitment to monetary union, in the meantime the eac may want to consider introducing a common basket currency in the form of notes and coin, to circulate in parallel with national currencies.",
            "contribution_ids": [
                "R34271"
            ]
        },
        {
            "instance_id": "R34316xR34299",
            "comparison_id": "R34316",
            "paper_id": "R34299",
            "text": "The Process of Monetary Integration in the SADC Region* the african union has agreed, in principle, to implement monetary union and a single currency in africa by 2021. this would be based upon the prior formation of regional monetary unions, including one in the sadc region. this article considers the economic prerequisites and implications for a monetary union and, in the light of this, whether a sadc monetary union is feasible. after reviewing the existing monetary union within sadc (the rand-based common monetary area) and current sadc macroeconomic convergence initiatives, the article examines the extent to which key economic and monetary variables \u2013 inflation, interest rates and exchange rates \u2013 are converging within sadc. it concludes that there is a core \u2018convergence\u2019 group comprising the cma countries \u2013 south africa, lesotho, namibia and swaziland \u2013 plus botswana, mauritius, mozambique and tanzania whose macroeconomic performance satisfies some of the criteria for monetary union. the remaining sadc countries \u2013 angola, drc, malawi, zambia and zimbabwe \u2013 make up a \u2018non-converging\u2019 group that cannot yet be considered potential candidates for monetary union. however, even within the convergence group, countries remain far from satisfying the other prerequisites for monetary union, including significant intra-regional trade, and full capital and labour mobility. there are also major political constraints, making the au monetary union proposals and timetable highly ambitious.",
            "contribution_ids": [
                "R34300"
            ]
        },
        {
            "instance_id": "R34316xR34308",
            "comparison_id": "R34316",
            "paper_id": "R34308",
            "text": "On the feasibility of a monetary union in the Southern Africa Development Community this paper investigates the feasibility of a monetary union in southern africa development community (sadc) by looking at evidence of nominal exchange rate and inflation convergence. using a methodology based on estimating time-varying parameters, the evidence suggests non-convergence. the non-convergence of nominal exchange rate and consumer price inflation suggests that presently the chances of sadc member countries satisfying some form of maastricht-type criteria is quite low. copyright \u00a9 2007 john wiley & sons, ltd.",
            "contribution_ids": [
                "R34309"
            ]
        },
        {
            "instance_id": "R34316xR34314",
            "comparison_id": "R34316",
            "paper_id": "R34314",
            "text": "Assessment of monetary union in SADC: evidence from cointegration and panel unit root tests in this paper we investigate the likelihood of a proposed monetary union in the southern african development community (sadc) being successful from the viewpoint of the generalised purchasing power parity (gppp) hypothesis and optimum currency area (oca) theory. we apply johansen\u2019s multivariate co-integration technique, panel unit root tests, pedroni\u2019s residual cointegration test and error correction based panel cointegration tests. the findings from this study confirm that gppp holds among sadc member countries included in this study on account of cointegration and stationarity in real exchange rate series. the south african rand normalised long run beta coefficients of all the real exchange rates are below one except in the case of the mauritian rupee and all bear negative signs except in the case of the angolan new kwanza and mauritian rupee. this evidence support monetary union in the region except for angola and mauritius. however, the absolute magnitudes of the short run adjustment coefficients of sadc countries\u2019 real exchange rates are low and bear positive signs in some cases. this finding implies that the observed slow speed of adjustment for the (log) real exchange rate of sadc member states might constrain the effectiveness of stabilization policies in the wake of external shocks, rendering sadc countries vulnerable to macroeconomic instability in the region. this result has important policy implications for the proposed monetary union in sadc.",
            "contribution_ids": [
                "R34315"
            ]
        },
        {
            "instance_id": "R34411xR34372",
            "comparison_id": "R34411",
            "paper_id": "R34372",
            "text": "Isolation of Clostridium difficile from human jejunum: identification of a reservoir for disease? the possibility that the small intestine may represent a reservoir for clostridium difficile was studied, using segments of human jejunum collected at necropsy. our results (three of 100 specimens positive for c difficile culture) support the hypothesis that c difficile can be found in human jejunum and that it adheres to the normal mucosa as a resident bacterium. these findings suggest that gastrointestinal disease caused by c difficile has an endogenous origin.",
            "contribution_ids": [
                "R34373"
            ]
        },
        {
            "instance_id": "R34411xR34384",
            "comparison_id": "R34411",
            "paper_id": "R34384",
            "text": "Fatal Clostridium difficile infection of the small bowel after complex colorectal surgery pseudomembranous colitis is a well recognized complication of antibiotic use1 and is due to disturbances of the normal colonic bacterial flora, resulting in overgrowth of clostridium difficile. for recurrent or severe cases, oral vancomycin or metronidazole is the treatment of choice. progression to acute fulminant colitis with systemic toxic effects occasionally occurs, especially in the elderly and in the immunosuppressed. some of these patients may need surgical intervention for complications such as perforation.2 clostridium difficile is commonly regarded as a colonic pathogen and there are few reports of c. difficile enteritis with involvement of the small bowel (table 1). pseudomembrane formation caused by c. difficile is generally restricted to the colon, with abrupt termination at the ileocaecal valve.1,3,5,8,9 we report a case of fulminant and fatal c. difficile infection with pseudomembranes throughout the entire small bowel and colon in a patient following complex colorectal surgery. the relevant literature is reviewed.",
            "contribution_ids": [
                "R34385"
            ]
        },
        {
            "instance_id": "R34411xR34400",
            "comparison_id": "R34411",
            "paper_id": "R34400",
            "text": "Fulminant Clostridium difficile enteritis after proctocolectomy and ileal pouch-anal anastamosis clostridium difficile ( c. difficile ) infection of the small bowel is very rare. the disease course is more severe than that of c. difficile colitis, and the mortality is high. we present a case of c. difficile enteritis in a patient with with ileal pouch-anal anastamosis (ipaa), and review previous case reports in order to better characterize this unusual condition.",
            "contribution_ids": [
                "R34401"
            ]
        },
        {
            "instance_id": "R34454xR34444",
            "comparison_id": "R34454",
            "paper_id": "R34444",
            "text": "Facial Expression Recognition from Line-Based Caricatures the automatic recognition of facial expression presents a significant challenge to the pattern analysis and man-machine interaction research community. recognition from a single static image is particularly a difficult task. in this paper, we present a methodology for facial expression recognition from a single static image using line-based caricatures. the recognition process is completely automatic. it also addresses the computational expensive problem and is thus suitable for real-time applications. the proposed approach uses structural and geometrical features of a user sketched expression model to match the line edge map (lem) descriptor of an input face image. a disparity measure that is robust to expression variations is defined. the effectiveness of the proposed technique has been evaluated and promising results are obtained. this work has proven the proposed idea that facial expressions can be characterized and recognized by caricatures.",
            "contribution_ids": [
                "R34445"
            ]
        },
        {
            "instance_id": "R34454xR34448",
            "comparison_id": "R34454",
            "paper_id": "R34448",
            "text": "Facial expression recognition and synthesis based on an appearance model facial expression interpretation, recognition and analysis is a key issue in visual communication and man to machine interaction. we address the issues of facial expression recognition and synthesis and compare the proposed bilinear factorization based representations with previously investigated methods such as linear discriminant analysis and linear regression. we conclude that bilinear factorization outperforms these techniques in terms of correct recognition rates and synthesis photorealism especially when the number of training samples is restrained.",
            "contribution_ids": [
                "R34449"
            ]
        },
        {
            "instance_id": "R34454xR34452",
            "comparison_id": "R34454",
            "paper_id": "R34452",
            "text": "Facial event classification with task oriented dynamic bayesian network facial events include all activities of face and facial features in spatial or temporal space, such as facial expressions, face gesture, gaze and furrow happening, etc. developing an automated system for facial event classification is always a challenging task due to the richness, ambiguity and dynamic nature of facial expressions. this paper presents an efficient approach to real-world facial event classification. by integrating dynamic bayesian network (dbn) with a general-purpose facial behavior description language, a task-oriented stochastic and temporal framework is constructed to systematically represent and classify facial events of interest. based on the task oriented dbn, we can spatially and temporally incorporate results from previous times and prior knowledge of the application domain. with the top-down inference, the system can make active selection among multiple visual channels to identify the most effective sensory channels to use. with the bottom-up inference from observed evidences, the current facial event can be classified with a desired confident level via the belief propagation. we applied the task-oriented dbn framework to monitoring driver vigilance. experimental results demonstrate the feasibility and efficiency of our approach.",
            "contribution_ids": [
                "R34453"
            ]
        },
        {
            "instance_id": "R34605xR34522",
            "comparison_id": "R34605",
            "paper_id": "R34522",
            "text": "Towards identity anonymization on graphs the proliferation of network data in various application domains has raised privacy concerns for the individuals involved. recent studies show that simply removing the identities of the nodes before publishing the graph/social network data does not guarantee privacy. the structure of the graph itself, and in its basic form the degree of the nodes, can be revealing the identities of individuals. to address this issue, we study a specific graph-anonymization problem. we call a graph k-degree anonymous if for every node v, there exist at least k-1 other nodes in the graph with the same degree as v. this definition of anonymity prevents the re-identification of individuals by adversaries with a priori knowledge of the degree of certain nodes. we formally define the graph-anonymization problem that, given a graph g, asks for the k-degree anonymous graph that stems from g with the minimum number of graph-modification operations. we devise simple and efficient algorithms for solving this problem. our algorithms are based on principles related to the realizability of degree sequences. we apply our methods to a large spectrum of synthetic and real datasets and demonstrate their efficiency and practical utility.",
            "contribution_ids": [
                "R34523"
            ]
        },
        {
            "instance_id": "R34605xR34533",
            "comparison_id": "R34605",
            "paper_id": "R34533",
            "text": "Comparisons of randomization and K-degree anonymization schemes for privacy preserving social network publishing many applications of social networks require identity and/or relationship anonymity due to the sensitive, stigmatizing, or confidential nature of user identities and their behaviors. recent work showed that the simple technique of anonymizing graphs by replacing the identifying information of the nodes with random ids does not guarantee privacy since the identification of the nodes can be seriously jeopardized by applying background based attacks. in this paper, we investigate how well an edge based graph randomization approach can protect node identities and sensitive links. we quantify both identity disclosure and link disclosure when adversaries have one specific type of background knowledge (i.e., knowing the degrees of target individuals). we also conduct empirical comparisons with the recently proposed k-degree anonymization schemes in terms of both utility and risks of privacy disclosures.",
            "contribution_ids": [
                "R34534",
                "R34583"
            ]
        },
        {
            "instance_id": "R34605xR34540",
            "comparison_id": "R34605",
            "paper_id": "R34540",
            "text": "On identity disclosure in weighted graphs as an integral part of data security, identity disclosureis a major privacy breach, which reveals the identification of entities with certain background knowledge known by an adversary. most recent studies on this problem focus on the protection of relational data or simple graph data (i.e. undirected, un weighted and acyclic). however, a weighted graph can introduce much more unique information than its simple version, which makes the disclosure easier. as more real-world graphs or social networks are released publicly, there is growing concern about privacy breaching for the entities involved. in this paper, we first formalize a general anonymizing model to deal with weight-related attacks, and discuss an efficient metric to quantify information loss incurred in the perturbation. then we consider a very practical attack based on the sum of adjacent weights for each vertex, which is known as volume in graph theory field. we also propose a complete solution for the weight anonymization problem to prevent a graph from volume attack. our approaches are efficient and practical, and have been validated by extensive experiments on both synthetic and real-world datasets.",
            "contribution_ids": [
                "R34541"
            ]
        },
        {
            "instance_id": "R34605xR34550",
            "comparison_id": "R34605",
            "paper_id": "R34550",
            "text": "k-automorphism the growing popularity of social networks has generated interesting data management and data mining problems. an important concern in the release of these data for study is their privacy, since social networks usually contain personal information. simply removing all identifiable personal information (such as names and social security number) before releasing the data is insufficient. it is easy for an attacker to identify the target by performing different structural queries. in this paper we propose k-automorphism to protect against multiple structural attacks and develop an algorithm (called km) that ensures k-automorphism. we also discuss an extension of km to handle \"dynamic\" releases of the data. extensive experiments show that the algorithm performs well in terms of protection it provides.",
            "contribution_ids": [
                "R34551"
            ]
        },
        {
            "instance_id": "R34605xR34567",
            "comparison_id": "R34605",
            "paper_id": "R34567",
            "text": "The link prediction problem for social networks given a snapshot of a social network, can we infer which new interactions among its members are likely to occur in the near future? we formalize this question as the link prediction problem, and develop approaches to link prediction based on measures the \"proximity\" of nodes in a network. experiments on large co-authorship networks suggest that information about future interactions can be extracted from network topology alone, and that fairly subtle measures for detecting node proximity can outperform more direct measures.",
            "contribution_ids": [
                "R34568"
            ]
        },
        {
            "instance_id": "R34605xR34584",
            "comparison_id": "R34605",
            "paper_id": "R34584",
            "text": "Supervised random walks: predicting and recommending links in social networks predicting the occurrence of links is a fundamental problem in networks. in the link prediction problem we are given a snapshot of a network and would like to infer which interactions among existing members are likely to occur in the near future or which existing interactions are we missing. although this problem has been extensively studied, the challenge of how to effectively combine the information from the network structure with rich node and edge attribute data remains largely open.\\n we develop an algorithm based on supervised random walks that naturally combines the information from the network structure with node and edge level attributes. we achieve this by using these attributes to guide a random walk on the graph. we formulate a supervised learning task where the goal is to learn a function that assigns strengths to edges in the network such that a random walker is more likely to visit the nodes to which new links will be created in the future. we develop an efficient training algorithm to directly learn the edge strength estimation function.\\n our experiments on the facebook social graph and large collaboration networks show that our approach outperforms state-of-the-art unsupervised approaches as well as approaches that are based on feature extraction.",
            "contribution_ids": [
                "R34585",
                "R34586"
            ]
        },
        {
            "instance_id": "R34663xR34622",
            "comparison_id": "R34663",
            "paper_id": "R34622",
            "text": "Optimizing Medical Data Quality Based on Multiagent Web Service Framework one of the most important issues in e-healthcare information systems is to optimize the medical data quality extracted from distributed and heterogeneous environments, which can extremely improve diagnostic and treatment decision making. this paper proposes a multiagent web service framework based on service-oriented architecture for the optimization of medical data quality in the e-healthcare information system. based on the design of the multiagent web service framework, an evolutionary algorithm (ea) for the dynamic optimization of the medical data quality is proposed. the framework consists of two main components; first, an ea will be used to dynamically optimize the composition of medical processes into optimal task sequence according to specific quality attributes. second, a multiagent framework will be proposed to discover, monitor, and report any inconstancy between the optimized task sequence and the actual medical records. to demonstrate the proposed framework, experimental results for a breast cancer case study are provided. furthermore, to show the unique performance of our algorithm, a comparison with other works in the literature review will be presented.",
            "contribution_ids": [
                "R34623"
            ]
        },
        {
            "instance_id": "R34706xR34666",
            "comparison_id": "R34706",
            "paper_id": "R34666",
            "text": "User-Priority guided min min scheduling algorithm for load balancing in cloud computing \"cloud computing is emerging as a new paradigm of large-scale distributed computing. in order to utilize the power of cloud computing completely, we need an efficient task scheduling algorithm. the traditional min-min algorithm is a simple, efficient algorithm that produces a better schedule that minimizes the total completion time of tasks than other algorithms in the literature [7]. however the biggest drawback of it is load imbalanced, which is one of the central issues for cloud providers. in this paper, an improved load balanced algorithm is introduced on the ground of min-min algorithm in order to reduce the makespan and increase the resource utilization (lbimm). at the same time, cloud providers offer computer resources to users on a pay-per-use base. in order to accommodate the demands of different users, they may offer different levels of quality for services. then the cost per resource unit depends on the services selected by the user. in return, the user receives guarantees regarding the provided resources. to observe the promised guarantees, user-priority was considered in our proposed pa-lbimm so that user's demand could be satisfied more completely. at last, the introduced algorithm is simulated using matlab toolbox. the simulation results show that the improved algorithm can lead to significant performance gain and achieve over 20% improvement on both vip user satisfaction and resource utilization ratio.\"",
            "contribution_ids": [
                "R34667"
            ]
        },
        {
            "instance_id": "R34706xR34670",
            "comparison_id": "R34706",
            "paper_id": "R34670",
            "text": "Load Balancing for Internet Distributed Services Using Limited Redirection Rates the internet has become the universal support for computer applications. this increases the need for solutions that provide dependability and qos for web applications. the replication of web servers on geographically distributed data centers allows the service provider to tolerate disastrous failures and to improve the response times perceived by clients. a key issue for good performance of worldwide distributed web services is the efficiency of the load balancing mechanism used to distribute client requests among the replicated servers. load balancing can reduce the need for over-provision of resources, and help tolerate abrupt load peaks and/or partial failures through load conditioning. in this paper, we propose a new load balancing solution that reduces service response times by redirecting requests to the closest remote servers without overloading them. we also describe a middle ware that implements this protocol and present the results of a set of simulations that show its usefulness.",
            "contribution_ids": [
                "R34671"
            ]
        },
        {
            "instance_id": "R34706xR34678",
            "comparison_id": "R34706",
            "paper_id": "R34678",
            "text": "A Lock-Free Solution for Load Balancing in Multi-Core Environment load balancing device is an important part of cloud platform. one of the most common applications of load balancing is to provide a single powerful virtual machine from multiple servers. in multi-core environment, the load balancing device can run multiple physically parallel load-balancing processes to increase overall performance. an important issue when operating a load-balanced service is how to send all requests in a user session consistently to the same backend server, i.e. session maintaining. most of multiprocessing load balancing solutions use shared memory and lock when manage session. by modifying linux kernel, we avoid using shared memory and implement a lock-free multiprocessing load balancing solution.",
            "contribution_ids": [
                "R34679"
            ]
        },
        {
            "instance_id": "R34845xR34761",
            "comparison_id": "R34845",
            "paper_id": "R34761",
            "text": "Effects of some egg characteristics on the mass loss and hatchability of ostrich (Struthio camelus) eggs 1. this study was conducted to examine some egg characteristics and determine the effects of eggshell thickness and eggshell porosity on water loss and hatchability of eggs in ostriches. 2. shell thickness did not correlate significantly with hatchability. however, eggs of low shell thickness lost more mass (13\u00b703%) than those with intermediate (11\u00b722%) and high (10\u00b736%) shell thickness. mass loss during incubation was higher in hatched (11\u00b798%) than unhatched eggs (11\u00b709%). shell thickness was negatively correlated to egg mass loss (r = \u22120\u00b765). 3. the pore density was correlated with hatchability. hatchability was 50% lower in eggs with low pore densities (40\u00b793%) than with high densities (80\u00b794%). pore density was positively correlated with egg mass loss (r = 0\u00b763). incubation mass losses of hatched and unhatched eggs were not significantly different. 4. mean eggshell water vapour conductance (g) value and shell conductance constant (k) were 87\u00b777 \u00b1 4\u00b721 mg h2o/d/torr and 2\u00b744 respectively (n = 15). 5. because of eggshell functional properties and resulting low egg mass loss hatchability is low when ostrich eggs are artificially incubated. the mass of eggs used in the experiment was relatively high and their eggshell water vapour conductance was low. as a result, egg incubation mass loss was lower than it should be. it is concluded that incubator humidity should be low (25%) to allow enough mass loss during incubation from the eggs.",
            "contribution_ids": [
                "R34762"
            ]
        },
        {
            "instance_id": "R34845xR34773",
            "comparison_id": "R34845",
            "paper_id": "R34773",
            "text": "The Effect of Embryonic Development on the Thickness of the Egg Shells of Coturnix Quail abstract the average thickness of the shells from 75 unincubated coturnix quail eggs was found to be 0.193 mm. this was 7.3 percent greater than the average thickness (0.179 mm.) of the shells from 60 fully incubated eggs from the same hens. the two sets of eggs were collected simultaneously. this thickness difference was statistically significant (t-test:p",
            "contribution_ids": [
                "R34774"
            ]
        },
        {
            "instance_id": "R34845xR34796",
            "comparison_id": "R34845",
            "paper_id": "R34796",
            "text": "Avian embryonic development does not change the stable isotope composition of the calcite eggshell the avian embryo resorbs most of the calcium for bone formation from the calcite eggshell but the exact mechanisms of the resorption are unknown. the present study tested whether this process results in variable fractionation of the oxygen and carbon isotopes in shell calcium carbonate, which could provide a detailed insight into the temporal and spatial use of the eggshell by the developing embryo. despite the uncertainty regarding changes in stable isotope composition of the eggshell across developmental stages or regions of the shell, eggshells are a popular resource for the analysis of historic and extant trophic relationships. to clarify how the stable isotope composition varies with embryonic development, the \u03b413c and \u03b418o content of the carbonate fraction in shells of black-headed gull (larus ridibundus) eggs were sampled at four different stages of embryonic development and at five eggshell regions. no consistent relationship between the stable isotope composition of the eggshell and embryonic development, shell region or maculation was observed, although shell thickness decreased with development in all shell regions. by contrast, individual eggs differed significantly in isotope composition. these results establish that eggshells can be used to investigate a species\u2019 carbon and oxygen sources, regardless of the egg\u2019s developmental stage.",
            "contribution_ids": [
                "R34797"
            ]
        },
        {
            "instance_id": "R34845xR34824",
            "comparison_id": "R34845",
            "paper_id": "R34824",
            "text": "California Condors and DDE: a re-evaluation \"eggshells of wild california condors gymnogyps californianus were much thinner in the 1960s, when ddt was used heavily, than during earlier pre-ddt and later reduced-ddt periods. however, eggshell thickness was more strongly linked to egg size (mass) than to measured levels of p,p\u2032dde (the primary metabolite of ddt). egg size was consistent within individual females and yielded correlation coefficients with shell thickness ranging from 0.49 to 0.97, depending on the period and the analysis assumptions used. measured dde levels, although often substantial, provided only a weak correlation (r\\xa0=\\xa0\u22120.33) with shell thickness. in part, the absence of a strong dde/thickness correlation may have been an artefact of losses of dde from fragment membranes over time. nevertheless, the extreme (28\u201329%) shell thinning of the 1960s was not linked with clearly increased egg-breakage or nest-failure rates, and one female of the 1980s with 25.6% shell thinning was the most productive female of her era. some eggs with over 30% shell thinning hatched successfully, and broken eggs closely resembled hatched eggs in shell thickness, strongly suggesting that shell thinning was not an important cause of breakage. the apparent absence of harmful effects from the extreme shell thinning of the 1960s may have resulted from (1) the fact that historic pre-ddt condor eggs were on average 16.7% thicker shelled for their mass than predicted by the overall egg mass/shell thickness curve for birds, and (2) a possible egg-size decline or sampling bias toward small-egged females in the 1960s. that dde was an important cause of the condor's decline appears unlikely from overall available data.\"",
            "contribution_ids": [
                "R34825"
            ]
        },
        {
            "instance_id": "R36153xR36106",
            "comparison_id": "R36153",
            "paper_id": "R36106",
            "text": "Characterizing the transmission and identifying the control strategy for COVID-19 through epidemiological modeling abstract the outbreak of the novel coronavirus disease, covid-19, originating from wuhan, china in early december, has infected more than 70,000 people in china and other countries and has caused more than 2,000 deaths. as the disease continues to spread, the biomedical society urgently began identifying effective approaches to prevent further outbreaks. through rigorous epidemiological analysis, we characterized the fast transmission of covid-19 with a basic reproductive number 5.6 and proved a sole zoonotic source to originate in wuhan. no changes in transmission have been noted across generations. by evaluating different control strategies through predictive modeling and monte carlo simulations, a comprehensive quarantine in hospitals and quarantine stations has been found to be the most effective approach. government action to immediately enforce this quarantine is highly recommended.",
            "contribution_ids": [
                "R36107"
            ]
        },
        {
            "instance_id": "R36153xR36149",
            "comparison_id": "R36153",
            "paper_id": "R36149",
            "text": "Analysis of the epidemic growth of the early 2019-nCoV outbreak using internationally confirmed cases abstract background on january 23, 2020, a quarantine was imposed on travel in and out of wuhan, where the 2019 novel coronavirus (2019-ncov) outbreak originated from. previous analyses estimated the basic epidemiological parameters using symptom onset dates of the confirmed cases in wuhan and outside china. methods we obtained information on the 46 coronavirus cases who traveled from wuhan before january 23 and have been subsequently confirmed in hong kong, japan, korea, macau, singapore, and taiwan as of february 5, 2020. most cases have detailed travel history and disease progress. compared to previous analyses, an important distinction is that we used this data to informatively simulate the infection time of each case using the symptom onset time, previously reported incubation interval, and travel history. we then fitted a simple exponential growth model with adjustment for the january 23 travel ban to the distribution of the simulated infection time. we used a bayesian analysis with diffuse priors to quantify the uncertainty of the estimated epidemiological parameters. we performed sensitivity analysis to different choices of incubation interval and the hyperparameters in the prior specification. results we found that our model provides good fit to the distribution of the infection time. assuming the travel rate to the selected countries and regions is constant over the study period, we found that the epidemic was doubling in size every 2.9 days (95% credible interval [cri], 2 days\u20144.1 days). using previously reported serial interval for 2019-ncov, the estimated basic reproduction number is 5.7 (95% cri, 3.4\u20149.2). the estimates did not change substantially if we assumed the travel rate doubled in the last 3 days before january 23, when we used previously reported incubation interval for severe acute respiratory syndrome (sars), or when we changed the hyperparameters in our prior specification. conclusions our estimated epidemiological parameters are higher than an earlier report using confirmed cases in wuhan. this indicates the 2019-ncov could have been spreading faster than previous estimates.",
            "contribution_ids": [
                "R36150"
            ]
        },
        {
            "instance_id": "R38484xR23443",
            "comparison_id": "R38484",
            "paper_id": "R23443",
            "text": "The Norwegian Earth System Model, NorESM1-M \u00e2\u0080\u0093 Part 1: Description and basic evaluation of the physical climate \" abstract. the core version of the norwegian climate center's earth system model, named noresm1-m, is presented. the noresm family of models are based on the community climate system model version 4 (ccsm4) of the university corporation for atmospheric research, but differs from the latter by, in particular, an isopycnic coordinate ocean model and advanced chemistry\u2013aerosol\u2013cloud\u2013radiation interaction schemes. noresm1-m has a horizontal resolution of approximately 2\u00b0 for the atmosphere and land components and 1\u00b0 for the ocean and ice components. noresm is also available in a lower resolution version (noresm1-l) and a version that includes prognostic biogeochemical cycling (noresm1-me). the latter two model configurations are not part of this paper. here, a first-order assessment of the model stability, the mean model state and the internal variability based on the model experiments made available to cmip5 are presented. further analysis of the model performance is provided in an accompanying paper (iversen et al., 2013), presenting the corresponding climate response and scenario projections made with noresm1-m.\\n \"",
            "contribution_ids": [
                "R23444"
            ]
        },
        {
            "instance_id": "R38484xR9221",
            "comparison_id": "R38484",
            "paper_id": "R9221",
            "text": "The ACCESS coupled model: description, control climate and evaluation 4oasis3.2\u20135 coupling framework. the primary goal of the access-cm development is to provide the australian climate community with a new generation fully coupled climate model for climate research, and to participate in phase five of the coupled model inter-comparison project (cmip5). this paper describes the access-cm framework and components, and presents the control climates from two versions of the access-cm, access1.0 and access1.3, together with some fields from the 20 th century historical experiments, as part of model evaluation. while sharing the same ocean sea-ice model (except different setups for a few parameters), access1.0 and access1.3 differ from each other in their atmospheric and land surface components: the former is configured with the uk met office hadgem2 (r1.1) atmospheric physics and the met office surface exchange scheme land surface model version 2, and the latter with atmospheric physics similar to the uk met office global atmosphere 1.0 includ ing modifications performed at cawcr and the csiro community atmosphere biosphere land exchange land surface model version 1.8. the global average annual mean surface air temperature across the 500-year preindustrial control integrations show a warming drift of 0.35 \u00b0c in access1.0 and 0.04 \u00b0c in access1.3. the overall skills of access-cm in simulating a set of key climatic fields both globally and over australia significantly surpass those from the preceding csiro mk3.5 model delivered to the previous coupled model inter-comparison. however, access-cm, like other cmip5 models, has deficiencies in various as pects, and these are also discussed.",
            "contribution_ids": [
                "R9222",
                "R9228"
            ]
        },
        {
            "instance_id": "R41148xR41128",
            "comparison_id": "R41148",
            "paper_id": "R41128",
            "text": "Verification and implications of the dissolution-electrodeposition process during the electro-reduction of solid silica in molten CaCl 2 with the verification of the existence of the dissolution-electrodeposition mechanism during the electro-reduction of solid silica in molten cacl2, the present study not only provides direct scientific support for the controllable electrolytic extraction of nanostructured silicon in molten salts but it also opens an avenue to a continuous silicon extraction process via the electro-deposition of dissolved silicates in molten cacl2. in addition, the present study increases the general understanding of the versatile material extraction route via the electro-deoxidization process of solid oxides in molten salts, which also provokes reconsiderations on the electrochemistry of insulating compounds.",
            "contribution_ids": [
                "R41129"
            ]
        },
        {
            "instance_id": "R41148xR41136",
            "comparison_id": "R41148",
            "paper_id": "R41136",
            "text": "Toward cost-effective manufacturing of silicon solar cells: electrodeposition of high-quality Si films in a CaCl 2 -based molten salt electrodeposition of si films from a si-containing electrolyte is a cost-effective approach for the manufacturing of solar cells. proposals relying on fluoride-based molten salts have suffered from low product quality due to difficulties in impurity control. here we demonstrate the successful electrodeposition of high-quality si films from a cacl2 -based molten salt. soluble siiv -o anions generated from solid sio2 are electrodeposited onto a graphite substrate to form a dense film of crystalline si. impurities in the deposited si film are controlled at low concentrations (both b and p are less than 1\\u2005ppm). in the photoelectrochemical measurements, the film shows p-type semiconductor character and large photocurrent. a p-n junction fabricated from the deposited si film exhibits clear photovoltaic effects. this study represents the first step to the ultimate goal of developing a cost-effective manufacturing process for si solar cells based on electrodeposition.",
            "contribution_ids": [
                "R41137"
            ]
        },
        {
            "instance_id": "R41148xR41138",
            "comparison_id": "R41148",
            "paper_id": "R41138",
            "text": "Electrodeposition of crystalline and photoactive silicon directly from silicon dioxide nanoparticles in molten CaCl 2 silicon is a widely used semiconductor for electronic and photovoltaic devices because of its earth-abundance, chemical stability, and the tunable electrical properties by doping. therefore, the production of pure silicon films by simple and inexpensive methods has been the subject of many investigations. the desire for lower-cost silicon-based solar photovoltaic devices has encouraged the quest for solar-grade silicon production through processes alternative to the currently used czochralski process or other processes. electrodeposition is one of the least expensive methods for fabricating films of metals and semiconductors. electrodeposition of silicon has been studied for over 30 years, in various solution media such as molten salts (lif-kf-k2sif6 at 745 8c and bao-sio2-baf2 at 1465 8c ), organic solvents (acetonitrile, tetrahydrofuran), and room-temperature ionic liquids. recently, the direct electrochemical reduction of bulk solid silicon dioxide in a cacl2 melt was reported. [7] a key factor for silicon electrodeposition is the purity of silicon deposit because si for the use in photovoltaic devices is solargrade silicon (> 99.9999% or 6n) and its grade is even higher in electronic devices (electronic-grade silicon or 11n). in most cases, the electrodeposited silicon does not meet these requirements without further purification and, to our knowledge, none have been shown to exhibit a photoresponse. in fact, silicon electrodeposition is not as straightforward as metal deposition, since the deposited semiconductor layer is resistive at room temperature, which complicates electron transfer through the deposit. in many cases, for example in room-temperature aprotic solvents, the deposited silicon acts as an insulating layer and prevents a continuous deposition reaction. in some cases, the silicon deposit contains a high level of impurities (> 2%). moreover, the nucleation and growth of silicon requires a large amount of energy. the deposition is made even more challenging if the si precursor is sio2, which is a very resistive material. we reported previously the electrochemical formation of silicon on molybdenum from a cacl2 molten salt (850 8c) containing a sio2 nanoparticle (np with a diameter of 5\u2013 15 nm) suspension by applying a constant reduction current. however this si film did not show photoactivity. here we show the electrodeposition of photoactive crystalline silicon directly from sio2 nps from cacl2 molten salt on a silver electrode that shows a clear photoresponse. to the best of our knowledge, this is a first report of the direct electrodeposition of photoactive silicon. the electrochemical reduction and the cyclic voltammetry (cv) of sio2 were investigated as described previously. [8] in this study, we found that the replacement of the mo substrate by silver leads to a dramatic change in the properties of the silicon deposit. the silver substrate exhibited essentially the same electrochemical and cv behavior as other metal substrates, that is, a high reduction current for sio2 at negative potentials of 1.0 v with the development of a new redox couple near 0.65 v vs. a graphite quasireference electrode (qre) (figure 1a). figure 1b shows a change in the reduction current as a function of the reduction potential, and the optical images of silver electrodes before and after the electrolysis, which displays a dark gray-colored deposit after the reduction. figure 2 shows sem images of silicon deposits grown potentiostatically ( 1.25 v vs. graphite qre) on silver. the amount of silicon deposit increased with the deposition time, and the deposit finally covered the whole silver surface (figure 2). high-magnification images show that the silicon deposit is not a film but rather platelets or clusters of silicon crystals of domain sizes in the range of tens of micrometers. the average height of the platelets was around 25 mm after a 10000 s deposition (figure 2b), and 45 mm after a 20000s deposition (figure 2c), respectively. the edges of the silicon crystals were clearly observed. contrary to other substrates, silver enhanced the crystallization of silicon produced from silicon dioxide reduction and it is known that silver induces the crystallization of amorphous silicon. energy-dispersive spectrometry (eds) elemental mapping (images shown in the bottom row of figure 2) revealed that small silver islands exist on the top of the silicon deposits, which we think is closely related to the growth mechanism of silicon on silver. the eds spectrum of the silicon deposit (figure 3a) suggested that the deposited silicon was quite pure and the amounts of other elements such as c, ca, and cl were below the detection limit (about 0.1 atom%). since the oxygen signal was probably from the native oxide formed on exposure of the deposit to air and silicon does not form an alloy with silver, the purity of silicon was estimated to be at least 99.9 atom%. the successful reduction of si(4+) in silicon dioxide to elemental silicon (si) was confirmed by xray photoelectron spectroscopy (xps) of the silicon deposit [*] dr. s. k. cho, dr. f.-r. f. fan, prof. a. j. bard center for electrochemistry, department of chemistry and biochemistry, the university of texas at austin austin, tx 78712 (usa) e-mail: ajbard@mail.utexas.edu",
            "contribution_ids": [
                "R41139"
            ]
        },
        {
            "instance_id": "R41466xR41016",
            "comparison_id": "R41466",
            "paper_id": "R41016",
            "text": "Unique epidemiological and clinical features of the emerging 2019 novel coronavirus pneumonia (COVID-19) implicate special control measures by 27 february 2020, the outbreak of coronavirus disease 2019 (covid\u201019) caused 82\\u2009623 confirmed cases and 2858 deaths globally, more than severe acute respiratory syndrome (sars) (8273 cases, 775 deaths) and middle east respiratory syndrome (mers) (1139 cases, 431 deaths) caused in 2003 and 2013, respectively. covid\u201019 has spread to 46 countries internationally. total fatality rate of covid\u201019 is estimated at 3.46% by far based on published data from the chinese center for disease control and prevention (china cdc). average incubation period of covid\u201019 is around 6.4 days, ranges from 0 to 24 days. the basic reproductive number (r0) of covid\u201019 ranges from 2 to 3.5 at the early phase regardless of different prediction models, which is higher than sars and mers. a study from china cdc showed majority of patients (80.9%) were considered asymptomatic or mild pneumonia but released large amounts of viruses at the early phase of infection, which posed enormous challenges for containing the spread of covid\u201019. nosocomial transmission was another severe problem. a total of 3019 health workers were infected by 12 february 2020, which accounted for 3.83% of total number of infections, and extremely burdened the health system, especially in wuhan. limited epidemiological and clinical data suggest that the disease spectrum of covid\u201019 may differ from sars or mers. we summarize latest literatures on genetic, epidemiological, and clinical features of covid\u201019 in comparison to sars and mers and emphasize special measures on diagnosis and potential interventions. this review will improve our understanding of the unique features of covid\u201019 and enhance our control measures in the future.",
            "contribution_ids": [
                "R41017",
                "R41019",
                "R41020",
                "R41022",
                "R41023",
                "R41025"
            ]
        },
        {
            "instance_id": "R44930xR44793",
            "comparison_id": "R44930",
            "paper_id": "R44793",
            "text": "Effects of voluntary event cancellation and school closure as countermeasures against COVID\u00e2\u0088\u009219 outbreak in Japan abstract background to control the covid-19 outbreak in japan, sports and entertainment events were canceled and schools were closed throughout japan from february 26 through march 19. that policy has been designated as voluntary event cancellation and school closure (vecsc). object this study assesses vecsc effectiveness based on predicted outcomes. method: a simple susceptible\u2013infected\u2013recovery model was applied to data of patients with symptoms in japan during january 14 through march 25. the respective reproduction numbers were estimated before vecsc (r), during vecsc (r e ), and after vecsc (r a ). results results suggest r before vecsc as 1.987 [1.908, 2.055], r e during vecsc as 1.122 [0.980, 1.260], and r a after vecsc as 3.086 [2.529, 3.739]. discussion and conclusion results demonstrated that vecsc can reduce covid-19 infectiousness considerably, but the value of r rose to exceed 2.5 after vecsc.",
            "contribution_ids": [
                "R44794"
            ]
        },
        {
            "instance_id": "R44930xR44812",
            "comparison_id": "R44930",
            "paper_id": "R44812",
            "text": "Pattern of early human-to-human transmission of Wuhan 2019-nCoV abstract on december 31, 2019, the world health organization was notified about a cluster of pneumonia of unknown aetiology in the city of wuhan, china. chinese authorities later identified a new coronavirus (2019-ncov) as the causative agent of the outbreak. as of january 23, 2020, 655 cases have been confirmed in china and several other countries. understanding the transmission characteristics and the potential for sustained human-to-human transmission of 2019-ncov is critically important for coordinating current screening and containment strategies, and determining whether the outbreak constitutes a public health emergency of international concern (pheic). we performed stochastic simulations of early outbreak trajectories that are consistent with the epidemiological findings to date. we found the basic reproduction number, r 0 , to be around 2.2 (90% high density interval 1.4\u20143.8), indicating the potential for sustained human-to-human transmission. transmission characteristics appear to be of a similar magnitude to severe acute respiratory syndrome-related coronavirus (sars-cov) and the 1918 pandemic influenza. these findings underline the importance of heightened screening, surveillance and control efforts, particularly at airports and other travel hubs, in order to prevent further international spread of 2019-ncov.",
            "contribution_ids": [
                "R44815"
            ]
        },
        {
            "instance_id": "R44930xR44825",
            "comparison_id": "R44930",
            "paper_id": "R44825",
            "text": "Preliminary estimation of the basic reproduction number of novel coronavirus (2019-nCoV) in China, from 2019 to 2020: A data-driven analysis in the early phase of the outbreak backgrounds an ongoing outbreak of a novel coronavirus (2019-ncov) pneumonia hit a major city of china, wuhan, december 2019 and subsequently reached other provinces/regions of china and countries. we present estimates of the basic reproduction number, r0, of 2019-ncov in the early phase of the outbreak. methods accounting for the impact of the variations in disease reporting rate, we modelled the epidemic curve of 2019-ncov cases time series, in mainland china from january 10 to january 24, 2020, through the exponential growth. with the estimated intrinsic growth rate (\u03b3), we estimated r0 by using the serial intervals (si) of two other well-known coronavirus diseases, mers and sars, as approximations for the true unknown si. findings the early outbreak data largely follows the exponential growth. we estimated that the mean r0 ranges from 2.24 (95%ci: 1.96-2.55) to 3.58 (95%ci: 2.89-4.39) associated with 8-fold to 2-fold increase in the reporting rate. we demonstrated that changes in reporting rate substantially affect estimates of r0. conclusion the mean estimate of r0 for the 2019-ncov ranges from 2.24 to 3.58, and significantly larger than 1. our findings indicate the potential of 2019-ncov to cause outbreaks.",
            "contribution_ids": [
                "R44828",
                "R44832"
            ]
        },
        {
            "instance_id": "R44930xR44842",
            "comparison_id": "R44930",
            "paper_id": "R44842",
            "text": "Early Transmissibility Assessment of a Novel Coronavirus in Wuhan, China between december 1, 2019 and january 26, 2020, nearly 3000 cases of respiratory illness caused by a novel coronavirus originating in wuhan, china have been reported. in this short analysis, we combine publicly available cumulative case data from the ongoing outbreak with phenomenological modeling methods to conduct an early transmissibility assessment. our model suggests that the basic reproduction number associated with the outbreak (at time of writing) may range from 2.0 to 3.1. though these estimates are preliminary and subject to change, they are consistent with previous findings regarding the transmissibility of the related sars-coronavirus and indicate the possibility of epidemic potential.",
            "contribution_ids": [
                "R44843"
            ]
        },
        {
            "instance_id": "R44930xR44856",
            "comparison_id": "R44930",
            "paper_id": "R44856",
            "text": "Time-varying transmission dynamics of Novel Coronavirus Pneumonia in China abstract rationale several studies have estimated basic production number of novel coronavirus pneumonia (ncp). however, the time-varying transmission dynamics of ncp during the outbreak remain unclear. objectives we aimed to estimate the basic and time-varying transmission dynamics of ncp across china, and compared them with sars. methods data on ncp cases by february 7, 2020 were collected from epidemiological investigations or official websites. data on severe acute respiratory syndrome (sars) cases in guangdong province, beijing and hong kong during 2002-2003 were also obtained. we estimated the doubling time, basic reproduction number ( r 0 ) and time-varying reproduction number ( r t ) of ncp and sars. measurements and main results as of february 7, 2020, 34,598 ncp cases were identified in china, and daily confirmed cases decreased after february 4. the doubling time of ncp nationwide was 2.4 days which was shorter than that of sars in guangdong (14.3 days), hong kong (5.7 days) and beijing (12.4 days). the r 0 of ncp cases nationwide and in wuhan were 4.5 and 4.4 respectively, which were higher than r 0 of sars in guangdong ( r 0 =2.3), hongkong ( r 0 =2.3), and beijing ( r 0 =2.6). the r t for ncp continuously decreased especially after january 16 nationwide and in wuhan. the r 0 for secondary ncp cases in guangdong was 0.6, and the r t values were less than 1 during the epidemic. conclusions ncp may have a higher transmissibility than sars, and the efforts of containing the outbreak are effective. however, the efforts are needed to persist in for reducing time-varying reproduction number below one. at a glance commentary scientific knowledge on the subject since december 29, 2019, pneumonia infection with 2019-ncov, now named as novel coronavirus pneumonia (ncp), occurred in wuhan, hubei province, china. the disease has rapidly spread from wuhan to other areas. as a novel virus, the time-varying transmission dynamics of ncp remain unclear, and it is also important to compare it with sars. what this study adds to the field we compared the transmission dynamics of ncp with sars, and found that ncp has a higher transmissibility than sars. time-varying production number indicates that rigorous control measures taken by governments are effective across china, and persistent efforts are needed to be taken for reducing instantaneous reproduction number below one.",
            "contribution_ids": [
                "R44857",
                "R44861"
            ]
        },
        {
            "instance_id": "R44930xR44918",
            "comparison_id": "R44930",
            "paper_id": "R44918",
            "text": "Estimation of the Transmission Risk of the 2019-nCoV and Its Implication for Public Health Interventions since the emergence of the first cases in wuhan, china, the novel coronavirus (2019-ncov) infection has been quickly spreading out to other provinces and neighboring countries. estimation of the basic reproduction number by means of mathematical modeling can be helpful for determining the potential and severity of an outbreak and providing critical information for identifying the type of disease interventions and intensity. a deterministic compartmental model was devised based on the clinical progression of the disease, epidemiological status of the individuals, and intervention measures. the estimations based on likelihood and model analysis show that the control reproduction number may be as high as 6.47 (95% ci 5.71\u20137.23). sensitivity analyses show that interventions, such as intensive contact tracing followed by quarantine and isolation, can effectively reduce the control reproduction number and transmission risk, with the effect of travel restriction adopted by wuhan on 2019-ncov infection in beijing being almost equivalent to increasing quarantine by a 100 thousand baseline value. it is essential to assess how the expensive, resource-intensive measures implemented by the chinese authorities can contribute to the prevention and control of the 2019-ncov infection, and how long they should be maintained. under the most restrictive measures, the outbreak is expected to peak within two weeks (since 23 january 2020) with a significant low peak value. with travel restriction (no imported exposed individuals to beijing), the number of infected individuals in seven days will decrease by 91.14% in beijing, compared with the scenario of no travel restriction.",
            "contribution_ids": [
                "R44921"
            ]
        },
        {
            "instance_id": "R44978xR44693",
            "comparison_id": "R44978",
            "paper_id": "R44693",
            "text": "A randomised controlled trial of cognitive behaviour therapy vs treatment as usual in the treatment of mild to moderate late life depression this study provides an empirical evaluation of cognitive behaviour therapy (cbt) alone vs treatment as usual (tau) alone (generally pharmacotherapy) for late life depression in a uk primary care setting.",
            "contribution_ids": [
                "R44694"
            ]
        },
        {
            "instance_id": "R44978xR44700",
            "comparison_id": "R44978",
            "paper_id": "R44700",
            "text": "Telephone-based treatment for family practice patients with mild depression the need for treating milder forms of depression has recently been of increased interest. this was a randomized, controlled study to evaluate the effects of telephone-based problem-solving therapy for mild depression. comparison groups were a treatment-as-usual group and another group receiving stress-management training by telephone. from 1,742 family practice patients screened for depression, 54 with mild depression entered the study. treatment was provided by experienced family practice nurses, trained and supervised in the treatments. the hamilton rating scale for depression was administered before and after the intervention period, and the beck depression inventory and duke health profile were administered at the end of the intervention period. of the 36 subjects assigned to the problem-solving and stress-management groups, half dropped out early in the study. five from the treatment-as-usual group were lost to follow-up. in the remaining subjects, there was a significant decrease in depression scores. there were no significant differences in the amount of decrease between the groups on any scores. the small sample and high dropout rate limit the interpretation of the findings. however, since all subjects tended to improve, regardless of treatment received, mild levels of depression may generally remit even without focal intervention, and watchful waiting may be a reasonable alternative for management.",
            "contribution_ids": [
                "R44701"
            ]
        },
        {
            "instance_id": "R44978xR44709",
            "comparison_id": "R44978",
            "paper_id": "R44709",
            "text": "Acute and one-year outcome of a randomised controlled trial of brief cognitive therapy for major depressive disorder in primary care background the consensus statement on the treatment of depression (paykel &amp; priest, 1992) advocates the use of cognitive therapy techniques as an adjunct to medication. method this paper describes a randomised controlled trial of brief cognitive therapy (bct) plus \u2018treatment as usual\u2019 versus treatment as usual in the management of 48 patients with major depressive disorder presenting in primary care. results at the end of the acute phase, significantly more subjects ( p &lt; 0.05) met recovery criteria in the intervention group ( n =15) compared with the control group ( n =8). when initial neuroticism scores were controlled for, reductions in beck depression inventory and hamilton rating scale for depression scores favoured the bct group throughout the 12 months of follow-up. conclusions bct may be beneficial, but given the time constraints, therapists need to be more rather than less skilled in cognitive therapy. this, plus methodological limitations, leads us to advise caution before applying this approach more widely in primary care.",
            "contribution_ids": [
                "R44710"
            ]
        },
        {
            "instance_id": "R46295xR45100",
            "comparison_id": "R46295",
            "paper_id": "R45100",
            "text": "Charge carrier trapping and recombination dynamics in small semiconductor particles reference lpi-article-1985-033doi:10.1021/ja00312a043view record in web of science record created on 2006-02-21, modified on 2017-05-12",
            "contribution_ids": [
                "R45101"
            ]
        },
        {
            "instance_id": "R46295xR45112",
            "comparison_id": "R46295",
            "paper_id": "R45112",
            "text": "Photochemical Reduction of Oxygen Adsorbed to Nanocrystalline TiO2 Films:\u00e2\u0080\u0089 A Transient Absorption and Oxygen Scavenging Study of Different TiO2 Preparations transient absorption spectroscopy (tas) has been used to study the interfacial electron-transfer reaction between photogenerated electrons in nanocrystalline titanium dioxide (tio(2)) films and molecular oxygen. tio(2) films from three different starting materials (tio(2) anatase colloidal paste and commercial anatase/rutile powders degussa tio(2) p25 and vp tio(2) p90) have been investigated in the presence of ethanol as a hole scavenger. separate investigations on the photocatalytic oxygen consumption by the films have also been performed with an oxygen membrane polarographic detector. results show that a correlation exists between the electron dynamics of oxygen consumption observed by tas and the rate of oxygen consumption through the photocatalytic process. the highest activity and the fastest oxygen reduction dynamics were observed with films fabricated from anatase tio(2) colloidal paste. the use of tas as a tool for the prediction of the photocatalytic activities of the materials is discussed. tas studies indicate that the rate of reduction of molecular oxygen is limited by interfacial electron-transfer kinetics rather than by the electron trapping/detrapping dynamics within the tio(2) particles.",
            "contribution_ids": [
                "R45113"
            ]
        },
        {
            "instance_id": "R46295xR45122",
            "comparison_id": "R46295",
            "paper_id": "R45122",
            "text": "Dynamics of photogenerated charges in the phosphate modified TiO 2 and the enhanced activity for photoelectrochemical water splitting phosphate modified nanocrystalline tio2 (nc-tio2) films were prepared by a doctor blade method, followed by post-treatment with monometallic sodium orthophosphate solution. the dynamic processes of the photogenerated charges from the resulting nc-tio2 films were thoroughly investigated by means of transient absorption spectroscopy (tas). it is shown that photogenerated holes in the un-modified tio2 film exhibit the same dynamic decay process as its photogenerated electrons, in oxygen-free water of ph 7. however, photogenerated holes in the phosphate modified film display a slightly faster dynamic decay process than its photogenerated electrons, and photogenerated charges of the modified film have a much longer lifetime than those of the un-modified film. these differences are attributed to the surface-carried negative charges of nc-tio2 resulting from the phosphate groups (\u2013ti\u2013o\u2013p\u2013o\u2212). interestingly, the photoelectrochemical (pec) experiments show that modification with an appropriate amount of phosphate could improve the photocurrent density of the nc-tio2 film electrode by about 2 times, at a voltage of 0 v in the neutral electrolyte. based on the tas and pec measurements of un-modified and phosphate modified nc-tio2 films, with different conditions, it is suggested that the prolonged lifetime of photogenerated charges can be attributed to the negative electrostatic field formed in the surface layers. it is also responsible for the increase in activity for pec water splitting and for the reported photocatalytic degradation of pollutants. the suggested mechanism would be applicable to other oxide semiconductor photocatalysts and to modification with other inorganic anions.",
            "contribution_ids": [
                "R45123"
            ]
        },
        {
            "instance_id": "R46295xR45124",
            "comparison_id": "R46295",
            "paper_id": "R45124",
            "text": "Photocatalytic Oxidation Reactivity of Holes in the Sulfur- and Carbon-Doped TiO2 Powders Studied by Time-Resolved Diffuse Reflectance Spectroscopy the photocatalytic oxidation reactivities of the photogenerated holes (h+) during ultraviolet or visible laser flash photolysis of pure anatase and sulfur- and carbon-doped tio2 powders were investigated using time-resolved diffuse reflectance (tdr) spectroscopy. the one-electron oxidation processes of substrates such as methanol and 4-(methylthio)phenyl methanol (mtpm) by h+ at the tio2 surface were examined. the tdr spectra and time traces observed for charge carriers and the mtpm radical cation (mtpm\u2022+) revealed that the oxidation reactions of substrates by h+ generated during the 355-nm laser photolysis of tio2 powders increased in the order of pure tio2 > s-doped tio2 > c-doped tio2. on the other hand, no one-electron oxidation reactions of the substrates were observed during the 430-nm laser photolysis of the s- and c-doped tio2 powders, although the charge carriers were sufficiently generated upon excitation. the effects of the trapping and detrapping processes of h+ at the doping sites on the oxid...",
            "contribution_ids": [
                "R45125"
            ]
        },
        {
            "instance_id": "R46296xR46068",
            "comparison_id": "R46296",
            "paper_id": "R46068",
            "text": "N-Doped TiO2 Nanoparticle Based Visible Light Photocatalyst by Modified Peroxide Sol\u00e2\u0088\u0092Gel Method the peroxide gel route is employed to synthesize n-doped tio2 nanoparticles (np) at low temperature using titanium tetraisopropoxide, ethylmethylamine, and hydrogen peroxide as precursors. structural studies show anatase phase in the undoped titania nps as well as at 5 at. % n-doped titania nps, although with a degree of matrix disorder in the latter case. the annealing of n-doped titania nps at different temperatures shows that above 400 \u00b0c nitrogen escapes the o\u2212ti\u2212o matrix and at 500 \u00b0c the sample becomes crystalline. transmission electron microscopy reveals that the particle size is in the range of 20\u221230 nm for the undoped tio2 but only 5\u221210 nm for n-doped tio2. at higher nitrogen concentration (10 at. %) bubble-like agglomerates form. ftir and photoluminescence quenching also confirm the incorporation of nitrogen in anatase tio2. optical properties reveal an extended tailing of the absorption edge toward the visible region upon nitrogen doping. x-ray photoelectron spectroscopy is used to examine the ...",
            "contribution_ids": [
                "R46069"
            ]
        },
        {
            "instance_id": "R46296xR46080",
            "comparison_id": "R46296",
            "paper_id": "R46080",
            "text": "One-step solvothermal synthesis of a carbon@ TiO2 dyade structure effectively promoting visible-light photocatalysis the development of sunlight harvesting chemical systems to catalyze relevant reactions, i.e., water splitting, co 2 fi xation, and organic mineralization, is the key target in artifi cial photosynthesis but remains a diffi cult challenge. titanium dioxide (tio 2 ) has been widely used as a photocatalyst for solar energy conversion and environmental applications because of its low toxicity, abundance, high photostability, and high effi ciency. [ 1\u20134 ] however, the application of pure tio 2 is limited, because it requires ultraviolet (uv) light, which makes up only a small fraction ( < 4%) of the total solar spectrum reaching the surface of the earth. therefore, over the past few years, considerable efforts have been directed towards the improvement of the photocatalytic effi ciency of tio 2 in the visible (vis)-light region. [ 5\u20137 ] this has been mainly achieved by introducing various dopants into the tio 2 structure which can narrow the bandgap. the initial approach to dope tio 2 materials was achieved using transition metals ions such as v, cr, or fe. [ 6 , 8\u201310 ] however, such metal doped materials lack the necessary thermal stability, exhibit atom diffusion and a remarkably increased electron/hole recombination of defect sites, which results in a low photocatalytic effi ciency. [ 11 ] non-metal doping has since proved to be far more successful and has been extensively investigated. thus, numerous reports on tio 2 doped with b, f, n, c, s, or i have demonstrated a signifi cant improvement of the visible-light photocatalytic effi ciency. [ 4 , 12\u201316 ]",
            "contribution_ids": [
                "R46081"
            ]
        },
        {
            "instance_id": "R46296xR46084",
            "comparison_id": "R46296",
            "paper_id": "R46084",
            "text": "Electrical Properties of Nb\u00e2\u0080\u0090, Ga\u00e2\u0080\u0090, and Y\u00e2\u0080\u0090Substituted Nanocrystalline Anatase TiO2 Prepared by Hydrothermal Synthesis \"nanocrystalline anatase titanium dioxide powders were produced by a hydrothermal synthesis route in pure form and substituted with trivalent ga3+ and y3+ or pentavalent nb5+ with the intention of creating acceptor or donor states, respectively. the electrical conductivity of each powder was measured using the powder-solution-composite (psc) method. the conductivity increased with the addition of nb5+ from 3 similar to x similar to 10-3 similar to s/cm to 10 similar to x similar to 10-3 similar to s/cm in as-prepared powders, and from 0.3 similar to x similar to 10-3 similar to s/cm to 0.9 similar to x similar to 10-3 similar to s/cm in heat-treated powders (520 degrees c, 1 similar to h). in contrast, substitution with ga3+ and y3+ had no measureable effect on the material's conductivity. the lack of change with the addition of ga3+ and y3+, and relatively small increase upon nb5+ addition is attributed to ionic compensation owing to the highly oxidizing nature of hydrothermal synthesis.\"",
            "contribution_ids": [
                "R46086"
            ]
        },
        {
            "instance_id": "R46296xR46087",
            "comparison_id": "R46296",
            "paper_id": "R46087",
            "text": "Preparation, Photocatalytic Activity, and Mechanism of Nano-TiO2 Co-Doped with Nitrogen and Iron (III) nanoparticles of titanium dioxide co-doped with nitrogen and iron (iii) were first prepared using the homogeneous precipitation-hydrothermal method. the structure and properties of the co-doped were studied by xrd, xps, raman, fl, and uv-diffuse reflectance spectra. by analyzing the structures and photocatalytic activities of the undoped and nitrogen and/or fe3+-doped tio2 under ultraviolet and visible light irradiation, the probable mechanism of co-doped particles was investigated. it is presumed that the nitrogen and fe3+ ion doping induced the formation of new states closed to the valence band and conduction band, respectively. the co-operation of the nitrogen and fe3+ ion leads to the much narrowing of the band gap and greatly improves the photocatalytic activity in the visible light region. meanwhile, the co-doping can also promote the separation of the photogenerated electrons and holes to accelerate the transmission of photocurrent carrier. the photocatalyst co-doped with nitrogen and 0.5% fe3+ sho...",
            "contribution_ids": [
                "R46088"
            ]
        },
        {
            "instance_id": "R46296xR46105",
            "comparison_id": "R46296",
            "paper_id": "R46105",
            "text": "Improved photocatalytic activity of Sn 4+ doped TiO 2 nanoparticulate films prepared by plasma-enhanced chemical vapor deposition sn4+ ion doped tio2 \\n (tio2\u2013sn4+) nanoparticulate films with a doping ratio of about 7\u2236100 [(sn)\u2236(ti)] were prepared by the plasma-enhanced chemical vapor deposition (pcvd) method. the doping mode (lattice ti substituted by sn4+ ions) and the doping energy level of sn4+ were determined by x-ray diffraction (xrd), x-ray photoelectron spectroscopy (xps), surface photovoltage spectroscopy (sps) and electric field induced surface photovoltage spectroscopy (efisps). it is found that the introduction of a doping energy level of sn4+ ions is profitable to the separation of photogenerated carriers under both uv and visible light excitation. characterization of the films with xrd and sps indicates that after doping by sn, more surface defects are present on the surface. consequently, the photocatalytic activity for photodegradation of phenol in the presence of the tio2\u2013sn4+ film is higher than that of the pure tio2 film under both uv and visible light irradiation.",
            "contribution_ids": [
                "R46106"
            ]
        },
        {
            "instance_id": "R46299xR46221",
            "comparison_id": "R46299",
            "paper_id": "R46221",
            "text": "CO2 reduction over NaNbO3 and NaTaO3 perovskite photocatalysts both nanbo 3 and natao 3 exhibit interesting intrinsic photocatalytic activities for co 2 reduction in terms of conversion and selectivity.",
            "contribution_ids": [
                "R46222"
            ]
        },
        {
            "instance_id": "R46299xR46235",
            "comparison_id": "R46299",
            "paper_id": "R46235",
            "text": "Photocatalytic CO2 Reduction by Re(I) Polypyridyl Complexes Immobilized on Niobates Nanoscrolls \"immobilization of re(i) co2 reduction photocatalysts on metal oxide surfaces is an interesting approach to improve their stability and recyclability. in this work, we describe the photocatalytic activity of two re(i) complexes (fac-[re(nn)(co)3(cl)], nn = 4,4'-dicarboxylic acid-2,2'-bipyridine, 1, or 5,6-dione-1,10-phenantroline, 2) on the surface of hexaniobate nanoscrolls. after adsorption, the turnover number for co production (tonco) in dmf/teoa of 1 was increased from 9 to 58, which is 20% higher than that observed on tio2, being among the highest reported values for a re(i)-based photocatalyst under visible light irradiation without any sensitizer. the complex 2 is inactive in solution under visible-light irradiation, but it has a tonco of 35 when immobilized on hexaniobate nanoscrolls. transient absorption spectroscopy studies reveal that the slow back-electron transfer and the higher reducing power of the hexaniobate conduction-band electrons play a major role for the photocatalytic process. the r...\"",
            "contribution_ids": [
                "R46236"
            ]
        },
        {
            "instance_id": "R48103xR46670",
            "comparison_id": "R48103",
            "paper_id": "R46670",
            "text": "A Two-Phase Bio-NER System Based on Integrated Classifiers and Multiagent Strategy biomedical named entity recognition (bio-ner) is a fundamental step in biomedical text mining. this paper presents a two-phase bio-ner model targeting at jnlpba task. our two-phase method divides the task into two subtasks: named entity detection (ned) and named entity classification (nec). the ned subtask is accomplished based on the two-layer stacking method in the first phase, where named entities (nes) are distinguished from nonnamed-entities (nnes) in biomedical literatures without identifying their types. then six classifiers are constructed by four toolkits (crf++, yamcha, maximum entropy, mallet) with different training methods and integrated based on the two-layer stacking method. in the second phase for the nec subtask, the multiagent strategy is introduced to determine the correct entity type for entities identified in the first phase. the experiment results show that the presented approach can achieve an f-score of 76.06 percent, which outperforms most of the state-of-the-art systems.",
            "contribution_ids": [
                "R46671"
            ]
        },
        {
            "instance_id": "R48392xR48233",
            "comparison_id": "R48392",
            "paper_id": "R48233",
            "text": "A scaling approach to project regional sea level rise and its uncertainties abstract. climate change causes global mean sea level to rise due to thermal expansion of seawater and loss of land ice from mountain glaciers, ice caps and ice sheets. locally, sea level can strongly deviate from the global mean rise due to changes in wind and ocean currents. in addition, gravitational adjustments redistribute seawater away from shrinking ice masses. however, the land ice contribution to sea level rise (slr) remains very challenging to model, and comprehensive regional sea level projections, which include appropriate gravitational adjustments, are still a nascent field (katsman et al., 2011; slangen et al., 2011). here, we present an alternative approach to derive regional sea level changes for a range of emission and land ice melt scenarios, combining probabilistic forecasts of a simple climate model (magicc6) with the new cmip5 general circulation models. the contribution from ice sheets varies considerably depending on the assumptions for the ice sheet projections, and thus represents sizeable uncertainties for future sea level rise. however, several consistent and robust patterns emerge from our analysis: at low latitudes, especially in the indian ocean and western pacific, sea level will likely rise more than the global mean (mostly by 10\u201320%). around the northeastern atlantic and the northeastern pacific coasts, sea level will rise less than the global average or, in some rare cases, even fall. in the northwestern atlantic, along the american coast, a strong dynamic sea level rise is counteracted by gravitational depression due to greenland ice melt; whether sea level will be above- or below-average will depend on the relative contribution of these two factors. our regional sea level projections and the diagnosed uncertainties provide an improved basis for coastal impact analysis and infrastructure planning for adaptation to climate change.\\n",
            "contribution_ids": [
                "R48236",
                "R48239",
                "R48242",
                "R48244"
            ]
        },
        {
            "instance_id": "R48392xR48265",
            "comparison_id": "R48392",
            "paper_id": "R48265",
            "text": "Probabilistic 21st and 22nd century sea-level projections at a global network of tide-gauge sites. sea\u2010level rise due to both climate change and non\u2010climatic factors threatens coastal settlements, infrastructure, and ecosystems. projections of mean global sea\u2010level (gsl) rise provide insufficient information to plan adaptive responses; local decisions require local projections that accommodate different risk tolerances and time frames and that can be linked to storm surge projections. here we present a global set of local sea\u2010level (lsl) projections to inform decisions on timescales ranging from the coming decades through the 22nd century. we provide complete probability distributions, informed by a combination of expert community assessment, expert elicitation, and process modeling. between the years 2000 and 2100, we project a very likely (90% probability) gsl rise of 0.5\u20131.2\\u2009m under representative concentration pathway (rcp) 8.5, 0.4\u20130.9\\u2009m under rcp 4.5, and 0.3\u20130.8\\u2009m under rcp 2.6. site\u2010to\u2010site differences in lsl projections are due to varying non\u2010climatic background uplift or subsidence, oceanographic effects, and spatially variable responses of the geoid and the lithosphere to shrinking land ice. the antarctic ice sheet (ais) constitutes a growing share of variance in gsl and lsl projections. in the global average and at many locations, it is the dominant source of variance in late 21st century projections, though at some sites oceanographic processes contribute the largest share throughout the century. lsl rise dramatically reshapes flood risk, greatly increasing the expected number of \u201c1\u2010in\u201010\u201d and \u201c1\u2010in\u2010100\u201d year events.",
            "contribution_ids": [
                "R48267",
                "R48269",
                "R48271",
                "R48273",
                "R48275",
                "R48277"
            ]
        },
        {
            "instance_id": "R52143xR52079",
            "comparison_id": "R52143",
            "paper_id": "R52079",
            "text": "Patterns of trait convergence and divergence among native and exotic species in herbaceous plant communities are not modified by nitrogen enrichment 1.\\u2002community assembly theories predict that the success of invading species into a new community should be predictable by functional traits. environmental filters could constrain the number of successful ecological strategies in a habitat, resulting in similar suites of traits between native and successfully invading species (convergence). conversely, concepts of limiting similarity and competitive exclusion predict native species will prevent invasion by functionally similar exotic species, resulting in trait divergence between the two species pools. nutrient availability may further alter the strength of convergent or divergent forces in community assembly, by relaxing environmental constraints and/or influencing competitive interactions.",
            "contribution_ids": [
                "R52080"
            ]
        },
        {
            "instance_id": "R52143xR52090",
            "comparison_id": "R52143",
            "paper_id": "R52090",
            "text": "Variation in resource acquisition and utilization traits between native and invasive perennial forbs understanding the functional traits that allow invasives to outperform natives is a necessary first step in improving our ability to predict and manage the spread of invaders. in nutrient-limited systems, plant competitive ability is expected to be closely tied to the ability of a plant to exploit nutrient-rich microsites and use these captured nutrients efficiently. the broad objective of this work was to compare the ability of native and invasive perennial forbs to acquire and use nutrients from nutrient-rich microsites. we evaluated morphological and physiological responses among four native and four invasive species exposed to heterogeneous (patch) or homogeneous (control) nutrient distribution. invasives, on average, allocated more biomass to roots and allocated proportionately more root length to nutrient-rich microsites than did natives. invasives also had higher leaf n, photosynthetic rates, and photosynthetic nitrogen use efficiency than natives, regardless of treatment. while these results suggest multiple traits may contribute to the success of invasive forbs in low-nutrient environments, we also observed large variation in these traits among native forbs. these observations support the idea that functional trait variation in the plant community may be a better predictor of invasion resistance than the functional group composition of the plant community.",
            "contribution_ids": [
                "R52091"
            ]
        },
        {
            "instance_id": "R52143xR52102",
            "comparison_id": "R52143",
            "paper_id": "R52102",
            "text": "Functional differences between alien and native species: do biotic interactions determine the functional structure of highly invaded grasslands? summary 1. although observed functional differences between alien and native plant species support the idea that invasions are favoured by niche differentiation (nd), when considering invasions along large ecological gradients, habitat filtering (hf) has been proposed to constrain alien species such that they exhibit similar trait values to natives. 2. to reconcile these contrasting observations, we used a multiscale approach using plant functional traits to evaluate how biotic interactions with native species and grazing might determine the functional structure of highly invaded grasslands along an elevation gradient in new zealand. 3. at a regional scale, functional differences between alien and native plant species translated into nonrandom community assembly and high nd. alien and native species showed contrasting responses to elevation and the degree of nd between them decreased as elevation increased, suggesting a role for hf. at the plant-neighbourhood scale, species with contrasting traits were generally spatially segregated, highlighting the impact of biotic interactions in structuring local plant communities. a confirmatory multilevel path analysis showed that the effect of elevation and grazing was moderated by the presence of native species, which in turn influenced the local abundance of alien species. 4. our study showed that functional differences between aliens and natives are fundamental to understand the interplay between multiple mechanisms driving alien species success and their coexistence with natives. in particular, the success of alien species is driven by the presence of native species which can have a negative (biotic resistance) or a positive (facilitation) effect depending on the functional identity of alien species.",
            "contribution_ids": [
                "R52103"
            ]
        },
        {
            "instance_id": "R52143xR52109",
            "comparison_id": "R52143",
            "paper_id": "R52109",
            "text": "Establishment and Management of Native Functional Groups in Restoration the limiting similarity hypothesis predicts that communities should be more resistant to invasion by non\u2010natives when they include natives with a diversity of traits from more than one functional group. in restoration, planting natives with a diversity of traits may result in competition between natives of different functional groups and may influence the efficacy of different seeding and maintenance methods, potentially impacting native establishment. we compare initial establishment and first\u2010year performance of natives and the effectiveness of maintenance techniques in uniform versus mixed functional group plantings. we seeded ruderal herbaceous natives, longer\u2010lived shrubby natives, or a mixture of the two functional groups using drill\u2010 and hand\u2010seeding methods. non\u2010natives were left undisturbed, removed by hand\u2010weeding and mowing, or treated with herbicide to test maintenance methods in a factorial design. native functional groups had highest establishment, growth, and reproduction when planted alone, and hand\u2010seeding resulted in more natives as well as more of the most common invasive, brassica nigra. wick herbicide removed more non\u2010natives and resulted in greater reproduction of natives, while hand\u2010weeding and mowing increased native density. our results point to the importance of considering competition among native functional groups as well as between natives and invasives in restoration. interactions among functional groups, seeding methods, and maintenance techniques indicate restoration will be easier to implement when natives with different traits are planted separately.",
            "contribution_ids": [
                "R52110",
                "R52111"
            ]
        },
        {
            "instance_id": "R52143xR52116",
            "comparison_id": "R52143",
            "paper_id": "R52116",
            "text": "Are competitive effects of native species on an invader mediated by water availability? question \\n \\nclimate change processes could influence the dynamics of biotic interactions such as plant competition, especially in response to disturbance phenomena such as invasional processes. are competitive effects of native species on an invader mediated by water availability? \\n \\n \\n \\nlocation \\n \\nglasshouse facility, new south wales, australia. \\n \\n \\n \\nmethods \\n \\nwe constructed competitive hierarchies for a representative suite of species from coastal dune communities that have been invaded by the asteraceae shrub, bitou (chrysanthemoides monilifera subsp. rotundata). we used a comparative phytometer approach, where the invader species was grown with or without a suite of native species in glasshouse trials. this was used to construct competition hierarchies under two water stress conditions: non-droughted and droughted. the treatments were designed to simulate current and potential future water availability respectively. \\n \\n \\n \\nresults \\n \\nwe found that the invader experienced fewer competitive effects from some native species under water stress, particularly with regard to below-ground biomass effects. native species were often poor competitors with the invader, despite their adaptation to periodic water stress in native coastal environments. of the native species with significant competitive effects on the invader, functionally similar shrub species were the most effective competitors, as expressed in below-ground biomass. the relative position of species in the hierarchy was consistent across water treatments based on below-ground bitou biomass, but was contingent on water treatment when based on above-ground bitou biomass. \\n \\n \\n \\nconclusions \\n \\nthe competitive effects of native species on an invader are affected by water stress. while the direction of response to water stress is species-specific, many species have small competitive effects on the invader under droughted conditions. this could allow an increase in invader dominance with climate change.",
            "contribution_ids": [
                "R52117"
            ]
        },
        {
            "instance_id": "R52143xR52131",
            "comparison_id": "R52143",
            "paper_id": "R52131",
            "text": "Experimental invasion by legumes reveals non-random assembly rules in grassland communities 1 although experimental studies usually reveal that resistance to invasion increases with species diversity, observational studies sometimes show the opposite trend. the higher resistance of diverse plots to invasion may be partly due to the increased probability of a plot containing a species with similar resource requirements to the invader. 2 we conducted a study of the invasibility of monocultures belonging to three different functional groups by seven sown species of legume. by only using experimentally established monocultures, rather than manipulating the abundance of particular functional groups, we removed both species diversity and differences in underlying abiotic conditions as potentially confounding variables. 3 we found that legume monocultures were more resistant than monocultures of grasses or non\u2010leguminous forbs to invasion by sown legumes but not to invasion by other unsown species. the functional group effect remained after controlling for differences in total biomass and the average height of the above\u2010ground biomass. 4 the relative success of legume species and types also varied with monoculture characteristics. the proportional biomass of climbing legumes increased strongly with biomass height in non\u2010leguminous forb monocultures, while it declined with biomass height in grass monocultures. trifolium pratense was the most successful invader in grass monocultures, while vicia cracca was the most successful in non\u2010leguminous forb monocultures. 5 our results suggest that non\u2010random assembly rules operate in grassland communities both between and within functional groups. legume invaders found it much more difficult to invade legume plots, while grass and non\u2010leguminous forb plots favoured non\u2010climbing and climbing legumes, respectively. if plots mimic monospecific patches, the effect of these assembly rules in diverse communities might depend upon the patch structure of diverse communities. this dependency on patch structure may contribute to differences in results of research from experimental vs. natural communities.",
            "contribution_ids": [
                "R52132"
            ]
        },
        {
            "instance_id": "R52143xR52140",
            "comparison_id": "R52143",
            "paper_id": "R52140",
            "text": "Functionally Similar Species Confer Greater Resistance to Invasion: Implications for Grassland Restoration plant community functional composition can be manipulated in restored ecosystems to reduce the establishment potential of invading species. this study was designed to compare invasion resistance among communities with species functionally similar or dissimilar to yellow starthistle (centaurea solstitialis), a late\u2010season annual. a field experiment was conducted in the central valley of california with six experimental plant communities that included (1) six early\u2010season native annual forbs (af); (2) five late\u2010season native perennials and one summer annual forb (np); (3) a combination of three early\u2010season native annual forbs and three late\u2010season native perennials (fp); (4) six early\u2010season non\u2010native annual grasses (ag); (5) monoculture of the late\u2010season native perennial grass elymus glaucus (eg); and (6) monoculture of the late\u2010season native perennial grindelia camporum (gc). following establishment, c. solstitialis seed was added to half of the plots, and a monoculture of c. solstitialis (cs) was established as a control. over a 5\u2010year period, the af and ag communities were ineffective at preventing c. solstitialis invasion. centaurea solstitialis cover remained less than 10% in the fp and np communities, except in year 1. by the fourth year, e. glaucus cover was greater than 50% in np and fp communities and had spread to all other communities (e.g., 27% cover in cs in year 5). communities containing e. glaucus, which is functionally similar to c. solstitialis, better resisted invasion than communities lacking a functional analog. in contrast, g. camporum, which is also functionally similar to c. solstitialis, failed to survive. consequently, species selection for restored communities must consider not only functional similarity to the invader but also establishment success, competitiveness, and survivorship.",
            "contribution_ids": [
                "R52141"
            ]
        },
        {
            "instance_id": "R53407xR53258",
            "comparison_id": "R53407",
            "paper_id": "R53258",
            "text": "Patterns of phylogenetic diversity are linked to invasion impacts- not invasion resistance- in a native grassland question: there are often more invasive species in communities that are less phylogenetically diverse or distantly related to the invaders. this is thought to indicate reduced biotic resistance, but recent theory predicts that phylogenetic relationships have more influence on competitive outcomes when interactions are more pair-wise than diffuse. therefore, phylogenetic relationships should change when the invader becomes dominant and interactions are more pairwise, rather than alter biotic resistance, which is the outcome of diffuse interactions with the resident community; however both processes can produce similar phylogenetic structures within communities. we ask whether phylogenetic structure is more associated with biotic resistance or invasion impacts following bromus inermis (brome) invasion and identify the mechanisms behind changes to phylogenetic structure. location: native grassland in alberta, canada. methods: we tested whether phylogenetic structure affected biotic resistance by transplanting brome seedlings into intact vegetation and quantified invasion impacts on community structure by surveying across multiple invasion edges. additionally, we tested whether relatedness, rarity, average patch size, evolutionary distinctiveness or environmental tolerances determined species\u2019 response to brome invasion. results: neither phylogenetic diversity, nor relatedness to brome, influenced the strength of biotic resistance; resource availability was the strongest determinant of resistance. however, communities did become less diverse and phylogenetically over-dispersed following brome invasion, but not because of the loss of related species. brome invasion was associated with declines in common species from common lineages and increases in shade-tolerant species and rare species from species-poor lineages. conclusions: ourresults suggest that invasion is morelikelytoaffectthe phylogenetic structure of the community than the phylogenetic structure of the community will affect invasion. however, they also suggest that the degree of relatedness between the invader and the resident community is unlikely todrive these effects on phylogenetic community structure. consistent with previous studies, invasion effects were stronger for common species as they have reduced shade tolerance and cannot persist in a subordinate role. this suggests that invasion effects on phylogenetic community structure will depend on which species exhibit traits that enable persistence with the invader and how these traits are distributed across the phylogeny.",
            "contribution_ids": [
                "R53259"
            ]
        },
        {
            "instance_id": "R53407xR53261",
            "comparison_id": "R53407",
            "paper_id": "R53261",
            "text": "A phylogenetic approach towards understanding the drivers of plant invasiveness on Robben Island- South Africa \"invasive plant species are a considerable threat to ecosystems globally and on islands in particular where species diversity can be relatively low. in this study, we examined the phylogenetic basis of invasion success on robben island in south africa. the flora of the island was sampled extensively and the phylogeny of the local community was reconstructed using the two core dna barcode regions, rbcla and matk. by analysing the phylogenetic patterns of native and invasive floras at two different scales, we found that invasive alien species are more distantly related to native species, a confirmation of darwin's naturalization hypothesis. however, this pattern also holds even for randomly generated communities, therefore discounting the explanatory power of darwin's naturalization hypothesis as the unique driver of invasion success on the island. these findings suggest that the drivers of invasion success on the island may be linked to species traits rather than their evolutionary history alone, or to the combination thereof. this result also has implications for the invasion management programmes currently being implemented to rehabilitate the native diversity on robben island.\\xa0\u00a9 2013 the linnean society of london, botanical journal of the linnean society, 2013, 172, 142\u2013152.\"",
            "contribution_ids": [
                "R53262",
                "R53264"
            ]
        },
        {
            "instance_id": "R53407xR53322",
            "comparison_id": "R53407",
            "paper_id": "R53322",
            "text": "Is invasiveness a legacy of evolution? Phylogenetic patterns in the alien flora of Mediterranean islands 1 the mediterranean region has been invaded by a wide range of introduced plant species which differ greatly in their ecology, morphology and human utilization. in order to identify a suite of traits which characterize invasiveness, recent studies have advocated the use of evolutionary relationships to unravel highly confounded influences. 2 this study attempts to identify an evolutionary component to invasiveness and other complex invasion\u2010related traits in the mediterranean alien flora using an autocorrelation technique, the \u2018phylogenetic association test\u2019. i compared a traditional hierarchical taxonomy with the recent phylogeny of the angiosperm phylogeny group. 3 invasiveness did not have a significant phylogenetic component. any weak clustering was generally at the genus level. 4 several associated \u2018meta\u2010traits\u2019 (high introduction frequency, adaptation to several habitat types and favourability for different modes of introduction), exhibited stronger phylogenetic components. although each of these conveys some of the attributes of invasiveness, their clustering patterns differed considerably, suggesting that they arise from independent evolutionary pressures. furthermore, within each meta\u2010trait, different clusters may have been selected for different reasons. 5 other reasons for the lack of a detectable evolutionary component to invasiveness are discussed. firstly, the results of our test simulations suggested that incorrect phylogeny could result in a moderate degree of error. secondly, over evolutionary time, complex or stochastic events such as ecosystem change could radically alter the adaptive advantages of particular traits. 6 synthesis. since invasiveness has little phylogenetic component, i argue that it is less likely to be predictable from as yet unidentified traits in any simple way. although trait syndromes could develop without leaving a phylogenetic pattern, its absence probably indicates that the dominant selective forces are responses to short\u2010term ecological shifts, and a greater mechanistic understanding of these is needed.",
            "contribution_ids": [
                "R53323"
            ]
        },
        {
            "instance_id": "R53407xR53325",
            "comparison_id": "R53407",
            "paper_id": "R53325",
            "text": "How strongly do interactions with closely-related native species influence plant invasions? Darwin's naturalization hypothesis assessed on Mediterranean islands aim\\u2002 recent works have found the presence of native congeners to have a small effect on the naturalization rates of introduced plants, some suggesting a negative interaction (as proposed by charles darwin in the origin of species), and others a positive association. we assessed this question for a new biogeographic region, and discuss some of the problems associated with data base analyses of this type.",
            "contribution_ids": [
                "R53326"
            ]
        },
        {
            "instance_id": "R53407xR53340",
            "comparison_id": "R53407",
            "paper_id": "R53340",
            "text": "Patterns of bird invasion are consistent with environmental filtering predicting invasion potential has global significance for managing ecosystems as well as important theoretical implications for understanding community assembly. phylogenetic relationships of introduced species to the extant community may be predictive of establishment success because of the opposing forces of competition/shared enemies (which should limit invasions by close relatives) versus environmental filtering (which should allow invasions by close relatives). we examine here the association between establishment success of introduced birds and their phylogenetic relatedness to the extant avifauna within three highly invaded regions (florida, new zealand, and hawaii). published information on both successful and failed introductions, as well as native species, was compiled for all three regions. we created a phylogeny for each avifauna including all native and introduced bird species. from the estimated branch lengths on these phylogenies, we calculated multiple measurements of relatedness between each introduced species and the extant avifauna. we used generalized linear models to test for an association between relatedness and establishment success. we found that close relatedness to the extant avifauna was significantly associated with increased establishment success for exotic birds both at the regional (florida, hawaii, new zealand) and sub-regional (islands within hawaii) levels. our results suggest that habitat filtering may be more important than interspecific competition in avian communities assembled under high rates of anthropogenic species introductions. this work also supports the utility of community phylogenetic methods in the study of vertebrate invasions.",
            "contribution_ids": [
                "R53341",
                "R53343"
            ]
        },
        {
            "instance_id": "R53407xR53366",
            "comparison_id": "R53407",
            "paper_id": "R53366",
            "text": "Distinctiveness magnifies the impact of biological invaders in aquatic ecosystems there exist few empirical rules for the effects of introduced species, reflecting the context-dependent nature of biological invasions. a promising approach toward developing generalizations is to explore hypotheses that incorporate characteristics of both the invader and the recipient system. we present the first general test of the hypothesis that an invader\u2019s impact is determined by the system\u2019s evolutionary experience with similar species. through a meta-analysis, we compared the taxonomic distinctiveness of high- and low-impact invaders in several aquatic systems. we find that high-impact invaders (i.e. those that displace native species) are more likely to belong to genera not already present in the system.",
            "contribution_ids": [
                "R53367"
            ]
        },
        {
            "instance_id": "R53407xR53382",
            "comparison_id": "R53407",
            "paper_id": "R53382",
            "text": "Exotic taxa less related to native species are more invasive some species introduced into new geographical areas from their native ranges wreak ecological and economic havoc in their new environment. although many studies have searched for either species or habitat characteristics that predict invasiveness of exotic species, the match between characteristics of the invader and those of members of the existing native community may be essential to understanding invasiveness. here, we find that one metric, the phylogenetic relatedness of an invader to the native community, provides a predictive tool for invasiveness. using a phylogenetic supertree of all grass species in california, we show that highly invasive grass species are, on average, significantly less related to native grasses than are introduced but noninvasive grasses. the match between the invader and the existing native community may explain why exotic pest species are not uniformly noxious in all novel habitats. relatedness of invaders to the native biota may be one useful criterion for prioritizing management efforts of exotic species.",
            "contribution_ids": [
                "R53383",
                "R53385"
            ]
        },
        {
            "instance_id": "R53407xR53393",
            "comparison_id": "R53407",
            "paper_id": "R53393",
            "text": "Establishment success of introduced amphibians increases in the presence of congeneric species darwin\u2019s naturalization hypothesis predicts that the success of alien invaders will decrease with increasing taxonomic similarity to the native community. alternatively, shared traits between aliens and the native assemblage may preadapt aliens to their novel surroundings, thereby facilitating establishment (the preadaptation hypothesis). here we examine successful and failed introductions of amphibian species across the globe and find that the probability of successful establishment is higher when congeneric species are present at introduction locations and increases with increasing congener species richness. after accounting for positive effects of congeners, residence time, and propagule pressure, we also find that invader establishment success is higher on islands than on mainland areas and is higher in areas with abiotic conditions similar to the native range. these findings represent the first example in which the preadaptation hypothesis is supported in organisms other than plants and suggest that preadaptation has played a critical role in enabling introduced species to succeed in novel environments.",
            "contribution_ids": [
                "R53394"
            ]
        },
        {
            "instance_id": "R54244xR54028",
            "comparison_id": "R54244",
            "paper_id": "R54028",
            "text": "Jack-of-all-trades: phenotypic plasticity facilitates the invasion of an alien slug species \\n invasive alien species might benefit from phenotypic plasticity by being able to (i) maintain fitness in stressful environments (\u2018robust\u2019), (ii) increase fitness in favourable environments (\u2018opportunistic\u2019), or (iii) combine both abilities (\u2018robust and opportunistic\u2019). here, we applied this framework, for the first time, to an animal, the invasive slug,\\n arion lusitanicus \\n , and tested (i) whether it has a more adaptive phenotypic plasticity compared with a congeneric native slug,\\n arion fuscus \\n , and (ii) whether it is robust, opportunistic or both. during one year, we exposed specimens of both species to a range of temperatures along an altitudinal gradient (700\u20132400 m a.s.l.) and to high and low food levels, and we compared the responsiveness of two fitness traits: survival and egg production\\n . \\n during summer, the invasive species had a more adaptive phenotypic plasticity, and at high temperatures and low food levels, it survived better and produced more eggs than\\n a. fuscus \\n , representing the robust phenotype. during winter,\\n a. lusitanicus \\n displayed a less adaptive phenotype than\\n a. fuscus \\n . we show that the framework developed for plants is also very useful for a better mechanistic understanding of animal invasions. warmer summers and milder winters might lead to an expansion of this invasive species to higher altitudes and enhance its spread in the lowlands, supporting the concern that global climate change will increase biological invasions.\\n",
            "contribution_ids": [
                "R54029"
            ]
        },
        {
            "instance_id": "R54244xR54034",
            "comparison_id": "R54244",
            "paper_id": "R54034",
            "text": "Norway maple displays greater seasonal growth and phenotypic plasticity to light than native sugar maple norway maple (acer platanoides l), which is among the most invasive tree species in forests of eastern north america, is associated with reduced regeneration of the related native species, sugar maple (acer saccharum marsh) and other native flora. to identify traits conferring an advantage to norway maple, we grew both species through an entire growing season under simulated light regimes mimicking a closed forest understorey vs. a canopy disturbance (gap). dynamic shade-houses providing a succession of high-intensity direct-light events between longer periods of low, diffuse light were used to simulate the light regimes. we assessed seedling height growth three times in the season, as well as stem diameter, maximum photosynthetic capacity, biomass allocation above- and below-ground, seasonal phenology and phenotypic plasticity. given the north european provenance of norway maple, we also investigated the possibility that its growth in north america might be increased by delayed fall senescence. we found that norway maple had significantly greater photosynthetic capacity in both light regimes and grew larger in stem diameter than sugar maple. the differences in below- and above-ground biomass, stem diameter, height and maximum photosynthesis were especially important in the simulated gap where norway maple continued extension growth during the late fall. in the gap regime sugar maple had a significantly higher root : shoot ratio that could confer an advantage in the deepest shade of closed understorey and under water stress or browsing pressure. norway maple is especially invasive following canopy disturbance where the opposite (low root : shoot ratio) could confer a competitive advantage. considering the effects of global change in extending the potential growing season, we anticipate that the invasiveness of norway maple will increase in the future.",
            "contribution_ids": [
                "R54035"
            ]
        },
        {
            "instance_id": "R54244xR54048",
            "comparison_id": "R54244",
            "paper_id": "R54048",
            "text": "The relative importance for plant invasiveness of trait means, and their plasticity and integration in a multivariate framework functional traits, their plasticity and their integration in a phenotype have profound impacts on plant performance. we developed structural equation models (sems) to evaluate their relative contribution to promote invasiveness in plants along resource gradients. we compared 20 invasive-native phylogenetically and ecologically related pairs. sems included one morphological (root-to-shoot ratio (r/s)) and one physiological (photosynthesis nitrogen-use efficiency (pnue)) trait, their plasticities in response to nutrient and light variation, and phenotypic integration among 31 traits. additionally, these components were related to two fitness estimators, biomass and survival. the relative contributions of traits, plasticity and integration were similar in invasive and native species. trait means were more important than plasticity and integration for fitness. invasive species showed higher fitness than natives because: they had lower r/s and higher pnue values across gradients; their higher pnue plasticity positively influenced biomass and thus survival; and they offset more the cases where plasticity and integration had a negative direct effect on fitness. our results suggest that invasiveness is promoted by higher values in the fitness hierarchy--trait means are more important than trait plasticity, and plasticity is similar to integration--rather than by a specific combination of the three components of the functional strategy.",
            "contribution_ids": [
                "R54049"
            ]
        },
        {
            "instance_id": "R54244xR54052",
            "comparison_id": "R54244",
            "paper_id": "R54052",
            "text": "Light Response of Native and Introduced Miscanthus sinensis Seedlings \"the asian grass miscanthus sinensis (poaceae) is being considered for use as a bioenergy crop in the u.s. corn belt. originally introduced to the united states for ornamental plantings, it escaped, forming invasive populations. the concern is that naturalized m. sinensis populations have evolved shade tolerance. we tested the hypothesis that seedlings from within the invasive u.s. range of m. sinensis would display traits associated with shade tolerance, namely increased area for light capture and phenotypic plasticity, compared with seedlings from the native japanese populations. in a common garden experiment, seedlings of 80 half-sib maternal lines were grown from the native range (japan) and 60 half-sib maternal lines from the invasive range (u.s.) under four light levels. seedling leaf area, leaf size, growth, and biomass allocation were measured on the resulting seedlings after 12 wk. seedlings from both regions responded strongly to the light gradient. high light conditions resulted in seedlings with greater leaf area, larger leaves, and a shift to greater belowground biomass investment, compared with shaded seedlings. japanese seedlings produced more biomass and total leaf area than u.s. seedlings across all light levels. generally, u.s. and japanese seedlings allocated a similar amount of biomass to foliage and equal leaf area per leaf mass. subtle differences in light response by region were observed for total leaf area, mass, growth, and leaf size. u.s. seedlings had slightly higher plasticity for total mass and leaf area but lower plasticity for measures of biomass allocation and leaf traits compared with japanese seedlings. our results do not provide general support for the hypothesis of increased m. sinensis shade tolerance within its introduced u.s. range compared with native japanese populations. nomenclature: eulaliagrass; miscanthus sinensis anderss. management implications: eulaliagrass (miscanthus sinensis), an asian species under consideration for biomass production in the midwest, has escaped ornamental plantings in the united states to form naturalized populations. evidence suggests that u.s. populations are able to tolerate relatively shady conditions, but it is unclear whether u.s. populations have greater shade tolerance than the relatively shade-intolerant populations within the species' native range in asia. increased shade tolerance could result in a broader range of invaded light environments within the introduced range of m. sinensis. however, results from our common garden experiment do not support the hypothesis of increased shade tolerance in introduced u.s. populations compared with seedlings from native asian populations. our results do demonstrate that for both u.s. and japanese populations under low light conditions, m. sinensis seeds germinate and seedlings gain mass and leaf area; therefore, land managers should carefully monitor or eradicate m. sinensis within these habitats.\"",
            "contribution_ids": [
                "R54053"
            ]
        },
        {
            "instance_id": "R54244xR54064",
            "comparison_id": "R54244",
            "paper_id": "R54064",
            "text": "Plastic Traits of an Exotic Grass Contribute to Its Abundance but Are Not Always Favourable \"in herbaceous ecosystems worldwide, biodiversity has been negatively impacted by changed grazing regimes and nutrient enrichment. altered disturbance regimes are thought to favour invasive species that have a high phenotypic plasticity, although most studies measure plasticity under controlled conditions in the greenhouse and then assume plasticity is an advantage in the field. here, we compare trait plasticity between three co-occurring, c4 perennial grass species, an invader eragrostis curvula, and natives eragrostis sororia and aristida personata to grazing and fertilizer in a three-year field trial. we measured abundances and several leaf traits known to correlate with strategies used by plants to fix carbon and acquire resources, i.e. specific leaf area (sla), leaf dry matter content (ldmc), leaf nutrient concentrations (n, c\u2236n, p), assimilation rates (amax) and photosynthetic nitrogen use efficiency (pnue). in the control treatment (grazed only), trait values for sla, leaf c\u2236n ratios, amax and pnue differed significantly between the three grass species. when trait values were compared across treatments, e. curvula showed higher trait plasticity than the native grasses, and this correlated with an increase in abundance across all but the grazed/fertilized treatment. the native grasses showed little trait plasticity in response to the treatments. aristida personata decreased significantly in the treatments where e. curvula increased, and e. sororia abundance increased possibly due to increased rainfall and not in response to treatments or invader abundance. overall, we found that plasticity did not favour an increase in abundance of e. curvula under the grazed/fertilized treatment likely because leaf nutrient contents increased and subsequently its' palatability to consumers. e. curvula also displayed a higher resource use efficiency than the native grasses. these findings suggest resource conditions and disturbance regimes can be manipulated to disadvantage the success of even plastic exotic species.\"",
            "contribution_ids": [
                "R54065"
            ]
        },
        {
            "instance_id": "R54244xR54072",
            "comparison_id": "R54244",
            "paper_id": "R54072",
            "text": "Phenotypic Plasticity Influences the Size, Shape and Dynamics of the Geographic Distribution of an Invasive Plant phenotypic plasticity has long been suspected to allow invasive species to expand their geographic range across large-scale environmental gradients. we tested this possibility in australia using a continental scale survey of the invasive tree parkinsonia aculeata (fabaceae) in twenty-three sites distributed across four climate regions and three habitat types. using tree-level responses, we detected a trade-off between seed mass and seed number across the moisture gradient. individual trees plastically and reversibly produced many small seeds at dry sites or years, and few big seeds at wet sites and years. bigger seeds were positively correlated with higher seed and seedling survival rates. the trade-off, the relation between seed mass, seed and seedling survival, and other fitness components of the plant life-cycle were integrated within a matrix population model. the model confirms that the plastic response resulted in average fitness benefits across the life-cycle. plasticity resulted in average fitness being positively maintained at the wet and dry range margins where extinction risks would otherwise have been high (\u201cjack-of-all-trades\u201d strategy jt), and fitness being maximized at the species range centre where extinction risks were already low (\u201cmaster-of-some\u201d strategy ms). the resulting hybrid \u201cjack-and-master\u201d strategy (jm) broadened the geographic range and amplified average fitness in the range centre. our study provides the first empirical evidence for a jm species. it also confirms mechanistically the importance of phenotypic plasticity in determining the size, the shape and the dynamic of a species distribution. the jm allows rapid and reversible phenotypic responses to new or changing moisture conditions at different scales, providing the species with definite advantages over genetic adaptation when invading diverse and variable environments. furthermore, natural selection pressure acting on phenotypic plasticity is predicted to result in maintenance of the jt and strengthening of the ms, further enhancing the species invasiveness in its range centre.",
            "contribution_ids": [
                "R54073"
            ]
        },
        {
            "instance_id": "R54244xR54082",
            "comparison_id": "R54244",
            "paper_id": "R54082",
            "text": "Geographically distinct Ceratophyllum demersum populations differ in growth, photosynthetic responses and phenotypic plasticity to nitrogen availability \\n\\ntwo geographically distinct populations of the submerged aquatic macrophyte ceratophyllum demersum l. were compared after acclimation to five different nitrogen concentrations (0.005, 0.02, 0.05, 0.1 and 0.2\\u2009mm n) in a common garden setup. the two populations were an apparent invasive population from new zealand (nz) and a noninvasive population from denmark (dk). the populations were compared with a focus on both morphological and physiological traits. the nz population had higher relative growth rates (rgrs) and photosynthesis rates (pmax) (range: rgr, 0.06\u20130.08 per day; pmax, 200\u2013395\\u2009\u00b5mol\\u2009o2\\u2009g\u20131 dry mass (dm) h\u20131) compared with the danish population (range: rgr, 0.02\u20130.05 per day; pmax, 88\u2013169\\u2009\u00b5mol o2 g\u20131 dm h\u20131). the larger, faster-growing nz population also showed higher plasticity than the dk population in response to nitrogen in traits important for growth. hence, the observed differences in growth behaviour between the two populations are a result of genetic differences and differences in their level of plasticity. here, we show that two populations of the same species from similar climates but different geographical areas can differ in several ecophysiological traits after growth in a common garden setup.\\n",
            "contribution_ids": [
                "R54083"
            ]
        },
        {
            "instance_id": "R54244xR54094",
            "comparison_id": "R54244",
            "paper_id": "R54094",
            "text": "Multispecies comparison reveals that invasive and native plants differ in their traits but not in their plasticity summary 1. plastic responses to spatiotemporal environmental variation strongly influence species distribution, with widespread species expected to have high phenotypic plasticity. theoretically, high phenotypic plasticity has been linked to plant invasiveness because it facilitates colonization and rapid spreading over large and environmentally heterogeneous new areas. 2. to determine the importance of phenotypic plasticity for plant invasiveness, we compare well-known exotic invasive species with widespread native congeners. first, we characterized the phenotype of 20 invasive\u2013native ecologically and phylogenetically related pairs from the mediterranean region by measuring 20 different traits involved in resource acquisition, plant competition ability and stress tolerance. second, we estimated their plasticity across nutrient and light gradients. 3. on average, invasive species had greater capacity for carbon gain and enhanced performance over a range of limiting to saturating resource availabilities than natives. however, both groups responded to environmental variations with high albeit similar levels of trait plasticity. therefore, contrary to the theory, the extent of phenotypic plasticity was not significantly higher for invasive plants. 4. we argue that the combination of studying mean values of a trait with its plasticity can render insightful conclusions on functional comparisons of species such as those exploring the performance of species coexisting in heterogeneous and changing environments.",
            "contribution_ids": [
                "R54095"
            ]
        },
        {
            "instance_id": "R54244xR54120",
            "comparison_id": "R54244",
            "paper_id": "R54120",
            "text": "Variation in morphological characters of two invasive leafminers, Liriomyza huidobrensis and L. sativae, across a tropical elevation gradient abstract changes in morphological traits along elevation and latitudinal gradients in ectotherms are often interpreted in terms of the temperature-size rule, which states that the body size of organisms increases under low temperatures, and is therefore expected to increase with elevation and latitude. however other factors like host plant might contribute to spatial patterns in size as well, particularly for polyphagous insects. here elevation patterns for trait size and shape in two leafminer species are examined, liriomyza huidobrensis (blanchard) (diptera: agromyzidae) and l. sativae blanchard, along a tropical elevation gradient in java, indonesia. adult leafminers were trapped from different locations in the mountainous area of dieng in the province of central java. to separate environmental versus genetic effects, l. huidobrensis originating from 1378 m and 2129 m asl were reared in the laboratory for five generations. size variation along the elevation gradient was only found in l. huidobrensis and this followed expectations based on the temperature-size rule. there were also complex changes in wing shape along the gradient. morphological differences were influenced by genetic and environmental effects. findings are discussed within the context of adaptation to different elevations in the two species.",
            "contribution_ids": [
                "R54121"
            ]
        },
        {
            "instance_id": "R54244xR54126",
            "comparison_id": "R54244",
            "paper_id": "R54126",
            "text": "Differential patterns of plasticity to water availability along native and naturalized latitudinal gradients questions: does plasticity to water availability differ between native and naturalized and laboratory plant accessions? is there a relationship between morphological plasticity and a fitness measure? can we account for latitudinal patterns of plasticity with rainfall data from the seed source location? organism: we examined an array of 23 native, 14 naturalized, and 5 laboratory accessions of arabidopsis thaliana. methods: we employed a split-plot experimental design in the greenhouse with two water treatments. we measured morphological and fitness-related traits at various developmental stages. we utilized a published dataset representing 30-year average precipitation trends for each accession origin. results: we detected evidence of differential patterns of plasticity between native, naturalized, and laboratory populations for several morphological traits. native, laboratory, and naturalized populations also differed in which traits were positively associated with fitness, and did not follow the jack-of-all-trades or master-of-some scenarios. significant negative relationships were detected for plasticity in morphological traits with latitude. we found modest evidence that rainfall may play a role in this latitudinal trend.",
            "contribution_ids": [
                "R54127"
            ]
        },
        {
            "instance_id": "R54244xR54136",
            "comparison_id": "R54244",
            "paper_id": "R54136",
            "text": "Invasion strategies in clonal aquatic plants: are phenotypic differences caused by phenotypic plasticity or local adaptation?  background and aims\\nthe successful spread of invasive plants in new environments is often linked to multiple introductions and a diverse gene pool that facilitates local adaptation to variable environmental conditions. for clonal plants, however, phenotypic plasticity may be equally important. here the primary adaptive strategy in three non-native, clonally reproducing macrophytes (egeria densa, elodea canadensis and lagarosiphon major) in new zealand freshwaters were examined and an attempt was made to link observed differences in plant morphology to local variation in habitat conditions.\\n\\n\\nmethods\\nfield populations with a large phenotypic variety were sampled in a range of lakes and streams with different chemical and physical properties. the phenotypic plasticity of the species before and after cultivation was studied in a common garden growth experiment, and the genetic diversity of these same populations was also quantified.\\n\\n\\nkey results\\nfor all three species, greater variation in plant characteristics was found before they were grown in standardized conditions. moreover, field populations displayed remarkably little genetic variation and there was little interaction between habitat conditions and plant morphological characteristics.\\n\\n\\nconclusions\\nthe results indicate that at the current stage of spread into new zealand, the primary adaptive strategy of these three invasive macrophytes is phenotypic plasticity. however, while limited, the possibility that genetic diversity between populations may facilitate ecotypic differentiation in the future cannot be excluded. these results thus indicate that invasive clonal aquatic plants adapt to new introduced areas by phenotypic plasticity. inorganic carbon, nitrogen and phosphorous were important in controlling plant size of e. canadensis and l. major, but no other relationships between plant characteristics and habitat conditions were apparent. this implies that within-species differences in plant size can be explained by local nutrient conditions. all together this strongly suggests that invasive clonal aquatic plants adapt to a wide range of habitats in introduced areas by phenotypic plasticity rather than local adaptation.",
            "contribution_ids": [
                "R54137"
            ]
        },
        {
            "instance_id": "R54244xR54170",
            "comparison_id": "R54244",
            "paper_id": "R54170",
            "text": "Life history plasticity magnifies the ecological effects of a social wasp invasion  \\n an unresolved question in ecology concerns why the ecological effects of invasions vary in magnitude. many introduced species fail to interact strongly with the recipient biota, whereas others profoundly disrupt the ecosystems they invade through predation, competition, and other mechanisms. in the context of ecological impacts, research on biological invasions seldom considers phenotypic or microevolutionary changes that occur following introduction. here, we show how plasticity in key life history traits (colony size and longevity), together with omnivory, magnifies the predatory impacts of an invasive social wasp (\\n vespula pensylvanica \\n ) on a largely endemic arthropod fauna in hawaii. using a combination of molecular, experimental, and behavioral approaches, we demonstrate (\\n i \\n ) that yellowjackets consume an astonishing diversity of arthropod resources and depress prey populations in invaded hawaiian ecosystems and (\\n ii \\n ) that their impact as predators in this region increases when they shift from small annual colonies to large perennial colonies. such trait plasticity may influence invasion success and the degree of disruption that invaded ecosystems experience. moreover, postintroduction phenotypic changes may help invaders to compensate for reductions in adaptive potential resulting from founder events and small population sizes. the dynamic nature of biological invasions necessitates a more quantitative understanding of how postintroduction changes in invader traits affect invasion processes.\\n",
            "contribution_ids": [
                "R54171"
            ]
        },
        {
            "instance_id": "R54244xR54176",
            "comparison_id": "R54244",
            "paper_id": "R54176",
            "text": "Inducible defences as key adaptations for the successful invasion of Daphnia lumholtzi in North America? the mechanisms underlying successful biological invasions often remain unclear. in the case of the tropical water flea daphnia lumholtzi , which invaded north america, it has been suggested that this species possesses a high thermal tolerance, which in the course of global climate change promotes its establishment and rapid spread. however, d. lumholtzi has an additional remarkable feature: it is the only water flea that forms rigid head spines in response to chemicals released in the presence of fishes. these morphologically (phenotypically) plastic traits serve as an inducible defence against these predators. here, we show in controlled mesocosm experiments that the native north american species daphnia pulicaria is competitively superior to d. lumholtzi in the absence of predators. however, in the presence of fish predation the invasive species formed its defences and became dominant. this observation of a predator-mediated switch in dominance suggests that the inducible defence against fish predation may represent a key adaptation for the invasion success of d. lumholtzi .",
            "contribution_ids": [
                "R54177"
            ]
        },
        {
            "instance_id": "R54244xR54198",
            "comparison_id": "R54244",
            "paper_id": "R54198",
            "text": "Predicting invasiveness in exotic species: do subtropical native and invasive exotic aquatic plants differ in their growth responses to macronutrients? we investigated whether plasticity in growth responses to nutrients could predict invasive potential in aquatic plants by measuring the effects of nutrients on growth of eight non\u2010invasive native and six invasive exotic aquatic plant species. nutrients were applied at two levels, approximating those found in urbanized and relatively undisturbed catchments, respectively. to identify systematic differences between invasive and non\u2010invasive species, we compared the growth responses (total biomass, root:shoot allocation, and photosynthetic surface area) of native species with those of related invasive species after 13 weeks growth. the results were used to seek evidence of invasive potential among four recently naturalized species. there was evidence that invasive species tend to accumulate more biomass than native species (p = 0.0788). root:shoot allocation did not differ between native and invasive plant species, nor was allocation affected by nutrient addition. however, the photosynthetic surface area of invasive species tended to increase with nutrients, whereas it did not among native species (p = 0.0658). of the four recently naturalized species, hydrocleys nymphoides showed the same nutrient\u2010related plasticity in photosynthetic area displayed by known invasive species. cyperus papyrus showed a strong reduction in photosynthetic area with increased nutrients. h. nymphoides and c. papyrus also accumulated more biomass than their native relatives. h. nymphoides possesses both of the traits we found to be associated with invasiveness, and should thus be regarded as likely to be invasive.",
            "contribution_ids": [
                "R54199"
            ]
        },
        {
            "instance_id": "R54244xR54200",
            "comparison_id": "R54244",
            "paper_id": "R54200",
            "text": "Spreading of the invasive Carpobrotus aff. acinaciformis in Mediterranean ecosystems: The advantage of performing in different light environments abstract question: do specific environmental conditions affect the performance and growth dynamics of one of the most invasive taxa (carpobrotus aff. acinaciformis) on mediterranean islands? location: four populations located on mallorca, spain. methods: we monitored growth rates of main and lateral shoots of this stoloniferous plant for over two years (2002\u20132003), comparing two habitats (rocky coast vs. coastal dune) and two different light conditions (sun vs. shade). in one population of each habitat type, we estimated electron transport rate and the level of plant stress (maximal photochemical efficiency fv/fm) by means of chlorophyll fluorescence. results: main shoots of carpobrotus grew at similar rates at all sites, regardless habitat type. however, growth rate of lateral shoots was greater in shaded plants than in those exposed to sunlight. its high phenotypic plasticity, expressed in different allocation patterns in sun and shade individuals, and its clonal growth which promotes the continuous search of available resources, contributed to a good growth and photochemical efficiency of carpobrotus in the relatively moderate shade of the understories of mediterranean shrublands and woodlands. each main shoot of a carpobrotus clone (which can have several dozens main shoots) grows ca. 40 cm per year, which explains its vigorous habitat colonization capacity. conclusion: the highly plastic morphological response to different light regimes of this taxon contributes to a rapid colonization of heterogeneous coastal mediterranean environments spreading well beyond the open sand dune systems where it has been often reported. nomenclature: tutin et al. (1964\u20131980).",
            "contribution_ids": [
                "R54201"
            ]
        },
        {
            "instance_id": "R54244xR54202",
            "comparison_id": "R54244",
            "paper_id": "R54202",
            "text": "Photosynthesis and water-use efficiency: A comparison between invasive (exotic) and non-invasive (native) species invasive species have been hypothesized to out-compete natives though either a jack-of-all-trades strategy, where they are able to utilize resources effectively in unfavourable environments, a master-of-some, where resource utilization is greater than its competitors in favourable environments, or a combination of the two (jack-and-master). we examined the invasive strategy of berberis darwinii in new zealand compared with four co-occurring native species by examining germination, seedling survival, photosynthetic characteristics and water-use efficiency of adult plants, in sun and shade environments. berberis darwinii seeds germinated more in shady sites than the other natives, but survival was low. in contrast, while germination of b.\\xa0darwinii was the same as the native species in sunny sites, seedling survival after 18\\xa0months was nearly twice that of the all native species. the maximum photosynthetic rate of b.\\xa0darwinii was nearly double that of all native species in the sun, but was similar among all species in the shade. other photosynthetic traits (quantum yield and stomatal conductance) did not generally differ between b.\\xa0darwinii and the native species, regardless of light environment. berberis darwinii had more positive values of \u03b413c than the four native species, suggesting that it gains more carbon per unit water transpired than the competing native species. these results suggest that the invasion success of b.\\xa0darwinii may be partially explained by combination of a jack-of-all-trades scenario of widespread germination with a master-of-some scenario through its ability to photosynthesize at higher rates in the sun and, hence, gain a rapid height and biomass advantage over native species in favourable environments.",
            "contribution_ids": [
                "R54203"
            ]
        },
        {
            "instance_id": "R54244xR54214",
            "comparison_id": "R54244",
            "paper_id": "R54214",
            "text": "Phenotypic plasticity, precipitation, and invasiveness in the fire-promoting grass Pennisetum setaceum (poaceae) invasiveness may result from genetic variation and adaptation or phenotypic plasticity, and genetic variation in fitness traits may be especially critical. pennisetum setaceum (fountain grass, poaceae) is highly invasive in hawaii (hi), moderately invasive in arizona (az), and less invasive in southern california (ca). in common garden experiments, we examined the relative importance of quantitative trait variation, precipitation, and phenotypic plasticity in invasiveness. in two very different environments, plants showed no differences by state of origin (hi, ca, az) in aboveground biomass, seeds/flower, and total seed number. plants from different states were also similar within watering treatment. plants with supplemental watering, relative to unwatered plants, had greater biomass, specific leaf area (sla), and total seed number, but did not differ in seeds/flower. progeny grown from seeds produced under different watering treatments showed no maternal effects in seed mass, germination, biomass or sla. high phenotypic plasticity, rather than local adaptation is likely responsible for variation in invasiveness. global change models indicate that temperature and precipitation patterns over the next several decades will change, although the direction of change is uncertain. drier summers in southern california may retard further invasion, while wetter summers may favor the spread of fountain grass.",
            "contribution_ids": [
                "R54215"
            ]
        },
        {
            "instance_id": "R54244xR54218",
            "comparison_id": "R54244",
            "paper_id": "R54218",
            "text": "Rapid evolution in response to introduced predators I: rates and patterns of morphological and life-history trait divergence abstract \\n \\n background \\n introduced species can have profound effects on native species, communities, and ecosystems, and have caused extinctions or declines in native species globally. we examined the evolutionary response of native zooplankton populations to the introduction of non-native salmonids in alpine lakes in the sierra nevada of california, usa. we compared morphological and life-history traits in populations of daphnia with a known history of introduced salmonids and populations that have no history of salmonid introductions. \\n \\n \\n results \\n our results show that daphnia populations co-existing with fish have undergone rapid adaptive reductions in body size and in the timing of reproduction. size-related traits decreased by up to 13 percent in response to introduced fish. rates of evolutionary change are as high as 4,238 darwins (0.036 haldanes). \\n \\n \\n conclusion \\n species introductions into aquatic habitats can dramatically alter the selective environment of native species leading to a rapid evolutionary response. knowledge of the rates and limits of adaptation is an important component of understanding the long-term effects of alterations in the species composition of communities. we discuss the evolutionary consequences of species introductions and compare the rate of evolution observed in the sierra nevada daphnia to published estimates of evolutionary change in ecological timescales. \\n",
            "contribution_ids": [
                "R54219"
            ]
        },
        {
            "instance_id": "R54244xR54230",
            "comparison_id": "R54244",
            "paper_id": "R54230",
            "text": "Leaf-level phenotypic variability and plasticity of invasive Rhododendron ponticum and non-invasive Ilex aquifolium co-occurring at two contrasting European sites to understand the role of leaf-level plasticity and variability in species invasiveness, foliar characteristics were studied in relation to seasonal average integrated quantum flux density (qint) in the understorey evergreen species rhododendron ponticum and ilex aquifolium at two sites. a native relict population of r. ponticum was sampled in southern spain (mediterranean climate), while an invasive alien population was investigated in belgium (temperate maritime climate). ilex aquifolium was native at both sites. both species exhibited a significant plastic response to qint in leaf dry mass per unit area, thickness, photosynthetic potentials, and chlorophyll contents at the two sites. however, r. ponticum exhibited a higher photosynthetic nitrogen use efficiency and larger investment of nitrogen in chlorophyll than i. aquifolium. since leaf nitrogen (n) contents per unit dry mass were lower in r. ponticum, this species formed a larger foliar area with equal photosynthetic potential and light-harvesting efficiency compared with i. aquifolium. the foliage of r. ponticum was mechanically more resistant with larger density in the belgian site than in the spanish site. mean leaf-level phenotypic plasticity was larger in the belgian population of r. ponticum than in the spanish population of this species and the two populations of i. aquifolium. we suggest that large fractional investments of foliar n in photosynthetic function coupled with a relatively large mean, leaf-level phenotypic plasticity may provide the primary explanation for the invasive nature and superior performance of r. ponticum at the belgian site. with alleviation of water limitations from mediterranean to temperate maritime climates, the invasiveness of r. ponticum may also be enhanced by the increased foliage mechanical resistance observed in the alien populations.",
            "contribution_ids": [
                "R54231"
            ]
        },
        {
            "instance_id": "R54244xR54241",
            "comparison_id": "R54244",
            "paper_id": "R54241",
            "text": "Greater morphological plasticity of exotic honeysuckle species may make them better invaders than native species sempervirens l., a non-invasive native. we hypothesized that greater morphological plasticity may contribute to the ability of l. japonica to occupy more habitat types, and contribute to its invasiveness. we compared the morphology of plants provided with climbing supports with plants that had no climbing supports, and thus quantified their morphological plasticity in response to an important variable in their habitats. the two species responded differently to the treatments, with l. japonica showing greater responses in more characters. for example, lonicera japonica responded to climbing supports with a 15.3% decrease in internode length, a doubling of internode number and a 43% increase in shoot biomass. in contrast, climbing supports did not influence internode length or shoot biomass for l. sempervirens, and only resulted in a 25% increase in internode number. this plasticity may allow l. japonica to actively place plant modules in favorable microhabitats and ultimately affect plant fitness.",
            "contribution_ids": [
                "R54242"
            ]
        },
        {
            "instance_id": "R54867xR54574",
            "comparison_id": "R54867",
            "paper_id": "R54574",
            "text": "Anthropogenic Disturbance Can Determine the Magnitude of Opportunistic Species Responses on Marine Urban Infrastructures background coastal landscapes are being transformed as a consequence of the increasing demand for infrastructures to sustain residential, commercial and tourist activities. thus, intertidal and shallow marine habitats are largely being replaced by a variety of artificial substrata (e.g. breakwaters, seawalls, jetties). understanding the ecological functioning of these artificial habitats is key to planning their design and management, in order to minimise their impacts and to improve their potential to contribute to marine biodiversity and ecosystem functioning. nonetheless, little effort has been made to assess the role of human disturbances in shaping the structure of assemblages on marine artificial infrastructures. we tested the hypothesis that some negative impacts associated with the expansion of opportunistic and invasive species on urban infrastructures can be related to the severe human disturbances that are typical of these environments, such as those from maintenance and renovation works. methodology/principal findings maintenance caused a marked decrease in the cover of dominant space occupiers, such as mussels and oysters, and a significant enhancement of opportunistic and invasive forms, such as biofilm and macroalgae. these effects were particularly pronounced on sheltered substrata compared to exposed substrata. experimental application of the disturbance in winter reduced the magnitude of the impacts compared to application in spring or summer. we use these results to identify possible management strategies to inform the improvement of the ecological value of artificial marine infrastructures. conclusions/significance we demonstrate that some of the impacts of globally expanding marine urban infrastructures, such as those related to the spread of opportunistic, and invasive species could be mitigated through ecologically-driven planning and management of long-term maintenance of these structures. impact mitigation is a possible outcome of policies that consider the ecological features of built infrastructures and the fundamental value of controlling biodiversity in marine urban systems.",
            "contribution_ids": [
                "R54575"
            ]
        },
        {
            "instance_id": "R54867xR54585",
            "comparison_id": "R54867",
            "paper_id": "R54585",
            "text": "The incidence of exotic species following clearfelling of Eucalyptus regnans forest in the Central Highlands, Victoria invasion by exotic species following clearfelling of eucalyptus regnans f. muell. (mountain ash) forest was examined in the toolangi state forest in the central highlands of victoria. coupes ranging in age from < 1- to 10-years-old and the spar-stage forests (1939 bushfire regrowth) adjacent to each of these coupes and a mature, 250-year-old forest were surveyed. the dispersal and establishment of weeds was facilitated by clearfelling. an influx of seeds of exotic species was detected in recently felled coupes but not in the adjacent, unlogged forests. vehicles and frequently disturbed areas, such as roadside verges, are likely sources of the seeds of exotic species. the soil seed bank of younger coupes had a greater number and percentage of seeds of exotics than the 10-year-old coupes and the spar-stage and mature forests. exotic species were a minor component (< 1% vegetation cover) in the more recently logged coupes and were not present in 10-year-old coupes and the spar-stage and mature forests. these particular exotic species did not persist in the dense regeneration nor exist in the older forests because the weeds were ruderal species (light-demanding, short-lived and short-statured plants). the degree of influence that these particular exotic species have on the regeneration and survival of native species in e. regnans forests is almost negligible. however, the current management practices may need to be addressed to prevent a more threatening exotic species from establishing in these coupes and forests.",
            "contribution_ids": [
                "R54586",
                "R54587"
            ]
        },
        {
            "instance_id": "R54867xR54605",
            "comparison_id": "R54867",
            "paper_id": "R54605",
            "text": "Interannual variation of fish assemblage structure in a Mediterranean River: Implications of streamflow on the dominance of native or exotic species streams in mediterranean\u2010type climate regions are shaped by predictable seasonal events of flooding and drying over an annual cycle, but also present a strong interannual flow variation.",
            "contribution_ids": [
                "R54606"
            ]
        },
        {
            "instance_id": "R54867xR54607",
            "comparison_id": "R54867",
            "paper_id": "R54607",
            "text": "Determinants of Caulerpa racemosa distribution in the north-western Mediterranean predicting community susceptibility to invasion has become a priority for preserving biodiversity. we tested the hypothesis that the occurrence and abundance of the seaweed caulerpa racemosa in the north-western (nw) mediterranean would increase with increasing levels of human disturbance. data from a survey encompassing areas subjected to different human influences (i.e. from urbanized to protected areas) were fitted by means of generalized linear mixed models, including descriptors of habitats and communities. the incidence of occurrence of c. racemosa was greater on urban than extra-urban or protected reefs, along the coast of tuscany and nw sardinia, respectively. within the marine protected area of capraia island (tuscan archipelago), the probability of \\ndetecting c. racemosa did not vary according to the degree of protection (partial versus total). human influence was, however, a poor predictor of the seaweed cover. at the seascape level, c. racemosa was more widely spread within degraded (i.e. posidonia oceanica dead matte or algal turfs) than in better preserved habitats (i.e. canopy-forming macroalgae or p. oceanica seagrass meadows). at a smaller spatial scale, the presence of the seaweed was positively correlated to the diversity of macroalgae and negatively to that of sessile invertebrates. these results suggest that c. racemosa can take advantage of habitat degradation. thus, predicting invasion scenarios requires a thorough knowledge of ecosystem structure, at a hierarchy of levels of biological organization (from the \\nlandscape to the assemblage) and detailed information on the nature and intensity of sources of disturbance and spatial scales at which they operate.",
            "contribution_ids": [
                "R54608"
            ]
        },
        {
            "instance_id": "R54867xR54642",
            "comparison_id": "R54867",
            "paper_id": "R54642",
            "text": "Re-colonisation rate differs between co-existing indigenous and invasive intertidal mussels following major disturbance the potential of introduced species to become invasive is often linked to their ability to colonise disturbed habitats rapidly. we studied the effects of major disturbance by severe storms on the indigenous mussel perna perna and the invasive mussel mytilus galloprovincialis in sympatric intertidal populations on the south coast of south africa. at the study sites, these species dominate different shore levels and co-exist in the mid mussel zone. we tested the hypotheses that in the mid- zone p. perna would suffer less dislodgment than m. galloprovincialis, because of its greater tenacity, while m. galloprovincialis would respond with a higher re-colonisation rate. we estimated the per- cent cover of the 2 mussels in the mid-zone from photographs, once before severe storms and 3 times afterwards. m. galloprovincialis showed faster re-colonisation and 3 times more cover than p. perna 1 and 1.5 yr after the storms (when populations had recovered). storm-driven dislodgment in the mid- zone was highest for the species that initially dominated at each site, conforming to the concept of compensatory mortality. this resulted in similar cover of the 2 species immediately after the storms. thus, the storm wave forces exceeded the tenacity even of p. perna, while the higher recruitment rate of m. galloprovincialis can explain its greater colonisation ability. we predict that, because of its weaker attachment strength, m. galloprovincialis will be largely excluded from open coast sites where wave action is generally stronger, but that its greater capacity for exploitation competition through re-colonisation will allow it to outcompete p. perna in more sheltered areas (especially in bays) that are periodically disturbed by storms.",
            "contribution_ids": [
                "R54643"
            ]
        },
        {
            "instance_id": "R54867xR54663",
            "comparison_id": "R54867",
            "paper_id": "R54663",
            "text": "Fire and competition in a southern California grassland: impacts on the rare forb Erodium macrophyllum summary 1. the use of off-season burns to control exotic vegetation shows promise for land managers. in california, wildfires tend to occur in the summer and autumn, when most grassland vegetation is dormant. the effects of spring fires on native bunchgrasses have been examined but their impacts on native forbs have received less attention. 2. we introduced erodium macrophyllum, a rare native annual forb, by seeding plots in 10 different areas in a california grassland. we tested the hypotheses that e. macrophyllum would perform better (increased fecundity and germination) when competing with native grasses than with a mixture of exotic and native grasses, and fire would alter subsequent demography of e. macrophyllum and other species\u2019 abundances. we monitored the demography of e. macrophyllum for two seasons in plots manually weeded so that they were free from exotics, and in areas that were burned or not burned the spring after seeding. 3. weeding increased e. macrophyllum seedling emergence, survival and fecundity during both seasons. when vegetation was burned in june 2001 (at the end of the first growing season) to kill exotic grass seeds before they dispersed, all e. macrophyllum plants had finished their life cycle and dispersed seeds, suggesting that burns at this time of year would not directly impact on fecundity. in the growing season after burning (2002), burned plots had less recruitment of e. macrophyllum but more establishment of native grass seedlings, suggesting burning may differentially affect seedling recruitment. 4. at the end of the second growing season (june 2002), burned plots had less cover of exotic and native grasses but more cover of exotic forbs. nevertheless, e. macrophyllum plants in burned plots had greater fecundity than in non-burned plots, suggesting that exotic grasses are more competitive than exotic forbs. 5. a glasshouse study showed that exotic grasses competitively suppress e. macrophyllum to a greater extent than native grasses, indicating that the poor performance of e. macrophyllum in the non-burned plots was due to exotic grass competition. 6. synthesis and applications. this study illustrates that fire can alter the competitive environment in grasslands with differential effects on rare forbs, and that exotic grasses strongly interfere with e. macrophyllum. for land managers, the benefits of prescribed spring burns will probably outweigh the costs of decreased e. macrophyllum establishment. land managers can use spring burns to cause a flush of native grass recruitment and to create an environment that is, although abundant with exotic forbs, ultimately less competitive compared with non-burned areas dominated by exotic grasses.",
            "contribution_ids": [
                "R54664"
            ]
        },
        {
            "instance_id": "R54867xR54689",
            "comparison_id": "R54867",
            "paper_id": "R54689",
            "text": "Effect of disturbance and nutrient addition on native and introduced annuals in plant communities in the Western Australian wheatbelt to investigate factors affecting the ability of introduced species to invade natural communities in the western australian wheatbelt, five communities were examined within a nature reserve near kellerberrin. transect studies indicated that introduced annuals were more abundant in woodland than in shrub communities, despite an input of introduced seed into all communities. the response of native and introduced annuals to soil disturbance and fertilizer addition was examined. small areas were disturbed and/or provided with fertilizer prior to addition of seed of introduced annuals. in most communities, the introduced species used (avena fatua and ursinia anthemoides) established well only where the soil had been disturbed, but their growth was increased greatly when fertilizer was also added. establishment and growth of other introduced species also increased where nutrient addition and soil disturbance were combined. growth of several native annuals increased greatly with fertilizer addition, but showed little response to disturbance. fertilizer addition also significantly increased the number of native species present in most communities. this indicates that growth of both native and introduced species is limited by nutrient availability in these communities, but also that introduced species respond more to a combination of nutrient addition and soil disturbance.",
            "contribution_ids": [
                "R54690",
                "R54691"
            ]
        },
        {
            "instance_id": "R54867xR54694",
            "comparison_id": "R54867",
            "paper_id": "R54694",
            "text": "Removal of nonnative vines and post-hurricane recruitment in tropical hardwood forests of Florida abstract in hardwood subtropical forests of southern florida, nonnative vines have been hypothesized to be detrimental, as many species form dense \u201cvine blankets\u201d that shroud the forest. to investigate the effects of nonnative vines in post-hurricane regeneration, we set up four large (two pairs of 30 \u00d7 60 m) study areas in each of three study sites. one of each pair was unmanaged and the other was managed by removal of nonnative plants, predominantly vines. within these areas, we sampled vegetation in 5 \u00d7 5 m plots for stems 2 cm dbh (diameter at breast height) or greater and in 2 \u00d7 0.5 m plots for stems of all sizes. for five years, at annual censuses, we tagged and measured stems of vines, trees, shrubs and herbs in these plots. for each 5 \u00d7 5 m plot, we estimated percent coverage by individual vine species, using native and nonnative vines as classes. we investigated the hypotheses that: (1) plot coverage, occurrence and recruitment of nonnative vines were greater than that of native vines in unmanaged plots; (2) the management program was effective at reducing cover by nonnative vines; and (3) reduction of cover by nonnative vines improved recruitment of seedlings and saplings of native trees, shrubs, and herbs. in unmanaged plots, nonnative vines recruited more seedlings and had a significantly higher plot-cover index, but not a higher frequency of occurrence. management significantly reduced cover by nonnative vines and had a significant overall positive effect on recruitment of seedlings and saplings of native trees, shrubs and herbs. management also affected the seedling community (which included vines, trees, shrubs, and herbs) in some unanticipated ways, favoring early successional species for a longer period of time. the vine species with the greatest potential to \u201cstrangle\u201d gaps were those that rapidly formed dense cover, had shade tolerant seedling recruitment, and were animal-dispersed. this suite of traits was more common in the nonnative vines than in the native vines. our results suggest that some vines may alter the spatiotemporal pattern of recruitment sites in a forest ecosystem following a natural disturbance by creating many very shady spots very quickly.",
            "contribution_ids": [
                "R54695",
                "R54696"
            ]
        },
        {
            "instance_id": "R54867xR54697",
            "comparison_id": "R54867",
            "paper_id": "R54697",
            "text": "Alien Grass Invasion and Fire In the Seasonal Submontane Zone of Hawaii \"island ecosystems are notably susceptible to biological invasions (elton 1958), and the hawaiian islands in particular have been colonized by many introduced species (loope and mueller-dombois 1989). introduced plants now dominate extensive areas of the hawaiian islands, and 86 species of alien plants are presently considered to pose serious threats to hawaiian communities and ecosystems (smith 1985). among the most important invasive plants are several species of tropical and subtropical grasses that use the c4 photosynthetic pathway. these grasses now dominate extensive areas of dry and seasonally dry habitats in hawai'i. they may compete with native species, and they have also been shown to alter hydrological properties in the areas they invade (muellerdombois 1973). most importantly, alien grasses can introduce fire into areas where it was previously rare or absent (smith 1985), thereby altering the structure and functioning of previously native-dominated ecosystems. many of these grasses evolved in fire-affected areas and have mechanisms for surviving and recovering rapidly from fire (vogl 1975, christensen 1985), while most native species in hawai'i have little background with fire (mueller-dombois 1981) and hence few or no such mechanisms. consequently, grass invasion could initiate a grass/fire cycle whereby invading grasses promote fire, which in turn favors alien grasses over native species. such a scenario has been suggested in a number of areas, including latin america, western north america, australia, and hawai'i (parsons 1972, smith 1985, christensen and burrows 1986, mack 1986, macdonald and frame 1988). in most of these cases, land clearing by humans initiates colonization by alien grasses, and the grass/fire cycle then leads to their persistence. in hawai'i and perhaps other areas, however, grass invasion occurs without any direct human intervention. where such invasions initiate a grass/fire cy-\"",
            "contribution_ids": [
                "R54698"
            ]
        },
        {
            "instance_id": "R54867xR54704",
            "comparison_id": "R54867",
            "paper_id": "R54704",
            "text": "Prescribed fire effects on dalmation toadflax prescribed fires are important for rangeland restoration and affect plant community composition and species interactions. many rangeland plant communities have been, or are under the threat of noxious weed invasion, however there is little information on how fire effects weeds. our objective was to determine the effects of prescribed rangeland fire on dalmatian toadflax [linaria dalmatica (l.) miller] density, cover, biomass, and seed production. these plant characteristics, as well as density, cover, and biomass of perennial grasses and forbs were measured within burned and adjacent not-burned areas on 3 artemisia tridentata/agropyron spicatum habitat types in montana. areas were burned in the spring and measured in the fall 1999. comparisons of plant characteristics between the burned and not-burned sites were made using t-tests and non-parametric wilcoxon rank sum tests. after 1 growing season, fire did not affect density or cover of dalmatian toadflax. burning increased dalmatian toadflax bio- mass per square meter at 2 sites, and per plant biomass at all 3 sites. seed production of dalmatian toadflax was increased by fire at all 3 sites. fire reduced forb cover at 1 site and increased grass biomass at 2 sites. the increases in dalmatian toadflax biomass and seed production suggest that fire used to restore healthy plant communities may increase dalmatian toadflax dominance. we recommend weed management procedures, such as herbicide control and seeding desirable species, be integrated with prescribed fire where dalmatian toadflax is present in the plant community.",
            "contribution_ids": [
                "R54705",
                "R54706"
            ]
        },
        {
            "instance_id": "R54867xR54707",
            "comparison_id": "R54867",
            "paper_id": "R54707",
            "text": "Do biodiversity and human impact influence the introduction or establishment of alien mammals? what determines the number of alien species in a given region? \u2018native biodiversity\u2019 and \u2018human impact\u2019 are typical answers to this question. indeed, studies comparing different regions have frequently found positive relationships between number of alien species and measures of both native biodiversity (e.g. the number of native species) and human impact (e.g. human population). these relationships are typically explained by biotic acceptance or resistance, i.e. by influence of native biodiversity and human impact on the second step of the invasion process, establishment. the first step of the invasion process, introduction, has often been ignored. here we investigate whether relationships between number of alien mammals and native biodiversity or human impact in 43 european countries are mainly shaped by differences in number of introduced mammals or establishment success. our results suggest that correlation between number of native and established mammals is spurious, as it is simply explainable by the fact that both quantities are linked to country area. we also demonstrate that countries with higher human impact host more alien mammals than other countries because they received more introductions than other countries. differences in number of alien mammals cannot be explained by differences in establishment success. our findings highlight importance of human activities and question, at least for mammals in europe, importance of biotic acceptance and resistance.",
            "contribution_ids": [
                "R54708",
                "R57247"
            ]
        },
        {
            "instance_id": "R54867xR54720",
            "comparison_id": "R54867",
            "paper_id": "R54720",
            "text": "The influence of anthropogenic disturbance and environmental suitability on the distribution of the nonindigenous amphipod, Echinogammarus ischnus, at Laurentian Great Lakes coastal margins \"abstract invasion ecology offers a unique opportunity to examine drivers of ecological processes that regulate communities. biotic resistance to nonindigenous species establishment is thought to be greater in communities that have not been disturbed by human activities. alternatively, invasion may occur wherever environmental conditions are appropriate for the colonist, regardless of the composition of the existing community and the level of disturbance. we tested these hypotheses by investigating distribution of the nonindigenous amphipod, echinogammarus ischnus stebbing, 1899, in co-occurrence with a widespread amphipod, gammarus fasciatus say, 1818, at 97 sites across the laurentian great lakes coastal margins influenced by varying types and levels of anthropogenic stress. e. ischnus was distributed independently of disturbance gradients related to six anthropogenic disturbance variables that summarized overall nutrient input, nitrogen, and phosphorus load carried from the adjacent coastal watershed, agricultural land area, human population density, overall pollution loading, and the site-specific dominant stressor, consistent with the expectations of regulation by general environmental characteristics. our results support the view that the biotic facilitation by dreissenid mussels and distribution of suitable habitats better explain e. ischnus' distribution at laurentian great lakes coastal margins than anthropogenic disturbance.\"",
            "contribution_ids": [
                "R54721"
            ]
        },
        {
            "instance_id": "R54867xR54749",
            "comparison_id": "R54867",
            "paper_id": "R54749",
            "text": "Large Herbivore Grazing and Non-native Plant Invasions in Montane Grasslands of Central Argentina abstract: \\n grazing by large herbivores has the potential to facilitate invasion of natural grasslands by non-native plant species. often, both herbivore identity and plant community type modulate this effect. the objective of this study was to evaluate the impact of grazing on non-native plant species richness and cover in montane grasslands of central argentina as related to herbivore identity (horse or cattle) and plant community type. the study was conducted in piedmont valleys of the ventania mountains. the area is occupied by two major types of plant communities: short-needlegrass and tall-tussock grasslands. short-needlegrass grasslands occupy poor soils and have higher plant species diversity compared to tall-tussock grasslands which typically grow on rich soils. part of the study area is devoted to cattle husbandry, part is inhabited by feral horses, and part has been free of grazing by large herbivores for the last 15 years. we compared non-native species richness and cover at three levels of grazing (horse grazing, cattle grazing, grazing exclusion) and two levels of plant community type (short-needlegrass grassland and tall-tussock grassland) at the end of the growing season in 2006 and 2007. thirty-one nonnative plant species were found growing in the study area. grazing increased non-native species richness and cover and was highest under horse grazing and in communities on resource-rich soils. our results are consistent with the hypothesis that grazing by large non-native herbivores can facilitate non-native plant species invasion of natural grasslands. they also suggest that herbivore identity and community type modulate the effect of large herbivore grazing on grassland invasion by non-native plant species.",
            "contribution_ids": [
                "R54750"
            ]
        },
        {
            "instance_id": "R54867xR54751",
            "comparison_id": "R54867",
            "paper_id": "R54751",
            "text": "Old World Climbing Fern (Lygodium microphyllum) Invasion in Hurricane Caused Treefalls abstract: \\n we examined effects of a natural disturbance (hurricanes) on potential invasion of tree islands by an exotic plant (old world climbing fern, lygodium microphyllum) in the arthur r. marshall loxahatchee national wildlife refuge, florida. three major hurricanes in 2004 and 2005 caused varying degrees of impacts to trees on tree islands within the refuge. physical impacts of hurricanes were hypothesized to promote invasion and growth of l. microphyllum. we compared presence and density of l. microphyllum in plots of disturbed soil created by hurricane-caused treefalls to randomly selected non-disturbed plots on 12 tree islands. we also examined relationships between disturbed area size, canopy cover, and presence of standing water on presence and density of l. microphyllum. lygodium microphyllum was present in significantly more treefall plots than random non-treefall plots (76% of the treefall plots (n=55) and only 14% of random non-treefall plots (n=55)). density of l. microphyllum was higher in treefall plots compared to random non-disturbed plots (6.0 stems per m2 for treefall plots; 0.5 stems per m2 for random non-disturbed plots), and l. microphyllum density was correlated with disturbed area size (p = 0.005). lygodium microphyllum presence in treefall sites was significantly related to canopy cover and presence of water: it was present in five times more treefalls with water than those without. these results suggest that disturbances, such as hurricanes, that result in canopy openings and the creation of disturbed areas with standing water contribute to the ability of l. microphyllum to invade natural areas.",
            "contribution_ids": [
                "R54752"
            ]
        },
        {
            "instance_id": "R54867xR54781",
            "comparison_id": "R54867",
            "paper_id": "R54781",
            "text": "Are invaders disturbance-limited? Conservation of mountain grasslands in Central Argentina abstract extensive areas in the mountain grasslands of central argentina are heavily invaded by alien species from europe. a decrease in biodiversity and a loss of palatable species is also observed. the invasibility of the tall-grass mountain grassland community was investigated in an experiment of factorial design. six alien species which are widely distributed in the region were sown in plots where soil disturbance, above-ground biomass removal by cutting and burning were used as treatments. alien species did not establish in undisturbed plots. all three types of disturbances increased the number and cover of alien species; the effects of soil disturbance and biomass removal was cumulative. cirsium vulgare and oenothera erythrosepala were the most efficient alien colonizers. in conditions where disturbances did not continue the cover of aliens started to decrease in the second year, by the end of the third season, only a few adults were established. consequently, disturbances are needed to maintain alien populations in tall-grass mountain grasslands. burning also increased the species richness of native species. we conclude that an efficient way to control the distribution of alien species is to decrease grazing pressure while burning as a traditional management tool may be continued. nomenclature: cantero & bianco (1986).",
            "contribution_ids": [
                "R54782",
                "R54783"
            ]
        },
        {
            "instance_id": "R54867xR54791",
            "comparison_id": "R54867",
            "paper_id": "R54791",
            "text": "EFFECTS OF DISTURBANCE ON HERBACEOUS EXOTIC PLANT-SPECIES ON THE FLOODPLAIN OF THE POTOMAC RIVER \"-the objective of this study was to investigate specific effects of disturbance on exotic species in floodplain environments and to provide baseline data on the abundance of exotic herbs in the potomac river floodplain. frequency of exotics generally increased with man-made disturbance (forest fragmentation and recreational use of land) and decreased with increasing flooding frequency. species richness of exotics followed a similar pattern. some variation was found in individual species' responses to disturbance. the spread of alliaria officinalis and glecoma hederacea, the most frequent exotic species, was inhibited by forest fragmentation.\"",
            "contribution_ids": [
                "R54792"
            ]
        },
        {
            "instance_id": "R54867xR54797",
            "comparison_id": "R54867",
            "paper_id": "R54797",
            "text": "Mammals of the northern Philippines: tolerance for habitat disturbance and resistance to invasive species in an endemic insular fauna aim\\u2002 island faunas, particularly those with high levels of endemism, usually are considered especially susceptible to disruption from habitat disturbance and invasive alien species. we tested this general hypothesis by examining the distribution of small mammals along gradients of anthropogenic habitat disturbance in northern luzon island, an area with a very high level of mammalian endemism.",
            "contribution_ids": [
                "R54798"
            ]
        },
        {
            "instance_id": "R54867xR54817",
            "comparison_id": "R54867",
            "paper_id": "R54817",
            "text": "Recent Invasion of the Symbiont-Bearing Foraminifera Pararotalia into the Eastern Mediterranean Facilitated by the Ongoing Warming Trend the eastern mediterranean is a hotspot of biological invasions. numerous species of indo-pacific origin have colonized the mediterranean in recent times, including tropical symbiont-bearing foraminifera. among these is the species pararotalia calcariformata. unlike other invasive foraminifera, this species was discovered only two decades ago and is restricted to the eastern mediterranean coast. combining ecological, genetic and physiological observations, we attempt to explain the recent invasion of this species in the mediterranean sea. using morphological and genetic data, we confirm the species attribution to p. calcariformata mcculloch 1977 and identify its symbionts as a consortium of diatom species dominated by minutocellus polymorphus. we document photosynthetic activity of its endosymbionts using pulse amplitude modulated fluorometry and test the effects of elevated temperatures on growth rates of asexual offspring. the culturing of asexual offspring for 120 days shows a 30-day period of rapid growth followed by a period of slower growth. a subsequent 48-day temperature sensitivity experiment indicates a similar developmental pathway and high growth rate at 28\u00b0c, whereas an almost complete inhibition of growth was observed at 20\u00b0c and 35\u00b0c. this indicates that the offspring of this species may have lower tolerance to cold temperatures than what would be expected for species native to the mediterranean. we expand this hypothesis by applying a species distribution model (sdm) based on modern occurrences in the mediterranean using three environmental variables: irradiance, turbidity and yearly minimum temperature. the model reproduces the observed restricted distribution and indicates that the range of the species will drastically expand westwards under future global change scenarios. we conclude that p. calcariformata established a population in the levant because of the recent warming in the region. in line with observations from other groups of organisms, our results indicate that continued warming of the eastern mediterranean will facilitate the invasion of more tropical marine taxa into the mediterranean, disturbing local biodiversity and ecosystem structure.",
            "contribution_ids": [
                "R54818"
            ]
        },
        {
            "instance_id": "R54867xR54826",
            "comparison_id": "R54867",
            "paper_id": "R54826",
            "text": "Shoreline development drives invasion of Phragmites australis and the loss of plant diversity on New England salt marshes abstract:\\u2002 the reed phragmites australis cav. is aggressively invading salt marshes along the atlantic coast of north america. we examined the interactive role of habitat alteration (i.e., shoreline development) in driving this invasion and its consequences for plant richness in new england salt marshes. we surveyed 22 salt marshes in narragansett bay, rhode island, and quantified shoreline development, phragmites cover, soil salinity, and nitrogen availability. shoreline development, operationally defined as removal of the woody vegetation bordering marshes, explained >90% of intermarsh variation in phragmites cover. shoreline development was also significantly correlated with reduced soil salinities and increased nitrogen availability, suggesting that removing woody vegetation bordering marshes increases nitrogen availability and decreases soil salinities, thus facilitating phragmites invasion. soil salinity (64%) and nitrogen availability (56%) alone explained a large proportion of variation in phragmites cover, but together they explained 80% of the variation in phragmites invasion success. both univariate and aggregate (multidimensional scaling) analyses of plant community composition revealed that phragmites dominance in developed salt marshes resulted in an almost three\u2010fold decrease in plant species richness. our findings illustrate the importance of maintaining integrity of habitat borders in conserving natural communities and provide an example of the critical role that local conservation can play in preserving these systems. in addition, our findings provide ecologists and natural resource managers with a mechanistic understanding of how human habitat alteration in one vegetation community can interact with species introductions in adjacent communities (i.e., flow\u2010on or adjacency effects) to hasten ecosystem degradation.",
            "contribution_ids": [
                "R54827"
            ]
        },
        {
            "instance_id": "R54867xR54828",
            "comparison_id": "R54867",
            "paper_id": "R54828",
            "text": "Quantifying the impact of an extreme climate event on species diversity in fragmented temperate forests: the effect of the October 1987 storm on British broadleaved woodlands we report the impact of an extreme weather event, the october 1987 severe storm, on fragmented woodlands in southern britain. we analysed ecological changes between 1971 and 2002 in 143 200\u2010m2 plots in 10 woodland sites exposed to the storm with an ecologically equivalent sample of 150 plots in 16 non\u2010exposed sites. comparing both years, understorey plant species\u2010richness, species composition, soil ph and woody basal area of the tree and shrub canopy were measured. we tested the hypothesis that the storm had deflected sites from the wider national trajectory of an increase in woody basal area and reduced understorey species\u2010richness associated with ageing canopies and declining woodland management. we also expected storm disturbance to amplify the background trend of increasing soil ph, a uk\u2010wide response to reduced atmospheric sulphur deposition. path analysis was used to quantify indirect effects of storm exposure on understorey species richness via changes in woody basal area and soil ph. by 2002, storm exposure was estimated to have increased mean species richness per 200 m2 by 32%. woody basal area changes were highly variable and did not significantly differ with storm exposure. increasing soil ph was associated with a 7% increase in richness. there was no evidence that soil ph increased more as a function of storm exposure. changes in species richness and basal area were negatively correlated: a 3.4% decrease in richness occurred for every 0.1\u2010m2 increase in woody basal area per plot. despite all sites substantially exceeding the empirical critical load for nitrogen deposition, there was no evidence that in the 15 years since the storm, disturbance had triggered a eutrophication effect associated with dominance of gaps by nitrophilous species. synthesis. although the impacts of the 1987 storm were spatially variable in terms of impacts on woody basal area, the storm had a positive effect on understorey species richness. there was no evidence that disturbance had increased dominance of gaps by invasive species. this could change if recovery from acidification results in a soil ph regime associated with greater macronutrient availability.",
            "contribution_ids": [
                "R54829"
            ]
        },
        {
            "instance_id": "R54867xR54839",
            "comparison_id": "R54867",
            "paper_id": "R54839",
            "text": "Altered stream-flow regimes and invasive plant species: the Tamarix case aim to test the hypothesis that anthropogenic alteration of stream-flow regimes is a key driver of compositional shifts from native to introduced riparian plant species. location the arid south-western united states; 24 river reaches in the gila and lower colorado drainage basins of arizona. methods we compared the abundance of three dominant woody riparian taxa (native populus fremontii and salix gooddingii , and introduced tamarix ) between river reaches that varied in stream-flow permanence (perennial vs. intermittent), presence or absence of an upstream flow-regulating dam, and presence or absence of municipal effluent as a stream water source. results populus and salix were the dominant pioneer trees along the reaches with perennial flow and a natural flood regime. in contrast, tamarix had high abundance (patch area and basal area) along reaches with intermittent stream flows (caused by natural and cultural factors), as well as those with dam-regulated flows. main conclusions stream-flow regimes are strong determinants of riparian vegetation structure, and hydrological alterations can drive dominance shifts to introduced species that have an adaptive suite of traits. deep alluvial groundwater on intermittent rivers favours the deep-rooted, stress-adapted tamarix over the shallower-rooted and more competitive populus and salix . on flow-regulated rivers, shifts in flood timing favour the reproductively opportunistic tamarix over populus and salix , both of which have narrow germination windows . the prevailing hydrological conditions thus favour a new dominant pioneer species in the riparian corridors of the american southwest. these results reaffirm the importance of reinstating stream-flow regimes (inclusive of groundwater flows) for re-establishing the native pioneer trees as the dominant forest type.",
            "contribution_ids": [
                "R54840"
            ]
        },
        {
            "instance_id": "R54867xR54857",
            "comparison_id": "R54867",
            "paper_id": "R54857",
            "text": "Case studies of the expansion of Acacia dealbata in the valley of the river Mino (Galicia, Spain) aim of study: acacia dealbata is a naturalized tree of invasive behaviour that has expanded from small plots associated with vineyards into forest ecosystems. our main objective is to find evidence to support the notion that disturbances, particularly forest fires, are important driving factors in the current expansion of a. dealbata. area of study: we mapped it current distribution using three study areas and assesses the temporal changes registered in forest cover in these areas of the valley of the river mino. material and methods: the analyses were based on visual interpretation of aerial photographs taken in 1985 and 2003 of three 1x1 km study areas and field works. main result: a 62.4%, 48.6% and 22.2% of the surface area was covered by a. dealbata in 2003 in pure or mixed stands. furthermore, areas composed exclusively of a. dealbata make up 33.8%, 15.2% and 5.7% of the stands. the transition matrix analyses between the two dates support our hypothesis that the areas currently covered by a. dealbata make up a greater proportion of the forest area previously classified as unwooded or open forest than those without a. dealbata cover. both of these surface types are the result of an important impact of fire in the region. within each area, a. dealbata is mainly located on steeper terrain, which is more affected by fires. research highlights: a. dealbata is becoming the dominant tree species over large areas and the invasion of this species gives rise to monospecific stands, which may have important implications for future fire regimes. keywords: fire regime; mimosa; plant invasion; silver wattle.",
            "contribution_ids": [
                "R54858"
            ]
        },
        {
            "instance_id": "R55219xR54967",
            "comparison_id": "R55219",
            "paper_id": "R54967",
            "text": "Succession of floodplain grasslands following reduction in land use intensity: the importance of environmental conditions, management and dispersal summary 1. classical ecological theory predicts a succession towards plant communities that are determined by environmental conditions. however, in ecological restoration, species composition often remains different from the predicted target community, compromising the success of restoration measures. 2. we analysed the relative importance of environmental conditions, management and distance to source populations for floodplain grassland succession following re-conversion from intensive to traditional use. the study was established at 33 grassland sites in central german river valleys. species composition, environmental variables, past and current management, and the distance to source populations of characteristic species of traditional management (indicator species) were recorded and compared using multivariate statistics. we further tested the speed of colonization by two indicator species, silaum silaus and serratula tinctoria , along transects from source populations into unoccupied fields. 4. the species composition of the successional grassland was mainly determined by elevation, total soil nitrogen, distance to remnant species-rich grasslands and frequency of mowing or grazing. elevation and distance were negatively, and frequency was positively related to the occurrence of late successional species. 5. colonization by indicator species was only dependent on the distance to source populations; other explanatory variables were not significant. migration from adjacent source sites of s. silaus and s. tinctoria into re-converted grasslands was slow, reaching only 40 m and 15 m after 15 years. 6. synthesis and applications . the results demonstrated the limitations of the deterministic view on plant succession and the high relative importance of propagule availability in grassland restoration. natural colonization will only be successful if source populations of the target species are adjacent to the restoration sites. artificial introduction techniques are recommended to overcome dispersal barriers.",
            "contribution_ids": [
                "R54968"
            ]
        },
        {
            "instance_id": "R55219xR54981",
            "comparison_id": "R55219",
            "paper_id": "R54981",
            "text": "Dealing with scarce data to understand how environmental gradients and propagule pressure shape fine-scale alien distribution patterns on coastal dunes questions: on sandy coastal habitats, factors related to substrate and to wind action vary along the sea\u2013inland ecotone, forming a marked directional disturbance and stress gradient. further, input of propagules of alien plant species associated to touristic exploitation and development is intense. this has contributed to establishment and spread of aliens in coastal systems. records of alien species in databases of such heterogeneous landscapes remain scarce, posing a challenge for statistical modelling. we address this issue and attempt to shed light on the role of environmental stress/disturbance gradients and propagule pressure on invasibility of plant communities in these typical model systems. \\n \\nlocation: sandy coasts of lazio (central italy). \\n \\nmethods: we proposed an innovative methodology to deal with low prevalence of alien occurrence in a data set and high cost of field-based sampling by taking advantage, through predictive modelling, of the strong interrelation between vegetation and abiotic features in coastal dunes. we fitted generalized additive models to analyse (1) overall patterns of alien occurrence and spread and (2) specific patterns of the most common alien species recorded. \\n \\nconclusion: even in the presence of strong propagule pressure, variation in local abiotic conditions can explain differences in invasibility within a local environment, and intermediate levels of natural disturbance and stress offer the best conditions for spread of alien species. however, in our model system, propagule pressure is actually the main determinant of alien species occurrence and spread. we demonstrated that extending the information of environmental features measured in a subsample of vegetation plots through predictive modelling allows complex questions in invasion biology to be addressed without requiring disproportionate funding and sampling effort.",
            "contribution_ids": [
                "R54982",
                "R54983"
            ]
        },
        {
            "instance_id": "R55219xR54989",
            "comparison_id": "R55219",
            "paper_id": "R54989",
            "text": "Effects of pre-existing submersed vegetation and propagule pressure on the invasion success of Hydrilla verticillata summary \\n \\n \\n1 \\nwith biological invasions causing widespread problems in ecosystems, methods to curb the colonization success of invasive species are needed. the effective management of invasive species will require an integrated approach that restores community structure and ecosystem processes while controlling propagule pressure of non-native species. \\n \\n2 \\nwe tested the hypotheses that restoring native vegetation and minimizing propagule pressure of invasive species slows the establishment of an invader. in field and greenhouse experiments, we evaluated (i) the effects of a native submersed aquatic plant species, vallisneria americana, on the colonization success of a non-native species, hydrilla verticillata; and (ii) the effects of h. verticillata propagule density on its colonization success. \\n \\n3 \\nresults from the greenhouse experiment showed that v. americana decreased h. verticillata colonization through nutrient draw-down in the water column of closed mesocosms, although data from the field experiment, located in a tidal freshwater region of chesapeake bay that is open to nutrient fluxes, suggested that v. americana did not negatively impact h. verticillata colonization. however, h. verticillata colonization was greater in a treatment of plastic v. americana look-alikes, suggesting that the canopy of v. americana can physically capture h. verticillata fragments. thus pre-emption effects may be less clear in the field experiment because of complex interactions between competitive and facilitative effects in combination with continuous nutrient inputs from tides and rivers that do not allow nutrient draw-down to levels experienced in the greenhouse. \\n \\n4 \\ngreenhouse and field tests differed in the timing, duration and density of propagule inputs. however, irrespective of these differences, propagule pressure of the invader affected colonization success except in situations when the native species could draw-down nutrients in closed greenhouse mesocosms. in that case, no propagules were able to colonize. \\n \\n5 \\nsynthesis and applications. we have shown that reducing propagule pressure through targeted management should be considered to slow the spread of invasive species. this, in combination with restoration of native species, may be the best defence against non-native species invasion. thus a combined strategy of targeted control and promotion of native plant growth is likely to be the most sustainable and cost-effective form of invasive species management.",
            "contribution_ids": [
                "R54990",
                "R54991"
            ]
        },
        {
            "instance_id": "R55219xR54998",
            "comparison_id": "R55219",
            "paper_id": "R54998",
            "text": "COMPETITION BETWEEN NATIVE PERENNIAL AND EXOTIC ANNUAL GRASSES: IMPLICATIONS FOR AN HISTORICAL INVASION \"though established populations of invasive species can exert substantial competitive effects on native populations, exotic propagules may require disturbances that decrease competitive interference by resident species in order to become established. we compared the relative competitiveness of native perennial and exotic annual grasses in a california coastal prairie grassland to test whether the introduction of exotic propagules to coastal grasslands in the 19th century was likely to have been sufficient to shift community composition from native perennial to exotic annual grasses. under experimental field con- ditions, we compared the aboveground productivity of native species alone to native species competing with exotics, and exotic species alone to exotic species competing with natives. over the course of the four-year experiment, native grasses became increasingly dominant in the mixed-assemblage plots containing natives and exotics. although the competitive interactions in the first growing season favored the exotics, over time the native grasses significantly reduced the productivity of exotic grasses. the number of exotic seedlings emerging and the biomass of dicot seedlings removed during weeding were also significantly lower in plots containing natives as compared to plots that did not contain natives. we found evidence that the ability of established native perennial species to limit space available for exotic annual seeds to germinate and to limit the light available to exotic seedlings reduced exotic productivity and shifted competitive interactions in favor of the natives. if interactions between native perennial and exotic annual grasses follow a similar pattern in other coastal grassland habitats, then the introduction of exotic grass propagules alone without changes in land use or climate, or both, was likely insufficient to convert the region's grasslands.\"",
            "contribution_ids": [
                "R54999"
            ]
        },
        {
            "instance_id": "R55219xR55030",
            "comparison_id": "R55219",
            "paper_id": "R55030",
            "text": "GRASSLAND DIVERSITY AND PRODUCTIVITY: THE INTERPLAY OF RESOURCE AVAILABILITY AND PROPAGULE POOLS processes operating at multiple spatial scales govern the structure and functioning of ecological communities. we conducted a resource manipulation and propagule addition experiment in grassland to evaluate the interaction of local resource availability and propagule pools in governing local-scale plant colonization, biodiversity, and aboveground productivity. the availabilities of establishment microsites and water were manipulated in field plots for two years through the application of experimental soil disturbances and irrigation, respectively. resource manipulations led to increased invasibility of the community, as predicted by the theory of fluctuating resources. rates of colonization, enhanced by the sowing of 32 grassland species, increased plant diversity and aboveground productivity, but to a greater extent under conditions of resource enrichment. although resource enrichment generally increased diversity and productivity, these responses were contingent upon species availability and tended to be more pronounced in the presence of an expanded propagule pool. these findings suggest that biodiversity at the level of the available propagule pool and fluctuations in resources interact to regulate local resident diversity and productivity by determining opportunities for species sorting, by mediating community assembly, and by governing the potential for functional compensation in the community.",
            "contribution_ids": [
                "R55031"
            ]
        },
        {
            "instance_id": "R55219xR55074",
            "comparison_id": "R55219",
            "paper_id": "R55074",
            "text": "Predicting invasions by woody species in a temperate zone: a test of three risk assessment schemes in the Czech Republic (Central Europe) to assess the validity of previously developed risk assessment schemes in the conditions of central europe, we tested (1) australian weed risk assessment scheme (wra; pheloung et al. 1999); (2) wra with additional analysis by daehler et al. (2004); and (3) decision tree scheme of reichard and hamilton (1997) developed in north america, on a data set of 180 alien woody species commonly planted in the czech republic. this list included 17 invasive species, 9 naturalized but non\u2010invasive, 31 casual aliens, and 123 species not reported to escape from cultivation. the wra model with additional analysis provided best results, rejecting 100% of invasive species, accepting 83.8% of non\u2010invasive, and recommending further 13.0% for additional analysis. overall accuracy of the wra model with additional analysis was 85.5%, higher than that of the basic wra scheme (67.9%) and the reichard\u2013hamilton model (61.6%). only the reichard\u2013hamilton scheme accepted some invaders. the probability that an accepted species will become an invader was zero for both wra models and 3.2% for the reichard\u2013hamilton model. the probability that a rejected species would have been an invader was 77.3% for both wra models and 24.0% for the reichard\u2013hamilton model. it is concluded that the wra model, especially with additional analysis, appears to be a promising template for building a widely applicable system for screening out invasive plant introductions.",
            "contribution_ids": [
                "R55075",
                "R57005",
                "R57006",
                "R57007"
            ]
        },
        {
            "instance_id": "R55219xR55076",
            "comparison_id": "R55219",
            "paper_id": "R55076",
            "text": "The relative importance of latitude matching and propagule pressure in the colonization success of an invasive forb \"factors that influence the early stages of invasion can be critical to invasion success, yet are seldom studied. in particular, broad pre-adaptation to recipient climate may importantly influence early colonization success, yet few studies have explicitly examined this. i performed an experiment to determine how similarity between seed source and transplant site latitude, as a general indicator of pre-adaptation to climate, interacts with propagule pressure (100, 200 and 400 seeds/pot) to influence early colonization success of the widespread north american weed, st. john's wort hypericum perforatum. seeds originating from seven native european source populations were sown in pots buried in the ground in a field in western montana. seed source populations were either similar or divergent in latitude to the recipient transplant site. across seed density treatments, the match between seed source and recipient latitude did not affect the proportion of pots colonized or the number of individual colonists per pot. in contrast, propagule pressure had a significant and positive effect on colonization. these results suggest that propagules from many climatically divergent source populations can be viable invaders.\"",
            "contribution_ids": [
                "R55077"
            ]
        },
        {
            "instance_id": "R55219xR55083",
            "comparison_id": "R55219",
            "paper_id": "R55083",
            "text": "ALIEN FISHES IN CALIFORNIA WATERSHEDS: CHARACTERISTICS OF SUCCESSFUL AND FAILED INVADERS the literature on alien animal invaders focuses largely on successful invasions over broad geographic scales and rarely examines failed invasions. as a result, it is difficult to make predictions about which species are likely to become successful invaders or which environments are likely to be most susceptible to invasion. to address these issues, we developed a data set on fish invasions in watersheds throughout california (usa) that includes failed introductions. our data set includes information from three stages of the invasion process (establishment, spread, and integration). we define seven categorical predictor variables (trophic status, size of native range, parental care, maximum adult size, physiological tolerance, distance from nearest native source, and propagule pressure) and one continuous predictor variable (prior invasion success) for all introduced species. using an information-theoretic approach we evaluate 45 separate hypotheses derived from the invasion literature over these three sta...",
            "contribution_ids": [
                "R55084"
            ]
        },
        {
            "instance_id": "R55219xR55095",
            "comparison_id": "R55219",
            "paper_id": "R55095",
            "text": "The effect of propagule size on the invasion of an alien insect \"1. the movement of species from their native ranges to alien environments is a serious threat to biological diversity. the number of individuals involved in an invasion provides a strong theoretical basis for determining the likelihood of establishment of an alien species. 2. here a field experiment was used to manipulate the critical first stages of the invasion of an alien insect, a psyllid weed biocontrol agent, arytainilla spartiophila forster, in new zealand and to observe the progress of the invasion over the following 6 years. 3. fifty-five releases were made along a linear transect 135 km long: 10 releases of two, four, 10, 30 and 90 psyllids and five releases of 270 psyllids. six years after their original release, psyllids were present in 22 of the 55 release sites. analysis by logistic regression showed that the probability of establishment was significantly and positively related to initial release size, but that this effect was important only during the psyllids' first year in the field. 4. although less likely to establish, some of the releases of two and four psyllids did survive 5 years in the field. overall, releases that survived their first year had a 96% chance of surviving thereafter, providing the release site remained secure. the probability of colony loss due to site destruction remained the same throughout the experiment, whereas the probability of natural extinction reduced steeply over time. 5. during the first year colonies were undergoing a process of establishment and, in most cases, population size decreased. after this first year, a period of exponential growth ensued. 6. a lag period was observed before the populations increased dramatically in size. this was thought to be due to inherent lags caused by the nature of population growth, which causes the smaller releases to appear to have a longer lag period.\"",
            "contribution_ids": [
                "R55096"
            ]
        },
        {
            "instance_id": "R55219xR55122",
            "comparison_id": "R55219",
            "paper_id": "R55122",
            "text": "Behavioural plasticity associated with propagule size, resources, and the invasion success of the Argentine ant Linepithema humile summary 1. the number of individuals involved in an invasion event, or \u2018propagule size\u2019, has a strong theoretical basis for influencing invasion success. however, rarely has propagule size been experimentally manipulated to examine changes in invader behaviour, and propagule longevity and success. 2. we manipulated propagule size of the invasive argentine ant linepithema humile in laboratory and field studies. laboratory experiments involved l. humile propagules containing two queens and 10, 100, 200 or 1000 workers. propagules were introduced into arenas containing colonies of queens and 200 workers of the competing native ant monomorium antarcticum . the effects of food availability were investigated via treatments of only one central resource, or 10 separated resources. field studies used similar colony sizes of l. humile , which were introduced into novel environments near an invasion front. 3. in laboratory studies, small propagules of l. humile were quickly annihilated. only the larger propagule size survived and killed the native ant colony in some replicates. aggression was largely independent of food availability, but the behaviour of l. humile changed substantially with propagule size. in larger propagules, aggressive behaviour was significantly more frequent, while l. humile were much more likely to avoid conflict in smaller propagules. 4. in field studies, however, propagule size did not influence colony persistence. linepithema humile colonies persisted for up to 2 months, even in small propagules of 10 workers. factors such as temperature or competitor abundance had no effect, although some colonies were decimated by m. antarcticum . 5. synthesis and applications. although propagule size has been correlated with invasion success in a wide variety of taxa, our results indicate that it will have limited predictive power with species displaying behavioural plasticity. we recommend that aspects of animal behaviour be given much more consideration in attempts to model invasion success. secondly, areas of high biodiversity are thought to offer biotic resistance to invasion via the abundance of predators and competitors. invasive pests such as l. humile appear to modify their behaviour according to local conditions, and establishment was not related to resource availability. we cannot necessarily rely on high levels of native biodiversity to repel invasions.",
            "contribution_ids": [
                "R55123",
                "R55124"
            ]
        },
        {
            "instance_id": "R55219xR55150",
            "comparison_id": "R55219",
            "paper_id": "R55150",
            "text": "Propagule pressure and colony social organization are associated with the successful invasion and rapid range expansion of fire ants in China we characterized patterns of genetic variation in populations of the fire ant solenopsis invicta in china using mitochondrial dna sequences and nuclear microsatellite loci to test predictions as to how propagule pressure and subsequent dispersal following establishment jointly shape the invasion success of this ant in this recently invaded area. fire ants in wuchuan (guangdong province) are genetically differentiated from those found in other large infested areas of china. the immediate source of ants in wuchuan appears to be somewhere near texas, which ranks first among the southern usa infested states in the exportation of goods to china. most colonies from spatially distant, outlying areas in china are genetically similar to one another and appear to share a common source (wuchuan, guangdong province), suggesting that long\u2010distance jump dispersal has been a prevalent means of recent spread of fire ants in china. furthermore, most colonies at outlier sites are of the polygyne social form (featuring multiple egg\u2010laying queens per nest), reinforcing the important role of this social form in the successful invasion of new areas and subsequent range expansion following invasion. several analyses consistently revealed characteristic signatures of genetic bottlenecks for s. invicta populations in china. the results of this study highlight the invasive potential of this pest ant, suggest that the magnitude of international trade may serve as a predictor of propagule pressure and indicate that rates and patterns of subsequent range expansion are partly determined by the interplay between species traits and the trade and transportation networks.",
            "contribution_ids": [
                "R55151"
            ]
        },
        {
            "instance_id": "R56110xR56080",
            "comparison_id": "R56110",
            "paper_id": "R56080",
            "text": "The island biogeography of exotic bird species aim: a recent upsurge of interest in the island biogeography of exotic species has followed from the argument that they may provide valuable information on the natural processes structuring island biotas. here, we use data on the occurrence of exotic bird species across oceanic islands worldwide to demonstrate an alternative and previously untested hypothesis that these distributional patterns are a simple consequence of where humans have released such species, and hence of the number of species released. location: islands around the world. methods: statistical analysis of published information on the numbers of exotic bird species introduced to, and established on, islands around the world. results: established exotic birds showed very similar species-area relationships to native species, but different species-isolation relationships. however, in both cases the relationship for established exotics simply mimicked that for the number of exotic bird species introduced. exotic bird introductions scaled positively with human population size and island isolation, and islands that had seen more native species extinctions had had more exotic species released. main conclusion: the island biogeography of exotic birds is primarily a consequence of human, rather than natural, processes. \u00a9 2007 the authors journal compilation \u00a9 2007 blackwell publishing ltd.",
            "contribution_ids": [
                "R56081"
            ]
        },
        {
            "instance_id": "R56945xR56537",
            "comparison_id": "R56945",
            "paper_id": "R56537",
            "text": "Widespread association of the invasive ant Solenopsis invicta with an invasive mealybug \"factors such as aggressiveness and adaptation to disturbed environments have been suggested as important characteristics of invasive ant species, but diet has rarely been considered. however, because invasive ants reach extraordinary densities at introduced locations, increased feeding efficiency or increased exploitation of new foods should be important in their success. earlier studies suggest that honeydew produced by homoptera (e.g., aphids, mealybugs, scale insects) may be important in the diet of the invasive ant species solenopsis invicta. to determine if this is the case, we studied associations of s. invicta and homoptera in east texas and conducted a regional survey for such associations throughout the species' range in the southeast united states. in east texas, we found that s. invicta tended ho- moptera extensively and actively constructed shelters around them. the shelters housed a variety of homoptera whose frequency differed according to either site location or season, presumably because of differences in host plant availability and temperature. overall, we estimate that the honeydew produced in homoptera shelters at study sites in east texas could supply nearly one-half of the daily energetic requirements of an s. invicta colony. of that, 70% may come from a single species of invasive homoptera, the mealybugantonina graminis. homoptera shelters were also common at regional survey sites and a. graminis occurred in shelters at nine of 11 survey sites. a comparison of shelter densities at survey sites and in east texas suggests that our results from east texas could apply throughout the range of s. invicta in the southeast united states. antonina graminis may be an ex- ceptionally important nutritional resource for s. invicta in the southeast united states. while it remains largely unstudied, the tending of introduced or invasive homoptera also appears important to other, and perhaps all, invasive ant species. exploitative or mutually beneficial associations that occur between these insects may be an important, previously unrecognized factor promoting their success.\"",
            "contribution_ids": [
                "R56538"
            ]
        },
        {
            "instance_id": "R56945xR56541",
            "comparison_id": "R56945",
            "paper_id": "R56541",
            "text": "Seed and seedling demography of invasive and native trees of subtropical Pacific islands abstract bischofia javanica is an invasive tree of the bonin islands in the western pacific, japan. this species has aggressive growth, competitively replacing native trees in the natural forest of the islands. the aim of this study was to examine seed and seedling factors which might confer an advantage to the establishment of bischofia over native trees. during a 5-yr period we compared the demographic parameters of early life history of bischofia and elaeocarpus photiniaefolius, a native canopy dominant, in actively invaded forests. predation of elaeocarpus seeds by in troduced rodents was much higher before (27.9\u201332.9%) and after (41.3\u2013100%) dispersal of seeds than that of b. javanica. most elaeocarpus seeds lost viability ca. 6 mo after burial in forest soil while some seeds of bischofia remained viable for more than 2 yr. seedling survival in the first 2 yr was much higher in bischofia (16%) than in elaeocarpus (1.3%). the high persistence of bischofia in the shade, coupled to its rapid acclimation to high light levels, is an unusual combination because in forest tree species there is generally a trade-off between seedling survival in the shade and response to canopy opening. compared with a native canopy dominant, greater seed longevity, lower seed predation by introduced rodents, longer fruiting periods and the ability to form seedling banks under closed canopy appear to have contributed to the invasive success of bischofia on the bonin islands. nomenclature: satake et al. (1989).",
            "contribution_ids": [
                "R56542"
            ]
        },
        {
            "instance_id": "R56945xR56563",
            "comparison_id": "R56945",
            "paper_id": "R56563",
            "text": "Positive interactions between nonindigenous species facilitate transport by human vectors numerous studies have shown how interactions between nonindigenous spe- cies (nis) can accelerate the rate at which they establish and spread in invaded habitats, leading to an \"invasional meltdown.\" we investigated facilitation at an earlier stage in the invasion process: during entrainment of propagules in a transport pathway. the introduced bryozoan watersipora subtorquata is tolerant of several antifouling biocides and a common component of hull-fouling assemblages, a major transport pathway for aquatic nis. we predicted that colonies of w. subtorquata act as nontoxic refugia for other, less tolerant species to settle on. we compared rates of recruitment of w. subtorquata and other fouling organisms to surfaces coated with three antifouling paints and a nontoxic primer in coastal marinas in queensland, australia. diversity and abundance of fouling taxa were compared between bryozoan colonies and adjacent toxic or nontoxic paint surfaces. after 16 weeks immersion, w. subtorquata covered up to 64% of the tile surfaces coated in antifouling paint. twenty-two taxa occurred exclusively on w. subtorquata and were not found on toxic surfaces. other fouling taxa present on toxic surfaces were up to 248 times more abundant on w. subtorquata. because biocides leach from the paint surface, we expected a positive relationship between the size of w. subtorquata colonies and the abundance and diversity of epibionts. to test this, we compared recruitment of fouling organisms to mimic w. subtorquata colonies of three different sizes that had the same total surface area. sec- ondary recruitment to mimic colonies was greater when the surrounding paint surface contained biocides. contrary to our predictions, epibionts were most abundant on small mimic colonies with a large total perimeter. this pattern was observed in encrusting and erect bryozoans, tubiculous amphipods, and serpulid and sabellid polychaetes, but only in the presence of toxic paint. our results show that w. subtorquata acts as a foundation species for fouling assemblages on ship hulls and facilitates the transport of other species at greater abundance and frequency than would otherwise be possible. invasion success may be increased by positive interactions between nis that enhance the delivery of prop- agules by human transport vectors.",
            "contribution_ids": [
                "R56564"
            ]
        },
        {
            "instance_id": "R56945xR56565",
            "comparison_id": "R56945",
            "paper_id": "R56565",
            "text": "Invasional meltdown potential: Facilitation between introduced plants and mammals on French Mediterranean islands abstract in the increasingly important domain of insular invasion ecology, the role of facilitation between different introduced taxa has been mentioned, but rarely studied. this paper outlines facilitation between introduced mammals and the invasive succulents carpobrotus edulis and c. aff. acinaciformis on offshore islands in southeast france. rats and rabbits are the primary seed dispersers of carpobrotus sp. on the islands studied. no such dispersal activity was detected on the adjacent mainland. seed digestion by rats and rabbits also enhanced percent seed germination and speed, in spite of an associated reduction in seed size. in return, carpobrotus provides a water/energy-rich food source during the dry summer season, thus demonstrating a clear case of mutualism between invaders.",
            "contribution_ids": [
                "R56566"
            ]
        },
        {
            "instance_id": "R56945xR56608",
            "comparison_id": "R56945",
            "paper_id": "R56608",
            "text": "Facilitation and interference underlying the association between the woody invaders Pyracantha angustifolia and Ligustrum lucidum abstract questions: 1. is there any post-dispersal positive effect of the exotic shrub pyracantha angustifolia on the success of ligustrum lucidum seedlings, as compared to the effect of the native condalia montana or the open herbaceous patches between shrubs? 2. is the possible facilitation by pyracantha and/or condalia related to differential emergence, growth, or survival of ligustrum seedlings under their canopies? location: c\u00f3rdoba, central argentina. methods: we designed three treatments, in which ten mature individuals of pyracantha, ten of the dominant native shrub condalia montana, and ten patches without shrub cover were involved. in each treatment we planted seeds and saplings of ligustrum collected from nearby natural populations. seedlings emerging from the planted seeds were harvested after one year to measure growth. survival of the transplanted saplings was recorded every two month during a year. half of the planted seeds and transplanted saplings were cage-protected from rodents. results: ligustrum seedling emergence did not differ among treatments while growth was significantly higher in the absence of shrub cover. sapling survival was significantly higher under the canopy of pyracantha, intermediate under condalia, and lowest in the absence of shrub cover. caging did not affect growth but enhanced seedling emergence and sapling survival. conclusion: the differential sapling survival in the shrub canopy treatments is consistent with natural sapling distribution. pyracantha and, less so, condalia, has a nurse-plant effect on ligustrum. this results from contrasting effects of the shrubs on different stages of the life cycle of ligustrum: no effect on seedling emergence, negative on seedling growth, and positive on sapling survival. this suggests that efforts to control the expansion of ligustrum over the landscape should tackle pyracantha as well. nomenclature: zuloaga & morrone (1996, 1999).",
            "contribution_ids": [
                "R56609"
            ]
        },
        {
            "instance_id": "R56945xR56680",
            "comparison_id": "R56945",
            "paper_id": "R56680",
            "text": "Intra-regional transportation of a tugboat fouling community between the ports of Recife and Natal, northeast Brazil \" this study aimed to identify the incrusting and sedentary animals associated with the hull of a tugboat active in the ports of pernambuco and later loaned to the port of natal, rio grande do norte. thus, areas with dense biofouling were scraped and the species then classified in terms of their bioinvasive status for the brazilian coast. six were native to brazil, two were cryptogenic and 16 nonindigenous; nine of the latter were classified as established (musculus lateralis, sphenia fragilis, balanus trigonus, biflustra savartii, botrylloides nigrum, didemnum psammatodes, herdmania pallida, microscosmus exasperatus, and symplegma rubra) and three as invasive (mytilopsis leucophaeta, amphibalanus reticulatus, and striatobalanus amaryllis). the presence of m. leucophaeata, amphibalanus eburneus and a. reticulatus on the boat's hull propitiated their introduction onto the natal coast. the occurrence of a great number of tunicate species in natal reflected the port area's benthic diversity and facilitated the inclusion of two bivalves - musculus lateralis and sphenia fragilis - found in their siphons and in the interstices between colonies or individuals, respectively. the results show the role of biofouling on boat hulls in the introduction of nonindigenous species and that the port of recife acts as a source of some species. \"",
            "contribution_ids": [
                "R56681"
            ]
        },
        {
            "instance_id": "R56945xR56732",
            "comparison_id": "R56945",
            "paper_id": "R56732",
            "text": "Identification of alien predators that should not be removed for controlling invasive crayfish threatening endangered odonates 1. \\nwhen multiple invasive species coexist in the same ecosystem and their diets change as they grow, determining whether to eradicate any particular invader is difficult because of complex predator\u2013prey interactions. \\n \\n2. \\na stable isotope food-web analysis was conducted to explore an appropriate management strategy for three potential alien predators (snakehead channa argus, bullfrog rana catesbeiana, red-eared slider turtle trachemys scripta elegans) of invasive crayfish procambarus clarkii that had severely reduced the densities of endangered odonates in a pond in japan. \\n \\n3. \\nthe stable isotope analysis demonstrated that medium- and small-sized snakeheads primarily depended on crayfish and stone moroko pseudorasbora parva. both adult and juvenile bullfrogs depended on terrestrial arthropods, and juveniles exhibited a moderate dependence on crayfish. the turtle showed little dependence on crayfish. \\n \\n4. \\nthese results suggest that eradication of snakeheads risks the possibility of mesopredator release, while such risk appears to be low in other alien predators. copyright \u00a9 2011 john wiley & sons, ltd.",
            "contribution_ids": [
                "R56733"
            ]
        },
        {
            "instance_id": "R56945xR56756",
            "comparison_id": "R56945",
            "paper_id": "R56756",
            "text": "Does mutualism drive the invasion of two alien species? The case of Solenopsis invicta and Phenacoccus solenopsis although mutualism between ants and honeydew-producing hemipterans has been extensively recognized in ecosystem biology, however few attempts to test the hypothesis that mutualism between two alien species leads to the facilitation of the invasion process. to address this problem, we focus on the conditional mutualism between s. invicta and p. solenopsis by field investigations and indoor experiments. in the laboratory, ant colony growth increased significantly when ants had access to p. solenopsis and animal-based food. honeydew produced by p. solenopsis also improved the survival of ant workers. in the field, colony density of p. solenopsis was significantly greater on plots with ants than on plots without ants. the number of mealybug mummies on plants without fire ants was almost three times that of plants with fire ants, indicating a strong effect of fire ants on mealybug survival. in addition, the presence of s. invicta successfully contributed to the spread of p. solenopsis. the quantity of honeydew consumption by s. invicta was significantly greater than that of a presumptive native ant, tapinoma melanocephalum. when compared with the case without ant tending, mealybugs tended by ants matured earlier and their lifespan and reproduction increased. t. melanocephalum workers arrived at honeydew more quickly than s. invicta workers, while the number of foraging s. invicta workers on plants steadily increased, eventually exceeding that number of t. melanocephalum foragers. overall, these results suggest that the conditional mutualism between s. invicta and p. solenopsis facilitates population growth and fitness of both species. s. invicta tends to acquire much more honeydew and drive away native ants, promoting their predominance. these results suggest that the higher foraging tempo of s. invicta may provide more effective protection of p. solenopsis than native ants. thus mutualism between these two alien species may facilitate the invasion success of both species.",
            "contribution_ids": [
                "R56757"
            ]
        },
        {
            "instance_id": "R56945xR56762",
            "comparison_id": "R56945",
            "paper_id": "R56762",
            "text": "An invasive tree alters the structure of seed dispersal networks between birds and plants in French Polynesia aim\\u2002 we studied how the abundance of the highly invasive fruit\u2010bearing tree miconia calvescens dc. influences seed dispersal networks and the foraging patterns of three avian frugivores.",
            "contribution_ids": [
                "R56763"
            ]
        },
        {
            "instance_id": "R56945xR56795",
            "comparison_id": "R56945",
            "paper_id": "R56795",
            "text": "Invasive parasites in multiple invasive hosts: the arrival of a new host revives a stalled prior parasite invasion \"the success of a biological invasion can depend upon other invasions; and in some cases, an earlier invader may fail to spread until facilitated by a second invader. our study documents a case whereby an invasive parasite has remained patchily distributed for decades due to the fragmented nature of available hosts; but the recent arrival of a broadly distributed alternative invasive host species provides an opportunity for the parasite to expand its range considerably. at least 20 years ago, endoparasitic pentastomids (raillietiella frenata) were brought with their native host, the invasive asian house gecko hemidactylus frenatus, to the port city of darwin in tropical australia. these geckos rarely disperse away from human habitation, restricting the transmission of their parasites to urban environments \u2013 and thus, their pentastomids have remained patchily distributed and have only been recorded in scant localities, primarily surrounding darwin. the recent range expansion of the invasive cane toad rhinella marina into the darwin area has provided an alternative host for this pentastomid. our results show that the cane toad is a competent host for ra. frenata\u2013 toads shed fully embryonated pentastomid eggs in their faeces \u2013 and that pentastomids are now common in cane toads near darwin. likely reflecting the tendency for the parasite's traditional definitive host (the asian house gecko) and only known intermediate host (the cockroach) to reside around buildings, we found the prevalence of this parasite follows an urban distribution. because cane toads are widely distributed through urban and rural habitat and can shed viable pentastomid eggs, the toad invasion is likely to facilitate the parasite's spread across the tropics, into areas (and additional susceptible hosts) that were previously inaccessible to it.\"",
            "contribution_ids": [
                "R56796"
            ]
        },
        {
            "instance_id": "R56945xR56849",
            "comparison_id": "R56945",
            "paper_id": "R56849",
            "text": "The effects of mice on stoats in southern beech forests introduced stoats (mustela erminea) are important invasive predators in southern beech (nothofagus sp.) forests in new zealand. in these forests, one of their primary prey species \u2013 introduced house mice (mus musculus), fluctuate dramatically between years, driven by the irregular heavy seed-fall (masting) of the beech trees. we examined the effects of mice on stoats in this system by comparing the weights, age structure and population densities of stoats caught on two large islands in fiordland, new zealand \u2013 one that has mice (resolution island) and one that does not (secretary island). on resolution island, the stoat population showed a history of recruitment spikes and troughs linked to beech masting, whereas the secretary island population had more constant recruitment, indicating that rodents are probably the primary cause for the \u2018boom and bust\u2019 population cycle of stoats in beech forests. resolutions island stoats were 10% heavier on average than secretary island stoats, supporting the hypothesis that the availability of larger prey (mice verses w\u0113t\u0101) leads to larger stoats. beech masting years on this island were also correlated with a higher weight for stoats born in the year of the masting event. the detailed demographic information on the stoat populations of these two islands supports previously suggested interactions among mice, stoats and beech masting. these interactions may have important consequences for the endemic species that interact with fluctuating populations of mice and stoats.",
            "contribution_ids": [
                "R56850"
            ]
        },
        {
            "instance_id": "R56945xR56907",
            "comparison_id": "R56945",
            "paper_id": "R56907",
            "text": "Novel species interactions in a highly modified estuary: association of largemouth bass with Brazilian waterweed Egeria densa abstractfrequent invasions in coastal ecosystems result in novel species interactions that have unknown ecological consequences. largemouth bass micropterus salmoides and brazilian waterweed egeria densa are introduced species in the sacramento\u2013san joaquin river delta (the delta) of california, a highly modified estuary. in this system, brazilian waterweed and largemouth bass have seen marked increases in distribution and abundance in recent decades, but their association has not been specifically studied until now. we conducted a 2-year, bimonthly electrofishing survey with simultaneous sampling of water quality and submerged aquatic vegetation (sav) biomass at 33 locations throughout the delta. we used generalized linear mixed models to assess the relative influences of water temperature, conductivity, secchi depth, and sav biomass density on the abundance of both juvenile-sized and larger largemouth bass. water temperature had a positive relationship with the abundance of both size-classes, but only ju...",
            "contribution_ids": [
                "R56908"
            ]
        },
        {
            "instance_id": "R56945xR56923",
            "comparison_id": "R56945",
            "paper_id": "R56923",
            "text": "Early life stages of exotic gobiids as new hosts for unionid glochidia summary \\nintroduction of an exotic species has the potential to alter interactions between fish and bivalves; yet our knowledge in this field is limited, not least by lack of studies involving fish early life stages (els). \\nhere, for the first time, we examine glochidial infection of fish els by native and exotic bivalves in a system recently colonised by two exotic gobiid species (round goby neogobius melanostomus, tubenose goby proterorhinus semilunaris) and the exotic chinese pond mussel anodonta woodiana. \\nthe els of native fish were only rarely infected by native glochidia. by contrast, exotic fish displayed significantly higher native glochidia prevalence and mean intensity of infection than native fish (17 versus 2% and 3.3 versus 1.4 respectively), inferring potential for a parasite spillback/dilution effect. exotic fish also displayed a higher parasitic load for exotic glochidia, inferring potential for invasional meltdown. compared to native fish, presence of gobiids increased the total number of glochidia transported downstream on drifting fish by approximately 900%. \\nwe show that gobiid els are a novel, numerous and \u2018attractive\u2019 resource for unionid glochidia. as such, unionids could negatively affect gobiid recruitment through infection-related mortality of gobiid els and/or reinforce downstream unionid populations through transport on drifting gobiid els. these implications go beyond what is suggested in studies of older life stages, thereby stressing the importance of an holistic ontogenetic approach in ecological studies.",
            "contribution_ids": [
                "R56924"
            ]
        },
        {
            "instance_id": "R56945xR56929",
            "comparison_id": "R56945",
            "paper_id": "R56929",
            "text": "Asiatic Callosciurus squirrels as seed dispersers of exotic plants in the Pampas abstract seed dispersal by exotic mammals exemplifies mutualistic interactions that can modify the habitat by facilitating the establishment of certain species. we examined the potential for endozoochoric dispersal of exotic plants by callosciurus erythraeus introduced in the pampas region of argentina. we identified and characterized entire and damaged seeds found in squirrel faeces and evaluated the germination capacity and viability of entire seeds in laboratory assays. we collected 120 samples of squirrel faeces that contained 883 pellets in seasonal surveys conducted between july 2011 and june 2012 at 3 study sites within the main invasion focus of c. erythraeus in argentina. we found 226 entire seeds in 21% of the samples belonging to 4 species of exotic trees and shrubs. germination in laboratory assays was recorded for morus alba and casuarina sp.; however, germination percentage and rate was higher for seeds obtained from the fruits than for seeds obtained from the faeces. the largest size of entire seeds found in the faeces was 4.2\\u2009\u00d7\\u20094.0\\u2009mm, whereas the damaged seeds had at least 1 dimension \u2265 4.7\\u2009mm. our results indicated that c. erythraeus can disperse viable seeds of at least 2 species of exotic trees. c. erythraeus predated seeds of other naturalized species in the region. the morphometric description suggested a restriction on the maximum size for the passage of entire seeds through the digestive tract of squirrels, which provides useful information to predict its role as a potential disperser or predator of other species in other invaded communities.",
            "contribution_ids": [
                "R56930"
            ]
        },
        {
            "instance_id": "R57101xR56949",
            "comparison_id": "R57101",
            "paper_id": "R56949",
            "text": "Biological control attempts by introductions against pest insects in the field in Canada abstract this is an analysis of the attempts to colonize at least 208 species of parasites and predators on about 75 species of pest insects in the field in canada. there was colonization by about 10% of the species that were introduced in totals of under 5,000 individuals, 40% of those introduced in totals of between 5,000 and 31,200, and 78% of those introduced in totals of over 31,200. indications exist that initial colonizations may be favoured by large releases and by selection of release sites that are semi-isolated and not ecologically complex but that colonizations are hindered when the target species differs taxonomically from the species from which introduced agents originated and when the release site lacks factors needed for introduced agents to survive or when it is subject to potentially-avoidable physical disruptions. there was no evidence that the probability of colonization was increased when the numbers of individuals released were increased by laboratory propagation. about 10% of the attempts were successful from the economic viewpoint. successes may be overestimated if the influence of causes of coincidental, actual, or supposed changes in pest abundance are overlooked. most of the successes were by two or more kinds of agents of which at least one attacked species additional to the target pests. unplanned consequences of colonization have not been sufficiently harmful to warrant precautions to the extent advocated by turnbull and chant but are sufficiently potentially dangerous to warrant the restriction of all colonization attempts to biological control experts. it is concluded that most failures were caused by inadequate procedures, rather than by any weaknesses inherent in the method, that those inadequacies can be avoided in the future, and therefore that biological control of pest insects has much unrealized potential for use in canada.",
            "contribution_ids": [
                "R56950"
            ]
        },
        {
            "instance_id": "R57101xR56951",
            "comparison_id": "R57101",
            "paper_id": "R56951",
            "text": "The potential impact of the New Zealand flatworm, a predator of earthworms, in western Europe \"the new zealand flatworm arthurdendyus triangulatus (=artioposthia triangulata) is an example of an invasive organism that, by reducing lumbricid earthworm populations, could have a major impact on soil ecosystems in britain and the faroe islands. how it was introduced into the british isles is not known, but like many invasive species, it is suspected that it was introduced by humans and was associated with the trade between new zealand and britain. once established in britain it found in the large, readily available earthworm population a niche that it could exploit. the microclimate of the forests in the center and south of the south island of new zealand from whence the flatworm came is similar to that in parts of the british isles and consequently conducive to its survival. although when compared with many other invertebrate introductions (e.g., insects) the flatworm's rate of increase has been slow, a retrospective study strongly suggested that, in scotland, they spread from botanic gardens to horti...\"",
            "contribution_ids": [
                "R56952"
            ]
        },
        {
            "instance_id": "R57101xR56959",
            "comparison_id": "R57101",
            "paper_id": "R56959",
            "text": "Interception frequency of exotic bark and ambrosia beetles (Coleoptera: Scolytinae) and relationship with establishment in New Zealand and worldwide \" scolytinae species are among the most damaging forest pests, and many of them are invasive. over 1500 scolytinae interceptions were recorded at new zealand's borders between 1950 and 2000. among the 103 species were dendroctonus ponderosae, ips typographus, and other high-risk species, but actual arrivals probably included many more species. interceptions were primarily associated with dunnage, casewood (crating), and sawn timber, and originated from 59 countries, mainly from europe, australasia, northern asia, and north america. new zealand and united states interception data were highly correlated, and 7 of the 10 most intercepted species were shared. interception frequency and establishment in new zealand were not clearly related. by combining new zealand and united states interceptions of true bark beetles we obtained data on species found in shipments from around the world. logistic regression analysis showed that frequently intercepted species were about four times as likely as rarely intercepted species to be established somewhere. interception records of wood and bark borers are valuable for the prediction of invaders and for our general understanding of invasions. the use of alternatives to solid wood packaging, such as processed wood, should be encouraged to reduce the spread of invasive wood and bark borers. \"",
            "contribution_ids": [
                "R56960"
            ]
        },
        {
            "instance_id": "R57101xR56990",
            "comparison_id": "R57101",
            "paper_id": "R56990",
            "text": "Alien aquatic plant species in European countries hussner a (2012). alien aquatic plant species in european countries. weed research52, 297\u2013306. \\n \\nsummary \\nalien aquatic plant species cause serious ecological and economic impacts to european freshwater ecosystems. this study presents a comprehensive overview of all alien aquatic plants in europe, their places of origin and their distribution within the 46 european countries. in total, 96 aquatic species from 30 families have been reported as aliens from at least one european country. most alien aquatic plants are native to northern america, followed by asia and southern america. elodea canadensis is the most widespread alien aquatic plant in europe, reported from 41 european countries. azolla filiculoides ranks second (25), followed by vallisneria spiralis (22) and elodea nuttallii (20). the highest number of alien aquatic plant species has been found in italy and france (34 species), followed by germany (27), belgium and hungary (both 26) and the netherlands (24). even though the number of alien aquatic plants seems relatively small, the european and mediterranean plant protection organization (eppo, http://www.eppo.org) has listed 18 of these species as invasive or potentially invasive within the eppo region. as ornamental trade has been regarded as the major pathway for the introduction of alien aquatic plants, trading bans seem to be the most effective option to reduce the risk of further unintended entry of alien aquatic plants into europe.",
            "contribution_ids": [
                "R56991"
            ]
        },
        {
            "instance_id": "R57101xR57000",
            "comparison_id": "R57101",
            "paper_id": "R57000",
            "text": "Ecological predictions and risk assessment for alien fishes in North America methods of risk assessment for alien species, especially for nonagricultural systems, are largely qualitative. using a generalizable risk assessment approach and statistical models of fish introductions into the great lakes, north america, we developed a quantitative approach to target prevention efforts on species most likely to cause damage. models correctly categorized established, quickly spreading, and nuisance fishes with 87 to 94% accuracy. we then identified fishes that pose a high risk to the great lakes if introduced from unintentional (ballast water) or intentional pathways (sport, pet, bait, and aquaculture industries).",
            "contribution_ids": [
                "R57001",
                "R57002"
            ]
        },
        {
            "instance_id": "R57101xR57028",
            "comparison_id": "R57101",
            "paper_id": "R57028",
            "text": "Accounting for differential success in the biological control of homopteran and lepidopteran pests one of the strongest patterns in the historical record of biological control is that programmes targeted against lepidopteran pests have been far less successful than those targeted against homopteran pests. despite fueling considerable interest in the theory of host-parasitoid interactions, biological control has few unifying principles and no theoretical basis for understanding the differential pattern of success against these two pest groups. potential explanations considered here include competitive limitation of natural enemy establishment, the influence of antagonistic parasitoid interactions, generation time ratio, and gregarious parasitoid development. an analysis of the biological control record showed that on average six natural enemies have been introduced per pest for both pest groups, providing no evidence of a differential intensity of competition. similarly, use of a discrete time host-parasitoid model showed that antagonistic interactions that are common among parasitoids of lepidoptera should not limit the success of biological control as such interactions can readily be counteracted by host refuge breaking. a similar model showed that a small generation time ratio (coupled with a broad window of host attack) and gregarious development can facilitate the suppression of pest abundance by parasitoids, and both were found to be positively associated with success in the biological control record. of the four explanations considered here, generation time ratio coupled with a broad window of host attack appears to provide the best explanation for the differential pattern of success.",
            "contribution_ids": [
                "R57029"
            ]
        },
        {
            "instance_id": "R57101xR57067",
            "comparison_id": "R57101",
            "paper_id": "R57067",
            "text": "The role of opportunity in the unintentional introduction of nonnative ants a longstanding goal in the study of biological invasions is to predict why some species are successful invaders, whereas others are not. to understand this process, detailed information is required concerning the pool of species that have the opportunity to become established. here we develop an extensive database of ant species unintentionally transported to the continental united states and use these data to test how opportunity and species-level ecological attributes affect the probability of establishment. this database includes an amount of information on failed introductions that may be unparalleled for any group of unintentionally introduced insects. we found a high diversity of species (232 species from 394 records), 12% of which have become established in the continental united states. the probability of establishment increased with the number of times a species was transported (propagule pressure) but was also influenced by nesting habit. ground nesting species were more likely to become established compared with arboreal species. these results highlight the value of developing similar databases for additional groups of organisms transported by humans to obtain quantitative data on the first stages of the invasion process: opportunity and transport.",
            "contribution_ids": [
                "R57068",
                "R57069"
            ]
        },
        {
            "instance_id": "R57101xR57070",
            "comparison_id": "R57101",
            "paper_id": "R57070",
            "text": "A global meta-analysis of the ecological impacts of nonnative crayfish abstract.\\u2003 nonnative crayfish have been widely introduced and are a major threat to freshwater biodiversity and ecosystem functioning. despite documentation of the ecological effects of nonnative crayfish from >3 decades of case studies, no comprehensive synthesis has been done to test quantitatively for their general or species-specific effects on recipient ecosystems. we provide the first global meta-analysis of the ecological effects of nonnative crayfish under experimental settings to compare effects among species and across levels of ecological organization. our meta-analysis revealed strong, but variable, negative ecological impacts of nonnative crayfish with strikingly consistent effects among introduced species. in experimental settings, nonnative crayfish generally affect all levels of freshwater food webs. nonnative crayfish reduce the abundance of basal resources like aquatic macrophytes, prey on invertebrates like snails and mayflies, and reduce abundances and growth of amphibians and fish, but they do not consistently increase algal biomass. nonnative crayfish tend to have larger positive effects on growth of algae and larger negative effects on invertebrates and fish than native crayfish, but effect sizes vary considerably. our study supports the assessment of crayfish as strong interactors in food webs that have significant effects across native taxa via polytrophic, generalist feeding habits. nonnative crayfish species identity may be less important than extrinsic attributes of the recipient ecosystems in determining effects of nonnative crayfish. we identify some understudied and emerging nonnative crayfish that should be studied further and suggest expanding research to encompass more comparisons of native vs nonnative crayfish and different geographic regions. the consistent and general negative effects of nonnative crayfish warrant efforts to discourage their introduction beyond native ranges.",
            "contribution_ids": [
                "R57071"
            ]
        },
        {
            "instance_id": "R57501xR57133",
            "comparison_id": "R57501",
            "paper_id": "R57133",
            "text": "Functional group diversity, resource preemption and the genesis of invasion resistance in a community of marine algae \"although many studies have investigated how community characteristics such as diversity and disturbance relate to invasibility, the mechanisms underlying biotic resistance to introduced species are not well understood. i manipulated the functional group composition of native algal communities and invaded them with the introduced, japanese seaweed sargassum muticum to understand how individual functional groups contributed to overall invasion resistance. the results suggested that space preemption by crustose and turfy algae inhibited s. muticum recruitment and that light preemption by canopy and understory algae reduced s. muticum survivorship. however, other mechanisms i did not investigate could have contributed to these two results. in this marine community the sequential preemption of key resources by different functional groups in different stages of the invasion generated resistance to invasion by s. muticum. rather than acting collectively on a single resource the functional groups in this system were important for preempting either space or light, but not both resources. my experiment has important implications for diversity-invasibility studies, which typically look for an effect of diversity on individual resources. overall invasion resistance will be due to the additive effects of individual functional groups (or species) summed over an invader's life cycle. therefore, the cumulative effect of multiple functional groups (or species) acting on multiple resources is an alternative mechanism that could generate negative relationships between diversity and invasibility in a variety of biological systems.\"",
            "contribution_ids": [
                "R57134"
            ]
        },
        {
            "instance_id": "R57501xR57137",
            "comparison_id": "R57501",
            "paper_id": "R57137",
            "text": "Control of plant species diversity and community invasibility by species immigration: seed richness versus seed density brown, r. l. and fridley, j. d. 2003. control of plant species diversity andcommunity invasibility by species immigration: seed richness versus seed density. \u2013oikos 102: 15\u201324.immigration rates of species into communities are widely understood to in\ufb02uencecommunity diversity, which in turn is widely expected to in\ufb02uence the susceptibilityof ecosystems to species invasion. for a given community, however, immigrationprocesses may impact diversity by means of two separable components: the numberof species represented in seed inputs and the density of seed per species. theindependent effects of these components on plant species diversity and consequentrates of invasion are poorly understood. we constructed experimental plant commu-nities through repeated seed additions to independently measure the effects of seedrichness and seed density on the trajectory of species diversity during the develop-ment of annual plant communities. because we sowed species not found in theimmediate study area, we were able to assess the invasibility of the resultingcommunities by recording the rate of establishment of species from adjacent vegeta-tion. early in community development when species only weakly interacted, seedrichness had a strong effect on community diversity whereas seed density had littleeffect. after the plants became established, the effect of seed richness on measureddiversity strongly depended on seed density, and disappeared at the highest level ofseed density. the ability of surrounding vegetation to invade the experimentalcommunities was decreased by seed density but not by seed richness, primarilybecause the individual effects of a few sown species could explain the observedinvasion rates. these results suggest that seed density is just as important as seedrichness in the control of species diversity, and perhaps a more important determi-nant of community invasibility than seed richness in dynamic plant assemblages.",
            "contribution_ids": [
                "R57138"
            ]
        },
        {
            "instance_id": "R57501xR57171",
            "comparison_id": "R57501",
            "paper_id": "R57171",
            "text": "Invasion of exotic plant species in tallgrass prairie fragments abstract: the tallgrass prairie is one of the most severely affected ecosystems in north america. as a result of extensive conversion to agriculture during the last century, as little as 1% of the original tallgrass prairie remains. the remaining fragments of tallgrass prairie communities have conservation significance, but questions remain about their viability and importance to conservation. we investigated the effects of fragment size, native plant species diversity, and location on invasion by exotic plant species at 25 tallgrass prairie sites in central north america at various geographic scales. we used exotic species richness and relative cover as measures of invasion. exotic species richness and cover were not related to area for all sites considered together. there were no significant relationships between native species richness and exotic species richness at the cluster and regional scale or for all sites considered together. at the local scale, exotic species richness was positively related to native species richness at four sites and negatively related at one. the 10 most frequently occurring and abundant exotic plant species in the prairie fragments were cool\u2010season, or c3, species, in contrast to the native plant community, which was dominated by warm\u2010season, or c4, species. this suggests that timing is important to the success of exotic species in the tallgrass prairie. our study indicates that some small fragments of tallgrass prairie are relatively intact and should not be overlooked as long\u2010term refuges for prairie species, sources of genetic variability, and material for restoration.",
            "contribution_ids": [
                "R57172"
            ]
        },
        {
            "instance_id": "R57501xR57219",
            "comparison_id": "R57501",
            "paper_id": "R57219",
            "text": "Ecological filtering of exotic plants in an Australian sub-alpine environment abstract we investigated some of the factors influencing exotic invasion of native sub-alpine plant communities at a site in southeast australia. structure, floristic composition and invasibility of the plant communities and attributes of the invasive species were studied. to determine the plant characteristics correlated with invasiveness, we distinguished between roadside invaders, native community invaders and non-invasive exotic species, and compared these groups across a range of traits including functional group, taxonomic affinity, life history, mating system and morphology. poa grasslands and eucalyptus-poa woodlands contained the largest number of exotic species, although all communities studied appeared resilient to invasion by most species. most community invaders were broad-leaved herbs while roadside invaders contained both herbs and a range of grass species. over the entire study area the richness and cover of native and exotic herbaceous species were positively related, but exotic herbs were more negatively related to cover of specific functional groups (e.g. trees) than native herbs. compared with the overall pool of exotic species, those capable of invading native plant communities were disproportionately polycarpic, asteracean and cross-pollinating. our data support the hypothesis that strong ecological filtering of exotic species generates an exotic assemblage containing few dominant species and which functionally converges on the native assemblage. these findings contrast with those observed in the majority of invaded natural systems. we conclude that the invasion of closed sub-alpine communities must be viewed in terms of the unique attributes of the invading species, the structure and composition of the invaded communities and the strong extrinsic physical and climatic factors typical of the sub-alpine environment. nomenclature: australian plant name index (apni); http://www.anbg.gov.au/cgi-bin/apni abbreviations: knp = kosciuszko national park; mrpp = multi response permutation procedure; ve = variance explained.",
            "contribution_ids": [
                "R57220"
            ]
        },
        {
            "instance_id": "R57501xR57227",
            "comparison_id": "R57501",
            "paper_id": "R57227",
            "text": "Native Predators Do Not Influence Invasion Success of Pacific Lionfish on Caribbean Reefs biotic resistance, the process by which new colonists are excluded from a community by predation from and/or competition with resident species, can prevent or limit species invasions. we examined whether biotic resistance by native predators on caribbean coral reefs has influenced the invasion success of red lionfishes (pterois volitans and pterois miles), piscivores from the indo-pacific. specifically, we surveyed the abundance (density and biomass) of lionfish and native predatory fishes that could interact with lionfish (either through predation or competition) on 71 reefs in three biogeographic regions of the caribbean. we recorded protection status of the reefs, and abiotic variables including depth, habitat type, and wind/wave exposure at each site. we found no relationship between the density or biomass of lionfish and that of native predators. however, lionfish densities were significantly lower on windward sites, potentially because of habitat preferences, and in marine protected areas, most likely because of ongoing removal efforts by reserve managers. our results suggest that interactions with native predators do not influence the colonization or post-establishment population density of invasive lionfish on caribbean reefs.",
            "contribution_ids": [
                "R57228"
            ]
        },
        {
            "instance_id": "R57501xR57258",
            "comparison_id": "R57501",
            "paper_id": "R57258",
            "text": "Resource availability and plant diversity explain patterns of invasion of an exotic grass aims in this study, we examine two common invasion biology hypotheses\u2014 biotic resistance and fluctuating resource availability\u2014to explain the patterns of invasion of an invasive grass, microstegium vimineum. methods we used 13-year-old deer exclosures in great smoky mountains national park, usa, to examine how chronic disturbance by deer browsing affects available resources, plant diversity, and invasion in an understory plant community. using two replicate 1 m 2 plots in each deer browsed and unbrowsed area, we recorded each plant species present, the abundance per species, and the fractional per cent cover of vegetation by the cover classes: herbaceous, woody, and graminoid. for each sample plot, we also estimated overstory canopy cover, soil moisture, total soil carbon and nitrogen, and soil ph as a measure of abiotic differences between plots. important\\xa0findings we found that plant community composition between chronically browsed and unbrowsed plots differed markedly. plant diversity was 40% lower in browsed than in unbrowsed plots. at our sites, diver sity explained 48% and woody plant cover 35% of the variation in m. vimineum abundance. in addition, we found 3.3 times less m. vimineum in the unbrowsed plots due to higher woody plant cover and plant diversity than in the browsed plots. a\\xa0parsimonious explanation of these results indicate that disturbances such as herbivory may elicit multiple conditions, namely releasing available resources such as open space, light, and decreasing plant diversity, which may facilitate the proliferation of an invasive species. finally, by testing two different hypotheses, this study addresses more recent calls to incorporate multiple hypotheses into research attempting to explain plant invasion.",
            "contribution_ids": [
                "R57259"
            ]
        },
        {
            "instance_id": "R57501xR57271",
            "comparison_id": "R57501",
            "paper_id": "R57271",
            "text": "Negative native-exotic diversity relationship in oak savannas explained by human influence and climate recent research has proposed a scale-dependence to relationships between native diversity and exotic invasions. at fine spatial scales, native-exotic richness relationships should be negative as higher native richness confers resistance to invasion. at broad scales, relationships should be positive if natives and exotics respond similarly to extrinsic factors. yet few studies have examined both native and exotic richness patterns across gradients of human influence, where impacts could affect native and exotic species differently. we examined native-exotic richness relationships and extrinsic drivers of plant species richness and distributions across an urban development gradient in remnant oak savanna patches. in sharp contrast to most reported results, we found a negative relationship at the regional scale, and no relationship at the local scale. the negative regional-scale relationship was best explained by extrinsic factors, surrounding road density and climate, affecting natives and exotics in opposite ways, rather than a direct effect of native on exotic richness, or vice versa. models of individual species distributions also support the result that road density and climate have largely opposite effects on native and exotic species, although simple life history traits (life form, dispersal mode) do not predict which habitat characteristics are important for particular species. roads likely influence distributions and species richness by increasing both exotic propagule pressure and disturbance to native species. climate may partially explain the negative relationship due to differing climatic preferences within the native and exotic species pools. as gradients of human influence are increasingly common, negative broad-scale native-exotic richness relationships may be frequent in such landscapes.",
            "contribution_ids": [
                "R57272"
            ]
        },
        {
            "instance_id": "R57501xR57279",
            "comparison_id": "R57501",
            "paper_id": "R57279",
            "text": "Effects of a directional abiotic gradient on plant community dynamics and invasion in a coastal dune system 1 local abiotic factors are likely to play a crucial role in modifying the relative abundance of native and exotic species in plant communities. natural gradients provide an ideal opportunity to test this hypothesis. 2 in a coastal dune system in northern california, we used comparative and experimental studies to evaluate how a wind and soil texture gradient influences the relative abundance of native and exotic plant species in this community. 3 we detected small\u2010scale spatial variation in soil texture along a 200\u2010m gradient from relatively sheltered to more exposed. sand coarseness significantly increased with exposure while soil nitrate levels significantly decreased. the more extreme end of the gradient was also subject to greater wind speeds and less soil moisture. 4 the plant community consistently responded to this gradient in the 7 years censused. species richness decreased with exposure, cover of natives decreased and cover of exotics increased at the more extreme end of the gradient. 5 a single\u2010season wind\u2010shelter experiment similarly shifted the balance between native and exotic species. shelters decreased the relative density of exotic species and increased the relative density of natives regardless of position on the gradient. 6 these comparative and manipulative findings both suggest that a single factor, wind, at least partially explains the success of exotic species in a coastal dune plant community. this supports the hypothesis that local abiotic conditions can explain differences in invasibility within a plant community.",
            "contribution_ids": [
                "R57280"
            ]
        },
        {
            "instance_id": "R57501xR57305",
            "comparison_id": "R57501",
            "paper_id": "R57305",
            "text": "Patterns of invasion of an urban remnant of a species-rich grassland in southeastern Australia by non-native plant species . the invasion by non-native plant species of an urban remnant of a species-rich themeda triandra grassland in southeastern australia was quantified and related to abiotic influences. richness and cover of non-native species were highest at the edges of the remnant and declined to relatively uniform levels within the remnant. native species richness and cover were lowest at the edge adjoining a roadside but then showed little relation to distance from edge. roadside edge quadrats were floristically distinct from most other quadrats when ordinated by detrended correspondence analysis. \\n \\n \\n \\nsoil phosphorus was significantly higher at the roadside edge but did not vary within the remnant itself. all other abiotic factors measured (nh4, no3, s, ph and % organic carbon) showed little variation across the remnant. non-native species richness and cover were strongly correlated with soil phosphorus levels. native species were negatively correlated with soil phosphorus levels. canonical correspondence analysis identified the perennial non-native grasses of high biomass as species most dependent on high soil nutrient levels. such species may be resource-limited in undisturbed soils. \\n \\n \\n \\nthree classes of non-native plants have invaded this species-rich grassland: (1) generalist species (> 50 % frequency), mostly therophytes with non-specialized habitat or germination requirements; (2) resource-limited species comprising perennial species of high biomass that are dependent on nutrient increases and/or soil disturbances before they can invade the community and; (3) species of intermediate frequency (1\u201330 %), of low to high biomass potential, that appear to have non-specialized habitat requirements but are currently limited by seed dispersal, seedling establishment or the current site management. native species richness and cover are most negatively affected by increases in non-native cover. declines are largely evident once the non-native cover exceeds 40 %. \\n \\n \\n \\nwidespread, generalist non-native species are numerous in intact sites and will have to be considered a permanent part of the flora of remnant grasslands. management must aim to minimize increases in cover of any non-native species or the disturbances that favour the establishment of competitive non-native grasses if the native grassland flora is to be conserved in small, fragmented remnants.",
            "contribution_ids": [
                "R57306"
            ]
        },
        {
            "instance_id": "R57501xR57311",
            "comparison_id": "R57501",
            "paper_id": "R57311",
            "text": "Native plant diversity increases herbivory to non-natives there is often an inverse relationship between the diversity of a plant community and the invasibility of that community by non-native plants. native herbivores that colonize novel plants may contribute to diversity\u2013invasibility relationships by limiting the relative success of non-native plants. here, we show that, in large collections of non-native oak trees at sites across the usa, non-native oaks introduced to regions with greater oak species richness accumulated greater leaf damage than in regions with low oak richness. underlying this trend was the ability of herbivores to exploit non-native plants that were close relatives to their native host. in diverse oak communities, non-native trees were on average more closely related to native trees and received greater leaf damage than those in depauperate oak communities. because insect herbivores colonize non-native plants that are similar to their native hosts, in communities with greater native plant diversity, non-natives experience greater herbivory.",
            "contribution_ids": [
                "R57312"
            ]
        },
        {
            "instance_id": "R57501xR57313",
            "comparison_id": "R57501",
            "paper_id": "R57313",
            "text": "Habitat stress, species pool size and biotic resistance influence exotic plant richness in the Flooding Pampa grasslands 1 theory and empirical evidence suggest that community invasibility is influenced by propagule pressure, physical stress and biotic resistance from resident species. we studied patterns of exotic and native species richness across the flooding pampas of argentina, and tested for exotic richness correlates with major environmental gradients, species pool size, and native richness, among and within different grassland habitat types. 2 native and exotic richness were positively correlated across grassland types, increasing from lowland meadows and halophyte steppes, through humid to mesophyte prairies in more elevated topographic positions. species pool size was positively correlated with local richness of native and exotic plants, being larger for mesophyte and humid prairies. localities in the more stressful meadow and halophyte steppe habitats contained smaller fractions of their landscape species pools. 3 native and exotic species numbers decreased along a gradient of increasing soil salinity and decreasing soil depth, and displayed a unimodal relationship with soil organic carbon. when covarying habitat factors were held constant, exotic and native richness residuals were still positively correlated across sites. within grassland habitat types, exotic and native species richness were positively associated in meadows and halophyte steppes but showed no consistent relationship in the least stressful, prairie habitat types. 4 functional group composition differed widely between native and exotic species pools. patterns suggesting biotic resistance to invasion emerged only within humid prairies, where exotic richness decreased with increasing richness of native warm\u2010season grasses. this negative relationship was observed for other descriptors of invasion such as richness and cover of annual cool\u2010season forbs, the commonest group of exotics. 5 our results support the view that ecological factors correlated with differences in invasion success change with the range of environmental heterogeneity encompassed by the analysis. within narrow habitat ranges, invasion resistance may be associated with either physical stress or resident native diversity. biotic resistance through native richness, however, appeared to be effective only at intermediate locations along a stress/fertility gradient. 6 we show that certain functional groups, not just total native richness, may be critical to community resistance to invasion. identifying such native species groups is important for directing management and conservation efforts.",
            "contribution_ids": [
                "R57314"
            ]
        },
        {
            "instance_id": "R57501xR57324",
            "comparison_id": "R57501",
            "paper_id": "R57324",
            "text": "Mechanisms of resistance of Mediterranean annual communities to invasion by Conyza bonariensis: effects of native functional composition \"recent studies have shown that a high species or functional group richness may not always lead to a greater resistance of plant communities to invasion, whereas species and/or functional group composition can more reliably predict invasion resistance. the aim of this study was to understand the mechanisms through which functional group composition can influence the resistance of mediterranean annual communities to invasion by the exotic conyza bonariensis. to analyse the effects of functional composition on the performance of individuals introduced as seedlings we first examined the relationships between the demographic and vegetative parameters of c. bonariensis and the biomass achieved by each functional group (grasses, legumes and asteraceae rosettes) in synthetic communities. as a further step to approach the mechanisms involved in community resistance to invasion, we included in the analyses measurements of functional variables taken within the synthetic communities. \\n \\n \\n \\nin agreement with earlier results and theory suggesting that high nutrient availability can favour invasions, an abundant legume biomass in communities increased the final biomass and net fecundity of c. bonariensis, due to positive effects on soil nitrate concentration. survival and establishment of c. bonariensis were mainly favoured by a high biomass of asteraceae. additional results from measurements of herbivory suggested that c. bonariensis survival wasn't related to abiotic conditions but may be owed to a protection against herbivores in plots with abundant asteraceae. establishment was on the other hand likely to be hindered by the effects of abundant grass and legume foliage on light quality, and therefore easier within an asteraceae canopy. \\n \\n \\n \\nwe conclude that invasion of mediterranean old fields by species with biologies similar to c. bonariensis could be limited by favouring communities dominated by annual grasses.\"",
            "contribution_ids": [
                "R57325"
            ]
        },
        {
            "instance_id": "R57501xR57336",
            "comparison_id": "R57501",
            "paper_id": "R57336",
            "text": "Biotic and abiotic constraints to a plant invasion in vegetation communities of Tierra del Fuego the biotic resistance theory relates invader success to species richness, and predicts that, as species richness increases, invasibility decreases. the relationship between invader success and richness, however, seems to be positive at large scales of analysis, determined by abiotic constraints, and it is to be expected that it is negative at small scales, because of biotic interactions. moreover, the negative relationship at small scales would be stronger within species of the same functional group, because of having similar resource exploitation mechanisms. we studied the relationship between the cover of a worldwide invader of grasslands, hieracium pilosella l., and species richness, species diversity and the cover of different growth forms at two different levels of analysis in 128 sites during the initial invasion process in the fuegian steppe, southern patagonia, argentina. at regional level, the invader was positively correlated to total (r\\xa0=\\xa00.28, p\\xa0=\\xa00.003), exotic (r\\xa0=\\xa00.273, p\\xa0=\\xa00.004), and native species richness (r\\xa0=\\xa00.210, p\\xa0=\\xa00.026), and to species diversity (r\\xa0=\\xa00.193, p\\xa0=\\xa00.041). at community level, we found only a weak negative correlation between h.\\xa0pilosella and total richness (r\\xa0=\\xa0\u22120.426, p\\xa0=\\xa00.079) and diversity (r\\xa0=\\xa0\u22120.658, p\\xa0=\\xa00.063). the relationship between the invader and other species of the same growth form was positive both at regional (r\\xa0=\\xa00.484, p\\xa0<\\xa00.001) and community (r\\xa0=\\xa00.593, p\\xa0=\\xa00.012) levels. consequently, in the period of establishment and initial expansion of this exotic species, our results support the idea that invader success is related to abiotic factors at large scales of analysis. also, we observed a possible sign of biotic constraint at community level, although this was not related to the abundance of species of the same growth form.",
            "contribution_ids": [
                "R57337"
            ]
        },
        {
            "instance_id": "R57501xR57341",
            "comparison_id": "R57501",
            "paper_id": "R57341",
            "text": "Ecological resistance to Acer negundo invasion in a European riparian forest: relative importance of environmental and biotic drivers question \\n \\nthe relative importance of environmental vs. biotic resistance of recipient ecological communities remains poorly understood in invasion ecology. acer negundo, a north american tree, has widely invaded riparian forests throughout europe at the ecotone between early- (salix spp. and populus spp.) and late-successional (fraxinus spp.) species. however, it is not present in the upper part of the rhone river, where native alnus incana occurs at an intermediate position along the successional riparian gradient. is this absence of the invasive tree due to environmental or biotic resistance of the recipient communities, and in particular due to the presence of alnus? \\n \\n \\n \\nlocation \\n \\nupper rhone river, france. \\n \\n \\n \\nmethods \\n \\nwe undertook a transplant experiment in an alnus-dominated community along the upper rhone river, where we compared acer negundo survival and growth, with and without biotic interactions (tree and herb layer effects), to those of four native tree species from differing successional positions in the upper rhone communities (p. alba, s. alba, f. excelsior and alnus incana). \\n \\n \\n \\nresults \\n \\nwithout biotic interactions acer negundo performed similarly to native species, suggesting that the upper rhone floodplain is not protected from acer invasion by a simple abiotic barrier. in contrast, this species performed less well than f. excelsior and alnus incana in environments with intact tree and/or herb layers. alnus showed the best growth rate in these conditions, indicating biotic resistance of the native plant community. \\n \\n \\n \\nconclusions \\n \\nwe did not find evidence for an abiotic barrier to acer negundo invasion of the upper rhone river floodplain communities, but our results suggest a biotic resistance. in particular, we demonstrated that (i) additive competitive effects of the tree and herb layer led to acer negundo suppression and (ii) alnus incana grew more rapidly than acer negundo in this intermediate successional niche.",
            "contribution_ids": [
                "R57342"
            ]
        },
        {
            "instance_id": "R57501xR57343",
            "comparison_id": "R57501",
            "paper_id": "R57343",
            "text": "Native and naturalized plant diversity are positively correlated in scrub communities of California and Chile abstract. an emerging body of literature suggests that the richness of native and naturalized plant species are often positively correlated. it is unclear, however, whether this relationship is robust across spatial scales, and how a disturbance regime may affect it. here, i examine the relationships of both richness and abundance between native and naturalized species of plants in two mediterranean scrub communities: coastal sage scrub (css) in california and xeric\u2010sloped matorral (xsm) in chile. in each vegetation type i surveyed multiple sites, where i identified vascular plant species and estimated their relative cover. herbaceous species richness was higher in xsm, while cover of woody species was higher in css, where woody species have a strong impact upon herbaceous species. as there were few naturalized species with a woody growth form, the analyses performed here relate primarily to herbaceous species. relationships between the herbaceous cover of native and naturalized species were not significant in css, but were nearly significant in xsm. the herbaceous species richness of native and naturalized plants were not significantly correlated on sites that had burned less than one year prior to sampling in css, and too few sites were available to examine this relationship in xsm. in post 1\u2010year burn sites, however, herbaceous richness of native and naturalized species were positively correlated in both css and xsm. this relationship occurred at all spatial scales, from 400 m2 to 1 m2 plots. the consistency of this relationship in this study, together with its reported occurrence in the literature, suggests that this relationship may be general. finally, the residuals from the correlations between native and naturalized species richness and cover, when plotted against site age (i.e. time since the last fire), show that richness and cover of naturalized species are strongly favoured on recently burned sites in xsm; this suggests that herbaceous species native to chile are relatively poorly adapted to fire.",
            "contribution_ids": [
                "R57344",
                "R57345"
            ]
        },
        {
            "instance_id": "R57501xR57346",
            "comparison_id": "R57501",
            "paper_id": "R57346",
            "text": "Realistic plant species losses reduce invasion resistance in a California serpentine grassland 1.\\u2002the majority of experiments examining effects of species diversity on ecosystem functioning have randomly manipulated species richness. more recent studies demonstrate that realistic species losses have dramatically different effects on ecosystem functioning than those of randomized losses, but these results are based primarily on microcosm experiments or modelling efforts.",
            "contribution_ids": [
                "R57347"
            ]
        },
        {
            "instance_id": "R57501xR57354",
            "comparison_id": "R57501",
            "paper_id": "R57354",
            "text": "Species diversity and invasion resistance in a marine ecosystem \" theory predicts that systems that are more diverse should be more resistant to exotic species, but experimental tests are needed to verify this. in experimental communities of sessile marine invertebrates, increased species richness significantly decreased invasion success, apparently because species-rich communities more completely and efficiently used available space, the limiting resource in this system. declining biodiversity thus facilitates invasion in this system, potentially accelerating the loss of biodiversity and the homogenization of the world's biota. \"",
            "contribution_ids": [
                "R57355"
            ]
        },
        {
            "instance_id": "R57501xR57356",
            "comparison_id": "R57501",
            "paper_id": "R57356",
            "text": "Biodiversity, invasion resistance, and marine ecosystem function: Reconciling pattern and process a venerable generalization about community resistance to invasions is that more diverse communities are more resistant to invasion. however, results of experimental and observational studies often conflict, leading to vigorous debate about the mechanistic importance of diversity in determining invasion success in the field, as well as other eco- system properties, such as productivity and stability. in this study, we employed both field experiments and observational approaches to assess the effects of diversity on the invasion of a subtidal marine invertebrate community by three species of nonindigenous ascidians (sea squirts). in experimentally assembled communities, decreasing native diversity in- creased the survival and final percent cover of invaders, whereas the abundance of individual species had no effect on these measures of invasion success. increasing native diversity also decreased the availability of open space, the limiting resource in this system, by buffering against fluctuations in the cover of individual species. this occurred because temporal patterns of abundance differed among species, so space was most consistently and completely occupied when more species were present. when we held diversity constant, but manipulated resource availability, we found that the settlement and recruitment of new invaders dramatically increased with increasing availability of open space. this suggests that the effect of diversity on invasion success is largely due to its effects on resource (space) availability. apart from invasion resistance, the increased temporal stability found in more diverse communities may itself be considered an enhancement of ecosystem func- tion. in field surveys, we found a strong negative correlation between native-species richness and the number and frequency of nonnative invaders at the scale of both a single quadrat (25 3 25 cm), and an entire site (50 3 50 m). such a pattern suggests that the means by which diversity affects invasion resistance in our experiments is important in determining the distribution of invasive species in the field. further synthesis of mechanistic and ob- servational approaches should be encouraged, as this will increase our understanding of the conditions under which diversity does (and does not) play an important role in deter- mining the distribution of invaders in the field.",
            "contribution_ids": [
                "R57357",
                "R57358"
            ]
        },
        {
            "instance_id": "R57501xR57365",
            "comparison_id": "R57501",
            "paper_id": "R57365",
            "text": "Plant species invasions along the latitudinal gradient in the United States it has been long established that the richness of vascular plant species and many animal taxa decreases with increasing latitude, a pattern that very generally follows declines in actual and potential evapotranspiration, solar radiation, temperature, and thus, total productivity. using county-level data on vascular plants from the united states (3000 counties in the conterminous 48 states), we used the akaike information criterion (aic) to evaluate competing models predicting native and nonnative plant species density (number of species per square kilometer in a county) from various combinations of biotic variables (e.g., native bird species density, vegetation carbon, normalized difference vegetation in- dex), environmental/topographic variables (elevation, variation in elevation, the number of land cover classes in the county, radiation, mean precipitation, actual evapotranspiration, and potential evapotranspiration), and human variables (human population density, crop- land, and percentage of disturbed lands in a county). we found no evidence of a latitudinal gradient for the density of native plant species and a significant, slightly positive latitudinal gradient for the density of nonnative plant species. we found stronger evidence of a sig- nificant, positive productivity gradient (vegetation carbon) for the density of native plant species and nonnative plant species. we found much stronger significant relationships when biotic, environmental/topographic, and human variables were used to predict native plant species density and nonnative plant species density. biotic variables generally had far greater influence in multivariate models than human or environmental/topographic variables. later, we found that the best, single, positive predictor of the density of nonnative plant species in a county was the density of native plant species in a county. while further study is needed, it may be that, while humans facilitate the initial establishment invasions of non- native plant species, the spread and subsequent distributions of nonnative species are con- trolled largely by biotic and environmental factors.",
            "contribution_ids": [
                "R57366"
            ]
        },
        {
            "instance_id": "R57501xR57393",
            "comparison_id": "R57501",
            "paper_id": "R57393",
            "text": "Diversity effects on invasion vary with life history stage in marine macroalgae most experimental studies of diversity effects on invasibility have reported negative relationships while observational studies have often found positive correlations between the numbers of exotic and native taxa. nearly all of these studies have been done with terrestrial plants or aquatic invertebrates. we investigated effects of native macroalgal diversity on invasion success of the introduced macroalga sargassum muticum (yendo) fensholt (phaeophyceae: fucales) on the west coast of vancouver island. we conducted both observational field surveys of the correlation between native diversity and exotic cover, and experimental manipulations of native diversity in constructed 25 \ufffd 25 cm communities. field surveys found higher cover of s. muticum in plots with low native diversity, suggesting a negative relationship between diversity and invasibility at the neighbourhood scale. the experiment found initial cover of s. muticum germlings was highest in plots with greater diversity. over the duration of the experiment cover of settled germlings increased fastest in the low diversity plots, so that there was a weak negative effect of diversity on final cover of the invader after 77 days. the slope of the relationship reversed over time, with field patterns and experimental results converging at the end of the experiment. our results suggest native diversity has contrasting effects on different stages of invasion. diversity facilitates invader recruitment of s. muticum but decreases growth and or survivorship.",
            "contribution_ids": [
                "R57394",
                "R57395"
            ]
        },
        {
            "instance_id": "R58002xR57596",
            "comparison_id": "R58002",
            "paper_id": "R57596",
            "text": "Post-dispersal losses to seed predators: an experimental comparison of native and exotic old field plants invasions by exotic plants may be more likely if exotics have low rates of attack by natural enemies, including post-dispersal seed predators (granivores). we investigated this idea with a field experiment conducted near newmarket, ontario, in which we experimentally excluded vertebrate and terrestrial insect seed predators from seeds of 43 native and exotic old-field plants. protection from vertebrates significantly increased recovery of seeds; vertebrate exclusion produced higher recovery than controls for 30 of the experimental species, increasing overall seed recovery from 38.2 to 45.6%. losses to vertebrates varied among species, significantly increasing with seed mass. in contrast, insect exclusion did not significantly improve seed recovery. there was no evidence that aliens benefitted from a reduced rate of post-dispersal seed predation. the impacts of seed predators did not differ significantly between natives and exotics, which instead showed very similar responses to predator exclusion treatments. these results indicate that while vertebrate granivores had important impacts, especially on large-seeded species, exotics did not generally benefit from reduced rates of seed predation. instead, differences between natives and exotics were small compared with interspecific variation within these groups.key words: aliens, exotics, granivores, invaders, old fields, seed predators.",
            "contribution_ids": [
                "R57597"
            ]
        },
        {
            "instance_id": "R58002xR57598",
            "comparison_id": "R58002",
            "paper_id": "R57598",
            "text": "Lack of pre-dispersal seed predators in introduced Asteraceae in New Zealand the idea that naturalised invading plants have fewer phytophagous insects associated with them in their new environment relative to their native range is often assumed, but quantitative data are few and mostly refer to pests on crop species. in this study, the incidence of seed-eating insect larvae in flowerheads of naturalised asteraceae in new zealand is compared with that in britain where the species are native. similar surveys were carried out in both countries by sampling 200 flowerheads of three populations of the same thirteen species. in the new zealand populations only one seed-eating insect larva was found in 7800 flowerheads (0.013% infected flowerheads, all species combined) in contrast with the british populations which had 487 (6.24%) flowerheads infested. possible reasons for the low colonization level of the introduced asteraceae by native insects in new zealand are 1) the relatively recent introduction of the plants (100-200 years), 2) their phylogenetic distance from the native flora, and 3) the specialised nature of the bud-infesting habit of the insects.",
            "contribution_ids": [
                "R57599"
            ]
        },
        {
            "instance_id": "R58002xR57600",
            "comparison_id": "R58002",
            "paper_id": "R57600",
            "text": "Impact of fire on leaf nutrients, arthropod fauna and herbivory of native and exotic eucalypts in Kings Park, Perth, Western Australia the vegetation of kings park, near the centre of perth, western australia, once had an overstorey of eucalyptus marginata (jarrah) or eucalyptus gomphocephala (tuart), and many trees still remain in the bushland parts of the park. avenues and roadsides have been planted with eastern australian species, including eucalyptus cladocalyx (sugar gum) and eucalyptus botryoides (southern mahogany), both of which have become invasive. the present study examined the effect of a recent burn on the level of herbivory on these native and exotic eucalypts. leaf damage, shoot extension and number of new leaves were measured on tagged shoots of saplings of each tree species in unburnt and burnt areas over an 8-month period. leaf macronutrient levels were quantified and the number of arthropods on saplings was measured at the end of the recording period by chemical knockdown. leaf macronutrients were mostly higher in all four species in the burnt area, and this was associated with generally higher numbers of canopy arthropods and greater levels of leaf damage. it is suggested that the pulse of soil nutrients after the fire resulted in more nutrient-rich foliage, which in turn was more palatable to arthropods. the resulting high levels of herbivory possibly led to reduced shoot extension of e. gomphocephala, e. botryoides and, to a lesser extent, e. cladocalyx. this acts as a negative feedback mechanism that lessens the tendency for lush, post-fire regrowth to outcompete other species of plants. there was no consistent difference in the levels of the various types of leaf damage or of arthropods on the native and the exotic eucalypts, suggesting that freedom from herbivory is not contributing to the invasiveness of the two exotic species.",
            "contribution_ids": [
                "R57601"
            ]
        },
        {
            "instance_id": "R58002xR57618",
            "comparison_id": "R58002",
            "paper_id": "R57618",
            "text": "Plant-soil biota interactions and spatial distribution of black cherry in its native and invasive ranges one explanation for the higher abundance of invasive species in their non-native than native ranges is the escape from natural enemies. but there are few experimental studies comparing the parallel impact of enemies (or competitors and mutualists) on a plant species in its native and invaded ranges, and release from soil pathogens has been rarely investigated. here we present evidence showing that the invasion of black cherry (prunus serotina) into north-western europe is facilitated by the soil community. in the native range in the usa, the soil community that develops near black cherry inhibits the establishment of neighbouring conspecifics and reduces seedling performance in the greenhouse. in contrast, in the non-native range, black cherry readily establishes in close proximity to conspecifics, and the soil community enhances the growth of its seedlings. understanding the effects of soil organisms on plant abundance will improve our ability to predict and counteract plant invasions.",
            "contribution_ids": [
                "R57619"
            ]
        },
        {
            "instance_id": "R58002xR57635",
            "comparison_id": "R58002",
            "paper_id": "R57635",
            "text": "Invasive exotic plants suffer less herbivory than non-invasive exotic plants we surveyed naturally occurring leaf herbivory in nine invasive and nine non-invasive exotic plant species sampled in natural areas in ontario, new york and massachusetts, and found that invasive plants experienced, on average, 96% less leaf damage than non-invasive species. invasive plants were also more taxonomically isolated than non-invasive plants, belonging to families with 75% fewer native north american genera. however, the relationship between taxonomic isolation at the family level and herbivory was weak. we suggest that invasive plants may possess novel phytochemicals with anti-herbivore properties in addition to allelopathic and anti-microbial characteristics. herbivory could be employed as an easily measured predictor of the likelihood that recently introduced exotic plants may become invasive.",
            "contribution_ids": [
                "R57636"
            ]
        },
        {
            "instance_id": "R58002xR57727",
            "comparison_id": "R58002",
            "paper_id": "R57727",
            "text": "Diversity and abundance of arthropod floral visitor and herbivore assemblages on exotic and native Senecio species the enemy release hypothesis predicts that native herbivores prefer native, rather than exotic plants, giving invaders a competitive advantage. in contrast, the biotic resistance hypothesis states that many invaders are prevented from establishing because of competitive interactions, including herbivory, with native fauna and flora. success or failure of spread and establishment might also be influenced by the presence or absence of mutualists, such as pollinators. senecio madagascariensis (fireweed), an annual weed from south africa, inhabits a similar range in australia to the related native s. pinnatifolius. the aim of this study was to determine, within the context of invasion biology theory, whether the two senecio species share insect fauna, including floral visitors and herbivores. surveys were carried out in south-east queensland on allopatric populations of the two senecio species, with collected insects identified to morphospecies. floral visitor assemblages were variable between populations. however, the two senecio species shared the two most abundant floral visitors, honeybees and hoverflies. herbivore assemblages, comprising mainly hemipterans of the families cicadellidae and miridae, were variable between sites and no patterns could be detected between senecio species at the morphospecies level. however, when insect assemblages were pooled (i.e. community level analysis), s. pinnatifolius was shown to host a greater total abundance and richness of herbivores. senecio madagascariensis is unlikely to be constrained by lack of pollinators in its new range and may benefit from lower levels of herbivory compared to its native congener s. pinnatifolius.",
            "contribution_ids": [
                "R57728"
            ]
        },
        {
            "instance_id": "R58002xR57753",
            "comparison_id": "R58002",
            "paper_id": "R57753",
            "text": "Release from soil pathogens plays an important role in the success of invasive Carpobrotus in the Mediterranean introduced plant species can become locally dominant and threaten native flora and fauna. this dominance is often thought to be a result of release from specialist enemies in the invaded range, or the evolution of increased competitive ability. soil borne microorganisms have often been overlooked as enemies in this context, but a less deleterious plant soil interaction in the invaded range could explain local dominance. two plant species, carpobrotus edulis and the hybrid carpobrotus x cf. acinaciformis, are considered major pests in the mediterranean basin. we tested if release from soil-borne enemies and/or evolution of increased competitive ability could explain this dominance. comparing biomass production in non-sterile soil with that in sterilized soil, we found that inoculation with rhizosphere soil from the native range reduced biomass production by 32% while inoculation with rhizosphere soil from the invaded range did not have a significant effect on plant biomass. genotypes from the invaded range, including a hybrid, did not perform better than plants from the native range in sterile soil. hence evolution of increased competitive ability and hybridization do not seem to play a major role. we conclude that the reduced negative net impact of the soil community in the invaded range may contribute to the success of carpobrotus species in the mediterranean basin. \u00a9 2008 saab. published by elsevier b.v. all rights reserved.",
            "contribution_ids": [
                "R57754"
            ]
        },
        {
            "instance_id": "R58002xR57774",
            "comparison_id": "R58002",
            "paper_id": "R57774",
            "text": "Effects of large enemies on success of exotic species in marine fouling communities of Washington, USA the enemy release hypothesis, which posits that exotic species are less regulated by enemies than native species, has been well-supported in terrestrial systems but rarely tested in marine systems. here, the enemy release hypothesis was tested in a marine system by excluding large enemies (>1.3 cm) in dock fouling communities in washington, usa. after documenting the distribution and abundance of potential enemies such as chitons, gastropods and flatworms at 4 study sites, exclusion experiments were conducted to test the hypotheses that large grazing ene- mies (1) reduced recruitment rates in the exotic ascidian botrylloides violaceus and native species, (2) reduced b. violaceus and native species abundance, and (3) altered fouling community struc- ture. experiments demonstrated that, as predicted by the enemy release hypothesis, exclusion of large enemies did not significantly alter b. violaceus recruitment or abundance and it did signifi- cantly increase abundance or recruitment of 2 common native species. however, large enemy exclusion had no significant effects on most native species or on overall fouling community struc- ture. furthermore, neither b. violaceus nor total exotic species abundance correlated positively with abundance of large enemies across sites. i therefore conclude that release from large ene- mies is likely not an important mechanism for the success of exotic species in washington fouling communities.",
            "contribution_ids": [
                "R57775"
            ]
        },
        {
            "instance_id": "R58002xR57799",
            "comparison_id": "R58002",
            "paper_id": "R57799",
            "text": "Associations of leaf miners and leaf gallers with island plants of different residency histories aim\\u2002 introduced plant species are less likely to be attacked by herbivores than are native plant species. isolated oceanic islands provide an excellent model system for comparing the associations between herbivore species and plant species of different residency histories, namely endemic, indigenous (non\u2010endemic) or introduced (naturalized or cultivated) species. my aim was to test the prediction that, on isolated oceanic islands, introduced plant species have a lower tendency to have an association with insect herbivores than do endemic and indigenous plant species.",
            "contribution_ids": [
                "R57800"
            ]
        },
        {
            "instance_id": "R58002xR57808",
            "comparison_id": "R58002",
            "paper_id": "R57808",
            "text": "Range-expanding populations of a globally introduced weed experience negative plant-soil feedbacks \"background biological invasions are fundamentally biogeographic processes that occur over large spatial scales. interactions with soil microbes can have strong impacts on plant invasions, but how these interactions vary among areas where introduced species are highly invasive vs. naturalized is still unknown. in this study, we examined biogeographic variation in plant-soil microbe interactions of a globally invasive weed, centaurea solstitialis (yellow starthistle). we addressed the following questions (1) is centaurea released from natural enemy pressure from soil microbes in introduced regions? and (2) is variation in plant-soil feedbacks associated with variation in centaurea's invasive success? methodology/principal findings we conducted greenhouse experiments using soils and seeds collected from native eurasian populations and introduced populations spanning north and south america where centaurea is highly invasive and noninvasive. soil microbes had pervasive negative effects in all regions, although the magnitude of their effect varied among regions. these patterns were not unequivocally congruent with the enemy release hypothesis. surprisingly, we also found that centaurea generated strong negative feedbacks in regions where it is the most invasive, while it generated neutral plant-soil feedbacks where it is noninvasive. conclusions/significance recent studies have found reduced below-ground enemy attack and more positive plant-soil feedbacks in range-expanding plant populations, but we found increased negative effects of soil microbes in range-expanding centaurea populations. while such negative feedbacks may limit the long-term persistence of invasive plants, such feedbacks may also contribute to the success of invasions, either by having disproportionately negative impacts on competing species, or by yielding relatively better growth in uncolonized areas that would encourage lateral spread. enemy release from soil-borne pathogens is not sufficient to explain the success of this weed in such different regions. the biogeographic variation in soil-microbe effects indicates that different mechanisms may operate on this species in different regions, thus establishing geographic mosaics of species interactions that contribute to variation in invasion success.\"",
            "contribution_ids": [
                "R57809",
                "R57810"
            ]
        },
        {
            "instance_id": "R58002xR57816",
            "comparison_id": "R58002",
            "paper_id": "R57816",
            "text": "Diversity, loss, and gain of malaria parasites in a globally invasive bird \"invasive species can displace natives, and thus identifying the traits that make aliens successful is crucial for predicting and preventing biodiversity loss. pathogens may play an important role in the invasive process, facilitating colonization of their hosts in new continents and islands. according to the novel weapon hypothesis, colonizers may out-compete local native species by bringing with them novel pathogens to which native species are not adapted. in contrast, the enemy release hypothesis suggests that flourishing colonizers are successful because they have left their pathogens behind. to assess the role of avian malaria and related haemosporidian parasites in the global spread of a common invasive bird, we examined the prevalence and genetic diversity of haemosporidian parasites (order haemosporida, genera plasmodium and haemoproteus) infecting house sparrows (passer domesticus). we sampled house sparrows (n\\u200a=\\u200a1820) from 58 locations on 6 continents. all the samples were tested using pcr-based methods; blood films from the pcr-positive birds were examined microscopically to identify parasite species. the results show that haemosporidian parasites in the house sparrows' native range are replaced by species from local host-generalist parasite fauna in the alien environments of north and south america. furthermore, sparrows in colonized regions displayed a lower diversity and prevalence of parasite infections. because the house sparrow lost its native parasites when colonizing the american continents, the release from these natural enemies may have facilitated its invasion in the last two centuries. our findings therefore reject the novel weapon hypothesis and are concordant with the enemy release hypothesis.\"",
            "contribution_ids": [
                "R57817"
            ]
        },
        {
            "instance_id": "R58002xR57900",
            "comparison_id": "R58002",
            "paper_id": "R57900",
            "text": "The herbivorous arthropods associated with the invasive alien plant, Arundo donax, and the native analogous plant, Phragmites australis, in the Free State Province, South Africa the enemy release hypothesis (erh) predicts that when plant species are introduced outside their native range there is a release from natural enemies resulting in the plants becoming problematic invasive alien species (lake & leishman 2004; puliafico et al. 2008). the release from natural enemies may benefit alien plants more than simply reducing herbivory because, according to the evolution of increased competitive ability (eica) hypothesis, without pressure from herbivores more resources that were previously allocated to defence can be allocated to reproduction (blossey & notzold 1995). alien invasive plants are therefore expected to have simpler herbivore communities with fewer specialist herbivores (frenzel & brandl 2003; heleno et al. 2008; heger & jeschke 2014).",
            "contribution_ids": [
                "R57901"
            ]
        },
        {
            "instance_id": "R58002xR57902",
            "comparison_id": "R58002",
            "paper_id": "R57902",
            "text": "Herbivores on native and exotic Senecio plants: is host switching related to plant novelty and insect diet breadth under field conditions? native herbivores can establish novel interactions with alien plants after invasion. nevertheless, it is unclear whether these new associations are quantitatively significant compared to the assemblages with native flora under natural conditions. herbivores associated with two exotic plants, namely senecio inaequidens and s. pterophorus, and two coexisting natives, namely s. vulgaris and s. lividus, were surveyed in a replicated long\u2010term field study to ascertain whether the plant\u2013herbivore assemblages in mixed communities are related to plant novelty and insect diet breadth. native herbivores used exotic senecio as their host plants. of the 19 species of lepidoptera, diptera, and hemiptera found in this survey, 14 were associated with the exotic senecio plants. most of these species were polyphagous, yet we found a higher number of individuals with a narrow diet breadth, which is contrary to the assumption that host switching mainly occurs in generalist herbivores. the senecio specialist sphenella marginata (diptera: tephritidae) was the most abundant and widely distributed insect species (ca. 80% of the identified specimens). sphenella was associated with s. lividus, s. vulgaris and s. inaequidens and was not found on s. pterophorus. the presence of native plant congeners in the invaded community did not ensure an instantaneous ecological fitting between insects and alien plants. we conclude that novel associations between native herbivores and introduced senecio plants are common under natural conditions. plant novelty is, however, not the only predictor of herbivore abundance due to the complexity of natural conditions.",
            "contribution_ids": [
                "R57903"
            ]
        },
        {
            "instance_id": "R58002xR57904",
            "comparison_id": "R58002",
            "paper_id": "R57904",
            "text": "Escape from parasitism by the invasive alien ladybird, Harmonia axyridis alien species are often reported to perform better than functionally similar species native to the invaded range, resulting in high population densities, and a tendency to become invasive. the enemy release hypothesis (erh) explains the success of invasive alien species (ias) as a consequence of reduced mortality from natural enemies (predators, parasites and pathogens) compared with native species. the harlequin ladybird, harmonia axyridis, a species alien to britain, provides a model system for testing the erh. pupae of h. axyridis and the native ladybird coccinella septempunctata were monitored for parasitism between 2008 and 2011, from populations across southern england in areas first invaded by h. axyridis between 2004 and 2009. in addition, a semi\u2010field experiment was established to investigate the incidence of parasitism of adult h. axyridis and c. septempunctata by dinocampus coccinellae. harmonia axyridis pupae were parasitised at a much lower rate than conspecifics in the native range, and both pupae and adults were parasitised at a considerably lower rate than c. septempunctata populations from the same place and time (h. axyridis: 1.67%; c. septempunctata: 18.02%) or in previous studies on asian h. axyridis (2\u20137%). we found no evidence that the presence of h. axyridis affected the parasitism rate of c. septempunctata by d. coccinellae. our results are consistent with the general prediction that the prevalence of natural enemies is lower for introduced species than for native species at early stages of invasion. this may partly explain why h. axyridis is such a successful ias.",
            "contribution_ids": [
                "R57905",
                "R57906"
            ]
        },
        {
            "instance_id": "R58002xR57943",
            "comparison_id": "R58002",
            "paper_id": "R57943",
            "text": "Comparison of invertebrate herbivores on native and non-native Senecio species: Implications for the enemy release hypothesis the enemy release hypothesis posits that non-native plant species may gain a competitive advantage over their native counterparts because they are liberated from co-evolved natural enemies from their native area. the phylogenetic relationship between a non-native plant and the native community may be important for understanding the success of some non-native plants, because host switching by insect herbivores is more likely to occur between closely related species. we tested the enemy release hypothesis by comparing leaf damage and herbivorous insect assemblages on the invasive species senecio madagascariensis\\u2005poir. to that on nine congeneric species, of which five are native to the study area, and four are non-native but considered non-invasive. non-native species had less leaf damage than natives overall, but we found no significant differences in the abundance, richness and shannon diversity of herbivores between native and non-native senecio\\u2005l. species. the herbivore assemblage and percentage abundance of herbivore guilds differed among all senecio species, but patterns were not related to whether the species was native or not. species-level differences indicate that s.\\u2009madagascariensis may have a greater proportion of generalist insect damage (represented by phytophagous leaf chewers) than the other senecio species. within a plant genus, escape from natural enemies may not be a sufficient explanation for why some non-native species become more invasive than others.",
            "contribution_ids": [
                "R57944",
                "R57945",
                "R57946",
                "R57947"
            ]
        },
        {
            "instance_id": "R58002xR57948",
            "comparison_id": "R58002",
            "paper_id": "R57948",
            "text": "The parasite community of gobiid fishes (Actinopterygii: Gobiidae) from the Lower Volga River region abstract the parasitic fauna in the lower volga river basin was investigated for four gobiid species: the nonindigenous monkey goby neogobius fluviatilis (pallas, 1814), the round goby n. melanostomus (pallas, 1814), the caspian bighead goby ponticola gorlap (iljin, 1949), and the tubenose goby proterorhinus cf. semipellucidus (kessler, 1877). in total, 19 species of goby parasites were identified, of which two - bothriocephalus opsariichthydis yamaguti, 1934 and nicolla skrjabini (iwanitzki, 1928) - appeared to have been introduced from other geographic regions. the monkey goby had significantly fewer parasitic species (6), but relatively high levels of infection, in comparison to the native species. parasitism of the caspian bighead goby, which is the only predatory fish among the studied gobies, differed from the others according to the results of discriminant analysis. the parasitic fauna of the tubenose goby more closely resembled those of caspian sea gobiids, rather than the black sea monkey goby.",
            "contribution_ids": [
                "R57949"
            ]
        },
        {
            "instance_id": "R58002xR57959",
            "comparison_id": "R58002",
            "paper_id": "R57959",
            "text": "No release for the wicked: enemy release is dynamic and not associated with invasiveness the enemy release hypothesis predicts that invasive species will receive less damage from enemies, compared to co-occurring native and noninvasive exotic species in their introduced range. however, release operating early in invasion could be lost over time and with increased range size as introduced species acquire new enemies. we used three years of data, from 61 plant species planted into common gardens, to determine whether (1) invasive, noninvasive exotic, and native species experience differential damage from insect herbivores. and mammalian browsers, and (2) enemy release is lost with increased residence time and geographic spread in the introduced range. we find no evidence suggesting enemy release is a general mechanism contributing to invasiveness in this region. invasive species received the most insect herbivory, and damage increased with longer residence times and larger range sizes at three spatial scales. our results show that invasive and exotic species fail to escape enemies, particularly over longer temporal and larger spatial scales.",
            "contribution_ids": [
                "R57960",
                "R57961"
            ]
        },
        {
            "instance_id": "R58002xR57964",
            "comparison_id": "R58002",
            "paper_id": "R57964",
            "text": "Natural selection on plant resistance to herbivores in the native and introduced range plants introduced into a new range are expected to harbour fewer specialized herbivores and to receive less damage than conspecifics in native ranges. datura stramonium was introduced in spain about five centuries ago. here, we compare damage by herbivores, plant size, and leaf trichomes between plants from non-native and native ranges and perform selection analyses. non-native plants experienced much less damage, were larger and less pubescent than plants of native populations. while plant size was related to fitness in both ranges, selection to increase resistance was only detected in the native region. we suggest this is a consequence of a release from enemies in this new environment.",
            "contribution_ids": [
                "R57965"
            ]
        },
        {
            "instance_id": "R58002xR57971",
            "comparison_id": "R58002",
            "paper_id": "R57971",
            "text": "Insect assemblages associated with the exotic riparian shrub Russian olive (Elaeagnaceae), and co-occurring native shrubs in British Columbia, Canada abstract russian olive ( elaeagnus angustifolia linnaeus; elaeagnaceae) is an exotic shrub/tree that has become invasive in many riparian ecosystems throughout semi-arid, western north america, including southern british columbia, canada. despite its prevalence and the potentially dramatic impacts it can have on riparian and aquatic ecosystems, little is known about the insect communities associated with russian olive within its invaded range. at six sites throughout the okanagan valley of southern british columbia, canada, we compared the diversity of insects associated with russian olive plants to that of insects associated with two commonly co-occurring native plant species: woods\u2019 rose ( rosa woodsii lindley; rosaceae) and saskatoon ( amelanchier alnifolia (nuttall) nuttall ex roemer; rosaceae). total abundance did not differ significantly among plant types. family richness and shannon diversity differed significantly between woods\u2019 rose and saskatoon, but not between either of these plant types and russian olive. an abundance of thripidae (thysanoptera) on russian olive and tingidae (hemiptera) on saskatoon contributed to significant compositional differences among plant types. the families chloropidae (diptera), heleomyzidae (diptera), and gryllidae (orthoptera) were uniquely associated with russian olive, albeit in low abundances. our study provides valuable and novel information about the diversity of insects associated with an emerging plant invader of western canada.",
            "contribution_ids": [
                "R57972"
            ]
        },
        {
            "instance_id": "R6757xR6268",
            "comparison_id": "R6757",
            "paper_id": "R6268",
            "text": "Intui2: a prototype system for question answering over linked data an ever increasing amount of linked data is made available every day. public triple stores offer the possibility of querying hundreds of millions of triples. but this information can only be retrieved using specialized query languages like sparql, so for the majority of internet users, it is still unavailable. this paper presents a prototype system aimed at streamlining the access to the information stored as rdf. the system takes as input a natural language question formulated in english and generates an equivalent sparql query. the mapping is based on the analysis of the syntactic patterns present in the input question. in the initial evaluation results, against the 99 questions in the qald-3 dbpedia test set, the system provides a correct answer to 30 questions and a partial answer for another 3 questions, achieving an f-measure of 0.32.",
            "contribution_ids": [
                "R6269"
            ]
        },
        {
            "instance_id": "R6757xR6271",
            "comparison_id": "R6757",
            "paper_id": "R6271",
            "text": "Answering natural language questions with Intui3 intui3 is one of the participating systems at the fourth evaluation campaign on multilingual question answering over linked data, qald4. the system accepts as input a question formulated in natural language (in english), and uses syntactic and semantic information to construct its interpretation with respect to a given database of rdf triples (in this case dbpedia 3.9). the interpretation is mapped to the corresponding sparql query, which is then run against a sparql endpoint to retrieve the answers to the initial question. intui3 competed in the challenge called task 1: multilingual question answering over linked data, which offered 200 training questions and 50 test questions in 7 different languages. it obtained an f-measure of 0.24 by providing a correct answer to 10 of the test questions and a partial answer to 4 of them.",
            "contribution_ids": [
                "R6272"
            ]
        },
        {
            "instance_id": "R6757xR6322",
            "comparison_id": "R6757",
            "paper_id": "R6322",
            "text": "ISOFT at QALD-4: semantic similarity-based question answering system over linked data we present a question answering system over linked data. we use natural language processing tools to extract slots and sparql templates from the question. then, we use semantic similarity to map a natural language question to a sparql query. we combine important words to avoid loss of meaning, and compare combined words with uniform resource identifiers (uris) from a knowledgebase (kb). this process is more powerful than comparing each word individually. using our method, the problem of mapping a phrase of a user question to uris from a kb can be more easily solved than without our method; this method improves the f-measure of the system.",
            "contribution_ids": [
                "R6323"
            ]
        },
        {
            "instance_id": "R68535xR54884",
            "comparison_id": "R68535",
            "paper_id": "R54884",
            "text": "Past warming trend constrains future warming in CMIP6 models strong future warming in some new climate models is less likely as their recent warming is inconsistent with observed trends.",
            "contribution_ids": [
                "R54890",
                "R54893",
                "R54896",
                "R54899",
                "R54901",
                "R54902",
                "R54903",
                "R54904",
                "R54905",
                "R54906",
                "R54907",
                "R54908",
                "R54909",
                "R54910",
                "R54911",
                "R54912",
                "R54913",
                "R54914",
                "R54915",
                "R54916",
                "R54917",
                "R54918",
                "R54919",
                "R54920",
                "R54921",
                "R54922",
                "R54923",
                "R54924",
                "R54925",
                "R54951"
            ]
        },
        {
            "instance_id": "R6947xR6693",
            "comparison_id": "R6947",
            "paper_id": "R6693",
            "text": "TEXT2TABLE: Medical Text Summarization System Based on Named Entity Recognition and Modality Identification \"with the rapidly growing use of electronic health records, the possibility of large-scale clinical information extraction has drawn much attention. it is not, however, easy to extract information because these reports are written in natural language. to address this problem, this paper presents a system that converts a medical text into a table structure. this system's core technologies are (1) medical event recognition modules and (2) a negative event identification module that judges whether an event actually occurred or not. regarding the latter module, this paper also proposes an svm-based classifier using syntactic information. experimental results demonstrate empirically that syntactic information can contribute to the method's accuracy.\"",
            "contribution_ids": [
                "R6694"
            ]
        },
        {
            "instance_id": "R6947xR6701",
            "comparison_id": "R6947",
            "paper_id": "R6701",
            "text": "Multi-document summarisation using generic relation extraction experiments are reported that investigate the effect of various source document representations on the accuracy of the sentence extraction phase of a multi-document summarisation task. a novel representation is introduced based on generic relation extraction (gre), which aims to build systems for relation identification and characterisation that can be transferred across domains and tasks without modification of model parameters. results demonstrate performance that is significantly higher than a non-trivial baseline that uses tf*idf-weighted words and at least as good as a comparable but less general approach from the literature. analysis shows that the representations compared are complementary, suggesting that extraction performance could be further improved through system combination.",
            "contribution_ids": [
                "R6702"
            ]
        },
        {
            "instance_id": "R6947xR6715",
            "comparison_id": "R6947",
            "paper_id": "R6715",
            "text": "Automatic Multi-document Summarization Based on Clustering and Nonnegative Matrix Factorization abstract in this paper, a novel summarization method that uses nonnegative matrix factorization (nmf) and the clustering method is introduced to extract meaningful sentences relevant to a given query. the proposed method decomposes a sentence into the linear combination of sparse nonnegative semantic features so that it can represent a sentence as the sum of a few semantic features that are comprehensible intuitively. it can improve the quality of document summaries because it can avoid extracting those sentences whose similarities with the query are high but that are meaningless by using the similarity between the query and the semantic features. in addition, the proposed approach uses the clustering method to remove noise and avoid the biased inherent semantics of the documents being reflected in summaries. the method can ensure the coherence of summaries by using the rank score of sentences with respect to semantic features. the experimental results demonstrate that the proposed method has better performance than other methods that use the thesaurus, the latent semantic analysis (lsa), the k-means, and the nmf.",
            "contribution_ids": [
                "R6716"
            ]
        },
        {
            "instance_id": "R6947xR6719",
            "comparison_id": "R6947",
            "paper_id": "R6719",
            "text": "ThemeCrowds: multiresolution summaries of twitter usage users of social media sites, such as twitter, rapidly generate large volumes of text content on a daily basis. visual summaries are needed to understand what groups of people are saying collectively in this unstructured text data. users will typically discuss a wide variety of topics, where the number of authors talking about a specific topic can quickly grow or diminish over time, and what the collective is saying about the subject can shift as a situation develops. in this paper, we present a technique that summarises what collections of twitter users are saying about certain topics over time. as the correct resolution for inspecting the data is unknown in advance, the users are clustered hierarchically over a fixed time interval based on the similarity of their posts. the visualisation technique takes this data structure as its input. given a topic, it finds the correct resolution of users at each time interval and provides tags to summarise what the collective is discussing. the technique is tested on a large microblogging corpus, consisting of millions of tweets and over a million users.",
            "contribution_ids": [
                "R6720"
            ]
        },
        {
            "instance_id": "R6947xR6697",
            "comparison_id": "R6947",
            "paper_id": "R6697",
            "text": "OHSU Summarization and Entity Linking Systems we present two distinct text analysis systems. we first present two supervised sentence ranking approaches for use in extractive update summarization. for the first, we use the same general machine learning approach described in fisher and roark (2008) for update summarization. in the second, we use a similar machine learning approach, but include sub-sentential units produced by our discourse segmenter, see fisher and roark (2007b), as possible units for inclusion in a summary. interestingly, we find that one approach performs significantly better in the production of the base summary, while the other approach performs significantly better in the update summary. we then present a large-corpus entity linking system. this system expands queries using internal links within wikipedia and link entities with minimum-spanning-tree clustering. we present and evaluate empirical results on the tac 2009 knowledge-base-population data, and demonstrate competitive results with a simple system.",
            "contribution_ids": [
                "R6698"
            ]
        },
        {
            "instance_id": "R6948xR6586",
            "comparison_id": "R6948",
            "paper_id": "R6586",
            "text": "A multilingual news summarizer huge multilingual news articles are reported and disseminated on the internet. how to extract the key information and save the reading time is a crucial issue. this paper proposes architecture of multilingual news summarizer, including monolingual and multilingual clustering, similarity measure among meaningful units, and presentation of summarization results. translation among news stories, idiosyncrasy among languages, implicit information, and user preference are addressed.",
            "contribution_ids": [
                "R6587"
            ]
        },
        {
            "instance_id": "R6948xR6575",
            "comparison_id": "R6948",
            "paper_id": "R6575",
            "text": "Generating Natural Language Summaries from Multiple On-Line Sources we present a methodology for summarization of news about current events in the form of briefings that include appropriate background (historical) information. the system that we developed, summons, uses the output of systems developed for the darpa message understanding conferences to generate summaries of multiple documents on the same or related events, presenting similarities and differences, contradictions, and generalizations among sources of information. we describe the various components of the system, showing how information from multiple articles is combined, organized into a paragraph, and finally, realized as english sentences. a feature of our work is the extraction of descriptions of entities such as people and places for reuse to enhance a briefing.",
            "contribution_ids": [
                "R6576"
            ]
        },
        {
            "instance_id": "R6948xR6607",
            "comparison_id": "R6948",
            "paper_id": "R6607",
            "text": "GLEANS: A Generator of Logical Extracts and Abstracts for Nice Summaries generator postprocessor abstract with headline o j n u j n \\x80 j z y u y \\x7f y l jwith headline o j n u j n \\x80 j z y u y \\x7f y l j",
            "contribution_ids": [
                "R6608"
            ]
        },
        {
            "instance_id": "R69680xR69558",
            "comparison_id": "R69680",
            "paper_id": "R69558",
            "text": "A framework for explainable deep neural models using external knowledge graphs deep neural networks (dnns) have become the gold standard for solving challenging classification problems, especially given complex sensor inputs (e.g., images and video). while dnns are powerful, they are also brittle, and their inner workings are not fully understood by humans, leading to their use as \u201cblack-box\u201d models. dnns often generalize poorly when provided new data sampled from slightly shifted distributions; dnns are easily manipulated by adversarial examples; and the decision-making process of dnns can be difficult for humans to interpret. to address these challenges, we propose integrating dnns with external sources of semantic knowledge. large quantities of meaningful, formalized knowledge are available in knowledge graphs and other databases, many of which are publicly obtainable. but at present, these sources are inaccessible to deep neural methods, which can only exploit patterns in the signals they are given to classify. in this work, we conduct experiments on the ade20k dataset, using scene classification as an example task where combining dnns with external knowledge graphs can result in more robust and explainable models. we align the atomic concepts present in ade20k (i.e., objects) to wordnet, a hierarchically-organized lexical database. using this knowledge graph, we expand the concept categories which can be identified in ade20k and relate these concepts in a hierarchical manner. the neural architecture we present performs scene classification using these concepts, illuminating a path toward dnns which can efficiently exploit high-level knowledge in place of excessive quantities of direct sensory input. we hypothesize and experimentally validate that incorporating background knowledge via an external knowledge graph into a deep learning-based model should improve the explainability and robustness of the model.",
            "contribution_ids": [
                "R69559"
            ]
        },
        {
            "instance_id": "R69680xR69568",
            "comparison_id": "R69680",
            "paper_id": "R69568",
            "text": "Zero-shot recognition via semantic embeddings and knowledge graphs we consider the problem of zero-shot recognition: learning a visual classifier for a category with zero training examples, just using the word embedding of the category and its relationship to other categories, which visual data are provided. the key to dealing with the unfamiliar or novel category is to transfer knowledge obtained from familiar classes to describe the unfamiliar class. in this paper, we build upon the recently introduced graph convolutional network (gcn) and propose an approach that uses both semantic embeddings and the categorical relationships to predict the classifiers. given a learned knowledge graph (kg), our approach takes as input semantic embeddings for each node (representing visual category). after a series of graph convolutions, we predict the visual classifier for each category. during training, the visual classifiers for a few categories are given to learn the gcn parameters. at test time, these filters are used to predict the visual classifiers of unseen categories. we show that our approach is robust to noise in the kg. more importantly, our approach provides significant improvement in performance compared to the current state-of-the-art results (from 2 ~ 3% on some metrics to whopping 20% on a few).",
            "contribution_ids": [
                "R69569"
            ]
        },
        {
            "instance_id": "R69680xR69577",
            "comparison_id": "R69680",
            "paper_id": "R69577",
            "text": "Knowledgeable reader: Enhancing cloze-style read- ing comprehension with external commonsense knowledge we introduce a neural reading comprehension model that integrates external commonsense knowledge, encoded as a key-value memory, in a cloze-style setting. instead of relying only on document-to-question interaction or discrete features as in prior work, our model attends to relevant external knowledge and combines this knowledge with the context representation before inferring the answer. this allows the model to attract and imply knowledge from an external knowledge source that is not explicitly stated in the text, but that is relevant for inferring the answer. our model improves results over a very strong baseline on a hard common nouns dataset, making it a strong competitor of much more complex models. by including knowledge explicitly, our model can also provide evidence about the background knowledge used in the rc process.",
            "contribution_ids": [
                "R69578"
            ]
        },
        {
            "instance_id": "R69680xR69584",
            "comparison_id": "R69680",
            "paper_id": "R69584",
            "text": "Exploring knowledge graphs in an interpretable composite approach for text entailment, recognizing textual entailment is a key task for many semantic applications, such as question answering, text summarization, and information extraction, among others. entailment scenarios can range from a simple syntactic variation to more complex semantic relationships between pieces of text, but most approaches try a one-size-fits-all solution that usually favors some scenario to the detriment of another. we propose a composite approach for recognizing text entailment which analyzes the entailment pair to decide whether it must be resolved syntactically or semantically. we also make the answer interpretable: whenever an entailment is solved semantically, we explore a knowledge base composed of structured lexical definitions to generate natural language humanlike justifications, explaining the semantic relationship holding between the pieces of text. besides outperforming wellestablished entailment algorithms, our composite approach gives an important step towards explainable ai, using world knowledge to make the semantic reasoning process explicit and understandable.",
            "contribution_ids": [
                "R69585"
            ]
        },
        {
            "instance_id": "R69680xR69592",
            "comparison_id": "R69680",
            "paper_id": "R69592",
            "text": "Conditional focused neural question answering with large-scale knowledge bases how can we enable computers to automatically answer questions like \"who created the character harry potter\"? carefully built knowledge bases provide rich sources of facts. however, it remains a challenge to answer factoid questions raised in natural language due to numerous expressions of one question. in particular, we focus on the most common questions --- ones that can be answered with a single fact in the knowledge base. we propose cfo, a conditional focused neural-network-based approach to answering factoid questions with knowledge bases. our approach first zooms in a question to find more probable candidate subject mentions, and infers the final answers with a unified conditional probabilistic framework. powered by deep recurrent neural networks and neural embeddings, our proposed cfo achieves an accuracy of 75.7% on a dataset of 108k questions - the largest public one to date. it outperforms the current state of the art by an absolute margin of 11.8%.",
            "contribution_ids": [
                "R69593"
            ]
        },
        {
            "instance_id": "R69680xR69599",
            "comparison_id": "R69680",
            "paper_id": "R69599",
            "text": "Explicit knowledge-based reasoning for visual question answering we describe a method for visual question answering which is capable of reasoning about an image on the basis of information extracted from a large-scale knowledge base. the method not only answers natural language questions using concepts not contained in the image, but can explain the reasoning by which it developed its answer. it is capable of answering far more complex questions than the predominant long short-term memory-based approach, and outperforms it significantly in testing. we also provide a dataset and a protocol by which to evaluate general visual question answering methods.",
            "contribution_ids": [
                "R69600"
            ]
        },
        {
            "instance_id": "R69680xR69619",
            "comparison_id": "R69680",
            "paper_id": "R69619",
            "text": "Knowledge-driven stock trend prediction and explanation via temporal convolutional network deep neural networks have achieved promising results in stock trend prediction. however, most of these models have two common drawbacks, including (i) current methods are not sensitive enough to abrupt changes of stock trend, and (ii) forecasting results are not interpretable for humans. to address these two problems, we propose a novel knowledge-driven temporal convolutional network (kdtcn) for stock trend prediction and explanation. firstly, we extract structured events from financial news, and utilize external knowledge from knowledge graph to obtain event embeddings. then, we combine event embeddings and price values together to forecast stock trend. we evaluate the prediction accuracy to show how knowledge-driven events work on abrupt changes. we also visualize the effect of events and linkage among events based on knowledge graph, to explain why knowledge-driven events are common sources of abrupt changes. experiments demonstrate that kdtcn can (i) react to abrupt changes much faster and outperform state-of-the-art methods on stock datasets, as well as (ii) facilitate the explanation of prediction particularly with abrupt changes.",
            "contribution_ids": [
                "R69620"
            ]
        },
        {
            "instance_id": "R69680xR69623",
            "comparison_id": "R69680",
            "paper_id": "R69623",
            "text": "Knowledge-based transfer learning explanation \"machine learning explanation can significantly boost machine learning's application in decision making, but the usability of current methods is limited in human-centric explanation, especially for transfer learning, an important machine learning branch that aims at utilizing knowledge from one learning domain (i.e., a pair of dataset and prediction task) to enhance prediction model training in another learning domain. in this paper , we propose an ontology-based approach for human-centric explanation of transfer learning. three kinds of knowledge-based explanatory evidence, with different granularities, including general factors, particular narrators and core contexts are first proposed and then inferred with both local ontologies and external knowledge bases. the evaluation with us flight data and db-pedia has presented their confidence and availability in explaining the transferability of feature representation in flight departure delay forecasting.\"",
            "contribution_ids": [
                "R69624"
            ]
        },
        {
            "instance_id": "R69680xR69626",
            "comparison_id": "R69680",
            "paper_id": "R69626",
            "text": "Semantic explanations of predictions the main objective of explanations is to transmit knowledge to humans. this work proposes to construct informative explanations for predictions made from machine learning models. motivated by the observations from social sciences, our approach selects data points from the training sample that exhibit special characteristics crucial for explanation, for instance, ones contrastive to the classification prediction and ones representative of the models. subsequently, semantic concepts are derived from the selected data points through the use of domain ontologies. these concepts are filtered and ranked to produce informative explanations that improves human understanding. the main features of our approach are that (1) knowledge about explanations is captured in the form of ontological concepts, (2) explanations include contrastive evidences in addition to normal evidences, and (3) explanations are user relevant.",
            "contribution_ids": [
                "R69627"
            ]
        },
        {
            "instance_id": "R69680xR69630",
            "comparison_id": "R69680",
            "paper_id": "R69630",
            "text": "Deep knowledge-aware network for news recommendation online news recommender systems aim to address the information explosion of news and make personalized recommendation for users. in general, news language is highly condensed, full of knowledge entities and common sense. however, existing methods are unaware of such external knowledge and cannot fully discover latent knowledge-level connections among news. the recommended results for a user are consequently limited to simple patterns and cannot be extended reasonably. to solve the above problem, in this paper, we propose a deep knowledge-aware network (dkn) that incorporates knowledge graph representation into news recommendation. dkn is a content-based deep recommendation framework for click-through rate prediction. the key component of dkn is a multi-channel and word-entity-aligned knowledge-aware convolutional neural network (kcnn) that fuses semantic-level and knowledge-level representations of news. kcnn treats words and entities as multiple channels, and explicitly keeps their alignment relationship during convolution. in addition, to address users\u00bb diverse interests, we also design an attention module in dkn to dynamically aggregate a user\u00bbs history with respect to current candidate news. through extensive experiments on a real online news platform, we demonstrate that dkn achieves substantial gains over state-of-the-art deep recommendation models. we also validate the efficacy of the usage of knowledge in dkn.",
            "contribution_ids": [
                "R69631"
            ]
        },
        {
            "instance_id": "R69680xR69641",
            "comparison_id": "R69680",
            "paper_id": "R69641",
            "text": "Explod: a framework for explaining recommendations based on the linked open data cloud in this paper we present explod, a framework which exploits the information available in the linked open data (lod) cloud to generate a natural language explanation of the suggestions produced by a recommendation algorithm. the methodology is based on building a graph in which the items liked by a user are connected to the items recommended through the properties available in the lod cloud. next, given this graph, we implemented some techniques to rank those properties and we used the most relevant ones to feed a module for generating explanations in natural language. in the experimental evaluation we performed a user study with 308 subjects aiming to investigate to what extent our explanation framework can lead to more transparent, trustful and engaging recommendations. the preliminary results provided us with encouraging findings, since our algorithm performed better than both a non-personalized explanation baseline and a popularity-based one.",
            "contribution_ids": [
                "R69642"
            ]
        },
        {
            "instance_id": "R70287xR69999",
            "comparison_id": "R70287",
            "paper_id": "R69999",
            "text": "Human organ chip-enabled pipeline to rapidly repurpose therapeutics during viral pandemics the rising threat of pandemic viruses, such as sars-cov-2, requires development of new preclinical discovery platforms that can more rapidly identify therapeutics that are active in vitro and also translate in vivo . here we show that human organ-on-a-chip (organ chip) microfluidic culture devices lined by highly differentiated human primary lung airway epithelium and endothelium can be used to model virus entry, replication, strain-dependent virulence, host cytokine production, and recruitment of circulating immune cells in response to infection by respiratory viruses with great pandemic potential. we provide a first demonstration of drug repurposing by using oseltamivir in influenza a virus-infected organ chip cultures and show that co-administration of the approved anticoagulant drug, nafamostat, can double oseltamivir\u2019s therapeutic time window. with the emergence of the covid-19 pandemic, the airway chips were used to assess the inhibitory activities of approved drugs that showed inhibition in traditional cell culture assays only to find that most failed when tested in the organ chip platform. when administered in human airway chips under flow at a clinically relevant dose, one drug \u2013 amodiaquine - significantly inhibited infection by a pseudotyped sars-cov-2 virus. proof of concept was provided by showing that amodiaquine and its active metabolite (desethylamodiaquine) also significantly reduce viral load in both direct infection and animal-to-animal transmission models of native sars-cov-2 infection in hamsters. these data highlight the value of organ chip technology as a more stringent and physiologically relevant platform for drug repurposing, and suggest that amodiaquine should be considered for future clinical testing.",
            "contribution_ids": [
                "R70000",
                "R70045"
            ]
        },
        {
            "instance_id": "R70287xR51231",
            "comparison_id": "R70287",
            "paper_id": "R51231",
            "text": "Broad anti-coronaviral activity of FDA approved drugs against SARS-CoV-2 in vitro and SARS-CoV in vivo abstract sars-cov-2 emerged in china at the end of 2019 and has rapidly become a pandemic with roughly 2.7 million recorded covid-19 cases and greater than 189,000 recorded deaths by april 23rd, 2020 ( www.who.org ). there are no fda approved antivirals or vaccines for any coronavirus, including sars-cov-2. current treatments for covid-19 are limited to supportive therapies and off-label use of fda approved drugs. rapid development and human testing of potential antivirals is greatly needed. a quick way to test compounds with potential antiviral activity is through drug repurposing. numerous drugs are already approved for human use and subsequently there is a good understanding of their safety profiles and potential side effects, making them easier to fast-track to clinical studies in covid-19 patients. here, we present data on the antiviral activity of 20 fda approved drugs against sars-cov-2 that also inhibit sars-cov and mers-cov. we found that 17 of these inhibit sars-cov-2 at a range of ic50 values at non-cytotoxic concentrations. we directly follow up with seven of these to demonstrate all are capable of inhibiting infectious sars-cov-2 production. moreover, we have evaluated two of these, chloroquine and chlorpromazine, in vivo using a mouse-adapted sars-cov model and found both drugs protect mice from clinical disease.",
            "contribution_ids": [
                "R70095",
                "R70138",
                "R70153",
                "R70172",
                "R51233",
                "R51413"
            ]
        },
        {
            "instance_id": "R70287xR51386",
            "comparison_id": "R70287",
            "paper_id": "R51386",
            "text": "In vitro screening of a FDA approved chemical library reveals potential inhibitors of SARS-CoV-2 replication abstract a novel coronavirus, named sars-cov-2, emerged in 2019 in china and rapidly spread worldwide. as no approved therapeutics exists to treat covid-19, the disease associated to sars-cov-2, there is an urgent need to propose molecules that could quickly enter into clinics. repurposing of approved drugs is a strategy that can bypass the time-consuming stages of drug development. in this study, we screened the prestwick chemical library composed of 1,520 approved drugs in an infected cell-based assay. the robustness of the screen was assessed by the identification of drugs that already demonstrated in vitro antiviral effect against sars-cov-2. thereby, 90 compounds were identified as positive hits from the screen and were grouped according to their chemical composition and their known therapeutic effect. then ec50 and cc50 were determined for a subset of 15 compounds from a panel of 23 selected drugs covering the different groups. eleven compounds such as macrolides antibiotics, proton pump inhibitors, antiarrhythmic agents or cns drugs emerged showing antiviral potency with 2\\u2009&lt;\\u2009ec50\\u2009\u2264\\u200920\\xa0\u00b5m. by providing new information on molecules inhibiting sars-cov-2 replication in vitro, this study provides information for the selection of drugs to be further validated in vivo. disclaimer: this study corresponds to the early stages of antiviral development and the results do not support by themselves the use of the selected drugs to treat sars-cov-2 infection.",
            "contribution_ids": [
                "R51388",
                "R51404"
            ]
        },
        {
            "instance_id": "R70584xR70554",
            "comparison_id": "R70584",
            "paper_id": "R70554",
            "text": "Prediction of Sepsis in the Intensive Care Unit With Minimal Electronic Health Record Data: A Machine Learning Approach background sepsis is one of the leading causes of mortality in hospitalized patients. despite this fact, a reliable means of predicting sepsis onset remains elusive. early and accurate sepsis onset predictions could allow more aggressive and targeted therapy while maintaining antimicrobial stewardship. existing detection methods suffer from low performance and often require time-consuming laboratory test results. objective to study and validate a sepsis prediction method, insight, for the new sepsis-3 definitions in retrospective data, make predictions using a minimal set of variables from within the electronic health record data, compare the performance of this approach with existing scoring systems, and investigate the effects of data sparsity on insight performance. methods we apply insight, a machine learning classification system that uses multivariable combinations of easily obtained patient data (vitals, peripheral capillary oxygen saturation, glasgow coma score, and age), to predict sepsis using the retrospective multiparameter intelligent monitoring in intensive care (mimic)-iii dataset, restricted to intensive care unit (icu) patients aged 15 years or more. following the sepsis-3 definitions of the sepsis syndrome, we compare the classification performance of insight versus quick sequential organ failure assessment (qsofa), modified early warning score (mews), systemic inflammatory response syndrome (sirs), simplified acute physiology score (saps) ii, and sequential organ failure assessment (sofa) to determine whether or not patients will become septic at a fixed period of time before onset. we also test the robustness of the insight system to random deletion of individual input observations. results in a test dataset with 11.3% sepsis prevalence, insight produced superior classification performance compared with the alternative scores as measured by area under the receiver operating characteristic curves (auroc) and area under precision-recall curves (apr). in detection of sepsis onset, insight attains auroc = 0.880 (sd 0.006) at onset time and apr = 0.595 (sd 0.016), both of which are superior to the performance attained by sirs (auroc: 0.609; apr: 0.160), qsofa (auroc: 0.772; apr: 0.277), and mews (auroc: 0.803; apr: 0.327) computed concurrently, as well as saps ii (auroc: 0.700; apr: 0.225) and sofa (auroc: 0.725; apr: 0.284) computed at admission (p<.001 for all comparisons). similar results are observed for 1-4 hours preceding sepsis onset. in experiments where approximately 60% of input data are deleted at random, insight attains an auroc of 0.781 (sd 0.013) and apr of 0.401 (sd 0.015) at sepsis onset time. even with 60% of data missing, insight remains superior to the corresponding sirs scores (auroc and apr, p<.001), qsofa scores (p=.0095; p<.001) and superior to sofa and saps ii computed at admission (auroc and apr, p<.001), where all of these comparison scores (except insight) are computed without data deletion. conclusions despite using little more than vitals, insight is an effective tool for predicting sepsis onset and performs well even with randomly missing data.",
            "contribution_ids": [
                "R70555",
                "R70577"
            ]
        },
        {
            "instance_id": "R70584xR70566",
            "comparison_id": "R70584",
            "paper_id": "R70566",
            "text": "From vital signs to clinical outcomes for patients with sepsis: a machine learning basis for a clinical decision support system \"objective\\nto develop a decision support system to identify patients at high risk for hyperlactatemia based upon routinely measured vital signs and laboratory studies.\\n\\n\\nmaterials and methods\\nelectronic health records of 741 adult patients at the university of california davis health system who met at least two systemic inflammatory response syndrome criteria were used to associate patients' vital signs, white blood cell count (wbc), with sepsis occurrence and mortality. generative and discriminative classification (na\u00efve bayes, support vector machines, gaussian mixture models, hidden markov models) were used to integrate heterogeneous patient data and form a predictive tool for the inference of lactate level and mortality risk.\\n\\n\\nresults\\nan accuracy of 0.99 and discriminability of 1.00 area under the receiver operating characteristic curve (auc) for lactate level prediction was obtained when the vital signs and wbc measurements were analysed in a 24 h time bin. an accuracy of 0.73 and discriminability of 0.73 auc for mortality prediction in patients with sepsis was achieved with only three features: median of lactate levels, mean arterial pressure, and median absolute deviation of the respiratory rate.\\n\\n\\ndiscussion\\nthis study introduces a new scheme for the prediction of lactate levels and mortality risk from patient vital signs and wbc. accurate prediction of both these variables can drive the appropriate response by clinical staff and thus may have important implications for patient health and treatment outcome.\\n\\n\\nconclusions\\neffective predictions of lactate levels and mortality risk can be provided with a few clinical variables when the temporal aspect and variability of patient data are considered.\"",
            "contribution_ids": [
                "R70567",
                "R70583"
            ]
        },
        {
            "instance_id": "R70630xR70616",
            "comparison_id": "R70630",
            "paper_id": "R70616",
            "text": "An Unsupervised Multivariate Time Series Kernel Approach for Identifying Patients with Surgical Site Infection from Blood Samples a large fraction of the electronic health records consists of clinical measurements collected over time, such as blood tests, which provide important information about the health status of a patient. these sequences of clinical measurements are naturally represented as time series, characterized by multiple variables and the presence of missing data, which complicate analysis. in this work, we propose a surgical site infection detection framework for patients undergoing colorectal cancer surgery that is completely unsupervised, hence alleviating the problem of getting access to labelled training data. the framework is based on powerful kernels for multivariate time series that account for missing data when computing similarities. our approach show superior performance compared to baselines that have to resort to imputation techniques and performs comparable to a supervised classification baseline.",
            "contribution_ids": [
                "R70617"
            ]
        },
        {
            "instance_id": "R70630xR70622",
            "comparison_id": "R70630",
            "paper_id": "R70622",
            "text": "Improving Prediction of Surgical Site Infection Risk with Multilevel Modeling background surgical site infection (ssi) surveillance is a key factor in the elaboration of strategies to reduce ssi occurrence and in providing surgeons with appropriate data feedback (risk indicators, clinical prediction rule). aim to improve the predictive performance of an individual-based ssi risk model by considering a multilevel hierarchical structure. patients and methods data were collected anonymously by the french ssi active surveillance system in 2011. an ssi diagnosis was made by the surgical teams and infection control practitioners following standardized criteria. a random 20% sample comprising 151 hospitals, 502 wards and 62280 patients was used. three-level (patient, ward, hospital) hierarchical logistic regression models were initially performed. parameters were estimated using the simulation-based markov chain monte carlo procedure. results a total of 623 ssi were diagnosed (1%). the hospital level was discarded from the analysis as it did not contribute to variability of ssi occurrence (p \\u200a=\\u200a0.32). established individual risk factors (patient history, surgical procedure and hospitalization characteristics) were identified. a significant heterogeneity in ssi occurrence between wards was found (median odds ratio [mor] 3.59, 95% credibility interval [ci] 3.03 to 4.33) after adjusting for patient-level variables. the effects of the follow-up duration varied between wards (p<10\u22129), with an increased heterogeneity when follow-up was <15 days (mor 6.92, 95% ci 5.31 to 9.07]). the final two-level model significantly improved the discriminative accuracy compared to the single level reference model (p<10\u22129), with an area under the roc curve of 0.84. conclusion this study sheds new light on the respective contribution of patient-, ward- and hospital-levels to ssi occurrence and demonstrates the significant impact of the ward level over and above risk factors present at patient level (i.e., independently from patient case-mix).",
            "contribution_ids": [
                "R70623"
            ]
        },
        {
            "instance_id": "R76783xR76754",
            "comparison_id": "R76783",
            "paper_id": "R76754",
            "text": "A Comprehensive Survey of Knowledge Graph Embeddings with Literals: Techniques and Applications knowledge graphs are organized to describe entities from any discipline and the interrelations between them. apart from facilitating the inter-connectivity of datasets in the lod cloud, kgs have been used in a variety of applications such as web search or entity linking, and recently are part of popular search systems and q&a applications etc. however, the kg applications suffer from high computational and storage cost. hence, there arises the necessity of having a representation learning of the high dimensional kgs into low dimensional spaces preserving structural as well as relational information. in this study, we conduct a comprehensive survey based on techniques of kg embedding models which consider the structured information of the graph as well as the unstructured information in form of literals such as text, numerical values etc. furthermore, we address the challenges in their embedding models followed by a discussion on different application scenarios.",
            "contribution_ids": [
                "R76756"
            ]
        },
        {
            "instance_id": "R76783xR75675",
            "comparison_id": "R76783",
            "paper_id": "R75675",
            "text": "Knowledge Graph Refinement: A Survey of Approaches and Evaluation Methods in the recent years, different web knowledge graphs, both free and commercial, have been created. while google coined the term \"knowledge graph\" in 2012, there are also a few openly available knowledge graphs, with dbpedia, yago, and freebase being among the most prominent ones. those graphs are often constructed from semi-structured knowledge, such as wikipedia, or harvested from the web with a combination of statistical and linguistic methods. the result are large-scale knowledge graphs that try to make a good trade-off between completeness and correctness. in order to further increase the utility of such knowledge graphs, various refinement methods have been proposed, which try to infer and add missing knowledge to the graph, or identify erroneous pieces of information. in this article, we provide a survey of such knowledge graph refinement approaches, with a dual look at both the methods being proposed as well as the evaluation methodologies used.",
            "contribution_ids": [
                "R75677"
            ]
        },
        {
            "instance_id": "R8342xR8330",
            "comparison_id": "R8342",
            "paper_id": "R8330",
            "text": "An ontology of scientific experiments the formal description of experiments for efficient analysis, annotation and sharing of results is a fundamental part of the practice of science. ontologies are required to achieve this objective. a few subject-specific ontologies of experiments currently exist. however, despite the unity of scientific experimentation, no general ontology of experiments exists. we propose the ontology expo to meet this need. expo links the sumo (the suggested upper merged ontology) with subject-specific ontologies of experiments by formalizing the generic concepts of experimental design, methodology and results representation. expo is expressed in the w3c standard ontology language owl-dl. we demonstrate the utility of expo and its ability to describe different experimental domains, by applying it to two experiments: one in high-energy physics and the other in phylogenetics. the use of expo made the goals and structure of these experiments more explicit, revealed ambiguities, and highlighted an unexpected similarity. we conclude that, expo is of general value in describing experiments and a step towards the formalization of science.",
            "contribution_ids": [
                "R8331"
            ]
        },
        {
            "instance_id": "EMPTYxR107933",
            "comparison_id": "EMPTY",
            "paper_id": "R107933",
            "text": "The Ontology-based Business Architecture Engineering Framework business architecture became a well-known tool for business transformations. according to a recent study by forrester, 50 percent of the companies polled claimed to have an active business architecture initiative, whereas 20 percent were planning to engage in business architecture work in the near future. however, despite the high interest in ba, there is not yet a common understanding of the main concepts. there is a lack for the business architecture framework which provides a complete metamodel, suggests methodology for business architecture development and enables tool support for it. the org- master framework is designed to solve this problem using the ontology as a core of the metamodel. this paper describes the org-master framework, its implementation and dissemination.",
            "contribution_ids": [
                "R107935"
            ]
        },
        {
            "instance_id": "EMPTYxR8245",
            "comparison_id": "EMPTY",
            "paper_id": "R8245",
            "text": "Knowledge base shipping to the linked open data cloud popular knowledge bases that provide sparql endpoints for the web are usually experiencing a high number of requests, which often results in low availability of their interfaces. a common approach to counter the availability issue is to run a local mirror of the knowledge base. running a sparql endpoint is currently a complex task which requires a lot of effort and technical support for domain experts who just want to use the sparql interface. with our approach of containerised knowledge base shipping we are introducing a simple to setup methodology for running a local mirror of an rdf knowledge base and sparql endpoint with interchangeable exploration components. the flexibility of the presented approach further helps maintaining the publication infrastructure for dataset projects. we are demonstrating and evaluating the presented methodology at the example of the dataset projects dbpedia, catalogus professorum lipsiensium and s\u00e4chsisches pfarrerbuch.",
            "contribution_ids": [
                "R8246",
                "R8249"
            ]
        },
        {
            "instance_id": "EMPTYxR110487",
            "comparison_id": "EMPTY",
            "paper_id": "R110487",
            "text": "An analysis of Service Level Agreement parameters and scheduling in Multi-Tenant Cloud Systems in cloud systems it usually the case that there exists a multi-tenancy of cloud service customers meaning that some cloud service customers applications share the same cloud infrastructure. in this situation there must exist a service level agreement (sla) contract between the multi-tenant cloud service provider (mtcsp) and the cloud service customers (cscs). in this article we discuss about the parameters of an sla in the cloud and we particularize it in the case of multi-tenancy. we analyze and implement two algorithms with the purpose of optimizing the scheduling of tasks from the tenants of the multi-tenant cloud service. the results show that the algorithms can be used in different situations with good results.",
            "contribution_ids": [
                "R110489"
            ]
        },
        {
            "instance_id": "EMPTYxR141340",
            "comparison_id": "EMPTY",
            "paper_id": "R141340",
            "text": "Quantification of new production during a winterNoctiluca scintillansbloom in the Arabian Sea we present new data on the nitrate (new production), ammonium, urea uptake rates and f\u2010ratios for the eastern arabian sea (10\u00b0 to 22\u00b0n) during the late winter (northeast) monsoon, 2004, including regions of green noctilucascintillans bloom. a comparison of n\u2010uptake rates of the noctiluca dominated northern zone to the southern non\u2010bloom zone indicates the presence of two biogeochemical regimes during the late winter monsoon: highly productive north and less productive south. the conservative estimates of photic zone\u2010integrated total n\u2010uptake and f\u2010ratio are high in the north (\u223c19 mmolnm\u22122d\u22121 and 0.82, respectively) during the bloom and low (\u223c5.5 mmolnm\u22122d\u22121 and 0.38 respectively) in the south. the present and earlier data imply persistence of high n\u2010uptake and f\u2010ratio during blooms year after year. this quantification of the enhanced seasonal sequestration of carbon is an important input to global biogeochemical models.",
            "contribution_ids": [
                "R141341"
            ]
        },
        {
            "instance_id": "EMPTYxR144754",
            "comparison_id": "EMPTY",
            "paper_id": "R144754",
            "text": "Influenza surveillance in England and Wales using routine statistics: Development of \u2018cusum\u2019 graphs to compare 12 previous winters and to monitor the 1980/81 winter summary surveillance of influenza in england and wales is made by monitoring weekly data. principal indices are deaths, sickness-benefit claims (sbc), laboratory reports and observations from general practitioners (gps). the 12 winters 1968/9 to 1979/80 have been studied to see which indices best described size and timing of influenza epidemics. a method of plotting the data (called cusums) is suggested which makes it easier to see the effect of small epidemics. cusums for gp statistics and respiratory deaths were found to be the most helpful indices for describing both size and timing of the epidemics, followed by total deaths and sbc, which were less specific to influenza, and influenza deaths, which lagged behind other indices. deaths certified as pneumonia have been increasing over these years, whereas bronchitis deaths have been decreasing and these indices should not be used separately for monitoring. the laboratory reporting system is important. it confirms the presence of influenza virus in the community and indicates prevalent strains. because it is a voluntary system with no defined population base the reports are not reliable numerically for estimating relative size of epidemics or for developing cusums. cusum plots were unanimous in describing the winter of 1980/1 as one of little influenza activity.",
            "contribution_ids": [
                "R144756"
            ]
        },
        {
            "instance_id": "EMPTYxR145076",
            "comparison_id": "EMPTY",
            "paper_id": "R145076",
            "text": "Survey of Clostridium difficile infection surveillance systems in Europe, 2011 to develop a european surveillance protocol for clostridium difficile infection (cdi), existing national cdi surveillance systems were assessed in 2011. a web-based electronic form was provided for all national coordinators of the european cdi surveillance network (ecdis-net). of 35 national coordinators approached, 33 from 31 european countries replied. surveillance of cdi was in place in 14 of the 31 countries, comprising 18 different nationwide systems. three of 14 countries with cdi surveillance used public health notification of cases as the route of reporting, and in another three, reporting was limited to public health notification of cases of severe cdi. the cdi definitions published by the european society of clinical microbiology and infectious diseases (escmid) and the european centre for disease prevention and control (ecdc) were widely used, but there were differing definitions to distinguish between community- and healthcare-associated cases. all cdi surveillance systems except one reported annual national cdi rates (calculated as number of cases per patient-days). only four surveillance systems regularly integrated microbiological data (typing and susceptibility testing results). surveillance methods varied considerably between countries, which emphasises the need for a harmonised european protocol to allow consistent monitoring of the cdi epidemiology at european level. the results of this survey were used to develop a harmonised eu-wide hospital-based cdi surveillance protocol.",
            "contribution_ids": [
                "R145078"
            ]
        },
        {
            "instance_id": "EMPTYxR145334",
            "comparison_id": "EMPTY",
            "paper_id": "R145334",
            "text": "Implementing Syndromic Surveillance: A Practical Guide Informed by the Early Experience syndromic surveillance refers to methods relying on detection of individual and population health indicators that are discernible before confirmed diagnoses are made. in particular, prior to the laboratory confirmation of an infectious disease, ill persons may exhibit behavioral patterns, symptoms, signs, or laboratory findings that can be tracked through a variety of data sources. syndromic surveillance systems are being developed locally, regionally, and nationally. the efforts have been largely directed at facilitating the early detection of a covert bioterrorist attack, but the technology may also be useful for general public health, clinical medicine, quality improvement, patient safety, and research. this report, authored by developers and methodologists involved in the design and deployment of the first wave of syndromic surveillance systems, is intended to serve as a guide for informaticians, public health managers, and practitioners who are currently planning deployment of such systems in their regions.",
            "contribution_ids": [
                "R145336"
            ]
        },
        {
            "instance_id": "EMPTYxR145340",
            "comparison_id": "EMPTY",
            "paper_id": "R145340",
            "text": "Evaluation of Syndromic Surveillance Systems in 6 US State and Local Health Departments \"objective: evaluating public health surveillance systems is critical to ensuring that conditions of public health importance are appropriately monitored. our objectives were to qualitatively evaluate 6 state and local health departments that were early adopters of syndromic surveillance in order to (1) understand the characteristics and current uses, (2) identify the most and least useful syndromes to monitor, (3) gauge the utility for early warning and outbreak detection, and (4) assess how syndromic surveillance impacted their daily decision making. design: we adapted evaluation guidelines from the centers for disease control and prevention and gathered input from the centers for disease control and prevention subject matter experts in public health surveillance to develop a questionnaire. participants: we interviewed staff members from a convenience sample of 6 local and state health departments with syndromic surveillance programs that had been in operation for more than 10 years. results: three of the 6 interviewees provided an example of using syndromic surveillance to identify an outbreak (ie, cluster of foodborne illness in 1 jurisdiction) or detect a surge in cases for seasonal conditions (eg, influenza in 2 jurisdictions) prior to traditional, disease-specific systems. although all interviewees noted that syndromic surveillance has not been routinely useful or efficient for early outbreak detection or case finding in their jurisdictions, all agreed that the information can be used to improve their understanding of dynamic disease control environments and conditions (eg, situational awareness) in their communities. conclusion: in the jurisdictions studied, syndromic surveillance may be useful for monitoring the spread and intensity of large outbreaks of disease, especially influenza; enhancing public health awareness of mass gatherings and natural disasters; and assessing new, otherwise unmonitored conditions when real-time alternatives are unavailable. future studies should explore opportunities to strengthen syndromic surveillance by including broader access to and enhanced analysis of text-related data from electronic health records. health departments may accelerate the development and use of syndromic surveillance systems, including the improvement of the predictive value and strengthening the early outbreak detection capability of these systems. these efforts support getting the right information to the right people at the right time, which is the overarching goal of cdc's surveillance strategy.\"",
            "contribution_ids": [
                "R145342"
            ]
        },
        {
            "instance_id": "EMPTYxR159789",
            "comparison_id": "EMPTY",
            "paper_id": "R159789",
            "text": "The Potential of Using Vision Videos for CrowdRE: Video Comments as a Source of Feedback vision videos are established for soliciting feedback and stimulating discussions in requirements engineering (re) practices such as focus groups. different researchers motivated the transfer of these benefits into crowd-based re (crowdre) by using vision videos on social media platforms. so far, however, little research explored the potential of using vision videos for crowdre in detail. in this paper, we analyze and assess this potential, in particular, focusing on video comments as a source of feedback. in a case study, we analyzed 4505 comments on a vision video from youtube. we found that the video solicited 2770 comments from 2660 viewers in four days. this is more than 50% of all comments the video received in four years. even though only a certain fraction of these comments are relevant to re, the relevant comments address typical intentions and topics of user feedback, such as feature request or problem report. besides the typical user feedback categories, we found more than 300 comments that address the topic safety which has not appeared in previous analyses of user feedback. in an automated analysis, we compared the performance of three machine learning algorithms on classifying the video comments. despite certain differences, the algorithms classified the video comments well. based on these findings, we conclude that the use of vision videos for crowdre has a large potential. despite the preliminary nature of the case study, we are optimistic that vision videos can motivate stakeholders to actively participate in a crowd and solicit numerous of video comments as a valuable source of feedback.",
            "contribution_ids": [
                "R175000"
            ]
        },
        {
            "instance_id": "EMPTYxR74516",
            "comparison_id": "EMPTY",
            "paper_id": "R74516",
            "text": "Measuring human values in software engineering \"background: human values, such as prestige, social justice, and financial success, influence software production decision-making processes. while their subjectivity makes some values difficult to measure, their impact on software motivates our research. aim: to contribute to the scientific understanding and the empirical investigation of human values in software engineering (se). approach: drawing from social psychology, we consider values as mental representations to be investigated on three levels: at a system (l1), personal (l2), and instantiation level (l3). method: we design and develop a selection of tools for the investigation of values at each level, and focus on the design, development, and use of the values q-sort. results: from our study with 12 software practitioners, it is possible to extract three values `prototypes' indicative of an emergent typology of values considerations in se. conclusions: the values q-sort generates quantitative values prototypes indicating values relations (l1) as well as rich personal narratives (l2) that reflect specific software practices (l3). it thus offers a systematic, empirical approach to capturing values in se.\"",
            "contribution_ids": [
                "R74518"
            ]
        },
        {
            "instance_id": "EMPTYxR75426",
            "comparison_id": "EMPTY",
            "paper_id": "R75426",
            "text": "Security and Cryptographic Challenges for Authentication Based on Biometrics Data authentication systems based on biometrics characteristics and data represents one of the most important trend in the evolution of the society, e.g., smart city, internet-of-things (iot), cloud computing, big data. in the near future, biometrics systems will be everywhere in the society, such as government, education, smart cities, banks etc. due to its uniqueness, characteristic, biometrics systems will become more and more vulnerable, privacy being one of the most important challenges. the classic cryptographic primitives are not sufficient to assure a strong level of secureness for privacy. the current paper has several objectives. the main objective consists in creating a framework based on cryptographic modules which can be applied in systems with biometric authentication methods. the technologies used in creating the framework are: c#, java, c++, python, and haskell. the wide range of technologies for developing the algorithms give the readers the possibility and not only, to choose the proper modules for their own research or business direction. the cryptographic modules contain algorithms based on machine learning and modern cryptographic algorithms: aes (advanced encryption system), sha-256, rc4, rc5, rc6, mars, blowfish, twofish, threefish, rsa (rivest-shamir-adleman), elliptic curve, and diffie hellman. as methods for implementing with success the cryptographic modules, we will propose a methodology which can be used as a how-to guide. the article will focus only on the first category, machine learning, and data clustering, algorithms with applicability in the cloud computing environment. for tests we have used a virtual machine (virtual box) with apache hadoop and a biometric analysis tool. the weakness of the algorithms and methods implemented within the framework will be evaluated and presented in order for the reader to acknowledge the latest status of the security analysis and the vulnerabilities founded in the mentioned algorithms. another important result of the authors consists in creating a scheme for biometric enrollment (in results). the purpose of the scheme is to give a big overview on how to use it, step by step, in real life, and how to use the algorithms. in the end, as a conclusion, the current work paper gives a comprehensive background on the most important and challenging aspects on how to design and implement an authentication system based on biometrics characteristics.",
            "contribution_ids": [
                "R75428"
            ]
        },
        {
            "instance_id": "EMPTYxR75435",
            "comparison_id": "EMPTY",
            "paper_id": "R75435",
            "text": "MapReduce: simplified data processing on large clusters \" \\n mapreduce is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. users specify the computation in terms of a\\n map \\n and a\\n reduce \\n function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. programmers find the system easy to use: more than ten thousand distinct mapreduce programs have been implemented internally at google over the past four years, and an average of one hundred thousand mapreduce jobs are executed on google's clusters every day, processing a total of more than twenty petabytes of data per day.\\n \"",
            "contribution_ids": [
                "R75437"
            ]
        },
        {
            "instance_id": "EMPTYxR108350",
            "comparison_id": "EMPTY",
            "paper_id": "R108350",
            "text": "Improving Usability of Software Refactoring Tools \"post-deployment maintenance and evolution can account for up to 75% of the cost of developing a software system. software refactoring can reduce the costs associated with evolution by improving system quality. although refactoring can yield benefits, the process includes potentially complex, error-prone, tedious and time-consuming tasks. it is these tasks that automated refactoring tools seek to address. however, although the refactoring process is well-defined, current refactoring tools do not support the full process. to develop better automated refactoring support, we have completed a usability study of software refactoring tools. in the study, we analysed the task of software refactoring using the iso 9241-11 usability standard and fitts' list of task allocation. expanding on this analysis, we reviewed 11 collections of usability guidelines and combined these into a single list of 38 guidelines. from this list, we developed 81 usability requirements for refactoring tools. using these requirements, the software refactoring tools eclipse 3.2, condenser 1.05, refactorit 2.5.1, and eclipse 3.2 with the simian ui 2.2.12 plugin were studied. based on the analysis, we have selected a subset of the requirements that can be incorporated into a prototype refactoring tool intended to address the full refactoring process.\"",
            "contribution_ids": [
                "R108352"
            ]
        },
        {
            "instance_id": "EMPTYxR193371",
            "comparison_id": "EMPTY",
            "paper_id": "R193371",
            "text": "Automated recommendation of templates for legal requirements [context] in legal requirements elicitation, requirements analysts need to extract obligations from legal texts. however, legal texts often express obligations only indirectly, for example, by attributing a right to the counterpart. this phenomenon has already been described in the requirements engineering (re) literature [1]. [objectives] we investigate the use of requirements templates for the systematic elicitation of legal requirements. our work is motivated by two observations: (1) the existing literature does not provide a harmonized view on the requirements templates that are useful for legal re; (2) despite the promising recent advancements in natural language processing (nlp), automated support for legal re through the suggestion of requirements templates has not been achieved yet. our objective is to take steps toward addressing these limitations. [methods] we review and reconcile the legal requirement templates proposed in re. subsequently, we conduct a qualitative study to define nlp rules for template recommendation. [results and conclusions] our contributions consist of (a) a harmonized list of requirements templates pertinent to legal re, and (b) rules for the automatic recommendation of such templates. we evaluate our rules through a case study on 400 statements from two legal domains. the results indicate a recall and precision of 82,3% and 79,8%, respectively. we show that introducing some limited interaction with the analyst considerably improves accuracy. specifically, our human-feedback strategy increases recall by 12% and precision by 10,8%, thus yielding an overall recall of 94,3% and overall precision of 90,6%.",
            "contribution_ids": [
                "R193373"
            ]
        },
        {
            "instance_id": "EMPTYxR193406",
            "comparison_id": "EMPTY",
            "paper_id": "R193406",
            "text": "Theory as a source of software requirements today, when undertaking requirements elicitation, engineers attend to the needs and wants of the user groups considered relevant for the software system. however, answers to some relevant question (e.g., how to improve adoption of the intended system) cannot always be addressed through direct need and want elicitation. using an example of energy demand-response systems, this paper demonstrates that use of grounded theory analysis can help address such questions. the theory emerging from such analysis produces a set of additional requirements which cannot be directly elicited from individuals/groups, and would otherwise be missed out. thus, we demonstrate that the theory generated through grounded theory analysis can serve as an additional valuable source of software system requirements.",
            "contribution_ids": [
                "R193408"
            ]
        },
        {
            "instance_id": "EMPTYxR193481",
            "comparison_id": "EMPTY",
            "paper_id": "R193481",
            "text": "Extracting and classifying requirements from software engineering contracts in this paper, we present our work on extracting and classifying requirements from large software engineering contracts. typically, the process of requirements elicitation begins after a contractual agreement is signed by all participants. our interactions with the legal compliance team in a large vendor organization reveal that business contracts can help in the identification of high-level requirements relevant to the success of software engineering projects. we posit that requirements engineering as a discipline has an even wider scope than software engineering of which it is traditionally considered to be a sub-discipline. this is because software engineering-specific requirements are but a part of the success story of any large project. the requirements that emerge from contracts are obligatory in nature, whether or not they pertain to core software development. therefore, it is important that these are extracted and classified for the benefit of software engineers and other stakeholders responsible for a project. we discuss the results of an exploratory study and a range of experiments from the use of regular expressions to bidirectional encoder representations from transformers for automating the extraction and classification of requirements from software engineering contracts. with bidirectional encoder representations from transformers, we obtained a high f-score of greater than eighty four percent for classification of requirements.",
            "contribution_ids": [
                "R193483"
            ]
        },
        {
            "instance_id": "EMPTYxR193490",
            "comparison_id": "EMPTY",
            "paper_id": "R193490",
            "text": "Which app features are being used? Learning app feature usages from interaction data in the dynamic and fast-growing app market, monitoring and understanding how past releases are actually being used is indispensable for successful app maintenance and evolution. current app usage analytics tools either log execution events, e.g., in stack traces, or general usage information such as the app activation time, location, and device. in this paper, we focus on analyzing the usages of the single app features as described in release notes and app pages. we suggest monitoring nine app-independent, privacy-friendly interaction events for training a machine learning model to learn app feature usages. we conducted a crowdsourcing study with 55 participants who labeled 5,815 feature usages of 170 unique apps for 18 days. our within-apps evaluation shows that we could achieve encouraging precision and recall values already with ten labeled feature usages. for certain popular features such as browse newsfeed or send an email, we achieved f1 values above 88%. betweenapps feature learning seems feasible with f1 values of up to 86%.",
            "contribution_ids": [
                "R193492"
            ]
        },
        {
            "instance_id": "EMPTYxR193925",
            "comparison_id": "EMPTY",
            "paper_id": "R193925",
            "text": "Trace link recovery using semantic relation graphs and spreading activation trace link recovery tries to identify and link related existing requirements with each other to support further engineering tasks. existing approaches are mainly based on algebraic information retrieval or machine-learning. machinelearning approaches usually demand reasonably large and labeled datasets to train. algebraic information retrieval approaches like distance between tf-idf scores also work on smaller datasets without training but are limited in providing explanations for trace links. in this work, we present a trace link recovery approach that is based on an explicit representation of the content of requirements as a semantic relation graph and uses spreading activation to answer trace queries over this graph. our approach is fully automated including an nlp pipeline to transform unrestricted natural language requirements into a graph. we evaluate our approach on five common datasets. depending on the selected configuration, the predictive power strongly varies. with the best tested configuration, the approach achieves a mean average precision of 40% and a lag of 50%. even though the predictive power of our approach does not outperform state-of-the-art approaches, we think that an explicit knowledge representation is an interesting artifact to explore in trace link recovery approaches to generate explanations and refine results.",
            "contribution_ids": [
                "R193926"
            ]
        },
        {
            "instance_id": "EMPTYxR39020",
            "comparison_id": "EMPTY",
            "paper_id": "R39020",
            "text": "A data-driven assessment of early travel restrictions related to the spreading of the novel COVID-19 within mainland China two months after it was firstly reported, the novel coronavirus disease covid-19 has already spread worldwide. however, the vast majority of reported infections have occurred in china. to assess the effect of early travel restrictions adopted by the health authorities in china, we have implemented an epidemic metapopulation model that is fed with mobility data corresponding to 2019 and 2020. this allows to compare two radically different scenarios, one with no travel restrictions and another in which mobility is reduced by a travel ban. our findings indicate that i) travel restrictions are an effective measure in the short term, however, ii) they are ineffective when it comes to completely eliminate the disease. the latter is due to the impossibility of removing the risk of seeding the disease to other regions. our study also highlights the importance of developing more realistic models of behavioral changes when a disease outbreak is unfolding.",
            "contribution_ids": [
                "R39021",
                "R39022",
                "R39023",
                "R39024",
                "R39025",
                "R39027",
                "R39029",
                "R39031",
                "R39033",
                "R39035",
                "R39037",
                "R39039",
                "R39041",
                "R39043",
                "R39045",
                "R39047",
                "R39049",
                "R39051",
                "R39053",
                "R39055",
                "R39057",
                "R39059",
                "R39061",
                "R39062",
                "R39064",
                "R39066",
                "R39068",
                "R39070",
                "R39072",
                "R39074",
                "R39076"
            ]
        },
        {
            "instance_id": "EMPTYxR41169",
            "comparison_id": "EMPTY",
            "paper_id": "R41169",
            "text": "Statistics based predictions of coronavirus 2019-nCoV spreading in mainland China abstract background the epidemic outbreak cased by coronavirus 2019-ncov is of great interest to researches because of the high rate of spread of the infection and the significant number of fatalities. a detailed scientific analysis of the phenomenon is yet to come, but the public is already interested in the questions of the duration of the epidemic, the expected number of patients and deaths. for long time predictions, the complicated mathematical models are necessary which need many efforts for unknown parameters identification and calculations. in this article, some preliminary estimates will be presented. objective since the reliable long time data are available only for mainland china, we will try to predict the epidemic characteristics only in this area. we will estimate some of the epidemic characteristics and present the most reliable dependences for victim numbers, infected and removed persons versus time. methods in this study we use the known sir model for the dynamics of an epidemic, the known exact solution of the linear equations and statistical approach developed before for investigation of the children disease, which occurred in chernivtsi (ukraine) in 1988-1989. results the optimal values of the sir model parameters were identified with the use of statistical approach. the numbers of infected, susceptible and removed persons versus time were predicted. conclusions simple mathematical model was used to predict the characteristics of the epidemic caused by coronavirus 2019-ncov in mainland china. the further research should focus on updating the predictions with the use of fresh data and using more complicated mathematical models.",
            "contribution_ids": [
                "R41170",
                "R41171",
                "R41172"
            ]
        },
        {
            "instance_id": "EMPTYxR200003",
            "comparison_id": "EMPTY",
            "paper_id": "R200003",
            "text": "Detection of Antibodies against Norovirus Genogroup GIV in Carnivores abstract \\n noroviruses (novs) resembling human nov genotype giv (alphatron-like) have recently been detected in carnivores. by using an enzyme-linked immunosorbent assay based on baculovirus-expressed capsid protein vp1 of lion strain ggiv.2/pistoia/387/06/ita, nov-specific antibodies were detected in cats (16.11%) and dogs (4.8%), demonstrating that these animals are exposed to infections caused by novs.",
            "contribution_ids": [
                "R200005"
            ]
        },
        {
            "instance_id": "EMPTYxR202083",
            "comparison_id": "EMPTY",
            "paper_id": "R202083",
            "text": "Genetic Diversity and Histo-Blood Group Antigen Interactions of Rhesus Enteric Caliciviruses abstract recently, we reported the discovery and characterization of tulane virus (tv), a novel rhesus calicivirus (cv) (t. farkas, k. sestak, c. wei, and x. jiang, j. virol. 82: 5408-5416, 2008). tv grows well in tissue culture, and it represents a new genus within caliciviridae , with the proposed name of recovirus . we also reported a high prevalence of cv antibodies in macaques of the tulane national primate research center (tnprc) colony, including anti-norovirus (nov), anti-sapovirus (sav), and anti-tv (t. farkas, j. dufour, x. jiang, and k. sestak, j. gen. virol. 91:734-738, 2010). to broaden our knowledge about cv infections in captive nonhuman primates (nhp), 500 rhesus macaque stool samples collected from breeding colony tnprc macaques were tested for cvs. fifty-seven (11%) samples contained recovirus isolates. in addition, one nov was detected. phylogenetic analysis classified the recovirus isolates into two genogroups and at least four genetic types. the rhesus nov isolate was closely related to gii human novs. tv-neutralizing antibodies were detected in 88% of serum samples obtained from primate caretakers. binding and plaque reduction assays revealed the involvement of type a and b histo-blood group antigens (hbga) in tv infection. taken together, these findings indicate the zoonotic potential of primate cvs. the discovery of a genetically diverse and prevalent group of primate cvs and remarkable similarities between rhesus enteric cvs and human novs opens new possibilities for research involving in vitro and in vivo models of human nov gastroenteritis.",
            "contribution_ids": [
                "R202085"
            ]
        },
        {
            "instance_id": "EMPTYxR138611",
            "comparison_id": "EMPTY",
            "paper_id": "R138611",
            "text": "Paclitaxel/Chitosan Nanosupensions Provide Enhanced Intravesical Bladder Cancer Therapy with Sustained and Prolonged Delivery of Paclitaxel bladder cancer (bc) is a very common cancer. nonmuscle-invasive bladder cancer (nmibc) is the most common type of bladder cancer. after postoperative tumor resection, chemotherapy intravesical instillation is recommended as a standard treatment to significantly reduce recurrences. nanomedicine-mediated delivery of a chemotherapeutic agent targeting cancer could provide a solution to obtain longer residence time and high bioavailability of an anticancer drug. the approach described here provides a nanomedicine with sustained and prolonged delivery of paclitaxel and enhanced therapy of intravesical bladder cancer, which is paclitaxel/chitosan (ptx/cs) nanosupensions (nss). the positively charged ptx/cs nss exhibited a rod-shaped morphology with a mean diameter about 200 nm. they have good dispersivity in water without any protective agents, and the positively charged properties make them easy to be adsorbed on the inner mucosa of the bladder through electrostatic adsorption. ptx/cs nss also had a high drug loading capacity and can maintain sustained release of paclitaxel which could be prolonged over 10 days. cell experiments in vitro demonstrated that ptx/cs nss had good biocompatibility and effective bladder cancer cell proliferation inhibition. the significant anticancer efficacy against intravesical bladder cancer was verified by an in situ bladder cancer model. the paclitaxel/chitosan nanosupensions could provide sustained delivery of chemotherapeutic agents with significant anticancer efficacy against intravesical bladder cancer.",
            "contribution_ids": [
                "R138615"
            ]
        },
        {
            "instance_id": "EMPTYxR140238",
            "comparison_id": "EMPTY",
            "paper_id": "R140238",
            "text": "Oral Drug Delivery Systems for Ulcerative Colitis Therapy: A Comparative Study with Microparticles and Nanoparticles \\n background: \\n oral administrations of microparticles (mps) and nanoparticles (nps) have\\nbeen widely employed as therapeutic approaches for the treatment of ulcerative colitis (uc). however,\\nno previous study has comparatively investigated the therapeutic efficacies of mps and nps.\\n \\n \\n methods: \\n in this study, curcumin (cur)-loaded mps (cur-mps) and cur-loaded nps (cur-nps)\\nwere prepared using a single water-in-oil emulsion solvent evaporation technique. their therapeutic\\noutcomes against uc were further comparatively studied.\\n \\n \\n results: \\n the resultant spherical mps and nps exhibited slightly negative zeta-potential with average\\nparticle diameters of approximately 1.7 &amp;#181;m and 270 nm, respectively. it was found that nps exhibited\\na much higher cur release rate than mps within the same period of investigation. in vivo experiments\\ndemonstrated that oral administration of cur-mps and cur-nps reduced the symptoms\\nof inflammation in a uc mouse model induced by dextran sulfate sodium. importantly, cur-nps\\nshowed much better therapeutic outcomes in alleviating uc compared with cur-mps.\\n \\n \\n conclusion: \\n nps can improve the anti-inflammatory activity of cur by enhancing the drug release\\nand cellular uptake efficiency, in comparison with mps. thus, they could be exploited as a promising\\noral drug delivery system for effective uc treatment. \\n",
            "contribution_ids": [
                "R140240"
            ]
        },
        {
            "instance_id": "EMPTYxR144137",
            "comparison_id": "EMPTY",
            "paper_id": "R144137",
            "text": "Low active loading of cargo into engineered extracellular vesicles results in inefficient miRNA mimic delivery abstract extracellular vesicles (evs) hold great potential as novel systems for nucleic acid delivery due to their natural composition. our goal was to load evs with microrna that are synthesized by the cells that produce the evs. hek293t cells were engineered to produce evs expressing a lysosomal associated membrane, lamp2a fusion protein. the gene encoding pre-mir-199a was inserted into an artificial intron of the lamp2a fusion protein. the tat peptide/hiv-1 transactivation response (tar) rna interacting peptide was exploited to enhance the ev loading of the pre-mir-199a containing a modified tar rna loop. computational modeling demonstrated a stable interaction between the modified pre-mir-199a loop and tat peptide. emsa gel shift, recombinant dicer processing and luciferase binding assays confirmed the binding, processing and functionality of the modified pre-mir-199a. the tat-tar interaction enhanced the loading of the mir-199a into evs by 65-fold. endogenously loaded evs were ineffective at delivering active mir-199a-3p therapeutic to recipient sk-hep1 cells. while the low degree of mirna loading into evs through this approach resulted in inefficient distribution of rna cargo into recipient cells, the tat tar strategy to load mirna into evs may be valuable in other drug delivery approaches involving mirna mimics or other hairpin containing rnas.",
            "contribution_ids": [
                "R144142"
            ]
        },
        {
            "instance_id": "EMPTYxR144462",
            "comparison_id": "EMPTY",
            "paper_id": "R144462",
            "text": "Surface Functionalization of PLGA Nanoparticles to Increase Transport across the BBB for Alzheimer\u2019s Disease alzheimer\u2019s disease (ad) is a chronic neurodegenerative disorder that accounts for about 60% of all diagnosed cases of dementia worldwide. although there are currently several drugs marketed for its treatment, none are capable of slowing down or stopping the progression of ad. the role of the blood-brain barrier (bbb) plays a key role in the design of a successful treatment for this neurodegenerative disease. nanosized particles have been proposed as suitable drug delivery systems to overcome bbb with the purpose of increasing bioavailability of drugs in the brain. biodegradable poly (lactic-co-glycolic acid) nanoparticles (plga-nps) have been particularly regarded as promising drug delivery systems as they can be surface-tailored with functionalized molecules for site-specific targeting. in this review, a thorough discussion about the most recent functionalization strategies based on plga-nps for ad and their mechanisms of action is provided, together with a description of ad pathogenesis and the role of the bbb in brain targeting.",
            "contribution_ids": [
                "R144469"
            ]
        },
        {
            "instance_id": "EMPTYxR147006",
            "comparison_id": "EMPTY",
            "paper_id": "R147006",
            "text": "Exendin-4-Loaded PLGA Microspheres Relieve Cerebral Ischemia/Reperfusion Injury and Neurologic Deficits through Long-Lasting Bioactivity-Mediated Phosphorylated Akt/eNOS Signaling in Rats glucagon-like peptide-1 (glp-1) receptor activation in the brain provides neuroprotection. exendin-4 (ex-4), a glp-1 analog, has seen limited clinical usage because of its short half-life. we developed long-lasting ex-4-loaded poly(d,l-lactide-co-glycolide) microspheres (pex-4) and explored its neuroprotective potential against cerebral ischemia in diabetic rats. compared with ex-4, pex-4 in the gradually degraded microspheres sustained higher ex-4 levels in the plasma and cerebrospinal fluid for at least 2 weeks and improved diabetes-induced glycemia after a single subcutaneous administration (20 \u03bcg/day). ten minutes of bilateral carotid artery occlusion (cao) combined with hemorrhage-induced hypotension (around 30 mm hg) significantly decreased cerebral blood flow and microcirculation in male wistar rats subjected to streptozotocin-induced diabetes. cao increased cortical o 2 \u2013 levels by chemiluminescence amplification and prefrontal cortex edema by t2-weighted magnetic resonance imaging analysis. cao significantly increased aquaporin 4 and glial fibrillary acidic protein expression and led to cognition deficits. cao downregulated phosphorylated akt/endothelial nitric oxide synthase (p-akt/p-enos) signaling and enhanced nuclear factor (nf)-\u03babp65/ intercellular adhesion molecule-1 (icam-1) expression, endoplasmic reticulum (er) stress, and apoptosis in the cerebral cortex. pex-4 was more effective than ex-4 to improve cao-induced oxidative injury and cognitive deficits. the neuroprotection provided by pex-4 was through p-akt/p-enos pathways, which suppressed cao-enhanced nf- \u03bab/icam-1 signaling, er stress, and apoptosis.",
            "contribution_ids": [
                "R147008"
            ]
        },
        {
            "instance_id": "EMPTYxR147246",
            "comparison_id": "EMPTY",
            "paper_id": "R147246",
            "text": "PEG-g-chitosan nanoparticles functionalized with the monoclonal antibody OX26 for brain drug targeting aim: drug targeting to the cns is challenging due to the presence of blood\u2013brain barrier. we investigated chitosan (cs) nanoparticles (nps) as drug transporter system across the blood\u2013brain barrier, based on mab ox26 modified cs. materials &amp; methods: cs nps functionalized with peg, modified and unmodified with ox26 (cs-peg-ox26) were prepared and chemico-physically characterized. these nps were administered (intraperitoneal) in mice to define their ability to reach the brain. results: brain uptake of ox26-conjugated nps is much higher than of unmodified nps, because: long-circulating abilities (conferred by peg), interaction between cationic cs and brain endothelium negative charges and ox26 tfr receptor affinity. conclusion: cs-peg-ox26 nps are promising drug delivery system to the cns.",
            "contribution_ids": [
                "R147248"
            ]
        },
        {
            "instance_id": "EMPTYxR149126",
            "comparison_id": "EMPTY",
            "paper_id": "R149126",
            "text": "Superparamagnetic Iron Oxide\u2013enhanced MR Imaging of Head and Neck Lymph Nodes purpose\\nto compare findings on superparamagnetic iron oxide (spio)-enhanced magnetic resonance (mr) images of the head and neck with those from resected lymph node specimens and to determine the effect of such imaging on surgical planning in patients with histopathologically proved squamous cell carcinoma of the head and neck.\\n\\n\\nmaterials and methods\\nthirty patients underwent mr imaging with nonenhanced and spio-enhanced (2.6 mg fe/kg intravenously) t1-weighted (500/15 [repetition time msec/echo time msec]) and t2-weighted (1,900/80) spin-echo and t2-weighted gradient-echo (gre) (500/15, 15 degrees flip angle) sequences. signal intensity decrease was measured, and visual analysis was performed. surgical plans were modified, if necessary, according to mr findings. histopathologic and mr findings were compared.\\n\\n\\nresults\\nhistopathologic evaluation of 1,029 lymph nodes revealed 69 were metastatic. mr imaging enabled detection of 59 metastases. regarding lymph node levels, mr diagnosis was correct in 26 of 27 patients who underwent surgery: only one metastasis was localized in level ii with mr imaging, whereas histopathologic evaluation placed it at level iii. extent of surgery was changed in seven patients. spio-enhanced t2-weighted gre was the best sequence for differentiating between benign and malignant lymph nodes.\\n\\n\\nconclusion\\nspio-enhanced mr imaging has an important effect on planning the extent of surgery. on a patient basis, spio-enhanced mr images compared well with resected specimens.",
            "contribution_ids": [
                "R149128"
            ]
        },
        {
            "instance_id": "EMPTYxR138698",
            "comparison_id": "EMPTY",
            "paper_id": "R138698",
            "text": "Application of Autoencoder in Depression Diagnosis major depressive disorder (mdd) is a mental disorder characterized by at least two weeks of low mood which is present across most situations. diagnosis of mdd using rest-state functional magnetic resonance imaging (fmri) data faces many challenges due to the high dimensionality, small samples, noisy and individual variability. no method can automatically extract discriminative features from the origin time series in fmri images for mdd diagnosis. in this study, we proposed a new method for feature extraction and a workflow which can make an automatic feature extraction and classification without a prior knowledge. an autoencoder was used to learn pre-training parameters of a dimensionality reduction process using 3-d convolution network. through comparison with the other three feature extraction methods, our method achieved the best classification performance. this method can be used not only in mdd diagnosis, but also other similar disorders.",
            "contribution_ids": [
                "R138700"
            ]
        },
        {
            "instance_id": "EMPTYxR150549",
            "comparison_id": "EMPTY",
            "paper_id": "R150549",
            "text": "Classifying semantic relations in bioscience texts a crucial step toward the goal of automatic extraction of propositional information from natural language text is the identification of semantic relations between constituents in sentences. we examine the problem of distinguishing among seven relation types that can occur between the entities \"treatment\" and \"disease\" in bioscience text, and the problem of identifying such entities. we compare five generative graphical models and a neural network, using lexical, syntactic, and semantic features, finding that the latter help achieve high classification accuracy.",
            "contribution_ids": [
                "R150551"
            ]
        },
        {
            "instance_id": "EMPTYxR168492",
            "comparison_id": "EMPTY",
            "paper_id": "R168492",
            "text": "PoreWalker: A Novel Tool for the Identification and Characterization of Channels in Transmembrane Proteins from Their Three-Dimensional Structure transmembrane channel proteins play pivotal roles in maintaining the homeostasis and responsiveness of cells and the cross-membrane electrochemical gradient by mediating the transport of ions and molecules through biological membranes. therefore, computational methods which, given a set of 3d coordinates, can automatically identify and describe channels in transmembrane proteins are key tools to provide insights into how they function. herein we present porewalker, a fully automated method, which detects and fully characterises channels in transmembrane proteins from their 3d structures. a stepwise procedure is followed in which the pore centre and pore axis are first identified and optimised using geometric criteria, and then the biggest and longest cavity through the channel is detected. finally, pore features, including diameter profiles, pore-lining residues, size, shape and regularity of the pore are calculated, providing a quantitative and visual characterization of the channel. to illustrate the use of this tool, the method was applied to several structures of transmembrane channel proteins and was able to identify shape/size/residue features representative of specific channel families. the software is available as a web-based resource at http://www.ebi.ac.uk/thornton-srv/software/porewalker/.",
            "contribution_ids": [
                "R168494",
                "R168495",
                "R168496",
                "R168497"
            ]
        },
        {
            "instance_id": "EMPTYxR168508",
            "comparison_id": "EMPTY",
            "paper_id": "R168508",
            "text": "ACME: Automated Cell Morphology Extractor for Comprehensive Reconstruction of Cell Membranes the quantification of cell shape, cell migration, and cell rearrangements is important for addressing classical questions in developmental biology such as patterning and tissue morphogenesis. time-lapse microscopic imaging of transgenic embryos expressing fluorescent reporters is the method of choice for tracking morphogenetic changes and establishing cell lineages and fate maps in vivo. however, the manual steps involved in curating thousands of putative cell segmentations have been a major bottleneck in the application of these technologies especially for cell membranes. segmentation of cell membranes while more difficult than nuclear segmentation is necessary for quantifying the relations between changes in cell morphology and morphogenesis. we present a novel and fully automated method to first reconstruct membrane signals and then segment out cells from 3d membrane images even in dense tissues. the approach has three stages: 1) detection of local membrane planes, 2) voting to fill structural gaps, and 3) region segmentation. we demonstrate the superior performance of the algorithms quantitatively on time-lapse confocal and two-photon images of zebrafish neuroectoderm and paraxial mesoderm by comparing its results with those derived from human inspection. we also compared with synthetic microscopic images generated by simulating the process of imaging with fluorescent reporters under varying conditions of noise. both the over-segmentation and under-segmentation percentages of our method are around 5%. the volume overlap of individual cells, compared to expert manual segmentation, is consistently over 84%. by using our software (acme) to study somite formation, we were able to segment touching cells with high accuracy and reliably quantify changes in morphogenetic parameters such as cell shape and size, and the arrangement of epithelial and mesenchymal cells. our software has been developed and tested on windows, mac, and linux platforms and is available publicly under an open source bsd license (https://github.com/krm15/acme).",
            "contribution_ids": [
                "R168510",
                "R168511",
                "R168512",
                "R168513",
                "R168514",
                "R168515"
            ]
        },
        {
            "instance_id": "EMPTYxR168521",
            "comparison_id": "EMPTY",
            "paper_id": "R168521",
            "text": "Chaste: An Open Source C++ Library for Computational Physiology and Biology chaste \u2014 cancer, heart and soft tissue environment \u2014 is an open source c++ library for the computational simulation of mathematical models developed for physiology and biology. code development has been driven by two initial applications: cardiac electrophysiology and cancer development. a large number of cardiac electrophysiology studies have been enabled and performed, including high-performance computational investigations of defibrillation on realistic human cardiac geometries. new models for the initiation and growth of tumours have been developed. in particular, cell-based simulations have provided novel insight into the role of stem cells in the colorectal crypt. chaste is constantly evolving and is now being applied to a far wider range of problems. the code provides modules for handling common scientific computing components, such as meshes and solvers for ordinary and partial differential equations (odes/pdes). re-use of these components avoids the need for researchers to \u2018re-invent the wheel\u2019 with each new project, accelerating the rate of progress in new applications. chaste is developed using industrially-derived techniques, in particular test-driven development, to ensure code quality, re-use and reliability. in this article we provide examples that illustrate the types of problems chaste can be used to solve, which can be run on a desktop computer. we highlight some scientific studies that have used or are using chaste, and the insights they have provided. the source code, both for specific releases and the development version, is available to download under an open source berkeley software distribution (bsd) licence at http://www.cs.ox.ac.uk/chaste, together with details of a mailing list and links to documentation and tutorials.",
            "contribution_ids": [
                "R168523",
                "R168524",
                "R168525",
                "R168526"
            ]
        },
        {
            "instance_id": "EMPTYxR168535",
            "comparison_id": "EMPTY",
            "paper_id": "R168535",
            "text": "VBA: A Probabilistic Treatment of Nonlinear Models for Neurobiological and Behavioural Data this work is in line with an on-going effort tending toward a computational (quantitative and refutable) understanding of human neuro-cognitive processes. many sophisticated models for behavioural and neurobiological data have flourished during the past decade. most of these models are partly unspecified (i.e. they have unknown parameters) and nonlinear. this makes them difficult to peer with a formal statistical data analysis framework. in turn, this compromises the reproducibility of model-based empirical studies. this work exposes a software toolbox that provides generic, efficient and robust probabilistic solutions to the three problems of model-based analysis of empirical data: (i) data simulation, (ii) parameter estimation/model selection, and (iii) experimental design optimization.",
            "contribution_ids": [
                "R168536",
                "R168537",
                "R168538"
            ]
        },
        {
            "instance_id": "EMPTYxR151437",
            "comparison_id": "EMPTY",
            "paper_id": "R151437",
            "text": "Fast-discharge excitation of hot capillary plasmas for soft-x-ray amplifiers high-temperature (${\\\\mathit{t}}_{\\\\mathit{e}}$g150 ev), small-diameter (\\\\ensuremath{\\\\sim}200 \\\\ensuremath{\\\\mu}m) plasma columns have been efficiently generated by very fast (13 ns rise time, 28 ns full width at half maximum) pulsed discharge excitation of capillary channels filled with preionized gas. discharges in argon-filled capillaries at currents between 20 and 60 ka produced plasmas with ar x--ar xiv line emission, in which the degree of ionization was controlled by the magnitude of the current pulse. the characteristics of these plasmas differ from those created by vacuum discharges in the same capillaries and approach those necessary for soft-x-ray amplification in low-z elements.",
            "contribution_ids": [
                "R151439"
            ]
        },
        {
            "instance_id": "EMPTYxR151466",
            "comparison_id": "EMPTY",
            "paper_id": "R151466",
            "text": "Demonstration of a Discharge Pumped Table-Top Soft-X-Ray Laser we report the first observation of large soft-x-ray amplification ([ital gl]=7.2) in a discharge created plasma. a fast, [similar to]40 ka current pulse from a compact discharge was used to excite plasma columns up to 12 cm in length in 4 mm channels, producing population inversion in the [ital j]=0[minus]1 line of ne-like ar and resulting in a gain of 0.6 cm[sup [minus]1] at 46.9 nm. the beam divergence was measured to be [lt]9 mrad.",
            "contribution_ids": [
                "R151468"
            ]
        },
        {
            "instance_id": "EMPTYxR151668",
            "comparison_id": "EMPTY",
            "paper_id": "R151668",
            "text": "Lasing at 60.8 nm in Ne-like sulfur ions in ablated material excited by a capillary discharge we report the observation of discharge-pumped extreme ultraviolet lasing in collisionally excited ions of a material ablated from a solid target. excitation of sulfur plasmas by a capillary discharge resulted in amplification of the j50\u20131 line of ne-like sulfur at 60.8 nm, with a gain coefficient of 0.45 cm and a gain-length product of 7.5. overheating of the electron temperature and transient population effects are computed to make a significant contribution to the measured gain. @s1050-2947~97!01702-2#",
            "contribution_ids": [
                "R151669"
            ]
        },
        {
            "instance_id": "EMPTYxR152841",
            "comparison_id": "EMPTY",
            "paper_id": "R152841",
            "text": "Short Pulse X-Ray Laser at 32.6 nm Based on Transient Gain in Ne-like Titanium a novel two-step excitation scheme for an efficient table-top x-ray laser has been realized for the first time. a nanosecond pulse creates a plasma of neonlike ions of titanium, followed by a subpicosecond pulse which excites a nonstationary population inversion. with only a few joules of pump energy, a compact x-ray laser at 32.6 nm with a very high gain coefficient of $g\\\\phantom{\\\\rule{0ex}{0ex}}=\\\\phantom{\\\\rule{0ex}{0ex}}19{\\\\mathrm{cm}}^{\\\\ensuremath{-}1}$ and a gain-length product of $gl\\\\phantom{\\\\rule{0ex}{0ex}}=\\\\phantom{\\\\rule{0ex}{0ex}}9.5$ was achieved.",
            "contribution_ids": [
                "R152843"
            ]
        },
        {
            "instance_id": "EMPTYxR154122",
            "comparison_id": "EMPTY",
            "paper_id": "R154122",
            "text": "Efficient Excitation of Gain-Saturated Sub-9-nm-Wavelength Tabletop Soft-X-Ray Lasers and Lasing Down to 7.36\u00a0nm we have demonstrated the efficient generation of sub-9-nm-wavelength picosecond laser pulses of microjoule energy at 1-hz repetition rate with a tabletop laser. gain-saturated lasing was obtained a ...",
            "contribution_ids": [
                "R154124"
            ]
        },
        {
            "instance_id": "EMPTYxR193972",
            "comparison_id": "EMPTY",
            "paper_id": "R193972",
            "text": "A two stage green supplier selection and order allocation using AHP and multi-objective genetic algorithm optimization green supplier selection and order allocation problem involves multi-criteria decisions. in this paper, the available suppliers are ranked based on selected green criteria by decision makers in the purchasing department using analytic hierarchy process (ahp). then, genetic algorithm (ga), that uses real-coded representation chromosomes, is used to find the optimal solution for the multi-objective integer linear programming model. the model deals with three conflicting objectives which are: total purchasing cost (tcp), total green value of purchasing (tgvp) and total rejected item due to quality (tr). the model is illustrated by a numerical example.",
            "contribution_ids": [
                "R193974"
            ]
        },
        {
            "instance_id": "EMPTYxR140841",
            "comparison_id": "EMPTY",
            "paper_id": "R140841",
            "text": "SemEval-2015 Task 5: QA TempEval - Evaluating Temporal Information Understanding with Question Answering qa tempeval shifts the goal of previous tempevals away from an intrinsic evaluation methodology toward a more extrinsic goal of question answering. this evaluation requires systems to capture temporal information relevant to perform an end-user task, as opposed to corpus-based evaluation where all temporal information is equally important. evaluation results show that the best automated timeml annotations reach over 30% recall on questions with \u2018yes\u2019 answer and about 50% on easier questions with \u2018no\u2019 answers. features that helped achieve better results are event coreference and a time expression reasoner.",
            "contribution_ids": [
                "R140843"
            ]
        },
        {
            "instance_id": "EMPTYxR140859",
            "comparison_id": "EMPTY",
            "paper_id": "R140859",
            "text": "SemEval-2017 Task 8: RumourEval: Determining rumour veracity and\n            support for rumours media is full of false claims. even oxford dictionaries named \u201cpost-truth\u201d as the word of 2016. this makes it more important than ever to build systems that can identify the veracity of a story, and the nature of the discourse around it. rumoureval is a semeval shared task that aims to identify and handle rumours and reactions to them, in text. we present an annotation scheme, a large dataset covering multiple topics \u2013 each having their own families of claims and replies \u2013 and use these to pose two concrete challenges as well as the results achieved by participants on these challenges.",
            "contribution_ids": [
                "R140861"
            ]
        },
        {
            "instance_id": "EMPTYxR140867",
            "comparison_id": "EMPTY",
            "paper_id": "R140867",
            "text": "SemEval-2019 Task 1: Cross-lingual Semantic Parsing with UCCA we present the semeval 2019 shared task on universal conceptual cognitive annotation (ucca) parsing in english, german and french, and discuss the participating systems and results. ucca is a cross-linguistically applicable framework for semantic representation, which builds on extensive typological work and supports rapid annotation. ucca poses a challenge for existing parsing techniques, as it exhibits reentrancy (resulting in dag structures), discontinuous structures and non-terminal nodes corresponding to complex semantic units. the shared task has yielded improvements over the state-of-the-art baseline in all languages and settings. full results can be found in the task\u2019s website https://competitions.codalab.org/competitions/19160.",
            "contribution_ids": [
                "R140869"
            ]
        },
        {
            "instance_id": "EMPTYxR140882",
            "comparison_id": "EMPTY",
            "paper_id": "R140882",
            "text": "SIGMORPHON 2020 Shared Task 0: Typologically Diverse Morphological Inflection a broad goal in natural language processing (nlp) is to develop a system that has the capacity to process any natural language. most systems, however, are developed using data from just one language such as english. the sigmorphon 2020 shared task on morphological reinflection aims to investigate systems\u2019 ability to generalize across typologically distinct languages, many of which are low resource. systems were developed using data from 45 languages and just 5 language families, fine-tuned with data from an additional 45 languages and 10 language families (13 in total), and evaluated on all 90 languages. a total of 22 systems (19 neural) from 10 teams were submitted to the task. all four winning systems were neural (two monolingual transformers and two massively multilingual rnn-based models with gated attention). most teams demonstrate utility of data hallucination and augmentation, ensembles, and multilingual training for low-resource languages. non-neural learners and manually designed grammars showed competitive and even superior performance on some languages (such as ingrian, tajik, tagalog, zarma, lingala), especially with very limited data. some language families (afro-asiatic, niger-congo, turkic) were relatively easy for most systems and achieved over 90% mean accuracy while others were more challenging.",
            "contribution_ids": [
                "R140884"
            ]
        },
        {
            "instance_id": "EMPTYxR142180",
            "comparison_id": "EMPTY",
            "paper_id": "R142180",
            "text": "Detection and Diagnosis of Breast Cancer Using Artificial Intelligence Based Assessment of Maximum Intensity Projection Dynamic Contrast-Enhanced Magnetic Resonance Images we aimed to evaluate an artificial intelligence (ai) system that can detect and diagnose lesions of maximum intensity projection (mip) in dynamic contrast-enhanced (dce) breast magnetic resonance imaging (mri). we retrospectively gathered mips of dce breast mri for training and validation data from 30 and 7 normal individuals, 49 and 20 benign cases, and 135 and 45 malignant cases, respectively. breast lesions were indicated with a bounding box and labeled as benign or malignant by a radiologist, while the ai system was trained to detect and calculate possibilities of malignancy using retinanet. the ai system was analyzed using test sets of 13 normal, 20 benign, and 52 malignant cases. four human readers also scored these test data with and without the assistance of the ai system for the possibility of a malignancy in each breast. sensitivity, specificity, and area under the receiver operating characteristic curve (auc) were 0.926, 0.828, and 0.925 for the ai system; 0.847, 0.841, and 0.884 for human readers without ai; and 0.889, 0.823, and 0.899 for human readers with ai using a cutoff value of 2%, respectively. the ai system showed better diagnostic performance compared to the human readers (p = 0.002), and because of the increased performance of human readers with the assistance of the ai system, the auc of human readers was significantly higher with than without the ai system (p = 0.039). our ai system showed a high performance ability in detecting and diagnosing lesions in mips of dce breast mri and increased the diagnostic performance of human readers.",
            "contribution_ids": [
                "R142184"
            ]
        },
        {
            "instance_id": "EMPTYxR142185",
            "comparison_id": "EMPTY",
            "paper_id": "R142185",
            "text": "Artificial Intelligence Applied to Breast MRI for Improved                    Diagnosis background recognition of salient mri morphologic and kinetic features of various malignant tumor subtypes and benign diseases, either visually or with artificial intelligence (ai), allows radiologists to improve diagnoses that may improve patient treatment. purpose to evaluate whether the diagnostic performance of radiologists in the differentiation of cancer from noncancer at dynamic contrast material-enhanced (dce) breast mri is improved when using an ai system compared with conventionally available software. materials and methods in a retrospective clinical reader study, images from breast dce mri examinations were interpreted by 19 breast imaging radiologists from eight academic and 11 private practices. readers interpreted each examination twice. in the \"first read,\" they were provided with conventionally available computer-aided evaluation software, including kinetic maps. in the \"second read,\" they were also provided with ai analytics through computer-aided diagnosis software. reader diagnostic performance was evaluated with receiver operating characteristic (roc) analysis, with the area under the roc curve (auc) as a figure of merit in the task of distinguishing between malignant and benign lesions. the primary study end point was the difference in auc between the first-read and the second-read conditions. results one hundred eleven women (mean age, 52 years \u00b1 13 [standard deviation]) were evaluated with a total of 111 breast dce mri examinations (54 malignant and 57 nonmalignant lesions). the average auc of all readers improved from 0.71 to 0.76 (p = .04) when using the ai system. the average sensitivity improved when breast imaging reporting and data system (bi-rads) category 3 was used as the cut point (from 90% to 94%; 95% confidence interval [ci] for the change: 0.8%, 7.4%) but not when using bi-rads category 4a (from 80% to 85%; 95% ci: -0.9%, 11%). the average specificity showed no difference when using either bi-rads category 4a or category 3 as the cut point (52% and 52% [95% ci: -7.3%, 6.0%], and from 29% to 28% [95% ci: -6.4%, 4.3%], respectively). conclusion use of an artificial intelligence system improves radiologists\\' performance in the task of differentiating benign and malignant mri breast lesions. \u00a9 rsna, 2020 online supplemental material is available for this article. see also the editorial by krupinski in this issue.",
            "contribution_ids": [
                "R142188"
            ]
        },
        {
            "instance_id": "EMPTYxR142196",
            "comparison_id": "EMPTY",
            "paper_id": "R142196",
            "text": "Improving Breast Cancer Detection Accuracy of Mammography with the                     Concurrent Use of an Artificial Intelligence Tool purpose\\nto evaluate the benefits of an artificial intelligence (ai)-based tool for two-dimensional mammography in the breast cancer detection process.\\n\\n\\nmaterials and methods\\nin this multireader, multicase retrospective study, 14 radiologists assessed a dataset of 240 digital mammography images, acquired between 2013 and 2016, using a counterbalance design in which half of the dataset was read without ai and the other half with the help of ai during a first session and vice versa during a second session, which was separated from the first by a washout period. area under the receiver operating characteristic curve (auc), sensitivity, specificity, and reading time were assessed as endpoints.\\n\\n\\nresults\\nthe average auc across readers was 0.769 (95% ci: 0.724, 0.814) without ai and 0.797 (95% ci: 0.754, 0.840) with ai. the average difference in auc was 0.028 (95% ci: 0.002, 0.055, p = .035). average sensitivity was increased by 0.033 when using ai support (p = .021). reading time changed dependently to the ai-tool score. for low likelihood of malignancy (< 2.5%), the time was about the same in the first reading session and slightly decreased in the second reading session. for higher likelihood of malignancy, the reading time was on average increased with the use of ai.\\n\\n\\nconclusion\\nthis clinical investigation demonstrated that the concurrent use of this ai tool improved the diagnostic performance of radiologists in the detection of breast cancer without prolonging their workflow.supplemental material is available for this article.\u00a9 rsna, 2020.",
            "contribution_ids": [
                "R142201"
            ]
        },
        {
            "instance_id": "EMPTYxR146686",
            "comparison_id": "EMPTY",
            "paper_id": "R146686",
            "text": "Automatic Detection of Heartbeats in Heart Sound Signals Using Deep Convolutional Neural Networks the analysis of non-stationary signals commonly includes the signal segmentation process, dividing such signals into smaller time series, which are considered stationary and thus easier to process. most commonly, the methods for signal segmentation utilize complex filtering, transformation and feature extraction techniques together with various kinds of classifiers, which especially in the field of biomedical signals, do not perform very well and are generally prone to poor performance when dealing with signals obtained in highly variable environments. in order to address these problems, we designed a new method for the segmentation of heart sound signals using deep convolutional neural networks, which works in a straightforward automatic manner and does not require any complex pre-processing. the proposed method was tested on a set of heartbeat sound clips, collected by non-experts with mobile devices in highly variable environments with excessive background noise. the obtained results show that the proposed method outperforms other methods, which are taking advantage of using domain knowledge for the analysis of the signals. based on the encouraging experimental results, we believe that the proposed method can be considered as a solid basis for the further development of the automatic segmentation of highly variable signals using deep neural networks.",
            "contribution_ids": [
                "R146688"
            ]
        },
        {
            "instance_id": "EMPTYxR146689",
            "comparison_id": "EMPTY",
            "paper_id": "R146689",
            "text": "A Novel Method for Measuring the Timing of Heart Sound Components through Digital Phonocardiography the auscultation of heart sounds has been for decades a fundamental diagnostic tool in clinical practice. higher effectiveness can be achieved by recording the corresponding biomedical signal, namely the phonocardiographic signal, and processing it by means of traditional signal processing techniques. an unavoidable processing step is the heart sound segmentation, which is still a challenging task from a technical viewpoint\u2014a limitation of state-of-the-art approaches is the unavailability of trustworthy techniques for the detection of heart sound components. the aim of this work is to design a reliable algorithm for the identification and the classification of heart sounds\u2019 main components. the proposed methodology was tested on a sample population of 24 healthy subjects over 10-min-long simultaneous electrocardiographic and phonocardiographic recordings and it was found capable of correctly detecting and classifying an average of 99.2% of the heart sounds along with their components. moreover, the delay of each component with respect to the corresponding r-wave peak and the delay among the components of the same heart sound were computed: the resulting experimental values are coherent with what is expected from the literature and what was obtained by other studies.",
            "contribution_ids": [
                "R146693"
            ]
        },
        {
            "instance_id": "EMPTYxR146699",
            "comparison_id": "EMPTY",
            "paper_id": "R146699",
            "text": "A Markov-Switching Model Approach to Heart Sound Segmentation and Classification objective: we consider challenges in accurate segmentation of heart sound signals recorded under noisy clinical environments for subsequent classification of pathological events. existing state-of-the-art solutions to heart sound segmentation use probabilistic models such as hidden markov models (hmms), which, however, are limited by its observation independence assumption and rely on pre-extraction of noise-robust features. methods: we propose a markov-switching autoregressive (msar) process to model the raw heart sound signals directly, which allows efficient segmentation of the cyclical heart sound states according to the distinct dependence structure in each state. to enhance robustness, we extend the msar model to a switching linear dynamic system (slds) that jointly model both the switching ar dynamics of underlying heart sound signals and the noise effects. we introduce a novel algorithm via fusion of switching kalman filter and the duration-dependent viterbi algorithm, which incorporates the duration of heart sound states to improve state decoding. results: evaluated on physionet/cinc challenge 2016 dataset, the proposed msar-slds approach significantly outperforms the hidden semi-markov model (hsmm) in heart sound segmentation based on raw signals and comparable to a feature-based hsmm. the segmented labels were then used to train gaussian-mixture hmm classifier for identification of abnormal beats, achieving high average precision of 86.1% on the same dataset including very noisy recordings. conclusion: the proposed approach shows noticeable performance in heart sound segmentation and classification on a large noisy dataset. significance: it is potentially useful in developing automated heart monitoring systems for pre-screening of heart pathologies.",
            "contribution_ids": [
                "R146704"
            ]
        },
        {
            "instance_id": "EMPTYxR69294",
            "comparison_id": "EMPTY",
            "paper_id": "R69294",
            "text": "The SOFC-Exp Corpus and Neural Approaches to Information Extraction in the Materials Science Domain this paper presents a new challenging information extraction task in the domain of materials science. we develop an annotation scheme for marking information on experiments related to solid oxide fuel cells in scientific publications, such as involved materials and measurement conditions. with this paper, we publish our annotation guidelines, as well as our sofc-exp corpus consisting of 45 open-access scholarly articles annotated by domain experts. a corpus and an inter-annotator agreement study demonstrate the complexity of the suggested named entity recognition and slot filling tasks as well as high annotation quality. we also present strong neural-network based models for a variety of tasks that can be addressed on the basis of our new data set. on all tasks, using bert embeddings leads to large performance gains, but with increasing task complexity, adding a recurrent neural network on top seems beneficial. our models will serve as competitive baselines in future work, and analysis of their performance highlights difficult cases when modeling the data and suggests promising research directions.",
            "contribution_ids": [
                "R69295"
            ]
        },
        {
            "instance_id": "EMPTYxR69864",
            "comparison_id": "EMPTY",
            "paper_id": "R69864",
            "text": "Knowledge Base Completion with Out-of-Knowledge-Base Entities: A Graph Neural Network Approach knowledge base completion (kbc) aims to predict missing information in a knowledge this http url this paper, we address the out-of-knowledge-base (ookb) entity problem in kbc:how to answer queries concerning test entities not observed at training time. existing embedding-based kbc models assume that all test entities are available at training time, making it unclear how to obtain embeddings for new entities without costly retraining. to solve the ookb entity problem without retraining, we use graph neural networks (graph-nns) to compute the embeddings of ookb entities, exploiting the limited auxiliary knowledge provided at test time.the experimental results show the effectiveness of our proposed model in the ookb setting.additionally, in the standard kbc setting in which ookb entities are not involved, our model achieves state-of-the-art performance on the wordnet dataset. the code and dataset are available at this https url",
            "contribution_ids": [
                "R69866",
                "R69873"
            ]
        },
        {
            "instance_id": "EMPTYxR141877",
            "comparison_id": "EMPTY",
            "paper_id": "R141877",
            "text": "Low temperature aluminum nitride thin films for sensory applications a low-temperature sputter deposition process for the synthesis of aluminum nitride (aln) thin films that is attractive for applications with a limited temperature budget is presented. influence of the reactive gas concentration, plasma treatment of the nucleation surface and film thickness on the microstructural, piezoelectric and dielectric properties of aln is investigated. an improved crystal quality with respect to the increased film thickness was observed; where full width at half maximum (fwhm) of the aln films decreased from 2.88 \u00b1 0.16\u00b0 down to 1.25 \u00b1 0.07\u00b0 and the effective longitudinal piezoelectric coefficient (d33,f) increased from 2.30 \u00b1 0.32 pm/v up to 5.57 \u00b1 0.34 pm/v for film thicknesses in the range of 30 nm to 2 \u03bcm. dielectric loss angle (tan \u03b4) decreased from 0.626% \u00b1 0.005% to 0.025% \u00b1 0.011% for the same thickness range. the average relative permittivity (er) was calculated as 10.4 \u00b1 0.05. an almost constant transversal piezoelectric coefficient (|e31,f|) of 1.39 \u00b1 0.01 c/m2 was measured for samples in the range of 0.5 \u03bcm to 2 \u03bcm. transmission electron microscopy (tem) investigations performed on thin (100 nm) and thick (1.6 \u03bcm) films revealed an (002) oriented aln nucleation and growth starting directly from the aln-pt interface independent of the film thickness and exhibit comparable quality with the state-of-the-art aln thin films sputtered at much higher substrate temperatures.",
            "contribution_ids": [
                "R141879"
            ]
        },
        {
            "instance_id": "EMPTYxR144811",
            "comparison_id": "EMPTY",
            "paper_id": "R144811",
            "text": "High-Performance Graphene/\u03b2-Ga2O3 Heterojunction Deep-Ultraviolet Photodetector with Hot-Electron Excited Carrier Multiplication solar-blind ultraviolet (sbuv) detection has important applications in wireless secure communication, early warning, and so forth. however, the desired key device for sbuv detection and high-sensitivity and low-noise \"sandwich\" photodetector with large detective area is difficult to be fabricated because it is usually hard for traditional wide band gap semiconductors to boast both high conductivity and high sbuv transparency. here, we proposed to use graphene as the transparent conductive layer to form graphene/\u03b2-ga2o3 heterojunction. with the help of large-area graphene and hot carrier multiplication, a sbuv photodetector with large detective area, low dark current, and high sensitivity was successfully assembled. its photoresponsivity is 1-3 orders of magnitude higher than that of the conventional sbuv photodetectors, and its response speed can rival the best device ever reported.",
            "contribution_ids": [
                "R144815"
            ]
        },
        {
            "instance_id": "EMPTYxR140059",
            "comparison_id": "EMPTY",
            "paper_id": "R140059",
            "text": "Open data hackathons: an innovative strategy to enhance entrepreneurial intention \\n purpose \\n in terms of entrepreneurship, open data benefits include economic growth, innovation, empowerment and new or improved products and services. hackathons encourage the development of new applications using open data and the creation of startups based on these applications. researchers focus on factors that affect nascent entrepreneurs\u2019 decision to create a startup but researches in the field of open data hackathons have not been fully investigated yet. this paper aims to suggest a model that incorporates factors that affect the decision of establishing a startup by developers who have participated in open data hackathons. \\n \\n \\n design/methodology/approach \\n in total, 70 papers were examined and analyzed using a three-phased literature review methodology, which was suggested by webster and watson (2002). these surveys investigated several factors that affect a nascent entrepreneur to create a startup. \\n \\n \\n findings \\n eventually, by identifying the motivations for developers to participate in a hackathon, and understanding the benefits of the use of open data, researchers will be able to elaborate the proposed model and evaluate if the contest has contributed to the decision of establish a startup and what factors affect the decision to establish a startup apply to open data developers, and if the participants of the contest agree with these factors. \\n \\n \\n originality/value \\n the paper expands the scope of open data research on entrepreneurship field, stating the need for more research to be conducted regarding the open data in entrepreneurship through hackathons. \\n",
            "contribution_ids": [
                "R140061"
            ]
        },
        {
            "instance_id": "EMPTYxR161681",
            "comparison_id": "EMPTY",
            "paper_id": "R161681",
            "text": "Link Prediction of Weighted Triples for Knowledge Graph Completion Within the Scholarly Domain knowledge graphs (kgs) are widely used for modeling scholarly communication, performing scientometric analyses, and supporting a variety of intelligent services to explore the literature and predict research dynamics. however, they often suffer from incompleteness (e.g., missing affiliations, references, research topics), leading to a reduced scope and quality of the resulting analyses. this issue is usually tackled by computing knowledge graph embeddings (kges) and applying link prediction techniques. however, only a few kge models are capable of taking weights of facts in the knowledge graph into account. such weights can have different meanings, e.g. describe the degree of association or the degree of truth of a certain triple. in this paper, we propose the weighted triple loss, a new loss function for kge models that takes full advantage of the additional numerical weights on facts and it is even tolerant to incorrect weights. we also extend the rule loss, a loss function that is able to exploit a set of logical rules, in order to work with weighted triples. the evaluation of our solutions on several knowledge graphs indicates significant performance improvements with respect to the state of the art. our main use case is the large-scale aida knowledge graph, which describes 21 million research articles. our approach enables to complete information about affiliation types, countries, and research topics, greatly improving the scope of the resulting scientometrics analyses and providing better support to systems for monitoring and predicting research dynamics.",
            "contribution_ids": [
                "R161682"
            ]
        },
        {
            "instance_id": "EMPTYxR164557",
            "comparison_id": "EMPTY",
            "paper_id": "R164557",
            "text": "SaL-Lightning Dataset: Search and Eye Gaze Behavior, Resource Interactions and Knowledge Gain during Web Search the emerging research field search as learning (sal) investigates how the web facilitates learning through modern information retrieval systems. sal research requires significant amounts of data that capture both search behavior of users and their acquired knowledge in order to obtain conclusive insights or train supervised machine learning models. however, the creation of such datasets is costly and requires interdisciplinary efforts in order to design studies and capture a wide range of features. in this paper, we address this issue and introduce an extensive dataset based on a user study, in which 114 participants were asked to learn about the formation of lightning and thunder. participants\u2019 knowledge states were measured before and after web search through multiple-choice questionnaires and essay-based free recall tasks. to enable future research in sal-related tasks we recorded a plethora of features and person-related attributes. besides the screen recordings, visited web pages, and detailed browsing histories, a large number of behavioral features and resource features were monitored. we underline the usefulness of the dataset by describing three, already published, use cases.",
            "contribution_ids": [
                "R164564"
            ]
        },
        {
            "instance_id": "EMPTYxR165783",
            "comparison_id": "EMPTY",
            "paper_id": "R165783",
            "text": "ROBOKOP: an abstraction layer and user interface for knowledge graphs to support question answering abstract \\n \\n summary \\n knowledge graphs (kgs) are quickly becoming a common-place tool for storing relationships between entities from which higher-level reasoning can be conducted. kgs are typically stored in a graph-database format, and graph-database queries can be used to answer questions of interest that have been posed by users such as biomedical researchers. for simple queries, the inclusion of direct connections in the kg and the storage and analysis of query results are straightforward; however, for complex queries, these capabilities become exponentially more challenging with each increase in complexity of the query. for instance, one relatively complex query can yield a kg with hundreds of thousands of query results. thus, the ability to efficiently query, store, rank and explore sub-graphs of a complex kg represents a major challenge to any effort designed to exploit the use of kgs for applications in biomedical research and other domains. we present reasoning over biomedical objects linked in knowledge oriented pathways as an abstraction layer and user interface to more easily query kgs and store, rank and explore query results. \\n \\n \\n availability and implementation \\n an instance of the robokop ui for exploration of the robokop knowledge graph can be found at http://robokop.renci.org. the robokop knowledge graph can be accessed at http://robokopkg.renci.org. code and instructions for building and deploying robokop are available under the mit open software license from https://github.com/ncats-gamma/robokop. \\n \\n \\n supplementary information \\n supplementary data are available at bioinformatics online. \\n",
            "contribution_ids": [
                "R165791"
            ]
        },
        {
            "instance_id": "EMPTYxR166497",
            "comparison_id": "EMPTY",
            "paper_id": "R166497",
            "text": "Softcite dataset: A dataset of software mentions in biomedical and economic research publications software contributions to academic research are relatively invisible, especially to the formalized scholarly reputation system based on bibliometrics. in this article, we introduce a gold\u2010standard dataset of software mentions from the manual annotation of 4,971 academic pdfs in biomedicine and economics. the dataset is intended to be used for automatic extraction of software mentions from pdf format research publications by supervised learning at scale. we provide a description of the dataset and an extended discussion of its creation process, including improved text conversion of academic pdfs. finally, we reflect on our challenges and lessons learned during the dataset creation, in hope of encouraging more discussion about creating datasets for machine learning use.",
            "contribution_ids": [
                "R166503"
            ]
        },
        {
            "instance_id": "EMPTYxR175410",
            "comparison_id": "EMPTY",
            "paper_id": "R175410",
            "text": "The FAIR Data Maturity Model: An Approach to Harmonise FAIR Assessments in the past years, many methodologies and tools have been developed to assess the fairness of research data. these different methodologies and tools have been based on various interpretations of the fair principles, which makes comparison of the results of the assessments difficult. the work in the rda fair data maturity model working group reported here has delivered a set of indicators with priorities and guidelines that provide a \u2018lingua franca\u2019 that can be used to make the results of the assessment using those methodologies and tools comparable. the model can act as a tool that can be used by various stakeholders, including researchers, data stewards, policy makers and funding agencies, to gain insight into the current fairness of data as well as into the aspects that can be improved to increase the potential for reuse of research data. through increased efficiency and effectiveness, it helps research activities to solve societal challenges and to support evidence-based decisions. the maturity model is publicly available and the working group is encouraging application of the model in practice. experience with the model will be taken into account in the further development of the model.",
            "contribution_ids": [
                "R175412"
            ]
        },
        {
            "instance_id": "EMPTYxR175113",
            "comparison_id": "EMPTY",
            "paper_id": "R175113",
            "text": "Toward Altmetric-Driven Research-Paper Recommender System Framework \"the volume of literature and more particularly research-oriented publications is growing at an exponential rate, and better tools and methodologies are required to efficiently and effectively retrieve desired documents. the development of academic search engines, digital libraries and archives has led to better information filtering mechanisms that has resulted to improved search results. however, the state-of-the art research-paper recommender systems are still retrieving research articles without explicitly defining the domain of interest of the researchers. also, a rich set of research output (research objects) and their associated metrics are also not being utilized in the process of searching, querying, retrieving and recommending articles. consequently, a lot of irrelevant and unrelated information is being presented to the user. then again, the use of citation counts to rank and recommend research-paper to users is still disputed. recommendation metrics like citation counts, ratings in collaborative filtering, and keyword analysis' cannot be fully relied on as the only techniques through which similarity between documents can be computed, and this is because recommendations based on such metrics are not accurate and have lots of biasness. henceforth, altmetric-based techniques and methodologies are expected to give better recommendations of research papers since the circumstances surrounding a research papers are taken into consideration. this paper proposes a research paper recommender system framework that utilizes paper ontology and altmetric from research papers, to enhance the performance of research paper recommender systems.\"",
            "contribution_ids": [
                "R175115"
            ]
        },
        {
            "instance_id": "EMPTYxR178155",
            "comparison_id": "EMPTY",
            "paper_id": "R178155",
            "text": "A link prediction approach for item recommendation with complex number recommendation can be reduced to a sub-problem of link prediction, with specific nodes (users and items) and links (similar relations among users/items, and interactions between users and items). however, the previous link prediction algorithms need to be modified to suit the recommendation cases since they do not consider the separation of these two fundamental relations: similar or dissimilar and like or dislike. in this paper, we propose a novel and unified way to solve this problem, which models the relation duality using complex number. under this representation, the previous works can directly reuse. in experiments with the movie lens dataset and the android software website appchina.com, the presented approach achieves significant performance improvement comparing with other popular recommendation algorithms both in accuracy and coverage. besides, our results revealed some new findings. first, it is observed that the performance is improved when the user and item popularities are taken into account. second, the item popularity plays a more important role than the user popularity does in final recommendation. since its notable performance, we are working to apply it in a commercial setting, appchina.com website, for application recommendation.",
            "contribution_ids": [
                "R178157"
            ]
        },
        {
            "instance_id": "EMPTYxR186108",
            "comparison_id": "EMPTY",
            "paper_id": "R186108",
            "text": "Asset management maturity in public infrastructure: the case of Rijkswaterstaat in times of restructuring governmental policies and resources, the need for strategic asset management is growing. maturity models offer organisations a structure to assist them in improving their asset management performance. we present the results of a repeated maturity measurement based on the infrastructure management maturity matrix (im3) in rijkswaterstaat, a dutch public infrastructure organisation. the im3 distinguishes five maturity levels from ad hoc to optimised, and seven asset management dimensions: information management, internal coordination, external coordination, market approach, risk management, processes and roles, and culture and leadership. the results show significant progress on all dimensions, and continued learning and widespread awareness of asset management in the organisation. in the discussion, we reflect on the findings and possible future developments for the organisation. we also discuss the potential impact of infrastructure maturity models for the professionalisation of other asset intensive organisations",
            "contribution_ids": [
                "R186110"
            ]
        },
        {
            "instance_id": "EMPTYxR142374",
            "comparison_id": "EMPTY",
            "paper_id": "R142374",
            "text": "Integrating bioinformatic data sources over the SFSU ER design tools XML databus the sfsu er design tools were developed to support database design and data integration over multiple implementation data models. these tools allow users to enter and view entity relationship (er) schemas and to translate er schemas into a variety of equivalent implementation schemas, including relational (ansi sql2), object oriented (odmg 3.0), spreadsheet (universal relation with associated functional dependencies) and w3c xml dtd. in addition, for each implementation data model, the tools generate ddl statements to create a database, as well as simple jdbc/odbc based code to dump stored data into an xml file and to load data from an xml file into a database. data can be transferred from one data store to another over an http based xml databus. in this paper we describe the design and implementation of our xml databus using web services, as well as a new strategy to support integration of bioinformatics data sets. we first manually identify semantically equivalent attributes in both schemas, then automatically join the corresponding data sets into a single integrated collection of xml formatted data. our software is operational, and preliminary performance measurements over dtd and data downloaded from the nih-ncbi web site show that our strategy is feasible for moderately sized data sets.",
            "contribution_ids": [
                "R142376"
            ]
        },
        {
            "instance_id": "EMPTYxR73118",
            "comparison_id": "EMPTY",
            "paper_id": "R73118",
            "text": "Linking science: approaches for linking scientific publications across different LOD repositories enriching the content of a digital library (dl) with additional information from other dls and domains would facilitate the scholarly communication, scientific findings, and knowledge distribution. the implementation of semantic technologies by interlinking resources results in a new vision for interoperability among different dls. therefore, this research explores bibliographic linked open data (lod) repositories by investigating alignments among them. the application of global unigrams frequency is applied for determining the importance of terms on the set of metadata. the semantic relatedness of the retrieved publications is measured by comparing two main approaches with one another: vector space model through tf-idf and cosine similarity, versus a deep learning approach through word2vec implementation of word embeddings. in summary, they are performing with 40.5% difference, concerning the outcome of relevant retrieved publications. in addition to the given metadata, word embeddings achieve a better performance for short texts, such as publications titles.",
            "contribution_ids": [
                "R73120"
            ]
        },
        {
            "instance_id": "EMPTYxR139761",
            "comparison_id": "EMPTY",
            "paper_id": "R139761",
            "text": "The Story of the Markham Car Collection: A Cross-Platform Panoramic Tour of Contested Heritage in this article, we share our experiences of using digital technologies and various media to present historical narratives of a museum object collection aiming to provide an engaging experience on multiple platforms. based on p. joseph\u2019s article, dawson presented multiple interpretations and historical views of the markham car collection across various platforms using multimedia resources. through her creative production, she explored how to use cylindrical panoramas and rich media to offer new ways of telling the controversial story of the contested heritage of a museum\u2019s veteran and vintage car collection. the production\u2019s usability was investigated involving five experts before it was published online and the general users\u2019 experience was investigated. in this article, we present an important component of findings which indicates that virtual panorama tours featuring multimedia elements could be successful in attracting new audiences and that using this type of storytelling technique can be effective in the museum sector. the storyteller panorama tour presented here may stimulate glam (galleries, libraries, archives, and museums) professionals to think of new approaches, implement new strategies or services to engage their audiences more effectively. the research may ameliorate the education of future professionals as well.",
            "contribution_ids": [
                "R139763"
            ]
        },
        {
            "instance_id": "EMPTYxR139784",
            "comparison_id": "EMPTY",
            "paper_id": "R139784",
            "text": "The Management Of Heritage In Contested Cross-Border Contexts: Emerging Research On The Island Of Ireland this paper introduces the recently begun reinvent research project focused on the management of heritage in the cross-border cultural landscape of derry/londonderry. the importance of facilitating dialogue over cultural heritage to the maintenance of \u2018thin\u2019 borders in contested cross-border contexts is underlined in the paper, as is the relatively favourable strategic policy context for progressing \u2018heritage diplomacy\u2019 on the island of ireland. however, it is argued that more inclusive and participatory approaches to the management \\nof heritage are required to assist in the mediation of contestation, particularly accommodating a greater diversity of \u2018non-expert\u2019 opinion, in addition to \\nhelping identify value conflicts and dissonance. the application of digital technologies in the form of public participation geographic information systems (ppgis) is proposed, and this is briefly discussed in relation to some of \\nthe expected benefits and methodological challenges that must be addressed \\nin the reinvent project. the paper concludes by emphasising the importance \\nof dialogue and knowledge exchange between academia and heritage \\npolicymakers/practitioners.",
            "contribution_ids": [
                "R139785"
            ]
        },
        {
            "instance_id": "EMPTYxR140161",
            "comparison_id": "EMPTY",
            "paper_id": "R140161",
            "text": "Semantic similarity and machine learning with ontologies abstract \\n ontologies have long been employed in the life sciences to formally represent and reason over domain knowledge and they are employed in almost every major biological database. recently, ontologies are increasingly being used to provide background knowledge in similarity-based analysis and machine learning models. the methods employed to combine ontologies and machine learning are still novel and actively being developed. we provide an overview over the methods that use ontologies to compute similarity and incorporate them in machine learning methods; in particular, we outline how semantic similarity measures and ontology embeddings can exploit the background knowledge in ontologies and how ontologies can provide constraints that improve machine learning models. the methods and experiments we describe are available as a set of executable notebooks, and we also provide a set of slides and additional resources at https://github.com/bio-ontology-research-group/machine-learning-with-ontologies.",
            "contribution_ids": [
                "R140163"
            ]
        },
        {
            "instance_id": "EMPTYxR144951",
            "comparison_id": "EMPTY",
            "paper_id": "R144951",
            "text": "Accurate unlexicalized parsing we demonstrate that an unlexicalized pcfg can parse much more accurately than previously shown, by making use of simple, linguistically motivated state splits, which break down false independence assumptions latent in a vanilla treebank grammar. indeed, its performance of 86.36% (lp/lr f1) is better than that of early lexicalized pcfg models, and surprisingly close to the current state-of-the-art. this result has potential uses beyond establishing a strong lower bound on the maximum possible accuracy of unlexicalized models: an unlexicalized pcfg is much more compact, easier to replicate, and easier to interpret than more complex lexical models, and the parsing algorithms are simpler, more widely understood, of lower asymptotic complexity, and easier to optimize.",
            "contribution_ids": [
                "R144953"
            ]
        },
        {
            "instance_id": "EMPTYxR157417",
            "comparison_id": "EMPTY",
            "paper_id": "R157417",
            "text": "Autoformer: Searching transformers for visual recognition recently, pure transformer-based models have shown great potentials for vision tasks such as image classification and detection. however, the design of transformer networks is challenging. it has been observed that the depth, embedding dimension, and number of heads can largely affect the performance of vision transformers. previous models configure these dimensions based upon manual crafting. in this work, we propose a new one-shot architecture search framework, namely autoformer, dedicated to vision transformer search. autoformer entangles the weights of different blocks in the same layers during supernet training. benefiting from the strategy, the trained supernet allows thousands of subnets to be very well-trained. specifically, the performance of these subnets with weights inherited from the supernet is comparable to those retrained from scratch. besides, the searched models, which we refer to autoformers, surpass the recent state-of-the-arts such as vit and deit. in particular, autoformer-tiny/small/base achieve 74.7%/81.7%/82.4% top-1 accuracy on imagenet with 5.7m/22.9m/53.7m parameters, respectively. lastly, we verify the transferability of autoformer by providing the performance on downstream benchmarks and distillation experiments. code and models are available at https://github.com/microsoft/cream.",
            "contribution_ids": [
                "R157419"
            ]
        },
        {
            "instance_id": "EMPTYxR161808",
            "comparison_id": "EMPTY",
            "paper_id": "R161808",
            "text": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (nlp). the effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. in this paper, we explore the landscape of transfer learning techniques for nlp by introducing a unified framework that converts every language problem into a text-to-text format. our systematic study compares pre-training objectives, architectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks. by combining the insights from our exploration with scale and our new \"colossal clean crawled corpus\", we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. to facilitate future work on transfer learning for nlp, we release our dataset, pre-trained models, and code.",
            "contribution_ids": [
                "R161810"
            ]
        },
        {
            "instance_id": "EMPTYxR176039",
            "comparison_id": "EMPTY",
            "paper_id": "R176039",
            "text": "Attention is All you Need the dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. the best performing models also connect the encoder and decoder through an attention mechanism. we propose a new simple network architecture, the transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. our model achieves 28.4 bleu on the wmt 2014 english-to-german translation task, improving over the existing best results, including ensembles by over 2 bleu. on the wmt 2014 english-to-french translation task, our model establishes a new single-model state-of-the-art bleu score of 41.8 after training for 3.5 days on eight gpus, a small fraction of the training costs of the best models from the literature. we show that the transformer generalizes well to other tasks by applying it successfully to english constituency parsing both with large and limited training data.",
            "contribution_ids": [
                "R176041"
            ]
        },
        {
            "instance_id": "EMPTYxR176050",
            "comparison_id": "EMPTY",
            "paper_id": "R176050",
            "text": "Probabilistic Logic Graph Attention Networks for Reasoning knowledge base completion, which involves the prediction of missing relations between entities in a knowledge graph, has been an active area of research. markov logic networks, which combine probabilistic graphical models and first order logic, have proven to be effective on knowledge graph tasks like link prediction and question answering. however, their intractable inference limits their scalability and wider applicability across various tasks. in recent times, graph attention neural networks, which capture features of neighbouring entities, have achieved superior results on highly complex graph problems like node classification and link prediction. combining the best of both worlds, we propose probabilistic logic graph attention network (pgat) for reasoning. in the proposed model, the joint distribution of all possible triplets defined by a markov logic network is optimized with a variational em algorithm. this helps us to efficiently combine first-order logic and graph attention networks. with the goal of establishing strong baselines for future research on link prediction, we evaluate our model on various standard link prediction benchmarks, and obtain competitive results.",
            "contribution_ids": [
                "R176052"
            ]
        },
        {
            "instance_id": "EMPTYxR141429",
            "comparison_id": "EMPTY",
            "paper_id": "R141429",
            "text": "VUV Spectral Irradiance Measurements in H_2/He/Ar Microwave Plasmas and Comparison with Solar Data microwave plasmas with h2 and h2/rare gas mixtures are convenient sources of vuv radiation for laboratory simulations of astrophysical media. we recently undertook an extensive study to characterize microwave plasmas in an h2/he gas mixture in order to optimize a vuv solar simulator over the 115\u2013170 nm spectral range. in this paper, we extend our investigation to the effect of the addition of ar into h2/he plasma on the vuv spectral irradiance. our study combines various optical diagnostics such as a vuv spectrometer and optical emission spectroscopy. quantitative measurements of the spectral irradiance and photons flux in different mixtures are accomplished using a combination of vuv spectrometry and chemical actinometry. results show that the ar addition into h2/he plasma largely affects the predominant emissions of the hydrogen ly\u03b1 line (121.6 nm) and h2 (b\u03c3u\u2013x \u03c3g) band (150\u2013170 nm). while a microwave plasma with 1.4% h2/he is required to mimic the entire vuv solar spectrum in the 115\u2013170 nm range, the combination with 1.28% h2/35% ar/he is the best alternative to obtain a quasi-monochromatic spectrum with emission dominated by the ly\u03b1 line. the maximum of the spectral irradiance is significantly higher in the ternary mixtures compared to the binary mixture of 1.4% h2/he. further ar increase yielded lower spectral irradiance and absolute photon fluxes. our measured spectral irradiances are compared to vuv solar data in the 115\u2013170 nm range, emphasizing the use of microwave plasmas in astrophysical studies and laboratory simulations of planetary atmospheres.",
            "contribution_ids": [
                "R141431"
            ]
        },
        {
            "instance_id": "EMPTYxR144290",
            "comparison_id": "EMPTY",
            "paper_id": "R144290",
            "text": "Stark broadening of spectral lines along the isoelectronic sequence of B a systematic study of experimental stark widths of 3s-3p and 3p-3d transitions in n iii-ne vi measured in a plasma produced by the gas-liner pinch device is reported. the scaling of measured stark widths with the spectroscopic charge number z (z=3 for n iii, etc.) shows appreciable deviations from that predicted by some theoretical calculations in the electron-impact approximation. a strong indication is found that proton collisions influence the linewidth of the 2s2p3s4p0-2s2p3p4d transition in ne vi in a significant way.",
            "contribution_ids": [
                "R144647"
            ]
        },
        {
            "instance_id": "EMPTYxR139878",
            "comparison_id": "EMPTY",
            "paper_id": "R139878",
            "text": "A Conceptual Enterprise Architecture Framework for Smart Cities - A Survey Based Approach:  \"enterprise architecture for smart cities is the focus of the research project \u201ceadic - (developing an enterprise architecture for digital cities)\u201d which is the context of the reported results in this work. we report in detail the results of a survey we contacted. using these results we identify important quality and functional requirements for smart cities. important quality properties include interoperability, usability, security, availability, recoverability and maintainability. we also observe business-related issues such as an apparent uncertainty on who is selling services, the lack of business plan in most cases and uncertainty in commercialization of services. at the software architecture domain we present a conceptual architectural framework based on architectural patterns which address the identified quality requirements. the conceptual framework can be used as a starting point for actual smart cities' projects.\"",
            "contribution_ids": [
                "R139880"
            ]
        },
        {
            "instance_id": "EMPTYxR141934",
            "comparison_id": "EMPTY",
            "paper_id": "R141934",
            "text": "Smart Cities: Definitions, Dimensions, Performance, and Initiatives abstract as the term \u201csmart city\u201d gains wider and wider currency, there is still confusion about what a smart city is, especially since several similar terms are often used interchangeably. this paper aims to clarify the meaning of the word \u201csmart\u201d in the context of cities through an approach based on an in-depth literature review of relevant studies as well as official documents of international institutions. it also identifies the main dimensions and elements characterizing a smart city. the different metrics of urban smartness are reviewed to show the need for a shared definition of what constitutes a smart city, what are its features, and how it performs in comparison to traditional cities. furthermore, performance measures and initiatives in a few smart cities are identified.",
            "contribution_ids": [
                "R141936"
            ]
        },
        {
            "instance_id": "EMPTYxR141937",
            "comparison_id": "EMPTY",
            "paper_id": "R141937",
            "text": "Mapping Dimensions of Governance in Smart Cities: Practitioners versus Prior Research many of the challenges to be faced by smart cities surpass the capacities, capabilities, and reaches of their traditional institutions and their classical processes of governing, and therefore new and innovative forms of governance are needed to meet these challenges. according to the network governance literature, governance models in public administrations can be categorized through the identification and analysis of some main dimensions that govern in the way of managing the city by governments. based on prior research and on the perception of city practitioners in european smart cities, this paper seeks to analyze the relevance of main dimensions of governance models in smart cities. results could shed some light regarding new future research on efficient patterns of governance models within smart cities.",
            "contribution_ids": [
                "R141939",
                "R141973"
            ]
        },
        {
            "instance_id": "EMPTYxR141940",
            "comparison_id": "EMPTY",
            "paper_id": "R141940",
            "text": "Smart city or smart citizens? The Barcelona case purpose \u2013 in recent years, the term \u201csmart city\u201d has attracted a lot of attention from policy makers, business leaders and citizenship in general. although there is not a unique definition of what a smart city is, it is generally accepted that \u201csmart\u201d urban policies refer to local governments\u2019 initiatives that use information and communication technologies in order to increase the quality of life of their inhabitants while contributing to a sustainable development. so far, \u201csmart city\u201d approaches have generally been related to top-down processes of technology diffusion. the purpose of this paper is to present a broader view on \u201csmart\u201d initiatives to analyze both top-down and bottom-up dynamics in a smart city. the authors argue that these two perspectives are complementary and its combination can reinforce the collaboration between different city stakeholders. top-down and bottom-up initiatives are not opposed forces but, on the contrary, can have a synergistic effect on the innovation capacity of the city. both perspectives are illustrated by providing examples of different \u201csmart\u201d aspects in the city of barcelona: smart districts, open collaborative spaces, infrastructures and open data. design/methodology/approach \u2013 to illustrate the arguments, the authors analyze the case of the city of barcelona providing examples of top-down and bottom-up initiatives in four different smart city aspects: smart districts, open collaborative spaces, infrastructures and open data. the research method is based on a case study (yin, 1984). the primary data consisted on interviews to city council representatives as well as managers of local public institutions, like economic development offices, and local organizations like for instance coworking spaces. the authors interviewed also specialists on the innovation history of the city in order to validate the data. in addition, the authors used secondary data such as reports on the 22@, and documentation on the barcelona innovation policies, as well as doing a compilation of press articles and the online content of the institutional webpages. all together, the authors have followed a data triangulation strategy to seek data validation based on the cross-verification of the analyzed data sources. findings \u2013 the analysis suggests that the top-down and bottom-up perspectives are complementary and their combination can reinforce the collaboration between different city stakeholders. top-down and bottom-up initiatives are not opposed forces but, on the contrary, can have a synergistic effect on the innovation capacity of the city. both perspectives are illustrated by providing examples of different \u201csmart\u201d aspects in the city of barcelona: smart districts, open collaborative spaces, infrastructures and open data. research limitations/implications \u2013 nevertheless, the analysis has its limitations. even if the authors have emphasized the importance of the bottom-up initiatives, citizens do not have often the resources to act without governmental intervention. this is the case of services that require high-cost infrastructures or regulatory changes. also, as it usually happens in the case of disruptive technology, it is hard for citizens to understand the possibilities of its use. in these cases, firms and institutions must play an important role in the first phases of the diffusion of innovations, by informing and incentivizing its use. it is also important to note that some of the emerging usages of technology are confronted to legal or regulatory issues. for instance, distributed and shared wi-fi networks might be in opposition to economic interests of internet providers, that often difficult its expansion. it is also the case of services of the sharing economy that represent a menace to established institutions (like the tensions between uber and taxi companies, or airbnb and hotels). in these cases, city halls like it is the case in barcelona, tend to respond to these emergent uses of technology by regulating to ensure protection to existing corporate services. practical implications \u2013 in conclusion, the transformational process that leads a city to become a smart city has to take in consideration the complexity and the plurality of the urban reality. beyond considering citizens as being users, testers or consumers of technology, local administrations that are able to identify, nourish and integrate the emerging citizens\u2019 initiatives would contribute to the reinforcement of a smart city reality. originality/value \u2013 the contribution of the paper is to go beyond the generalized technologic discourse around smart cities by adding the layer of the citizens\u2019 initiatives.",
            "contribution_ids": [
                "R141942"
            ]
        },
        {
            "instance_id": "EMPTYxR141949",
            "comparison_id": "EMPTY",
            "paper_id": "R141949",
            "text": "Making smart cities work in the face of conflicts: lessons from practitioners of South Korea\u2019s U-City projects a common concern in relation to smart cities is how to turn the concept into reality. the aim of this research is to investigate the implementation process of smart cities based upon the experience of south korea\u2019s u-city projects. the research shows that poorly-managed conflicts during implementation can diminish the potential of smart cities and discourage future improvements. the nature of smart cities is based on the concept of governance, while the planning practice is still in the notion of government. in order to facilitate the collaborative practice, the research has shown that collaborative institutional arrangements and joint fact-finding processes might secure an integrated service delivery for smart cities by overcoming operational difficulties in real-life contexts.",
            "contribution_ids": [
                "R141951"
            ]
        },
        {
            "instance_id": "EMPTYxR141961",
            "comparison_id": "EMPTY",
            "paper_id": "R141961",
            "text": "Smart Cities at the Crossroads: New Tensions in City Transformation the smart cities movement has produced a large number of projects and experiments around the world. to understand the primary ones, as well as their underlying tensions and the insights emerging from them, the editors of this special issue of the california management review enlisted a panel of experts, academics, and practitioners from different nationalities, backgrounds, experiences, and perspectives. the panel focused its discussion on three main areas: new governance models for smart cities, how to spur growth and renewal, and the sharing economy\u2014both commons and market based.",
            "contribution_ids": [
                "R141963"
            ]
        },
        {
            "instance_id": "EMPTYxR141974",
            "comparison_id": "EMPTY",
            "paper_id": "R141974",
            "text": "Smart Governance: Using a Literature Review and Empirical Analysis to Build a Research Model the attention for smart governance, a key aspect of smart cities, is growing, but our conceptual understanding of it is still limited. this article fills this gap in our understanding by exploring the concept of smart governance both theoretically and empirically and developing a research model of smart governance. on the basis of a systematic review of the literature defining elements, aspired outcomes and implementation strategies are identified as key dimensions of smart governance. inductively, we identify various categories within these variables. the key dimensions were presented to a sample of representatives of european local governments to investigate the dominant perceptions of practitioners and to refine the categories. our study results in a model for research into the implementation strategies, smart governance arrangements, and outcomes of smart governance.",
            "contribution_ids": [
                "R141976"
            ]
        },
        {
            "instance_id": "EMPTYxR141980",
            "comparison_id": "EMPTY",
            "paper_id": "R141980",
            "text": "Smart Cities Governance: The Need for a Holistic Approach to Assessing Urban Participatory Policy Making most of the definitions of a \u201csmart city\u201d make a direct or indirect reference to improving performance as one of the main objectives of initiatives to make cities \u201csmarter\u201d. several evaluation approaches and models have been put forward in literature and practice to measure smart cities. however, they are often normative or limited to certain aspects of cities\u2019 \u201csmartness\u201d, and a more comprehensive and holistic approach seems to be lacking. thus, building on a review of the literature and practice in the field, this paper aims to discuss the importance of adopting a holistic approach to the assessment of smart city governance and policy decision making. it also proposes a performance assessment framework that overcomes the limitations of existing approaches and contributes to filling the current gap in the knowledge base in this domain. one of the innovative elements of the proposed framework is its holistic approach to policy evaluation. it is designed to address a smart city\u2019s specificities and can benefit from the active participation of citizens in assessing the public value of policy decisions and their sustainability over time. we focus our attention on the performance measurement of codesign and coproduction by stakeholders and social innovation processes related to public value generation. more specifically, we are interested in the assessment of both the citizen centricity of smart city decision making and the processes by which public decisions are implemented, monitored, and evaluated as regards their capability to develop truly \u201cblended\u201d value services\u2014that is, simultaneously socially inclusive, environmentally friendly, and economically sustainable.",
            "contribution_ids": [
                "R141982"
            ]
        },
        {
            "instance_id": "EMPTYxR141986",
            "comparison_id": "EMPTY",
            "paper_id": "R141986",
            "text": "How smart is smart? Theoretical and empirical considerations on implementing smart city objectives \u2013 a case study of Dutch railway station areas the current widespread attention on the concept of smart city in both policy and practice has stimulated academic discussion regarding the scope and applicability of this concept. an important question is whether cities and regions are truly advanced in implementing the concept in their policies and practices relative to its conceptual elaborations in academia. the aim of this paper is to analyse this congruence between theory and practice in the context of the ongoing transformations of railway station areas in european urban regions. based on in-depth interviewing using aspects of q-methodology, this paper investigates whether and how smart city concepts are implemented by stakeholders in three station redevelopment projects in the netherlands. the results show that the current implementation of smart city concepts in practice is varied but modest and not (yet) very advanced. knowledge exchange and innovations are currently hampered by a lack of acceptance and know-how among stakeholders, as well as by institutional and competitive constraints. for instance, stakeholders stress that data privacy regulations should be well organized before further implementation can occur. transparency about how and what data are used may create more willingness among users to assist in developing and accepting new data technologies. however, the technologies are not yet completely developed, and concerns about the \u201closs\u201d of personal privacy are holding back the widespread and advanced use of data supplied technologies. although stakeholders seem to be aware of the opportunities the smart city concept offers, for now, the widespread implementation of innovative and advanced smart city concepts remains in the future.",
            "contribution_ids": [
                "R141988"
            ]
        },
        {
            "instance_id": "EMPTYxR141998",
            "comparison_id": "EMPTY",
            "paper_id": "R141998",
            "text": "How are citizens involved in smart cities? Analysing citizen participation in Japanese ``Smart Communities'' \"in recent years, ``smart cities'' have rapidly increased in discourses as well as in their real number, and raise various issues. while citizen engagement is a key element of most definitions of smart cities, information and communication technologies (icts) would also have great potential for facilitating public participation. however, scholars have highlighted that little research has focused on actual practices of citizen involvement in smart cities so far. in this respect, the authors analyse public participation in japanese ``smart communities'', paying attention to both official discourses and actual practices. smart communities were selected in 2010 by the japanese government which defines them as ``smart city'' projects and imposed criteria such as focus on energy issues, participation and lifestyle innovation. drawing on analysis of official documents as well as on interviews with each of the four smart communities' stakeholders, the paper explains that very little input is expected from japanese citizens. instead, icts are used by municipalities and electric utilities to steer project participants and to change their behaviour. the objective of smart communities would not be to involve citizens in city governance, but rather to make them participate in the co-production of public services, mainly energy production and distribution.\"",
            "contribution_ids": [
                "R142000"
            ]
        },
        {
            "instance_id": "EMPTYxR142005",
            "comparison_id": "EMPTY",
            "paper_id": "R142005",
            "text": "Human limitations to introduction of smart cities: Comparative analysis from two CEE cities abstract smart cities are a modern administrative/ developmental concept that tries to combine the development of urban areas with a higher level of citizens\u2019 participation. however, there is a lack of understanding of the concept\u2019s potential, due possibly to an unwillingness to accept a new form of relationship with the citizens. in this article, the willingness to introduce the elements of smart cities into two central and eastern european cities is tested. the results show that people are reluctant to use technology above the level of their needs and show little interest in participating in matters of governance, which prevents smart cities from developing in reality.",
            "contribution_ids": [
                "R142007"
            ]
        },
        {
            "instance_id": "EMPTYxR142008",
            "comparison_id": "EMPTY",
            "paper_id": "R142008",
            "text": "Speculative futures: Cities, data, and governance beyond smart urbanism in this paper, i examine the convergence of big data and urban governance beyond the discursive and material contexts of the smart city. i argue that in addition to understanding the intensifying relationship between data, cities, and governance in terms of regimes of automated management and coordination in \u2018actually existing\u2019 smart cities, we should further engage with urban algorithmic governance and governmentality as material-discursive projects of future-ing, i.e., of anticipating particular kinds of cities-to-come. as urban big data looks to the future, it does so through the lens of an anticipatory security calculus fixated on identifying and diverting risks of urban anarchy and personal harm against which life in cities must be securitized. i suggest that such modes of algorithmic speculation are discernible at two scales of urban big data praxis: the scale of the body, and that of the city itself. at the level of the urbanite body, i use the selective example of mobile neighborhood safety apps to demonstrate how algorithmic governmentality enacts digital mediations of individual mobilities by routing individuals around \u2018unsafe\u2019 parts of the city in the interests of technologically ameliorating the risks of urban encounter. at the scale of the city, amongst other empirical examples, sentiment analytics approaches prefigure ephemeral spatialities of civic strife by aggregating and mapping individual emotions distilled from unstructured real-time content flows (such as tweets). in both of these instances, the urban futures anticipated by the urban \u2018big data security assemblage\u2019 are highly uneven, as data and algorithms cannot divest themselves of urban inequalities and the persistence of their geographies.",
            "contribution_ids": [
                "R142010"
            ]
        },
        {
            "instance_id": "EMPTYxR142029",
            "comparison_id": "EMPTY",
            "paper_id": "R142029",
            "text": "Smart governance as key to multi-jurisdictional smart city initiatives: The case of the eCityGov Alliance quite a number of smart-city initiatives from around the world have been analyzed and documented, and a growing body of academic knowledge is evolving around the phenomenon of the smart city. smart-city government is seen as an important driver for developing a smart urban environment. the ecitygov alliance in the pacific northwest of the usa represents a special case of a successful smart-city collaboration between nine neighboring municipalities, which combined forces to provide smart services to citizens and businesses that no single municipality could have provided alone. developing and maintaining a collaborative governance model appears as the most important key success factor in such multi-jurisdictional smart-city undertakings. this study investigates the governance model of the ecitygov alliance and its opportunities, and potential pitfalls. it concludes that the ecitygov alliance can serve as a role model for such multi-jurisdictional smart-city initiatives.",
            "contribution_ids": [
                "R142031"
            ]
        },
        {
            "instance_id": "EMPTYxR142032",
            "comparison_id": "EMPTY",
            "paper_id": "R142032",
            "text": "The empty rhetoric of the smart city: from digital inclusion to economic promotion in Philadelphia smart city initiatives have been adopted by cities worldwide, proposing forward-looking, technological solutions to urban problems big and small. these policies are indicative of a digitized urban condition, where social and economic exchange rely on globalized telecommunications networks, and governance strategies follow suit. propelled through events such as ibm\u2019s smarter cities challenge, the smart city acts as a data-driven logic urban change where widespread benefit to a city and its residents is proposed, masking the utility of these policies to further entrepreneurial economic development strategies. in this article, i present a case study of the digital on-ramps initiative that emerged from ibm\u2019s policy-consultation in philadelphia. the initiative proposed a social media-style workforce education application (app) to train up to 500,000 low-literacy residents for jobs in the information and knowledge economy, but even as the city\u2019s mayor declared the project a success, it did not meet expectations. this essay argues that the rhetoric of intelligent, transformative digital change works much more to \u201csell\u201d a city in the global economy than to actually address urban inequalities.",
            "contribution_ids": [
                "R142034"
            ]
        },
        {
            "instance_id": "EMPTYxR146443",
            "comparison_id": "EMPTY",
            "paper_id": "R146443",
            "text": "Encouraging civic participation through local news aggregation traditional sources of information for small and rural communities have been disappearing over the past decade. a lot of the information and discussion related to such local geographic areas is now scattered across websites of numerous local organizations, individual blogs, social media and other user-generated media (youtube, flickr). it is important to capture this information and make it easily accessible to local citizens to facilitate citizen engagement and social interaction. furthermore, a system that has location-based support can provide local citizens with an engaging way to interact with this information and identify the local issues most relevant to them. a location-based interface for a local geographic area enables people to identify and discuss local issues related to specific locations such as a particular street or a road construction site. we created an information aggregator, called the virtual town square (vts), to support and facilitate local discussion and interaction. we created a location-based interface for users to access the information collected by vts. in this paper, we discuss focus group interviews with local citizens that motivated our design of a local news and information aggregator to facilitate civic participation. we then discuss the unique design challenges in creating such a local news aggregator and our design approach to create a local information ecosystem. we describe vts and the initial evaluation and feedback we received from local users and through weekly meetings with community partners.",
            "contribution_ids": [
                "R146445"
            ]
        },
        {
            "instance_id": "EMPTYxR142138",
            "comparison_id": "EMPTY",
            "paper_id": "R142138",
            "text": "Mapping Intracellular Temperature Using Green Fluorescent Protein heat is of fundamental importance in many cellular processes such as cell metabolism, cell division and gene expression. (1-3) accurate and noninvasive monitoring of temperature changes in individual cells could thus help clarify intricate cellular processes and develop new applications in biology and medicine. here we report the use of green fluorescent proteins (gfp) as thermal nanoprobes suited for intracellular temperature mapping. temperature probing is achieved by monitoring the fluorescence polarization anisotropy of gfp. the method is tested on gfp-transfected hela and u-87 mg cancer cell lines where we monitored the heat delivery by photothermal heating of gold nanorods surrounding the cells. a spatial resolution of 300 nm and a temperature accuracy of about 0.4 \u00b0c are achieved. benefiting from its full compatibility with widely used gfp-transfected cells, this approach provides a noninvasive tool for fundamental and applied research in areas ranging from molecular biology to therapeutic and diagnostic studies.",
            "contribution_ids": [
                "R142140"
            ]
        },
        {
            "instance_id": "EMPTYxR142311",
            "comparison_id": "EMPTY",
            "paper_id": "R142311",
            "text": "ERONTO: a tool for extracting ontologies from extended E/R diagrams realization of semantic web requires structuring of web data using domain ontologies. most data intensive websites are powered by relational databases whose design process involves developing conceptual model using e/r or extended e/r diagrams. this paper discusses the implementation details of a tool that builds domain ontologies in owl (ontology web language) from extended e/r diagrams. ontology development being a knowledge intensive task, our tool would be helpful in reducing the developmental efforts by automating the process. we bring out the differences and the similarities between the expressive capabilities of the two conceptual modeling methods, namely owl and extended e/r diagrams.",
            "contribution_ids": [
                "R142313"
            ]
        },
        {
            "instance_id": "EMPTYxR142319",
            "comparison_id": "EMPTY",
            "paper_id": "R142319",
            "text": "An Innovative Statistical Tool for Automatic OWL-ERD Alignment aligning two representations of the same domain with different expressiveness is a crucial topic in nowadays semantic web and big data research. owl ontologies and entity relation diagrams are the most widespread representations whose alignment allows for semantic data access via ontology interface, and ontology storing techniques. the term \"\"alignment\" encompasses three different processes: owl-to-erd and erd-to-owl transformation, and owl-erd mapping. in this paper an innovative statistical tool is presented to accomplish all the three aspects of the alignment. the main idea relies on the use of a hmm to estimate the most likely erd sentence that is stated in a suitable grammar, and corresponds to the observed owl axiom. the system and its theoretical background are presented, and some experiments are reported.",
            "contribution_ids": [
                "R142321"
            ]
        },
        {
            "instance_id": "EMPTYxR142349",
            "comparison_id": "EMPTY",
            "paper_id": "R142349",
            "text": "Mapping between Relational Database Schema and OWL Ontology for Deep Annotation creating mappings between database schema and web ontology is a preconditioning process in the generation of ontological annotations for dynamic web page contents extracted from the database. in this paper, a practical approach to creating mappings between a relational database schema and an owl ontology is presented. the approach can automatically construct the mappings by following a set of predefined heuristic rules based on the conceptual correspondences between the schema and the ontology. this automatic mapping is implemented as the core functionality in a prototype tool d2omapper that has some assistant functions to help the user manually create and maintain the mappings. case studies show that the proposed approach is effective and the produced mappings can be applied to semantic annotation of database-based, dynamic web pages",
            "contribution_ids": [
                "R142351"
            ]
        },
        {
            "instance_id": "EMPTYxR142352",
            "comparison_id": "EMPTY",
            "paper_id": "R142352",
            "text": "Schema  ontologies are one of the key technologies for data integration and meta-databases, by connecting databases on a semantical level. still, everything fails when one of the database schemas changes: specific parts of the ontology have to be reconstructed by hand. we propose an approach that allows the database schema and the ontology to change and evolve, without ever losing their connection to each other. we call that \"coevolution\". coevolution cannot be completely automated, as data definition languages do not define the change of semantical concepts, but only technical schema changes. in this paper we present our mapping of database schemas to ontologies, describe how these ontologies can be enriched by semantical information and show our approach to transfer schema changes to the ontology",
            "contribution_ids": [
                "R142354"
            ]
        },
        {
            "instance_id": "EMPTYxR146670",
            "comparison_id": "EMPTY",
            "paper_id": "R146670",
            "text": "ParsCit: an Open-source CRF Reference String Parsing Package we describe parscit, a freely available, open-source implementation of a reference string parsing package. at the core of parscit is a trained conditional random field (crf) model used to label the token sequences in the reference string. a heuristic model wraps this core with added functionality to identify reference strings from a plain text file, and to retrieve the citation contexts. the package comes with utilities to run it as a web service or as a standalone utility. we compare parscit on three distinct reference string datasets and show that it compares well with other previously published work.",
            "contribution_ids": [
                "R146672"
            ]
        },
        {
            "instance_id": "EMPTYxR146741",
            "comparison_id": "EMPTY",
            "paper_id": "R146741",
            "text": "The Stanford CoreNLP Natural Language Processing Toolkit we describe the design and use of the stanford corenlp toolkit, an extensible pipeline that provides core natural language analysis. this toolkit is quite widely used, both in the research nlp community and also among commercial and government users of open source nlp technology. we suggest that this follows from a simple, approachable design, straightforward interfaces, the inclusion of robust and good quality analysis components, and not requiring use of a large amount of associated baggage.",
            "contribution_ids": [
                "R146743",
                "R162883",
                "R187503"
            ]
        },
        {
            "instance_id": "EMPTYxR147523",
            "comparison_id": "EMPTY",
            "paper_id": "R147523",
            "text": "The ACL Anthology Reference Corpus: A Reference Dataset for Bibliographic Research in Computational Linguistics this is a post-print of a paper from sixth international conference on language resources and evaluation 2008 http://www.lrec-conf.org/lrec2008/",
            "contribution_ids": [
                "R147525"
            ]
        },
        {
            "instance_id": "EMPTYxR156121",
            "comparison_id": "EMPTY",
            "paper_id": "R156121",
            "text": "The Web as a Knowledge-Base for Answering Complex Questions answering complex questions is a time-consuming activity for humans that requires reasoning and integration of information. recent work on reading comprehension made headway in answering simple questions, but tackling complex questions is still an ongoing research challenge. conversely, semantic parsers have been successful at handling compositionality, but only when the information resides in a target knowledge-base. in this paper, we present a novel framework for answering broad and complex questions, assuming answering simple questions is possible using a search engine and a reading comprehension model. we propose to decompose complex questions into a sequence of simple questions, and compute the final answer from the sequence of answers. to illustrate the viability of our approach, we create a new dataset of complex questions, complexwebquestions, and present a model that decomposes questions and interacts with the web to compute an answer. we empirically demonstrate that question decomposition improves performance from 20.8 precision@1 to 27.5 precision@1 on this new dataset.",
            "contribution_ids": [
                "R156123"
            ]
        },
        {
            "instance_id": "EMPTYxR163221",
            "comparison_id": "EMPTY",
            "paper_id": "R163221",
            "text": "Extraction of Information from the Text of Chemical Patents. 1. Identification of Specific Chemical Names much attention has been paid to translating isolated chemical names into forms such as connection tables, but less effort has been expended in identifying substance names in running text to make them available for processing. the requirement for automatic name identification becomes a more urgent priority today, not the least in light of the inherent importance of patents and the increasing complexity of newly synthesized substances and, with these, the need for error-free processing of information from patent and other documents. the elaboration of a methodology for isolating substance names in the text of english-language patents is described here, using, in part, the sgml (standard generalized markup language) of the patent text as an aid to this process. evaluation of the procedures, which are still at an early stage of development, demonstrates that even simple methods can achieve very high degrees of success.",
            "contribution_ids": [
                "R163223"
            ]
        },
        {
            "instance_id": "EMPTYxR166335",
            "comparison_id": "EMPTY",
            "paper_id": "R166335",
            "text": "Overview of BioCreAtIvE task 1B: normalized gene lists abstract \\n \\n background \\n our goal in biocreative has been to assess the state of the art in text mining, with emphasis on applications that reflect real biological applications, e.g., the curation process for model organism databases. this paper summarizes the biocreative task 1b, the \"normalized gene list\" task, which was inspired by the gene list supplied for each curated paper in a model organism database. the task was to produce the correct list of unique gene identifiers for the genes and gene products mentioned in sets of abstracts from three model organisms (yeast, fly, and mouse). \\n \\n \\n results \\n eight groups fielded systems for three data sets (yeast, fly, and mouse). for yeast, the top scoring system (out of 15) achieved 0.92 f-measure (harmonic mean of precision and recall); for mouse and fly, the task was more difficult, due to larger numbers of genes, more ambiguity in the gene naming conventions (particularly for fly), and complex gene names (for mouse). for fly, the top f-measure was 0.82 out of 11 systems and for mouse, it was 0.79 out of 16 systems. \\n \\n \\n conclusion \\n this assessment demonstrates that multiple groups were able to perform a real biological task across a range of organisms. the performance was dependent on the organism, and specifically on the naming conventions associated with each organism. these results hold out promise that the technology can provide partial automation of the curation process in the near future. \\n",
            "contribution_ids": [
                "R166336"
            ]
        },
        {
            "instance_id": "EMPTYxR76157",
            "comparison_id": "EMPTY",
            "paper_id": "R76157",
            "text": "SemEval-2020 Task 3: Graded Word Similarity in Context this paper presents the graded word similarity in context (gwsc) task which asked participants to predict the effects of context on human perception of similarity in english, croatian, slovene and finnish. we received 15 submissions and 11 system description papers. a new dataset (cosimlex) was created for evaluation in this task: it contains pairs of words, each annotated within two different contexts. systems beat the baselines by significant margins, but few did well in more than one language or subtask. almost every system employed a transformer model, but with many variations in the details: wordnet sense embeddings, translation of contexts, tf-idf weightings, and the automatic creation of datasets for fine-tuning were all used to good effect.",
            "contribution_ids": [
                "R76159",
                "R76226",
                "R76231",
                "R76232",
                "R76233",
                "R76244",
                "R76245",
                "R76246",
                "R76247",
                "R76248",
                "R76249",
                "R76250",
                "R76251",
                "R76289",
                "R76290",
                "R76291",
                "R76292",
                "R76293",
                "R76294",
                "R76295",
                "R76296",
                "R76298",
                "R76299",
                "R76300",
                "R76301"
            ]
        },
        {
            "instance_id": "EMPTYxR150967",
            "comparison_id": "EMPTY",
            "paper_id": "R150967",
            "text": "Annotation of Chemical Named Entities we describe the annotation of chemical named entities in scientific text. a set of annotation guidelines defines 5 types of named entities, and provides instructions for the resolution of special cases. a corpus of fulltext chemistry papers was annotated, with an inter-annotator agreement f score of 93%. an investigation of named entity recognition using lingpipe suggests that f scores of 63% are possible without customisation, and scores of 74% are possible with the addition of custom tokenisation and the use of dictionaries.",
            "contribution_ids": [
                "R150969"
            ]
        },
        {
            "instance_id": "EMPTYxR182166",
            "comparison_id": "EMPTY",
            "paper_id": "R182166",
            "text": "Nutrition education, farm production diversity, and commercialization on household and individual dietary diversity in Zimbabwe background nutrition education is crucial for improved nutrition outcomes. however, there are no studies to the best of our knowledge that have jointly analysed the roles of nutrition education, farm production diversity and commercialization on household, women and child dietary diversity. objective this article jointly analyses the role of nutrition education, farm production diversity and commercialization on household, women and children dietary diversity in zimbabwe. in addition, we analyze separately the roles of crop and livestock diversity and individual agricultural practices on dietary diversity. design data were collected from 2,815 households randomly selected in eight districts. negative binomial regression was used for model estimations. results nutrition education increased household, women, and child dietary diversity by 3, 9 and 24%, respectively. farm production diversity had a strong and positive association with household and women dietary diversity. crop diversification led to a 4 and 5% increase in household and women dietary diversity, respectively. furthermore, livestock diversification and market participation were positively associated with household, women, and children dietary diversity. the cultivation of pulses and fruits increased household, women, and children dietary diversity. vegetable production and goat rearing increased household and women dietary diversity. conclusions nutrition education and improving access to markets are promising strategies to improve dietary diversity at both household and individual level. results demonstrate the value of promoting nutrition education; farm production diversity; small livestock; pulses, vegetables and fruits; crop-livestock integration; and market access for improved nutrition.",
            "contribution_ids": [
                "R182168"
            ]
        },
        {
            "instance_id": "EMPTYxR182384",
            "comparison_id": "EMPTY",
            "paper_id": "R182384",
            "text": "Production diversity and dietary diversity in smallholder farm households significance \\n given that hunger and malnutrition are still widespread problems in many developing countries, the question of how to make agriculture and food systems more nutrition-sensitive is of high relevance for research and policy. many of the undernourished people in africa and asia are small-scale subsistence farmers. diversifying production on these farms is often perceived as a promising strategy to improve dietary quality and diversity. this hypothesis is tested with data from smallholder farm households in indonesia, kenya, ethiopia, and malawi. higher farm production diversity significantly contributes to dietary diversity in some situations, but not in all. improving small farmers\u2019 access to markets seems to be a more effective strategy to improve nutrition than promoting production diversity on subsistence farms.",
            "contribution_ids": [
                "R182386"
            ]
        },
        {
            "instance_id": "EMPTYxR142089",
            "comparison_id": "EMPTY",
            "paper_id": "R142089",
            "text": "Iranian Registry of Crohn\u2019s and Colitis: study profile of first nation-wide inflammatory bowel disease registry in Middle East background/aims a recent study revealed increasing incidence and prevalence of inflammatory bowel disease (ibd) in iran. the iranian registry of crohn\u2019s and colitis (ircc) was designed recently to answer the needs. we reported the design, methods of data collection, and aims of ircc in this paper. methods ircc is a multicenter prospective registry, which is established with collaboration of more than 100 gastroenterologists from different provinces of iran. minimum data set for ircc was defined according to an international consensus on standard set of outcomes for ibd. a pilot feasibility study was performed on 553 ibd patients with a web-based questionnaire. the reliability of questionnaire evaluated by cronbach\u2019s \u03b1. results all sections of questionnaire had cronbach\u2019s \u03b1 of more than 0.6. in pilot study, 312 of participants (56.4%) were male and mean age was 38 years (standard deviation=12.8) and 378 patients (68.35%) had ulcerative colitis, 303 subjects (54,7%) had college education and 358 patients (64.74%) were of fars ethnicity. we found that 68 (12.3%), 44 (7.9%), and 13 (2.3%) of participants were smokers, hookah and opium users, respectively. history of appendectomy was reported in 58 of patients (10.48%). the most common medication was 5-aminosalicylate (94.39%). conclusions to the best of our knowledge, ircc is the first national ibd registry in the middle east and could become a reliable infrastructure for national and international research on ibd. ircc will improve the quality of care of ibd patients and provide national information for policy makers to better plan for controlling ibd in iran.",
            "contribution_ids": [
                "R142093"
            ]
        },
        {
            "instance_id": "EMPTYxR178436",
            "comparison_id": "EMPTY",
            "paper_id": "R178436",
            "text": "SAIDuCANT: Specification-Based Automotive Intrusion Detection Using Controller Area Network (CAN) Timing the proliferation of embedded devices in modern vehicles has opened the traditionally-closed vehicular system to the risk of cybersecurity attacks through physical and remote access to the in-vehicle network such as the controller area network (can). the can bus does not implement a security protocol that can protect the vehicle against the increasing cyber and physical attacks. to address this risk, we introduce a novel algorithm to extract the real-time model parameters of the can bus and develop saiducant, a specification-based intrusion detection system (ids) using anomaly-based supervised learning with the real-time model as input. we evaluate the effectiveness of saiducant with real can logs collected from two passenger cars and on an open-source can dataset collected from real-world scenarios. experimental results show that saiducant can effectively detect data injection attacks with low false positive rates. over four real attack scenarios from the open-source dataset, saiducant observes at most one false positive before detecting an attack whereas other detection approaches using can timing features detect on average more than a hundred false positives before a real attack occurs.",
            "contribution_ids": [
                "R178442"
            ]
        },
        {
            "instance_id": "EMPTYxR188891",
            "comparison_id": "EMPTY",
            "paper_id": "R188891",
            "text": "Evaluation Framework for Network Intrusion Detection Systems for In-Vehicle CAN modern vehicles are complex safety critical cyber physical systems, that are connected to the outside world, with all security implications it brings. different network intrusion detection systems (nidss) proposed for the can bus, the predominant type of in-vehicle network, to improve security are hard to compare due to disparate evaluation methods adopted. in this paper we provide the means to compare can nidss on equal footing and evaluate the ones detailed in the literature. based on this we observe some limitation of existing approaches and why in the can setting it is intrinsically difficult to distinguish benign from malicious payload. we argue that \u201cmeaning-aware\u201d detection (a concept we define) which is challenging (but perhaps not impossible) to create for this setting.",
            "contribution_ids": [
                "R188893"
            ]
        },
        {
            "instance_id": "EMPTYxR204210",
            "comparison_id": "EMPTY",
            "paper_id": "R204210",
            "text": "Accelerating PUF-based UAV Authentication Protocols Using Programmable Switch many uav technology use cases (e.g., traffic management) has ultra-low latency and strong security requirements. but achieving both simultaneously is challenging. in this work, we consider uav device authentication as a use case and develop a fast and secure uav device authentication system. our key idea is to leverage highly secure physically unclonable functions (pufs) and high-speed programmable packet-processing data planes, and develop a practically deployable puf-based authentication protocol for uavs that is (a) robust to various security attacks, and (b) enables uav authentication at network speed. in this work, we demonstrate the feasibility of our idea by offloading the authentication protocol to a tofino-based highspeed programmable switch. our preliminary experiments show that protocol offloading would reduce authentication latency significantly (approx. 100 %).",
            "contribution_ids": [
                "R204212"
            ]
        },
        {
            "instance_id": "EMPTYxR191648",
            "comparison_id": "EMPTY",
            "paper_id": "R191648",
            "text": "Fake Accounts Detection on Twitter Using Blacklist social networking sites such as twitter, facebook, weibo etc. are extremely mainstream today. also, the greater part of the malicious users utilize these sites to persuade legitimate users for different purposes, for example, to promote their products item, to enter their spam links, to stigmatize other persons and so forth. an ever increasing number of users are utilized these social networking sites and fake accounts on these destinations are turned into a major issue. in this paper, fake accounts are detected using blacklist instead of traditional spam words list. blacklist is created by using topic modeling approach and keyword extraction approach. we conduct an evaluation experiment with not only 1ks - 10kn dataset but also social honeypot dataset. the accuracy of the traditional spam words list based approach and our blacklist based approach are compared. decorate, a meta-learner classifier is applied for classifying fake accounts on twitter from legitimate accounts. our approach achieves 95.4% accuracy and true positive rate is 0.95.",
            "contribution_ids": [
                "R191650"
            ]
        },
        {
            "instance_id": "EMPTYxR186234",
            "comparison_id": "EMPTY",
            "paper_id": "R186234",
            "text": "PredictRoute: A Network Path Prediction Toolkit \" accurate prediction of network paths between arbitrary hosts on the internet is of vital importance for network operators, cloud providers, and academic researchers. we present predictroute, a system that predicts network paths between hosts on the internet using historical knowledge of the data and control plane. in addition to feeding on freely available traceroutes and bgp routing tables, predictroute optimally explores network paths towards chosen bgp prefixes. predictroute's strategy for exploring network paths discovers 4x more autonomous system (as) hops than other well-known strategies used in practice today. using a corpus of traceroutes, predictroute trains probabilistic models of routing towards prefixes on the internet to predict network paths and their likelihood. predictroute's as-path predictions differ from the measured path by at most 1 hop, 75% of the time. we expose predictroute's path prediction capability via a rest api to facilitate its inclusion in other applications and studies. we additionally demonstrate the utility of predictroute in improving real-world applications for circumventing internet censorship and preserving anonymity online. \"",
            "contribution_ids": [
                "R186236"
            ]
        },
        {
            "instance_id": "EMPTYxR144046",
            "comparison_id": "EMPTY",
            "paper_id": "R144046",
            "text": "Land Use and Avian Species Diversity Along an Urban Gradient i examined the distribution and abundance of bird species across an urban gradient, and concomitant changes in community structure, by censusing summer resident bird populations at six sites in santa clara county, california (all former oak woodlands). these sites represented a gradient of urban land use that ranged from relatively undisturbed to highly developed, and included a biological preserve, recreational area, golf course, residential neighborhood, office park, and business district. the composition of the bird community shifted from predominantly native species in the undisturbed area to invasive and exotic species in the business district. species richness, shannon diversity, and bird biomass peaked at moderately disturbed sites. one or more species reached maximal densities in each of the sites, and some species were restricted to a given site. the predevelopment bird species (assumed to be those found at the most undisturbed site) dropped out gradually as the sites became more urban. these patterns were significantly related to shifts in habitat structure that occurred along the gradient, as determined by canonical correspondence analysis (cca) using the environmental variables of percent land covered by pavement, buildings, lawn, grasslands, and trees or shrubs. i compared each formal site to four additional sites with similar levels of development within a two-county area to verify that the bird communities at the formal study sites were rep- resentative of their land use category.",
            "contribution_ids": [
                "R144048"
            ]
        },
        {
            "instance_id": "EMPTYxR52092",
            "comparison_id": "EMPTY",
            "paper_id": "R52092",
            "text": "Species composition and diversity affect grassland susceptibility and response to invasion in a microcosm experiment, i tested how species composition, species rich- ness, and community age affect the susceptibility of grassland communities to invasion by a noxious weed (centaurea solstitialis l.). i also examined how these factors influenced centaurea\\'s impact on the rest of the plant community. when grown in monoculture, eight species found in california\\'s grasslands differed widely in their ability to suppress centaurea growth. the most effective competitor in monoculture was hemizonia congesta ssp. iuzulifolia, which, like centaurea, is a summer- active annual forb. on average, centaurea growth decreased as the species richness of communities increased. however, no polyculture suppressed centaurea growth more than the monoculture of hemizonia. centaurea generally made up a smaller proportion of com- munity biomass in newly created (\"new\") microcosms than in older (\"established\") mi- crocosms, largely because centaurea\\'s competitors were more productive in the new treat- ment. measures of complementarity suggest that centaurea partitioned resources with an- nual grasses in the new microcosms. this resource partitioning may help to explain cen- taurea\\'s great success in western north american grasslands. centaurea strongly suppressed growth of some species but hardly affected others. an- nual grasses were the least affected species in the new monocultures, and perennial grasses were among the least affected species in the established monocultures. in the new micro- cosms, centaurea\\'s suppression of competing species marginally abated with increasing species richness. this trend was a consequence of the declining success of centaurea in species-rich communities, rather than a change in the vulnerability of these communities to suppression by a given amount of the invader. the impact of the invader was not related to species richness in the-established microcosms. the results of this study suggest that, at the neighborhood level, diversity can limit invasibility and may reduce the impact of an invader.",
            "contribution_ids": [
                "R52093"
            ]
        },
        {
            "instance_id": "EMPTYxR175444",
            "comparison_id": "EMPTY",
            "paper_id": "R175444",
            "text": "Efficient synthesis of physically valid human motion \\n optimization is a promising way to generate new animations from a minimal amount of input data. physically based optimization techniques, however, are difficult to scale to complex animated characters, in part because evaluating and differentiating physical quantities becomes prohibitively slow. traditional approaches often require optimizing or constraining parameters involving joint torques; obtaining first derivatives for these parameters is generally an\\n o \\n (\\n d \\n 2 \\n ) process, where\\n d \\n is the number of degrees of freedom of the character. in this paper, we describe a set of objective functions and constraints that lead to linear time analytical first derivatives. the surprising finding is that this set includes constraints on physical validity, such as ground contact constraints. considering only constraints and objective functions that lead to linear time first derivatives results in fast per-iteration computation times and an optimization problem that appears to scale well to more complex characters. we show that qualities such as squash-and-stretch that are expected from physically based optimization result from our approach. our animation system is particularly useful for synthesizing highly dynamic motions, and we show examples of swinging and leaping motions for characters having from 7 to 22 degrees of freedom.\\n",
            "contribution_ids": [
                "R175446"
            ]
        },
        {
            "instance_id": "EMPTYxR75340",
            "comparison_id": "EMPTY",
            "paper_id": "R75340",
            "text": "What Public Transit API Logs Tell Us about Travel Flows in the field of smart cities, researchers need an indication of how people move in and between cities. yet, getting statistics of travel flows within public transit systems has proven to be troublesome. in order to get an indication of public transit travel flows in belgium, we analyzed the query logs of the irail api, a highly expressive route planning api for the belgian railways. we were able to study 100k to 500k requests for each month between october 2012 and november 2015, which is between 0.56% and 1.66% of the amount of monthly passengers. using data visualizations, we illustrate the commuting patterns in belgium and confirm that brussels, the capital, acts as a central hub. the flemish region appears to be polycentric, while in the walloon region, everything converges on brussels. the findings correspond to the real travel demand, according to experts of the passenger federation trein tram bus. we conclude that query logs of route planners are of high importance in getting an indication of travel flows. however, better travel intentions would be acquirable using dedicated http post requests.",
            "contribution_ids": [
                "R75342"
            ]
        },
        {
            "instance_id": "EMPTYxR175447",
            "comparison_id": "EMPTY",
            "paper_id": "R175447",
            "text": "Motion synthesis and editing in low-dimensional spaces \"human motion is difficult to create and manipulate because of the high dimensionality and spatiotemporal nature of human motion data. recently, the use of large collections of captured motion data has added increased realism in character animation. in order to make the synthesis and analysis of motion data tractable, we present a low\u2010dimensional motion space in which high\u2010dimensional human motion can be effectively visualized, synthesized, edited, parameterized, and interpolated in both spatial and temporal domains. our system allows users to create and edit the motion of animated characters in several ways: the user can sketch and edit a curve on low\u2010dimensional motion space, directly manipulate the character's pose in three\u2010dimensional object space, or specify key poses to create in\u2010between motions. copyright \u00a9 2006 john wiley & sons, ltd.\"",
            "contribution_ids": [
                "R175449"
            ]
        },
        {
            "instance_id": "EMPTYxR178308",
            "comparison_id": "EMPTY",
            "paper_id": "R178308",
            "text": "The KIT whole-body human motion database we present a large-scale whole-body human motion database consisting of captured raw motion data as well as the corresponding post-processed motions. this database serves as a key element for a wide variety of research questions related e.g. to human motion analysis, imitation learning, action recognition and motion generation in robotics. in contrast to previous approaches, the motion data in our database considers the motions of the observed human subject as well as the objects with which the subject is interacting. the information about human-object relations is crucial for the proper understanding of human actions and their goal-directed reproduction on a robot. to facilitate the creation and processing of human motion data, we propose procedures and techniques for capturing of motion, labeling and organization of the motion capture data based on a motion description tree, as well as for the normalization of human motion to an unified representation based on a reference model of the human body. we provide software tools and interfaces to the database allowing access and efficient search with the proposed motion representation.",
            "contribution_ids": [
                "R178310"
            ]
        },
        {
            "instance_id": "EMPTYxR178314",
            "comparison_id": "EMPTY",
            "paper_id": "R178314",
            "text": "Human motion database with a binary tree and node transition graphs database of human motion has been widely used for recognizing human motion and synthesizing humanoid motions. in this paper, we propose a data structure for storing and extracting human motion data and demonstrate that the database can be applied to the recognition and motion synthesis problems in robotics. we develop an efficient method for building a human motion database from a collection of continuous, multi-dimensional motion clips. the database consists of a binary tree representing the hierarchical clustering of the states observed in the motion clips, as well as node transition graphs representing the possible transitions among the nodes in the binary tree. using databases constructed from real human motion data, we demonstrate that the proposed data structure can be used for human motion recognition, state estimation and prediction, and robot motion planning.",
            "contribution_ids": [
                "R178316"
            ]
        },
        {
            "instance_id": "EMPTYxR178317",
            "comparison_id": "EMPTY",
            "paper_id": "R178317",
            "text": "HMDB: A large video database for human motion recognition with nearly one billion online videos viewed everyday, an emerging new frontier in computer vision research is recognition and search in video. while much effort has been devoted to the collection and annotation of large scalable static image datasets containing thousands of image categories, human action datasets lag far behind. current action recognition databases contain on the order of ten different action categories collected under fairly controlled conditions. state-of-the-art performance on these datasets is now near ceiling and thus there is a need for the design and creation of new benchmarks. to address this issue we collected the largest action video database to-date with 51 action categories, which in total contain around 7,000 manually annotated clips extracted from a variety of sources ranging from digitized movies to youtube. we use this database to evaluate the performance of two representative computer vision systems for action recognition and explore the robustness of these methods under various conditions such as camera motion, viewpoint, video quality and occlusion.",
            "contribution_ids": [
                "R178319"
            ]
        },
        {
            "instance_id": "EMPTYxR178329",
            "comparison_id": "EMPTY",
            "paper_id": "R178329",
            "text": "Multimodal Database for Human Activity Recognition and Fall Detection fall detection can improve the security and safety of older people and alert when fall occurs. fall detection systems are mainly based on wearable sensors, ambient sensors, and vision. each method has commonly known advantages and limitations. multimodal and data fusion approaches present a combination of data sources in order to better describe falls. publicly available multimodal datasets are needed to allow comparison between systems, algorithms and modal combinations. to address this issue, we present a publicly available dataset for fall detection considering inertial measurement units (imus), ambient infrared presence/absence sensors, and an electroencephalogram helmet. it will allow human activity recognition researchers to do experiments considering different combination of sensors.",
            "contribution_ids": [
                "R178333"
            ]
        },
        {
            "instance_id": "EMPTYxR189637",
            "comparison_id": "EMPTY",
            "paper_id": "R189637",
            "text": "Human upper-body inverse kinematics for increased embodiment in consumer-grade virtual reality having a virtual body can increase embodiment in virtual reality (vr) applications. however, comsumer-grade vr falls short of delivering sufficient sensory information for full-body motion capture. consequently, most current vr applications do not even show arms, although they are often in the field of view. we address this shortcoming with a novel human upper-body inverse kinematics algorithm specifically targeted at tracking from head and hand sensors only. we present heuristics for elbow positioning depending on the shoulder-to-hand distance and for avoiding reaching unnatural joint limits. our results show that our method increases the accuracy compared to general inverse kinematics applied to human arms with the same tracking input. in a user study, participants preferred our method over displaying disembodied hands without arms, but also over a more expensive motion capture system. in particular, our study shows that virtual arms animated with our inverse kinematics system can be used for applications involving heavy arm movement. we demonstrate that our method can not only be used to increase embodiment, but can also support interaction involving arms or shoulders, such as holding up a shield.",
            "contribution_ids": [
                "R189639"
            ]
        },
        {
            "instance_id": "EMPTYxR189640",
            "comparison_id": "EMPTY",
            "paper_id": "R189640",
            "text": "Real-Time Inverse Kinematics Techniques for Anthropomorphic Limbs in this paper we develop a set of inverse kinematics algorithms suitable for an anthropomorphic arm or leg. we use a combination of analytical and numerical methods to solve generalized inverse kinematics problems including position, orientation, and aiming constraints. our combination of analytical and numerical methods results in faster and more reliable algorithms than conventional inverse jacobian and optimization-based techniques. additionally, unlike conventional numerical algorithms, our methods allow the user to interactively explore all possible solutions using an intuitive set of parameters that define the redundancy of the system.",
            "contribution_ids": [
                "R189642"
            ]
        },
        {
            "instance_id": "EMPTYxR191635",
            "comparison_id": "EMPTY",
            "paper_id": "R191635",
            "text": "A Full-Body Gesture Database for Automatic Gesture Recognition this paper presents a full-body gesture database which contains 2d video data and 3d motion data of 14 normal gestures, 10 abnormal gestures and 30 command gestures for 20 subjects. we call this database the korea university gesture (kug) database. using 3d motion cameras and 3 sets of stereo cameras, we captured 3d motion data and 3 pairs of stereo-video data at 3 different directions for normal and abnormal gestures. in case of command gestures, 2 pairs of stereo-video data is obtained by 2 sets of stereo cameras with different focal length in order to effectively capture views of whole body and upper body, simultaneously. in addition to these, the 2d silhouette data is synthesized by separating a subject and background in 2d stereo-video data and saved as binary mask images. in this paper, we describe the gesture capture system, the organization of database, the potential usages of the database and the way of obtaining the kug database",
            "contribution_ids": [
                "R191637"
            ]
        },
        {
            "instance_id": "EMPTYxR78224",
            "comparison_id": "EMPTY",
            "paper_id": "R78224",
            "text": "Assessment of Cadmium and Lead Distribution in the Outcrop Rocks of Abakaliki Anticlinorium in the Southern Benue Trough, Nigeria this study investigates the distribution of cadmium and lead concentrations in the outcrop rock samples collected from abakaliki anticlinorium in the southern benue trough, nigeria. the outcrop rock samples from seven sampling locations were air\u2013dried for seventy\u2013two hours, homogenized by grinding and pass through < 63 micron mesh sieve. the ground and homogenized rock samples were pulverized and analyzed for cadmium and lead using x-ray fluorescence spectrometer. the concentrations of heavy metals in the outcrop rock samples ranged from < 0.10 \u2013 7.95 mg kg\u20131 for cadmium (cd) and < 1.00 \u2013 4966.00 mg kg\u20131 for lead (pb). apart from an anomalous concentration measured in afikpo shale (middle segment), the results obtained revealed that rock samples from all the sampling locations yielded cadmium concentrations of < 0.10 mg kg\u20131 and the measured concentrations were below the average crustal abundance of 0.50 mg kg\u20131. although background concentration of <1.00 \u00b1 0.02 mg kg\u20131 was measured in abakaliki shale, rock samples from all the sampling locations revealed anomalous lead concentrations above average crustal abundance of 30 mg kg\u20131. the results obtained reveal important contributions towards understanding of heavy metal distribution patterns and provide baseline data that can be used for potential identification of areas at risk associated with natural sources of heavy metals contamination in the region. the use of outcrop rocks provides a cost\u2013effective approach for monitoring regional heavy metal contamination associated with dissolution and/or weathering of rocks or parent materials. evaluation of heavy metals may be effectively used in large scale regional pollution monitoring of soil, groundwater, atmospheric and marine environment. therefore, monitoring of heavy metal concentrations in soils, groundwater and atmospheric environment is imperative in order to prevent bioaccumulation in various ecological receptors.",
            "contribution_ids": [
                "R78226",
                "R78232",
                "R78235"
            ]
        },
        {
            "instance_id": "EMPTYxR78247",
            "comparison_id": "EMPTY",
            "paper_id": "R78247",
            "text": "An Ontology-Based Framework for Publishing and Exploiting Linked Open Data: A Use Case on Water Resources Management nowadays, the increasing demand of water for electricity production, agricultural and industrial uses are directly affecting the reduction of available quality water for human consumption in the world. efficient and sustainable maintenance of water reservoirs and supply networks implies a holistic strategy that takes into account, as much as possible, information from the stages of water usage. next,-generation decision-making software tools, for supporting water management, require the integration of multiple and heterogeneous data sources of different knowledge domains. in this regard, linked data and semantic web technologies enable harmonization of different data sources, as well as the efficient querying for feeding upper-level business intelligence processes. this work investigates the design, implementation and usage of a semantic approach driven by ontology to capture, store, integrate and exploit real-world data concerning water supply networks management. as a main contribution, the proposal helps with obtaining semantically enriched linked data, enhancing the analysis of water network performance. for validation purposes, in the use case, a series of data sources from different measures have been considered, in the scope of an actual water management system of the mediterranean region of valencia (spain), throughout several years of activity. the obtained experience shows the benefits of using the proposed approach to identify possible correlations between the measures such as the supplied water, the water leaks or the population.",
            "contribution_ids": [
                "R78249"
            ]
        },
        {
            "instance_id": "EMPTYxR78274",
            "comparison_id": "EMPTY",
            "paper_id": "R78274",
            "text": "Ontological requirement specification for smart irrigation systems: A SOSA/SSN and SAREF comparison precision agriculture is nowadays getting more and more attention in europe. due to the common water shortage problem, precision irrigation could become a key activity to save and use water in a more sustainable way. this paper builds upon an automatic irrigation system implemented as a context-aware system in which context is acquired thanks to a wireless sensor network. in such system, ontologies are used to solve integration problem of heterogeneous data provided by different types of sensors. moreover, ontologies enable reasoning over these data to enrich the context. the automatic irrigation system will be installed on the pilot site of irstea called agrotechnopole, located in montoldre. the main goal of this paper is to analyze the sosa/ssn and saref standard ontologies in regards to the ontological requirements that arise from the agrotechnopole use case.",
            "contribution_ids": [
                "R78276"
            ]
        },
        {
            "instance_id": "EMPTYxR69996",
            "comparison_id": "EMPTY",
            "paper_id": "R69996",
            "text": "Exploring the Evolution and Provenance of Git Versioned RDF Data the distributed character and the manifold possibilities for interchanging data on the web lead to the problem of getting hold of the provenance of the data. especially in the domain of digital humanities and when dealing with linked data in an enterprise context provenance information is needed to support the collaborative process of data management. we are proposing a possibility for capturing and exploring provenance information, based on the methodology of managing rdf data in a tool stack on top of the decentralized source code management system git. this comprises a queriable history graph, the possibility to query arbitrary revisions of a git versioned store and in the minimal granularity the possibility to annotate individual statements with their provenance information.",
            "contribution_ids": [
                "R69998"
            ]
        },
        {
            "instance_id": "EMPTYxR140145",
            "comparison_id": "EMPTY",
            "paper_id": "R140145",
            "text": "Assessment of Cities in Russia According to the Concept of \"Smart City\" in the Context of the Application of Information and Communication Technologies the article deals with the \"smart city\" concept, which is understood as such a model of the city, which provides, on the one hand, the sustainability of its development, and on the other - to stay in the comfort of its occupants. to analyze and assess the state of affairs, we have chosen one of the five \u201csmart city\u201d key elements, namely, the information-communication technologies including the following: new urban technologies, ict in education, ict in public health care, in electronic government and public services. the situation in three biggest volga federal region cities (kazan, samara and nizhniy novgorod) has been analyzed. recommendations on how to implement the \u201csmart city\u201d concept in other russia\u2019s cities are made. doi: 10.5901/mjss.2014.v5n18p55",
            "contribution_ids": [
                "R140146"
            ]
        },
        {
            "instance_id": "EMPTYxR140147",
            "comparison_id": "EMPTY",
            "paper_id": "R140147",
            "text": "The Role of Advanced Sensing in Smart Cities in a world where resources are scarce and urban areas consume the vast majority of these resources, it is vital to make cities greener and more sustainable. advanced systems to improve and automate processes within a city will play a leading role in smart cities. from smart design of buildings, which capture rain water for later use, to intelligent control systems, which can monitor infrastructures autonomously, the possible improvements enabled by sensing technologies are immense. ubiquitous sensing poses numerous challenges, which are of a technological or social nature. this paper presents an overview of the state of the art with regards to sensing in smart cities. topics include sensing applications in smart cities, sensing platforms and technical challenges associated with these technologies. in an effort to provide a holistic view of how sensing technologies play a role in smart cities, a range of applications and technical challenges associated with these applications are discussed. as some of these applications and technologies belong to different disciplines, the material presented in this paper attempts to bridge these to provide a broad overview, which can be of help to researchers and developers in understanding how advanced sensing can play a role in smart cities.",
            "contribution_ids": [
                "R140148"
            ]
        },
        {
            "instance_id": "EMPTYxR140151",
            "comparison_id": "EMPTY",
            "paper_id": "R140151",
            "text": "Smart cities as corporate storytelling \"on 4 november 2011, the trademark \u2018smarter cities\u2019 was officially registered as belonging to ibm. this was an important milestone in a struggle between it companies over visibility and legitimacy in the smart city market. drawing on actor-network theory and critical planning theory, the paper analyzes ibm's smarter city campaign and finds it to be storytelling, aimed at making the company an \u2018obligatory passage point\u2019 in the implementation of urban technologies. our argument unfolds in three parts. we first trace the emergence of the term \u2018smart city\u2019 in the public sphere. secondly, we show that ibm's influential story about smart cities is far from novel but rather mobilizes and revisits two long-standing tropes: systems thinking and utopianism. finally, we conclude, first by addressing two critical questions raised by this discourse: technocratic reductionism and the introduction of new moral imperatives in urban management; and second, by calling for the crafting of alternative smart city stories.\"",
            "contribution_ids": [
                "R140152"
            ]
        },
        {
            "instance_id": "EMPTYxR151147",
            "comparison_id": "EMPTY",
            "paper_id": "R151147",
            "text": "Open source software for disaster management evaluating how the sahana disaster information system coordinates disparate institutional and technical resources in the wake of the indian ocean tsunami.",
            "contribution_ids": [
                "R151148",
                "R152894",
                "R153017",
                "R153410",
                "R153514",
                "R153629",
                "R153830",
                "R155916",
                "R156022"
            ]
        },
        {
            "instance_id": "EMPTYxR151208",
            "comparison_id": "EMPTY",
            "paper_id": "R151208",
            "text": "Crisis Response Information Networks in the past two decades, organizational scholars have focused significant attention on how organizations manage crises. while most of these studies concentrate on crisis prevention, there is a growing emphasis on crisis response. because information that is critical to crisis response may become outdated as crisis conditions change, crisis response research recognizes that the management of information flows and networks is critical to crisis response. yet despite its importance, little is known about the various types of crisis information networks and the role of it in enabling these information networks. employing concepts from information flow and social network theories, this paper contributes to crisis management research by developing four crisis response information network prototypes. these networks are based on two main dimensions: (1) information flow intensity and (2) network density. we describe how considerations of these two dimensions with supporting case evidence yield four prototypical crisis information response networks: information star, information pyramid, information forest, and information black-out. in addition, we examine the role of it within each information network structure. we conclude with guidelines for managers to deploy appropriate information networks during crisis response and with suggestions for future research related to it and crisis management.",
            "contribution_ids": [
                "R151209",
                "R152929",
                "R153048",
                "R153441",
                "R153548",
                "R153662",
                "R153861",
                "R155948",
                "R156053"
            ]
        },
        {
            "instance_id": "EMPTYxR151306",
            "comparison_id": "EMPTY",
            "paper_id": "R151306",
            "text": "Effective Use of Mobile-Enabled Emergency Warning Systems effective warning can be life-saving in the event of an emergency. the pervasiveness of smartphones among the population affords public authorities a distributed network they can leverage for emergency notification. in germany, for instance, warning apps (e.g., nina, katwarn) are integrated within emergency warning systems (ews) authorities use for emergency communication. online reviews by users of two major warning apps, however, indicate the public is mildly unsatisfied with how they communicate emergency-related information. drawing on a representational perspective of information systems, we postulate that the intended use of ews is enabling the population to retrieve faithful digital representations of emergencies for informing protective counteractions. we test this theoretical claim by analyzing warning app online reviews and interviews with emergency management experts. in doing so, we identified 11 enabling dimensions of effective use of mobile-enabled warning systems. the dimensions constitute a model for studying the effective use of ews from a representational theory perspective. the a from an dimensions of representational fidelity: currency, completeness, exactitude, trust, and relevance.",
            "contribution_ids": [
                "R151307",
                "R152988",
                "R153097",
                "R153490",
                "R153607",
                "R153712",
                "R153910",
                "R155999",
                "R156100"
            ]
        },
        {
            "instance_id": "EMPTYxR153502",
            "comparison_id": "EMPTY",
            "paper_id": "R153502",
            "text": "THIS IS NOT A DRILL: Mobile Telephony, Information Verification, and Expressive Communication During Hawaii\u00e2\u0080\u0099s False Missile Alert on saturday, 13 january 2018, residents of hawaii received a chilling message through their smartphones. it read, in all caps, ballistic missile threat inbound to hawaii. seek immediate shelter. this is not a drill. the message was mistakenly sent, but many residents lived in a threatened state of mind for the 38\\u2009minutes it took before a retraction was made. this study is based on a survey of 418 people who experienced the alert, recollecting their immediate responses, including how they attempted to verify the alert and how they used their mobile devices and social media for expressive interactions during the alert period. with the ongoing testing in the united states of nationwide wireless emergency alerts, along with similar expansions of these systems in other countries, the event in hawaii serves to illuminate how people understand and respond to mobile-based alerts. it shows the extreme speed that information\u2014including misinformation\u2014can flow in an emergency, and, for many, expressive communication affects people\u2019s reactions.",
            "contribution_ids": [
                "R153503",
                "R153618",
                "R153723",
                "R153922",
                "R156011",
                "R156111"
            ]
        },
        {
            "instance_id": "EMPTYxR159632",
            "comparison_id": "EMPTY",
            "paper_id": "R159632",
            "text": "A multimedia computer supported cooperative work environment for requirements engineering the authors describe the architecture and the main features of a multimedia computer supported cooperative work environment (mcscwe) and its application in requirements engineering. the mcscwe has been utilized in several requirements engineering activities, and the use of the mcscwe in a case study conducted for the sacramento area council of governments (sacog) is presented. for the sacog case study, 85 participants were convened by sacog and divided into seven spatially distributed groups working on the same problem sets, i.e., the problem of coming up with a strategic plan to reduce congestion and meet clean air requirements as required by federal law. the results of the case study demonstrate that the mcscwe was effective and efficient in assisting this group to come to consensus on the issues and strategies necessary to achieve these goals. >",
            "contribution_ids": [
                "R159634"
            ]
        },
        {
            "instance_id": "EMPTYxR159642",
            "comparison_id": "EMPTY",
            "paper_id": "R159642",
            "text": "Requirements elicitation and validation with real world scenes a requirements specification defines the requirements for the future system at a conceptual level (i.e., class or type level). in contrast, a scenario represents a concrete example of current or future system usage. in early re phases, scenarios are used to support the definition of high level requirements (goals) to be achieved by the new system. in many cases, those goals can to a large degree be elicited by observing, documenting and analyzing scenarios about current system usage. to support the elicitation and validation of the goals achieved by the existing system and to illustrate problems of the old system, we propose to capture current system usage using rich media (e.g., video, speech, pictures, etc.) and to interrelate those observations with the goal definitions. thus, we aim at making the abstraction process which leads to the definition of the conceptual models more transparent and traceable. we relate the parts of the observations which have caused the definition of a goal or against which a goal was validated with the corresponding goal. these interrelations provide the basis for: 1) explaining and illustrating a goal model to, e.g., untrained stakeholders and/or new team members; 2) detecting, analyzing, and resolving a different interpretation of the observations; 3) comparing different observations using computed goal annotations; and 4) refining or detailing a goal model during later process phases. using the prime implementation framework, we have implemented the prime-crews environment, which supports the interrelation of conceptual models and captured system usage observations. we report on our experiences with prime-crews gained in an experimental case study.",
            "contribution_ids": [
                "R159644"
            ]
        },
        {
            "instance_id": "EMPTYxR159647",
            "comparison_id": "EMPTY",
            "paper_id": "R159647",
            "text": "Video brainstorming and prototyping: techniques for participatory design this tutorial is designed for hci designers and researchers interested in learning specific techniques for using video to support a range of participatory design activities. based on a combination of lectures, video demonstrations and hands-on exercises, the tutorial will give participants practical experience using video to observe users in laboratory and field settings, to analyze multimedia data, to explore and capture design ideas (video brainstorming), to simulate interaction techniques with users (wizard-of-oz and video prototyping) and to present video-based design ideas to users and managers. participants will gain experience shooting video and will address practical issues such as maintaining video archives and ethical issues such as obtaining informed consent. although these video techniques are applicable in a variety of design settings, the emphasis here is on participatory design, using video as a tool to help users, researchers and designers gather and communicate design ideas.",
            "contribution_ids": [
                "R159649"
            ]
        },
        {
            "instance_id": "EMPTYxR159675",
            "comparison_id": "EMPTY",
            "paper_id": "R159675",
            "text": "Applying a Video-based Requirements Engineering Technique to an Airport Scenario in the development of software-intensive systems, the interaction between customer and supplier is usually text-based. we argue that with agile project management gaining momentum, the inclusion of end-user feedback and a better mutual understanding between customer and supplier on hardware and software design goals becomes increasingly important. we propose the use of video techniques, video-based requirements engineering (vbre), to support the communication between all stakeholders. the key ingredients of vbre are user-centric videos and an exploratory environment for creating multi-path scenarios. in this workshop session, the participants will get hands-on experience with vbre techniques and tools while working on a fictitious airport baggage handling system.",
            "contribution_ids": [
                "R159677"
            ]
        },
        {
            "instance_id": "EMPTYxR159686",
            "comparison_id": "EMPTY",
            "paper_id": "R159686",
            "text": "Contravision: exploring users' reactions to futuristic technology \"how can we best explore the range of users' reactions when developing future technologies that may be controversial, such as personal healthcare systems? our approach -- contravision -- uses futuristic videos, or other narrative forms, that convey either negative or positive aspects of the proposed technology for the same scenarios. we conducted a user study to investigate what range of responses the different versions elicited. our findings show that the use of two systematically comparable representations of the same technology can elicit a wider spectrum of reactions than a single representation can. we discuss why this is so and the value of obtaining breadth in user feedback for potentially controversial technologies.\"",
            "contribution_ids": [
                "R159688"
            ]
        },
        {
            "instance_id": "EMPTYxR159690",
            "comparison_id": "EMPTY",
            "paper_id": "R159690",
            "text": "Focusing spontaneous feedback to support system evolution modern software systems are rarely built from scratch. they rather evolve over a long period of time while components and subsystems are developed independently. during that evolution, new and changing requirements emerge when end-users interact with the system. users encounter situations that provoke spontaneous complaints or suggestions, which may be the seed of new requirements. however, there are two challenges: how to capture spontaneous reactions and how to focus and let them mature into valid requirements? we propose concepts that enable citizens to report a problem or make a suggestion by smartphone. a key for preserving the spontaneous impetus is to lower the threshold for composing and sending feedback. software providers who are interested in feedback can define filtering and focusing aids; they guide end-users in giving focused feedback. focused feedback is also better prepared to be transformed to requirements. our con-texter tool demonstrates technical feasibility of these concepts. we explore and characterize a potential application domain empirically. based on the findings, we discuss potentials and limitations of our approach.",
            "contribution_ids": [
                "R159692"
            ]
        },
        {
            "instance_id": "EMPTYxR159774",
            "comparison_id": "EMPTY",
            "paper_id": "R159774",
            "text": "Reframing Societal Discourse as Requirements Negotiation: Vision Statement challenges in spatial planning include adjusting settlement patterns to increasing or shrinking populations; it also includes organizing food delivery in rural and peripheral environments. discourse typically starts with an open problem and the search for a holistic and innovative solution. software will often be needed to implement the innovation. spatial planning problems are characterized by large and heterogeneous groups of stakeholders, such as municipalities, companies, interest groups, citizens, women and men, young people and children. current techniques for participation are slow, laborious and costly, and they tend to miss out on many stakeholders or interest groups.we propose a triple shift in perspective: (1) discourse is reframed as a requirements process with the explicit goal to state software, hardware, and organizational requirements. (2) due to the above-mentioned characteristics of spatial planning problems, we suggest using techniques of requirements engineering (re) and crowdre for getting stakeholders (e.g. user groups) involved. (3) we propose video as a medium for communicating problems, solution alternatives, and arguments effectively within a mixed crowd of officials, citizens, children and elderly people.although few spatial planning problems can be solved by software alone, this new perspective helps to focus discussions anyway. re techniques can assist in finding common ground despite the heterogeneous group of stakeholders, e.g. citizens. digital requirements and video are well-suited for facilitating distribution, feedback, and discourse via the internet. in this paper, we propose this new perspective as a timely opportunity for the spatial planning domain \u2013 and as an increasingly important application domain of crowdre.",
            "contribution_ids": [
                "R159776"
            ]
        },
        {
            "instance_id": "EMPTYxR159798",
            "comparison_id": "EMPTY",
            "paper_id": "R159798",
            "text": "Keep Your Stakeholders Engaged: Interactive Vision Videos in Requirements Engineering one of the most important issues in requirements engineering (re) is the alignment of stakeholders\u2019 mental models. making sure that all stakeholders share the same vision of a changing system is crucial to the success of any project. misaligned mental models of stakeholders can lead to conflicting requirements. a promising approach to this problem is the use of video showing a system vision, so-called vision videos, which help stakeholders to disclose, discuss, and align their mental models of the future system. however, videos have the drawback of allowing viewers to adopt a passive role, as has been shown in research on e-learning. in this role, viewers tend to be inactive, unfocused and bored while watching a video. in this paper, we learn and adopt findings from scientific literature in the field of e-learning on how to mitigate this passive role while watching vision videos in requirements engineering. in this way, we developed concepts that incorporate interactive elements into vision videos to help viewers stay focused. these elements include questions that are asked during the video and ways for viewers to decide what happens next in the video. in a preliminary evaluation with twelve participants, we found statistically significant differences when comparing the interactive vision videos with their traditional form. using an interactive vision videos, viewers are noticeably more engaged and gather more information on the shown system.",
            "contribution_ids": [
                "R159800"
            ]
        },
        {
            "instance_id": "EMPTYxR159971",
            "comparison_id": "EMPTY",
            "paper_id": "R159971",
            "text": "Fabrication of polycrystalline 3C-SiC micro pressure sensors for hightemperature applications high temperature micro pressure sensors were fabricated by using polycrystalline 3c-sic piezoresistors grown on oxidized soi substrates by apcvd. these have been made by bulk micromachining under diaphragm and si membrane thickness of . the pressure sensitivity of implemented pressure sensors was 0.1 mv/. the nonlinearity and the hysteresis of sensors were and . in the temperature range of with 5 bar fs, tcs (temperature coefficient of sensitivity), tcr (temperature coefficient of resistance), and tcgf (temperature coefficient of gauge factor) of the sensor were -1867 ppm/, -792 ppm/, and -1042 ppm/, respectively.",
            "contribution_ids": [
                "R159973"
            ]
        },
        {
            "instance_id": "EMPTYxR159975",
            "comparison_id": "EMPTY",
            "paper_id": "R159975",
            "text": "Improved reliability of SiC pressure sensors for long term high temperature applications we report advancement in the reliability of silicon carbide pressure sensors operating at 600 \u00b0c for extended periods. the large temporal drifts in zero pressure offset voltage at 600 \u00b0c observed previously were significantly suppressed to allow improved reliable operation. this improvement was the result of further enhancement of the electrical and mechanical integrity of the bondpad/contact metallization, and the introduction of studded bump bonding on the pad. the stud bump contact promoted strong adhesion between the au bond pad and the au die-attach. the changes in the zero offset voltage and bridge resistance over time at temperature were explained by the microstructure and phase changes within the contact metallization, that were analyzed with auger electron spectroscopy (aes) and field emission scanning electron microscopy (fe-sem).",
            "contribution_ids": [
                "R159977"
            ]
        },
        {
            "instance_id": "EMPTYxR159984",
            "comparison_id": "EMPTY",
            "paper_id": "R159984",
            "text": "4H-SiC Piezoresistive Pressure Sensors at 800 \u00c2\u00b0C With Observed Sensitivity Recovery uncooled mems-based 4h-sic wheatstone bridge configured piezoresistive pressure sensors were demonstrated from 23 \u00b0c to 800 \u00b0c. the full-scale output (fso) voltage exhibited gradual decrease with increasing temperature from 23 \u00b0c to 400 \u00b0c, then swung upward as temperature increased further to where the values measured at 800 \u00b0c were nearly equal to or higher than the room temperature values. this newly observed fso behavior in 4h-sic contrasts sharply with the fso behavior of silicon piezoresistive sensors that decrease continuously with increasing temperature. the increase in the sensor output sensitivity at 800 \u00b0c implies higher signal to noise ratio and improved fidelity, thereby offering promise of further insertion into >600 \u00b0c environments without the need for cooling and complex signal conditioning.",
            "contribution_ids": [
                "R159986"
            ]
        },
        {
            "instance_id": "EMPTYxR160015",
            "comparison_id": "EMPTY",
            "paper_id": "R160015",
            "text": "Demonstration of SiC Pressure Sensors at 750 \u00c2\u00b0C we report the first demonstration of mems-based 4h-sic piezoresistive pressure sensors tested at 750 \u00b0c and in the process confirmed the existence of strain sensitivity recovery with increasing temperature above 400 \u00b0c, eventually achieving near or up to 100 % of the room temperature values at 750 \u00b0c. this strain sensitivity recovery phenomenon in 4h-sic is uncharacteristic of the well-known monotonic decrease in strain sensitivity with increasing temperature in silicon piezoresistors. for the three sensors tested, the room temperature full-scale output (fso) at 200 psig ranged between 29 and 36 mv. although the fso at 400 \u00b0c dropped by about 60 %, full recovery was achieved at 750 \u00b0c. this result will allow the operation of sic pressure sensors at higher temperatures, thereby permitting deeper insertion into the engine combustion chamber to improve the accurate quantification of combustor dynamics.",
            "contribution_ids": [
                "R160017"
            ]
        },
        {
            "instance_id": "EMPTYxR160019",
            "comparison_id": "EMPTY",
            "paper_id": "R160019",
            "text": "Design of SiC-Doped Piezoresistive Pressure Sensor for High-Temperature Applications within these studies the piezoresistive effect was analyzed for 6h-sic and 4h-sic material doped with various elements: n, b, and sc. bulk sic crystals with a specific concentration of dopants were fabricated by the physical vapor transport (pvt) technique. for such materials, the structures and properties were analyzed using x-ray diffraction, sem, and hall measurements. the samples in the form of a beam were also prepared and strained (bent) to measure the resistance change (gauge factor). based on the results obtained for bulk materials, piezoresistive thin films on 6h-sic and 4h-sic substrate were fabricated by chemical vapor deposition (cvd). such materials were shaped by focus ion beam (fib) into pressure sensors with a specific geometry. the characteristics of the sensors made from different materials under a range of pressures and temperatures were obtained and are presented herewith.",
            "contribution_ids": [
                "R160023"
            ]
        },
        {
            "instance_id": "EMPTYxR160025",
            "comparison_id": "EMPTY",
            "paper_id": "R160025",
            "text": "Toward a Self-Sensing Piezoresistive Pressure Sensor for All-SiC Monolithic Integration this work focusses on the design and fabrication of surface micromachined pressure sensors, designed in a modular way for the integration with analog front-end read-out electronics. polycrystalline 3c silicon carbide (sic) was used to fabricate free-standing high topography cavities exploiting surface micromaching. the poly-sic was in-situ doped and the membrane itself is used as piezoresistive element, thereby forming a so-called self-sensing membrane, easing fabrication. after sacrificial release, the cavity is sealed by conformal deposition of poly-sic whereby the reference pressure of the absolute pressure sensor is determined. aluminum and titanium metallizations were used and ohmic contacts were confirmed by wafer-scale measurements. measurements were carried out on different devices ranging from 100 kpa down to 10 pa at room temperature. the wheatstone bridge yields a logarithmic response of 1.1 mvbar $^{-}1\\\\text{v}^{-}1$ . a square 300 $\\\\mu \\\\text{m}$ device exhibits a logarithmic impedance behavior yielding a response of $\\\\delta {r} / {r}$ of $1.6\\\\times 10^{-3}$ bar $^{-1}$ . the realized pressure devices are a first step toward a sic asic + mems platform for intended operation in harsh environments, such as industrial process monitoring, combustion control or structural health monitoring. the future outlook of the integration concept implies extended functionality by front-end transducer read-out, signal amplification and communication.",
            "contribution_ids": [
                "R160030"
            ]
        },
        {
            "instance_id": "EMPTYxR160032",
            "comparison_id": "EMPTY",
            "paper_id": "R160032",
            "text": "Fabrication of SiC Sealing Cavity Structure for All-SiC Piezoresistive Pressure Sensor Applications high hardness and corrosion resistance of sic (silicon carbide) bulk materials have always been a difficult problem in the processing of an all-sic piezoresistive pressure sensor. in this work, we demonstrated a sic sealing cavity structure utilizing sic shallow plasma-etched process (\u226420 \u03bcm) and sic\u2013sic room temperature bonding technology. the sic bonding interface was closely connected, and its average tensile strength could reach 6.71 mpa. in addition, through a rapid thermal annealing (rta) experiment of 1 min and 10 mins in n2 atmosphere of 1000 \u00b0c, it was found that si, c and o elements at the bonding interface were diffused, while the width of the intermediate interface layer was narrowed, and the tensile strength could remain stable. this sic sealing cavity structure has important application value in the realization of an all-sic piezoresistive pressure sensor.",
            "contribution_ids": [
                "R160035"
            ]
        },
        {
            "instance_id": "EMPTYxR160105",
            "comparison_id": "EMPTY",
            "paper_id": "R160105",
            "text": "High temperature SiC pressure sensors with low offset voltage shift very low (~0.125 mv) shifts in offset voltage were achieved in silicon carbide (sic) piezoresistive pressure sensors during thermal cycling between 25 and 500 \u00b0c for 500 hours. it resulted in reduced measurement error to ~ 0.36 % and ~ 0.9 % of the full-scale output at 25 and 500 \u00b0c, respectively. the reduction in the offset shift was the result of the advancement made in controlling the intermetallic diffusion and microstructural phase changes within the contact metallization. the low offset voltage results provide critical figures of merit needed for quantifying the measurement error and correction when the sic pressure sensors are used. the results demonstrate more robust and reliable sic pressure sensors operating with significantly reduced fso errors at 500 \u00b0c.",
            "contribution_ids": [
                "R160107"
            ]
        },
        {
            "instance_id": "EMPTYxR161439",
            "comparison_id": "EMPTY",
            "paper_id": "R161439",
            "text": "Atomic Layer Deposition of Ta-doped TiO2 Electrodes for Dye-Sensitized Solar Cells ta-doped tio 2 inverse opals were obtained by selective etching of a silica template after atomic layer deposition (ald) of ta-doped tio 2 films and were applied as an electrode for dye-sensitized solar cells (dsscs). ta content in the ta-doped tio 2 film was controlled by the ta/(ta+ti) unitcycle ratios in the ta\u2015tio 2 supercycle of ald. also, excellent step coverage of nearly 100% in the inverse opal structure was confirmed by field-emission scanning electron microscopy (fe-sem). maximum photo-conversion efficiency of 1.56% was achieved with the ta (3.4 atom %)-doped tio 2 inverse opal electrode due to increased photocurrent density. however, further ta doping (> 4.9 atom %) decreased the j sc and photoconversion efficiency.",
            "contribution_ids": [
                "R161441"
            ]
        },
        {
            "instance_id": "EMPTYxR161446",
            "comparison_id": "EMPTY",
            "paper_id": "R161446",
            "text": "TiO2inverse-opal electrode fabricated by atomic layer deposition for dye-sensitized solar cell applications tio2 inverse opals (tio) fabricated by the atomic layer deposition (ald) technique showed a superior infiltration result when compared to those fabricated by the conventional nanoparticles-infiltration method reported in previous studies. the ald can achieve high filling fractions of more than ca. 96% of the maximum possible infiltration by conformal filling of 288, 390 and 510 nm opals, giving rise to high quality tio. the photoelectrochemical performances of the ald-fabricated tio photoanodes of different sizes are investigated systematically for the first time in dye-sensitized solar cells (dscs). when the tio with a size of 288 nm was used as photoanode and indoline dye as a sensitizer in dscs, the power conversion efficiency of the cell could attain 2.22% (air mass 1.5). it is found that the efficiency increases with decreasing lattice size of tio electrode due to the larger surface area for dye loading. owing to the selective reflectivity of the inverse opal, ipce spectra of tio electrodes revealed a strong wavelength dependence. strategies relating to the characteristics of selective reflection and the design of composite photoanodes to enhance the efficiency of dscs are discussed.",
            "contribution_ids": [
                "R161448"
            ]
        },
        {
            "instance_id": "EMPTYxR161453",
            "comparison_id": "EMPTY",
            "paper_id": "R161453",
            "text": "Atomic Layer Deposition of TiO2 on Mesoporous nanoITO: Conductive Core\u00e2\u0080\u0093Shell Photoanodes for Dye-Sensitized Solar Cells core-shell structures consisting of thin shells of conformal tio2 deposited on high surface area, conductive sn-doped in2o3 nanoparticle. mesoscopic films were synthesized by atomic layer deposition and studied for application in dye-sensitized solar cells. results obtained with the n719 dye show that short-circuit current densities, open-circuit voltages, and back electron transfer lifetimes all increased with increasing tio2 shell thickness up to 1.8-2.4 nm and then decline as the thickness was increased further. at higher shell thicknesses, back electron transfer to -ru(iii) is increasingly competitive with transport to the nanoito core resulting in decreased device efficiencies.",
            "contribution_ids": [
                "R161455"
            ]
        },
        {
            "instance_id": "EMPTYxR161648",
            "comparison_id": "EMPTY",
            "paper_id": "R161648",
            "text": "Charm and beauty in the deconfined plasma from quenched lattice QCD we present continuum extrapolated results of charmonium and bottomonium correlators in the vector channel at several temperatures below and above tc. the continuum extrapolation jointly performed with the interpolations to have physical values of j/\u03c8 and \u03c5 masses in the confined phase is based on calculations on several large quenched isotropic lattices using clover-improved wilson valence fermions carrying different quark masses. the extrapolated lattice correlators are confronted with perturbation theory results incorporating resummed thermal effects around the threshold from pnrqcd and vacuum asymptotics above the threshold. an additional transport peak is modelled below the threshold allowing for an estimate of the diffusion coefficients for charm and bottom quarks. we find that charmonium correlators in the vector channel can be well reproduced by perturbative spectral functions above tc where no resonance peaks for j/\u03c8 are needed at and above 1.1 tc, while for bottomonium correlators a resonance peak for \u03c5 is still needed up to 1.5 tc. by analyzing the transport contribution to the correlators we find that the drag coefficient of a charm quark is larger than that of a bottom quark.",
            "contribution_ids": [
                "R161654"
            ]
        },
        {
            "instance_id": "EMPTYxR166697",
            "comparison_id": "EMPTY",
            "paper_id": "R166697",
            "text": "Factors affecting conference participation decision-making \"business travel, as the sector with the fastest growth in the tourism industry globally, has received increased attention from both countries and cities, particularly from emerging destinations. in developing economies, business travel, including attending meetings, conferences, incentives and other business events, often plays a leading role in the growth of the wider travel and tourism sector. therefore, tourism authorities and convention bureaus at the national and city levels have been struggling to attract international conferences and a larger number of participants to conferences. understanding factors, which appear to be important in the conference participation decision-making process, can help conference organizers and destinations to attract more participants and thus gain more benefit from this growing sector of the tourism industry. therefore, this study aims to examine factors affecting the conference participation decision-making from the academics' perspective. furthermore, it investigates how different socio-demographic characteristics of the respondents influence the extracted factors of the conference participation decision-making process. the data was collected from the academics employed at the university of novi sad in serbia. the findings reveal six dimensions of conference participation decision-making: destination stimuli, costs and destination accessibility, educational and professional opportunities, intervening opportunities, location factors, and conference factors. the results also show that there are statistically significant differences in some extracted factors between respondents of different gender, age, education level, and academic position, while the frequency of participation in international conferences does not influence the factors. the results could be of interest to all stakeholders in the business travel and tourism industry.\"",
            "contribution_ids": [
                "R166699"
            ]
        },
        {
            "instance_id": "EMPTYxR108390",
            "comparison_id": "EMPTY",
            "paper_id": "R108390",
            "text": "A novel method for calibrating head models to account for variability in conductivity and its evaluation in a sphere model the accuracy in electroencephalography (eeg) and combined eeg and magnetoencephalography (meg) source reconstructions as well as in optimized transcranial electric stimulation (tes) depends on the conductive properties assigned to the head model, and most importantly on individual skull conductivity. in this study, we present an automatic pipeline to calibrate head models with respect to skull conductivity based on the reconstruction of the p20/n20 response using somatosensory evoked potentials and fields. in order to validate in a well-controlled setup without interplay with numerical errors, we evaluate the accuracy of this algorithm in a 4-layer spherical head model using realistic noise levels as well as dipole sources at different eccentricities with strengths and orientations related to somatosensory experiments. our results show that the reference skull conductivity can be reliably reconstructed for sources resembling the generator of the p20/n20 response. in case of erroneous assumptions on scalp conductivity, the resulting skull conductivity parameter counterbalances this effect, so that eeg source reconstructions using the fitted skull conductivity parameter result in lower errors than when using the standard value. we propose an automatized procedure to calibrate head models which only relies on non-invasive modalities that are available in a standard meg laboratory, measures under in vivo conditions and in the low frequency range of interest. calibrated head modeling can improve eeg and combined eeg/meg source analysis as well as optimized tes.",
            "contribution_ids": [
                "R108391"
            ]
        },
        {
            "instance_id": "EMPTYxR108404",
            "comparison_id": "EMPTY",
            "paper_id": "R108404",
            "text": "Lung Tissue Evaluation Detecting and Measuring Morphological Characteristics of Cell Regions the goal of this study is to develop an automated, accurate and time efficient image processing algorithmic scheme, capable of segmenting lung tissue slides and quantitatively detecting any possible morphological characteristic that may differentiate healthy cells from adenocarcinoma. microscopy images are segmented into the key regions via a proposed clever, sequential fusion methodology, combining image clustering, the watershed transform and mathematical morphology and analyzed utilizing an innovative tissue evaluation approach based on quantitative assessments of the extracted cell regions shape and size. the preliminary results of this work indicate that it is possible to discriminate healthy cells from cancerous ones considering their overall morphology within the tissue and measuring possible indices that may reveal an evolving neoplasia, a tumor growth or a malfunction in cell proliferation. applying the proposed method to a much larger and more variform dataset is our next plan for the upcoming future in order to validate and ensure the robustness and accuracy of the proposed classification scheme, making it an extremely valuable assisting tool for medical experts for cancer diagnosis and prognosis.",
            "contribution_ids": [
                "R108405"
            ]
        },
        {
            "instance_id": "EMPTYxR108406",
            "comparison_id": "EMPTY",
            "paper_id": "R108406",
            "text": "Mining Cross-Frequency Coupling Microstates from Resting State MEG: An Application to Mild Traumatic Brain Injury recent studies have investigated the possible role of dynamic functional connectivity and the role of cross-frequency coupling (cfc) to provide the substrate for reliable biomarkers of brain disorders. in this study, we analyzed time-varying cfc profiles from resting state magnetoencephal-ographic recordings of 30 mild traumatic brain injury (mtbi) patients and 50 normal controls. interactions among sensors at specific pairs of frequency bands were computed via estimation of phase-to-amplitude couplings. we then computed time-varying functional connectivity graphs that were described in terms of segregation (local efficiency, le) and integration (global efficiency, ge) and mapped those graphs to time series of ge/le estimates. the resulting dynamic network revealed transitions between a limited number of microstates for mtbi subjects compared to controls. the significant differences in transition probability between the two groups, along with the limited repertoire of possible states, can form the basis for a robust dynamic connectomic biomarker for the diagnosis of mtbi.",
            "contribution_ids": [
                "R108407"
            ]
        },
        {
            "instance_id": "EMPTYxR108422",
            "comparison_id": "EMPTY",
            "paper_id": "R108422",
            "text": "Constrained maximum intensity optimized multi-electrode tDCS targeting of human somatosensory network transcranial direct current stimulation (tdcs) is a noninvasive method that delivers current through the scalp to enhance or suppress brain activity. the standard way of applying tdcs is by the use of two large rectangular sponge electrodes on the scalp. the resulting currents often stimulate a broad region of the brain distributed over brain networks. in order to address this issue, recently, multi-electrode transcranial direct current stimulation with optimized montages has been used to stimulate brain regions of interest (roi) with improved trade-off between focality and intensity of the electrical current at the target brain region. however, in many cases only the location of target region is considered and not the orientation. here we emphasize the importance of calculating the individualized target location and orientation by combined electroencephalography and magnetoencephalography (emeg) source analysis in individualized skull-conductivity calibrated finite element method (fem) head models and stimulate the target region by four different tdcs montages. we have chosen the generator of the p20/n20 component, located at brodmann area 3b and oriented mainly from posterior to anterior directions as our target for stimulation because it can be modeled as a single dipole source with a fixed position and orientation. the simulations will deliver optimized excitatory and inhibitory electrode montages that are in future investigations compared to standard and sham tdcs in a somatosensory experiment. we also present a new constrained maximum intensity (cmi) optimization approach that better distributes the currents over multiple electrodes, therefore should lead to less tingling and burning sensations at the skin, and thus allows an easier realization of the sham condition significantly reducing the current intensity parallel to the target.",
            "contribution_ids": [
                "R108423"
            ]
        },
        {
            "instance_id": "EMPTYxR108458",
            "comparison_id": "EMPTY",
            "paper_id": "R108458",
            "text": "Dynamic Proofs of Retrievability with Low Server Storage proofs of retrievability (pors) are protocols which allow a client to store data remotely and to efficiently ensure, via audits, that the entirety of that data is still intact. a dynamic por system also supports efficient retrieval and update of any small portion of the data. we propose new, simple protocols for dynamic por that are designed for practical efficiency, trading decreased persistent storage for increased server computation, and show in fact that this tradeoff is inherent via a lower bound proof of time-space for any por scheme. notably, ours is the first dynamic por which does not require any special encoding of the data stored on the server, meaning it can be trivially composed with any database service or with existing techniques for encryption or redundancy. our implementation and deployment on google cloud platform demonstrates our solution is scalable: for example, auditing a 1tb file takes 16 minutes at a monetary cost of just $0.23 usd. we also present several further enhancements, reducing the amount of client storage, or the communication bandwidth, or allowing public verifiability, wherein any untrusted third party may conduct an audit.",
            "contribution_ids": [
                "R108459"
            ]
        },
        {
            "instance_id": "EMPTYxR108464",
            "comparison_id": "EMPTY",
            "paper_id": "R108464",
            "text": "Proofs of Retrievability: Theory and Implementation \"a proof of retrievability (por) is a compact proof by a file system (prover) to a client (verifier) that a target file f is intact, in the sense that the client can fully recover it. as pors incur lower communication complexity than transmission of f itself, they are an attractive building block for high-assurance remote storage systems.\\n in this paper, we propose a theoretical framework for the design of pors. our framework improves the previously proposed por constructions of juels-kaliski and shacham-waters, and also sheds light on the conceptual limitations of previous theoretical models for pors. it supports a fully byzantine adversarial model, carrying only the restriction---fundamental to all pors---that the adversary's error rate be bounded when the client seeks to extract f. we propose a new variant on the juels-kaliski protocol and describe a prototype implementation. we demonstrate practical encoding even for files f whose size exceeds that of client main memory.\"",
            "contribution_ids": [
                "R108465"
            ]
        },
        {
            "instance_id": "EMPTYxR108468",
            "comparison_id": "EMPTY",
            "paper_id": "R108468",
            "text": "BOSSA: A Decentralized System for Proofs of Data Retrievability and Replication proofs of retrievability and proofs of replication are two cryptographic tools that enable a remote server to prove that the users\u2019 data has been correctly stored. nevertheless, the literature either requires the users themselves to perform expensive verification jobs, or relies on a \u201cfully trustworthy\u201d third party auditor (tpa) to execute the public verification. in addition, none of existing solutions consider the underlying incentive issues behind a rational server who is motivated to collect users\u2019 data but tries to evade the replication checking in order to save storage resources. in this article, we propose the first decentralized system for proofs of data retrievability and replication\u2014 ${\\\\sf bossa}$ bossa , which is incentive-compatible for each party and realizes automated auditing atop off-the-shelf blockchain platforms. we deal with issues such as proof enforcements to catch malicious behaviors, new metrics to measure the contributions, and reward distributions to create a fair reciprocal environment. ${\\\\sf bossa}$ bossa also incorporates privacy-enhancing techniques to prevent decentralized peers (including blockchain nodes) from inferring private information about the outsourced data. security analysis is presented in the context of integrity, privacy, and reliability. we implement a prototype based on ${\\\\sf bossa}$ bossa leveraging the smart contracts of ethereum blockchain. our extensive experimental evaluations demonstrate the practicality of our proposal.",
            "contribution_ids": [
                "R108469"
            ]
        },
        {
            "instance_id": "EMPTYxR108472",
            "comparison_id": "EMPTY",
            "paper_id": "R108472",
            "text": "PoReps: Proofs of Space on Useful Data a proof-of-replication (porep) is an interactive proof system in which a prover defends a publicly verifiable claim that it is dedicating unique resources to storing one or more retrievable replicas of a data file. in this sense a porep is both a proof of space (pos) and a proof of retrievability (por). this paper establishes a foundation for poreps, exploring both their capabilities and their limitations. while poreps may unconditionally demonstrate possession of data, they fundamentally cannot guarantee that the data is stored redundantly. furthermore, as poreps are proofs of space, they must rely either on rational time/space tradeoffs or timing bounds on the online prover\u2019s runtime. we introduce a rational security notion for poreps called -rational replication based on the notion of an -nash equilibrium, which captures the property that a server does not gain any significant advantage by storing its data in any other (non-redundant) format. we apply our definitions to formally analyze two recently proposed porep constructions based on verifiable delay functions and depth robust graphs. lastly, we reflect on a notable application of poreps\u2014its unique suitability as a nakamoto consensus mechanism that replaces proof-of-work with poreps on real data, simultaneously incentivizing and subsidizing the cost of file storage.",
            "contribution_ids": [
                "R108473"
            ]
        },
        {
            "instance_id": "EMPTYxR108480",
            "comparison_id": "EMPTY",
            "paper_id": "R108480",
            "text": "Homomorphic Authentication Scheme for Proof of Retrievability with Public Verifiability cloud storages are the cloud computing model that stores, manages, and operates data storage as a service. these are widely used nowadays and are being adopted by many organizations or individuals. the ease of using cloud storage is that the users can upload the data in remote cloud storage and can be accessed by any device through the internet. these cloud storage are managed by cloud service providers. despite having benefits, users don\u2019t get physical access to the servers that store their data. thus, users need some integrity verification techniques that confirm that data stored in the data center is intact. this paper presents the public verifiability service that provides integrity verification of data placed in the cloud. the proposed system is built on pseudorandom functions (prfs) which rely on homomorphic linear property. we also considered the third party auditor (tpa) to confirm the integrity of cloud data through auditing. our experimental study shows that the proposed method is provably secure.",
            "contribution_ids": [
                "R108481"
            ]
        },
        {
            "instance_id": "EMPTYxR108494",
            "comparison_id": "EMPTY",
            "paper_id": "R108494",
            "text": "Dynamic Outsourced Proofs of Retrievability Enabling Auditing Migration for Remote Storage Security remote data auditing service is important for mobile clients to guarantee the intactness of their outsourced data stored at cloud side. to relieve mobile client from the nonnegligible burden incurred by performing the frequent data auditing, more and more literatures propose that the execution of such data auditing should be migrated from mobile client to third-party auditor (tpa). however, existing public auditing schemes always assume that tpa is reliable, which is the potential risk for outsourced data security. although outsourced proofs of retrievability (opor) have been proposed to further protect against the malicious tpa and collusion among any two entities, the original opor scheme applies only to the static data, which is the limitation that should be solved for enabling data dynamics. in this paper, we design a novel authenticated data structure called bv23tree, which enables client to batch-verify the indices and values of any number of appointed leaves all at once for efficiency. by utilizing bv23tree and a hierarchical storage structure, we present the first solution for dynamic opor (dopor), which extends the opor model to support dynamic updates of the outsourced data. extensive security and performance analyses show the reliability and effectiveness of our proposed scheme.",
            "contribution_ids": [
                "R108495"
            ]
        },
        {
            "instance_id": "EMPTYxR108496",
            "comparison_id": "EMPTY",
            "paper_id": "R108496",
            "text": "Dynamic Proofs of Retrievability for Coded Cloud Storage Systems cloud storage allows users to store their data in a remote server to get rid of expensive local storage and management costs and then access data of interest anytime anywhere. a number of solutions have been proposed to tackle the verification of remote data integrity and retrievability in cloud storage systems. most of existing schemes, however, do not support efficient data dynamics and/or suffer from security vulnerabilities when involving dynamic data operations. in this paper, we propose a dynamic proof of retrievability scheme supporting public auditability and communication-efficient recovery from data corruptions. to this end, we split up the data into data blocks and encode each data block individually using outer code and inner code before outsourcing so that i) an update inside any data block only affects a few codeword symbols and ii) communication-efficient data repair for a breakdown server can be achieved and communication overhead for small data corruptions within a server can be eliminated. based on the encoded data blocks, we utilize rb23tree to enforce the data sequence for dynamic operations, preventing the cloud service provider from manipulating data block to pass the integrity check in the dynamic scenario. formal security analysis and extensive experimental evaluations are conducted, showing that the proposed scheme is practical for use in cloud storage systems.",
            "contribution_ids": [
                "R108497"
            ]
        },
        {
            "instance_id": "EMPTYxR108505",
            "comparison_id": "EMPTY",
            "paper_id": "R108505",
            "text": "Proof of Retrievability with Efficient Verification the computationally sound proof (cs proof) is a proof system which reduces the verifier\u2019s computation to a level polylogarithmic in that of accepting. if used in cloud computing, cs proof will significantly reduce computation of the client whose computation resources are much more limited than that of the cloud server. we are the first to introduce cs proof belonging to complexity theory into cloud computing, where a protocol for data integrity verification is proposed to reduce the customer\u2019s computation. concretely, the customer\u2019s computation is only poly-logarithmic in that of the traditional protocols. however, in our opinion, the significance of this study is not the improved efficiency, but that we introduce a new way to achieve integrity verification. the proposed protocol supports public verification even without the customer\u2019s public key and satisfies the security against semi-honest adversaries. the customer\u2019s privacy holds against both the cloud and the third-party verifier. the proposed protocol can be considered as a proper application of cs proof to integrity verification in cloud computing.",
            "contribution_ids": [
                "R108506"
            ]
        },
        {
            "instance_id": "EMPTYxR108509",
            "comparison_id": "EMPTY",
            "paper_id": "R108509",
            "text": "SW-POR: A Novel POR Scheme Using Slepian-Wolf Coding for Cloud Storage cloud computing is a service by which the clients can outsource their data to the cloud storage server to deal with the local storage limitation. however, the cloud storage providers are untrustworthy, which can lead to several security challenges, such as data availability, data integrity, and data confidentiality. to mitigate the issues of data availability and data integrity, a novel slepian-wolf-based proof of retrievability (sw-por) scheme is proposed to enable the client to check whether the distributed data stored in the cloud servers is intact or not. the proposed sw-por scheme not only can obtain an optimal coded block size, but also it can provide the exact-repair feature and low complexity. in this paper, the security analysis and efficiency analysis are provided. simulation results show that the sw-por scheme can accomplish a significant improvement in computation time.",
            "contribution_ids": [
                "R108510"
            ]
        },
        {
            "instance_id": "EMPTYxR108513",
            "comparison_id": "EMPTY",
            "paper_id": "R108513",
            "text": "Towards Efficient Provable Data Possession in Cloud Storage provable data possession (pdp) allows data owner to periodically and remotely audit integrity of their data stored in a cloud storage, without retrieving the file and without keeping a local copy. ateniese et al. (ccs 07, acm tiss \u201911) proposed the first pdp scheme, which is very efficient in communication and storage. however their scheme requires a lot of group exponentiation operations: in the setup, one group exponentiation is required to generate a tag per each data block. in each verification, (equivalently) (m+ `) group exponentiations are required to generate a proof, where m is the size of a data block and ` is the number of blocks accessed during a verification. this paper proposed an efficient pdp scheme. compared to ateniese et al. (ccs 07, acm tiss \u201911), the proposed scheme has the same complexities in communication and storage, but is much more efficient in computation: in the setup, no expensive group exponentiations are required. in each verification, only m group exponentiations are required to generate a proof. our experiment shows that our scheme is about 400 times faster than ateniese et al. (ccs 07, acm tiss \u201911) in the setup phase. the security of the proposed scheme is proved under knowledge of exponent assumption and factorization assumption.",
            "contribution_ids": [
                "R108514"
            ]
        },
        {
            "instance_id": "EMPTYxR108515",
            "comparison_id": "EMPTY",
            "paper_id": "R108515",
            "text": "A Novel Zero Knowledge Proof of Retrievability proof of retrievability is a cryptographic tool which interacts between the data user and the server, and the server proves to the data user the integrity of data which he will download. it is a crucial problem in outsourcing storage such as cloud computing. in this paper, a novel scheme called the zero knowledge proof of retrievability is proposed, which combines proof of retrievability and zero knowledge proof. it has lower computation and communication complexity and higher security than the previous schemes.",
            "contribution_ids": [
                "R108516"
            ]
        },
        {
            "instance_id": "EMPTYxR108517",
            "comparison_id": "EMPTY",
            "paper_id": "R108517",
            "text": "Proofs of Retrievability from Linearly Homomorphic Structure-Preserving Signatures proofs of retrievability (por) enables clients to outsource huge amount of data to cloud servers, and provides an efficient audit protocol, which can be employed to check that all the data is being maintained properly and can be retrieved from the server. in this paper, we present a generic construction of por from linearly homomorphic structure-preserving signature (lhsps), which makes public verification possible. authenticity and retrievability of our por scheme are guaranteed by the unforgeability of lhsps. we further extend our result to dynamic por, which supports dynamic update of outsourced data. our construction is free of complicated data structures like merkle hash tree. with an instantiation of a recent lhsps scheme proposed by kiltz and wee (eurocrypt15), we derive a publicly verifiable (dynamic) por scheme. the security is based on standard assumptions and proved in the standard model.",
            "contribution_ids": [
                "R108518"
            ]
        },
        {
            "instance_id": "EMPTYxR186659",
            "comparison_id": "EMPTY",
            "paper_id": "R186659",
            "text": "Built Environment Factors Affecting Bike Sharing Ridership: Data-Driven Approach for Multiple Cities identification of factors influencing ridership is necessary for policy-making, as well as, when examining transferability and aspects of performance and reliability. in this work, a data-driven method is formulated to correlate arrivals and departures of station-based bike sharing systems with built environment factors in multiple cities. ridership data from stations of multiple cities are pooled in one data set regardless of their geographic boundaries. the method bundles the collection, analysis, and processing of data, as well as, the model\u2019s estimation using statistical and machine learning techniques. the method was applied on a national level in six cities in germany, and also on an international level in three cities in europe and north america. the results suggest that the model\u2019s performance did not depend on clustering cities by size but by the relative daily distribution of the rentals. selected statistically significant factors were identified to vary temporally (e.g., nightclubs were significant during the night). the most influencing variables were related to the city population, distance to city center, leisure-related establishments, and transport-related infrastructure. this data-driven method can help as a support decision-making tool to implement or expand bike sharing systems.",
            "contribution_ids": [
                "R186661"
            ]
        },
        {
            "instance_id": "EMPTYxR192299",
            "comparison_id": "EMPTY",
            "paper_id": "R192299",
            "text": "Classification of COVID-19 in chest X-ray images using DeTraC deep convolutional neural network abstract chest x-ray is the first imaging technique that plays an important role in the diagnosis of covid-19 disease. due to the high availability of large-scale annotated image datasets, great success has been achieved using convolutional neural networks ( cnn s) for image recognition and classification. however, due to the limited availability of annotated medical images, the classification of medical images remains the biggest challenge in medical diagnosis. thanks to transfer learning, an effective mechanism that can provide a promising solution by transferring knowledge from generic object recognition tasks to domain-specific tasks. in this paper, we validate and a deep cnn , called decompose, transfer, and compose ( detrac ), for the classification of covid-19 chest x-ray images. detrac can deal with any irregularities in the image dataset by investigating its class boundaries using a class decomposition mechanism. the experimental results showed the capability of detrac in the detection of covid-19 cases from a comprehensive image dataset collected from several hospitals around the world. high accuracy of 93.1% (with a sensitivity of 100%) was achieved by detrac in the detection of covid-19 x-ray images from normal, and severe acute respiratory syndrome cases.",
            "contribution_ids": [
                "R192301"
            ]
        },
        {
            "instance_id": "EMPTYxR25763",
            "comparison_id": "EMPTY",
            "paper_id": "R25763",
            "text": "H-Mine: Fast and space-preserving frequent pattern mining in large databases in this study, we propose a simple and novel data structure using hyper-links, h-struct, and a new mining algorithm, h-mine, which takes advantage of this data structure and dynamically adjusts links in the mining process. a distinct feature of this method is that it has a very limited and precisely predictable main memory cost and runs very quickly in memory-based settings. moreover, it can be scaled up to very large databases using database partitioning. when the data set becomes dense, (conditional) fp-trees can be constructed dynamically as part of the mining process. our study shows that h-mine has an excellent performance for various kinds of data, outperforms currently available algorithms in different settings, and is highly scalable to mining large databases. this study also proposes a new data mining methodology, space-preserving mining, which may have a major impact on the future development of efficient and scalable data mining methods. \u2020decreased",
            "contribution_ids": [
                "R25764"
            ]
        },
        {
            "instance_id": "EMPTYxR25925",
            "comparison_id": "EMPTY",
            "paper_id": "R25925",
            "text": "One-step competitive immunochromatographic assay for semiquantitative determination of lipoprotein(a) in plasma \" abstract \\n numerous studies have associated high concentrations of lipoprotein(a) [lp(a)] with atherosclerosis. we developed a rapid, one-step competitive immunochromatographic assay to measure lp(a) in plasma. the assay is performed on a nitrocellulose membrane strip and the result is determined by a visual readout of rust-colored colloidal selenium. the assay is based on the principle that lp(a) in the sample will compete with lp(a)-coated colloidal selenium for binding to the anti-lp(a) monoclonal antibody immobilized on the assay strip in the format of four ladder bars. the number of capture bars that appear as a result of the formation of colloidal selenium color is proportional to the concentration of the lp(a) protein in the samples. the strip assay semiquantitatively measures lp(a) concentrations ranging from 0 to 180 mg/l of lp(a) protein in serum, plasma, or fingerstick whole-blood samples. this assay appears very useful for quick identification of individuals with above-normal concentrations of plasma lp(a) protein (&amp;gt; 70 mg/l), and has potential for monitoring a patient's response to treatment with lp(a)-lowering drugs. \"",
            "contribution_ids": [
                "R25926"
            ]
        },
        {
            "instance_id": "EMPTYxR25959",
            "comparison_id": "EMPTY",
            "paper_id": "R25959",
            "text": "Immunochromatographic Assay for Quantitation of Milk Progesterone. \"we describe a rapid immunochromatographic method for the quantitation of progesterone in bovine milk. the method is based on a 'competitive' assay format using the monoclonal antibody to progesterone and a progesterone-protein conjugate labelled with colloidal gold particles. the monoclonal antibody to progesterone is immobilized as a narrow detection zone on a porous membrane. the sample is mixed with colloidal gold particles coated with progesterone-protein conjugate, and the mixture is allowed to migrate past the detection zone. migration is facilitated by capillary forces. the amount of labelled progesterone-protein conjugate bound to the detection zone, as detected by photometric scanning, is inversely proportional to the amount of progesterone present in the sample. analysis is complete in less than 10 min. the method has a practical detection limit of 5 ng of progesterone per ml of bovine milk.\"",
            "contribution_ids": [
                "R25960"
            ]
        },
        {
            "instance_id": "EMPTYxR26067",
            "comparison_id": "EMPTY",
            "paper_id": "R26067",
            "text": "Subjective and objective assessment of acoustical and overall environmental quality in secondary school classrooms a subjective survey on perceived environmental quality has been carried out on 51 secondary-school classrooms, some of which have been acoustically renovated, and acoustical measurements were carried out in eight of the 51 classrooms, these eight being representative of the different types of classrooms that are the subject of the survey. a questionnaire, which included items on overall quality and its single aspects such as acoustical, thermal, indoor air and visual quality, has been administered to 1006 students. the students perceived that acoustical and visual quality had the most influence on their school performance and, with the same dissatisfaction for acoustical, thermal and indoor air quality, they attributed more relevance, in the overall quality judgment, to the acoustical condition. acoustical quality was correlated to speech comprehension, which was correlated to the speech transmission index, even though the index does not reflect all the aspects by which speech comprehension can be influenced. acoustical satisfaction was lower in nonrenovated classrooms, and one of the most important consequences of poor acoustics was a decrease in concentration. the stronger correlation between average noise disturbance scores and l(a max) levels, more than l(aeq) and l(a90), showed that students were more disturbed by intermittent than constant noise.",
            "contribution_ids": [
                "R26068"
            ]
        },
        {
            "instance_id": "EMPTYxR26077",
            "comparison_id": "EMPTY",
            "paper_id": "R26077",
            "text": "Perceived Importance of the Quality of the Indoor Environment in Commercial Buildings recognition of the importance of the quality of the indoor environment (ieq) to health, comfort and productivity of building end users has produced increasing numbers of voluntary schemes whose assessment embraces a wide spectrum of environmental attributes. studies which aim to derive appropriate weighting factors for these attributes through soliciting the perceived importance from experts are abundant. this article reports the findings of a study which, based on face-to-face interviews with 548 end users and 66 building professionals, processed their perceived importance of ieq using the analytical hierarchy process (ahp). attributes included were thermal comfort, air cleanliness, odor and noise associated with the air conditioning system of typical commercial buildings. correlation analysis of the ranking results of the ahp weights revealed the difference in perceived importance of the attributes according to gender of the respondents. other factors also found to have influence on the perceived importance of the ieq were whether the respondents were professionals or other end users and the reason for them working or visiting the buildings and the duration of their stay. these all varied with psychophysical factors such as personal experiences, needs and expectations. further work is needed to study whether the weighting factors should be derived from the perceptions of experts, end users, or a balance between the two.",
            "contribution_ids": [
                "R26078"
            ]
        },
        {
            "instance_id": "EMPTYxR159783",
            "comparison_id": "EMPTY",
            "paper_id": "R159783",
            "text": "Anforderungen kl\u00c3\u00a4ren mit Videoclips viele gro\u00dfe softwaresysteme sind heute vernetzt, in ger\u00e4te eingebettet und mit anzeigesystemen verbunden. sie erscheinen den nutzern als komplizierte, computergest\u00fctzte umwelt, deren bestandteile kaum zu unterscheiden sind. die ger\u00e4te und ihre umgebung, die software und die bed\u00fcrfnisse der benutzer entwickeln sich w\u00e4hrend des betriebs st\u00e4ndig weiter. damit ein systemteil n\u00fctzlich und wettbewerbsf\u00e4hig bleibt, braucht man fortw\u00e4hrend r\u00fcckmeldungen und bewertungen. die techniken des klassischen requirements engineering reichen dazu aber nicht aus. in diesem beitrag stellen wir einen ansatz vor, um mit kurzen und einfachen videoclips in dieser situation an feedback heranzukommen. bei deren auswertung werden aktuelle anforderungen identifiziert und gekl\u00e4rt.",
            "contribution_ids": [
                "R159787"
            ]
        },
        {
            "instance_id": "EMPTYxR159803",
            "comparison_id": "EMPTY",
            "paper_id": "R159803",
            "text": "Using Vision Videos in a Virtual Focus Group: Experiences and Recommendations facilitated meetings are an established practice for the requirements engineering activities elicitation and validation. focus groups are one well-known technique to implement this practice. several researchers already reported the successful use of vision videos to stimulate active discussions among the participants of on-site focus groups, e.g., for validating scenarios and eliciting feedback. these vision videos show scenarios of a system vision. in this way, the videos serve all parties involved as a visual reference point to actively disclose, discuss, and align their mental models of the future system to achieve shared understanding. in the joint project trusd, we had planned to conduct such an on-site focus group using a vision video to validate a scenario of a future software tool, the so-called privacy dashboard. however, the covid-19 pandemic and its associated measures led to an increase in home and remote working, which also affected us. therefore, we had to replan and conduct the focus group virtually. in this paper, we report about our experiences and recommendations for the use of vision videos in virtual focus groups.",
            "contribution_ids": [
                "R159807"
            ]
        },
        {
            "instance_id": "EMPTYxR166677",
            "comparison_id": "EMPTY",
            "paper_id": "R166677",
            "text": "Conference Indexing in Digital Libraries: A Ranking Model and Case Study on dblp digital library curators make relevance decisions in their daily work to prioritize the most urgent metadata updates. in this work, we propose a complex relevance and ranking model to support the decision and prioritization process of digital library curators. our approach incorporates different aspects of relevance decisions into a framework for feasible data quality management in digital libraries. a case study demonstrates the effects of the factors we use to model these aspects.",
            "contribution_ids": [
                "R166679"
            ]
        },
        {
            "instance_id": "EMPTYxR189991",
            "comparison_id": "EMPTY",
            "paper_id": "R189991",
            "text": "Minibatch vs Local SGD with Shuffling: Tight Convergence Bounds and Beyond in distributed learning, local sgd (also known as federated averaging) and its simple baseline minibatch sgd are widely studied optimization methods. most existing analyses of these methods assume independent and unbiased gradient estimates obtained via with-replacement sampling. in contrast, we study shuffling-based variants: minibatch and local random reshuffling, which draw stochastic gradients without replacement and are thus closer to practice. for smooth functions satisfying the polyak-{\\\\l}ojasiewicz condition, we obtain convergence bounds (in the large epoch regime) which show that these shuffling-based variants converge faster than their with-replacement counterparts. moreover, we prove matching lower bounds showing that our convergence analysis is tight. finally, we propose an algorithmic modification called synchronized shuffling that leads to convergence rates faster than our lower bounds in near-homogeneous settings.",
            "contribution_ids": [
                "R189992"
            ]
        },
        {
            "instance_id": "EMPTYxR27276",
            "comparison_id": "EMPTY",
            "paper_id": "R27276",
            "text": "University entrepreneurship: a taxonomy of the literature the literature on university entrepreneurship is rapidly expanding, in both the united states and europe. since the literature is also fairly fragmented, however, we submit that it is time to take stock of the current knowledge to provide directions for future research and guideposts for policy makers. to accomplish this, we present an unusually comprehensive and detailed literature analysis of the stream of research on university entrepreneurship, now encompassing 173 articles published in a variety of academic journals. four major research streams emerge in this area of study: (i) entrepreneurial research university, (ii) productivity of technology transfer offices, (iii) new firm creation, and (iv) environmental context including networks of innovation. we inductively derive a framework describing the dynamic process of university entrepreneurship based on a synthesis of the literature. we submit that this framework is useful in guiding future research on this important, yet complex and under-researched topic.",
            "contribution_ids": [
                "R27277"
            ]
        },
        {
            "instance_id": "EMPTYxR27472",
            "comparison_id": "EMPTY",
            "paper_id": "R27472",
            "text": "Aging, labor turn- over and firm performance we study whether older workers are costly to firms. our estimation equations are derived from a variant of the decomposition methods frequently used for measuring micro-level sources of industry productivity growth. by using comprehensive linked employer-employee data from the finnish business sector, we study the productivity and wage effects, and hence the profitability effects, of hiring and separation of younger and older workers. the evidence shows that separations of older workers are profitable to firms, especially in the manufacturing ict-industries. robustness checks include the use of regional labor supply and other variables as instruments for the potential endogeneity of the labor flows.",
            "contribution_ids": [
                "R27473"
            ]
        },
        {
            "instance_id": "EMPTYxR27480",
            "comparison_id": "EMPTY",
            "paper_id": "R27480",
            "text": "Does the ageing workforce hamper the innovativeness of firms? (No) evidence from Germany due to demographic changes, the personnel structure of the workforce in countries like germany and japan will change considerably in the next few years. at the same time, companies need creative and skilled human resources to innovate. we analysed data from the 2001 german community innovation survey to explore the impact of personnel structure (share of older employees, skills shortages, share of highly skilled employees) on innovation input and output. overall, we did not find support for a negative effect of a high share of older employees in a company on innovation output. however, companies with a high share of older employees tended to invest less in further training (considered innovation input). this contradicts the call for lifelong learning. in accordance with our propositions, a high share of highly skilled employees had a positive effect on innovation input and output. companies which experienced skills shortages were more likely to invest in further training. however, they were, somewhat surprisingly, more innovative than companies which did not suffer from skills shortages.",
            "contribution_ids": [
                "R27481"
            ]
        },
        {
            "instance_id": "EMPTYxR27719",
            "comparison_id": "EMPTY",
            "paper_id": "R27719",
            "text": "On biomass energy consumption and real Output in the U abstract this empirical note utilizes us annual data from 1949 to 2007 to examine the causal relationship between biomass energy consumption and real gross domestic product (gdp) within a multivariate framework. toda-yamamoto causality tests reveal unidirectional causality from biomass energy consumption to real gdp supportive of the growth hypothesis.",
            "contribution_ids": [
                "R27720"
            ]
        },
        {
            "instance_id": "EMPTYxR28517",
            "comparison_id": "EMPTY",
            "paper_id": "R28517",
            "text": "Material requirements for high voltage, high power IGBT devices abstract the two basic package types of current igbt modules, which evolved from opposing requirements of traction and power transmission applications, are presented. it is shown that reliability and lifetime aspects given by traction puts most stringent limitations on the choice of materials at given cost targets. the materials used today for high power packaging and the future developments of high power igbt-packages are discussed.",
            "contribution_ids": [
                "R28518"
            ]
        },
        {
            "instance_id": "EMPTYxR28898",
            "comparison_id": "EMPTY",
            "paper_id": "R28898",
            "text": "Integration of 300 mm fab layouts and material handling automation \"we present key approaches and methodologies from intel's 300 mm factory integration efforts. the topics discussed in this paper are aimed at cross-functional optimization of fab layouts, automated material handling systems (amhs) and operations. we discuss the key benefits of up front understanding of the interactions and investigate specific attributes in layouts and amhs configurations where the integrated design/analysis is addressing cost-benefits and flexibility trade-offs needed in the high volume 300 mm factories.\"",
            "contribution_ids": [
                "R28899"
            ]
        },
        {
            "instance_id": "EMPTYxR28908",
            "comparison_id": "EMPTY",
            "paper_id": "R28908",
            "text": "An AGV routing policy reflecting the current and future state of semiconductor and LCD production lines \"this paper presents an efficient policy for agv and part routing in semiconductor and lcd production bays using information on the future state of systems where agvs play a central role in material handling. these highly informative systems maintain a great deal of information on current and near-future status, such as the arrival and operation completion times of parts, thereby enabling a new approach for production shop control. efficient control of agvs is vital in semiconductor and lcd plants because agv systems often limit the total production capacity of these very expensive plants. with the proposed procedure, the cell controller records the future events chronologically and uses this information to determine the destination and source of parts between the parts' operation machine and temporary storage. it is shown by simulation that the new control policy reduces agv requirements and flow time of parts.\"",
            "contribution_ids": [
                "R28909"
            ]
        },
        {
            "instance_id": "EMPTYxR28923",
            "comparison_id": "EMPTY",
            "paper_id": "R28923",
            "text": "Simulating the transport and scheduling of priority lots in semiconductor factories as the high technology product market becomes more dynamic and competitive, chip manufacturers need to bring products to customers in short periods of time. as a result, semiconductor fabrication plants regularly contain lots with priority status. these lots have several unique characteristics compared to other production lots, both in terms of lot transport and scheduling on tools. these lots consume tool capacity that may impact the factory output rate. priority lots also have specific policies for transport. the impact of these priority lots on other lots in the fabrication is not easily quantified, as many factors are involved. dynamic factory and amhs simulation models are capable of capturing the variability of a factory, and the interactions of critical constraints that prevent predictable manufacturing. this paper presents a breakthrough modeling approach to study the behaviors of priority lots, and to quantify their impact to manufacturing.",
            "contribution_ids": [
                "R28924"
            ]
        },
        {
            "instance_id": "EMPTYxR28926",
            "comparison_id": "EMPTY",
            "paper_id": "R28926",
            "text": "Operational modeling and simulation of an inter-bay AMHS in semiconductor wafer fabrication this paper studies the operational logic in an inter-bay automated material handling system (amhs) in semiconductor wafer fabrication. this system consists of stockers located in a two-floor layout. automated moving devices transfer lots between stockers within the same floor (intra-floor lot transfer) or between different floors (inter-floor lot transfer). intra-floor lot-transferring transports use a two-rail one-directional system, whereas inter-floor lot-transferring transports use lifters. the decision problem consists of selecting rails and lifters that minimize average lot-delivery time. several operation rules to deliver lots from source stocker to destination stocker are proposed and their performance is evaluated by discrete event simulation.",
            "contribution_ids": [
                "R28927"
            ]
        },
        {
            "instance_id": "EMPTYxR28934",
            "comparison_id": "EMPTY",
            "paper_id": "R28934",
            "text": "Vehicle positioning in complex automated transport systems this paper addresses the problem of vehicle positioning for automated transport in full-automated manufacturing systems. this study is motivated by the complexity of vehicle control found in semiconductor fabrication where the material handling network path is composed of multiple interconnected loops. we propose an integer linear program that minimizes the maximum time needed to serve a transport request. we also present a variant of the model in order to take into account the utilization rate of vehicles. the practical usefulness of the model is also discussed",
            "contribution_ids": [
                "R28935"
            ]
        },
        {
            "instance_id": "EMPTYxR28946",
            "comparison_id": "EMPTY",
            "paper_id": "R28946",
            "text": "Identifying Software Project Risks: An International Delphi Study\u00e2\u0080\u009d advocates of software risk management claim that by identifying and analyzing threats to success (i.e., risks) action can be taken to reduce the chance of failure of a project. the first step in the risk management process is to identify the risk itself, so that appropriate countermeasures can be taken. one problem in this task, however, is that no validated lists are available to help the project manager understand the nature and types of risks typically faced in a software project. this paper represents a first step toward alleviating this problem by developing an authoritative list of common risk factors. we deploy a rigorous data collection method called a \"ranking-type\" delphi survey to produce a rank-order list of risk factors. this data collection method is designed to elicit and organize opinions of a panel of experts through iterative, controlled feedback. three simultaneous surveys were conducted in three different settings: hong kong, finland, and the united states. this was done to broaden our view of the types of risks, rather than relying on the view of a single culture-an aspect that has been ignored in past risk management research. in forming the three panels, we recruited experienced project managers in each country. the paper presents the obtained risk factor list, compares it with other published risk factor lists for completeness and variation, and analyzes common features and differences in risk factor rankings in the three countries. we conclude by discussing implications of our findings for both research and improving risk management practice.",
            "contribution_ids": [
                "R28947",
                "R28948",
                "R28950"
            ]
        },
        {
            "instance_id": "EMPTYxR29248",
            "comparison_id": "EMPTY",
            "paper_id": "R29248",
            "text": "ERP systems and open source: an initial review and some implications for SMEs purpose the purpose of this paper is to further build up the knowledge about reasons for small and mid\u2010sized enterprises (smes) to adopt open source enterprise resource planning (erp) systems. design/methodology/approach the paper presents and analyses findings in articles about proprietary erps and open source erps. in addition, a limited investigation of the distribution channel sourceforge for open source is made. findings the cost perspective seems to receive a high attention regarding adoption of open source erps. this can be questioned and the main conclusion is that costs seem to have a secondary role in adoption or non adoption of open source erps. research limitations/implications the paper is mainly a conceptual paper written from a literature review. the ambition is to search support for the findings by doing more research in the area. practical implications the findings presented are of interest both for developers of proprietary erps as well as smes since it is shown that there are definitely reasons other than costs involved when deciding on proprietary erps or open source erps. originality/value it can be argued that there is a lack of research conducted and published about why smes choose open source erps instead of proprietary erps. this paper identifies the gap and suggests future research directions about this subject.",
            "contribution_ids": [
                "R29249"
            ]
        },
        {
            "instance_id": "EMPTYxR29255",
            "comparison_id": "EMPTY",
            "paper_id": "R29255",
            "text": "A Comparative Study of Issues Affecting ERP Implementation in Large Scale and Small Medium Scale Enterprises in India: A Pareto Approach paper attempts to explore and identify issues affecting enterprise resource planning (erp) implementation in context to indian small and medium enterprises (smes) and large enterprises. issues which are considered more important for large scale enterprises may not be of equal importance for a small and medium scale enterprise and hence replicating the implementation experience which holds for large organizations will not a wise approach on the part of the implementation vendors targeting small scale enterprises. this paper attempts to highlight those specific issues where a different approach needs to be adopted. pareto analysis has been applied to identify the issues for indian smes and large scale enterprises as available from the published literature. also by doing comparative analysis between the identified issues for indian large enterprises and smes four issues are proved to be crucial for smes in india but not for large enterprises such as proper system implementation strategy, clearly defined scope of implementation procedure, proper project planning and minimal customization of the system selected for implementation, because of some limitations faced by the indian smes compared to large enterprises.",
            "contribution_ids": [
                "R29256"
            ]
        },
        {
            "instance_id": "EMPTYxR29279",
            "comparison_id": "EMPTY",
            "paper_id": "R29279",
            "text": "Re-conceptualizing Information Systems Models: An Experience from ERP Systems Environment \"information systems have transformed organizations, performance and work. hence, the linkage between information systems and individual performance has been an ongoing concern in information systems (is) research. in the last decades, is researchers have concentrated their efforts in developing and testing models that help with the investigation of is and user performance in different environments. as a result, a number of models for studying end users' systems utilization and other related issues including system usefulness, system success and user aspects in business organizations have appeared. a synthesized model consolidating three well known and widely used models in is research is proposed. the model was empirically tested in a sophisticated is environment investigating the impacts of the enterprise recourse planning (erp) systems on user perceived performance. statistical analysis was performed including factors analysis and regression to test the model and prove its validity. the findings demonstrated that the proposed model performed well as most factors had direct and or indirect significant influences on user perceived performance suggesting therefore that the model possesses the ability to explain the main impacts of these factors on user performance.\"",
            "contribution_ids": [
                "R29280"
            ]
        },
        {
            "instance_id": "EMPTYxR29285",
            "comparison_id": "EMPTY",
            "paper_id": "R29285",
            "text": "ERP systems in public sector erp systems are tended to be implemented in the public sector. in this paper the \"industries\" of public sector are identified which are suitable for erp implementation. the systematic review method is used to give an overview of state of the art erp system implementation in the public sector worldwide in the last five years as well as possible directions of future research. finally, the critical review is given regarding potential of erp system implementation in the public sector.",
            "contribution_ids": [
                "R29286"
            ]
        },
        {
            "instance_id": "EMPTYxR30515",
            "comparison_id": "EMPTY",
            "paper_id": "R30515",
            "text": "Green enterprise computing data: Assumptions and realities \"until now, green computing research has largely relied on few, short-term power measurements to characterize the energy use of enterprise computing. this paper brings new and comprehensive power datasets through powernet, a hybrid sensor network that monitors the power and utilization of the it systems in a large academic building. over more than two years, we have collected power data from 250+ individual computing devices and have monitored a subset of cpu and network loads. this dense, long-term monitoring allows us to extrapolate the data to a detailed breakdown of electricity use across the building's computing systems. our datasets provide an opportunity to examine assumptions commonly made in green computing. we show that power variability both between similar devices and over time for a single device can lead to cost or savings estimates that are off by 15-20%. extending the coverage of measured devices and the duration (to at least one month) significantly reduces errors. lastly, our experiences with collecting data and the subsequent analysis lead to a better understanding of how one should go about power characterization studies. we provide several methodology guidelines for future green computing research.\"",
            "contribution_ids": [
                "R30516",
                "R30520"
            ]
        },
        {
            "instance_id": "EMPTYxR29354",
            "comparison_id": "EMPTY",
            "paper_id": "R29354",
            "text": "Open source ERP in organization: research agenda open source software (oss) is a growing phenomenon, changing the way in which information systems (is) are developed, distributed and implemented. the success of oss in the worldwide market for operating systems, web servers, and other infrastructure software is substantial. however, it is still infrequent in erp type application domains, which are said to be impossible to design from an os angle. while a significant number of research investigate aspects of os, few researches were dedicated to os erp. based on a review of the academic and professional literature, this paper aims to improve our understanding of the current influence of os erp in organizations, to provide a new light on a previously developed topic and to challenge the conventional wisdom in our field which stipulates that there are some areas like erp applications where os could not be developed.",
            "contribution_ids": [
                "R29355"
            ]
        },
        {
            "instance_id": "EMPTYxR31241",
            "comparison_id": "EMPTY",
            "paper_id": "R31241",
            "text": "Middle-Income Traps: A Conceptual and Empirical Survey the term \"middle-income trap\" has entered common parlance in the development policy community, despite the lack of a precise definition. this paper discusses in more detail the definitional issues associated with the term. it also provides evidence on whether the growth performance of middle-income countries (mics) has been different from other income categories, including historical transition phases in the inter-country distribution of income. a transition matrix analysis and an exploration of cross-country growth patterns provide little support for the existence of a middle-income trap.",
            "contribution_ids": [
                "R31242"
            ]
        },
        {
            "instance_id": "EMPTYxR31295",
            "comparison_id": "EMPTY",
            "paper_id": "R31295",
            "text": "Gradient Feature Matching for Expression Invariant Face Recognition using Single Reference Image \"automatic recognition of human faces irrespective of the expression variations is a challenging problem. in this paper, we propose a novel method for face recognition based on `edge-strings'. experimental studies on face perception have shown the significance of edge features in visual perception and learning. in the proposed technique, the edges of a face are identified, and a feature string is created from edge pixels. this forms a symbolic descriptor corresponding to the edge image referred to as `edge-string'. the `edge-strings' are then compared using the smith-waterman algorithm to match them. the class corresponding to each image is identified based on the number of string primitives that match. local string alignment algorithm is more robust to noise than global alignment algorithm; it gives better performance even if the input image is noisy. in addition, this method needs only a single training image per class. the proposed technique is a good solution for expression invariant face recognition. the effectiveness of the proposed method is compared with state-of-the-art algorithms on the yale face database, the japanese female face expression database (jaffe) and cmu amp face expression database.\"",
            "contribution_ids": [
                "R31296"
            ]
        },
        {
            "instance_id": "EMPTYxR33589",
            "comparison_id": "EMPTY",
            "paper_id": "R33589",
            "text": "Long-term outcome of social skills intervention based on interactive LEGO play lego \u00a9 building materials have been adapted as a therapeutic modality for increasing motivation to participate in social skills intervention, and providing a medium through which children with social and communication handicaps can effectively interact. a 3 year retrospective study of long-term outcome for autistic spectrum children participating in lego \u00a9 therapy ( n = 60) compared vineland adaptive behavior scale socialization domain (vabs\u2013sd) and gilliam autism rating scale social interaction subscale (gars\u2013si) scores preand post-treatment with a matched comparison sample ( n = 57) who received comparable non-lego \u00a9 therapy. although both groups made significant gains on the two outcome measures, lego \u00a9 participants improved significantly more than the comparison subjects. diagnosis and pre-treatment full-scale iq scores did not predict outcome scores; however, vineland adaptive behavior composite, vineland communication domain, and verbal iq all predicted outcome on the vabs\u2013sd, especially for the lego \u00a9 therapy group. results are discussed in terms of implications for methods of social skills intervention for autistic spectrum disorders.",
            "contribution_ids": [
                "R33590"
            ]
        },
        {
            "instance_id": "EMPTYxR33629",
            "comparison_id": "EMPTY",
            "paper_id": "R33629",
            "text": "Adult outcome for children with autism \"background\\ninformation on long-term prognosis in autism is limited. outcome is known to be poor for those with an iq below 50, but there have been few systematic studies of individuals with an iq above this.\\n\\n\\nmethod\\nsixty-eight individuals meeting criteria for autism and with a performance iq of 50 or above in childhood were followed up as adults. their mean age when first seen was 7 years (range 3-15 years); at follow-up the average age was 29 years (range 21-48 years). outcome measures included standardised cognitive, language and attainment tests. information on social, communication and behavioural problems was obtained from the autism diagnostic interview (adi).\\n\\n\\nresults\\nalthough a minority of adults had achieved relatively high levels of independence, most remained very dependent on their families or other support services. few lived alone, had close friends, or permanent employment. communication generally was impaired, and reading and spelling abilities were poor. stereotyped behaviours or interests frequently persisted into adulthood. ten individuals had developed epilepsy. overall, only 12% were rated as having a 'very good' outcome; 10% were rated as 'good' and 19% as 'fair'. the majority was rated as having a 'poor' (46%) or 'very poor' (12%) outcome. individuals with a childhood performance iq of at least 70 had a significantly better outcome than those with an iq below this. however, within the normal iq range outcome was very variable and, on an individual level, neither verbal nor performance iq proved to be consistent prognostic indicators.\\n\\n\\nconclusions\\nalthough outcome for adults with autism has improved over recent years, many remain highly dependent on others for support. this study provides some information on prognostic indicators, but more fine-grained research is needed into the childhood variables that are associated with good or poor outcome.\"",
            "contribution_ids": [
                "R33630"
            ]
        },
        {
            "instance_id": "EMPTYxR33631",
            "comparison_id": "EMPTY",
            "paper_id": "R33631",
            "text": "Subgroups of Children With Autism by Cluster Analysis: A Longitudinal Examination objectives\\na hierarchical cluster analysis was conducted using a sample of 138 school-age children with autism. the objective was to examine (1) the characteristics of resulting subgroups, (2) the relationship of these subgroups to subgroups of the same children determined at preschool age, and (3) preschool variables that best predicted school-age functioning.\\n\\n\\nmethod\\nninety-five cases were analyzed.\\n\\n\\nresults\\nfindings support the presence of 2 subgroups marked by different levels of social, language, and nonverbal ability, with the higher group showing essentially normal cognitive and behavioral scores. the relationship of high- and low-functioning subgroup membership to levels of functioning at preschool age was highly significant.\\n\\n\\nconclusions\\nschool-age functioning was strongly predicted by preschool cognitive functioning but was not strongly predicted by preschool social abnormality or severity of autistic symptoms. the differential outcome of the 2 groups shows that high iq is necessary but not sufficient for optimal outcome in the presence of severe language impairment.",
            "contribution_ids": [
                "R33632"
            ]
        },
        {
            "instance_id": "EMPTYxR33955",
            "comparison_id": "EMPTY",
            "paper_id": "R33955",
            "text": "Techniques for data hiding data hiding is the process of embedding data into image and audio signals. the process is constrained by the quantity of data, the need for invariance of the data under conditions where the `host' signal is subject to distortions, e.g., compression, and the degree to which the data must be immune to interception, modification, or removal. we explore both traditional and novel techniques for addressing the data hiding process and evaluate these techniques in light of three applications: copyright protecting, tamper-proofing, and augmentation data embedding.",
            "contribution_ids": [
                "R33956"
            ]
        },
        {
            "instance_id": "EMPTYxR33957",
            "comparison_id": "EMPTY",
            "paper_id": "R33957",
            "text": "Reversible data embedding using a difference expansion reversible data embedding has drawn lots of interest recently. being reversible, the original digital content can be completely restored. we present a novel reversible data-embedding method for digital images. we explore the redundancy in digital images to achieve very high embedding capacity, and keep the distortion low.",
            "contribution_ids": [
                "R33958"
            ]
        },
        {
            "instance_id": "EMPTYxR34478",
            "comparison_id": "EMPTY",
            "paper_id": "R34478",
            "text": "The structure of production, technical change and productivity in a port\u00e2\u0080\u009d the primary focus of this paper is the modelling and estimation of the structure of production, technical change and total factor productivity (tfp) growth in a port. special attention is given to the specification of technical change which is measured as the percent of containerization. our findings indicate that technical change has been labour saving and capital using. tfp has been growing from 1966-1983 at an annual average rate of 0.11. the main contribution to tfp growth has been containerization. on the average, 85% of the growth in tfp has been due to containerization and 15% of the growth has been due to economies of scale and output growth.",
            "contribution_ids": [
                "R34479"
            ]
        },
        {
            "instance_id": "EMPTYxR50025",
            "comparison_id": "EMPTY",
            "paper_id": "R50025",
            "text": "Segmentation of Ocular Pathologies Using Deep Convolutional Neural Network diabetes mellitus (dm) is a chronic, progressive and life-threatening disease. the ocular manifestations of dm, diabetic retinopathy (dr) and diabetic macular edema (dme), are the leading causes of blindness in the adult population throughout the world. early diagnosis of dr and dm through screening tests and successive treatments can reduce the threat to visual acuity. in this context, we propose an encoder decoder based semantic segmentation network sop-net (segmentation of ocular pathologies using deep convolutional neural network) for simultaneous delineation of retinal pathologies (hard exudates, soft exudates, hemorrhages, microaneurysms). the proposed semantic segmentation framework is capable of providing segmentation results at pixel-level with good localization of object boundaries. sop-net has been trained and tested on idrid dataset which is publicly available with pixel level annotations of retinal pathologies. the network achieved average accuracies of 98.98%, 90.46%, 96.79%, and 96.70% for segmentation of hard exudates, soft exudates, hemorrhages, and microaneurysms. the proposed methodology has the capability to be used in developing a diagnostic system for organizing large scale ophthalmic screening programs.",
            "contribution_ids": [
                "R50027"
            ]
        },
        {
            "instance_id": "EMPTYxR50090",
            "comparison_id": "EMPTY",
            "paper_id": "R50090",
            "text": "Translating the Concept of Goal Setting into Practice: What \u00e2\u0080\u0098else\u00e2\u0080\u0099 Does It Require than a Goal Setting Tool?:  this conceptual paper reviews the current status of goal setting in the area of technology enhanced learning and education. besides a brief literature review, three current projects on goal setting are discussed. the paper shows that the main barriers for goal setting applications in education are not related to the technology, the available data or analytical methods, but rather the human factor. the most important bottlenecks are the lack of students goal setting skills and abilities, and the current curriculum design, which, especially in the observed higher education institutions, provides little support for goal setting interventions.",
            "contribution_ids": [
                "R50092"
            ]
        },
        {
            "instance_id": "EMPTYxR50147",
            "comparison_id": "EMPTY",
            "paper_id": "R50147",
            "text": "Improving Wikipedia's accuracy: Is edit age a solution? wikipedia is fast becoming a key information source for many despite criticism that it is unreliable and inaccurate. a number of recommendations have been made to sort the chaff from the wheat in wikipedia, among which is the idea of color-coding article segment edits according to age (cross, 2006). using data collected as part of a wider study published in nature, this article examines the distribution of errors throughout the life of a select group of wikipedia articles. the survival time of each error edit in terms of the edit counts and days was calculated and the hypothesis that surviving material added by older edits is more trustworthy was tested. surprisingly, we find that roughly 20% of errors can be attributed to surviving text added by the first edit, which confirmed the existence of a first-mover effect (viegas, wattenberg, & kushal, 2004) whereby material added by early edits are less likely to be removed. we suggest that the sizable number of errors added by early edits is simply a result of more material being added near the beginning of the life of the article. overall, the results do not provide support for the idea of trusting surviving segments attributed to older edits because such edits tend to add more material and hence contain more errors which do not seem to be offset by greater opportunities for error correction by later edits. \u00a9 2008 wiley periodicals, inc.",
            "contribution_ids": [
                "R50149"
            ]
        },
        {
            "instance_id": "EMPTYxR50376",
            "comparison_id": "EMPTY",
            "paper_id": "R50376",
            "text": "Inferring Missing Categorical Information in Noisy and Sparse Web Markup embedded markup of web pages has seen widespread adoption throughout the past years driven by standards such as rdfa and microdata and initiatives such as schema.org, where recent studies show an adoption by 39% of all web pages already in 2016. while this constitutes an important information source for tasks such as web search, web page classification or knowledge graph augmentation, individual markup nodes are usually sparsely described and often lack essential information. for instance, from 26 million nodes describing events within the common crawl in 2016, 59% of nodes provide less than six statements and only 257,000 nodes (0.96%) are typed with more specific event subtypes. nevertheless, given the scale and diversity of web markup data, nodes that provide missing information can be obtained from the web in large quantities, in particular for categorical properties. such data constitutes potential training data for inferring missing information to significantly augment sparsely described nodes. in this work, we introduce a supervised approach for inferring missing categorical properties in web markup. our experiments, conducted on properties of events and movies, show a performance of 79% and 83% f1 score correspondingly, significantly outperforming existing baselines.",
            "contribution_ids": [
                "R50378"
            ]
        },
        {
            "instance_id": "EMPTYxR52278",
            "comparison_id": "EMPTY",
            "paper_id": "R52278",
            "text": "Measuring the predictability of life outcomes with a scientific mass collaboration significance hundreds of researchers attempted to predict six life outcomes, such as a child\u2019s grade point average and whether a family would be evicted from their home. these researchers used machine-learning methods optimized for prediction, and they drew on a vast dataset that was painstakingly collected by social scientists over 15 y. however, no one made very accurate predictions. for policymakers considering using predictive models in settings such as criminal justice and child-protective services, these results raise a number of concerns. additionally, researchers must reconcile the idea that they understand life trajectories with the fact that none of the predictions were very accurate. how predictable are life trajectories? we investigated this question with a scientific mass collaboration using the common task method; 160 teams built predictive models for six life outcomes using data from the fragile families and child wellbeing study, a high-quality birth cohort study. despite using a rich dataset and applying machine-learning methods optimized for prediction, the best predictions were not very accurate and were only slightly better than those from a simple benchmark model. within each outcome, prediction error was strongly associated with the family being predicted and weakly associated with the technique used to generate the prediction. overall, these results suggest practical limits to the predictability of life outcomes in some settings and illustrate the value of mass collaborations in the social sciences.",
            "contribution_ids": [
                "R52279"
            ]
        },
        {
            "instance_id": "EMPTYxR8345",
            "comparison_id": "EMPTY",
            "paper_id": "R8345",
            "text": "Decentralised Authoring, Annotations and Notifications for a Read-Write Web with dokieli abstract while the web was designed as a decentralised environment, individual authors still lack the ability to conveniently author and publish documents, and to engage in social interactions with documents of others in a truly decentralised fashion. we present dokieli , a fully decentralised, browser-based authoring and annotation platform with built-in support for social interactions, through which people retain ownership of and sovereignty over their data. the resulting \u201cliving\u201d documents are interoperable and independent of dokieli since they follow standards and best practices, such as html+rdfa for a fine-grained semantic structure, linked data platform for personal data storage, and linked data notifications for updates. this article describes dokieli\u2019s architecture and implementation, demonstrating advanced document authoring and interaction without a single point of control. such an environment provides the right technological conditions for independent publication of scientific articles, news, and other works that benefit from diverse voices and open interactions. to experience the described features please open this document in your web browser under its canonical uri: http://csarven.ca/dokieli-rww .",
            "contribution_ids": [
                "R8346"
            ]
        },
        {
            "instance_id": "EMPTYxR76168",
            "comparison_id": "EMPTY",
            "paper_id": "R76168",
            "text": "Selective Binding of Monovalent Cations to the Stacking G-Quartet Structure Formed by Guanosine 5\u2018-Monophosphate:\u00a0 A Solid-State NMR Study \"we report a solid-state multinuclear ((23)na, (15)n, (13)c, and (31)p) nmr study on the relative affinity of monovalent cations for a stacking g-quartet structure formed by guanosine 5'-monophosphate (5'-gmp) self-association at ph 8. two major types of cations are bound to the 5'-gmp structure: one at the surface and the other within the channel cavity between two g-quartets. the channel cation is coordinated to eight carbonyl oxygen atoms from the guanine bases, whereas the surface cation is close to the phosphate group and likely to be only partially hydrated. on the basis of solid-state (23)na nmr results from a series of ion titration experiments, we have obtained quantitative thermodynamic parameters concerning the relative cation binding affinity for each of the two major binding sites. for the channel cavity site, the values of the free energy difference (delta g degrees at 25 degrees c) for ion competition between m(+) and na(+) ions are k(+) (-1.9 kcal mol(-1)), nh(4)(+) (-1.8 kcal mol(-1)), rb(+) (-0.3 kcal mol(-1)), and cs(+) (1.8 kcal mol(-1)). for the surface site, the values delta g degrees are k(+) (2.5 kcal mol(-1)), nh(4)(+) (-1.3 kcal mol(-1)), rb(+) (1.1 kcal mol(-1)), and cs(+) (0.9 kcal mol(-1)). solid-state nmr data suggest that the affinity of monovalent cations for the 5'-gmp structure follows the order nh(4)(+) > na(+) > cs(+) > rb(+) > k(+) at the surface site and k(+) > nh(4)(+) > rb(+) > na(+) > cs(+) > li(+) at the channel cavity site. we have found that the cation-induced stability of a 5'-gmp structure is determined only by the affinity of monovalent cations for the channel site and that the binding of monovalent cations to phosphate groups plays no role in 5'-gmp self-ordered structure. we have demonstrated that solid-state (23)na and (15)n nmr can be used simultaneously to provide mutually complementary information about competitive binding between na(+) and nh(4)(+) ions.\"",
            "contribution_ids": [
                "R76170"
            ]
        },
        {
            "instance_id": "EMPTYxR46146",
            "comparison_id": "EMPTY",
            "paper_id": "R46146",
            "text": "A hybrid of CdS/HCa2Nb3O10 ultrathin nanosheets for promoting photocatalytic hydrogen eVolution a hybrid of cds/hca 2 nb 3 o 10 ultrathin nanosheets with a tough heterointerface was successfully fabricated. efficient interfacial charge transfer from cds to hca 2 nb 3 o 10 nanosheets was achieved to realize the enhanced photocatalytic h 2 evolution activity.",
            "contribution_ids": [
                "R46147"
            ]
        },
        {
            "instance_id": "EMPTYxR187558",
            "comparison_id": "EMPTY",
            "paper_id": "R187558",
            "text": "The Pandemic Penalty: The Gendered Effects of COVID-19 on Scientific Productivity academia serves as a valuable case for studying the effects of social forces on workplace productivity, using a concrete measure of output: scholarly papers. many academics, especially women, have experienced unprecedented challenges to scholarly productivity during the coronavirus disease 2019 (covid-19) pandemic. the authors analyze the gender composition of more than 450,000 authorships in the arxiv and biorxiv scholarly preprint repositories from before and during the covid-19 pandemic. this analysis reveals that the underrepresentation of women scientists in the last authorship position necessary for retention and promotion in the sciences is growing more inequitable. the authors find differences between the arxiv and biorxiv repositories in how gender affects first, middle, and sole authorship submission rates before and during the pandemic. a review of existing research and theory outlines potential mechanisms underlying this widening gender gap in productivity during covid-19. the authors aggregate recommendations for institutional change that could ameliorate challenges to women\u2019s productivity during the pandemic and beyond.",
            "contribution_ids": [
                "R187561",
                "R187612",
                "R187620",
                "R187623"
            ]
        },
        {
            "instance_id": "EMPTYxR49056",
            "comparison_id": "EMPTY",
            "paper_id": "R49056",
            "text": "Global mean sea-level rise in a world agreed upon in Paris although the 2015 paris agreement seeks to hold global average temperature to \u2018well below 2\\u2009\u00b0c above pre-industrial levels and to pursue efforts to limit the temperature increase to 1.5\\u2009\u00b0c above pre-industrial levels\u2019, projections of global mean sea-level (gmsl) rise commonly focus on scenarios in which there is a high probability that warming exceeds 1.5\\u2009\u00b0c. using a semi-empirical model, we project gmsl changes between now and 2150 ce under a suite of temperature scenarios that satisfy the paris agreement temperature targets. the projected magnitude and rate of gmsl rise varies among these low emissions scenarios. stabilizing temperature at 1.5\\u2009\u00b0c instead of 2\\u2009\u00b0c above preindustrial reduces gmsl in 2150 ce by 17 cm (90% credible interval: 14\u201321 cm) and reduces peak rates of rise by 1.9 mm yr\u22121 (90% credible interval: 1.4\u20132.6 mm yr\u22121). delaying the year of peak temperature has little long-term influence on gmsl, but does reduce the maximum rate of rise. stabilizing at 2\\u2009\u00b0c in 2080 ce rather than 2030 ce reduces the peak rate by 2.7 mm yr\u22121 (90% credible interval: 2.0\u20134.0 mm yr\u22121).",
            "contribution_ids": [
                "R49060",
                "R49064"
            ]
        },
        {
            "instance_id": "EMPTYxR75084",
            "comparison_id": "EMPTY",
            "paper_id": "R75084",
            "text": "A Survey on Knowledge Graph Embedding: Approaches, Applications and Benchmarks a knowledge graph (kg), also known as a knowledge base, is a particular kind of network structure in which the node indicates entity and the edge represent relation. however, with the explosion of network volume, the problem of data sparsity that causes large-scale kg systems to calculate and manage difficultly has become more significant. for alleviating the issue, knowledge graph embedding is proposed to embed entities and relations in a kg to a low-, dense and continuous feature space, and endow the yield model with abilities of knowledge inference and fusion. in recent years, many researchers have poured much attention in this approach, and we will systematically introduce the existing state-of-the-art approaches and a variety of applications that benefit from these methods in this paper. in addition, we discuss future prospects for the development of techniques and application trends. specifically, we first introduce the embedding models that only leverage the information of observed triplets in the kg. we illustrate the overall framework and specific idea and compare the advantages and disadvantages of such approaches. next, we introduce the advanced models that utilize additional semantic information to improve the performance of the original methods. we divide the additional information into two categories, including textual descriptions and relation paths. the extension approaches in each category are described, following the same classification criteria as those defined for the triplet fact-based models. we then describe two experiments for comparing the performance of listed methods and mention some broader domain tasks such as question answering, recommender systems, and so forth. finally, we collect several hurdles that need to be overcome and provide a few future research directions for knowledge graph embedding.",
            "contribution_ids": [
                "R75086"
            ]
        },
        {
            "instance_id": "EMPTYxR49577",
            "comparison_id": "EMPTY",
            "paper_id": "R49577",
            "text": "From Governance of Innovation to Innovations in Governance in the last few decades, many new phenomena, such as globalization and digitization, have changed the world by enabling the connection between organizations and individuals across geographies, institutions, and industries. the resulting complex nexus of interdependent relationships has dramatically altered the way in which firms innovate and govern themselves. as a consequence of this fast-changing world, both innovation and governance become strategic priorities. on the one hand, innovation is a fundamental antecedent of competitive advantage, and hence the ability to innovate determines the fate of firms, regions, and countries. on the other hand, the value from innovation can only be created, captured, and distributed when there exists effective corporate governance. this proposed presenter symposium seeks to examine the tight, yet unexplored, relationships between these two critical strategic dimensions.\" innovation in the boardroom presenter: matthew semadeni; arizona state u. corporate governance fo...",
            "contribution_ids": [
                "R49579"
            ]
        },
        {
            "instance_id": "EMPTYxR130466",
            "comparison_id": "EMPTY",
            "paper_id": "R130466",
            "text": "Data-to-Text Generation with Content Selection and Planning recent advances in data-to-text generation have led to the use of large-scale datasets and neural network models which are trained end-to-end, without explicitly modeling what to say and in what order. in this work, we present a neural network architecture which incorporates content selection and planning without sacrificing end-to-end training. we decompose the generation task into two stages. given a corpus of data records (paired with descriptive documents), we first generate a content plan highlighting which information should be mentioned and in which order and then generate the document while taking the content plan into account. automatic and human-based evaluation experiments show that our model1 outperforms strong baselines improving the state-of-the-art on the recently released rotowire dataset.",
            "contribution_ids": [
                "R130467"
            ]
        },
        {
            "instance_id": "EMPTYxR170007",
            "comparison_id": "EMPTY",
            "paper_id": "R170007",
            "text": "Pathological grooming: Evidence for a single factor behind trichotillomania, skin picking and nail biting although trichotillomania (ttm), skin picking (sp), and nail biting (nb) have been receiving growing scientific attention, the question as to whether these disorders can be regarded as separate entities or they are different manifestations of the same underlying tendency is unclear. data were collected online in a community survey, yielding a sample of 2705 participants (66% women, mean age: 29.1, sd: 8.6). hierarchical factor analysis was used to identify a common latent factor and the multiple indicators and multiple causes (mimic) modelling was applied to test the predictive effect of borderline personality disorder symptoms, impulsivity, distress and self-esteem on pathological grooming. pearson correlation coefficients between ttm, sp and nb were between 0.13 and 0.29 (p < 0.01). the model yielded an excellent fit to the data (cfi = 0.992, tli = 0.991, \u03c72 = 696.65, p < 0.001, df = 222, rmsea = 0.030, cfit of rmsea = 1.000), supporting the existence of a latent factor. the mimic model indicated an adequate fit (cfi = 0.993, tli = 0.992, \u03c72 = 655.8, p < 0.001, df = 307, rmsea = 0.25, ci: 0.022\u20130.028, pclose = 1.000). ttm, sp and nb each were loaded significantly on the latent factor, indicating the presence of a general grooming factor. impulsivity, psychiatric distress and contingent self-esteem had significant predictive effects, whereas borderline personality disorder had a nonsignificant predictive effect on the latent factor. we found evidence that the category of pathological grooming is meaningful and encompasses three symptom manifestations: trichotillomania, skin picking and nail biting. this latent underlying factor is not better explained by indicators of psychopathology, which supports the notion that the urge to self-groom, rather than general psychiatric distress, impulsivity, self-esteem or borderline symptomatology, is what drives individual grooming behaviours.",
            "contribution_ids": [
                "R170008"
            ]
        },
        {
            "instance_id": "EMPTYxR168766",
            "comparison_id": "EMPTY",
            "paper_id": "R168766",
            "text": "Neural Activity during Natural Viewing of Sesame Street Statistically Predicts Test Scores in Early Childhood neural activity that is evoked naturalistically in children during educational television viewing can be used to predict math and verbal knowledge.",
            "contribution_ids": [
                "R168768",
                "R168769"
            ]
        },
        {
            "instance_id": "EMPTYxR131642",
            "comparison_id": "EMPTY",
            "paper_id": "R131642",
            "text": "MultiFiT: Efficient Multi-lingual Language Model Fine-tuning pretrained language models are promising particularly for low-resource languages as they only require unlabelled data. however, training existing models requires huge amounts of compute, while pretrained cross-lingual models often underperform on low-resource languages. we propose multi-lingual language model fine-tuning (multifit) to enable practitioners to train and fine-tune language models efficiently in their own language. in addition, we propose a zero-shot method using an existing pretrained cross-lingual model. we evaluate our methods on two widely used cross-lingual classification datasets where they outperform models pretrained on orders of magnitude more data and compute. we release all models and code.",
            "contribution_ids": [
                "R131643"
            ]
        },
        {
            "instance_id": "EMPTYxR197024",
            "comparison_id": "EMPTY",
            "paper_id": "R197024",
            "text": "Language-agnostic BERT Sentence Embedding while bert is an effective method for learning monolingual sentence embeddings for semantic similarity and embedding based transfer learning bert based cross-lingual sentence embeddings have yet to be explored. we systematically investigate methods for learning multilingual sentence embeddings by combining the best methods for learning monolingual and cross-lingual representations including: masked language modeling (mlm), translation language modeling (tlm), dual encoder translation ranking, and additive margin softmax. we show that introducing a pre-trained multilingual language model dramatically reduces the amount of parallel training data required to achieve good performance by 80%. composing the best of these methods produces a model that achieves 83.7% bi-text retrieval accuracy over 112 languages on tatoeba, well above the 65.5% achieved by laser, while still performing competitively on monolingual transfer learning benchmarks. parallel data mined from commoncrawl using our best model is shown to train competitive nmt models for en-zh and en-de. we publicly release our best multilingual sentence embedding model for 109+ languages at https://tfhub.dev/google/labse.",
            "contribution_ids": [
                "R197026"
            ]
        },
        {
            "instance_id": "EMPTYxR171445",
            "comparison_id": "EMPTY",
            "paper_id": "R171445",
            "text": "Territorial choruses of giant otter groups (Pteronura brasiliensis) encode information on group identity group living animals often engage in corporate territorial defence. territorial group vocalizations can provide information about group identity, size and composition. neighbouring groups may use this information to avoid unfavourable direct conflicts. giant otters are highly social and territorial animals with an elaborate vocal repertoire. they produce long-range screams when they are alert or excited, i.e. in an alarm, isolation or begging context. long-range screams are not only produced by one individual at a time (\u2018single screams\u2019) but also by multiple group members simultaneously, resulting in a highly conspicuous \u2018group chorus\u2019. wild giant otters regularly produce group choruses during interactions with predators, when they detect intruders in their territory or before group reunions after separation. since single screams and especially group choruses probably contribute to the groups\u2019 corporate territorial defence, we hypothesized that group identity is encoded in single screams and group choruses. we analysed vocalizations from five wild and three captive giant otter groups and found statistical evidence for a group signature in group choruses. results for single screams were less conclusive, which might have been caused by the comparatively lower sample size. we suggest that giant otters may gain information on group identity by listening to group choruses. group identity likely constitutes important social information for giant otters since territory boundaries of neighbouring groups can overlap and direct inter-group conflicts are severe. therefore, group chorusing may contribute to the mutual avoidance of members from different groups.",
            "contribution_ids": [
                "R171446",
                "R171447",
                "R171448"
            ]
        },
        {
            "instance_id": "EMPTYxR172784",
            "comparison_id": "EMPTY",
            "paper_id": "R172784",
            "text": "Dictating the Risk: Experimental Evidence on Giving in Risky Environments we study if and how social preferences extend to risky environments. we provide experimental evidence from different versions of dictator games with risky outcomes and establish that preferences that are exclusively based on ex post or on ex ante comparisons cannot generate the observed behavioral patterns. the more money decision-makers transfer in the standard dictator game, the more likely they are to equalize payoff chances under risk. risk to the recipient does, however, generally decrease the transferred amount. ultimately, a utility function with a combination of ex post and ex ante fairness concerns may best describe behavior. (jel c72, d63, d64, d81)",
            "contribution_ids": [
                "R172786",
                "R182000"
            ]
        },
        {
            "instance_id": "EMPTYxR68724",
            "comparison_id": "EMPTY",
            "paper_id": "R68724",
            "text": "Mining User Interests from Social Media \"social media users readily share their preferences, life events, sentiment and opinions, and implicitly signal their thoughts, feelings, and psychological behavior. this makes social media a viable source of information to accurately and effectively mine users' interests with the hopes of enabling more effective user engagement, better quality delivery of appropriate services and higher user satisfaction. in this tutorial, we cover five important aspects related to the effective mining of user interests: (1) the foundations of social user interest modeling, such as information sources, various types of representation models and temporal features, (2) techniques that have been adopted or proposed for mining user interests, (3) different evaluation methodologies and benchmark datasets, (4) different applications that have been taking advantage of user interest mining from social media platforms, and (5) existing challenges, open research questions and exciting opportunities for further work.\"",
            "contribution_ids": [
                "R68726"
            ]
        },
        {
            "instance_id": "EMPTYxR131130",
            "comparison_id": "EMPTY",
            "paper_id": "R131130",
            "text": "Multi-Format Contrastive Learning of Audio Representations recent advances suggest the advantage of multi-modal training in comparison with single-modal methods. in contrast to this view, in our work we find that similar gain can be obtained from training with different formats of a single modality. in particular, we investigate the use of the contrastive learning framework to learn audio representations by maximizing the agreement between the raw audio and its spectral representation. we find a significant gain using this multi-format strategy against the single-format counterparts. moreover, on the downstream audioset and esc-50 classification task, our audio-only approach achieves new state-ofthe-art results with a mean average precision of 0.376 and an accuracy of 90.5%, respectively.",
            "contribution_ids": [
                "R131131"
            ]
        },
        {
            "instance_id": "EMPTYxR6657",
            "comparison_id": "EMPTY",
            "paper_id": "R6657",
            "text": "MSBGA: A Multi-Document Summarization System Based on Genetic Algorithm the multi-document summarizer using genetic algorithm-based sentence extraction (msbga) regards summarization process as an optimization problem where the optimal summary is chosen among a set of summaries formed by the conjunction of the original articles sentences. to solve the np hard optimization problem, msbga adopts genetic algorithm, which can choose the optimal summary on global aspect. the evaluation function employs four features according to the criteria of a good summary: satisfied length, high coverage, high informativeness and low redundancy. to improve the accuracy of term frequency, msbga employs a novel method tfs, which takes word sense into account while calculating term frequency. the experiments on duc04 data show that our strategy is effective and the rouge-1 score is only 0.55% lower than the best participant in duc04",
            "contribution_ids": [
                "R6658"
            ]
        },
        {
            "instance_id": "EMPTYxR196163",
            "comparison_id": "EMPTY",
            "paper_id": "R196163",
            "text": "Targeted Syntactic Evaluation of Language Models we present a data set for evaluating the grammaticality of the predictions of a language model. we automatically construct a large number of minimally different pairs of english sentences, each consisting of a grammatical and an ungrammatical sentence. the sentence pairs represent different variations of structure-sensitive phenomena: subject-verb agreement, reflexive anaphora and negative polarity items. we expect a language model to assign a higher probability to the grammatical sentence than the ungrammatical one. in an experiment using this data set, an lstm language model performed poorly on many of the constructions. multi-task training with a syntactic objective (ccg supertagging) improved the lstm\u2019s accuracy, but a large gap remained between its performance and the accuracy of human participants recruited online. this suggests that there is considerable room for improvement over lstms in capturing syntax in a language model.",
            "contribution_ids": [
                "R196165"
            ]
        },
        {
            "instance_id": "EMPTYxR171200",
            "comparison_id": "EMPTY",
            "paper_id": "R171200",
            "text": "Effects of Multidrug Resistant Tuberculosis Treatment on Patients\u00e2\u0080\u0099 Health Related Quality of Life: Results from a Follow Up Study \"background at present, within the management of multidrug resistant tuberculosis (mdr-tb) much attention is being paid to the traditional microbiological and clinical indicators. evaluation of the impact of mdr-tb treatment on patients\u2019 health related quality of life (hrqol) has remained a neglected area. objective to evaluate the impact of mdr-tb treatment on patients hrqol, and determine the predictors of variability in hrqol along the course of treatment methods a prospective follow up study was conducted at the programmatic management unit for drug resistant tb of lady reading hospital peshawar. culture confirmed eligible mdr-tb patients were asked to self complete sf-36v2 at the baseline visit, and subsequently after the completion of 12 months of treatment and at the end of treatment. a score of <47 norm-based scoring (nbs) points on component summary measures and health domain scales was considered indicative of function impairment. general linear model repeated measures anova was used examine the change and predictors of change in physical component summary (pcs) and mental component summary (mcs) scores over the time. results a total of 68 out of enrolled 81 eligible mdr-tb patients completed sf-36v2 questionnaire at the three time points. patients\u2019 mean pcs scores at the three time points were, 38.2\u00b14.7, 38.6\u00b14.4 and 42.2\u00b15.2 respectively, and mean mcs were 33.7\u00b17.0, 35.5\u00b16.9 and 40.0\u00b16.9 respectively. length of sickness prior to the diagnosis of mdr-tb was predictive of difference in pcs scores (f = 4.988, df = 1, 66), whereas patients\u2019 gender (f = 5.638, df = 1, 66) and length of sickness prior to the diagnosis of mdr-tb (f = 4.400, df = 1, 66) were predictive of difference in mcs scores. conclusion despite the positive impact of mdr-tb treatment on patients' hrqol, the scores on component summary measures suggested compromised physical and mental health even at the end of treatment. a large multicenter study is suggested to confirm the present findings.\"",
            "contribution_ids": [
                "R171201"
            ]
        },
        {
            "instance_id": "EMPTYxR169891",
            "comparison_id": "EMPTY",
            "paper_id": "R169891",
            "text": "Best anthropometric discriminators of incident type 2 diabetes among white and black adults: A longitudinal ARIC study objective to determine which anthropometric measures are the strongest discriminators of incident type 2 diabetes (t2dm) among white and black males and females in a large u.s. cohort. methods we used atherosclerosis risk in communities study data from 12,121 participants aged 45\u201364 years without diabetes at baseline who were followed for over 11 years. anthropometric measures included a body shape index (absi), body adiposity index (bai), body mass index (bmi), waist circumference (wc), waist to hip ratio (whr), waist to height ratio (whtr), and waist to hip to height ratio (whhr). all anthropometric measures were repeated at each visit and converted to z-scores. hazard ratios and 95% confidence intervals adjusted for age were calculated using repeated measures cox proportional hazard regression analysis. akaike information criteria was used to select best-fit models. the magnitude of the hazard ratio effect sizes and the harrell\u2019s c-indexes were used to rank the highest associations and discriminators, respectively. results there were 1,359 incident diabetes cases. higher values of all anthropometric measures increased the risk for development of t2dm (p < 0.0001) except absi, which was not significant in white and black males. statistically significant hazard ratios ranged from 1.26\u20131.63 for males and 1.15\u20131.88 for females. in general, the largest hazard ratios were those that corresponded to the highest harrell\u2019s c-index and lowest akaike information criteria values. among white and black males and females, bmi, wc, whr, and whtr were comparable in discriminating cases from non-cases of t2dm. absi, bai, and whhr were inferior discriminators of incident t2dm across all race-gender groups. conclusions bmi, the most commonly used anthropometric measure, and three anthropometric measures that included waist circumference (i.e., wc, whr, whtr) were the best anthropometric discriminators of incident t2dm across all race-gender groups in the aric cohort.",
            "contribution_ids": [
                "R169892"
            ]
        },
        {
            "instance_id": "EMPTYxR108950",
            "comparison_id": "EMPTY",
            "paper_id": "R108950",
            "text": "In situ measurement of VUV/UV radiation from low-pressure microwave-produced plasma in Ar/O2 gas mixtures ultraviolet (uv) and vacuum ultraviolet (vuv) spectral irradiance is determined in low-pressure microwave-produced plasma, which is regularly used for polymer surface treatment. the re-emitted fluorescence in the uv/vis spectral range from a sodium salicylate layer is measured. this fluorescence is related to vuv/uv radiation in different spectral bands based on cut-off filters. the background produced by direct emitted radiation in the fluorescence spectral region is quantified using a specific background filter, thus enabling the use of the whole fluorescence spectral range. a novel procedure is applied to determine the absolute value of the vuv/uv irradiance on a substrate. for that, an independent measurement of the absolute spectral emissivity of the plasma in the uv is performed. the measured irradiances on a substrate from a 25 pa ar/o2-produced plasma are in the range of 1015\u20131016 (photon s\u22121cm\u22122). these values include the contribution from impurities present in the discharge.",
            "contribution_ids": [
                "R109002"
            ]
        },
        {
            "instance_id": "EMPTYxR170506",
            "comparison_id": "EMPTY",
            "paper_id": "R170506",
            "text": "Hepatitis C Virus Phylogenetic Clustering Is Associated with the Social-Injecting Network in a Cohort of People Who Inject Drugs it is hypothesized that social networks facilitate transmission of the hepatitis c virus (hcv). we tested for association between hcv phylogeny and reported injecting relationships using longitudinal data from a social network design study. people who inject drugs were recruited from street drug markets in melbourne, australia. interviews and blood tests took place three monthly (during 2005\u20132008), with participants asked to nominate up to five injecting partners at each interview. the hcv core region of individual isolates was then sequenced and phylogenetic trees were constructed. genetic clusters were identified using bootstrapping (cut-off: 70%). an adjusted jaccard similarity coefficient was used to measure the association between the reported injecting relationships and relationships defined by clustering in the phylogenetic analysis (statistical significance assessed using the quadratic assignment procedure). 402 participants consented to participate; 244 hcv infections were observed in 238 individuals. 26 genetic clusters were identified, with 2\u20137 infections per cluster. newly acquired infection (aor\\u200a=\\u200a2.03, 95% ci: 1.04\u20133.96, p\\u200a=\\u200a0.037, and hcv genotype 3 (vs. genotype 1, aor\\u200a=\\u200a2.72, 95% ci: 1.48\u20134.99) were independent predictors of being in a cluster. 54% of participants whose infections were part of a cluster in the phylogenetic analysis reported injecting with at least one other participant in that cluster during the study. overall, 16% of participants who were infected at study entry and 40% of participants with newly acquired infections had molecular evidence of related infections with at least one injecting partner. likely transmission clusters identified in phylogenetic analysis correlated with reported injecting relationships (adjusted jaccard coefficient: 0.300; p<0.001). this is the first study to show that hcv phylogeny is associated with the injecting network, highlighting the importance of the injecting network in hcv transmission.",
            "contribution_ids": [
                "R170507"
            ]
        },
        {
            "instance_id": "EMPTYxR170460",
            "comparison_id": "EMPTY",
            "paper_id": "R170460",
            "text": "Adherence as a Predictor of Sexual Behaviors in People Living with HIV/AIDS during the First Year of Antiretroviral Therapy in Rural Cameroon: Data from Stratall ANRS 12110/ESTHER Trial objective this study aims to investigate the time pattern of inconsistence condom use (icu) during the first year of antiretroviral therapy (art) and its relationship with treatment adherence in na\u00efve hiv-infected adult patients. methods data collection was nested within a longitudinal trial on hiv treatment. icu was defined as reporting to have \u201cnever\u201d, \u201csometimes\u201d or \u201cnearly always\u201d used condoms with one\u2019s main or casual partner(s) - either hiv-negative or of unknown hiv status in the three previous months. adherence was defined as taking 100% of their art prescribed doses in the 4 days before the visit and \u201cnot having interrupted treatment\u201d, even once, for more than two consecutive days during the 4 previous weeks. mixed logistic regression was used to study the relationship between adherence and icu. results among the 459 patients enrolled, 212 (46%) during 334 visits reported to have had sexual intercourse at least once with their partner(s) \u2013 either hiv-negative or of unknown hiv status- during the first 12 months of art. the proportion of icu was 76%, 50% and 59% at month 0 (m0), month 6 (m6) and month 12 (m12), while 60% and 66% of patients were art-adherent at m6 and m12, respectively. after adjustment for the frequency of sexual activity, type of sexual partner(s), perceived social class and desire for a child, patients adherent to art were less likely to report icu when compared with baseline (aor [95% ci]: 0.38 [0.19\u20130.76]; p\\u200a=\\u200a0.006). conclusions adherence to art is associated with a lower risk of icu but this result needs to be interpreted carefully. as adherence behaviors are not only determined by problems with the healthcare systems but also by social barriers encountered by patients in their daily life, counseling should not only be art adherence-centered but also patient-centered, including sexual risk minimization and psychosocial support.",
            "contribution_ids": [
                "R170461",
                "R170462"
            ]
        },
        {
            "instance_id": "EMPTYxR108940",
            "comparison_id": "EMPTY",
            "paper_id": "R108940",
            "text": "Vacuum ultraviolet emission from microwave Ar-H2 plasmas vacuum ultraviolet emission from ar-h2 wave driven microwave (2.45\\u2009ghz) plasmas operating at low pressures (0.1\u20131\\u2009mbar) has been investigated. the emitted spectra show the presence of the ar resonance lines at 104.8 and 106.7\\u2009nm and of the lyman-\u03b1,\u03b2 atomic lines at 121.6\\u2009nm and 102.6\\u2009nm, respectively. the increase of the hydrogen amount in the mixture results in an abrupt increase of the werner and lyman molecular bands intensity. the lyman-\u03b2 intensity shows little changes in the range of 5%\u201330% of hydrogen in the mixture while the lyman-\u03b1 intensity tends to decrease as the percentage of hydrogen increases.",
            "contribution_ids": [
                "R108997"
            ]
        },
        {
            "instance_id": "EMPTYxR169110",
            "comparison_id": "EMPTY",
            "paper_id": "R169110",
            "text": "Environmental Enrichment Alters Nicotine-Mediated Locomotor Sensitization and Phosphorylation of DARPP-32 and CREB in Rat Prefrontal Cortex exposure within an environmental enrichment paradigm results in neurobiological adaptations and decreases the baseline of locomotor activity. the current study determined activation of darpp-32 (dopamine- and camp-regulated phosphoprotein-32) and creb (camp response element binding protein), and locomotor activity in rats raised in enriched (ec), impoverished (ic), and standard (sc) conditions following repeated administration of nicotine or saline. in the saline-control group, the basal phosphorylation state of darpp-32 at threonine-34 site (pdarpp-32 thr34) in the prefrontal cortex (pfc) was lower in ec compared to ic and sc rats, which was positively correlated with their respective baseline activities. while nicotine (0.35 mg/kg, freebase) produced locomotor sensitization across all housing conditions when the nicotine-mediated locomotor activity was expressed as a percent change from their respective saline control, ec rats displayed greater sensitization to nicotine than ic and sc rats. consistent with the behavioral findings, repeated nicotine injection increased pdarpp-32 thr34 in pfc of ec and ic rats and in nucleus accumbens of ec rats; however, the magnitude of change from saline control in nicotine-induced enhancement of pdarpp-32 thr34 in pfc was strikingly increased in ec rats relative to ic rats. moreover, ec rats had lower basal phosphorylation levels of creb at serine 133 in pfc and nucleus accumbens compared to ic and sc rats, whereas the nicotine-induced increase in phosphorylated creb-ser133 was more pronounced in pfc of ec rats relative to ic and sc rats. collectively, these findings suggest innovative insights into advancing our understanding of the molecular mechanisms of enrichment-induced changes in the motivational effects of nicotine, and aiding in the identification of new therapeutic strategies for tobacco smokers.",
            "contribution_ids": [
                "R169111",
                "R169112",
                "R169113"
            ]
        },
        {
            "instance_id": "EMPTYxR196501",
            "comparison_id": "EMPTY",
            "paper_id": "R196501",
            "text": "No Army, No Navy: BERT Semi-Supervised Learning of Arabic Dialects we present our deep leaning system submitted to madar shared task 2 focused on twitter user dialect identification. we develop tweet-level identification models based on grus and bert in supervised and semi-supervised set-tings. we then introduce a simple, yet effective, method of porting tweet-level labels at the level of users. our system ranks top 1 in the competition, with 71.70% macro f1 score and 77.40% accuracy.",
            "contribution_ids": [
                "R196503"
            ]
        },
        {
            "instance_id": "EMPTYxR169549",
            "comparison_id": "EMPTY",
            "paper_id": "R169549",
            "text": "Association between Childhood Strabismus and Refractive Error in Chinese Preschool Children purpose to investigate the association between concomitant esotropia or concomitant exotropia and refractive error in preschool children methods a population-based sample of 5831 children aged 3 to 6 years was selected from all kindergartens in a representative county (yuhuatai district, nanjing, jiangsu province) of nanjing, china. clinical examinations including ocular alignment, ocular motility, visual acuity, optometry, stereopsis screening, slit lamp examination and fundus examination were performed by trained ophthalmologists and optometrists. odd ratios (or) and 95% confidence intervals (95% ci) were calculated to evaluate the association of refractive error with concomitant esotropia and concomitant exotropia. results in multivariate logistic regression analysis, concomitant esotropia was associated independently with spherical equivalent anisometropia (or, 3.15 for 0.50 to = 1.00 d of anisometropia) and hyperopia. there was a severity-dependent association of hyperopia with the development of concomitant esotropia, with ors increasing from 9.3 for 2.00 to = 5.00 d of hyperopia. concomitant exotropia was associated with astigmatism (or, 3.56 for 0.50 to 1.00 d of astigmatism, and 1.9 for <0.00 d of astigmatism), myopia (or, 40.54 for -1.00 to <0.00 d of myopia, and 18.93 for <-1.00 d of myopia), and hyperopia (or, 67.78 for 1.00 to <2.00 d of hyperopia, 23.13 for 2.00 to <3.00 d of hyperopia, 25.57 for 3.00 to <4.00 d of hyperopia, and 8.36 for 4.00 to <5.00 d of hyperopia). conclusions this study highlights the close associations between refractive error and the prevalence of concomitant esotropia and concomitant exotropia, which should be considered when managing childhood refractive error.",
            "contribution_ids": [
                "R169550",
                "R169551"
            ]
        },
        {
            "instance_id": "EMPTYxR135960",
            "comparison_id": "EMPTY",
            "paper_id": "R135960",
            "text": "Knowledge extraction from web-based application source code: An approach to database reverse engineering for ontology development this paper presents a novel approach for extracting knowledge from web-based application source code in supplementing and assisting ontology development from database schemas. the structure of web-based application source code is defined in order to distinguish different kinds of knowledge within the source code for ontology development. the connections between the relevant parts of web application source code and the backend database schema with their various forms are explicitly specified in detail. a knowledge processing and integration model for extracting and integrating the knowledge embedded in the source code for ontology development is then proposed.",
            "contribution_ids": [
                "R135962"
            ]
        },
        {
            "instance_id": "EMPTYxR171278",
            "comparison_id": "EMPTY",
            "paper_id": "R171278",
            "text": "Inconsistency between Self-Reported Energy Intake and Body Mass Index among Urban, African-American Children background to prevent obesity, it is important to assess dietary habits through self-reported energy intake (ei) in children. we investigated how ei is associated with body mass index and which elements of dietary habits and status are associated with ei among african-american (aa) children. methods we assessed and included data from 218 10\u201314-year-old aa children in baltimore, md, usa. ei was calculated using a food frequency questionnaire. the basal metabolic rate (bmr) was used as the predicted minimal rate of energy expenditure of children. a fully adjusted multiple logistic regression was used to determine the prevalence of obesity (\u2265 95th bmi-for-age percentile) among the quartiles of ei/bmr ratio using the third quartile for the reference. the differences in the age-adjusted mean ei/bmr among the categories of dietary habits, social support, and socio economic status were analyzed using a general linear model. results children with the lowest ei/bmr had significantly higher adjusted odds ratio (aor) of obesity as compared to those in the third quartile of ei/bmr (boys aor 4.3; 95% confidence interval 1.08, 20 and girls aor 4.1; 1.02, 21). in girls, the adjusted mean ei/bmr in the group that prepared food less than the means (3.8 times/week) was significantly lower than the group that prepared food over the means (p = 0.03). further, the group that reported eating breakfast under 4 times/week indicated an adjusted mean ei/bmr lower than the group that ate breakfast over 5 times/week in both sexes. conclusions when ei was under-reported with reference to bmr, we may observe high prevalence of obesity. further, food preparation by children and frequent consumption of breakfast may instill food cognition with usual dietary habits. therefore, holistic assessments including dietary habits are required to examine self-reported food intake especially among overweight/obese children.",
            "contribution_ids": [
                "R171279"
            ]
        },
        {
            "instance_id": "EMPTYxR74317",
            "comparison_id": "EMPTY",
            "paper_id": "R74317",
            "text": "Impact of COVID-19 pandemic on mobility in ten countries and associated perceived risk for all transport modes the restrictive measures implemented in response to the covid-19 pandemic have triggered sudden massive changes to travel behaviors of people all around the world. this study examines the individual mobility patterns for all transport modes (walk, bicycle, motorcycle, car driven alone, car driven in company, bus, subway, tram, train, airplane) before and during the restrictions adopted in ten countries on six continents: australia, brazil, china, ghana, india, iran, italy, norway, south africa and the united states. this cross-country study also aims at understanding the predictors of protective behaviors related to the transport sector and covid-19. findings hinge upon an online survey conducted in may 2020 (n = 9,394). the empirical results quantify tremendous disruptions for both commuting and non-commuting travels, highlighting substantial reductions in the frequency of all types of trips and use of all modes. in terms of potential virus spread, airplanes and buses are perceived to be the riskiest transport modes, while avoidance of public transport is consistently found across the countries. according to the protection motivation theory, the study sheds new light on the fact that two indicators, namely income inequality, expressed as gini index, and the reported number of deaths due to covid-19 per 100,000 inhabitants, aggravate respondents\u2019 perceptions. this research indicates that socio-economic inequality and morbidity are not only related to actual health risks, as well documented in the relevant literature, but also to the perceived risks. these findings document the global impact of the covid-19 crisis as well as provide guidance for transportation practitioners in developing future strategies.",
            "contribution_ids": [
                "R74325"
            ]
        },
        {
            "instance_id": "EMPTYxR155530",
            "comparison_id": "EMPTY",
            "paper_id": "R155530",
            "text": "Nitrogen budgets following a Lagrangian strategy in the Western Tropical South Pacific Ocean: the prominent role of N&lt;sub&gt;2&lt;/sub&gt; fixation (OUTPACE cruise) abstract. we performed n budgets at three stations in the western tropical south pacific (wtsp) ocean during austral summer conditions (feb. mar. 2015) and quantified all major n fluxes both entering the system (n2 fixation, nitrate eddy diffusion, atmospheric deposition) and leaving the system (pn export). thanks to a lagrangian strategy, we sampled the same water mass for the entire duration of each long duration (5 days) station, allowing to consider only vertical exchanges. two stations located at the western end of the transect (melanesian archipelago (ma) waters, ld a and ld b) were oligotrophic and characterized by a deep chlorophyll maximum (dcm) located at 51\\u2009\u00b1\\u200918\\u2009m and 81\\u2009\u00b1\\u20099\\u2009m at ld a and ld b. station ld c was characterized by a dcm located at 132\\u2009\u00b1\\u20097\\u2009m, representative of the ultra-oligotrophic waters of the south pacific gyre (spg water). n2 fixation rates were extremely high at both ld a (593\\u2009\u00b1\\u200951\\u2009\u00b5mol\\u2009n\\u2009m\u22122\\u2009d\u22121) and ld b (706\\u2009\u00b1\\u2009302\\u2009\u00b5mol\\u2009n\\u2009m\u22122\\u2009d\u22121), and the diazotroph community was dominated by trichodesmium. n2 fixation rates were lower (59\\u2009\u00b1\\u200916\\u2009\u00b5mol\\u2009n\\u2009m\u22122\\u2009d\u22121) at ld c and the diazotroph community was dominated by unicellular n2-fixing cyanobacteria (ucyn). at all stations, n2 fixation was the major source of new n (&gt;\\u200990\\u2009%) before atmospheric deposition and upward nitrate fluxes induced by turbulence. n2 fixation contributed circa 8\u201312\\u2009% of primary production in the ma region and 3\\u2009% in the spg water and sustained nearly all new primary production at all stations. the e-ratio (e-ratio\\u2009=\\u2009pc export/pp) was maximum at ld a (9.7\\u2009%) and was higher than the e-ratio in most studied oligotrophic regions (~\\u20091\\u2009%), indicating a high efficiency of the wtsp to export carbon relative to primary production. the direct export of diazotrophs assessed by qpcr of the nifh gene in sediment traps represented up to 30.6\\u2009% of the pc export at ld a, while there contribution was 5 and \\n",
            "contribution_ids": [
                "R155531"
            ]
        },
        {
            "instance_id": "EMPTYxR195998",
            "comparison_id": "EMPTY",
            "paper_id": "R195998",
            "text": "Mining Associations Between Quality Concerns and Functional Requirements the cost and effort of developing software systems in a new technical area can be extensive. an organization must perform a domain analysis to discover competing products, analyze their architectures and features, and ultimately discover and specify product requirements. however, delivering high quality products, depends not only on gaining an understanding of functional requirements, but also of qualities such as performance, reliability, security, and usability. discovering such concerns early in the requirements process drives architectural design decisions. this paper extends our prior work on mining functional requirements from large collections of domain documents, by proposing and evaluating a new technique for discovering and specifying quality concerns related to specific functional components. we evaluate our approach against three domains of positive train control, electronic health records, and medical infusion pumps, and show that it significantly outperforms a basic information retrieval approach. finally we classified the forms of retrieved information, discussed the utility of different types, and conducted a small study with an experienced engineer to investigate the quality of requirements produced using our approach.",
            "contribution_ids": [
                "R195999"
            ]
        },
        {
            "instance_id": "EMPTYxR78423",
            "comparison_id": "EMPTY",
            "paper_id": "R78423",
            "text": "Regional Competitiveness as an Aspect Promoting Sustainability of Latvia providing of sustainability is one of the main priorities in normative documents in various countries. factors affecting regional competitiveness is seen as close to them determining sustainability in many researches. the aim of this research was to identify and evaluate main factors of competitiveness for statistical regions of latvia to promote sustainable development of the country, applying the complex regional competitiveness assessment system developed by the author. the analysis of the regional competitiveness index (rci) and its sub-indexes showed that each statistical region has both: factors promoting and hindering competitiveness. overall the most competitive is riga statistical region, but the last place takes latgale statistical region. it is possible to promote equal regional development and sustainability of latvia by implementing well-developed regional development strategy and national action plan. to develop such strategies, it is necessary to understand the concept of sustainable competitiveness. to evaluate sustainable competitiveness of latvia and its regions it is necessary to develop further the methodology of regional competitiveness evaluation.",
            "contribution_ids": [
                "R78425"
            ]
        },
        {
            "instance_id": "EMPTYxR189450",
            "comparison_id": "EMPTY",
            "paper_id": "R189450",
            "text": "FNG-IE: an improved graph-based method for keyword extraction from scholarly big-data keyword extraction is essential in determining influenced keywords from huge documents as the research repositories are becoming massive in volume day by day. the research community is drowning in data and starving for information. the keywords are the words that describe the theme of the whole document in a precise way by consisting of just a few words. furthermore, many state-of-the-art approaches are available for keyword extraction from a huge collection of documents and are classified into three types, the statistical approaches, machine learning, and graph-based methods. the machine learning approaches require a large training dataset that needs to be developed manually by domain experts, which sometimes is difficult to produce while determining influenced keywords. however, this research focused on enhancing state-of-the-art graph-based methods to extract keywords when the training dataset is unavailable. this research first converted the handcrafted dataset, collected from impact factor journals into n -grams combinations, ranging from unigram to pentagram and also enhanced traditional graph-based approaches. the experiment was conducted on a handcrafted dataset, and all methods were applied on it. domain experts performed the user study to evaluate the results. the results were observed from every method and were evaluated with the user study using precision, recall and f-measure as evaluation matrices. the results showed that the proposed method (fng-ie) performed well and scored near the machine learning approaches score.",
            "contribution_ids": [
                "R189454"
            ]
        },
        {
            "instance_id": "EMPTYxR110128",
            "comparison_id": "EMPTY",
            "paper_id": "R110128",
            "text": "Mixed language usage in Belarus: the sociostructural background of language choice abstract this article reports findings from a survey on language usage in belarus, which encompasses bilingual belarusian and russian. first, the distribution of language usage is discussed. then the dependency of language usage on some sociocultural conditions is explored. finally, the changes in language usage over three generations are discussed. we find that a mixed belarusian\u2013russian form of speech is widely used in the cities studied and that it is spoken across all educational levels. however, it seems to be predominantly utilized in informal communication, especially among friends and family members, leaving russian and belarusian to more formal or public venues.",
            "contribution_ids": [
                "R110130"
            ]
        },
        {
            "instance_id": "EMPTYxR170142",
            "comparison_id": "EMPTY",
            "paper_id": "R170142",
            "text": "Trophic ecology of sympatric small cats in the Brazilian Pampa information about resource partitioning among small cat species that live in sympatry in south america is fairly incomplete. knowledge about feeding habits is essential for understanding the role of these predators in the environment, the impact on prey populations, and potential competition among themselves and with other carnivores. this study aimed to describe and compare the diet of four sympatric small cats in the grasslands of southern brazil. we analysed the stomach contents of 37 geoffroy\u2019s cats (leopardus geoffroyi), 27 margays (leopardus wiedii), 14 pampas cats (leopardus colocola), and 20 jaguarundis (herpailurus yagouaroundi) obtained as road kill in the brazilian pampa in southern brazil. small mammals were the most representative class consumed by all cats, followed by aves, reptilia, and amphibia. some items, such as rodents cavia aperea, akodon sp., oligoryzomys sp. and passeriformes were consumed by all cat species. niche overlap varied widely, from 10% (margay x jaguarundi) to 92% (jaguarundi x pampas cat). niche breadth indicated that jaguarundi were the most specialized of the cats (bsta = 0.24) in this region, with a diet closely associated to c. aperea. margay consumed more items associated with arboreal behaviour than other cat species, but consumed more terrestrial items than arboreal ones. the pampas cat consumed mostly terrestrial species associated with open fields. geoffroy\u2019s cat consumed mammals found in a diversity of habitats, indicating high ecological flexibility. species with more similarity in diet such as jaguarundi and pampas cat probably present temporal segregation in activity. in conclusion, despite their habitat and diet similarities, these four species explore distinct microhabitats by foraging different prey groups, what favor them to live in sympatry.",
            "contribution_ids": [
                "R170143"
            ]
        },
        {
            "instance_id": "EMPTYxR110605",
            "comparison_id": "EMPTY",
            "paper_id": "R110605",
            "text": "Epigenetic Hallmarks of Fetal Early Atherosclerotic Lesions in Humans importance although increasingly strong evidence suggests a role of maternal total cholesterol and low-density lipoprotein cholesterol (ldlc) levels during pregnancy as a risk factor for atherosclerotic disease in the offspring, the underlying mechanisms need to be clarified for future clinical applications. objective to test whether epigenetic signatures characterize early fetal atherogenesis associated with maternal hypercholesterolemia and to provide a quantitative estimate of the contribution of maternal cholesterol level to fetal lesion size. design, setting, and participants this autopsy study analyzed 78 human fetal aorta autopsy samples from the division of human pathology, department of advanced biomedical sciences, federico ii university of naples, naples, italy. maternal levels of total cholesterol, ldlc, high-density lipoprotein cholesterol (hdlc), triglycerides, and glucose and body mass index (bmi) were determined during hospitalization owing to spontaneous fetal death. data were collected and immediately processed and analyzed to prevent degradation from january 1, 2011, through november 30, 2016. main outcomes and measurements results of dna methylation and messenger rna levels of the following genes involved in cholesterol metabolism were assessed: superoxide dismutase 2 (sod2), low-density lipoprotein receptor (ldlr), sterol regulatory element binding protein 2 (srebp2), liver x receptor &agr; (lxr&agr;), and adenosine triphosphate\u2013binding cassette transporter 1 (abca1). results among the 78 fetal samples included in the analysis (59% male; mean [sd] fetal age, 25 [3] weeks), maternal cholesterol level explained a significant proportion of the fetal aortic lesion variance in multivariate analysis (61%; p\\u2009=\\u2009.001) independently by the effect of levels of hdlc, triglycerides, and glucose and bmi. moreover, maternal total cholesterol and ldlc levels were positively associated with methylation of srebp2 in fetal aortas (pearson correlation, 0.488 and 0.503, respectively), whereas in univariate analysis, they were inversely correlated with srebp2 messenger rna levels in fetal aortas (pearson correlation, \u22120.534 and \u22120.671, respectively). epivariations of genes controlling cholesterol metabolism in cholesterol-treated human aortic endothelial cells were also observed. conclusions and relevance the present study provides a stringent quantitative estimate of the magnitude of the association of maternal cholesterol levels during pregnancy with fetal aortic lesions and reveals the epigenetic response of fetal aortic srebp2 to maternal cholesterol level. the role of maternal cholesterol level during pregnancy and epigenetic signature in offspring in cardiovascular primary prevention warrants further long-term causal relationship studies.",
            "contribution_ids": [
                "R110607"
            ]
        },
        {
            "instance_id": "EMPTYxR68609",
            "comparison_id": "EMPTY",
            "paper_id": "R68609",
            "text": "If the Engineering Literature Fits, Use It! Student Application of Grey Literature and Engineering Standards the acrl information literacy standards include the need for students to use information effectively to accomplish a specific purpose. to use information for a specific purpose students should have an ability to differentiate the types of information available, assess the relevance and credibility of the source to their application, and then apply the information within the context of their writing. engineering students are usually aware of monographs and periodicals from introductory library instruction but are unfamiliar with grey literature and engineering standards. to address this need, collaboration between library and engineering instruction for a senior level capstone mechanical engineering design course was created. the course consisted of 3 independent sections of approximately 18 students each that were randomly paired and assigned projects from the same pool of 10 system-level experiments. the students were tasked with developing a full analysis and report of the system-level performance of their respective experiment. library instruction occurred during the second lecture of class and consisted of a fifty minute overview presentation followed by two hours of work time. all sections were presented information types as five different categories: monographs, scholarly articles, grey literature, standards, and multimedia. one section of the class was randomly selected and presented information types placed into contextual uses within example sections of a report and assigned a worksheet requiring them to find sources specific to their project and list them within the report section they planned to implement the literature. the efficacy of this pedagogical change to contextualize examples followed by immediate application was assessed by measuring the frequency and type of citations used by all 3 sections of the class. citation analysis found a statistically insignificant 7% increase in total number of citations used by the test section students. although the utilization of engineering standards did not increase, the use of grey literature in the test section increase 83% compared with the two control sections taught by the same engineering faculty. furthermore the test section decreased their use of multimedia information. two subsequent sections of the course taught by other engineering faculty are also compared. this provides a preliminary indication that contextualizing library instruction by information type increases the diversity of literature utilized by engineering students. the overall credibility of citations utilized by students in their reports is likely to increase if this diversity increases the use of grey literature and standards.",
            "contribution_ids": [
                "R68611"
            ]
        },
        {
            "instance_id": "EMPTYxR201754",
            "comparison_id": "EMPTY",
            "paper_id": "R201754",
            "text": "Augmented personalized health: How smart data with IoTs and AI is about to change healthcare healthcare as we know it is in the process of going through a massive change \u2014 from episodic to continuous, from disease focused to wellness and quality of life focused, from clinic centric to anywhere a patient is, from clinician controlled to patient empowered, and from being driven by limited data to 360-degree, multimodal personal-public-population physical-cyber-social big data driven. while ability to create and capture data is already here, the upcoming innovations will be in converting this big data into smart data through contextual and personalized processing such that patients and clinicians can make better decisions and take timely actions for augmented personalized health. this paper outlines current opportunities and challenges, with a focus on key ai approaches to make this a reality. the broader vision is exemplified using three ongoing applications (asthma in children, bariatric surgery, and pain management) as part of the kno.e.sis khealth personalized digital health initiative.",
            "contribution_ids": [
                "R201756"
            ]
        },
        {
            "instance_id": "EMPTYxR160558",
            "comparison_id": "EMPTY",
            "paper_id": "R160558",
            "text": "Classification of Iowa wetlands using an airborne hyperspectral image: a comparison of the spectral angle mapper classifier and an object-oriented approach \"wetlands mapping using multispectral imagery from landsat multispectral scanner (mss) and thematic mapper (tm) and syst\u00e8me pour l'observation de la terre (spot) does not in general provide high classification accuracies because of poor spectral and spatial resolutions. this study tests the feasibility of using high-resolution hyperspectral imagery to map wetlands in iowa with two nontraditional classification techniques: the spectral angle mapper (sam) method and a new nonparametric object-oriented (oo) classification. the software programs used were envi and ecognition. accuracies of these classified images were assessed by using the information collected through a field survey with a global positioning system and high-resolution color infrared images. wetlands were identified more accurately with the oo method (overall accuracy 92.3%) than with sam (63.53%). this paper also discusses the limitations of these classification techniques for wetlands, as well as discussing future directions for study.\"",
            "contribution_ids": [
                "R160560"
            ]
        },
        {
            "instance_id": "EMPTYxR170431",
            "comparison_id": "EMPTY",
            "paper_id": "R170431",
            "text": "Associations of Insulin and Insulin-Like Growth Factors with Physical Performance in Old Age in the Boyd Orr and Caerphilly Studies objective insulin and the insulin-like growth factor (igf) system regulate growth and are involved in determining muscle mass, strength and body composition. we hypothesised that igf-i and igf-ii are associated with improved, and insulin with worse, physical performance in old age. methods physical performance was measured using the get-up and go timed walk and flamingo balance test at 63\u201386 years. we examined prospective associations of insulin, igf-i, igf-ii and igfbp-3 with physical performance in the uk-based caerphilly prospective study (caps; n\\u200a=\\u200a739 men); and cross-sectional insulin, igf-i, igf-ii, igfbp-2 and igfbp-3 in the boyd orr cohort (n\\u200a=\\u200a182 men, 223 women). results in confounder-adjusted models, there was some evidence in caps that a standard deviation (sd) increase in igf-i was associated with 1.5% faster get-up and go test times (95% ci: \u22120.2%, 3.2%; p\\u200a=\\u200a0.08), but little association with poor balance, 19 years later. coefficients in boyd orr were in the same direction as caps, but consistent with chance. higher levels of insulin were weakly associated with worse physical performance (caps and boyd orr combined: get-up and go time\\u200a=\\u200a1.3% slower per sd log-transformed insulin; 95% ci: 0.0%, 2.7%; p\\u200a=\\u200a0.07; or poor balance 1.13; 95% ci; 0.98, 1.29; p\\u200a=\\u200a0.08), although associations were attenuated after controlling for body mass index (bmi) and co-morbidities. in boyd orr, a one sd increase in igfbp-2 was associated with 2.6% slower get-up and go times (95% ci: 0.4%, 4.8% slower; p\\u200a=\\u200a0.02), but this was only seen when controlling for bmi and co-morbidities. there was no consistent evidence of associations of igf-ii, or igfbp-3 with physical performance. conclusions there was some evidence that high igf-i and low insulin levels in middle-age were associated with improved physical performance in old age, but estimates were imprecise. larger cohorts are required to confirm or refute the findings.",
            "contribution_ids": [
                "R170432"
            ]
        },
        {
            "instance_id": "EMPTYxR170558",
            "comparison_id": "EMPTY",
            "paper_id": "R170558",
            "text": "Associations between Perceived HIV Stigma and Quality of Life at the Dyadic Lvel: The Actor-Partner Interdependence Model \"background few studies have investigated the relationship between hiv-related stigma and quality life at the dyadic level. the objective of this study was to examine the actor and partner effects of stigma that was perceived by people living with hiv/aids (plwhas) and caregivers on quality of life at the dyadic level. method a survey was conducted among 148 dyads consisting of one plwha and one caregiver (296 participants) in nanning, china. the interdependent relationship between a pair of dyadic members that influences the associations between stigma and quality of life was analyzed, using an innovative dyadic analysis technique: the actor-partner interdependence model (apim). results we found in this dyadic analysis that (1) plwhas compared to their caregivers exhibited a higher level of perceived hiv stigma and lower level of quality of life measured in four domains; (2) both plwhas' and caregivers' perceived hiv stigma influenced their own quality of life; (3) the quality of life was not substantially influenced by their partners' perceived stigma; and (4) both actor and partner effects of stigma on quality of life were similar among plwhas and their caregivers. conclusion as hiv stigma and quality of life are complex phenomena rooted in cultures, intervention programs should be carefully planned based on social or cognitive theories and should be culturally adopted.\"",
            "contribution_ids": [
                "R170559"
            ]
        },
        {
            "instance_id": "EMPTYxR169576",
            "comparison_id": "EMPTY",
            "paper_id": "R169576",
            "text": "Different Populations of Blacklegged Tick Nymphs Exhibit Differences in Questing Behavior That Have Implications for Human Lyme Disease Risk animal behavior can have profound effects on pathogen transmission and disease incidence. we studied the questing (= host-seeking) behavior of blacklegged tick (ixodes scapularis) nymphs, which are the primary vectors of lyme disease in the eastern united states. lyme disease is common in northern but not in southern regions, and prior ecological studies have found that standard methods used to collect host-seeking nymphs in northern regions are unsuccessful in the south. this led us to hypothesize that there are behavior differences between northern and southern nymphs that alter how readily they are collected, and how likely they are to transmit the etiological agent of lyme disease to humans. to examine this question, we compared the questing behavior of i. scapularis nymphs originating from one northern (lyme disease endemic) and two southern (non-endemic) us regions at field sites in wisconsin, rhode island, tennessee, and florida. laboratory-raised uninfected nymphs were monitored in circular 0.2 m2 arenas containing wooden dowels (mimicking stems of understory vegetation) for 10 (2011) and 19 (2012) weeks. the probability of observing nymphs questing on these stems (2011), and on stems, on top of leaf litter, and on arena walls (2012) was much greater for northern than for southern origin ticks in both years and at all field sites (19.5 times greater in 2011; 3.6\u201311.6 times greater in 2012). our findings suggest that southern origin i. scapularis nymphs rarely emerge from the leaf litter, and consequently are unlikely to contact passing humans. we propose that this difference in questing behavior accounts for observed geographic differences in the efficacy of the standard sampling techniques used to collect questing nymphs. these findings also support our hypothesis that very low lyme disease incidence in southern states is, in part, a consequence of the type of host-seeking behavior exhibited by southern populations of the key lyme disease vector.",
            "contribution_ids": [
                "R169577",
                "R169578",
                "R169579"
            ]
        },
        {
            "instance_id": "EMPTYxR110753",
            "comparison_id": "EMPTY",
            "paper_id": "R110753",
            "text": "Generating Abstractive Summaries from Meeting Transcripts summaries of meetings are very important as they convey the essential content of discussions in a concise form. both participants and non-participants are interested in the summaries of meetings to plan for their future work. generally, it is time consuming to read and understand the whole documents. therefore, summaries play an important role as the readers are interested in only the important context of discussions. in this work, we address the task of meeting document summarization. automatic summarization systems on meeting conversations developed so far have been primarily extractive, resulting in unacceptable summaries that are hard to read. the extracted utterances contain disfluencies that affect the quality of the extractive summaries. to make summaries much more readable, we propose an approach to generating abstractive summaries by fusing important content from several utterances. we first separate meeting transcripts into various topic segments, and then identify the important utterances in each segment using a supervised learning approach. the important utterances are then combined together to generate a one-sentence summary. in the text generation step, the dependency parses of the utterances in each segment are combined together to create a directed graph. the most informative and well-formed sub-graph obtained by integer linear programming (ilp) is selected to generate a one-sentence summary for each topic segment. the ilp formulation reduces disfluencies by leveraging grammatical relations that are more prominent in non-conversational style of text, and therefore generates summaries that is comparable to human-written abstractive summaries. experimental results show that our method can generate more informative summaries than the baselines. in addition, readability assessments by human judges as well as log-likelihood estimates obtained from the dependency parser show that our generated summaries are significantly readable and well-formed.",
            "contribution_ids": [
                "R110755"
            ]
        },
        {
            "instance_id": "EMPTYxR74457",
            "comparison_id": "EMPTY",
            "paper_id": "R74457",
            "text": "Design study of OER-CC ontology: A semantic web approach to describe open educational resources through the application of semantic technologies to describe open educational resources, any agent (human or software-based) could process and understand its contents, therefore, the agent could perform tasks autonomously or in a more effective way. in this paper, we describe the design and validation of the oer-cc ontology, which models the domain knowledge of educational resources licensed under creative commons licenses. one of the most important contributions of this work is that we implement different rules and axioms to identify inconsistencies between rights provided by a licensed on an learning material and particular uses that are performed on it.",
            "contribution_ids": [
                "R74458",
                "R109098"
            ]
        },
        {
            "instance_id": "EMPTYxR155256",
            "comparison_id": "EMPTY",
            "paper_id": "R155256",
            "text": "Dictator games: a meta study over the last 25 years, more than a hundred dictator game experiments have been published. this meta study summarises the evidence. exploiting the fact that most experiments had to fix parameters they did not intend to test, in multiple regression the meta study is able to assess the effect of single manipulations, controlling for a host of alternative explanatory factors. the resulting rich dataset also provides a testbed for comparing alternative specifications of the statistical model for analysing dictator game data. it shows how tobit models (assuming that dictators would even want to take money) and hurdle models (assuming that the decision to give a positive amount is separate from the choice of amount, conditional on giving) provide additional insights.",
            "contribution_ids": [
                "R155258",
                "R164571",
                "R164574"
            ]
        },
        {
            "instance_id": "EMPTYxR49581",
            "comparison_id": "EMPTY",
            "paper_id": "R49581",
            "text": "An Overview of Microsoft Academic Service (MAS) and Applications in this paper we describe a new release of a web scale entity graph that serves as the backbone of microsoft academic service (mas), a major production effort with a broadened scope to the namesake vertical search engine that has been publicly available since 2008 as a research prototype. at the core of mas is a heterogeneous entity graph comprised of six types of entities that model the scholarly activities: field of study, author, institution, paper, venue, and event. in addition to obtaining these entities from the publisher feeds as in the previous effort, we in this version include data mining results from the web index and an in-house knowledge base from bing, a major commercial search engine. as a result of the bing integration, the new mas graph sees significant increase in size, with fresh information streaming in automatically following their discoveries by the search engine. in addition, the rich entity relations included in the knowledge base provide additional signals to disambiguate and enrich the entities within and beyond the academic domain. the number of papers indexed by mas, for instance, has grown from low tens of millions to 83 million while maintaining an above 95% accuracy based on test data sets derived from academic activities at microsoft research. based on the data set, we demonstrate two scenarios in this work: a knowledge driven, highly interactive dialog that seamlessly combines reactive search and proactive suggestion experience, and a proactive heterogeneous entity recommendation.",
            "contribution_ids": [
                "R49596"
            ]
        },
        {
            "instance_id": "EMPTYxR168655",
            "comparison_id": "EMPTY",
            "paper_id": "R168655",
            "text": "ASPASIA: A toolkit for evaluating the effects of biological interventions on SBML model behaviour a calibrated computational model reflects behaviours that are expected or observed in a complex system, providing a baseline upon which sensitivity analysis techniques can be used to analyse pathways that may impact model responses. however, calibration of a model where a behaviour depends on an intervention introduced after a defined time point is difficult, as model responses may be dependent on the conditions at the time the intervention is applied. we present aspasia (automated simulation parameter alteration and sensitivity analysis), a cross-platform, open-source java toolkit that addresses a key deficiency in software tools for understanding the impact an intervention has on system behaviour for models specified in systems biology markup language (sbml). aspasia can generate and modify models using sbml solver output as an initial parameter set, allowing interventions to be applied once a steady state has been reached. additionally, multiple sbml models can be generated where a subset of parameter values are perturbed using local and global sensitivity analysis techniques, revealing the model\u2019s sensitivity to the intervention. to illustrate the capabilities of aspasia, we demonstrate how this tool has generated novel hypotheses regarding the mechanisms by which th17-cell plasticity may be controlled in vivo. by using aspasia in conjunction with an sbml model of th17-cell polarisation, we predict that promotion of the th1-associated transcription factor t-bet, rather than inhibition of the th17-associated transcription factor ror\u03b3t, is sufficient to drive switching of th17 cells towards an ifn-\u03b3-producing phenotype. our approach can be applied to all sbml-encoded models to predict the effect that intervention strategies have on system behaviour. aspasia, released under the artistic license (2.0), can be downloaded from http://www.york.ac.uk/ycil/software.",
            "contribution_ids": [
                "R168656",
                "R168657",
                "R168658"
            ]
        },
        {
            "instance_id": "EMPTYxR111114",
            "comparison_id": "EMPTY",
            "paper_id": "R111114",
            "text": "Development of optimized substitution ratio for wheatcassava-african yam bean flour composite for Nigerian bread industries an optimization study of the mix ratio for substitution of wheat flour with cassava and african yam bean flours (ayb) was carried out and reported in this paper. the aim was to obtain a mix ratio that would optimise selected physical properties of the bread. wheat flour was substituted with cassava and african yam bean flours at different levels: 80% to 100% of wheat, 0% to 10% of cassava flour and 0% to 10% for ayb flour. the experiment was conducted in mixture design which was generated and analysed by design-expert software 11 version. the composite dough was prepared in different mix ratios according to the design matrix and subsequentlybaked under the same conditions and analysed for the following loaf quality attributes: loaf specific volume, bread crumb hardness and crumb colour index as response variables. the objective functions were to maximize loaf specific volume, minimize wheat flour, bread crumb hardness and crumb colour index to obtain the most suitable substitution ratio acceptable to\\xa0 consumers. predictive models for the response variables were developed with the coefficient of determination (r2 ) of 0.991 for loaf specific volume (lsv) while that of bread crumb hardness (bch) and crumb colour index (cci) were 0.834 and 0.895 respectively at 95% confidence interval (ci).the predicted optimal substitution ratio was obtained as follows: 88% wheat flour, 10% cassava flour, and 2% ayb flour. at this formulation, the predicted loaf specific volume was 2.11cm3 /g, bread crumb hardness was 25.12n, and crumb colour index was 18.88.the study shows that addition of 2% of ayb flour in the formulation would help to optimise the lsv, bch and the cci of the wheat-cassava flour bread at the mix ratio of 88:10. application of the results of this study in bread industries will reduce the cost of bread in nigeria, which is influenced by the rising cost of imported wheat. this is a significant development because wheat flour was the sole baking flour in nigeria before wheat substitution initiative.&#x0d;\\nkeywords: bread, wheat, cassava, african yam bean, flour, dough, loaf specific volume, crumb hardness, crumb colour index",
            "contribution_ids": [
                "R111116"
            ]
        },
        {
            "instance_id": "EMPTYxR133207",
            "comparison_id": "EMPTY",
            "paper_id": "R133207",
            "text": "Deep Exploration via Bootstrapped DQN efficient exploration in complex environments remains a major challenge for reinforcement learning. we propose bootstrapped dqn, a simple algorithm that explores in a computationally and statistically efficient manner through use of randomized value functions. unlike dithering strategies such as epsilon-greedy exploration, bootstrapped dqn carries out temporally-extended (or deep) exploration; this can lead to exponentially faster learning. we demonstrate these benefits in complex stochastic mdps and in the large-scale arcade learning environment. bootstrapped dqn substantially improves learning times and performance across most atari games.",
            "contribution_ids": [
                "R133208"
            ]
        },
        {
            "instance_id": "EMPTYxR209121",
            "comparison_id": "EMPTY",
            "paper_id": "R209121",
            "text": "Fake News Identification on Twitter with Hybrid CNN and RNN Models the problem associated with the propagation of fake news continues to grow at an alarming scale. this trend has generated much interest from politics to academia and industry alike. we propose a framework that detects and classifies fake news messages from twitter posts using hybrid of convolutional neural networks and long-short term recurrent neural network models. the proposed work using this deep learning approach achieves 82% accuracy. our approach intuitively identifies relevant features associated with fake news stories without previous knowledge of the domain.",
            "contribution_ids": [
                "R209123"
            ]
        },
        {
            "instance_id": "EMPTYxR70746",
            "comparison_id": "EMPTY",
            "paper_id": "R70746",
            "text": "Measurement invariance of the ICT engagement construct and its association with students\u00e2\u0080\u0099 performance in China and Germany: Evidence from PISA 2015 data \"the present study investigated the factor structure of and measurement invariance in the information and communication technology (ict) engagement construct, and the relationship between ict engagement and students' performance on science, mathematics and reading in china and germany. samples were derived from the programme for international student assessment (pisa) 2015 survey. configural, metric and scalar equivalence were found in a multigroup exploratory structural equation model. in the regression model, a significantly positive association between interest in ict and student achievement was found in china, in contrast to a significantly negative association in germany. all achievement scores were negatively and significantly correlated with perceived ict competence scores in china, whereas science and mathematics achievement scores were not predicted by scores on ict competence in germany. similar patterns were found in china and germany in terms of perceived autonomy in using ict and social relatedness in using ict to predict students' achievement. the implications of all the findings were discussed. [abstract from author]\"",
            "contribution_ids": [
                "R70748"
            ]
        },
        {
            "instance_id": "EMPTYxR195298",
            "comparison_id": "EMPTY",
            "paper_id": "R195298",
            "text": "Social Media Based Topic Modeling for Smart Campus: A Deep Topical Correlation Analysis Method smart campus builds on characteristic learning and feedback evaluation of diverse students and aims to enable intelligent, accurate, and customized education. mining social media data, especially topic modeling, from students, provides a non-intrusive method to know the instantaneous thoughts and willings of them. however, it is challenging to deal with multi-modal data (i.e., text, images, and videos contained in the social media data) as well as the modality dependence and missing modality. in this paper, we present a novel deep topical correlation analysis (dtca) approach, which achieves robust and accurate topic detection for microblogs and simultaneously handles the two challenges aforementioned. in particular, bidirectional recurrent neural networks and convolutional neural networks are used to learn deep textual and visual features, respectively. then, a canonical correlation analysis-based fusion scheme is proposed, which has two innovations to deal with both modality independence and modality missing, i.e., a filter gate to capture the modality dependency and a matrix-projection based component to handle the missing modality. dtca is trained in an end-to-end manner, in which the parameters of visual, textual, and cross-modal prediction parts are trained jointly. we further release a large-scale cross-modal twitter dataset for topic detection, denoted as tm-twitter. on this dataset, extensive and quantitative evaluations are conducted with comparisons to several state-of-the-art and alternative approaches. significant performance gains are reported to demonstrate the merits of the proposed dtca.",
            "contribution_ids": [
                "R195300"
            ]
        },
        {
            "instance_id": "EMPTYxR74695",
            "comparison_id": "EMPTY",
            "paper_id": "R74695",
            "text": "Development of a reconstruction quality metric for optical three-dimensional measurement systems in use for hot-state measurement object abstract. optical three-dimensional (3-d) geometry measurements are state of the art when it comes to contactless quality control and maintenance of the shape of technical components that exclude tactile measurements due to filigree or internal structures. optical inspection methods are also characterized by a fast and high-resolution 3-d inspection of complex geometries. and due to their noncontact principle, they can carry out measurements in places that would otherwise not be accessible due to harsh environmental conditions or specimens such as hot forged parts. however, there are currently no methods to estimate the reconstruction quality for the optical 3-d geometry measurements of hot objects. the mainly used geometric measurement standards cannot be used for the characterization of hot measurements since the calibrated geometrical values are not transferable to high temperatures. for the development of such a metric, we present the fundamentals of the concepts and algorithms for an estimation of the reconstruction quality are presented and evaluated using a two-dimensional simulation model. the generated findings were applied to the 3-d geometry measurement of a hot object in a laboratory environment. the results are compared with general state-of-the-art reconstruction quality metrics.",
            "contribution_ids": [
                "R74697"
            ]
        },
        {
            "instance_id": "EMPTYxR75893",
            "comparison_id": "EMPTY",
            "paper_id": "R75893",
            "text": "Interpretable Multi-Modal Hate Speech Detection with growing role of social media in shaping public opinions and beliefs across the world, there has been an increased attention to identify and counter the problem of hate speech on social media. hate speech on online spaces has serious manifestations, including social polarization and hate crimes. while prior works have proposed automated techniques to detect hate speech online, these techniques primarily fail to look beyond the textual content. moreover, few attempts have been made to focus on the aspects of interpretability of such models given the social and legal implications of incorrect predictions. in this work, we propose a deep neural multi-modal model that can: (a) detect hate speech by effectively capturing the semantics of the text along with socio-cultural context in which a particular hate expression is made, and (b) provide interpretable insights into decisions of our model. by performing a thorough evaluation of different modeling techniques, we demonstrate that our model is able to outperform the existing state-of-the-art hate speech classification approaches. finally, we show the importance of social and cultural context features towards unearthing clusters associated with different categories of hate.",
            "contribution_ids": [
                "R75894"
            ]
        },
        {
            "instance_id": "EMPTYxR169703",
            "comparison_id": "EMPTY",
            "paper_id": "R169703",
            "text": "Biomarkers of Exposure to Polycyclic Aromatic Hydrocarbons and Cognitive Function among Elderly in the United States (National Health and Nutrition Examination Survey: 2001-2002) recent studies report a link between common environmental exposures, such as particulate matter air pollution and tobacco smoke, and decline in cognitive function. the purpose of this study was to assess the association between exposure to polycyclic aromatic hydrocarbons (pahs), a selected group of chemicals present in particulate matter and tobacco smoke, and measures of cognitive performance among elderly in the general population. this cross-sectional analysis involved data from 454 individuals aged 60 years and older from the 2001\u20132002 national health and nutrition examination survey. the association between pah exposures (as measured by urinary biomarkers) and cognitive function (digit symbol substitution test (dsst)) was assessed using multiple linear regression analyses. after adjusting for age, socio-economic status and diabetes we observed a negative association between urinary 1-hydroxypyrene, the gold standard of pah exposure biomarkers, and dsst score. a one percent increase in urinary 1-hydroxypyrene resulted in approximately a 1.8 percent poorer performance on the digit symbol substitution test. our findings are consistent with previous publications and further suggest that pahs, at least in part may be responsible for the adverse cognitive effects linked to tobacco smoke and particulate matter air pollution.",
            "contribution_ids": [
                "R169704"
            ]
        },
        {
            "instance_id": "EMPTYxR136477",
            "comparison_id": "EMPTY",
            "paper_id": "R136477",
            "text": "Communicating with Sensation Seekers: An fMRI Study of Neural Responses to Antidrug Public Service Announcements abstract this study examined the neural basis of processing high- and low-message sensation value (msv) antidrug public service announcements (psas) in high (hss) and low sensation seekers (lss) using fmri. hss more strongly engaged the salience network when processing psas (versus lss), suggesting that high-msv psas attracted their attention. hss and lss participants who engaged higher level cognitive processing regions reported that the psas were more convincing and believable and recalled the psas better immediately after testing. in contrast, hss and lss participants who strongly engaged visual attention regions for viewing psas reported lower personal relevance. these findings provide neurobiological evidence that high-msv content is salient to hss, a primary target group for antidrug messages, and additional cognitive processing is associated with higher perceived message effectiveness.",
            "contribution_ids": [
                "R136479"
            ]
        },
        {
            "instance_id": "EMPTYxR169714",
            "comparison_id": "EMPTY",
            "paper_id": "R169714",
            "text": "Modelling Visual Change Detection and Identification under Free Viewing Conditions we examined whether the abilities of observers to perform an analogue of a real-world monitoring task involving detection and identification of changes to items in a visual display could be explained better by models based on signal detection theory (sdt) or high threshold theory (htt). our study differed from most previous studies in that observers were allowed to inspect the initial display for 3s, simulating the long inspection times typical of natural viewing, and their eye movements were not constrained. for the majority of observers, combined change detection and identification performance was best modelled by a sdt-based process that assumed that memory resources were distributed across all eight items in our displays. some observers required a parameter to allow for sometimes making random guesses at the identities of changes they had missed. however, the performance of a small proportion of observers was best explained by a htt-based model that allowed for lapses of attention.",
            "contribution_ids": [
                "R169715"
            ]
        },
        {
            "instance_id": "EMPTYxR74398",
            "comparison_id": "EMPTY",
            "paper_id": "R74398",
            "text": "Guidelines to producing structured interoperable data from Open Access Repositories one of the fundamental concepts of open educational resources (oer) is \u201cthe ability to freely adapt and reuse existing pieces of knowledge.\u201d the application of semantic web approach and linked data technologies to open education seeks to turn data and metadata from open educational repositories into actionable interoperability for the improvement of discovering, using and reusing of oer. interoperability is not an end in itself. instead, optimizing the level of interoperability has societal and educational value as a means to others purposes. interoperability can have a positive impact on open innovation, user choice, ease to reuse and adapt educational materials, global discovery of open and diverse content, among other things. this paper reports on the implementation of linked open data for open access repositories in a new interoperable and global open educational ecosystem. the goal is to improve the metadata interoperability between various collections of open material, so as to facilitate the discoverability and subsequent combining, remixing, or adapting oer; that is, oer data should be easily accessible to any user: human being or a machine agent. this work addressed two challenges in the oer ecosystem: providing evidence of globally discoverability and reusability academic resources. although there is much further potential for teaching and learning to realize, linked open data is a critical enabler of global and interoperable oer ecosystem.",
            "contribution_ids": [
                "R74399",
                "R109064"
            ]
        },
        {
            "instance_id": "EMPTYxR170201",
            "comparison_id": "EMPTY",
            "paper_id": "R170201",
            "text": "Do coaching style and game circumstances predict athletes' perceived justice of their coach? A longitudinal study in elite handball and volleyball teams objective the present longitudinal study is the first to examine game to game fluctuations of perceived justice of elite volleyball and handball coaches. more specifically, we studied whether coaching style (i.e., need support versus control), coach behaviors (decision justifications), player\u2019s status (i.e., starter or substitute), and game result (win/loss) predicted athletes\u2019 perceived justice and its fluctuations. methods a longitudinal questionnaire study was performed during 6 consecutive weeks among belgian female volleyball (n = 57) and male handball players (n = 39). we administered a general questionnaire (i.e., need support/control) the first week, and game-specific questionnaires (i.e., justice, decision justifications, game circumstances) after six consecutive games. because game-to-game measures (i.e., within-athlete) were nested into individuals (between-athletes) we conducted hierarchical linear modeling to examine the hypotheses. results multilevel analyses showed that 49% of the variance of perceived justice was situated at the within-athlete level. furthermore, coaches\u2019 need support and the provision of decision justifications were positive predictors of athletes\u2019 perceived justice of the coach. more specific, the impact of justifications was less strong in a high need supportive environment and stronger in a high controlling environment. finally, both the status of the player and the game result were negative predictors of athletes\u2019 perceived justice. conclusions we can conclude that athletes\u2019 perceived justice of their coach shifts considerably from game-to-game. furthermore, the coaching style and coaching behaviors can help to overcome the negative effects of specific game circumstances such as being a substitute or losing a game on athletes\u2019 perceived justice of the coach.",
            "contribution_ids": [
                "R170202"
            ]
        },
        {
            "instance_id": "EMPTYxR171132",
            "comparison_id": "EMPTY",
            "paper_id": "R171132",
            "text": "Promoting Healthy Behaviors among Egyptian Mothers: A Quasi-Experimental Study of a Health Communication Package Delivered by Community Organizations decisions made at the household level, for example, to seek antenatal care or breastfeed, can have a direct impact on the health of mothers and newborns. the smart community-based initiatives program in egypt worked with community development associations to encourage better household decision-making by training community health workers to disseminate information and encourage healthy practices during home visits, group sessions, and community activities with pregnant women, mothers of young children, and their families. a quasi-experimental design was used to evaluate the program, with household surveys conducted before and after the intervention in intervention and comparison areas. survey questions asked about women\u2019s knowledge and behaviors related to maternal and newborn care and child nutrition and, at the endline, exposure to smart activities. exposure to program activities was high in intervention areas of upper egypt: 91% of respondents reported receiving home visits and 84% attended group sessions. in lower egypt, these figures were 58% and 48%, respectively. knowledge of danger signs related to pregnancy, delivery, and newborn illness increased significantly more in intervention than comparison areas in both regions (with one exception in lower egypt), after controlling for child\u2019s age and woman\u2019s education; this pattern also occurred for two of five behaviors (antenatal care visits and consumption of iron-folate tablets). findings suggest that there may have been a significant dose-response relationship between exposure to smart activities and certain knowledge and behavioral indicators, especially in upper egypt. the findings demonstrate the ability of civil society organizations with minimal health programming experience to increase knowledge and promote healthy behaviors among pregnant women and new mothers. the smart approach offers a promising strategy to fill gaps in health education and counseling and strengthen community support for behavior change.",
            "contribution_ids": [
                "R171133"
            ]
        },
        {
            "instance_id": "EMPTYxR74481",
            "comparison_id": "EMPTY",
            "paper_id": "R74481",
            "text": "Open educational resources and standards in the eMadrid network this paper presents the main results achieved in the program emadrid program in open educational resources, free software, open data, and about formats and standardization of content and services.",
            "contribution_ids": [
                "R74482",
                "R109111"
            ]
        },
        {
            "instance_id": "EMPTYxR131877",
            "comparison_id": "EMPTY",
            "paper_id": "R131877",
            "text": "A Distributional Perspective on Reinforcement Learning \"in this paper we argue for the fundamental importance of the value distribution: the distribution of the random return received by a reinforcement learning agent. this is in contrast to the common approach to reinforcement learning which models the expectation of this return, or value. although there is an established body of literature studying the value distribution, thus far it has always been used for a specific purpose such as implementing risk-aware behaviour. we begin with theoretical results in both the policy evaluation and control settings, exposing a significant distributional instability in the latter. we then use the distributional perspective to design a new algorithm which applies bellman's equation to the learning of approximate value distributions. we evaluate our algorithm using the suite of games from the arcade learning environment. we obtain both state-of-the-art results and anecdotal evidence demonstrating the importance of the value distribution in approximate reinforcement learning. finally, we combine theoretical and empirical evidence to highlight the ways in which the value distribution impacts learning in the approximate setting.\"",
            "contribution_ids": [
                "R131878",
                "R131977"
            ]
        },
        {
            "instance_id": "EMPTYxR188116",
            "comparison_id": "EMPTY",
            "paper_id": "R188116",
            "text": "Construction of a Linked Data Set of COVID-19 Knowledge Graphs: Development and Applications background with the continuous spread of covid-19, information about the worldwide pandemic is exploding. therefore, it is necessary and significant to organize such a large amount of information. as the key branch of artificial intelligence, a knowledge graph (kg) is helpful to structure, reason, and understand data. objective to improve the utilization value of the information and effectively aid researchers to combat covid-19, we have constructed and successively released a unified linked data set named openkg-covid19, which is one of the largest existing kgs related to covid-19. openkg-covid19 includes 10 interlinked covid-19 subgraphs covering the topics of encyclopedia, concept, medical, research, event, health, epidemiology, goods, prevention, and character. methods in this paper, we introduce the key techniques exploited in building covid-19 kgs in a top-down manner. first, the schema of the modeling process for each kg in openkg-covid19 is described. second, we propose different methods for extracting knowledge from open government sites, professional texts, public domain\u2013specific sources, and public encyclopedia sites. the curated 10 covid-19 kgs are further linked together at both the schema and data levels. in addition, we present the naming convention for openkg-covid19. results openkg-covid19 has more than 2572 concepts, 329,600 entities, 513 properties, and 2,687,329 facts, and the data set will be updated continuously. each covid-19 kg was evaluated, and the average precision was found to be above 93%. we have developed search and browse interfaces and a sparql endpoint to improve user access. possible intelligent applications based on openkg-covid19 for further development are also described. conclusions a kg is useful for intelligent question-answering, semantic searches, recommendation systems, visualization analysis, and decision-making support. research related to covid-19, biomedicine, and many other communities can benefit from openkg-covid19. furthermore, the 10 kgs will be continuously updated to ensure that the public will have access to sufficient and up-to-date knowledge.",
            "contribution_ids": [
                "R188118"
            ]
        },
        {
            "instance_id": "EMPTYxR171453",
            "comparison_id": "EMPTY",
            "paper_id": "R171453",
            "text": "Validation of the child and youth resilience measure among South African adolescents resilience is a dynamic, interactive process between resources that contribute to safeguarding a person and the adversities they experience. within this promotional framework of resilience, this study sought to validate the child and youth resilience measure (cyrm-28) among a sample of south african adolescents (n = 1854). confirmatory factor analysis supported a superior level of fit for a 24-item, three-factor model (i.e., individual/social, familial, and community/spiritual). internal consistency and test-retest reliability estimates at a 12-month interval (n = 648) supported the reliability of the scales. higher scores on the scales were associated with feeling more connected at school, greater parental monitoring perceptions, and lower sexual risk, confirming the convergent and criterion validity of the instrument. partial discriminative power was evidenced based on selected scale distinctions according to age and sex groupings. collectively, the findings suggest the 24-item cyrm is a valid and reliable self-report measure to assess the availability of resources associated with resilience in south african youth.",
            "contribution_ids": [
                "R171454",
                "R171455"
            ]
        },
        {
            "instance_id": "EMPTYxR110509",
            "comparison_id": "EMPTY",
            "paper_id": "R110509",
            "text": "Dominant factors that govern pressure natriuresis in diuresis and antidiuresis: a mathematical model we have developed a whole kidney model of the urine concentrating mechanism and renal autoregulation. the model represents the tubuloglomerular feedback (tgf) and myogenic mechanisms, which together affect the resistance of the afferent arteriole and thus glomerular filtration rate. tgf is activated by fluctuations in macula densa [cl \u2212 ] and the myogefnic mechanism by changes in hydrostatic pressure. the model was used to investigate the relative contributions of medullary blood flow autoregulation and inhibition of transport in the proximal convoluted tubule to pressure natriuresis in both diuresis and antidiuresis. the model predicts that medullary blood flow autoregulation, which only affects the interstitial solute composition in the model, has negligible influence on the rate of nacl excretion. however, it exerts a significant effect on urine flow, particularly in the antidiuretic kidney. this suggests that interstitial washout has significant implications for the maintenance of hydration status but little direct bearing on salt excretion, and that medullary blood flow may only play a signaling role for stimulating a pressure-natriuresis response. inhibited reabsorption in the model proximal convoluted tubule is capable of driving pressure natriuresis when the known actions of vasopressin on the collecting duct epithelium are taken into account.",
            "contribution_ids": [
                "R110510"
            ]
        },
        {
            "instance_id": "EMPTYxR170586",
            "comparison_id": "EMPTY",
            "paper_id": "R170586",
            "text": "Neuropsychological and Socio-Occupational Functioning in Young Psychiatric Outpatients: A Longitudinal Investigation background clinical symptoms and neuropsychological deficits are longitudinally associated with functional outcome in chronic psychiatric cohorts. the current study extended these findings to young and early-course psychiatric outpatients, with the aim of identifying cognitive markers that predict later socio-occupational functioning. methods at baseline, 183 young psychiatric outpatients were assessed. ninety-three returned for follow-up (m\\u200a=\\u200a21.6 years old; sd\\u200a=\\u200a4.5) with an average re-assessment interval of 21.6 months (sd\\u200a=\\u200a7.0), and primary diagnoses of major depressive disorder (n\\u200a=\\u200a34), bipolar disorder (n\\u200a=\\u200a29), or psychosis (n\\u200a=\\u200a30). the primary outcome measure was cross-validated with various other functional measures and structural equation modelling was used to map out the interrelationships between predictors and later functional outcome. results good socio-occupational functioning at follow-up was associated with better quality of life, less disability, current employment and being in a romantic relationship. the final structural equation model explained 47.5% of the variability in functional outcome at follow-up, with baseline neuropsychological functioning (a composite of memory, working memory and attentional switching) the best independent predictor of later functional outcome. notably, depressive and negative symptoms were only associated with functioning cross-sectionally. diagnosis at follow-up was not associated with functional outcome. conclusions neuropsychological functioning was the single best predictor of later socio-occupational outcome among young psychiatric outpatients. therefore, framing psychiatric disorders along a neuropsychological continuum is likely to be more useful in predicting functional trajectory than traditional symptom-based classification systems. the current findings also have implications for early intervention utilising cognitive remediation approaches.",
            "contribution_ids": [
                "R170587",
                "R170588"
            ]
        },
        {
            "instance_id": "EMPTYxR189153",
            "comparison_id": "EMPTY",
            "paper_id": "R189153",
            "text": "Urban Land Use and Land Cover Classification Using Multisource Remote Sensing Images and Social Media Data land use and land cover (lulc) are diverse and complex in urban areas. remotely sensed images are commonly used for land cover classification but hardly identifies urban land use and functional areas because of the semantic gap (i.e., different definitions of similar or identical buildings). social media data, \u201cmarks\u201d left by people using mobile phones, have great potential to overcome this semantic gap. multisource remote sensing data are also expected to be useful in distinguishing different lulc types. this study examined the capability of combined multisource remote sensing images and social media data in urban lulc classification. multisource remote sensing images included a chinese ziyuan-3 (zy-3) high-resolution image, a landsat 8 operational land imager (oli) multispectral image, and a sentinel-1a synthetic aperture radar (sar) image. social media data consisted of the hourly spatial distribution of wechat users, which is a ubiquitous messaging and payment platform in china. lulc was classified into 10 types, namely, vegetation, bare land, road, water, urban village, greenhouses, residential, commercial, industrial, and educational buildings. a method that integrates object-based image analysis, decision trees, and random forests was used for lulc classification. the overall accuracy and kappa value attained by the combination of multisource remote sensing images and wechat data were 87.55% and 0.84, respectively. they further improved to 91.55% and 0.89, respectively, by integrating the textural and spatial features extracted from the zy-3 image. the zy-3 high-resolution image was essential for urban lulc classification because it is necessary for the accurate delineation of land parcels. the addition of landsat 8 oli, sentinel-1a sar, or wechat data also made an irreplaceable contribution to the classification of different lulc types. the landsat 8 oli image helped distinguish between the urban village, residential buildings, commercial buildings, and roads, while the sentinel-1a sar data reduced the confusion between commercial buildings, greenhouses, and water. rendering the spatial and temporal dynamics of population density, the wechat data improved the classification accuracies of an urban village, greenhouses, and commercial buildings.",
            "contribution_ids": [
                "R189155"
            ]
        },
        {
            "instance_id": "EMPTYxR134434",
            "comparison_id": "EMPTY",
            "paper_id": "R134434",
            "text": "Text classification with word embedding regularization and soft similarity measure \"since the seminal work of mikolov et al., word embeddings have become the preferred word representations for many natural language processing tasks. document similarity measures extracted from word embeddings, such as the soft cosine measure (scm) and the word mover's distance (wmd), were reported to achieve state-of-the-art performance on semantic text similarity and text classification. \\ndespite the strong performance of the wmd on text classification and semantic text similarity, its super-cubic average time complexity is impractical. the scm has quadratic worst-case time complexity, but its performance on text classification has never been compared with the wmd. recently, two word embedding regularization techniques were shown to reduce storage and memory costs, and to improve training speed, document processing speed, and task performance on word analogy, word similarity, and semantic text similarity. however, the effect of these techniques on text classification has not yet been studied. \\nin our work, we investigate the individual and joint effect of the two word embedding regularization techniques on the document processing speed and the task performance of the scm and the wmd on text classification. for evaluation, we use the $k$nn classifier and six standard datasets: bbcsport, twitter, ohsumed, reuters-21578, amazon, and 20news. \\nwe show 39% average $k$nn test error reduction with regularized word embeddings compared to non-regularized word embeddings. we describe a practical procedure for deriving such regularized embeddings through cholesky factorization. we also show that the scm with regularized word embeddings significantly outperforms the wmd on text classification and is over 10,000 times faster.\"",
            "contribution_ids": [
                "R134435"
            ]
        },
        {
            "instance_id": "EMPTYxR147191",
            "comparison_id": "EMPTY",
            "paper_id": "R147191",
            "text": "Estimating Oceanic Primary Production Using Vertical Irradiance and Chlorophyll Profiles from Ocean Gliders in the North Atlantic an autonomous underwater vehicle (seaglider) has been used to estimate marine primary production (pp) using a combination of irradiance and fluorescence vertical profiles. this method provides estimates for depth-resolved and temporally evolving pp on fine spatial scales in the absence of ship-based calibrations. we describe techniques to correct for known issues associated with long autonomous deployments such as sensor calibration drift and fluorescence quenching. comparisons were made between the seaglider, stable isotope ((13)c), and satellite estimates of pp. the seaglider-based pp estimates were comparable to both satellite estimates and stable isotope measurements.",
            "contribution_ids": [
                "R147193"
            ]
        },
        {
            "instance_id": "EMPTYxR130962",
            "comparison_id": "EMPTY",
            "paper_id": "R130962",
            "text": "Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling recurrent neural networks have been very successful at predicting sequences of words in tasks such as language modeling. however, all such models are based on the conventional classification framework, where the model is trained against one-hot targets, and each word is represented both as an input and as an output in isolation. this causes inefficiencies in learning both in terms of utilizing all of the information and in terms of the number of parameters needed to train. we introduce a novel theoretical framework that facilitates better learning in language modeling, and show that our framework leads to tying together the input embedding and the output projection matrices, greatly reducing the number of trainable variables. our framework leads to state of the art performance on the penn treebank with a variety of network models.",
            "contribution_ids": [
                "R130963",
                "R130967",
                "R130971"
            ]
        },
        {
            "instance_id": "EMPTYxR2022",
            "comparison_id": "EMPTY",
            "paper_id": "R2022",
            "text": "Why Reinvent the Wheel modern question answering (qa) systems need to flexibly integrate a number of components specialised to fulfil specific tasks in a qa pipeline. key qa tasks include named entity recognition and disambiguation, relation extraction, and query building. since a number of different software components exist that implement different strategies for each of these tasks, it is a major challenge to select and combine the most suitable components into a qa system, given the characteristics of a question. we study this optimisation problem and train classifiers, which take features of a question as input and have the goal of optimising the selection of qa components based on those features. we then devise a greedy algorithm to identify the pipelines that include the suitable components and can effectively answer the given question. we implement this model within frankenstein, a qa framework able to select qa components and compose qa pipelines. we evaluate the effectiveness of the pipelines generated by frankenstein using the qald and lc-quad benchmarks. these results not only suggest that frankenstein precisely solves the qa optimisation problem but also enables the automatic composition of optimised qa pipelines, which outperform the static baseline qa pipeline. thanks to this flexible and fully automated pipeline generation process, new qa components can be easily included in frankenstein, thus improving the performance of the generated pipelines.",
            "contribution_ids": [
                "R2038"
            ]
        },
        {
            "instance_id": "EMPTYxR199014",
            "comparison_id": "EMPTY",
            "paper_id": "R199014",
            "text": "Requirements engineering: The quest for the dependent variable \"requirements engineering is a vibrant and broad research area. it covers a range of activities with different objectives. by reviewing experiments previously included in systematic literature reviews, this paper provides an overview of the dependent variables used in experimental requirements engineering research. this paper also identifies the theoretical motivation for the use of these variables in the experiments. the results show that a wide range of different variables has been applied in experiments and operationalized through both subjective assessments (e.g., subjects' perceived utility of a technique) and objective measurements (e.g., the number of defects found in a requirements specification). the theoretical basis for these variables and operationalizations are unclear in most cases. directions for theoretical work to identify suitable dependent variables are provided.\"",
            "contribution_ids": [
                "R199016"
            ]
        },
        {
            "instance_id": "EMPTYxR135097",
            "comparison_id": "EMPTY",
            "paper_id": "R135097",
            "text": "Sequential Random Network for Fine-grained Image Classification deep convolutional neural network (dcnn) and transformer have achieved remarkable successes in image recognition. however, their performance in fine-grained image recognition is still difficult to meet the requirements of actual needs. this paper proposes a sequence random network (srn) to enhance the performance of dcnn. the output of dcnn is one-dimensional features. this onedimensional feature abstractly represents image information, but it does not express well the detailed information of image. to address this issue, we use the proposed srn, which composed of bilstm and several tanh-dropout blocks (called bilstm-tdn), to further process dcnn one-dimensional features for highlighting the detail information of image. after the feature transform by bilstmtdn, the recognition performance has been greatly improved. we conducted the experiments on six fine-grained image datasets. except for fgvc-aircraft, the accuracy of the proposed methods on the other datasets exceeded 99%. experimental results show that bilstm-tdn is far superior to the existing state-of-the-art methods. in addition to dcnn, bilstm-tdn can also be extended to other models, such as transformer.",
            "contribution_ids": [
                "R135098",
                "R135105"
            ]
        },
        {
            "instance_id": "EMPTYxR155867",
            "comparison_id": "EMPTY",
            "paper_id": "R155867",
            "text": "Psychological distance towards COVID-19: Geographical and hypothetical distance predict attitudes and mediate knowledge abstract while different antecedents have been examined to explain peoples\u2019 reactions towards covid-19, there is only scarce understanding about the role of the subjective closeness and distance to the pandemic. within the current study, we applied the concept of psychological distance to understand the distance towards covid-19 and investigated its (1) connection with preventive attitudes and proactive behaviors, (2) context-specific antecedents, and its (3) mediating effect of knowledge on attitudes. using an online sample from a german quantitative cross-sectional study ( n \\u2009=\\u2009395, m \\u2009=\\u200932.2\\xa0years, sd \\u2009=\\u200913.9\\xa0years, 64.3% female) in july 2020, a time with a general low incidence of people infected with sars-cov2, we measured relevant socio-psychological constructs addressing covid-19 and included further information from external sources. based on a path model, we found geographical distance as a significant predictor of cognitive attitudes towards covid-19. furthermore, hypothetical distance (i.e., feeling to be likely affected by covid-19) predicted not only participants\u2019 affective, cognitive, and behavioral attitudes, but also the installation of a corona warning-app. while several variables affected the different dimensions of psychological distance, hypothetical and geographical distance mediated the effect of knowledge on attitudes. these results underline the role of geographical and hypothetical distance for health-related behaviors and education. for example, people will only comply with preventive measures if they feel geographically concerned by the disease, which is particularly challenging for fast-spreading global diseases such as covid-19. therefore, there is a need to clearly communicate the personal risks of diseases and address peoples\u2019 hypothetical distance.",
            "contribution_ids": [
                "R155872"
            ]
        },
        {
            "instance_id": "EMPTYxR109313",
            "comparison_id": "EMPTY",
            "paper_id": "R109313",
            "text": "KGen: a knowledge graph generator from biomedical scientific literature abstract \\n background \\n knowledge is often produced from data generated in scientific investigations. an ever-growing number of scientific studies in several domains result into a massive amount of data, from which obtaining new knowledge requires computational help. for example, alzheimer\u2019s disease, a life-threatening degenerative disease that is not yet curable. as the scientific community strives to better understand it and find a cure, great amounts of data have been generated, and new knowledge can be produced. a proper representation of such knowledge brings great benefits to researchers, to the scientific community, and consequently, to society. \\n \\n methods \\n in this article, we study and evaluate a semi-automatic method that generates knowledge graphs (kgs) from biomedical texts in the scientific literature. our solution explores natural language processing techniques with the aim of extracting and representing scientific literature knowledge encoded in kgs. our method links entities and relations represented in kgs to concepts from existing biomedical ontologies available on the web. we demonstrate the effectiveness of our method by generating kgs from unstructured texts obtained from a set of abstracts taken from scientific papers on the alzheimer\u2019s disease. we involve physicians to compare our extracted triples from their manual extraction via their analysis of the abstracts. the evaluation further concerned a qualitative analysis by the physicians of the generated kgs with our software tool. \\n \\n results \\n the experimental results indicate the quality of the generated kgs. the proposed method extracts a great amount of triples, showing the effectiveness of our rule-based method employed in the identification of relations in texts. in addition, ontology links are successfully obtained, which demonstrates the effectiveness of the ontology linking method proposed in this investigation. \\n \\n conclusions \\n we demonstrate that our proposal is effective on building ontology-linked kgs representing the knowledge obtained from biomedical scientific texts. such representation can add value to the research in various domains, enabling researchers to compare the occurrence of concepts from different studies. the kgs generated may pave the way to potential proposal of new theories based on data analysis to advance the state of the art in their research domains. \\n",
            "contribution_ids": [
                "R109316"
            ]
        },
        {
            "instance_id": "EMPTYxR206122",
            "comparison_id": "EMPTY",
            "paper_id": "R206122",
            "text": "Measuring the Evolution of a Scientific Field through Citation Frames citations have long been used to characterize the state of a scientific field and to identify influential works. however, writers use citations for different purposes, and this varied purpose influences uptake by future scholars. unfortunately, our understanding of how scholars use and frame citations has been limited to small-scale manual citation analysis of individual papers. we perform the largest behavioral study of citations to date, analyzing how scientific works frame their contributions through different types of citations and how this framing affects the field as a whole. we introduce a new dataset of nearly 2,000 citations annotated for their function, and use it to develop a state-of-the-art classifier and label the papers of an entire field: natural language processing. we then show how differences in framing affect scientific uptake and reveal the evolution of the publication venues and the field as a whole. we demonstrate that authors are sensitive to discourse structure and publication venue when citing, and that how a paper frames its work through citations is predictive of the citation count it will receive. finally, we use changes in citation framing to show that the field of nlp is undergoing a significant increase in consensus.",
            "contribution_ids": [
                "R206124"
            ]
        },
        {
            "instance_id": "EMPTYxR6622",
            "comparison_id": "EMPTY",
            "paper_id": "R6622",
            "text": "The University of Lethbridge Text Summarizer at DUC 2002 text summarization addresses both the problem of selecting the most important portions of text and the problem of generating coherent summaries. we present in this paper the summarizer of the university of lethbridge at duc 2002, which is based on an efficient use of topical clues. the method we present addresses the problem of producing summaries, in the context of single and multiple documents.",
            "contribution_ids": [
                "R6623"
            ]
        },
        {
            "instance_id": "EMPTYxR134920",
            "comparison_id": "EMPTY",
            "paper_id": "R134920",
            "text": "The Tsetlin Machine - A Game Theoretic Bandit Driven Approach to Optimal Pattern Recognition with Propositional Logic although simple individually, artificial neurons provide state-of-the-art performance when interconnected in deep networks. arguably, the tsetlin automaton is an even simpler and more versatile learning mechanism, capable of solving the multi-armed bandit problem. merely by means of a single integer as memory, it learns the optimal action in stochastic environments through increment and decrement operations. in this paper, we introduce the tsetlin machine, which solves complex pattern recognition problems with propositional formulas, composed by a collective of tsetlin automata. to eliminate the longstanding problem of vanishing signal-to-noise ratio, the tsetlin machine orchestrates the automata using a novel game. further, both inputs, patterns, and outputs are expressed as bits, while recognition and learning rely on bit manipulation, simplifying computation. our theoretical analysis establishes that the nash equilibria of the game align with the propositional formulas that provide optimal pattern recognition accuracy. this translates to learning without local optima, only global ones. in five benchmarks, the tsetlin machine provides competitive accuracy compared with svms, decision trees, random forests, naive bayes classifier, logistic regression, and neural networks. we further demonstrate how the propositional formulas facilitate interpretation. we believe the combination of high accuracy, interpretability, and computational simplicity makes the tsetlin machine a promising tool for a wide range of domains.",
            "contribution_ids": [
                "R134921"
            ]
        },
        {
            "instance_id": "EMPTYxR168556",
            "comparison_id": "EMPTY",
            "paper_id": "R168556",
            "text": "Pep2Path: Automated Mass Spectrometry-Guided Genome Mining of Peptidic Natural Products nonribosomally and ribosomally synthesized bioactive peptides constitute a source of molecules of great biomedical importance, including antibiotics such as penicillin, immunosuppressants such as cyclosporine, and cytostatics such as bleomycin. recently, an innovative mass-spectrometry-based strategy, peptidogenomics, has been pioneered to effectively mine microbial strains for novel peptidic metabolites. even though mass-spectrometric peptide detection can be performed quite fast, true high-throughput natural product discovery approaches have still been limited by the inability to rapidly match the identified tandem mass spectra to the gene clusters responsible for the biosynthesis of the corresponding compounds. with pep2path, we introduce a software package to fully automate the peptidogenomics approach through the rapid bayesian probabilistic matching of mass spectra to their corresponding biosynthetic gene clusters. detailed benchmarking of the method shows that the approach is powerful enough to correctly identify gene clusters even in data sets that consist of hundreds of genomes, which also makes it possible to match compounds from unsequenced organisms to closely related biosynthetic gene clusters in other genomes. applying pep2path to a data set of compounds without known biosynthesis routes, we were able to identify candidate gene clusters for the biosynthesis of five important compounds. notably, one of these clusters was detected in a genome from a different subphylum of proteobacteria than that in which the molecule had first been identified. all in all, our approach paves the way towards high-throughput discovery of novel peptidic natural products. pep2path is freely available from http://pep2path.sourceforge.net/, implemented in python, licensed under the gnu general public license v3 and supported on ms windows, linux and mac os x.",
            "contribution_ids": [
                "R168557",
                "R168558",
                "R168559",
                "R168560",
                "R168561",
                "R168562",
                "R168563"
            ]
        },
        {
            "instance_id": "EMPTYxR111061",
            "comparison_id": "EMPTY",
            "paper_id": "R111061",
            "text": "Reversed urbanism: Inferring urban performance through behavioral patterns in temporal telecom data abstract a fundamental aspect of well performing cities is successful public spaces. for centuries, understanding these places has been limited to sporadic observations and laborious data collection. this study proposes a novel methodology to analyze citywide, discrete urban spaces using highly accurate anonymized telecom data and machine learning algorithms. through superposition of human dynamics and urban features, this work aims to expose clear correlations between the design of the city and the behavioral patterns of its users. geolocated telecom data, obtained for the state of andorra, were initially analyzed to identify \u201cstay-points\u201d\u2014events in which cellular devices remain within a certain roaming distance for a given length of time. these stay-points were then further analyzed to find clusters of activity characterized in terms of their size, persistence, and diversity. multivariate linear regression models were used to identify associations between the formation of these clusters and various urban features such as urban morphology or land-use within a 25\u201350 meters resolution. some of the urban features that were found to be highly related to the creation of large, diverse and long-lasting clusters were the presence of service and entertainment amenities, natural water features, and the betweenness centrality of the road network; others, such as educational and park amenities were shown to have a negative impact. ultimately, this study suggests a \u201creversed urbanism\u201d methodology: an evidence-based approach to urban design, planning, and decision making, in which human behavioral patterns are instilled as a foundational design tool for inferring the success rates of highly performative urban places.",
            "contribution_ids": [
                "R111064"
            ]
        },
        {
            "instance_id": "EMPTYxR170046",
            "comparison_id": "EMPTY",
            "paper_id": "R170046",
            "text": "Comparison of fMRI paradigms assessing visuospatial processing: Robustness and reproducibility the development of brain imaging techniques, in particular functional magnetic resonance imaging (fmri), made it possible to non-invasively study the hemispheric lateralization of cognitive brain functions in large cohorts. comprehensive models of hemispheric lateralization are, however, still missing and should not only account for the hemispheric specialization of individual brain functions, but also for the interactions among different lateralized cognitive processes (e.g., language and visuospatial processing). this calls for robust and reliable paradigms to study hemispheric lateralization for various cognitive functions. while numerous reliable imaging paradigms have been developed for language, which represents the most prominent left-lateralized brain function, the reliability of imaging paradigms investigating typically right-lateralized brain functions, such as visuospatial processing, has received comparatively less attention. in the present study, we aimed to establish an fmri paradigm that robustly and reliably identifies right-hemispheric activation evoked by visuospatial processing in individual subjects. in a first study, we therefore compared three frequently used paradigms for assessing visuospatial processing and evaluated their utility to robustly detect right-lateralized brain activity on a single-subject level. in a second study, we then assessed the test-retest reliability of the so-called landmark task\u2013the paradigm that yielded the most robust results in study 1. at the single-voxel level, we found poor reliability of the brain activation underlying visuospatial attention. this suggests that poor signal-to-noise ratios can become a limiting factor for test-retest reliability. this represents a common detriment of fmri paradigms investigating visuospatial attention in general and therefore highlights the need for careful considerations of both the possibilities and limitations of the respective fmri paradigm\u2013in particular, when being interested in effects at the single-voxel level. notably, however, when focusing on the reliability of measures of hemispheric lateralization (which was the main goal of study 2), we show that hemispheric dominance (quantified by the lateralization index, li, with |li| >0.4) of the evoked activation could be robustly determined in more than 62% and, if considering only two categories (i.e., left, right), in more than 93% of our subjects. furthermore, the reliability of the lateralization strength (li) was \u201cfair\u201d to \u201cgood\u201d. in conclusion, our results suggest that the degree of right-hemispheric dominance during visuospatial processing can be reliably determined using the landmark task, both at the group and single-subject level, while at the same time stressing the need for future refinements of experimental paradigms and more sophisticated fmri data acquisition techniques.",
            "contribution_ids": [
                "R170047",
                "R170048",
                "R170049",
                "R170050",
                "R170051",
                "R170052",
                "R170053",
                "R170054",
                "R170055"
            ]
        },
        {
            "instance_id": "EMPTYxR75706",
            "comparison_id": "EMPTY",
            "paper_id": "R75706",
            "text": "Natural Plant Extracts as Acid-Base Indicator and Determination of Their pKa Value commonly used indicators for acid-base titrations are synthetic, and this work was focused to identify the eco-friendly natural indicators and to determine their pka values. the analytical potential of the flower extracts is very promising as seen in its application in acid-base titrimetry. these selected flower extracts were found to perform well in titrating strong acid-strong base than in weak acid-strong base. we have obtained a sharp and clear colour change from red to brownish yellow for the bougainvillea glabra extract, from red to yellow for the bauhinia purpurea extract, and from red to brownish yellow for the impatiens balsamina extract. all the three flower extracts gave clear colour change with acids and bases, and the colour change was maintained with different acids and bases. the sharp contrast between their colours in acid and base made the pigment suitable for use as acid-base indicators. as these flower extracts have very simple,cost-effective, environment friendly extraction procedure and excellent performance with sharp colour change in end points of the titrations, it would be possible to replace the standard indicators being used in conventional laboratories with natural flower indicators.",
            "contribution_ids": [
                "R75709"
            ]
        },
        {
            "instance_id": "EMPTYxR44491",
            "comparison_id": "EMPTY",
            "paper_id": "R44491",
            "text": "Suspected phenobarbital-induced pseudolymphoma in a cat case description\\na 4.5-year-old spayed female domestic shorthair cat was evaluated because of a generalized seizure disorder that developed after an anesthesia-related hypoxic event.\\n\\n\\nclinical findings\\nfollowing administration of phenobarbital, the seizures stopped but the cat developed severe generalized lymphadenopathy. results of a cbc and serum biochemical analysis were unremarkable. cytologic examination of the lymph nodes revealed a reactive lymphocyte population. differential diagnoses included neoplasia and infection, but results of related diagnostic tests were all negative.\\n\\n\\ntreatment and outcome\\ntreatment was changed from phenobarbital to levetiracetam. ten days following discontinuation of phenobarbital, the lymph node enlargement resolved, and the cat remained free of seizures with levetiracetam as treatment.\\n\\n\\nclinical relevance\\npseudolymphoma and anticonvulsant hypersensitivity syndrome are recognized potential sequelae to anticonvulsant administration in humans. however, a pseudolymphoma-like reaction to anticonvulsants in veterinary species has not previously been reported. this case highlighted a potentially serious yet reversible sequela to phenobarbital treatment that may have been mistaken for more severe illness such as neoplasia.",
            "contribution_ids": [
                "R44492"
            ]
        },
        {
            "instance_id": "EMPTYxR46578",
            "comparison_id": "EMPTY",
            "paper_id": "R46578",
            "text": "Rule-Based named entity recognition in Urdu named entity recognition or extraction (ner) is an important task for automated text processing for industries and academia engaged in the field of language processing, intelligence gathering and bioinformatics. in this paper we discuss the general problem of named entity recognition, more specifically the challenges in ner in languages that do not have language resources e.g. large annotated corpora. we specifically address the challenges for urdu ner and differentiate it from other south asian (indic) languages. we discuss the differences between hindi and urdu and conclude that the ner computational models for hindi cannot be applied to urdu. a rule-based urdu ner algorithm is presented that outperforms the models that use statistical learning.",
            "contribution_ids": [
                "R46579"
            ]
        },
        {
            "instance_id": "EMPTYxR146997",
            "comparison_id": "EMPTY",
            "paper_id": "R146997",
            "text": "Enhancing the Performance of Organic Solar Cells by Hierarchically Supramolecular Self-Assembly of Fused-Ring Electron Acceptors three novel non-fullerene small molecular acceptors itoic, itoic-f, and itoic-2f were designed and synthesized with easy chemistry. the concept of supramolecular chemistry was successfully used in the molecular design, which includes noncovalently conformational locking (via intrasupramolecular interaction) to enhance the planarity of backbone and electrostatic interaction (intersupramolecular interaction) to enhance the \u03c0\u2013\u03c0 stacking of terminal groups. fluorination can further strengthen the intersupramolecular electrostatic interaction of terminal groups. as expected, the designed acceptors exhibited excellent device performance when blended with polymer donor pbdb-t. in comparison with the parent acceptor molecule dc-idt2t reported in the literature with a power conversion efficiency (pce) of 3.93%, itoic with a planar structure exhibited a pce of 8.87% and itoic-2f with a planar structure and enhanced electrostatic interaction showed a quite impressive pce of 12.17%. our result demonstrates the import...",
            "contribution_ids": [
                "R146999"
            ]
        },
        {
            "instance_id": "EMPTYxR172814",
            "comparison_id": "EMPTY",
            "paper_id": "R172814",
            "text": "AUTOMATING DATA ACQUISITION INTO ONTOLOGIES FROM PHARMACOGENETICS RELATIONAL DATA SOURCES USING DECLARATIVE OBJECT DEFINITIONS AND XML ontologies are useful for organizing large numbers of concepts having complex relationships, such as the breadth of genetic and clinical knowledge in pharmacogenomics. but because ontologies change and knowledge evolves, it is time consuming to maintain stable mappings to external data sources that are in relational format. we propose a method for interfacing ontology models with data acquisition from external relational data sources. this method uses a declarative interface between the ontology and the data source, and this interface is modeled in the ontology and implemented using xml schema. data is imported from the relational source into the ontology using xml, and data integrity is checked by validating the xml submission with an xml schema. we have implemented this approach in pharmgkb (http://www.pharmgkb.org/), a pharmacogenetics knowledge base. our goals were to (1) import genetic sequence data, collected in relational format, into the pharmacogenetics ontology, and (2) automate the process of updating the links between the ontology and data acquisition when the ontology changes. we tested our approach by linking pharmgkb with data acquisition from a relational model of genetic sequence information. the ontology subsequently evolved, and we were able to rapidly update our interface with the external data and continue acquiring the data. similar approaches may be helpful for integrating other heterogeneous information sources in order make the diversity of pharmacogenetics data amenable to computational analysis.",
            "contribution_ids": [
                "R172816"
            ]
        },
        {
            "instance_id": "EMPTYxR160155",
            "comparison_id": "EMPTY",
            "paper_id": "R160155",
            "text": "Nitrous oxide cycling in the Arabian Sea depth profiles of dissolved nitrous oxide (n2o) were measured in the central and western arabian sea during four cruises in may and july\u2013august 1995 and may\u2013july 1997 as part of the german contribution to the arabian sea process study of the joint global ocean flux study. the vertical distribution of n2o in the water column on a transect along 65\u00b0e showed a characteristic double-peak structure, indicating production of n2o associated with steep oxygen gradients at the top and bottom of the oxygen minimum zone. we propose a general scheme consisting of four ocean compartments to explain the n2o cycling as a result of nitrification and denitrification processes in the water column of the arabian sea. we observed a seasonal n2o accumulation at 600\u2013800 m near the shelf break in the western arabian sea. we propose that, in the western arabian sea, n2o might also be formed during bacterial oxidation of organic matter by the reduction of io3 \u2212 to i\u2212, indicating that the biogeochemical cycling of n2o in the arabian sea during the sw monsoon might be more complex than previously thought. a compilation of sources and sinks of n2o in the arabian sea suggested that the n2o budget is reasonably balanced.",
            "contribution_ids": [
                "R160157",
                "R160165"
            ]
        },
        {
            "instance_id": "EMPTYxR76379",
            "comparison_id": "EMPTY",
            "paper_id": "R76379",
            "text": "Designing for Game-Based Learning: The Effective Integration of Technology to Support Learning the use of games and game structures in educational contexts is growing in popularity. an increasing number of technologies have been developed to meet the needs of designing a course as a game. this article discussed the design process in game-based learning and reviewed the research on structuring a course with a focus on feedback, goals, and interaction. in addition, we presented the best practices and technologies to support the integration of badges and leaderboards into game-based learning. with the intentional and systematic design of game-based learning, instructors and designers will increase the impact of game attributes and elements on student achievement and motivation. further investigation of game-based learning attributes and elements is needed to provide detailed knowledge on the compatibility with current technological tools.",
            "contribution_ids": [
                "R76381"
            ]
        },
        {
            "instance_id": "EMPTYxR197009",
            "comparison_id": "EMPTY",
            "paper_id": "R197009",
            "text": "Mind the Gap: Assessing Temporal Generalization in Neural Language Models our world is open-ended, non-stationary, and constantly evolving; thus what we talk about and how we talk about it change over time. this inherent dynamic nature of language contrasts with the current static language modelling paradigm, which trains and evaluates models on utterances from overlapping time periods. despite impressive recent progress, we demonstrate that transformer-xl language models perform worse in the realistic setup of predicting future utterances from beyond their training period, and that model performance becomes increasingly worse with time. we find that, while increasing model size alone\u2014a key driver behind recent progress\u2014does not solve this problem, having models that continually update their knowledge with new information can indeed mitigate this performance degradation over time. hence, given the compilation of ever-larger language modelling datasets, combined with the growing list of language-model-based nlp applications that require up-to-date factual knowledge about the world, we argue that now is the right time to rethink the static way in which we currently train and evaluate our language models, and develop adaptive language models that can remain up-to-date with respect to our ever-changing and non-stationary world. we will publicly release our dynamic, streaming language modelling benchmarks for wmt and arxiv to facilitate language model evaluation that takes temporal dynamics into account.1",
            "contribution_ids": [
                "R197011"
            ]
        },
        {
            "instance_id": "EMPTYxR199123",
            "comparison_id": "EMPTY",
            "paper_id": "R199123",
            "text": "Selecting creativity techniques for creative requirements: An evaluation of four techniques using creativity workshops requirements engineering is recognized as a creative process where stakeholders jointly discover new creative ideas for innovative and novel products that eventually are expressed as requirements. this paper evaluates four different creativity techniques, namely hall of fame, constraint removal, brainstorming, and idea box, using creativity workshops with students and industry practitioners. in total, 34 creativity workshops were conducted with 90 students from two universities, and 86 industrial practitioners from six companies. the results from this study indicate that brainstorming can generate by far the most ideas, while hall of fame generates most creative ideas. idea box generates the least number of ideas, and the least number of creative ideas. finally, hall of fame was the technique that led to the most number of requirements that was included in future releases of the products.",
            "contribution_ids": [
                "R199125"
            ]
        },
        {
            "instance_id": "EMPTYxR209105",
            "comparison_id": "EMPTY",
            "paper_id": "R209105",
            "text": "Bidirectional LSTM Based on POS tags and CNN Architecture for Fake News Detection fake news generally on social media spreads very quickly and this brings many serious consequences. traditional lexico-syntactic based features have limited success to detect fake news. majority of fake news detection techniques are tested on small dataset containing limited training examples. in this work, we evaluate our architecture on liar-liar dataset which contain 12836 short news from different sources including social media. the proposed architecture incorporates pos (part of speech) tags information of news article through bidirectional lstm and speaker profile information through convolutional neural network. the results show that the resulting hybrid architecture significantly improves detection performance of fake news on liar dataset.",
            "contribution_ids": [
                "R209107"
            ]
        },
        {
            "instance_id": "EMPTYxR170080",
            "comparison_id": "EMPTY",
            "paper_id": "R170080",
            "text": "Visualizing the intercity correlation of PM2.5 time series in the Beijing-Tianjin-Hebei region using ground-based air quality monitoring data the beijing-tianjin-hebei area faces a severe fine particulate matter (pm2.5) problem. to date, considerable progress has been made toward understanding the pm2.5 problem, including spatial-temporal characterization, driving factors, and health effects. however, little research has been done on the dynamic interactions and relationships between pm2.5 concentrations in different cities in this area. to address the research gap, this study discovered a phenomenon of time-lagged intercity correlations of pm2.5 time series and proposed a visualization framework based on this phenomenon to visualize the interaction in pm2.5 concentrations between cities. the visualizations produced using the framework show that there are significant time-lagged correlations between the pm2.5 time series in different cities in this area. the visualizations also show that the correlations are more significant in colder months and between cities that are closer, and that there are seasonal changes in the temporal order of the correlated pm2.5 time series. further analysis suggests that the time-lagged intercity correlations of pm2.5 time series are most likely due to synoptic meteorological variations. we argue that the visualizations demonstrate the interactions of air pollution between cities in the beijing-tianjin-hebei area and the significant effect of synoptic meteorological conditions on pm2.5 pollution. the visualization framework could help determine the pathway of regional transportation of air pollution and may also be useful in delineating the area of interaction of pm2.5 pollution for impact analysis.",
            "contribution_ids": [
                "R170081",
                "R170082",
                "R170083",
                "R170084"
            ]
        },
        {
            "instance_id": "EMPTYxR170538",
            "comparison_id": "EMPTY",
            "paper_id": "R170538",
            "text": "Chronic Subordinate Colony Housing (CSC) as a Model of Chronic Psychosocial Stress in Male Rats chronic subordinate colony housing (csc) is an adequate and reliable mouse model of chronic psychosocial stress, resulting in reduced body weight gain, reduced thymus and increased adrenal weight, long-lasting anxiety-like behaviour, and spontaneous colitis. furthermore, csc mice show increased corticotrophin (acth) responsiveness to acute heterotypic stressors, suggesting a general mechanism which allows a chronically-stressed organism to adequately respond to a novel threat. therefore, the aim of the present study was to extend the csc model to another rodent species, namely male wistar rats, and to characterize relevant physiological, immunological, and behavioural consequences; placing particular emphasis on changes in hypothalamo-pituitary-adrenal (hpa) axis responsiveness to an acute heterotypic stressor. in line with previous mouse data, exposure of wistar rats to 19 days of csc resulted in a decrease in body weight gain and absolute thymus mass, mild colonic barrier defects and intestinal immune activation. moreover, no changes in stress-coping behaviour or social preference were seen; again in agreement with the mouse paradigm. most importantly, csc rats showed an increased plasma corticosterone response to an acute heterotypic stressor (open arm, 5 min) despite displaying similar basal levels and similar basal and stressor-induced plasma acth levels. in contrast to csc mice, anxiety-related behaviour and absolute, as well as relative adrenal weights remained unchanged in csc rats. in summary, the csc paradigm could be established as an adequate model of chronic psychosocial stress in male rats. our data further support the initial hypothesis that adrenal hyper-responsiveness to acth during acute heterotypic stressors represents a general adaptation, which enables a chronically-stressed organism to adequately respond to novel challenges.",
            "contribution_ids": [
                "R170539"
            ]
        },
        {
            "instance_id": "EMPTYxR109529",
            "comparison_id": "EMPTY",
            "paper_id": "R109529",
            "text": "A Markovian Model for the Analysis of Age of Information in IoT Networks age of information (aoi) is a critical metric in status update systems as these systems require the fresh updates. this letter investigates the uplink of an internet-of-thing (iot) network where ${l}$ nodes transmit their information packets to a base station. the effects of the arrival rate of packets at the nodes, the number of nodes in the system, and queue length of each node have been studied by devising a discrete time markov chain (mc) model. this model helps in predicting the values of aoi and probability of packet drops in such systems. the notion of first-in first-out is used for queuing, which transmits the oldest packet first, resulting in decreasing the overall aoi of the system. the results show that aoi increases with the increase in queue length, number of nodes and arrival rate and we quantify the aforementioned metrics using the mc model. the results found using the mc model are also validated using extensive simulations.",
            "contribution_ids": [
                "R109531"
            ]
        },
        {
            "instance_id": "EMPTYxR195664",
            "comparison_id": "EMPTY",
            "paper_id": "R195664",
            "text": "The Trouble with Security Requirements \"manifold approaches to security requirements engineering have been proposed, yet there is no consensus how to elicit, analyze, or express security needs. this perspective paper systematizes the problem space of security requirements engineering. security needs result from the interplay of three dimensions: threats, security goals, and system design. elementary statements can be made in each dimension, but such one-dimensional requirements remain partial and insufficient. to understand security needs, one has to analyze their interaction. distinct analysis tasks arise for each pair of dimensions and are supported by different techniques: risk analysis, as in coras, between threats and security goals; security design, as exemplified by the framework of haley et al., between goals and design; and security design analysis, such as microsoft's threat modeling technique with data flow diagrams and stride, between design and threats. all three perspectives are necessary to develop secure systems. security requirements engineering must iterate through them, because threats determine the relevance of security goals, security design seeks ways to fulfill them, and design choices themselves influence threats and security goals.\"",
            "contribution_ids": [
                "R195665"
            ]
        },
        {
            "instance_id": "EMPTYxR195749",
            "comparison_id": "EMPTY",
            "paper_id": "R195749",
            "text": "How Much Undocumented Knowledge is there in Agile Software Development?: Case Study on Industrial Project Using Issue Tracking System and Version Control System in agile software development projects, software engineers prioritize implementation over documentation to eliminate needless documentation. is the cost of missing documentation greater than the cost of producing unnecessary or unused documentation? even without these documents, software engineers maintain other software artifacts, such as tickets in an issue tracking system (its) or source code committed to a version control system (vcs). do these artifacts contain the necessary knowledge? in this paper, we examine undocumented knowledge in an agile software development project at ntt. for our study, we collected 159 commit logs in a vcs and 102 tickets in the its from the three-month period of the project. we propose a ticket-commit network chart (tcc) that visually represents time-series commit activities along with filed issue tickets. we also implement a tool to generate the tcc using both commit log and ticket data. our study revealed that in 16% of all commits, software engineers committed source code to the vcs without a corresponding issue ticket in the its. had these commits been based on individual issue tickets, these \"unissued\" tickets would have accounted for 20% of all tickets. software users and requirements engineers also evaluated the contents of these commits and found that 42% of the \"unissued\" tickets were required for software operation and 23% of those were required for requirements modification.",
            "contribution_ids": [
                "R195750"
            ]
        },
        {
            "instance_id": "EMPTYxR139810",
            "comparison_id": "EMPTY",
            "paper_id": "R139810",
            "text": "Digital heritage interpretation: a conceptual framework abstract \u2018heritage interpretation\u2019 has always been considered as an effective learning, communication and management tool that increases visitors\u2019 awareness of and empathy to heritage sites or artefacts. yet the definition of \u2018digital heritage interpretation\u2019 is still wide and so far, no significant method and objective are evident within the domain of \u2018digital heritage\u2019 theory and discourse. considering \u2018digital heritage interpretation\u2019 as a process rather than as a tool to present or communicate with end-users, this paper presents a critical application of a theoretical construct ascertained from multiple disciplines and explicates four objectives for a comprehensive interpretive process. a conceptual model is proposed and further developed into a conceptual framework with fifteen considerations. this framework is then implemented and tested on an online platform to assess its impact on end-users\u2019 interpretation level. we believe the presented interpretive framework (predic) will help heritage professionals and media designers to develop interpretive heritage project.",
            "contribution_ids": [
                "R139813"
            ]
        },
        {
            "instance_id": "EMPTYxR135546",
            "comparison_id": "EMPTY",
            "paper_id": "R135546",
            "text": "Acute Lymphoblastic Leukemia Detection from Microscopic Images Using Weighted Ensemble of Convolutional Neural Networks \" although automated acute lymphoblastic leukemia (all) detection is essential, it is challenging due to the morphological correlation between malignant and normal cells. the traditional all classification strategy is arduous, time-consuming, often suffers inter-observer variations, and necessitates experienced pathologists. this article has automated the all detection task, employing deep convolutional neural networks (cnns). we explore the weighted ensemble of deep cnns to recommend a better all cell classifier. the weights are estimated from ensemble candidates' corresponding metrics, such as accuracy, f1-score, auc, and kappa values. various data augmentations and pre-processing are incorporated for achieving a better generalization of the network. we train and evaluate the proposed model utilizing the publicly available c-nmc-2019 all dataset. our proposed weighted ensemble model has outputted a weighted f1-score of 88.6%, a balanced accuracy of 86.2%, and an auc of 0.941 in the preliminary test set. the qualitative results displaying the gradient class activation maps confirm that the introduced model has a concentrated learned region. in contrast, the ensemble candidate models, such as xception, vgg-16, densenet-121, mobilenet, and inceptionresnet-v2, separately produce coarse and scatter learned areas for most example cases. since the proposed ensemble yields a better result for the aimed task, it can experiment in other domains of medical diagnostic applications. \"",
            "contribution_ids": [
                "R135550"
            ]
        },
        {
            "instance_id": "EMPTYxR74451",
            "comparison_id": "EMPTY",
            "paper_id": "R74451",
            "text": "Combining Linked Data and mobiles devices to improve access to OCW as the web becomes increasingly populated with diverse data, it continues evolving from a web of linked documents to a web linked data. this evolution allows relationships to be expressed between content in distributed data sets, enabling the way for integration of raw data from multiple knowledge domains and heterogeneous datasets. however, as the web becomes increasingly populated with linked data, there is also a need to support users with applications to visualize or to explore available data for a specific task, especially in mobile applications. examples of these tasks are consuming linked data, or creating new semantic relations between data entities, people and places. with the advent of mobiles, our views and behaviors about access/interaction the internet are shifting. specialized applications are available as an important alternative to replace a standard web browser for mobile access. in this article, authors show a three-tier client-server architecture using android framework. this architecture relies on the rdf data from linked opencourseware dataset. additionally, authors show three proof-of-concept based on architecture which integrates into a common used interface for rdf data management on mobile devices.",
            "contribution_ids": [
                "R74452",
                "R109095"
            ]
        },
        {
            "instance_id": "EMPTYxR196176",
            "comparison_id": "EMPTY",
            "paper_id": "R196176",
            "text": "Cambridge at SemEval-2021 Task 2: Neural WiC-Model with Data Augmentation and Exploration of Representation this paper describes the system of the cambridge team submitted to the semeval-2021 shared task on multilingual and cross-lingual word-in-context disambiguation. building on top of a pre-trained masked language model, our system is first pre-trained on out-of-domain data, and then fine-tuned on in-domain data. we demonstrate the effectiveness of the proposed two-step training strategy and the benefits of data augmentation from both existing examples and new resources. we further investigate different representations and show that the addition of distance-based features is helpful in the word-in-context disambiguation task. our system yields highly competitive results in the cross-lingual track without training on any cross-lingual data; and achieves state-of-the-art results in the multilingual track, ranking first in two languages (arabic and russian) and second in french out of 171 submitted systems.",
            "contribution_ids": [
                "R196178"
            ]
        },
        {
            "instance_id": "EMPTYxR170911",
            "comparison_id": "EMPTY",
            "paper_id": "R170911",
            "text": "Information Seeking Regarding Tobacco and Lung Cancer: Effects of Seasonality this paper conducted one of the first comprehensive international internet analyses of seasonal patterns in information seeking concerning tobacco and lung cancer. search query data for the terms \u201ctobacco\u201d and \u201clung cancer\u201d from january 2004 to january 2014 was collected from google trends. the relevant countries included the usa, canada, the uk, australia, and china. two statistical approaches including periodogram and cross-correlation were applied to analyze seasonal patterns in the collected search trends and their associations. for these countries except china, four out of six cross-correlations of seasonal components of the search trends regarding tobacco were above 0.600. for these english-speaking countries, similar patterns existed in the data concerning lung cancer, and all cross-correlations between seasonal components of the search trends regarding tobacco and that regarding lung cancer were also above 0.700. seasonal patterns widely exist in information seeking concerning tobacco and lung cancer on an international scale. the findings provide a piece of novel internet-based evidence for the seasonality and health effects of tobacco use.",
            "contribution_ids": [
                "R170912"
            ]
        },
        {
            "instance_id": "EMPTYxR194895",
            "comparison_id": "EMPTY",
            "paper_id": "R194895",
            "text": "Scalable Analysis of Real-Time Requirements detecting issues in real-time requirements is usually a trade-off between flexibility and cost: the effort expended depends on how expensive it is to fix a defect introduced by faulty, ambiguous or incomplete requirements. the most rigorous techniques for real-time requirement analysis depend on the formalisation of these requirements. completely formalised real-time requirements allow the detection of issues that are hard to find through other means, like real-time inconsistency (i.e., \"do the requirements lead to deadlocks and starvation of the system?\") or vacuity (i.e., \"are some requirements trivially satisfied\"). current analysis techniques for real-time requirements suffer from scalability issues \u2013 larger sets of such requirements are usually intractable. we present a new technique to analyse formalised real-time requirements for various properties. our technique leverages recent advances in software model checking and automatic theorem proving by converting the analysis problem for real-time requirements to a program analysis task. we also report preliminary results from an ongoing, large scale application of our technique in the automotive domain at bosch.",
            "contribution_ids": [
                "R194897"
            ]
        },
        {
            "instance_id": "EMPTYxR170085",
            "comparison_id": "EMPTY",
            "paper_id": "R170085",
            "text": "An upstream sequence modulates phenazine production at the level of transcription and translation in the biological control strain Pseudomonas chlororaphis 30-84 phenazines are bacterial secondary metabolites and play important roles in the antagonistic activity of the biological control strain p. chlororaphis 30\u201384 against take-all disease of wheat. the expression of the p. chlororaphis 30\u201384 phenazine biosynthetic operon (phzxyfabcd) is dependent on the phzr/phzi quorum sensing system located immediately upstream of the biosynthetic operon as well as other regulatory systems including gac/rsm. bioinformatic analysis of the sequence between the divergently oriented phzr and phzx promoters identified features within the 5\u2019-untranslated region (5\u2019-utr) of phzx that are conserved only among 2ohpca producing pseudomonas. the conserved sequence features are potentially capable of producing secondary structures that negatively modulate one or both promoters. transcriptional and translational fusion assays revealed that deletion of 90-bp of sequence at the 5\u2019-utr of phzx led to up to 4-fold greater expression of the reporters with the deletion compared to the controls, which indicated this sequence negatively modulates phenazine gene expression both transcriptionally and translationally. this 90-bp sequence was deleted from the p. chlororaphis 30\u201384 chromosome, resulting in 30-84enh, which produces significantly more phenazine than the wild-type while retaining quorum sensing control. the transcriptional expression of phzr/phzi and amount of ahl signal produced by 30-84enh also were significantly greater than for the wild-type, suggesting this 90-bp sequence also negatively affects expression of the quorum sensing genes. in addition, deletion of the 90-bp partially relieved rsme-mediated translational repression, indicating a role for gac/rsme interaction. compared to the wild-type, enhanced phenazine production by 30-84enh resulted in improvement in fungal inhibition, biofilm formation, extracellular dna release and suppression of take-all disease of wheat in soil without negative consequences on growth or rhizosphere persistence. this work provides greater insight into the regulation of phenazine biosynthesis with potential applications for improved biological control.",
            "contribution_ids": [
                "R170086",
                "R170087",
                "R170088"
            ]
        },
        {
            "instance_id": "EMPTYxR195868",
            "comparison_id": "EMPTY",
            "paper_id": "R195868",
            "text": "Boosting L2 Listening Comprehension Through Web-Based Listening Activities on Reduced Forms \" in the field of second language (l2) perception, there is a common adherence to quantitative methods to examine reduced forms (rfs). this chapter extends the field by reporting on an investigation that analyzed l2 listeners' perceptions of rfs in english from a qualitative perspective. rfs instruction through web-based activities was delivered to a total of 80 learners of english of varying proficiency for five weeks. twenty participants reflected on their performance on rfs listening tasks and provided justifications for their perceptions of the target rfs. qualitative analysis revealed that the rfs that influenced l2 learners' perceptions of rfs were linking, pause phenomena, and assimilation. the results of using such qualitative methodology highlights the important role that rfs plays in perception judgements in syllable-timed languages such as turkish, a factor which has not always been given much prominence in previous l2 fluency quantitative research. \"",
            "contribution_ids": [
                "R195870"
            ]
        },
        {
            "instance_id": "EMPTYxR193447",
            "comparison_id": "EMPTY",
            "paper_id": "R193447",
            "text": "CNN-based image analysis for malaria diagnosis malaria is a major global health threat. the standard way of diagnosing malaria is by visually examining blood smears for parasite-infected red blood cells under the microscope by qualified technicians. this method is inefficient and the diagnosis depends on the experience and the knowledge of the person doing the examination. automatic image recognition technologies based on machine learning have been applied to malaria blood smears for diagnosis before. however, the practical performance has not been sufficient so far. this study proposes a new and robust machine learning model based on a convolutional neural network (cnn) to automatically classify single cells in thin blood smears on standard microscope slides as either infected or uninfected. in a ten-fold cross-validation based on 27,578 single cell images, the average accuracy of our new 16-layer cnn model is 97.37%. a transfer learning model only achieves 91.99% on the same images. the cnn model shows superiority over the transfer learning model in all performance indicators such as sensitivity (96.99% vs 89.00%), specificity (97.75% vs 94.98%), precision (97.73% vs 95.12%), f1 score (97.36% vs 90.24%), and matthews correlation coefficient (94.75% vs 85.25%).",
            "contribution_ids": [
                "R193449"
            ]
        },
        {
            "instance_id": "EMPTYxR198689",
            "comparison_id": "EMPTY",
            "paper_id": "R198689",
            "text": "Stimulating Stakeholders' Imagination: New Creativity Triggers for Eliciting Novel Requirements requirements engineering is a creative process in which stakeholders and engineers work together to create ideas for new products, services and systems. several techniques have proved to be effective for eliciting creative requirements. yet, most of these techniques are heavy to implement and require long periods of time to be applied correctly. few lightweight creativity techniques have been developed for use in requirements engineering. one such lightweight technique is the creativity trigger, which provides simple guidance to stakeholders and engineers to help produce creative requirements. while easy to apply, creativity triggers were derived informally from experience of practitioners and have not been validated in a systematic way. this paper reports design and preliminary validation research, that sought to provide empirical foundations for a more complete set of lightweight creativity triggers, to be used by stakeholders and engineers to quickly and simply generate new and useful requirements on products, services and systems.",
            "contribution_ids": [
                "R198691"
            ]
        },
        {
            "instance_id": "EMPTYxR67647",
            "comparison_id": "EMPTY",
            "paper_id": "R67647",
            "text": "Quecksilber und Quecksilberverbindungen \u00e2\u0080\u0093 Bestimmung von Quecksilber in Blut und Urin mittels Kaltdampf\u00e2\u0080\u0090AAS [Biomonitoring Methods in German language, 2019] the working group \u201canalyses in biological materials\u201d of the permanent senate commission for the investigation of health hazards of chemical compounds in the work area validated the presented biomonitoring method. \\nmercury is determined by flow injection cold vapour atomic absorption spectrometry (cv\u2010aas). the digested blood or urine samples are stabilised with potassium permanganate, introduced into the acid carrier flow (hydrochloric acid) and mixed with the reducing agent sodium borohydride. mercury vapour formed by reduction is transported with an argon flow into the atomisation cell of the aa spectrometer. \\ncalibration is performed using matrix matched calibration solutions. the mercury concentrations in real samples are calculated from the linear relationship between the measured absorbance and the mass concentration of mercury.",
            "contribution_ids": [
                "R67648"
            ]
        },
        {
            "instance_id": "EMPTYxR74455",
            "comparison_id": "EMPTY",
            "paper_id": "R74455",
            "text": "Using linked open data to improve the search of open educational resources for engineering students in this paper, authors apply the linked data design issues to describe and retrieve information that is semantically related to open educational resources related to the engineering education, that are accessible via the ocw higher institutions. linked data have the potential of create bridges between ocw data silos. to assess the impact of linked data in ocw, the authors present an interface of faceted search for open educational content. the authors demonstrate that ocw resource metadata related to engineering open courses can be consumed and enriched using datasets hosted by the linkedopendata cloud.",
            "contribution_ids": [
                "R74456",
                "R109097"
            ]
        },
        {
            "instance_id": "EMPTYxR188068",
            "comparison_id": "EMPTY",
            "paper_id": "R188068",
            "text": "Gender Inequality in Research Productivity During the COVID-19 Pandemic problem definition: we study the disproportionate impact of the lockdown as a result of the covid-19 outbreak on female and male academic research productivity in social science. academic/practical relevance: the lockdown has caused substantial disruptions to academic activities, requiring people to work from home. how this disruption affects productivity and the related gender equity is an important operations and societal question. methodology: we collect data from the largest open-access preprint repository for social science on 41,858 research preprints in 18 disciplines produced by 76,832 authors across 25 countries over a span of two years. we use a difference-in-differences approach leveraging the exogenous pandemic shock. results: our results indicate that, in the 10 weeks after the lockdown in the united states, although total research productivity increased by 35%, female academics\u2019 productivity dropped by 13.2% relative to that of male academics. we also show that this intensified productivity gap is more pronounced for assistant professors and for academics in top-ranked universities and is found in six other countries. managerial implications: our work points out the fairness issue in productivity caused by the lockdown, a finding that universities will find helpful when evaluating faculty productivity. it also helps organizations realize the potential unintended consequences that can arise from telecommuting.",
            "contribution_ids": [
                "R188073"
            ]
        },
        {
            "instance_id": "EMPTYxR129805",
            "comparison_id": "EMPTY",
            "paper_id": "R129805",
            "text": "Improving Neural Language Modeling via Adversarial Training recently, substantial progress has been made in language modeling by using deep neural networks. however, in practice, large scale neural language models have been shown to be prone to overfitting. in this paper, we present a simple yet highly effective adversarial training mechanism for regularizing neural language models. the idea is to introduce adversarial noise to the output embedding layer while training the models. we show that the optimal adversarial noise yields a simple closed-form solution, thus allowing us to develop a simple and time efficient algorithm. theoretically, we show that our adversarial mechanism effectively encourages the diversity of the embedding vectors, helping to increase the robustness of models. empirically, we show that our method improves on the single model state-of-the-art results for language modeling on penn treebank (ptb) and wikitext-2, achieving test perplexity scores of 46.01 and 38.07, respectively. when applied to machine translation, our method improves over various transformer-based translation baselines in bleu scores on the wmt14 english-german and iwslt14 german-english tasks.",
            "contribution_ids": [
                "R129806",
                "R129809",
                "R129812",
                "R129821"
            ]
        },
        {
            "instance_id": "EMPTYxR151319",
            "comparison_id": "EMPTY",
            "paper_id": "R151319",
            "text": "S2ORC: The Semantic Scholar Open Research Corpus we introduce s2orc, a large corpus of 81.1m english-language academic papers spanning many academic disciplines. the corpus consists of rich metadata, paper abstracts, resolved bibliographic references, as well as structured full text for 8.1m open access papers. full text is annotated with automatically-detected inline mentions of citations, figures, and tables, each linked to their corresponding paper objects. in s2orc, we aggregate papers from hundreds of academic publishers and digital archives into a unified source, and create the largest publicly-available collection of machine-readable academic text to date. we hope this resource will facilitate research and development of tools and tasks for text mining over academic text.",
            "contribution_ids": [
                "R151321"
            ]
        },
        {
            "instance_id": "EMPTYxR171070",
            "comparison_id": "EMPTY",
            "paper_id": "R171070",
            "text": "Exploring the Spatial Association between Social Deprivation and Cardiovascular Disease Mortality at the Neighborhood Level cardiovascular disease (cvd), the leading cause of death in the united states, is impacted by neighborhood-level factors including social deprivation. to measure the association between social deprivation and cvd mortality in harris county, texas, global (ordinary least squares (ols) and local (geographically weighted regression (gwr)) models were built. the models explored the spatial variation in the relationship at a census-tract level while controlling for age, income by race, and education. a significant and spatially varying association (p < .01) was found between social deprivation and cvd mortality, when controlling for all other factors in the model. the gwr model provided a better model fit over the analogous ols model (r2 = .65 vs. .57), reinforcing the importance of geography and neighborhood of residence in the relationship between social deprivation and cvd mortality. findings from the gwr model can be used to identify neighborhoods at greatest risk for poor health outcomes and to inform the placement of community-based interventions.",
            "contribution_ids": [
                "R171071"
            ]
        },
        {
            "instance_id": "EMPTYxR171213",
            "comparison_id": "EMPTY",
            "paper_id": "R171213",
            "text": "Routine Outcome Monitoring and Clinical Decision-Making in Forensic Psychiatry Based on the Instrument for Forensic Treatment Evaluation background rehabilitation in forensic psychiatry is achieved gradually with different leave modules, in line with the risk need responsivity model. a forensic routine outcome monitoring tool should measure treatment progress based on the rehabilitation theory, and it should be predictive of important treatment outcomes in order to be usable in decision-making. therefore, this study assesses the predictive validity for both positive (i.e., leave) and negative (i.e., inpatient incidents) treatment outcomes with the instrument for forensic treatment evaluation (ifte). methods two-hundred and twenty-four patients were included in this study. roc analyses were conducted with the ifte factors and items for three leave modules: guided, unguided and transmural leave for the whole group of patients. predictive validity of the ifte for aggression in general, physical aggression specifically, and urine drug screening (uds) violations was assessed for patients with the main diagnoses in dutch forensic psychiatry, patients with personality disorders and the most frequently occurring co-morbid disorders: those with combined personality and substance use disorders. results and conclusions results tentatively imply that the ifte has a reasonable to good predictive validity for inpatient aggression and a marginal to reasonable predictive value for leave approvals and uds violations. the ifte can be used for information purposes in treatment decision-making, but reports should be interpreted with care and acknowledge patients\u2019 personal risk factors, strengths and other information sources.",
            "contribution_ids": [
                "R171214"
            ]
        },
        {
            "instance_id": "EMPTYxR170470",
            "comparison_id": "EMPTY",
            "paper_id": "R170470",
            "text": "Self-Reported Health Status in Primary Health Care: The Influence of Immigration and Other Associated Factors objective the aims of this study are to compare self-reported health status between spanish-born and latin american-born spanish residents, adjusted by length of residence in the host country; and additionally, to analyse sociodemographic and psychosocial variables associated with a better health status. design this is a cross-sectional population based study of latin american-born (n\\u200a=\\u200a691) and spanish-born (n\\u200a=\\u200a903) in 15 urban primary health care centres in madrid (spain), carried out between 2007 and 2009. the participants provided information, through an interview, about self-reported health status, socioeconomic characteristics, psychosocial factors and migration conditions. descriptive and multiple logistic regression analyses were conducted. results the spanish-born participants reported a better health status than the latin america-born participants (79.8% versus 69.3%, p<0.001). different patterns of self-reported health status were observed depending on the length of residence in the host country. the proportion of immigrants with a better health status is greater in those who have been in spain for less than five years compared to those who have stayed longer. better health status is significantly associated with being men, under 34 years old, being spanish-born, having a monthly incomes of over 1000 euros, and having considerable social support and low stress. conclusions better self-reported health status is associated with being spanish-born, men, under 34 years old, having an uppermiddle-socioeconomic status, adequate social support, and low stress. additionally, length of residence in the host country is seen as a related factor in the self-reported health status of immigrants.",
            "contribution_ids": [
                "R170471",
                "R170472"
            ]
        },
        {
            "instance_id": "EMPTYxR170224",
            "comparison_id": "EMPTY",
            "paper_id": "R170224",
            "text": "Prevalence of functional constipation among Palestinian preschool children and the relation to stressful life events aim increasing evidence exists with respect to the relation between stressful life events and functional constipation (fc). we aimed to investigate the prevalence of fc in palestinian refugee preschool children and to determine if stress and trauma exposure are risk factors of fc in these children. methods from november 2013 until may 2014, a cross-sectional survey was conducted in west bank, gaza and jordan. mothers of 862 palestinian refugee children aged 7\u201348 months were interviewed on defecation pattern, socio-economic factors and the child\u2019s exposure to traumatic events. results twelve percent of the palestinian refugee children fulfilled the criteria for fc. the prevalence of constipation was significantly lower in gaza compared to jordan (2% vs. 17%, p <0,001). living in gaza was associated with lower odds of fc (or 0,08, 95% ci 0,03\u20130,20). trauma exposure was associated with higher odds of fc (or 1,19, 95% ci 1,06\u20131,35), however only a small number of children had been exposed to traumatic events. conclusion the overall prevalence of fc in palestinian preschool children is comparable to prevalence rates among older children worldwide. in this age group stressful life events and trauma exposure seem not to play an important role in the development of fc.",
            "contribution_ids": [
                "R170225"
            ]
        },
        {
            "instance_id": "EMPTYxR196723",
            "comparison_id": "EMPTY",
            "paper_id": "R196723",
            "text": "HDT-UD: A very large Universal Dependencies treebank for German we report on the conversion of the hamburg dependency treebank (foth et al., 2014) to universal dependencies. the hdt consists of more than 200.000 sentences annotated with dependency structure, making every attempt at manual conversion or manual post-processing extremely costly. the conversion employs an unranked tree transducer. this formalism allows to express transformation rules in a concise way, guarantees the well-formedness of the output and is predictable to the rule writers. together with the release of a converted subset of the hdt spanning 3 million tokens, we release an interactive workbench for writing and refining tree transducer rules. our conversion achieves a very high labeled accuracy with respect to a manually converted gold standard of 97.3%. up to now, the conversion effort took about 1000 hours of work.",
            "contribution_ids": [
                "R196725"
            ]
        },
        {
            "instance_id": "EMPTYxR49126",
            "comparison_id": "EMPTY",
            "paper_id": "R49126",
            "text": "Adjusting Mitigation Pathways to Stabilize Climate at 1.5\u00c2\u00b0C and 2.0\u00c2\u00b0C Rise in Global Temperatures to Year 2300 to avoid the most dangerous consequences of anthropogenic climate change, the paris agreement provides a clear and agreed climate mitigation target of stabilizing global surface warming to under 2.0\u00b0c above preindustrial, and preferably closer to 1.5\u00b0c. however, policy makers do not currently know exactly what carbon emissions pathways to follow to stabilize warming below these agreed targets, because there is large uncertainty in future temperature rise for any given pathway. this large uncertainty makes it difficult for a cautious policy maker to avoid either: (1) allowing warming to exceed the agreed target or (2) cutting global emissions more than is required to satisfy the agreed target, and their associated societal costs. this study presents a novel adjusting mitigation pathway (amp) approach to restrict future warming to policy\u2010driven targets, in which future emissions reductions are not fully determined now but respond to future surface warming each decade in a self\u2010adjusting manner. a large ensemble of earth system model simulations, constrained by geological and historical observations of past climate change, demonstrates our self\u2010adjusting mitigation approach for a range of climate stabilization targets ranging from 1.5\u00b0c to 4.5\u00b0c, and generates amp scenarios up to year 2300 for surface warming, carbon emissions, atmospheric co2, global mean sea level, and surface ocean acidification. we find that lower 21st century warming targets will significantly reduce ocean acidification this century, and will avoid up to 4 m of sea\u2010level rise by year 2300 relative to a high\u2010end scenario.",
            "contribution_ids": [
                "R49129",
                "R49133"
            ]
        },
        {
            "instance_id": "EMPTYxR6689",
            "comparison_id": "EMPTY",
            "paper_id": "R6689",
            "text": "AdaSum: an adaptive model for summarization topic representation mismatch is a key problem in topic-oriented summarization for the specified topic is usually too short to understand/interpret. this paper proposes a novel adaptive model for summarization, adasum, under the assumption that the summary and the topic representation can be mutually boosted. adasum aims to simultaneously optimize the topic representation and extract effective summaries. this model employs a mutual boosting process to minimize the topic representation mismatch for base summarizers. furthermore, a linear combination of base summarizers is proposed to further reduce the topic representation mismatch from the diversity of base summarizers with a general learning framework. we prove that the training process of adasum can enhance the performance measure used. experimental results on duc 2007 dataset show that adasum significantly outperforms the baseline methods for summarization (e.g. mrp, lexrank, and gsps).",
            "contribution_ids": [
                "R6690"
            ]
        },
        {
            "instance_id": "EMPTYxR38559",
            "comparison_id": "EMPTY",
            "paper_id": "R38559",
            "text": "Semi-supervised identification of rarely appearing persons in video by correcting weak labels some recent approaches for character identification in movies and tv broadcasts are realized in a semi-supervised manner by assigning transcripts and/or subtitles to the speakers. however, the labels obtained in this way achieve only an accuracy of $80\\\\% - 90\\\\%$ and the number of training examples for the different actors is unevenly distributed. in this paper, we propose a novel approach for person identification in video by correcting and extending the training data with reliable predictions to reduce the number of annotation errors. furthermore, the intra-class diversity of rarely speaking characters is enhanced. to address the imbalance of training data per person, we suggest two complementary prediction scores. these scores are also used to recognize whether or not a face track belongs to a (supporting) character whose identity does not appear in the transcript etc. experimental results demonstrate the feasibility of the proposed approach, outperforming the current state of the art.",
            "contribution_ids": [
                "R38561"
            ]
        },
        {
            "instance_id": "EMPTYxR171325",
            "comparison_id": "EMPTY",
            "paper_id": "R171325",
            "text": "Quality of reproductive healthcare for adolescents: A nationally representative survey of providers in Mexico objective adolescents need sexual and reproductive health services but little is known about quality-of-care in lower- and middle-income countries where most of the world\u2019s adolescents reside. quality-of-care has important implications as lower quality may be linked to higher unplanned pregnancy and sexually transmitted infection rates. this study sought to generate evidence about quality-of-care in public sexual and reproductive health services for adolescents. methods this cross-sectional study had a complex, probabilistic, stratified sampling design, representative at the national, regional and rural/urban level in mexico, collecting provider questionnaires at 505 primary care units in 2012. a sexual and reproductive quality-of-healthcare index was defined and multinomial logistic regression was utilized in 2015. results at the national level 13.9% (95%ci: 6.9\u201326.0) of healthcare units provide low quality, 68.6% (95%ci: 58.4\u201377.3) medium quality and 17.5% (95%ci: 11.9\u201325.0) high quality reproductive healthcare services to adolescents. urban or metropolitan primary care units were at least 10 times more likely to provide high quality care than those in rural areas. units with a space specifically for counseling adolescents were at least 8 times more likely to provide high quality care. ministry of health clinics provided the lowest quality of service, while those from social security for the underserved provided the best. conclusions the study indicates higher quality sexual and reproductive healthcare services are needed. in mexico and other middle- to low-income countries where quality-of-care has been shown to be a problem, incorporating adolescent-friendly, gender-equity and rights-based perspectives could contribute to improvement. setting and disseminating standards for care in guidelines and providing tools such as algorithms could help healthcare personnel provide higher quality care.",
            "contribution_ids": [
                "R171326"
            ]
        },
        {
            "instance_id": "EMPTYxR75148",
            "comparison_id": "EMPTY",
            "paper_id": "R75148",
            "text": "Ontologies as a semantic model in IoT abstract the world is witnessing an increasing use of iot-based devices to collect sensor data in order to perceive the real world and generate abstractions. this data is highly heterogeneous in nature as it is obtained from various domains utilizing different representation schemes. semantic approaches come as a rescue to this interoperability problem incurred because of heterogeneous sensor data from iot devices. the data thus obtained should be represented in form of ontologies which are considered as the cornerstone of the semantic web for knowledge sharing, information extraction, information integration and many more. the content and the quality of the ontologies should be analyzed by evaluating them to ensure that the ontology is well designed, structured, and contains all essential concepts and relationships between them for efficient reasoning. this paper focuses on the evaluation of ontologies and, as a case study, evaluates a military resource ontology (mro) by using evaluation tools such as ontometric, oops!, ontocom, based on evaluation approaches, aspects and criteria. these tools detect errors by diagnosing various metrics and pitfalls. evaluation methods are grouped in two phases: verification and validation. in this paper, \u2018queryonto\u2019 tool is introduced to verify and validate the mro by searching, query/answering, and visualizing.",
            "contribution_ids": [
                "R75150"
            ]
        },
        {
            "instance_id": "EMPTYxR131636",
            "comparison_id": "EMPTY",
            "paper_id": "R131636",
            "text": "Multilingual Models for Compositional Distributed Semantics we present a novel technique for learning semantic representations, which extends the distributional hypothesis to multilingual data and joint-space embeddings. our models leverage parallel data and learn to strongly align the embeddings of semantically equivalent sentences, while maintaining sufficient distance between those of dissimilar sentences. the models do not rely on word alignments or any syntactic information and are successfully applied to a number of diverse languages. we extend our approach to learn semantic representations at the document level, too. we evaluate these models on two cross-lingual document classification tasks, outperforming the prior state of the art. through qualitative analysis and the study of pivoting effects we demonstrate that our representations are semantically plausible and can capture semantic relationships across languages without parallel data.",
            "contribution_ids": [
                "R131637"
            ]
        },
        {
            "instance_id": "EMPTYxR8048",
            "comparison_id": "EMPTY",
            "paper_id": "R8048",
            "text": "Future changes of wind energy potentials over Europe in\u00c2\u00a0a\u00c2\u00a0large CMIP5 multi-model ensemble: FUTURE CHANGES OF WIND ENERGY OVER EUROPE IN A CMIP5 ENSEMBLE a statistical\u2010dynamical downscaling method is used to estimate future changes of wind energy output (eout) of a benchmark wind turbine across europe at the regional scale. with this aim, 22 global climate models (gcms) of the coupled model intercomparison project phase 5 (cmip5) ensemble are considered. the downscaling method uses circulation weather types and regional climate modelling with the cosmo\u2010clm model. future projections are computed for two time periods (2021\u20132060 and 2061\u20132100) following two scenarios (rcp4.5 and rcp8.5). the cmip5 ensemble mean response reveals a more likely than not increase of mean annual eout over northern and central europe and a likely decrease over southern europe. there is some uncertainty with respect to the magnitude and the sign of the changes. higher robustness in future changes is observed for specific seasons. except from the mediterranean area, an ensemble mean increase of eout is simulated for winter and a decreasing for the summer season, resulting in a strong increase of the intra\u2010annual variability for most of europe. the latter is, in particular, probable during the second half of the 21st century under the rcp8.5 scenario. in general, signals are stronger for 2061\u20132100 compared to 2021\u20132060 and for rcp8.5 compared to rcp4.5. regarding changes of the inter\u2010annual variability of eout for central europe, the future projections strongly vary between individual models and also between future periods and scenarios within single models. this study showed for an ensemble of 22 cmip5 models that changes in the wind energy potentials over europe may take place in future decades. however, due to the uncertainties detected in this research, further investigations with multi\u2010model ensembles are needed to provide a better quantification and understanding of the future changes.",
            "contribution_ids": [
                "R8049"
            ]
        },
        {
            "instance_id": "EMPTYxR188119",
            "comparison_id": "EMPTY",
            "paper_id": "R188119",
            "text": "COVID-19 Knowledge Graph: Accelerating Information Retrieval and Discovery for Scientific Literature the coronavirus disease (covid-19) has claimed the lives of over one million people and infected more than thirty-five million people worldwide. several search engines have surfaced to provide researchers with additional tools to find and retrieve information from the rapidly growing corpora on covid19. these engines lack extraction and visualization tools necessary to retrieve and interpret complex relations inherent to scientific literature. moreover, because these engines mainly rely upon semantic information, their ability to capture complex global relationships across documents is limited, which reduces the quality of similarity-based article recommendations for users. in this work, we present the covid-19 knowledge graph (ckg), a heterogeneous graph for extracting and visualizing complex relationships between covid-19 scientific articles. the ckg combines semantic information with document topological information for the application of similar document retrieval. the ckg is constructed using the latent schema of the data, and then enriched with biomedical entity information extracted from the unstructured text of articles using scalable aws technologies to form relations in the graph. finally, we propose a document similarity engine that leverages low-dimensional graph embeddings from the ckg with semantic embeddings for similar article retrieval. analysis demonstrates the quality of relationships in the ckg and shows that it can be used to uncover meaningful information in covid-19 scientific articles. the ckg helps power www.cord19.aws and is publicly available.",
            "contribution_ids": [
                "R188121"
            ]
        },
        {
            "instance_id": "EMPTYxR170748",
            "comparison_id": "EMPTY",
            "paper_id": "R170748",
            "text": "Coping with Stress and Types of Burnout: Explanatory Power of Different Coping Strategies background burnout occurs when professionals use ineffective coping strategies to try to protect themselves from work-related stress. the dimensions of \u2018overload\u2019, \u2018lack of development\u2019 and \u2018neglect\u2019, belonging to the \u2018frenetic\u2019, \u2018under-challenged\u2019 and \u2018worn-out\u2019 subtypes, respectively, comprise a brief typological definition of burnout. the aim of the present study was to estimate the explanatory power of the different coping strategies on the development of burnout subtypes. methods this was a cross-sectional survey with a random sample of university employees, stratified by occupation (n\\u200a=\\u200a429). multivariate linear regression models were constructed between the \u2018burnout clinical subtypes questionnaire\u2019, with its three dimensions \u2013overload, lack of development and neglect\u2013 as dependent variables, and the \u2018coping orientation for problem experiences\u2019, with its fifteen dimensions, as independent variables. adjusted multiple determination coefficients and beta coefficients were calculated to evaluate and compare the explanatory capacity of the different coping strategies. results the \u2018coping orientation for problem experiences\u2019 subscales together explained 15% of the \u2018overload\u2019 (p<0.001), 9% of the \u2018lack of development\u2019 (p<0.001), and 21% of the \u2018neglect\u2019 (p<0.001). \u2018overload\u2019 was mainly explained by \u2018venting of emotions\u2019 (beta\\u200a=\\u200a0.34; p<0.001); \u2018lack of development\u2019 by \u2018cognitive avoidance\u2019 (beta\\u200a=\\u200a0.21; p<0.001); and \u2018neglect\u2019 by \u2018behavioural disengagement\u2019 (beta\\u200a=\\u200a0.40; p<0.001). other interesting associations were observed. conclusions these findings further our understanding of the way in which the effectiveness of interventions for burnout may be improved, by influencing new treatments and preventive programmes using features of the strategies for handling stress in the workplace.",
            "contribution_ids": [
                "R170749"
            ]
        },
        {
            "instance_id": "EMPTYxR195153",
            "comparison_id": "EMPTY",
            "paper_id": "R195153",
            "text": "Efficiency and Effectiveness of Requirements Elicitation Techniques for Children [context] the market for software targeting children, both for education and entertainment, is growing. existing work, mainly from hci, has considered the effectiveness of elicitation techniques for eliciting requirements from children as part of a design process. [objective] however, we are lacking work which compares requirements elicitation techniques when used with children. [methods] this study compares five elicitation techniques, taking into consideration the effectiveness and efficiency of each technique. techniques were used with a total of 54 children aged 8-13, eliciting requirements for a museum flight simulator. we compare techniques by looking at the number and type of requirements discovered, perceived participant satisfaction, resources required, perceived usefulness, and requirements coverage of domain specific categories. [conclusions] we observed notable differences between the techniques, including the effectiveness of observations and relative ineffectiveness of questionnaires. we present a set of guidelines to aid industry in eliciting requirements for child-friendly software.",
            "contribution_ids": [
                "R195154"
            ]
        },
        {
            "instance_id": "EMPTYxR130871",
            "comparison_id": "EMPTY",
            "paper_id": "R130871",
            "text": "Partially Shuffling the Training Data to Improve Language Models although sgd requires shuffling the training data between epochs, currently none of the word-level language modeling systems do this. naively shuffling all sentences in the training data would not permit the model to learn inter-sentence dependencies. here we present a method that partially shuffles the training data between epochs. this method makes each batch random, while keeping most sentence ordering intact. it achieves new state of the art results on word-level language modeling on both the penn treebank and wikitext-2 datasets.",
            "contribution_ids": [
                "R130872",
                "R130881"
            ]
        },
        {
            "instance_id": "EMPTYxR49152",
            "comparison_id": "EMPTY",
            "paper_id": "R49152",
            "text": "REDI: Towards knowledge graph-powered scholarly information management and research networking academic data management has become an increasingly challenging task as research evolves over time. essential tasks such as information retrieval and research networking have turned into extremely difficult operations due to an ever-growing number of researchers and scientific articles. numerous initiatives have emerged in the it environments to address this issue, especially focused on web technologies. although those approaches have individually provided solutions for diverse problems, they still can not offer integrated knowledge bases nor flexibility to exploit adequately this information. in this article, we present redi, a linked data-powered framework for academic knowledge management and research networking, which introduces a new perspective of integration. redi combines information from multiple sources into a consolidated knowledge base through state-of-the-art procedures and leverages semantic web standards to represent the information. moreover, redi takes advantage of such knowledge for data visualisation and analysis, which ultimately improves and simplifies many activities including research networking.",
            "contribution_ids": [
                "R49155"
            ]
        },
        {
            "instance_id": "EMPTYxR171327",
            "comparison_id": "EMPTY",
            "paper_id": "R171327",
            "text": "C-tactile afferent stimulating touch carries a positive affective value the rewarding sensation of touch in affiliative interactions is hypothesized to be underpinned by a specialized system of nerve fibers called c-tactile afferents (cts), which respond optimally to slowly moving, gentle touch, typical of a caress. however, empirical evidence to support the theory that cts encode socially relevant, rewarding tactile information in humans is currently limited. while in healthy participants, touch applied at ct optimal velocities (1-10cm/sec) is reliably rated as subjectively pleasant, neuronopathy patients lacking large myelinated afferents, but with intact c-fibres, report that the conscious sensation elicited by stimulation of cts is rather vague. given this weak perceptual impact the value of self-report measures for assessing the specific affective value of ct activating touch appears limited. therefore, we combined subjective ratings of touch pleasantness with implicit measures of affective state (facial electromyography) and autonomic arousal (heart rate) to determine whether ct activation carries a positive affective value. we recorded the activity of two key emotion-relevant facial muscle sites (zygomaticus major\u2014smile muscle, positive affect & corrugator supercilii\u2014frown muscle, negative affect) while participants evaluated the pleasantness of experimenter administered stroking touch, delivered using a soft brush, at two velocities (ct optimal 3cm/sec & ct non-optimal 30cm/sec), on two skin sites (ct innervated forearm & non-ct innervated palm). on both sites, 3cm/sec stroking touch was rated as more pleasant and produced greater heart rate deceleration than 30cm/sec stimulation. however, neither self-report ratings nor heart rate responses discriminated stimulation on the ct innervated arm from stroking of the non-ct innervated palm. in contrast, significantly greater activation of the zygomaticus major (smiling muscle) was seen specifically to ct optimal, 3cm/sec, stroking on the forearm in comparison to all other stimuli. these results offer the first empirical evidence in humans that tactile stimulation that optimally activates cts carries a positive affective valence that can be measured implicitly.",
            "contribution_ids": [
                "R171328",
                "R171329"
            ]
        },
        {
            "instance_id": "EMPTYxR144086",
            "comparison_id": "EMPTY",
            "paper_id": "R144086",
            "text": "A cationic fluorescent polymeric thermometer for the ratiometric sensing of intracellular temperature the temperature-dependent fluorescence spectra of a new polymeric thermometer enabled highly sensitive and practical ratiometric temperature sensing inside mammalian cells.",
            "contribution_ids": [
                "R144088"
            ]
        },
        {
            "instance_id": "EMPTYxR76164",
            "comparison_id": "EMPTY",
            "paper_id": "R76164",
            "text": "Patterns and Correlates for Bullying among Young Adolescents in Ghana bullying is relatively common and is considered to be a public health problem among adolescents worldwide. the present study examined the risk factors associated with bullying behavior among adolescents in a lower-middle-income country setting. data on 6235 adolescents aged 11\u201316 years, derived from the republic of ghana\u2019s contribution to the global school-based health survey, were analyzed using bivariate and multinomial logistic regression analysis. a high prevalence of bullying was found among ghanaian adolescents. alcohol-related health compromising behaviors (alcohol use, alcohol misuse and getting into trouble as a result of alcohol) increased the risk of being bullied. in addition, substance use, being physically attacked, being seriously injured, hunger and truancy were also found to increase the risk of being bullied. however, having understanding parents and having classmates who were kind and helpful reduced the likelihood of being bullied. these findings suggest that school-based intervention programs aimed at reducing rates of peer victimization should simultaneously target multiple risk behaviors. teachers can also reduce peer victimization by introducing programs that enhance adolescents\u2019 acceptance of each other in the classroom.",
            "contribution_ids": [
                "R76166"
            ]
        },
        {
            "instance_id": "EMPTYxR134578",
            "comparison_id": "EMPTY",
            "paper_id": "R134578",
            "text": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale while the transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. in vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. we show that this reliance on cnns is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. when pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (imagenet, cifar-100, vtab, etc.), vision transformer (vit) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.",
            "contribution_ids": [
                "R134579",
                "R134602",
                "R134625",
                "R134628"
            ]
        },
        {
            "instance_id": "EMPTYxR186138",
            "comparison_id": "EMPTY",
            "paper_id": "R186138",
            "text": "ShEx-Lite: Automatic Generation of Domain Object Models from a Shape Expressions Subset Language shape expressions (shex) was defined as a human-readable and concise language to describe and validate rdf. in the last years, the usage of shex has grown and more functionalities are being demanded. one such functionality is to ensure interoperability between shex schemas and domain models in programming languages. in this paper, we present shex-lite, a tabular based subset of shex that allows to generate domain object models in different object-oriented languages. although the current system generates java and python, it offers a public interface so anyone can implement code generation in other programming languages. the system has been employed in a workflow where the shape expressions are used both to define constraints over an ontology and to generate domain objects that will be part of a clean architecture style.",
            "contribution_ids": [
                "R186140"
            ]
        },
        {
            "instance_id": "EMPTYxR129793",
            "comparison_id": "EMPTY",
            "paper_id": "R129793",
            "text": "Unsupervised Neural Machine Translation with Weight Sharing unsupervised neural machine translation (nmt) is a recently proposed approach for machine translation which aims to train the model without using any labeled data. the models proposed for unsupervised nmt often use only one shared encoder to map the pairs of sentences from different languages to a shared-latent space, which is weak in keeping the unique and internal characteristics of each language, such as the style, terminology, and sentence structure. to address this issue, we introduce an extension by utilizing two independent encoders but sharing some partial weights which are responsible for extracting high-level representations of the input sentences. besides, two different generative adversarial networks (gans), namely the local gan and global gan, are proposed to enhance the cross-language translation. with this new approach, we achieve significant improvements on english-german, english-french and chinese-to-english translation tasks.",
            "contribution_ids": [
                "R129794"
            ]
        },
        {
            "instance_id": "EMPTYxR110357",
            "comparison_id": "EMPTY",
            "paper_id": "R110357",
            "text": "Simultaneous laser doping and annealing to form lateral p\u00e2\u0080\u0093n junction diode structure on silicon carbide films laser-assisted doping of intrinsic silicon carbide (sic) films deposited on si (100) substrates by pulsed laser deposition (pld) method and its influence on simultaneous annealing of the thin film is studied. pld grown intrinsic sic films are transformed to p-type sic and n-type sic, using laser-assisted doping in aqueous aluminum chloride and phosphoric solutions, respectively. simultaneous doping and annealing of the sic film are observed during laser-assisted doping. by precisely positioning the selectively doped region, lateral p\u2013n diodes are formed on the sic films without using any mask. electric characteristics confirmed the formation of a lateral p\u2013n diode structure. numerical analysis of temperature distribution along the depth of the sic films explains the mechanism of simultaneous doping and annealing during the laser treatment.",
            "contribution_ids": [
                "R110360"
            ]
        },
        {
            "instance_id": "EMPTYxR171247",
            "comparison_id": "EMPTY",
            "paper_id": "R171247",
            "text": "Open-Access Mega-Journals: A Bibliometric Profile in this paper we present the first comprehensive bibliometric analysis of eleven open-access mega-journals (oamjs). oamjs are a relatively recent phenomenon, and have been characterised as having four key characteristics: large size; broad disciplinary scope; a gold-oa business model; and a peer-review policy that seeks to determine only the scientific soundness of the research rather than evaluate the novelty or significance of the work. our investigation focuses on four key modes of analysis: journal outputs (the number of articles published and changes in output over time); oamj author characteristics (nationalities and institutional affiliations); subject areas (the disciplinary scope of oamjs, and variations in sub-disciplinary output); and citation profiles (the citation distributions of each oamj, and the impact of citing journals). we found that while the total output of the eleven mega-journals grew by 14.9% between 2014 and 2015, this growth is largely attributable to the increased output of scientific reports and medicine. we also found substantial variation in the geographical distribution of authors. several journals have a relatively high proportion of chinese authors, and we suggest this may be linked to these journals\u2019 high journal impact factors (jifs). the mega-journals were also found to vary in subject scope, with several journals publishing disproportionately high numbers of articles in certain sub-disciplines. our citation analsysis offers support for bj\u00f6rk & catani\u2019s suggestion that oamjs\u2019s citation distributions can be similar to those of traditional journals, while noting considerable variation in citation rates across the eleven titles. we conclude that while the oamj term is useful as a means of grouping journals which share a set of key characteristics, there is no such thing as a \u201ctypical\u201d mega-journal, and we suggest several areas for additional research that might help us better understand the current and future role of oamjs in scholarly communication.",
            "contribution_ids": [
                "R171248",
                "R171249"
            ]
        },
        {
            "instance_id": "EMPTYxR197296",
            "comparison_id": "EMPTY",
            "paper_id": "R197296",
            "text": "Developing a Multilingual Annotated Corpus of Misogyny and Aggression in this paper, we discuss the development of a multilingual annotated corpus of misogyny and aggression in indian english, hindi, and indian bangla as part of a project on studying and automatically identifying misogyny and communalism on social media (the comma project). the dataset is collected from comments on youtube videos and currently contains a total of over 20,000 comments. the comments are annotated at two levels - aggression (overtly aggressive, covertly aggressive, and non-aggressive) and misogyny (gendered and non-gendered). we describe the process of data collection, the tagset used for annotation, and issues and challenges faced during the process of annotation. finally, we discuss the results of the baseline experiments conducted to develop a classifier for misogyny in the three languages.",
            "contribution_ids": [
                "R197298"
            ]
        },
        {
            "instance_id": "EMPTYxR74395",
            "comparison_id": "EMPTY",
            "paper_id": "R74395",
            "text": "Framework for the integration of digital resources based-on a Semantic Web approach [Marco de Trabajo para la Integraci\u00c3\u00b3n de Recursos Digitales Basado en un Enfoque de Web Sem\u00c3\u00a1ntica] espanolen un entorno abierto como la web, no es posible estandarizar los procesos de descripcion y publicacion de metadatos, cada institucion puede manejar diferentes formatos o modelos de datos. para mejorar la interoperabilidad semantica entre repositorios heterogeneos, se estan adoptando enfoques basados en tecnologias de la web semantica; de esta manera, cada libreria digital puede conservar sus cualidades locales especificas y no requerira resignarlas para poder normalizar el intercambio, reuso o la cosecha de recursos digitales. en este trabajo, se presenta un ciclo que cubre los procesos de: extraccion de metadatos desde repositorios oai-pmh, y la generacion y publicacion de datos enlazados, con el proposito de mejorar la integracion e interoperabilidad de recursos almacenados en librerias digitales. la propuesta descrita facilita la existencia de diversidad de metodos y estandares en los procesos de cada proveedor de recursos digitales. englishfrom the point of view of access to metadata from distributed repositories, the open archives initiative (oai) proposed a protocol for the interchange and harvesting of metadata called oai-pmh. this protocol provide a low degree of interoperability, however, with an approach based on semantic technologies, the interoperability of data can reach a higher level; thus, each digital library can retain their specific local qualities and will not require reassign them in order to standardize the exchange, re-use or harvesting of digital resources. in this paper, the process for the extraction of metadata, generation and publishing linked data in order to improve integration and interoperability between resources stored on digital libraries is presented. the proposal facilitates the existence of diversity of methods and standards in the processes of each supplier of digital resources",
            "contribution_ids": [
                "R74396",
                "R109062"
            ]
        },
        {
            "instance_id": "EMPTYxR171548",
            "comparison_id": "EMPTY",
            "paper_id": "R171548",
            "text": "Social capital and Internet use in an age-comparative perspective with a focus on later life older adults (aged 65+) are still less likely to adopt the internet when compared to other age groups, although their usage is increasing. to explore the societal effects of internet usage, scholars have been using social capital as an analytical tool. social capital pertains to the resources that are potentially available in one\u2019s social ties. as the internet becomes a prominent source of information, communication, and participation in industrialized countries, it is critical to study how it affects social resources from an age-comparative perspective. research has found a positive association between internet use and social capital, though limited attention has been paid to older adults. studies have also found a positive association between social capital and wellbeing, health, sociability, and social support amongst older adults. however, little is known about how internet usage or lack thereof relates to their social capital. to address this gap, we used a mixed-methods approach to examine the relationship between internet usage and social capital and whether and how it differs by age. for this, we surveyed a representative sample of 417 adults (18+) living in lisbon, portugal, of which 118 are older adults. social capital was measured through bonding, bridging, and specific resources, and analyzed with latent class modeling and logistic regressions. internet usage was measured through frequency and type of use. fourteen follow-up semi-structured interviews helped contextualize the survey data. our findings show that social capital decreased with age but varied for each type of internet user. older adults were less likely to have a high level of social capital; yet within this age group, frequent internet users had higher levels than other users and non-users. on the one hand, the internet seems to help maintain, accrue, and even mobilize social capital. on the other hand, it also seems to reinforce social inequality and accumulated advantage (known as the matthew effect).",
            "contribution_ids": [
                "R171549",
                "R171550"
            ]
        },
        {
            "instance_id": "EMPTYxR146924",
            "comparison_id": "EMPTY",
            "paper_id": "R146924",
            "text": "Nonfullerene Polymer Solar Cells Based on a Main-Chain Twisted Low-Bandgap Acceptor with Power Conversion Efficiency of 13.2% a new acceptor\u2013donor\u2013acceptor-structured nonfullerene acceptor, 2,2\u2032-((2z,2\u2032z)-(((4,4,9,9-tetrakis(4-hexylphenyl)-4,9-dihydro-s-indaceno[1,2-b:5,6-b\u2032]dithiophene-2,7-diyl)bis(4-((2-ethylhexyl)oxy)thiophene-4,3-diyl))bis(methanylylidene))bis(5,6-difluoro-3-oxo-2,3-dihydro-1h-indene-2,1-diylidene))dimalononitrile (i-ieico-4f), is designed and synthesized via main-chain substituting position modification of 2-(5,6-difluoro-3-oxo-2,3-dihydro-1h-indene-2,1-diylidene)dimalononitrile. unlike its planar analogue ieico-4f with strong absorption in the near-infrared region, i-ieico-4f exhibits a twisted main-chain configuration, resulting in 164 nm blue shifts and leading to complementary absorption with the wide-bandgap polymer (j52). a high solution molar extinction coefficient of 2.41 \u00d7 105 m\u20131 cm\u20131, and sufficiently high energy of charge-transfer excitons of 1.15 ev in a j52:i-ieico-4f blend were observed, in comparison with those of 2.26 \u00d7 105 m\u20131 cm\u20131 and 1.08 ev for ieico-4f. a power conversion efficiency of...",
            "contribution_ids": [
                "R146928"
            ]
        },
        {
            "instance_id": "EMPTYxR170851",
            "comparison_id": "EMPTY",
            "paper_id": "R170851",
            "text": "The Effect of Gender and Social Capital on the Dual Burden of Malnutrition: A Multilevel Study in Indonesia \"introduction the paradoxical phenomenon of the coexistence of overweight and underweight individuals in the same household, referred to as the \u201cdual burden of malnutrition\u201d, is a growing nutrition dilemma in low- and middle-income countries (lmics). aims the objectives of this study were (i) to examine the extent of the dual burden of malnutrition across different provinces in indonesia and (ii) to determine how gender, community social capital, place of residency and other socio-economic factors affect the prevalence of the dual burden of malnutrition. methods the current study utilized data from the fourth wave of the indonesian family life survey (ifls) conducted between november 2007 and april 2008. the dataset contains information from 12,048 households and 45,306 individuals of all ages. this study focused on households with individuals over two years old. to account for the multilevel nature of the data, a multilevel multiple logistic regression was conducted. results approximately one-fifth of all households in indonesia exhibited the dual burden of malnutrition, which was more prevalent among male-headed households, households with a high socio-economic status (ses), and households in urban areas. minimal variation in the dual burden of malnutrition was explained by the community level differences (<4%). living in households with a higher ses resulted in higher odds of the dual burden of malnutrition but not among female-headed households and communities with the highest social capital. conclusion to improve household health and reduce the inequality across different ses groups, this study emphasizes the inclusion of women's empowerment and community social capital into intervention programs addressing the dual burden of malnutrition.\"",
            "contribution_ids": [
                "R170852"
            ]
        },
        {
            "instance_id": "EMPTYxR169913",
            "comparison_id": "EMPTY",
            "paper_id": "R169913",
            "text": "Predictive value of traction force measurement in vacuum extraction: Development of a multivariate prognostic model objective to enable early prediction of strong traction force vacuum extraction. design observational cohort. setting karolinska university hospital delivery ward, tertiary unit. population and sample size term mid and low metal cup vacuum extraction deliveries june 2012\u2014february 2015, n = 277. methods traction forces during vacuum extraction were collected prospectively using an intelligent handle. levels of traction force were analysed pairwise by subjective category strong versus non-strong extraction, in order to define an objective predictive value for strong extraction. statistical analysis a logistic regression model based on the shrinkage and selection method lasso was used to identify the predictive capacity of the different traction force variables. predictors total (time force integral, newton minutes) and peak traction (newton) force in the first to third pull; difference in traction force between the second and first pull, as well as the third and first pull respectively. accumulated traction force at the second and third pull. outcome subjectively categorized extraction as strong versus non-strong. results the prevalence of strong extraction was 26%. prediction including the first and second pull: auc 0,85 (ci 0,80\u20130,90); specificity 0,76; sensitivity 0,87; ppv 0,56; npv 0,94. prediction including the first to third pull: auc 0,86 (ci 0,80\u20130,91); specificity 0,87; sensitivity 0,70; ppv 0,65; npv 0,89. conclusion traction force measurement during vacuum extraction can help exclude strong category extraction from the second pull. from the third pull, two-thirds of strong extractions can be predicted.",
            "contribution_ids": [
                "R169914",
                "R169915",
                "R169916"
            ]
        },
        {
            "instance_id": "EMPTYxR46346",
            "comparison_id": "EMPTY",
            "paper_id": "R46346",
            "text": "Robust lexical features for improved neural network named-entity recognition neural network approaches to named-entity recognition reduce the need for carefully hand-crafted features. while some features do remain in state-of-the-art systems, lexical features have been mostly discarded, with the exception of gazetteers. in this work, we show that this is unfair: lexical features are actually quite useful. we propose to embed words and entity types into a low-dimensional vector space we train from annotated data produced by distant supervision thanks to wikipedia. from this, we compute \u2014 offline \u2014 a feature vector representing each word. when used with a vanilla recurrent neural network model, this representation yields substantial improvements. we establish a new state-of-the-art f1 score of 87.95 on ontonotes 5.0, while matching state-of-the-art performance with a f1 score of 91.73 on the over-studied conll-2003 dataset.",
            "contribution_ids": [
                "R46348"
            ]
        },
        {
            "instance_id": "EMPTYxR68540",
            "comparison_id": "EMPTY",
            "paper_id": "R68540",
            "text": "The biology of color in living color \\n \\n animals live in a colorful world, but we rarely stop to think about how this color is produced and perceived, or how it evolved. cuthill\\n et al. \\n review how color is used for social signals between individual animals and how it affects interactions with parasites, predators, and the physical environment. new approaches are elucidating aspects of animal coloration, from the requirements for complex cognition and perception mechanisms to the evolutionary dynamics surrounding its development and diversification.\\n \\n \\n science \\n , this issue p.\\n eaan0221 \\n",
            "contribution_ids": [
                "R68558"
            ]
        },
        {
            "instance_id": "EMPTYxR206177",
            "comparison_id": "EMPTY",
            "paper_id": "R206177",
            "text": "A Natural Language Processing Pipeline for Detecting Informal Data References in Academic Literature discovering authoritative links between publications and the datasets that they use can be a labor-intensive process. we introduce a natural language processing pipeline that retrieves and reviews publications for informal references to research datasets, which complements the work of data librarians. we first describe the components of the pipeline and then apply it to expand an authoritative bibliography linking thousands of social science studies to the data-related publications in which they are used. the pipeline increases recall for literature to review for inclusion in data-related collections of publications and makes it possible to detect informal data references at scale. we contribute (1) a novel named entity recognition (ner) model that reliably detects informal data references and (2) a dataset connecting items from social science literature with datasets they reference. together, these contributions enable future work on data reference, data citation networks, and data reuse.",
            "contribution_ids": [
                "R206179"
            ]
        },
        {
            "instance_id": "EMPTYxR171533",
            "comparison_id": "EMPTY",
            "paper_id": "R171533",
            "text": "Increase in suicides the months after the death of Robin Williams in the US investigating suicides following the death of robin williams, a beloved actor and comedian, on august 11th, 2014, we used time-series analysis to estimate the expected number of suicides during the months following williams\u2019 death. monthly suicide count data in the us (1999\u20132015) were from the centers for disease control and prevention wide-ranging online data for epidemiologic research (cdc wonder). expected suicides were calculated using a seasonal autoregressive integrated moving averages model to account for both the seasonal patterns and autoregression. time-series models indicated that we would expect 16,849 suicides from august to december 2014; however, we observed 18,690 suicides in that period, suggesting an excess of 1,841 cases (9.85% increase). although excess suicides were observed across gender and age groups, males and persons aged 30\u201344 had the greatest increase in excess suicide events. this study documents associations between robin williams\u2019 death and suicide deaths in the population thereafter.",
            "contribution_ids": [
                "R171534",
                "R171535"
            ]
        },
        {
            "instance_id": "EMPTYxR110002",
            "comparison_id": "EMPTY",
            "paper_id": "R110002",
            "text": "Application of support vector regression analysis to estimate total organic carbon content of Cambay shale in Cambay basin, India \u00e2\u0080\u0093 a case study abstract the objective of the present study is to estimate total organic carbon (toc) content over the entire thickness of cambay shale, in the boreholes of jambusar\u2013broach block of cambay basin, india. to achieve this objective, support vector regression (svr), a supervised data mining technique, has been utilized using five basic wireline logs as input variables. suitable svr model has been developed by selecting epsilon-svr algorithm and varying three different kernel functions and parameters like gamma and cost on a sample dataset. the best result is obtained when the radial-basis kernel function with gamma = 1 and cost = 1, are used. finally, the performance of developed svr model is compared with the \u03b4logr method. the toc computed by svr method is found to be more precise than the \u03b4logr method, as it has better agreement with the core-toc. thus, in the present study area, the svr method is found to be a powerful tool for estimating toc of cambay shale in a continuous and rapid manner.",
            "contribution_ids": [
                "R110004"
            ]
        },
        {
            "instance_id": "EMPTYxR109143",
            "comparison_id": "EMPTY",
            "paper_id": "R109143",
            "text": "Towards Improving the Quality of Knowledge Graphs with Data-driven Ontology Patterns and SHACL as linked data available on the web continue to grow, understanding their structure and assessing their quality remains a challenging task making such the bottleneck for their reuse. abstat is an online semantic profiling tool which helps data consumers in better understanding of the data by extracting data-driven ontology patterns and statistics about the data. the shacl shapes constraint language helps users capturing quality issues in the data by means of co straints. in this paper we propose a methodology to improve the quality of different versions of the data by means of shacl constraints learned from the semantic profiles produced by abstat.",
            "contribution_ids": [
                "R109145"
            ]
        },
        {
            "instance_id": "EMPTYxR175356",
            "comparison_id": "EMPTY",
            "paper_id": "R175356",
            "text": "Genomic Island Prediction via Chi-Square Test and Random Forest Algorithm genomic islands are related to microbial adaptation and carry different genomic characteristics from the host. therefore, many methods have been proposed to detect genomic islands from the rest of the genome by evaluating its sequence composition. many sequence features have been proposed, but many of them have not been applied to the identification of genomic islands. in this paper, we present a scheme to predict genomic islands using the chi-square test and random forest algorithm. we extract seven kinds of sequence features and select the important features with the chi-square test. all the selected features are then input into the random forest to predict the genome islands. three experiments and comparison show that the proposed method achieves the best performance. this understanding can be useful to design more powerful method for the genomic island prediction.",
            "contribution_ids": [
                "R175359"
            ]
        },
        {
            "instance_id": "EMPTYxR195597",
            "comparison_id": "EMPTY",
            "paper_id": "R195597",
            "text": "Datasets from Fifteen Years of Automated Requirements Traceability Research: Current State, Characteristics, and Quality software datasets play a crucial role in advancing automated software traceability research. they can be used by researchers in different ways to develop or validate new automated approaches. the diversity and quality of the datasets within a research community have a significant impact on the accuracy, generalizability, and reproducibility of the results and consequently on the usefulness and practicality of the techniques under study. collecting and assessing the quality of such datasets are not trivial tasks and have been reported as an obstacle by many researchers in the domain of software engineering. this paper presents a first-of-its-kind study to review and assess the datasets that have been used in software traceability research over the last fifteen years. it presents and articulates the current status of these datasets, their characteristics, and their threats to validity. furthermore, this paper introduces a traceability-dataset quality assessment (t-dqa) framework to categorize software traceability datasets and assist researchers to select appropriate datasets for their research based on different characteristics of the datasets and the context in which those datasets will be used.",
            "contribution_ids": [
                "R195598"
            ]
        },
        {
            "instance_id": "EMPTYxR201407",
            "comparison_id": "EMPTY",
            "paper_id": "R201407",
            "text": "Personal Knowledge Graphs: Use Cases in e-learning Platforms personal knowledge graphs (pkgs) are introduced by the semantic web community as small-sized user-centric knowledge graphs (kgs). pkgs fill the gap of personalised representation of user data and interests on the top of big, well-established encyclopedic kgs, such as dbpedia [21]. inspired by the widely recent usage of pkgs in the medical domain to represent patient data, this phd proposal aims to adopt a similar technique in the educational domain in e-learning platforms by deploying pkgs to represent users and learners. we propose a novel pkg development that relies on ontology and interlinks to linked open data. hence, adding the dimension of personalisation and explainability in users\u2019 featured data while respecting privacy. this research design is developed in two use cases: a collaborative search learning platform and an e-learning platform. our preliminary results show that e-learning platforms can get benefited from our approach by providing personalised recommendations and more user and group-specific data.",
            "contribution_ids": [
                "R201408"
            ]
        },
        {
            "instance_id": "EMPTYxR195849",
            "comparison_id": "EMPTY",
            "paper_id": "R195849",
            "text": "Detecting Vague Words &amp; Phrases in Requirements Documents in a Multilingual Environment vagueness in software requirements documents can lead to several maintenance problems, especially when the customer and development team do not share the same language. currently, companies rely on human translators to maintain communication and limit vagueness by translating the requirement documents by hand. in this paper, we describe two approaches that automatically identify vagueness in requirements documents in a multilingual environment. we perform two studies for calibration purposes under strict industrial limitations, and describe the tool that we ultimately deploy. in the first study, six participants, two native portuguese speakers and four native spanish speakers, evaluated both approaches. then, we conducted a field study to test the performance of the best approach in real-world environments at two companies. we describe several lessons learned for research and industrial deployment.",
            "contribution_ids": [
                "R195850"
            ]
        },
        {
            "instance_id": "EMPTYxR187658",
            "comparison_id": "EMPTY",
            "paper_id": "R187658",
            "text": "An online convex optimization algorithm for controlling linear systems with state and input constraints \"this paper studies the problem of controlling linear dynamical systems subject to point-wise-in-time constraints. we present an algorithm similar to online gradient descent, that can handle time-varying and a priori unknown convex cost functions while restraining the system states and inputs to polytopic constraint sets. analysis of the algorithm's performance, measured by dynamic regret, reveals that sub-linear regret is achieved if the variation of the cost functions is sublinear in time. finally, we present an example to illustrate implementation details as well as the algorithm's performance and show that the proposed algorithm ensures constraint satisfaction.\"",
            "contribution_ids": [
                "R187660"
            ]
        },
        {
            "instance_id": "EMPTYxR197711",
            "comparison_id": "EMPTY",
            "paper_id": "R197711",
            "text": "LemMED: Fast and Effective Neural Morphological Analysis with Short Context Windows we present lemmed, a character-level encoder-decoder for contextual morphological analysis (combined lemmatization and tagging). lemmed extends and is named after two other attention-based models, namely lematus, a contextual lemmatizer, and med, a morphological (re)inflection model. our approach does not require training separate lemmatization and tagging models, nor does it need additional resources and tools, such as morphological dictionaries or transducers. moreover, lemmed relies solely on character-level representations and on local context. although the model can, in principle, account for global context on sentence level, our experiments show that using just a single word of context around each target word is not only more computationally feasible, but yields better results as well. we evaluate lemmed in the framework of the simgmorphon-2019 shared task on combined lemmatization and tagging. in terms of average performance lemmed ranks 5th among 13 systems and is bested only by the submissions that use contextualized embeddings.",
            "contribution_ids": [
                "R197713"
            ]
        },
        {
            "instance_id": "EMPTYxR196695",
            "comparison_id": "EMPTY",
            "paper_id": "R196695",
            "text": "TempoQR: Temporal Question Reasoning over Knowledge Graphs knowledge graph question answering (kgqa) involves retrieving facts from a knowledge graph (kg) using natural language queries. a kg is a curated set of facts consisting of entities linked by relations. certain facts include also temporal information forming a temporal kg (tkg). although many natural questions involve explicit or implicit time constraints, question answering (qa) over tkgs has been a relatively unexplored area. existing solutions are mainly designed for simple temporal questions that can be answered directly by a single tkg fact.\\n this paper puts forth a comprehensive embedding-based framework for answering complex questions over tkgs. our method termed temporal question reasoning (tempoqr) exploits tkg embeddings to ground the question to the specific entities and time scope it refers to. it does so by augmenting the question embeddings with context, entity and time-aware information by employing three specialized modules. the first computes a textual representation of a given question, the second combines it with the entity embeddings for entities involved in the question, and the third generates question-specific time embeddings. finally, a transformer-based encoder learns to fuse the generated temporal information with the question representation, which is used for answer predictions. extensive experiments show that tempoqr improves accuracy by 25--45 percentage points on complex temporal questions over state-of-the-art approaches and it generalizes better to unseen question types.",
            "contribution_ids": [
                "R196697"
            ]
        },
        {
            "instance_id": "EMPTYxR147372",
            "comparison_id": "EMPTY",
            "paper_id": "R147372",
            "text": "Landsat 8 OLI Data for Identification of Hydrothermal Alteration Zone in Singhbhum Shear Zone using Successive Band Depth Difference Technique\u00e2\u0080\u0093A New Image Processing Approach current science, vol. 116, no. 10, 25 may 2019 1639 krishnendu banerjee, manish kumar jain and surajit panda are in the indian institute of technology (ism), dhanbad 826 004, india and a. t. jeyaseelan is in the regional remote sensing centre west, national remote sensing centre, indian space research organisation, jodhpur 342 003, india. *for correspondence. (e-mail: rsgis.pintu@gmail.com) landsat 8 oli data for identification of hydrothermal alteration zone in singhbhum shear zone using successive band depth difference technique \u2013 a new image processing approach",
            "contribution_ids": [
                "R147374"
            ]
        },
        {
            "instance_id": "EMPTYxR110833",
            "comparison_id": "EMPTY",
            "paper_id": "R110833",
            "text": "Polysomnographic characteristics in patients with mucopolysaccharidoses to evaluate the prevalence of obstructive sleep apnea (osa) and to clarify sleep characteristics in patients with mucopolysaccharidoses (mps), we performed overnight polysomnographic studies in 24 patients (22 males and 2 females; 3 with mps i, 15 with mps ii, 1 with mps iii, 1 with mps iv, and 4 with mps vi; mean age, 10.8\\u2009\u00b1\\u20096.0 years; age range, 2.0\u201323.7 years; 2 patients \u226518 years of age). the nadir arterial oxygen saturation (sao2) was 74.5\\u2009\u00b1\\u200912.3%, and the average percentage of sleep time with an sao2 of \\u200910) in 13. two patients with mps ii who received enzyme replacement therapy had reductions in rdi after treatment (38.9\u201310.8 and 3.5\u20132.0, respectively). the prevalence of moderate to severe osa was 88% (21/24) in patients with mps. the overnight polysomnography will help to determine the abnormalities of breathing during sleep more precisely and urge the clinicians to take necessary action for patients with severe manifestations. pediatr pulmonol. 2010;45:1205\u20131212. \u00a9 2010 wiley\u2010liss, inc.",
            "contribution_ids": [
                "R110835"
            ]
        },
        {
            "instance_id": "EMPTYxR169786",
            "comparison_id": "EMPTY",
            "paper_id": "R169786",
            "text": "Ten-Year Changes in the Prevalence and Socio-Demographic Determinants of Physical Activity among Polish Adults Aged 20 to 74 Years. Results of the National Multicenter Health Surveys WOBASZ (2003-2005) and WOBASZ II (2013-2014) introduction the aim of the study was to estimate ten-year changes in physical activity (pa) patterns and sociodemographic determinants among adult residents of poland. methods the study comprised two independent samples of randomly selected adults aged 20\u201374 years participating in the national multicentre health survey wobasz (2003\u20132005; n = 14572) and wobasz ii (2013\u20132014; n = 5694). in both surveys the measurements were performed by six academic centers in all 16 voivodships of poland (108 measurement points in each survey). sociodemographic data were collected by an interviewer-administered questionnaire in both surveys. physical activity was assessed in three domains: leisure-time, occupational and commuting physical activity. results leisure-time pa changed substantially between the surveys (p<0.001). the prevalence of subjects being active on most days of week fell in both genders in the years 2003\u20132014 (37.4% vs 27.3% in men); 32.7% vs 28.3% in women. none or occasional activity increased from 49.6% to 56.8% in men, while remained stable in women (55.2% vs 54.9%). in both wobasz surveys the likelihood of physical inactivity was higher in less educated individuals, smokers and those living in large agglomerations (p<0.01). no significant changes were observed in occupational activity in men between the surveys, while in women percentage of sedentary work increased from 43.4% to % 49.4% (p<0.01). commuting pa decreased significantly in both genders (p<0.001). about 79.3% of men and 71.3% of women reported no active commuting in the wobasz ii survey. conclusions the observed unfavourable changes in pa emphasize the need for novel intervention concepts in order to reverse this direction. further detailed monitoring of pa patterns in poland is of particular importance.",
            "contribution_ids": [
                "R169787",
                "R169788"
            ]
        },
        {
            "instance_id": "EMPTYxR129508",
            "comparison_id": "EMPTY",
            "paper_id": "R129508",
            "text": "Deeper Task-Specificity Improves Joint Entity and Relation Extraction multi-task learning (mtl) is an effective method for learning related tasks, but designing mtl models necessitates deciding which and how many parameters should be task-specific, as opposed to shared between tasks. we investigate this issue for the problem of jointly learning named entity recognition (ner) and relation extraction (re) and propose a novel neural architecture that allows for deeper task-specificity than does prior work. in particular, we introduce additional task-specific bidirectional rnn layers for both the ner and re tasks and tune the number of shared and task-specific layers separately for different datasets. we achieve state-of-the-art (sota) results for both tasks on the ade dataset; on the conll04 dataset, we achieve sota results on the ner task and competitive results on the re task while using an order of magnitude fewer trainable parameters than the current sota architecture. an ablation study confirms the importance of the additional task-specific layers for achieving these results. our work suggests that previous solutions to joint ner and re undervalue task-specificity and demonstrates the importance of correctly balancing the number of shared and task-specific parameters for mtl approaches in general.",
            "contribution_ids": [
                "R129509"
            ]
        },
        {
            "instance_id": "EMPTYxR187739",
            "comparison_id": "EMPTY",
            "paper_id": "R187739",
            "text": "All the research that\u00e2\u0080\u0099s fit to print: Open access and the news media abstract \\n the goal of the open access (oa) movement is to help everyone access scholarly research, not just those who can afford to. however, most studies looking at whether oa has met this goal have focused on whether other scholars are making use of oa research. few have considered how the broader public, including the news media, uses oa research. i sought to answer whether the news media mentions oa articles more or less than paywalled articles by looking at articles published from 2010 through 2018 in journals across all four quartiles of the journal impact factor using data obtained through altmetric.com and web of science. gold, green and hybrid oa articles all had a positive correlation with the number of news mentions received. news mentions for oa articles did see a dip in 2018, although they remained higher than those for paywalled articles.",
            "contribution_ids": [
                "R187741"
            ]
        },
        {
            "instance_id": "EMPTYxR146865",
            "comparison_id": "EMPTY",
            "paper_id": "R146865",
            "text": "A simple small molecule as an acceptor for fullerene-free organic solar cells with efficiency near 8% a small molecule named dictf was synthesized and an organic solar cell based on ptb7-th:dictf exhibited a high pce of 7.93%.",
            "contribution_ids": [
                "R146868"
            ]
        },
        {
            "instance_id": "EMPTYxR74999",
            "comparison_id": "EMPTY",
            "paper_id": "R74999",
            "text": "The Economic Lives of the Poor \" the 1990 world development report from the world bank defined the \u201cextremely poor\u201d people of the world as those who are currently living on no more than $1 per day per person. but how actually does one live on less than $1 per day? this essay is about the economic lives of the extremely poor: the choices they face, the constraints they grapple with, and the challenges they meet. a number of recent data sets and a body of new research allow us to start building an image of the way the extremely poor live their lives. our discussion builds on household surveys conducted in 13 countries: cote d'ivoire, guatemala, india, indonesia, mexico, nicaragua, pakistan, panama, papua new guinea, peru, south africa, tanzania, and timor leste (east timor). these surveys provide detailed information on extremely poor households around the world, from asia to africa to latin america, including information on what they consume, where they work, and how they save and borrow. we consider the extremely poor\u2014those living in households where the consumption per capita is less than $1.08 per person per day\u2014as well as the merely \u201cpoor\u201d\u2014defined as those who live under $2.16 a day\u2014using 1993 purchasing power parity as benchmark. in keeping with convention, we call these the $1 and $2 dollar poverty lines, respectively. \"",
            "contribution_ids": [
                "R75001"
            ]
        },
        {
            "instance_id": "EMPTYxR73154",
            "comparison_id": "EMPTY",
            "paper_id": "R73154",
            "text": "DataCite: Lessons Learned on Persistent Identifiers for Research Data data are the infrastructure of science and they serve as the groundwork for scientific pursuits. data publication has emerged as a game-changing breakthrough in scholarly communication. data form the outputs of research but also are a gateway to new hypotheses, enabling new scientific insights and driving innovation. and yet stakeholders across the scholarly ecosystem, including practitioners, institutions, and funders of scientific research are increasingly concerned about the lack of sharing and reuse of research data. across disciplines and countries, researchers, funders, and publishers are pushing for a more effective research environment, minimizing the duplication of work and maximizing the interaction between researchers. availability, discoverability, and reproducibility of research outputs are key factors to support data reuse and make possible this new environment of highly collaborative research. an interoperable e-infrastructure is imperative in order to develop new platforms and services for to data publication and reuse. datacite has been working to establish and promote methods to locate, identify and share information about research data. along with service development, datacite supports and advocates for the standards behind persistent identifiers (in particular dois, digital object identifiers) for data and other research outputs. persistent identifiers allow different platforms to exchange information consistently and unambiguously and provide a reliable way to track citations and reuse. because of this, data publication can become a reality from a technical standpoint, but the adoption of data publication and data citation as a practice by researchers is still in its early stages. since 2009, datacite has been developing a series of tools and services to foster the adoption of data publication and citation among the research community. through the years, datacite has worked in a close collaboration with interdisciplinary partners on these issues and we have gained insight into the development of data publication workflows. this paper describes the types of different actions and the lessons learned by datacite.\\xa0",
            "contribution_ids": [
                "R73155"
            ]
        },
        {
            "instance_id": "EMPTYxR138490",
            "comparison_id": "EMPTY",
            "paper_id": "R138490",
            "text": "Heterotrophic bacteria as major nitrogen fixers in the euphotic zone of the Indian Ocean: NITROGEN FIXATION IN THE INDIAN OCEAN diazotrophy in the indian ocean is poorly understood compared to that in the atlantic and pacific oceans. we first examined the basin\u2010scale community structure of diazotrophs and their nitrogen fixation activity within the euphotic zone during the northeast monsoon period along about 69\u00b0e from 17\u00b0n to 20\u00b0s in the oligotrophic indian ocean, where a shallow nitracline (49\u201359\\u2009m) prevailed widely and the sea surface temperature (sst) was above 25\u00b0c. phosphate was detectable at the surface throughout the study area. the dissolved iron concentration and the ratio of iron to nitrate\\u2009+\\u2009nitrite at the surface were significantly higher in the arabian sea than in the equatorial and southern indian ocean. nitrogen fixation in the arabian sea (24.6\u201347.1 \u03bcmoln m\u22122 d\u22121) was also significantly greater than that in the equatorial and southern indian ocean (6.27\u201316.6 \u03bcmoln m\u22122 d\u22121), indicating that iron could control diazotrophy in the indian ocean. phylogenetic analysis of nifh showed that most diazotrophs belonged to the proteobacteria and that cyanobacterial diazotrophs were absent in the study area except in the arabian sea. furthermore, nitrogen fixation was not associated with light intensity throughout the study area. these results are consistent with nitrogen fixation in the indian ocean, being largely performed by heterotrophic bacteria and not by cyanobacteria. the low cyanobacterial diazotrophy was attributed to the shallow nitracline, which is rarely observed in the pacific and atlantic oligotrophic oceans. because the shallower nitracline favored enhanced upward nitrate flux, the competitive advantage of cyanobacterial diazotrophs over nondiazotrophic phytoplankton was not as significant as it is in other oligotrophic oceans.",
            "contribution_ids": [
                "R138492"
            ]
        },
        {
            "instance_id": "EMPTYxR170436",
            "comparison_id": "EMPTY",
            "paper_id": "R170436",
            "text": "Social, Environmental and Psychological Factors Associated with Objective Physical Activity Levels in the Over 65s objective to assess physical activity levels objectively using accelerometers in community dwelling over 65 s and to examine associations with health, social, environmental and psychological factors. design cross sectional survey. setting 17 general practices in scotland, united kingdom. participants random sampling of over 65 s registered with the practices in four strata young-old (65\u201380 years), old-old (over 80 years), more affluent and less affluent groups. main outcome measures accelerometry counts of activity per day. associations between activity and theory of planned behaviour variables, the physical environment, health, wellbeing and demographic variables were examined with multiple regression analysis and multilevel modelling. results 547 older people (mean (sd) age 79(8) years, 54% female) were analysed representing 94% of those surveyed. accelerometry counts were highest in the affluent younger group, followed by the deprived younger group, with lowest levels in the deprived over 80 s group. multiple regression analysis showed that lower age, higher perceived behavioural control, the physical function subscale of sf-36, and having someone nearby to turn to were all independently associated with higher physical activity levels (r2\\u200a=\\u200a0.32). in addition, hours of sunshine were independently significantly associated with greater physical activity in a multilevel model. conclusions other than age and hours of sunlight, the variables identified are modifiable, and provide a strong basis for the future development of novel multidimensional interventions aimed at increasing activity participation in later life.",
            "contribution_ids": [
                "R170437",
                "R170438"
            ]
        },
        {
            "instance_id": "EMPTYxR134911",
            "comparison_id": "EMPTY",
            "paper_id": "R134911",
            "text": "ProjectionNet: Learning Efficient On-Device Deep Networks Using Neural Projections deep neural networks have become ubiquitous for applications related to visual recognition and language understanding tasks. however, it is often prohibitive to use typical neural networks on devices like mobile phones or smart watches since the model sizes are huge and cannot fit in the limited memory available on such devices. while these devices could make use of machine learning models running on high-performance data centers with cpus or gpus, this is not feasible for many applications because data can be privacy sensitive and inference needs to be performed directly \"on\" device. \\nwe introduce a new architecture for training compact neural networks using a joint optimization framework. at its core lies a novel objective that jointly trains using two different types of networks--a full trainer neural network (using existing architectures like feed-forward nns or lstm rnns) combined with a simpler \"projection\" network that leverages random projections to transform inputs or intermediate representations into bits. the simpler network encodes lightweight and efficient-to-compute operations in bit space with a low memory footprint. the two networks are trained jointly using backpropagation, where the projection network learns from the full network similar to apprenticeship learning. once trained, the smaller network can be used directly for inference at low memory and computation cost. we demonstrate the effectiveness of the new approach at significantly shrinking the memory requirements of different types of neural networks while preserving good accuracy on visual recognition and text classification tasks. we also study the question \"how many neural bits are required to solve a given task?\" using the new framework and show empirical results contrasting model predictive capacity (in bits) versus accuracy on several datasets.",
            "contribution_ids": [
                "R134912"
            ]
        },
        {
            "instance_id": "EMPTYxR171236",
            "comparison_id": "EMPTY",
            "paper_id": "R171236",
            "text": "Development and Validation of the Motivations for Selection of Medical Study (MSMS) Questionnaire in India background and objective understanding medical students\u2019 motivation to select medical studies is particularly salient to inform practice and policymaking in countries\u2014such as india\u2014where shortage of medical personnel poses crucial and chronical challenges to healthcare systems. this study aims to develop and validate a questionnaire to assess the motivation of medical students to select medical studies. methods a motivation for selection of medical study (msms) questionnaire was developed using extensive literature review followed by delphi technique. the scale consisted of 12 items, 5 measuring intrinsic dimensions of motivations and 7 measuring extrinsic dimensions. exploratory factor analysis (efa), confirmatory factor analysis (cfa), validity, reliability and data quality checks were conducted on a sample of 636 medical students from six medical colleges of three north indian states. results the msms questionnaire consisted of 3 factors (subscales) and 8 items. the three principal factors that emerged after efa were the scientific factor (e.g. research opportunities and the ability to use new cutting edge technologies), the societal factor (e.g. job security) and the humanitarian factor (e.g. desire to help others). the cfa conducted showed goodness-of-fit indices supporting the 3-factor model. conclusion the three extracted factors cut across the traditional dichotomy between intrinsic and extrinsic motivation and uncover a novel three-faceted motivation construct based on scientific factors, societal expectations and humanitarian needs. this validated instrument can be used to evaluate the motivational factors of medical students to choose medical study in india and similar settings and constitutes a powerful tool for policymakers to design measures able to increase selection of medical curricula.",
            "contribution_ids": [
                "R171237"
            ]
        },
        {
            "instance_id": "EMPTYxR134288",
            "comparison_id": "EMPTY",
            "paper_id": "R134288",
            "text": "Exploration by Random Network Distillation \"we introduce an exploration bonus for deep reinforcement learning methods that is easy to implement and adds minimal overhead to the computation performed. the bonus is the error of a neural network predicting features of the observations given by a fixed randomly initialized neural network. we also introduce a method to flexibly combine intrinsic and extrinsic rewards. we find that the random network distillation (rnd) bonus combined with this increased flexibility enables significant progress on several hard exploration atari games. in particular we establish state of the art performance on montezuma's revenge, a game famously difficult for deep reinforcement learning methods. to the best of our knowledge, this is the first method that achieves better than average human performance on this game without using demonstrations or having access to the underlying state of the game, and occasionally completes the first level.\"",
            "contribution_ids": [
                "R134289"
            ]
        },
        {
            "instance_id": "EMPTYxR171260",
            "comparison_id": "EMPTY",
            "paper_id": "R171260",
            "text": "The Everyday Moral Judge \u00e2\u0080\u0093 Autobiographical Recollections of Moral Emotions moral emotions are typically elicited in everyday social interactions and regulate social behavior. previous research in the field of attribution theory identified ought (the moral standard of a given situation or intended goal), goal-attainment (a goal can be attained vs. not attained) and effort (high vs. low effort expenditure) as cognitive antecedents of moral emotions. in contrast to earlier studies, mainly relying on thought experiments, we investigated autobiographical recollections of n = 312 participants by means of an online study. we analyzed a diverse range of moral emotions, i.e., admiration, anger, contempt, indignation, pride, respect, schadenfreude, and sympathy, by using a mixed-method approach. qualitative and quantitative methods clearly corroborate the important role of ought, goal-attainment, and effort as eliciting conditions of moral emotions. furthermore, we built categorical systems based on our participants\u2019 descriptions of real-life situations, allowing for more fine-grained distinctions between seemingly similar moral emotions. we thus identify additional prerequisites explaining more subtle differences between moral emotion clusters as they emerge from our analyses (i.e., cluster 1: admiration, pride, and respect; cluster 2: anger, contempt, and indignation; cluster 3: schadenfreude and sympathy). results are discussed in the light of attributional theories of moral emotions, and implications for future research are derived.",
            "contribution_ids": [
                "R171261"
            ]
        },
        {
            "instance_id": "EMPTYxR197210",
            "comparison_id": "EMPTY",
            "paper_id": "R197210",
            "text": "Self-Guided Contrastive Learning for BERT Sentence Representations although bert and its variants have reshaped the nlp landscape, it still remains unclear how best to derive sentence embeddings from such pre-trained transformers. in this work, we propose a contrastive learning method that utilizes self-guidance for improving the quality of bert sentence representations. our method fine-tunes bert in a self-supervised fashion, does not rely on data augmentation, and enables the usual [cls] token embeddings to function as sentence vectors. moreover, we redesign the contrastive learning objective (nt-xent) and apply it to sentence representation learning. we demonstrate with extensive experiments that our approach is more effective than competitive baselines on diverse sentence-related tasks. we also show it is efficient at inference and robust to domain shifts.",
            "contribution_ids": [
                "R197212"
            ]
        },
        {
            "instance_id": "EMPTYxR133821",
            "comparison_id": "EMPTY",
            "paper_id": "R133821",
            "text": "Policy Optimization With Penalized Point Probability Distance: An Alternative To Proximal Policy Optimization as the most successful variant and improvement for trust region policy optimization (trpo), proximal policy optimization (ppo) has been widely applied across various domains with several advantages: efficient data utilization, easy implementation, and good parallelism. in this paper, a first-order gradient reinforcement learning algorithm called policy optimization with penalized point probability distance (pop3d), which is a lower bound to the square of total variance divergence is proposed as another powerful variant. firstly, we talk about the shortcomings of several commonly used algorithms, by which our method is partly motivated. secondly, we address to overcome these shortcomings by applying pop3d. thirdly, we dive into its mechanism from the perspective of solution manifold. finally, we make quantitative comparisons among several state-of-the-art algorithms based on common benchmarks. simulation results show that pop3d is highly competitive compared with ppo. besides, our code is released in this https url.",
            "contribution_ids": [
                "R133822"
            ]
        },
        {
            "instance_id": "EMPTYxR170350",
            "comparison_id": "EMPTY",
            "paper_id": "R170350",
            "text": "Captive Housing during Water Vole (Arvicola terrestris) Reintroduction: Does Short-Term Social Stress Impact on Animal Welfare? \"background animals captive bred for reintroduction are often housed under conditions which are not representative of their preferred social structure for at least part of the reintroduction process. specifically, this is most likely to occur during the final stages of the release programme, whilst being housed during transportation to the release site. the degree of social stress experienced by individuals during this time may negatively impact upon their immunocompetence. methodology/principal findings we examined two measure of stress - body weight and leukocyte coping capacity (lcc) - to investigate the effects of group size upon captive-bred water voles destined for release within a reintroduction program. water voles were housed in laboratory cages containing between one and eight individuals. lcc scores were negatively correlated with group size, suggesting that individuals in larger groups experienced a larger degree of immuno-suppression than did individuals housed in smaller groups or individually. during the course of the study mean body weights increased, in contrast to expectations from a previous study. this was attributed to the individuals sampled being sub-adults and thus growing in length and weight during the course of the investigation. conclusions/significance the reintroduction process will inevitably cause some stress to the release cohort. however, for water voles we conclude that the stress experienced may be reduced by decreasing group size within captive colony and/or transportation housing practises. these findings are of significance to other species' reintroductions, in highlighting the need to consider life-history strategies when choosing housing systems for animals being maintained in captivity prior to release to the wild. a reduction in stress experienced at the pre-release stage may improve immunocompetence and thus animal welfare and initial survival post-release.\"",
            "contribution_ids": [
                "R170351"
            ]
        },
        {
            "instance_id": "EMPTYxR137143",
            "comparison_id": "EMPTY",
            "paper_id": "R137143",
            "text": "Optimal Decomposition and Reconstruction of Discrete Wavelet Transformation for Short-Term Load Forecasting to achieve high accuracy in prediction, a load forecasting algorithm must model various consumer behaviors in response to weather conditions or special events. different triggers will have various effects on different customers and lead to difficulties in constructing an adequate prediction model due to non-stationary and uncertain characteristics in load variations. this paper proposes an open-ended model of short-term load forecasting (stlf) which has general prediction ability to capture the non-linear relationship between the load demand and the exogenous inputs. the prediction method uses the whale optimization algorithm, discrete wavelet transform, and multiple linear regression model (woa-dwt-mlr model) to predict both system load and aggregated load of power consumers. woa is used to optimize the best combination of detail and approximation signals from dwt to construct an optimal mlr model. the proposed model is validated with both the system-side data set and the end-user data set for independent system operator-new england (iso-ne) and smart meter load data, respectively, based on mean absolute percentage error (mape) criterion. the results demonstrate that the proposed method achieves lower prediction error than existing methods and can have consistent prediction of non-stationary load conditions that exist in both test systems. the proposed method is, thus, beneficial to use in the energy management system.",
            "contribution_ids": [
                "R137144"
            ]
        },
        {
            "instance_id": "EMPTYxR171130",
            "comparison_id": "EMPTY",
            "paper_id": "R171130",
            "text": "Cognitive Performance and Long-Term Social Functioning in Psychotic Disorder: A Three-Year Follow-Up Study objective studies have linked cognitive functioning to everyday social functioning in psychotic disorders, but the nature of the relationships between cognition, social cognition, symptoms, and social functioning remains unestablished. modelling the contributions of non-social and social cognitive ability in the prediction of social functioning may help in more clearly defining therapeutic targets to improve functioning. method in a sample of 745 patients with a non-affective psychotic disorder, the associations between cognition and social cognition at baseline on the one hand, and self-reported social functioning three years later on the other, were analysed. first, case-control comparisons were conducted; associations were subsequently further explored in patients, investigating the potential mediating role of symptoms. analyses were repeated in a subsample of 233 patients with recent-onset psychosis. results information processing speed and immediate verbal memory were stronger associated with social functioning in patients than in healthy controls. most cognition variables significantly predicted social functioning at follow-up, whereas social cognition was not associated with social functioning. symptoms were robustly associated with follow-up social functioning, with negative symptoms fully mediating most associations between cognition and follow-up social functioning. illness duration did not moderate the strength of the association between cognitive functioning and follow-up social functioning. no associations were found between (social) cognition and follow-up social functioning in patients with recent-onset psychosis. conclusions although cognitive functioning is associated with later social functioning in psychotic disorder, its role in explaining social functioning outcome above negative symptoms appears only modest. in recent-onset psychosis, cognition may have a negligible role in predicting later social functioning. moreover, social cognition tasks may not predict self-reported social functioning.",
            "contribution_ids": [
                "R171131"
            ]
        },
        {
            "instance_id": "EMPTYxR168963",
            "comparison_id": "EMPTY",
            "paper_id": "R168963",
            "text": "Sources and Coverage of Medical News on Front Pages of US Newspapers background medical news that appears on newspaper front pages is intended to reach a wide audience, but how this type of medical news is prepared and distributed has not been systematically researched. we thus quantified the level of visibility achieved by front-page medical stories in the united states and analyzed their news sources. methodology using the online resource newseum, we investigated front-page newspaper coverage of four prominent medical stories, and a high-profile non-medical news story as a control, reported in the us in 2007. two characteristics were quantified by two raters: which newspaper titles carried each target front-page story (interrater agreement, >96%; kappa, >0.92) and the news sources of each target story (interrater agreement, >94%; kappa, >0.91). national rankings of the top 200 us newspapers by audited circulation were used to quantify the extent of coverage as the proportion of the total circulation of ranked newspapers in newseum. findings in total, 1630 front pages were searched. each medical story appeared on the front pages of 85 to 117 (67.5%\u201378.7%) ranked newspaper titles that had a cumulative daily circulation of 23.1 to 33.4 million, or 61.8% to 88.4% of all newspapers. in contrast, the non-medical story achieved front-page coverage in 152 (99.3%) newspaper titles with a total circulation of 41.0 million, or 99.8% of all newspapers. front-page medical stories varied in their sources, but the washington post, los angeles times, new york times and the associated press together supplied 61.7% of the total coverage of target front-page medical stories. conclusion front-page coverage of medical news from different sources is more accurately revealed by analysis of circulation counts rather than of newspaper titles. journals wishing to widen knowledge of research news and organizations with important health announcements should target at least the four dominant media organizations identified in this study.",
            "contribution_ids": [
                "R168964",
                "R168965"
            ]
        },
        {
            "instance_id": "EMPTYxR140556",
            "comparison_id": "EMPTY",
            "paper_id": "R140556",
            "text": "An image processing approach for converging ASTER-derived spectral maps for mapping Kolhan limestone, Jharkhand, India in the present study, we have attempted the delineation of limestone using different spectral mapping algorithms in aster data. each spectral mapping algorithm derives limestone exposure map independently. although these spectral maps are broadly similar to each other, they are also different at places in terms of spatial disposition of limestone pixels. therefore, an attempt is made to integrate the results of these spectral maps to derive an integrated map using minimum noise fraction (mnf) method. the first mnf image is the result of two cascaded principal component methods suitable for preserving complementary information derived from each spectral map. while implementing mnf, noise or non-coherent pixels occurring within a homogeneous patch of limestone are removed first using shift difference method, before attempting principal component analysis on input spectral maps for deriving composite spectral map of limestone exposures. the limestone exposure map is further validated based on spectral data and ancillary geological data.",
            "contribution_ids": [
                "R140557"
            ]
        },
        {
            "instance_id": "EMPTYxR110617",
            "comparison_id": "EMPTY",
            "paper_id": "R110617",
            "text": "Early Onset Intrauterine Growth Restriction in a Mouse Model of Gestational Hypercholesterolemia and Atherosclerosis the susceptibility to develop atherosclerosis is increased by intrauterine growth restriction and prenatal exposure to maternal hypercholesterolemia. here, we studied whether mouse gestational hypercholesterolemia and atherosclerosis affected fetal development and growth at different stages of gestation. female ldlr ko mice fed a proatherogenic, high cholesterol (hc) diet for 3 weeks before conception and during pregnancy exhibited a significant increase in non-hdl cholesterol and developed atherosclerosis. at embryonic days 12.5 (e12.5), e15.5, and e18.5, maternal gestational hypercholesterolemia and atherosclerosis were associated to a 22\u201324% reduction in male and female fetal weight without alterations in fetal number/litter or morphology nor placental weight or structure. feeding the hc diet exclusively at the periconceptional period did not alter fetal growth, suggesting that maternal hypercholesterolemia affected fetal weight only after implantation. vitamin e supplementation (1,000\\u2009ui of \u03b1-tocopherol/kg) of hc-fed females did not change the mean weight of e18.5 fetuses but reduced the percentage of fetuses exhibiting body weights below the 10th percentile of weight (hc: 90% vs. hc/vite: 68%). in conclusion, our results showed that maternal gestational hypercholesterolemia and atherosclerosis in mice were associated to early onset fetal growth restriction and that dietary vitamin e supplementation had a beneficial impact on this condition.",
            "contribution_ids": [
                "R110619"
            ]
        },
        {
            "instance_id": "EMPTYxR170685",
            "comparison_id": "EMPTY",
            "paper_id": "R170685",
            "text": "Psychological and Social Factors Associated with Late Pregnancy Iron Deficiency Anaemia in Rural Viet Nam: A Population-Based Prospective Study objectives the aim of this study was to examine the relationships between psychological and social factors and late pregnancy ida among pregnant women in rural viet nam. methods pregnant women from 50 randomly-selected communes within ha nam province were recruited and assessed at 12 - 20 weeks gestation (wave 1, w1). they were followed up in the last trimester (wave 2, w2). ida was defined as haemoglobin < 11 g/dl and serum ferritin < 15 ng/ml. symptoms of common mental disorders (cmd) were assessed by the edinburgh postnatal depression scale-vietnam (epds-v). persistent antenatal cmd was defined as having an epds-v score \u2265 4 in both w1 and w2. hypothesis models were tested by structural equation modeling analyses. results a total of 378 women provided complete data at both w1 and w2. the incidence risk of ida in the third trimester was 13.2% (95% confidence interval (ci): 9.8-16.7). persistent cmd was found in 16.9% (95% ci: 13.1-20.7) pregnant women and predicted by intimate partner violence, fear of other family members, experience of childhood abuse, coincidental life adversity, and having a preference for the sex of the baby. there was a significant pathway from persistent cmd to ida in late pregnancy via the length of time that iron supplements had been taken. receiving advice to take iron supplements and higher household wealth index were indirectly related to lower risk of late pregnancy ida. early pregnancy ida and being multi-parous also contributed to late pregnancy ida. conclusions antenatal ida and cmd are prevalent public health problems among women in viet nam. the link between them suggests that while direct recommendations to use iron supplements are important, the social factors associated with common mental disorders should be addressed in antenatal care in order to improve the health of pregnant women and their infants.",
            "contribution_ids": [
                "R170686"
            ]
        },
        {
            "instance_id": "EMPTYxR134494",
            "comparison_id": "EMPTY",
            "paper_id": "R134494",
            "text": "HDLTex: Hierarchical Deep Learning for Text Classification increasingly large document collections require improved information processing methods for searching, retrieving, and organizing text. central to these information processing methods is document classification, which has become an important application for supervised learning. recently the performance of traditional supervised classifiers has degraded as the number of documents has increased. this is because along with growth in the number of documents has come an increase in the number of categories. this paper approaches this problem differently from current document classification methods that view the problem as multi-class classification. instead we perform hierarchical classification using an approach we call hierarchical deep learning for text classification (hdltex). hdltex employs stacks of deep learning architectures to provide specialized understanding at each level of the document hierarchy.",
            "contribution_ids": [
                "R134495"
            ]
        },
        {
            "instance_id": "EMPTYxR170674",
            "comparison_id": "EMPTY",
            "paper_id": "R170674",
            "text": "Altered Metabolites in the Plasma of Autism Spectrum Disorder: A Capillary Electrophoresis Time-of-Flight Mass Spectroscopy Study clinical diagnosis and severity of autism spectrum disorders (asd) are determined by trained clinicians based on clinical evaluations of observed behaviors. as such, this approach is inevitably dependent on the expertise and subjective assessment of those administering the clinical evaluations. there is a need to identify objective biological markers associated with diagnosis or clinical severity of the disorder. to identify novel candidate metabolites as potential biomarkers for asd, the current study applied capillary electrophoresis time-of-flight mass spectroscopy (ce-tofms) for high-throughput profiling of metabolite levels in the plasma of 25 psychotropic-na\u00efve adult males with high-functioning asd and 28 age-matched typically-developed control subjects. ten asd participants and ten age-matched controls were assigned in the first exploration set, while 15 asd participants and 18 controls were included in the second replication set. by ce-tofms analysis, a total of 143 metabolites were detected in the plasma of the first set. of these, 17 metabolites showed significantly different relative areas between the asd participants and the controls (p<0.05). of the 17 metabolites, we consistently found that the asd participants had significantly high plasma levels of arginine (p\\u200a=\\u200a0.024) and taurine (p\\u200a=\\u200a0.018), and significantly low levels of 5-oxoproline (p<0.001) and lactic acid (p\\u200a=\\u200a0.031) compared with the controls in the second sample set. further confirmatory analysis using quantification of absolute metabolite concentrations supported the robustness of high arginine (p\\u200a=\\u200a0.001) and low lactic acid (p\\u200a=\\u200a0.003) in the combined sample (n\\u200a=\\u200a53). the present study identified deviated plasma metabolite levels associated with oxidative stress and mitochondrial dysfunction in individuals with asd.",
            "contribution_ids": [
                "R170675"
            ]
        },
        {
            "instance_id": "EMPTYxR74133",
            "comparison_id": "EMPTY",
            "paper_id": "R74133",
            "text": "Research Notes: Smart City Control Room Dashboards: Big Data Infrastructure, from data to decision support smart city control rooms are mainly focused on dashboards which are in turn created by using the socalled dashboard builders tools or generated custom. for a city the production of dashboards is not something that is performed once forever, and it is a continuous working task for improving city monitoring, to follow extraordinary events and/or activities, to monitor critical conditions and cases. thus, relevant complexities are due to the data aggregation architecture and to the identification of modalities to present data and their identification, prediction, etc., to arrive at producing high level representations that can be used by decision makers. in this paper, the architecture of a dashboard builder for creating smart city control rooms is presented. as a validation and test, it has been adopted for generating the dashboards in florence city and other cities in tuscany area. the solution proposed has been developed in the context of replicate h2020 european commission flagship project on smart city and communities.",
            "contribution_ids": [
                "R74135"
            ]
        },
        {
            "instance_id": "EMPTYxR171001",
            "comparison_id": "EMPTY",
            "paper_id": "R171001",
            "text": "Domestic Cats (Felis silvestris catus) Do Not Show Signs of Secure Attachment to Their Owners the ainsworth strange situation test (sst) has been widely used to demonstrate that the bond between both children and dogs to their primary carer typically meets the requirements of a secure attachment (i.e. the carer being perceived as a focus of safety and security in otherwise threatening environments), and has been adapted for cats with a similar claim made. however methodological problems in this latter research make the claim that the cat-owner bond is typically a secure attachment, operationally definable by its behaviour in the sst, questionable. we therefore developed an adapted version of the sst with the necessary methodological controls which include a full counterbalance of the procedure. a cross-over design experiment with 20 cat-owner pairs (10 each undertaking one of the two versions of the sst first) and continuous focal sampling was used to record the duration of a range of behavioural states expressed by the cats that might be useful for assessing secure attachment. since data were not normally distributed, non-parametric analyses were used on those behaviours shown to be reliable across the two versions of the test (which excluded much cat behaviour). although cats vocalised more when the owner rather the stranger left the cat with the other individual, there was no other evidence consistent with the interpretation of the bond between a cat and its owner meeting the requirements of a secure attachment. these results are consistent with the view that adult cats are typically quite autonomous, even in their social relationships, and not necessarily dependent on others to provide a sense of security and safety. it is concluded that alternative methods need to be developed to characterise the normal psychological features of the cat-owner bond.",
            "contribution_ids": [
                "R171002"
            ]
        },
        {
            "instance_id": "EMPTYxR171456",
            "comparison_id": "EMPTY",
            "paper_id": "R171456",
            "text": "Assortment, but not knowledge of assortment, affects cooperation and individual success in human groups the success or failure of human collective action often depends on the cooperation tendencies of individuals in groups, and on the information that individuals have about each other\u2019s cooperativeness. however, it is unclear whether these two factors have an interactive effect on cooperation dynamics. using a decision-making experiment, we confirm that groups comprising individuals with higher cooperation tendencies cooperate at a higher level than groups comprising individuals with low cooperation tendencies. moreover, assorting individuals with similar cooperation tendency together affected behaviour so that the most cooperative individuals tended to cooperate more and the least cooperative individuals cooperated less, compared to their behaviour in randomly formed groups. in line with predictions of evolutionary models of cooperation, there was a strong positive association between individuals\u2019 cooperation tendency and success when groups were formed assortatively, whereas such association did not exist when groups were formed randomly. surprisingly, information about group members\u2019 cooperativeness in assorted groups had no effect on cooperation levels. we discuss potential explanations for why information about cooperativeness of others may be disregarded in certain circumstances.",
            "contribution_ids": [
                "R171457",
                "R171458"
            ]
        },
        {
            "instance_id": "EMPTYxR74723",
            "comparison_id": "EMPTY",
            "paper_id": "R74723",
            "text": "Disability, Mobility and Transport in Low- and Middle-Income Countries: A Thematic Review this paper discusses issues affecting the transport and mobility needs of people with disabilities in middle- and low-income countries and how disability intersects with a range of other factors to impact on transport needs, use and engagement. the paper is intended to stimulate discussion and identify areas for further research, and identifies a number of key issues that are salient to discussions around equitable and inclusive transport provision, including patterns of transport use, behaviour and experiences, solutions and policy directions, measuring access and inclusion, policies and intersectionality. the paper also identifies gaps in knowledge and provision, barriers to addressing these gaps, and some possible solutions to overcoming these barriers. these include shifting the focus from access to inclusion, reconceptualising how \u2018special\u2019 transport might be provided, and most importantly listening to the voices and experiences of adults and children with disabilities. despite lack of transport often being cited as a reason for lack of inclusion of people with disabilities, there is surprisingly little evidence which either quantifies this or translates what this lack of access means to people with disabilities in their daily lives in low- and middle-income countries.",
            "contribution_ids": [
                "R74725"
            ]
        },
        {
            "instance_id": "EMPTYxR170363",
            "comparison_id": "EMPTY",
            "paper_id": "R170363",
            "text": "The Impact of Anxiety-Inducing Distraction on Cognitive Performance: A Combined Brain Imaging and Personality Investigation background previous investigations revealed that the impact of task-irrelevant emotional distraction on ongoing goal-oriented cognitive processing is linked to opposite patterns of activation in emotional and perceptual vs. cognitive control/executive brain regions. however, little is known about the role of individual variations in these responses. the present study investigated the effect of trait anxiety on the neural responses mediating the impact of transient anxiety-inducing task-irrelevant distraction on cognitive performance, and on the neural correlates of coping with such distraction. we investigated whether activity in the brain regions sensitive to emotional distraction would show dissociable patterns of co-variation with measures indexing individual variations in trait anxiety and cognitive performance. methodology/principal findings event-related fmri data, recorded while healthy female participants performed a delayed-response working memory (wm) task with distraction, were investigated in conjunction with behavioural measures that assessed individual variations in both trait anxiety and wm performance. consistent with increased sensitivity to emotional cues in high anxiety, specific perceptual areas (fusiform gyrus - fg) exhibited increased activity that was positively correlated with trait anxiety and negatively correlated with wm performance, whereas specific executive regions (right lateral prefrontal cortex - pfc) exhibited decreased activity that was negatively correlated with trait anxiety. the study also identified a role of the medial and left lateral pfc in coping with distraction, as opposed to reflecting a detrimental impact of emotional distraction. conclusions these findings provide initial evidence concerning the neural mechanisms sensitive to individual variations in trait anxiety and wm performance, which dissociate the detrimental impact of emotion distraction and the engagement of mechanisms to cope with distracting emotions. our study sheds light on the neural correlates of emotion-cognition interactions in normal behaviour, which has implications for understanding factors that may influence susceptibility to affective disorders, in general, and to anxiety disorders, in particular.",
            "contribution_ids": [
                "R170364"
            ]
        },
        {
            "instance_id": "EMPTYxR155532",
            "comparison_id": "EMPTY",
            "paper_id": "R155532",
            "text": "Linkage Between Dinitrogen Fixation and Primary Production in the Oligotrophic South Pacific Ocean the import of nitrogen via dinitrogen fixation supports primary production, particularly in the oligotrophic ocean; however, to what extent dinitrogen fixation influences primary production, and the role of specific types of diazotrophs, remains poorly understood. we examined the relationship between primary production and dinitrogen fixation together with diazotroph community structure in the oligotrophic western and eastern south pacific ocean and found that dinitrogen fixation was higher than nitrate\u2010based new production. primary production increased in the middle of the western subtropical region, where the cyanobacterium trichodesmium dominated the diazotroph community and accounted for up to 7.8% of the phytoplankton community, and the abundance of other phytoplankton taxa (especially prochlorococcus) was high. these results suggest that regenerated production was enhanced by nitrogen released from trichodesmium and that carbon fixation by trichodesmium also contributed significantly to total primary production. although volumetric dinitrogen fixation was comparable between the western and eastern subtropical regions, primary production in the western waters was more than twice as high as that in the eastern waters, where ucyn\u2010a1 (photoheterotroph) and heterotrophic bacteria were the dominant diazotrophs. this suggests that dinitrogen fixed by these diazotrophs contributed relatively little to primary production of the wider community, and there was limited carbon fixation by these diazotrophs. hence, we document how the community composition of diazotrophs in the field can be reflected in how much nitrogen becomes available to the wider phytoplankton community and in how much autotrophic diazotrophs themselves fix carbon and thereby influences the magnitude of local primary production.",
            "contribution_ids": [
                "R155534"
            ]
        },
        {
            "instance_id": "EMPTYxR171581",
            "comparison_id": "EMPTY",
            "paper_id": "R171581",
            "text": "Impact of an animal-assisted therapy programme on physiological and psychosocial variables of paediatric oncology patients the objective of this study was to propose an intervention and safety protocol for performing animal-assisted therapy (aat) and evaluating its efficacy in children under outpatient oncological treatment based on psychological, physiological, and quality of life indicators for the children and caregivers. the sample consisted of 24 children diagnosed with leukaemia and solid tumours (58% girls with a mean age of 8.0 years) who underwent an aat programme consisting of three 30-min sessions in an open group. two dogs (one labrador retriever and one golden retriever) were used, and activities such as sensory stimulation, gait training, and socialization were conducted. the exclusion criteria were severe mental problems, inability to answer the questions included in the instruments used, allergy to animals, unavailability/lack of interest, isolation precaution, surgical wound, use of invasive devices, ostomy, no current blood count for evaluation, neutropaenia, infection, fever, diarrhoea, vomiting, respiratory symptoms at the beginning of the intervention or 1 week before the intervention, hospitalization or scheduled surgery, and non-completion of the aat programme. the variables analysed using validated self or other evaluations were stress, pain, mood, anxiety, depression, quality of life, heart rate, and blood pressure. a quasi-experimental study design was used. we observed a decrease in pain (p = 0.046, d = \u20130.894), irritation (p = 0.041, d = \u20130.917), and stress (p = 0.005; d = \u20131.404) and a tendency towards improvement of depressive symptoms (p = 0.069; d = \u20130.801). among the caregivers, an improvement was observed in anxiety (p = 0.007, d = \u20131.312), mental confusion (p = 0.006, d = \u20131.350), and tension (p = 0.006, d = \u20131.361). therefore, the selection criteria and care protocols used for the aat programme in the oncological context were adequate, and the programme was effective.",
            "contribution_ids": [
                "R171582"
            ]
        },
        {
            "instance_id": "EMPTYxR186691",
            "comparison_id": "EMPTY",
            "paper_id": "R186691",
            "text": "Soil Organic Matter Prediction Model with Satellite Hyperspectral Image Based on Optimized Denoising Method in order to improve the signal-to-noise ratio of the hyperspectral sensors and exploit the potential of satellite hyperspectral data for predicting soil properties, we took mingshui county as the study area, which the study area is approximately 1481 km2, and we selected gaofen-5 (gf-5) satellite hyperspectral image of the study area to explore an applicable and accurate denoising method that can effectively improve the prediction accuracy of soil organic matter (som) content. first, fractional-order derivative (fod) processing is performed on the original reflectance (or) to evaluate the optimal fod. second, singular value decomposition (svd), fourier transform (ft) and discrete wavelet transform (dwt) are used to denoise the or and optimal fod reflectance. third, the spectral indexes of the reflectance under different denoising methods are extracted by optimal band combination algorithm, and the input variables of different denoising methods are selected by the recursive feature elimination (rfe) algorithm. finally, the som content is predicted by a random forest prediction model. the results reveal that 0.6-order reflectance describes more useful details in satellite hyperspectral data. five spectral indexes extracted from the reflectance under different denoising methods have a strong correlation with the som content, which is helpful for realizing high-accuracy som predictions. all three denoising methods can reduce the noise in hyperspectral data, and the accuracies of the different denoising methods are ranked dwt &gt; ft &gt; svd, where 0.6-order-dwt has the highest accuracy (r2 = 0.84, rmse = 3.36 g kg\u22121, and rpiq = 1.71). this paper is relatively novel, in that gf-5 satellite hyperspectral data based on different denoising methods are used to predict som, and the results provide a highly robust and novel method for mapping the spatial distribution of som content at the regional scale.",
            "contribution_ids": [
                "R186693"
            ]
        },
        {
            "instance_id": "EMPTYxR165663",
            "comparison_id": "EMPTY",
            "paper_id": "R165663",
            "text": "Cooperation and Punishment in Public Goods Experiments this paper provides evidence that free riders are heavily punished even if punishment is costly and does not provide any material benefits for the punisher. the more free riders negatively deviate from the group standard the more they are punished. as a consequence, the existence of an opportunity for costly punishment causes a large increase in cooperation levels because potential free riders face a credible threat. we show, in particular, that in the presence of a costly punishment opportunity almost complete cooperation can be achieved and maintained although, under the standard assumptions of rationality and selfishness, there should be no cooperation at all. we also show that free riding causes strong negative emotions among cooperators. the intensity of these emotions is the stronger the more the free riders deviate from the group standard. our results provide, therefore, support for the hypothesis that emotions are guarantors of credible threats.",
            "contribution_ids": [
                "R165677"
            ]
        },
        {
            "instance_id": "EMPTYxR170445",
            "comparison_id": "EMPTY",
            "paper_id": "R170445",
            "text": "From Social Network (Centralized vs. Decentralized) to Collective Decision-Making (Unshared vs. Shared Consensus) \"relationships we have with our friends, family, or colleagues influence our personal decisions, as well as decisions we make together with others. as in human beings, despotism and egalitarian societies seem to also exist in animals. while studies have shown that social networks constrain many phenomena from amoebae to primates, we still do not know how consensus emerges from the properties of social networks in many biological systems. we created artificial social networks that represent the continuum from centralized to decentralized organization and used an agent-based model to make predictions about the patterns of consensus and collective movements we observed according to the social network. these theoretical results showed that different social networks and especially contrasted ones \u2013 star network vs. equal network - led to totally different patterns. our model showed that, by moving from a centralized network to a decentralized one, the central individual seemed to lose its leadership in the collective movement's decisions. we, therefore, showed a link between the type of social network and the resulting consensus. by comparing our theoretical data with data on five groups of primates, we confirmed that this relationship between social network and consensus also appears to exist in animal societies.\"",
            "contribution_ids": [
                "R170446"
            ]
        },
        {
            "instance_id": "EMPTYxR206397",
            "comparison_id": "EMPTY",
            "paper_id": "R206397",
            "text": "Computer Science Named Entity Recognition in the Open Research Knowledge Graph . domain-speci\ufb01c named entity recognition (ner) on computer science (cs) scholarly articles is an information extraction task that is arguably more challenging for the various annotation aims that can beset the task and has been less studied than ner in the general domain. given that signi\ufb01cant progress has been made on ner, we believe that scholarly domain-speci\ufb01c ner will receive increasing attention in the years to come. currently, progress on cs ner \u2013 the focus of this work \u2013 is hampered in part by its recency and the lack of a standardized annotation aim for scienti\ufb01c entities/terms. this work proposes a standardized task by de\ufb01ning a set of seven contribution-centric scholarly entities for cs ner viz., research problem , solution , resource , language , tool , method , and dataset . following which, its main contributions are: combines existing cs ner resources that maintain their annotation focus on the set or subset of contribution-centric scholarly entities we consider; further, noting the need for big data to train neural ner models, this work additionally supplies thousands of contribution-centric entity annotations from article titles and abstracts, thus releasing a cumulative large novel resource for cs ner; and, \ufb01nally, trains a sequence labeling cs ner model inspired after state-of-the-art neural architectures from the general domain ner task. throughout the work, several practical considerations are made which can be useful to information technology designers of the digital libraries.",
            "contribution_ids": [
                "R206399"
            ]
        },
        {
            "instance_id": "EMPTYxR110289",
            "comparison_id": "EMPTY",
            "paper_id": "R110289",
            "text": "The Third Place: The Library as Collaborative and Community Space in a Time of Fiscal Restraint \"in a period of fiscal constraint, when assumptions about the library as place are being challenged, administrators question the contribution of every expense to student success. libraries have been successful in migrating resources and services to a digital environment accessible beyond the library. what is the role of the library as place when users do not need to visit the building to utilize library services and resources? we argue that the college library building's core role is as a space for collaborative learning and community interaction that cannot be jettisoned in the new normal.\"",
            "contribution_ids": [
                "R110291"
            ]
        },
        {
            "instance_id": "EMPTYxR75825",
            "comparison_id": "EMPTY",
            "paper_id": "R75825",
            "text": "Evidence-Based Decision-Making (Part II): Applications in Disaster Relief Operations abstract recognized limitations to data in disaster management have led to dozens of initiatives to strengthen data gathering and decision-making during disasters. these initiatives are complicated by fundamental problems of definitions of terms, ambiguity of concepts, lack of standardization in methods of data collection, and inadequate attempts to strengthen the analytic capability of field organizations. cross-cutting issues in needs assessment, coordination, and evaluation illustrate additional recurring challenges in dealing with evidence in humanitarian assistance. these challenges include lack of agency expertise, dyscoordination at the field level, inappropriate reliance on indicators that measure process rather than outcome, flawed scientific inference, and erosion of the concept of minimum standards. decision-making in disaster management currently places a premium on expert or eminence-based decisions. by contrast, scientific advances in disaster medicine call for evidence-based decisions whose strength of evidence is established by the methods of data acquisition. at present, disaster relief operations may be data driven, but that does not mean that they are soundly evidence-based. options for strengthening evidence-based activities include rigorously adhering to evidenced-based interventions, using evidence-based tools to identify new approaches to problems of concern, studying model programs as well as failed ones to identify approaches that deserve replication, and improving standards for evidence of effectiveness in disaster science and services.",
            "contribution_ids": [
                "R75827"
            ]
        },
        {
            "instance_id": "EMPTYxR169468",
            "comparison_id": "EMPTY",
            "paper_id": "R169468",
            "text": "The Influence of Work-Related Chronic Stress on the Regulation of Emotion and on Functional Connectivity in the Brain \"despite mounting reports about the negative effects of chronic occupational stress on cognitive and emotional functions, the underlying mechanisms are unknown. recent findings from structural mri raise the question whether this condition could be associated with a functional uncoupling of the limbic networks and an impaired modulation of emotional stress. to address this, 40 subjects suffering from burnout symptoms attributed to chronic occupational stress and 70 controls were investigated using resting state functional mri. the participants' ability to up- regulate, down-regulate, and maintain emotion was evaluated by recording their acoustic startle response while viewing neutral and negatively loaded images. functional connectivity was calculated from amygdala seed regions, using explorative linear correlation analysis. stressed subjects were less capable of down-regulating negative emotion, but had normal acoustic startle responses when asked to up-regulate or maintain emotion and when no regulation was required. the functional connectivity between the amygdala and the anterior cingulate cortex correlated with the ability to down-regulate negative emotion. this connectivity was significantly weaker in the burnout group, as was the amygdala connectivity with the dorsolateral prefrontal cortex and the motor cortex, whereas connectivity from the amygdala to the cerebellum and the insular cortex were stronger. in subjects suffering from chronic occupational stress, the functional couplings within the emotion- and stress-processing limbic networks seem to be altered, and associated with a reduced ability to down-regulate the response to emotional stress, providing a biological substrate for a further facilitation of the stress condition.\"",
            "contribution_ids": [
                "R169469",
                "R169470",
                "R169471",
                "R169472"
            ]
        },
        {
            "instance_id": "EMPTYxR171668",
            "comparison_id": "EMPTY",
            "paper_id": "R171668",
            "text": "Patients experiences of self-management and strategies for dealing with chronic conditions in rural Malawi background the high burden of chronic communicable diseases such as hiv/aids, and an escalating rise of non-communicable diseases (ncds) in malawi and other sub-saharan african countries, calls for a shift in how health care services are designed and delivered. patient-centred care and patient self-management are critical elements in chronic care, and are advocated as universal strategies. in sub-saharan africa, there is need for more evidence around the practice of patient self-management, and how to best support patients with chronic conditions in the african context. our study explored self-management practices of patients with different chronic conditions, and their strategies to overcome care challenges in a resource-constrained setting in malawi. methods this is primarily a qualitative study, involving patients with different chronic conditions from one rural district in malawi. data are drawn from semi-structured questions of a survey with 129 patients (from the third of four-part data collection series), 14 in-depth interviews, and four focus-group discussions with patients (n = 31 respondents). a framework approach was used for qualitative analysis, and descriptive statistical analysis was performed on survey data. results patients demonstrated ability to self-manage their conditions, though this varied between conditions, and was influenced by individual and external factors. factors included: 1) ability to acquire appropriate disease knowledge; 2) poverty level; 3) the presence of support from family caregivers and community-based support initiatives; 4) the nature of one\u2019s social relations; and 5) the ability to deal with stressors and stigma. ncd and hiv comorbid patients were more disadvantaged in their access to care, as they experienced frequent drug stock-outs and incurred additional costs when referred. these barriers contributed to delayed care, poorer treatment adherence, and likelihood of poorer treatment outcomes. patients proved resourceful and made adjustments in the face of (multiple) care challenges. conclusion our findings complement other research on self-management experiences in chronically ill patients with its analysis on factors and barriers that influence patient self-management capacity in a resource-constrained setting. we recommend expanding current peer-patient and support group initiatives to patients with ncds, and further investments in the decentralisation of integrated health services to primary care level in malawi.",
            "contribution_ids": [
                "R171669"
            ]
        },
        {
            "instance_id": "EMPTYxR193715",
            "comparison_id": "EMPTY",
            "paper_id": "R193715",
            "text": "Discriminative sentence compression with soft syntactic evidence we present a model for sentence compression that uses a discriminative largemargin learning framework coupled with a novel feature set defined on compressed bigrams as well as deep syntactic representations provided by auxiliary dependency and phrase-structure parsers. the parsers are trained out-of-domain and contain a significant amount of noise. we argue that the discriminative nature of the learning algorithm allows the model to learn weights relative to any noise in the feature set to optimize compression accuracy directly. this differs from current state-of-the-art models (knight and marcu, 2000) that treat noisy parse trees, for both compressed and uncompressed sentences, as gold standard when calculating model parameters.",
            "contribution_ids": [
                "R193717"
            ]
        },
        {
            "instance_id": "EMPTYxR12016",
            "comparison_id": "EMPTY",
            "paper_id": "R12016",
            "text": "Solving Mixed Model Workplace Time-dependent Assembly Line Balancing Problem with FSS Algorithm balancing assembly lines, a family of optimization problems commonly known as assembly line balancing problem, is notoriously np-hard. they comprise a set of problems of enormous practical interest to manufacturing industry due to the relevant frequency of this type of production paradigm. for this reason, many researchers on computational intelligence and industrial engineering have been conceiving algorithms for tackling different versions of assembly line balancing problems utilizing different methodologies. in this article, it was proposed a problem version referred as mixed model workplace time-dependent assembly line balancing problem with the intention of including pressing issues of real assembly lines in the optimization problem, to which four versions were conceived. heuristic search procedures were used, namely two swarm intelligence algorithms from the fish school search family: the original version, named \"vanilla\", and a special variation including a stagnation avoidance routine. either approaches solved the newly posed problem achieving good results when compared to particle swarm optimization algorithm.",
            "contribution_ids": [
                "R12018"
            ]
        },
        {
            "instance_id": "EMPTYxR169032",
            "comparison_id": "EMPTY",
            "paper_id": "R169032",
            "text": "Schizotypy and Behavioural Adjustment and the Role of Neuroticism objective in the present study the relationship between behavioural adjustment following cognitive conflict and schizotypy was investigated using a stroop colour naming paradigm. previous research has found deficits with behavioural adjustment in schizophrenia patients. based on these findings, we hypothesized that individual differences in schizotypy, a personality trait reflecting the subclinical expression of the schizophrenia phenotype, would be associated with behavioural adjustment. additionally, we investigated whether such a relationship would be explained by individual differences in neuroticism, a non-specific measure of negative trait emotionality known to be correlated with schizotypy. methods 106 healthy volunteers (mean age: 25.1, 60% females) took part. post-conflict adjustment was measured in a computer-based version of the stroop paradigm. schizotypy was assessed using the schizotypal personality questionnaire (spq) and neuroticism using the neo-ffi. results we found a negative correlation between schizotypy and post-conflict adjustment (r\\u200a=\\u200a\u2212.30, p<.01); this relationship remained significant when controlling for effects of neuroticism. regression analysis revealed that particularly the subscale no close friends drove the effect. conclusion previous findings of deficits in cognitive control in schizophrenia patients were extended to the subclinical personality expression of the schizophrenia phenotype and found to be specific to schizotypal traits over and above the effects of negative emotionality.",
            "contribution_ids": [
                "R169033"
            ]
        },
        {
            "instance_id": "EMPTYxR171428",
            "comparison_id": "EMPTY",
            "paper_id": "R171428",
            "text": "Social interactions between live and artificial weakly electric fish: Electrocommunication and locomotor behavior of Mormyrus rume proboscirostris towards a mobile dummy fish \"mormyrid weakly electric fish produce short, pulse-type electric organ discharges for actively probing their environment and to communicate with conspecifics. animals emit sequences of pulse-trains that vary in overall frequency and temporal patterning and can lead to time-locked interactions with the discharge activity of other individuals. both active electrolocation and electrocommunication are additionally accompanied by stereotypical locomotor patterns. however, the concrete roles of electrical and locomotor patterns during social interactions in mormyrids are not well understood. here we used a mobile fish dummy that was emitting different types of electrical playback sequences to study following behavior and interaction patterns (electrical and locomotor) between individuals of weakly electric fish. we confronted single individuals of mormyrus rume proboscirostris with a mobile dummy fish designed to attract fish from a shelter and recruit them into an open area by emitting electrical playbacks of natural discharge sequences. we found that fish were reliably recruited by the mobile dummy if it emitted electrical signals and followed it largely independently of the presented playback patterns. while following the dummy, fish interacted with it spatially by displaying stereotypical motor patterns, as well as electrically, e.g. through discharge regularizations and by synchronizing their own discharge activity to the playback. however, the overall emission frequencies of the dummy were not adopted by the following fish. instead, social signals based on different temporal patterns were emitted depending on the type of playback. in particular, double pulses were displayed in response to electrical signaling of the dummy and their expression was positively correlated with an animals' rank in the dominance hierarchy. based on additional analysis of swimming trajectories and stereotypical locomotor behavior patterns, we conclude that the reception and emission of electrical communication signals play a crucial role in mediating social interactions in mormyrid weakly electric fish.\"",
            "contribution_ids": [
                "R171429",
                "R171430"
            ]
        },
        {
            "instance_id": "EMPTYxR168945",
            "comparison_id": "EMPTY",
            "paper_id": "R168945",
            "text": "Virulence in Murine Model Shows the Existence of Two Distinct Populations of Brazilian Vaccinia virus Strains brazilian vaccinia virus had been isolated from sentinel mice, rodents and recently from humans, cows and calves during outbreaks on dairy farms in several rural areas in brazil, leading to high economic and social impact. some phylogenetic studies have demonstrated the existence of two different populations of brazilian vaccinia virus strains circulating in nature, but little is known about their biological characteristics. therefore, our goal was to study the virulence pattern of seven brazilian vaccinia virus strains. infected balb/c mice were monitored for morbidity, mortality and viral replication in organs as trachea, lungs, heart, kidneys, liver, brain and spleen. based on the virulence potential, the brazilian vaccinia virus strains were grouped into two groups. one group contained gp1v, vbh, sav and bav which caused disease and death in infected mice and the second one included arav, gp2v and pstv which did not cause any clinical signals or death in infected balb/c mice. the subdivision of brazilian vaccinia virus strains into two groups is in agreement with previous genetic studies. those data reinforce the existence of different populations circulating in brazil regarding the genetic and virulence characteristics.",
            "contribution_ids": [
                "R168946"
            ]
        },
        {
            "instance_id": "EMPTYxR170033",
            "comparison_id": "EMPTY",
            "paper_id": "R170033",
            "text": "Neuroimaging of decoding and language comprehension in young very low birth weight (VLBW) adolescents: Indications for compensatory mechanisms in preterm children with very low birth weight (vlbw \u2264 1500 g), reading problems are often observed. reading comprehension is dependent on word decoding and language comprehension. we investigated neural activation\u2013within brain regions important for reading\u2013related to components of reading comprehension in young vlbw adolescents in direct comparison to normal birth weight (nbw) term-born peers, with the use of functional magnetic resonance imaging (fmri). we hypothesized that the decoding mechanisms will be affected by vlbw, and expect to see increased neural activity for vlbw which may be modulated by task performance and cognitive ability. the study investigated 13 (11 included in fmri) young adolescents (ages 12 to 14 years) born preterm with vlbw and in 13 nbw controls (ages 12\u201314 years) for performance on the block design and vocabulary subtests of the wechsler intelligence scale for children; and for semantic, orthographic, and phonological processing during an fmri paradigm. the vlbw group showed increased phonological activation in left inferior frontal gyrus, decreased orthographic activation in right supramarginal gyrus, and decreased semantic activation in left inferior frontal gyrus. block design was related to altered right-hemispheric activation, and vlbw showed lower wisc block design scores. left angular gyrus showed activation increase specific for vlbw with high accuracy on the semantic test. young vlbw adolescents showed no accuracy and reaction time performance differences on our fmri language tasks, but they did exhibit altered neural activation during these tasks. this altered activation for vlbw was observed as increased activation during phonological decoding, and as mainly decreased activation during orthographic and semantic processing. correlations of neural activation with accuracy on the semantic fmri task and with decreased wisc block design performance were specific for the vlbw group. together, results suggest compensatory mechanisms by recruiting additional brain regions upon altered neural development of decoding for vlbw.",
            "contribution_ids": [
                "R170034",
                "R170035",
                "R170036",
                "R170037",
                "R170038"
            ]
        },
        {
            "instance_id": "EMPTYxR170902",
            "comparison_id": "EMPTY",
            "paper_id": "R170902",
            "text": "Latent Factor Modeling of Four Schizotypy Dimensions with Theory of Mind and Empathy preliminary evidence suggests that theory of mind and empathy relate differentially to factors of schizotypy. the current study assessed 686 undergraduate students and used structural equation modeling to examine links between a four-factor model of schizotypy with performance on measures of theory of mind (reading the mind in the eyes test [mie]) and empathy (interpersonal reactivity index [iri]). schizotypy was assessed using three self-report measures which were simultaneously entered into the model. results revealed that the negative factor of schizotypy showed a negative relationship with the empathy factor, which was primarily driven by the empathic concern subscale of the iri and the no close friends and constricted affect subscales of the schizotypal personality questionnaire. these findings are consistent with a growing body of literature suggesting a relatively specific relationship between negative schizotypy and empathy, and are consistent with several previous studies that found no relationship between mie performance and schizotypy.",
            "contribution_ids": [
                "R170903"
            ]
        },
        {
            "instance_id": "EMPTYxR170692",
            "comparison_id": "EMPTY",
            "paper_id": "R170692",
            "text": "Differences in Simulated Doctor and Patient Medical Decision Making: A Construal Level Perspective background patients are often confronted with diverse medical decisions. often lacking relevant medical knowledge, patients fail to independently make medical decisions and instead generally rely on the advice of doctors. objective this study investigated the characteristics of and differences in doctor\u2013patient medical decision making on the basis of construal level theory. methods a total of 420 undergraduates majoring in clinical medicine were randomly assigned to six groups. their decisions to opt for radiotherapy and surgery were investigated, with the choices described in a positive/neutral/negative frame \u00d7 decision making for self/others. results compared with participants giving medical advice to patients, participants deciding for themselves were more likely to select radiotherapy (f1, 404\\u200a=\\u200a13.92, p\\u200a=\\u200a011). participants from positive or neutral frames exhibited a higher tendency to choose surgery than did those from negative frames (f2, 404\\u200a=\\u200a22.53, p<.001). the effect of framing on independent decision making was nonsignificant (f2, 404\\u200a=\\u200a1.07, p\\u200a=\\u200a35); however the effect of framing on the provision of advice to patients was significant (f2, 404\\u200a=\\u200a12.95, p<.001). the effect of construal level was significant in the positive frame (f1, 404\\u200a=\\u200a8.06, p\\u200a=\\u200a005) and marginally significant in the neutral frame (f2, 404\\u200a=\\u200a3.31, p\\u200a=\\u200a07) but nonsignificant in the negative frame (f2, 404\\u200a=\\u200a.29, p\\u200a=\\u200a59). conclusion both social distance and framing depiction significantly affected medical decision making and exhibited a significant interaction. differences in medical decision making between doctors and patients need further investigation.",
            "contribution_ids": [
                "R170693"
            ]
        },
        {
            "instance_id": "EMPTYxR155349",
            "comparison_id": "EMPTY",
            "paper_id": "R155349",
            "text": "Flexible Self-Aligned Double-Gate IGZO TFT in this letter, flexible double-gate (dg) thin-film transistors (tfts) based on ingazno4 and fabricated on free standing plastic foil, using self-alignment (sa) are presented. the usage of transparent indium-tin-oxide instead of opaque metals enables sa of source-, drain-, and top-gate contacts. hence, all layers, which can cause parasitic capacitances, are structured by sa. compared with bottom-gate reference tfts fabricated on the same substrate, dg tfts exhibit a by 68% increased transconductance and a subthreshold swing as low as 109 mv/dec decade (-37%). the clockwise hysteresis of the dg tfts is as small as 5 mv. because of sa, the source/drain to gate overlaps are as small as \u2248 1 \u03bcm leading to parasitic overlap capacitances of 5.5 ff \u03bcm-1. therefore a transit frequency of 5.6 mhz is measured on 7.5 \u03bcm long transistors. in addition, the flexible devices stay fully operational when bent to a tensile radius of 6 mm.",
            "contribution_ids": [
                "R155351"
            ]
        },
        {
            "instance_id": "EMPTYxR147402",
            "comparison_id": "EMPTY",
            "paper_id": "R147402",
            "text": "Pegmatite spectral behavior considering ASTER and Landsat 8 OLI data in Naipa and Muiane mines (Alto Ligonha, Mozambique) the naipa and muiane mines are located on the nampula complex, a stratigraphic tectonic subdivision of the mozambique belt, in the alto ligonha region. the pegmatites are of the li-cs-ta type, intrude a chlorite phyllite and gneisses with amphibole and biotite. the mines are still active. the main objective of this work was to analyze the pegmatite\u2019s spectral behavior considering aster and landsat 8 oli data. an aster image from 27/05/2005, and an image landsat oli image from 02/02/2018 were considered. the data were radiometric calibrated and after atmospheric corrected considered the dark object subtraction algorithm available in the semi-automatic classification plugin accessible in qgis software. in the field, samples were collected from lepidolite waste pile in naipa and muaine mines. a spectroadiometer was used in order to analyze the spectral behavior of several pegmatite\u2019s samples collected in the field in alto ligonha (naipa and muiane mines). in addition, qgis software was also used for the spectral mapping of the hypothetical hydrothermal alterations associated with occurrences of basic metals, beryl gemstones, tourmalines, columbite-tantalites, and lithium minerals. a supervised classification algorithm was employed - spectral angle mapper for the data processing, and the overall accuracy achieved was 80%. the integration of aster and landsat 8 oli data have proved very useful for pegmatite\u2019s mapping. from the results obtained, we can conclude that: (i) the combination of aster and landsat 8 oli data allows us to obtain more information about mineral composition than just one sensor, i.e., these two sensors are complementary; (ii) the alteration spots identified in the mines area are composed of clay minerals. in the future, more data and others image processing algorithms can be applied in order to identify the different lithium minerals, as spodumene, petalite, amblygonite and lepidolite.",
            "contribution_ids": [
                "R147404"
            ]
        },
        {
            "instance_id": "EMPTYxR170222",
            "comparison_id": "EMPTY",
            "paper_id": "R170222",
            "text": "Pre-Roman improvements to agricultural production: Evidence from livestock husbandry in late prehistoric Italy domestication of wild cattle, sheep, and pigs began a process of body size diminution. in most of western europe this process continued across prehistory and was not reversed until the roman period. however, in italy, an increase in livestock body size occurred during the iron age, earlier than the western provinces. in order to better understand the nature and timing of this early increase in animal size, this paper presents a detailed regional study of taxonomic abundance and biometric data from zooarchaeological assemblages recovered from the po and venetian\u2013friulian plains in northern italy. our results demonstrate a high level of regionality in the choice of species exploited, with husbandry systems focused on different domesticates, as well as regional differences in animal size. however, despite significant variation in species frequencies, settlement structure, and epigraphic tradition, all areas with sufficient data demonstrate similar significant changes in livestock body size. cattle and sheep increased incrementally in size prior to the roman conquest in all regions considered; surprisingly, pigs continued to decrease in size throughout later prehistory. the incremental pace and pan-regional character of the size change in cattle and sheep suggests an internally motivated phenomenon rather than herd replacement with a new larger population, as might follow colonisation or conquest. the divergence in size trends for bovids and suids suggests a noteworthy change in cattle and sheep herding practices during the iron age or final centuries of the bronze age, in contrast with greater continuity in pig management. our analysis provides a thorough zooarchaeological synthesis for northern italy and, for the first time, demonstrates that both cattle and sheep increased in size outside of roman territory well before the conquest of this area. this study offers a basis for future chemical analyses (dna, isotopes), which will further investigate the cause(s) of livestock size changes in northern italy.",
            "contribution_ids": [
                "R170223"
            ]
        },
        {
            "instance_id": "EMPTYxR196166",
            "comparison_id": "EMPTY",
            "paper_id": "R196166",
            "text": "Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies the success of long short-term memory (lstm) neural networks in language processing is typically attributed to their ability to capture long-distance statistical regularities. linguistic regularities are often sensitive to syntactic structure; can such dependencies be captured by lstms, which do not have explicit structural representations? we begin addressing this question using number agreement in english subject-verb dependencies. we probe the architecture\u2019s grammatical competence both using training objectives with an explicit grammatical target (number prediction, grammaticality judgments) and using language models. in the strongly supervised settings, the lstm achieved very high overall accuracy (less than 1% errors), but errors increased when sequential and structural information conflicted. the frequency of such errors rose sharply in the language-modeling setting. we conclude that lstms can capture a non-trivial amount of grammatical structure given targeted supervision, but stronger architectures may be required to further reduce errors; furthermore, the language modeling signal is insufficient for capturing syntax-sensitive dependencies, and should be supplemented with more direct supervision if such dependencies need to be captured.",
            "contribution_ids": [
                "R196168"
            ]
        },
        {
            "instance_id": "EMPTYxR155200",
            "comparison_id": "EMPTY",
            "paper_id": "R155200",
            "text": "Martian minerals components at Gale crater detected by MRO CRISM hyperspectral images \"gale crater on mars has the layered structure of deposit covered by the noachian/hesperian boundary. mineral identification and classification at this region can provide important constrains on environment and geological evolution for mars. although curiosity rove has provided the in-situ mineralogical analysis in gale, but it restricted in small areas. compact reconnaissance imaging spectrometer for mars (crism) aboard the mars reconnaissance orbiter (mro) with enhanced spectral resolution can provide more information in spatial and time scale. in this paper, crism near-infrared spectral data are used to identify mineral classes and groups at martian gale region. by using diagnostic absorptions features analysis in conjunction with spectral angle mapper (sam), detailed mineral species are identified at gale region, e.g., kaolinite, chlorites, smectite, jarosite, and northupite. the clay minerals' diversity in gale crater suggests the variation of aqueous alteration. the detection of northupite suggests that the gale region has experienced the climate change from moist condition with mineral dissolution to dryer climate with water evaporation. the presence of ferric sulfate mineral jarosite formed through the oxidation of iron sulfides in acidic environments shows the experience of acidic sulfur-rich condition in gale history.\"",
            "contribution_ids": [
                "R155202"
            ]
        },
        {
            "instance_id": "EMPTYxR166596",
            "comparison_id": "EMPTY",
            "paper_id": "R166596",
            "text": "Ontologies in Portal Design portals are becoming more and more ubiquitous on the internet and that is why their architecture is a topic of concern among domain stakeholders. in order to ensure a solid architecture in portal design, ontologies must be considered as a necessary agent of design. an ontology provides a classification system for all the data and metadata in a domain. ontologies supply metadata in order to bring about a streamlined delivery of information to users. while portals exist in order to assist users gain access to information, ontologies enhance portals by providing access to relevant information.",
            "contribution_ids": [
                "R166598"
            ]
        },
        {
            "instance_id": "EMPTYxR170228",
            "comparison_id": "EMPTY",
            "paper_id": "R170228",
            "text": "Results from e-KISS: electronic-KIOSK Intervention for Safer Sex: A pilot randomized controlled trial of an interactive computer-based intervention for sexual health in adolescents and young adults introduction interactive computer-based interventions (icbi) are potentially scalable tools for use in real-world settings to promote sexual health and prevent sexually transmitted infections (stis) and unintended pregnancies. we developed and assessed the feasibility and acceptability of an icbi for promoting adolescent and young adult sexual health, and the effectiveness of the intervention in reducing unprotected sex, stis, and unintended pregnancy. methods this pilot randomized controlled trial enrolled sti clinic patients, in seattle, washington, who were 14\u201324 years old and reported unprotected vaginal sex during the last 2 months. both the control and intervention group used a computerized survey to enter their sexual health and only the intervention group received the icbi. the icbi included personalized sexual health feedback from a physician avatar; instructive video modules advocating sexual health; and identification of one behavior to change. at 3-month follow-up, participants reported on interim sexual and pregnancy histories and underwent repeat sti testing. we assessed intervention impact on unprotected vaginal sex, number of sexual partners, incident stis, and unintended pregnancy. results of 272 participants, 242 (89%) completed the study, of whom 65% were female. while these findings did not reach statistical significance, at 3-month follow-up, the intervention group reported a 33% lower rate of unprotected vaginal sex (no condom use) [irr = 0.67, 95% ci: 0.44\u20131.02]; 29% fewer sex partners [irr = 0.71, 95% ci: 0.50\u20131.03]; and 48% fewer stis [irr = 0.52, 95% ci: 0.25\u20131.08] when compared to the control group. similarly, as compared to the control group, intervention females reported a lower rate of unprotected vaginal sex (no birth control) [irr = 0.80, 95% ci: 0.47\u20131.35] and half as many unintended pregnancies (n = 5) versus control females (n = 10) [irr = 0.51, 95% ci: 0.17\u20131.58]. in exploratory analyses, intervention females reported fewer partners [irr = 0.71, 95% ci: 0.50\u20131.00] and a significantly lower rate of vaginal sex without condoms [irr = 0.50, 95% ci: 0.30\u20130.85]. conclusion the intervention was acceptable to both males and females, and at 3-month follow-up, there were non-significant reductions in risk behavior for all outcomes. among females, exploratory analysis showed a significant reduction in vaginal sex without condoms.",
            "contribution_ids": [
                "R170229",
                "R170230"
            ]
        },
        {
            "instance_id": "EMPTYxR191038",
            "comparison_id": "EMPTY",
            "paper_id": "R191038",
            "text": "Digital Methods for Hashtag Engagement Research this article seeks to contribute to the field of digital research by critically accounting for the relationship between hashtags and their forms of grammatization\u2014the platform techno-materialization process of online activity. we approach hashtags as sociotechnical formations that serve social media research not only as criteria in corpus selection but also displaying the complexity of the online engagement and its entanglement with the technicity of web platforms. therefore, the study of hashtag engagement requires a grasping of the functioning of the platform itself (technicity) along with the platform grammatization. in this respect, we propose the three-layered (3l) perspective for addressing hashtag engagement. the first contemplates potential differences between high-visibility and ordinary hashtag usage culture, its related actors, and content. the second focuses on hashtagging activity and the repurposing of how hashtags can be differently embedded into social media databases. the last layer looks particularly into the images and texts to which hashtags are brought to relation. to operationalize the 3l framework, we draw on the case of the \u201cimpeachment-cum-coup\u201d of brazilian president dilma rousseff. when cross-read, the three layers add value to one another, providing also difference visions of the high-visibility and ordinary groups.",
            "contribution_ids": [
                "R191041"
            ]
        },
        {
            "instance_id": "EMPTYxR184042",
            "comparison_id": "EMPTY",
            "paper_id": "R184042",
            "text": "Innovation under pressure: Implications for data privacy during the Covid-19 pandemic the global covid-19 pandemic has resulted in social and economic disruption unprecedented in the modern era. many countries have introduced severe measures to contain the virus, including travel restrictions, public event bans, non-essential business closures and remote work policies. while digital technologies help governments and organizations to enforce protection measures, such as contact tracing, their rushed deployment and adoption also raises profound concerns about surveillance, privacy and data protection. this article presents two critical cases on digital surveillance technologies implemented during the covid-19 pandemic and delineates the privacy implications thereof. we explain the contextual nature of privacy trade-offs during a pandemic and explore how regulatory and technical responses are needed to protect privacy in such circumstances. by providing a multi-disciplinary conversation on the value of privacy and data protection during a global pandemic, this article reflects on the implications digital solutions have for the future and raises the question of whether there is a way to have expedited privacy assessments that could anticipate and help mitigate adverse privacy implications these may have on society.",
            "contribution_ids": [
                "R184043"
            ]
        },
        {
            "instance_id": "EMPTYxR71565",
            "comparison_id": "EMPTY",
            "paper_id": "R71565",
            "text": "Bright Visible-Infrared Light Emitting Diodes Based on Hybrid Halide Perovskite with Spiro-OMeTAD as a Hole-Injecting Layer hybrid halide perovskites that are currently intensively studied for photovoltaic applications, also present outstanding properties for light emission. here, we report on the preparation of bright solid state light emitting diodes (leds) based on a solution-processed hybrid lead halide perovskite (pe). in particular, we have utilized the perovskite generally described with the formula ch3nh3pbi(3-x)cl(x) and exploited a configuration without electron or hole blocking layer in addition to the injecting layers. compact tio2 and spiro-ometad were used as electron and hole injecting layers, respectively. we have demonstrated a bright combined visible-infrared radiance of 7.1 w\u00b7sr(-1)\u00b7m(-2) at a current density of 232 ma\u00b7cm(-2), and a maximum external quantum efficiency (eqe) of 0.48%. the devices prepared surpass the eqe values achieved in previous reports, considering devices with just an injecting layer without any additional blocking layer. significantly, the maximum eqe value of our devices is obtained at applied voltages as low as 2 v, with a turn-on voltage as low as the pe band gap (v(turn-on) = 1.45 \u00b1 0.06 v). this outstanding performance, despite the simplicity of the approach, highlights the enormous potentiality of pe-leds. in addition, we present a stability study of unsealed pe-leds, which demonstrates a dramatic influence of the measurement atmosphere on the performance of the devices. the decrease of the electroluminescence (el) under continuous operation can be attributed to an increase of the non-radiative recombination pathways, rather than a degradation of the perovskite material itself.",
            "contribution_ids": [
                "R71567"
            ]
        },
        {
            "instance_id": "EMPTYxR209234",
            "comparison_id": "EMPTY",
            "paper_id": "R209234",
            "text": "Document-level relation extraction with adaptive thresholding and localized context pooling document-level relation extraction (re) poses new challenges compared to its sentence-level re counterpart. one document commonly contains multiple entity pairs, and one entity pair occurs multiple times in the document associated with multiple possible relations. in this paper, we propose two novel techniques, adaptive thresholding and localized context pooling, to solve the multilabel and multi-entity problems. the adaptive thresholding replaces the global threshold for multi-label classification in the prior work by a learnable entities-dependent threshold. the localized context pooling directly transfers attention from pre-trained language models to locate relevant context that is useful to decide the relation. we experiment on three document-level re benchmark datasets: docred, a recently released large-scale re dataset, and two datasets cdr and gda in the biomedical domain. our atlop (adaptive thresholding and localized context pooling) model achieves an f1 score of 63.4; and also significantly outperforms existing models on both cdr and gda.",
            "contribution_ids": [
                "R209236"
            ]
        },
        {
            "instance_id": "EMPTYxR169013",
            "comparison_id": "EMPTY",
            "paper_id": "R169013",
            "text": "The Neurotropic Parasite Toxoplasma Gondii Increases Dopamine Metabolism \"the highly prevalent parasite toxoplasma gondii manipulates its host's behavior. in infected rodents, the behavioral changes increase the likelihood that the parasite will be transmitted back to its definitive cat host, an essential step in completion of the parasite's life cycle. the mechanism(s) responsible for behavioral changes in the host is unknown but two lines of published evidence suggest that the parasite alters neurotransmitter signal transduction: the disruption of the parasite-induced behavioral changes with medications used to treat psychiatric disease (specifically dopamine antagonists) and identification of a tyrosine hydroxylase encoded in the parasite genome. in this study, infection of mammalian dopaminergic cells with t. gondii enhanced the levels of k+-induced release of dopamine several-fold, with a direct correlation between the number of infected cells and the quantity of dopamine released. immunostaining brain sections of infected mice with dopamine antibody showed intense staining of encysted parasites. based on these analyses, t. gondii orchestrates a significant increase in dopamine metabolism in neural cells. tyrosine hydroxylase, the rate-limiting enzyme for dopamine synthesis, was also found in intracellular tissue cysts in brain tissue with antibodies specific for the parasite-encoded tyrosine hydroxylase. these observations provide a mechanism for parasite-induced behavioral changes. the observed effects on dopamine metabolism could also be relevant in interpreting reports of psychobehavioral changes in toxoplasmosis-infected humans.\"",
            "contribution_ids": [
                "R169014",
                "R169015",
                "R169016"
            ]
        },
        {
            "instance_id": "EMPTYxR146888",
            "comparison_id": "EMPTY",
            "paper_id": "R146888",
            "text": "High-performance fullerene-free polymer solar cells with 6.31% efficiency a nonfullerene electron acceptor (ieic) based on indaceno[1,2- b :5,6- b \u2032]dithiophene and 2-(3-oxo-2,3-dihydroinden-1-ylidene)malononitrile was designed and synthesized, and fullerene-free polymer solar cells based on the ieic acceptor showed power conversion efficiencies of up to 6.31%.",
            "contribution_ids": [
                "R146891"
            ]
        },
        {
            "instance_id": "EMPTYxR170441",
            "comparison_id": "EMPTY",
            "paper_id": "R170441",
            "text": "Fluctuating Environments, Sexual Selection and the Evolution of Flexible Mate Choice in Birds environmentally-induced fluctuation in the form and strength of natural selection can drive the evolution of morphology, physiology, and behavior. here we test the idea that fluctuating climatic conditions may also influence the process of sexual selection by inducing unexpected reversals in the relative quality or sexual attractiveness of potential breeding partners. although this phenomenon, known as \u2018ecological cross-over\u2019, has been documented in a variety of species, it remains unclear the extent to which it has driven the evolution of major interspecific differences in reproductive behavior. we show that after controlling for potentially influential life history and demographic variables, there are significant positive associations between the variability and predictability of annual climatic cycles and the prevalence of infidelity and divorce within populations of a taxonomically diverse array of socially monogamous birds. our results are consistent with the hypothesis that environmental factors have shaped the evolution of reproductive flexibility and suggest that in the absence of severe time constraints, secondary mate choice behaviors can help prevent, correct, or minimize the negative consequences of ecological cross-overs. our findings also illustrate how a basic evolutionary process like sexual selection is susceptible to the increasing variability and unpredictability of climatic conditions that is resulting from climate change.",
            "contribution_ids": [
                "R170442"
            ]
        },
        {
            "instance_id": "EMPTYxR144129",
            "comparison_id": "EMPTY",
            "paper_id": "R144129",
            "text": "Representing the Hierarchy of Industrial Taxonomies in OWL: The gen/tax Approach existing taxonomies are valuable input for creating ontologies, because they reflect some degree of community consensus and contain, readily available, a wealth of concept definitions plus a hierarchy. however, the transformation of such taxonomies into useful ontologies is not as straightforward as it appears, because simply taking the hierarchy of concepts, which was originally developed for some external purpose other than ontology engineering, as the subsumption hierarchy using rdfs:subclassof can yield useless ontologies. in this paper, we (1) illustrate the problem by analyzing owl and rdf-s ontologies derived from unspsc (a products and services taxonomy), (2) detail how the interpretation and representation of the original taxonomic relationship is an important modeling decision when deriving ontologies from existing taxonomies, (3) propose a novel \u201cgen/tax\u201d approach to capture the original semantics of taxonomies in owl, based on the split of each category in the taxonomy into two concepts, a generic concept and a taxonomy concept, and (4) show the usefulness of this approach by transforming ecl@ss into a fully-fledged products and services ontology.",
            "contribution_ids": [
                "R144131"
            ]
        },
        {
            "instance_id": "EMPTYxR169299",
            "comparison_id": "EMPTY",
            "paper_id": "R169299",
            "text": "History of Childhood Abuse, Sensation Seeking, and Intimate Partner Violence under/Not under the Influence of a Substance: A Cross-Sectional Study in Russia objectives to examine correlates of perpetration and victimization of intimate partner violence (ipv) under and not under the influence of a substance, we conducted a study among women in russia. methods in 2011, a cross-sectional survey was conducted among patients receiving services at a clinic for sexually transmitted infections in st. petersburg, russia. multinomial logistic regression was used for analysis. results of 299 women, 104 (34.8%) and 113 (37.8%) reported a history of ipv perpetration and victimization, respectively. nearly half (47.1%) of perpetrators and 61.1% of victims reported that the latest ipv event (perpetration and victimization, respectively) was experienced under the influence of a substance. factors independently associated with ipv victimization under the influence of a substance were alcohol misuse and a higher number of lifetime sex partners, whereas only experience of childhood abuse (emotional and physical abuse) was independently associated with ipv victimization that did not occur under the influence of a substance. childhood physical abuse, lower age of first sex, sensation seeking, and alcohol misuse were independently associated with ipv perpetration under the influence of a substance, while only childhood abuse (emotional and physical abuse) was independently associated with ipv perpetration that did not occur under the influence of a substance. conclusions ipv under and not under the influence of a substance had different correlates (e.g., alcohol misuse and sensation seeking). despite the strong association between substance use and ipv, experience of childhood abuse is an important predictor of ipv perpetration and victimization in russia, above and beyond substance use.",
            "contribution_ids": [
                "R169300"
            ]
        },
        {
            "instance_id": "EMPTYxR74947",
            "comparison_id": "EMPTY",
            "paper_id": "R74947",
            "text": "Palm biomass waste as supplementary source of electricity generation in Ghana: Case of the Juaben Oil Mills the purpose of the study was to examine the potential of palm biomass, taking a case of the juaben oil mills in the ashanti region of ghana, which has over the years generated electricity for its operations from its waste products and other benefits that have accrued to the company and the host community. primary data collection and intensive desk study approaches were employed albeit qualitatively, to describe the use of palm biomass as supplementary source of electricity generation in ghana. the study showed that there is enough potential (waste by-products) for electricity generation to supplement current production from hydropower to meet growing demand. however, policy and institutional arrangements do not easily allow generation and extension for communal benefits. the authors therefore recommend a relook at existing policy and institutional arrangements to help promote this alternative source of energy for efficient and sustainable domestic and industrial uses. we also argue that ensuring efficiency in energy generation calls for r&amp;d into its commercial potential and explore more efficient means of managing industrial and other agro biofuel wastes in developing economies. future energy policy must also create and harness diversity of available biomass resources and reduce the delivery risks of the resources.",
            "contribution_ids": [
                "R74949"
            ]
        },
        {
            "instance_id": "EMPTYxR169211",
            "comparison_id": "EMPTY",
            "paper_id": "R169211",
            "text": "The Association of Sport Performance with ACE and ACTN3 Genetic Polymorphisms: A Systematic Review and Meta-Analysis background genetic polymorphism is suggested to be associated with human physical performance. the angiotensin i-converting enzyme insertion/deletion (ace i/d) polymorphism and the \u03b1-actinin-3 gene (actn3) r577x polymorphism have been most widely studied for such association analysis. however, the findings are frequently heterogeneous. we aim to summarize the associations of ace i/d and actn3 r577x with sport performance by means of meta-analysis. methods we systematically reviewed and quantitatively summarized published studies, until october 31, 2012, on relationship between ace/actn3 genetic polymorphisms and sports performance, respectively. results a total of 366 articles on ace and 88 articles on actn3 were achieved by literature search. a significant association was found for ace ii genotype compared to d allele carriage (dd+id) with increased possibility of physical performance (or, 1.23; 95% ci, 1.05\u20131.45). with respect to sport discipline, the ii genotype was found to be associated with performance in endurance athletes (or, 1.35; 95% ci, 1.17\u20131.55). on the other hand, no significant association was observed for actn3 rr genotype as compared to x allele carriage (xx+rx) (or, 1.03; 95% ci, 0.92\u20131.15). however, when restricted the analyses to power events, a significant association was observed (or, 1.21; 95% ci, 1.03\u20131.42). conclusion our results provide more solid evidence for the associations between ace ii genotype and endurance events and between actn3 r allele and power events. the findings suggest that the genetic profiles might influence human physical performance.",
            "contribution_ids": [
                "R169212"
            ]
        },
        {
            "instance_id": "EMPTYxR171591",
            "comparison_id": "EMPTY",
            "paper_id": "R171591",
            "text": "Work routines moderate the association between eveningness and poor psychological well-being well-being is a useful screening method for the detection of mood disorders. evidence associating psychological well-being with sleep-wake patterns exists, as well as associations with sleep-wake patterns, work-related parameters, and perceived self-efficacy. despite the growing research regarding the relationship between these factors and mental health, there are few studies that analyze them together. objective: to investigate if the association between sleep-wake patterns and psychological well-being is mediated or moderated by perceived self-efficacy, work flexibility and work routines. material and methods: this cohort study was performed in southern brazil. a sample of 987 individuals was analyzed (66.9% women; mean age = 43.9 years). work routines parameters and work schedule flexibility were evaluated, most participants were farmers (46%) and most worked 7 days a week (69.1%). munich chronotype questionnaire (mctq) was administered for evaluation of sleep-wake patterns, general self-efficacy scale (gse) for assessment the participants\u2019 beliefs about how they coped with daily hassles, and world health organization five-item well-being index (who-5) for evaluation of psychological well-being levels. moderation and mediation models were tested. results: the moderation model showed influences of work end time on the relationship between sleep onset time and psychological well-being (r2 = 0.147; f = 24.16; p<0.001). the final regression model showed an association of psychological well-being with sex (beta = -0.086; p = 0.004), sleep onset time (beta = -0.086; p = 0.006), and self-efficacy (beta = 0.316; p<0.001); the work end time showed association in the interaction with sleep onset time (beta = -0.075; p = 0.016). conclusion: the findings support the direct association of psychological well-being with sleep-wake patterns and self-efficacy, and show an interaction between work routines and sleep-wake patterns. our results draw attention to the importance of the interplay between individual and social rhythms in relation to psychological well-being.",
            "contribution_ids": [
                "R171592"
            ]
        },
        {
            "instance_id": "EMPTYxR170564",
            "comparison_id": "EMPTY",
            "paper_id": "R170564",
            "text": "Increased Drinking following Social Isolation Rearing: Implications for Polydipsia Associated with Schizophrenia primary polydipsia, excessive drinking without known medical cause, is especially associated with a diagnosis of schizophrenia. we used animal models of schizophrenia-like symptoms to examine the effects on schedule-induced polydipsia: post-weaning social isolation rearing, subchronic mk-801 treatment (an nmda-receptor antagonist) or the two combined. male, sprague-dawley rats reared in groups or in isolation beginning at postnatal day 21 were further divided to receive subchronic mk-801 (0.5 mg/kg twice daily) or saline for 7 days beginning on postnatal day 62. following a 4-day withdrawal period, all groups were trained on a schedule-induced polydipsia paradigm. under food-restriction, animals reared in isolation and receiving food pellets at 1-min intervals developed significantly more drinking behavior than those reared with others. the addition of subchronic mk-801 treatment did not significantly augment the amount of water consumed. these findings suggest a predisposition to polydipsia is a schizophrenia-like behavioral effect of post-weaning social isolation.",
            "contribution_ids": [
                "R170565"
            ]
        },
        {
            "instance_id": "EMPTYxR8034",
            "comparison_id": "EMPTY",
            "paper_id": "R8034",
            "text": "An Overview of CMIP5 and the Experiment Design \" the fifth phase of the coupled model intercomparison project (cmip5) will produce a state-of-the- art multimodel dataset designed to advance our knowledge of climate variability and climate change. researchers worldwide are analyzing the model output and will produce results likely to underlie the forthcoming fifth assessment report by the intergovernmental panel on climate change. unprecedented in scale and attracting interest from all major climate modeling groups, cmip5 includes \u201clong term\u201d simulations of twentieth-century climate and projections for the twenty-first century and beyond. conventional atmosphere\u2013ocean global climate models and earth system models of intermediate complexity are for the first time being joined by more recently developed earth system models under an experiment design that allows both types of models to be compared to observations on an equal footing. besides the longterm experiments, cmip5 calls for an entirely new suite of \u201cnear term\u201d simulations focusing on recent decades and the future to year 2035. these \u201cdecadal predictions\u201d are initialized based on observations and will be used to explore the predictability of climate and to assess the forecast system's predictive skill. the cmip5 experiment design also allows for participation of stand-alone atmospheric models and includes a variety of idealized experiments that will improve understanding of the range of model responses found in the more complex and realistic simulations. an exceptionally comprehensive set of model output is being collected and made freely available to researchers through an integrated but distributed data archive. for researchers unfamiliar with climate models, the limitations of the models and experiment design are described. \"",
            "contribution_ids": [
                "R8035"
            ]
        },
        {
            "instance_id": "EMPTYxR168785",
            "comparison_id": "EMPTY",
            "paper_id": "R168785",
            "text": "What Can Interaction Webs Tell Us About Species Roles? the group model is a useful tool to understand broad-scale patterns of interaction in a network, but it has previously been limited in use to food webs, which contain only predator-prey interactions. natural populations interact with each other in a variety of ways and, although most published ecological networks only include information about a single interaction type (e.g., feeding, pollination), ecologists are beginning to consider networks which combine multiple interaction types. here we extend the group model to signed directed networks such as ecological interaction webs. as a specific application of this method, we examine the effects of including or excluding specific interaction types on our understanding of species roles in ecological networks. we consider all three currently available interaction webs, two of which are extended plant-mutualist networks with herbivores and parasitoids added, and one of which is an extended intertidal food web with interactions of all possible sign structures (+/+, -/0, etc.). species in the extended food web grouped similarly with all interactions, only trophic links, and only nontrophic links. however, removing mutualism or herbivory had a much larger effect in the extended plant-pollinator webs. species removal even affected groups that were not directly connected to those that were removed, as we found by excluding a small number of parasitoids. these results suggest that including additional species in the network provides far more information than additional interactions for this aspect of network structure. our methods provide a useful framework for simplifying networks to their essential structure, allowing us to identify generalities in network structure and better understand the roles species play in their communities.",
            "contribution_ids": [
                "R168786",
                "R168787"
            ]
        },
        {
            "instance_id": "EMPTYxR166567",
            "comparison_id": "EMPTY",
            "paper_id": "R166567",
            "text": "Managing Knowledge and Scholarly Assets in Academic Libraries knowledge management (km) aspects have prominent role in corporate sectors since many years. but there is an opportunity in higher education sector (i.e. in academia) especially to adapt the strategy in libraries to manage intellectual or scholarly assets of an organization. this chapter is intended for library professionals, knowledge managers, students and other communities planning to implement the knowledge management aspects in libraries. the objective of this chapter is to provide insight on strategic approach for successful implementation of knowledge management in libraries. it caters to library and km professionals who want to improve their understanding of the vital role and implementation of km aspects in libraries. in this direction, this chapter provides ideas to its readers about the approaches about strategy and innovative measures, practical applications, tools and technologies, platforms, challenges, and issues, change management and other related aspects required for library and information science (lis) and knowledge management (km) professionals.",
            "contribution_ids": [
                "R166569"
            ]
        }
    ]
}